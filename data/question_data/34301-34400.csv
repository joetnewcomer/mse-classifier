,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Finding the minimum number of selections .,Finding the minimum number of selections .,,"Lets assume I have three boxes that contains only apples , only  oranges and a mix of apples and oranges respectively and all of them are mislabelled . What is the minimum number of selections that I need to make so that I can be certain which box contains what fruits assuming I can pick one fruit at a time from any of the boxes ? P.S: It is not a homework task . So don't put that tag in here . I was asked this in an interview. I was looking for  a interview tag but couldn't find one .","Lets assume I have three boxes that contains only apples , only  oranges and a mix of apples and oranges respectively and all of them are mislabelled . What is the minimum number of selections that I need to make so that I can be certain which box contains what fruits assuming I can pick one fruit at a time from any of the boxes ? P.S: It is not a homework task . So don't put that tag in here . I was asked this in an interview. I was looking for  a interview tag but couldn't find one .",,"['probability', 'combinatorics']"
1,Random walk and its expectation,Random walk and its expectation,,"Let $S_n=X_1+X_2+...+X_n$, where $X_i=1$ with probability $p$ and $X_i=-1$ with probability $q=1-p$, for all $i$ and independently of each other. Assume that $S_0=0$ and $0<p<\frac{1}{2}$. Show $$E\left(\sup\limits_{0\le k\le n}S_k\right) \le \frac{p}{q-p}$$ I would like to know how to prove it.","Let $S_n=X_1+X_2+...+X_n$, where $X_i=1$ with probability $p$ and $X_i=-1$ with probability $q=1-p$, for all $i$ and independently of each other. Assume that $S_0=0$ and $0<p<\frac{1}{2}$. Show $$E\left(\sup\limits_{0\le k\le n}S_k\right) \le \frac{p}{q-p}$$ I would like to know how to prove it.",,"['probability', 'random-walk']"
2,"Show the result of the following infinite sum, based on a binomial random variable conditioned on a Poisson random variable","Show the result of the following infinite sum, based on a binomial random variable conditioned on a Poisson random variable",,"$$\sum_{n=0}^\infty \binom{n}{k}p^k(1-p)^{n-k}\frac{\lambda^ne^{-\lambda}}{n!} = \frac{(\lambda p)^ke^{-\lambda p}}{k!}$$ That is, given a random variable $X$ with Poisson distribution $X \sim \operatorname{Poisson}(\lambda)$, and, given $X = n$, random variable $Y$ is distributed by a binomial such that $Y \sim B(n,p): p \in [0,1]$. Given $n$, $P(Y = k|X = n) = \binom{n}{k}p^k(1-p)^{n-k}$. Given $\lambda$, $P(X=n) = \dfrac{\lambda^ne^{-\lambda}}{n!}$. Therefore, $P(Y = k|\lambda) = \sum_{n=0}^\infty P(Y = k | X = n)P(X = n | \lambda) = \sum_{n=0}^\infty \binom{n}{k}p^k(1-p)^{n-k}\dfrac{\lambda^ne^{-\lambda}}{n!}$. What properties and identities can be used to demonstrate the equality above?","$$\sum_{n=0}^\infty \binom{n}{k}p^k(1-p)^{n-k}\frac{\lambda^ne^{-\lambda}}{n!} = \frac{(\lambda p)^ke^{-\lambda p}}{k!}$$ That is, given a random variable $X$ with Poisson distribution $X \sim \operatorname{Poisson}(\lambda)$, and, given $X = n$, random variable $Y$ is distributed by a binomial such that $Y \sim B(n,p): p \in [0,1]$. Given $n$, $P(Y = k|X = n) = \binom{n}{k}p^k(1-p)^{n-k}$. Given $\lambda$, $P(X=n) = \dfrac{\lambda^ne^{-\lambda}}{n!}$. Therefore, $P(Y = k|\lambda) = \sum_{n=0}^\infty P(Y = k | X = n)P(X = n | \lambda) = \sum_{n=0}^\infty \binom{n}{k}p^k(1-p)^{n-k}\dfrac{\lambda^ne^{-\lambda}}{n!}$. What properties and identities can be used to demonstrate the equality above?",,"['probability', 'sequences-and-series', 'probability-theory', 'probability-distributions']"
3,what is the behaviour of moving dot with 50% chance to go left or right?,what is the behaviour of moving dot with 50% chance to go left or right?,,"If a dot is moving (from zero) left or right, by one, with 50% chance to go left or right - is it going to go to the +inf or -inf when it has infinite moves?","If a dot is moving (from zero) left or right, by one, with 50% chance to go left or right - is it going to go to the +inf or -inf when it has infinite moves?",,"['probability', 'random-walk']"
4,Probabilistic Sieve of Eratosthenes,Probabilistic Sieve of Eratosthenes,,Consider the following algorithm: function Rand():     return a uniformly random real between 0.0 and 1.0  function Sieve(n):      assert(n >= 2)      for i = 2 to n         X[i] = true      for i = 2 to n         if (X[i])             for j = i+1 to n                 if (Rand() < 1/i)                     X[j] = false      return X[n] What is the probability that Sieve(k) returns true as a function of k ?  What is the limit of this probability as k goes to infinity (if it has one) ?,Consider the following algorithm: function Rand():     return a uniformly random real between 0.0 and 1.0  function Sieve(n):      assert(n >= 2)      for i = 2 to n         X[i] = true      for i = 2 to n         if (X[i])             for j = i+1 to n                 if (Rand() < 1/i)                     X[j] = false      return X[n] What is the probability that Sieve(k) returns true as a function of k ?  What is the limit of this probability as k goes to infinity (if it has one) ?,,"['probability', 'number-theory', 'algorithms']"
5,Expected value of Stock Price,Expected value of Stock Price,,"Someone plans to use x dollars buying some stock share, the stock price is $a$ dollars per share now. One year later, the stock price will possibly increase to $ra$ or decrease to $a/r$ (r>1) which the probability is $p$, or remain the price now which probability is $1-2p$. If he want to own more shares, should he buy the stock share or one year later? Solution I: The expected value of the share price one year later is $a(rp+\frac{p}{r}+1-2p)$. So one year later he can buy $\frac{x}{a(rp+\frac{p}{r}+1-2p)}<\frac{x}{a}$. So buy the stock share now. Solution II: One year later, if price is $ra$, he can buy $\frac{x}{ra}$ shares; if price is $\frac{a}{r}$, he can buy $\frac{xr}{a}$ shares. Then the expected value of the shares he can buy one year later is $$\frac{x}{ra}*p+\frac{xr}{a}*p+\frac{x}{a}*(1-2p)>\frac{x}{a}$$. So buy the stock one year later. What's wrong with Solution II.","Someone plans to use x dollars buying some stock share, the stock price is $a$ dollars per share now. One year later, the stock price will possibly increase to $ra$ or decrease to $a/r$ (r>1) which the probability is $p$, or remain the price now which probability is $1-2p$. If he want to own more shares, should he buy the stock share or one year later? Solution I: The expected value of the share price one year later is $a(rp+\frac{p}{r}+1-2p)$. So one year later he can buy $\frac{x}{a(rp+\frac{p}{r}+1-2p)}<\frac{x}{a}$. So buy the stock share now. Solution II: One year later, if price is $ra$, he can buy $\frac{x}{ra}$ shares; if price is $\frac{a}{r}$, he can buy $\frac{xr}{a}$ shares. Then the expected value of the shares he can buy one year later is $$\frac{x}{ra}*p+\frac{xr}{a}*p+\frac{x}{a}*(1-2p)>\frac{x}{a}$$. So buy the stock one year later. What's wrong with Solution II.",,['probability']
6,Unimodality and continuity for probability distribution,Unimodality and continuity for probability distribution,,"From Wikipedia about the conditions for the Vysochanskij–Petunin inequality The sole restriction on the distribution is that it be unimodal and   have finite variance. ( This implies that it is a continuous   probability distribution except at the mode, which may have a non-zero   probability. ) Does it mean that unimodality and finite variance imply the distribution is continuous except at the mode? Why is that? Thanks!","From Wikipedia about the conditions for the Vysochanskij–Petunin inequality The sole restriction on the distribution is that it be unimodal and   have finite variance. ( This implies that it is a continuous   probability distribution except at the mode, which may have a non-zero   probability. ) Does it mean that unimodality and finite variance imply the distribution is continuous except at the mode? Why is that? Thanks!",,['probability']
7,"$X$ standard normal distribution, $E[X^k]=?$","standard normal distribution,",X E[X^k]=?,"I'm stuck with a homework problem where we are supposed to prove that the expected value $E[X^k]$, if $X$ has standard normal distribution, is equal to: $$E[X^{2k}]=\frac{(2k)!}{k!\cdot2^k}.$$ But I cannot think of the correct approach. Can anyone help me? all the best :) Marie","I'm stuck with a homework problem where we are supposed to prove that the expected value $E[X^k]$, if $X$ has standard normal distribution, is equal to: $$E[X^{2k}]=\frac{(2k)!}{k!\cdot2^k}.$$ But I cannot think of the correct approach. Can anyone help me? all the best :) Marie",,"['probability', 'expectation', 'normal-distribution', 'moment-generating-functions']"
8,Probability and Axiom of Choice,Probability and Axiom of Choice,,"I'm not a logician, so I apologize if what follows translates to nonsense. I would like to try to define a different theory of random choice. I hesitate to call it probability theory because I do not expect it to follow the usual rules of probability. I will however refer to it as a warped theory of probability. For the sake of simplicity take $\mathbb{Z}$ or $[-\infty,\infty]$. It is an easy fact that one CANNOT define a discrete uniform distribution on either of these spaces in the usual sense. One of two things necessarly goes wrong: normalization or countable additivity. However, according to the axiom of choice, I can pick an element of $\mathbb{Z}$ or $[-\infty,\infty]$. Even though these sets are well ordered, I would still like to use the axiom of choice as explained below. In fact, if I have infinitely many copies of $\mathbb{Z}$ or $[-\infty,\infty]$ then I can pick elements from each copy turning it into a product space. Since there is no real recipe for how the axiom of choice picks elements, I would like to think that if I want to define a ""uniform"" distribution on $\mathbb{Z}$ or $[-\infty,\infty]$, then I would invoke the axiom of choice to generate an element. Can any of this be formalized into a useful theory? In short, I would like to pick an element of each set with the underlying notion that I have no preference to the choice I make. I'm invoking the axiom of choice as a means to do so. That is, I am defining the notion of a uniform distribution through the process of saying ""by the axiom of choice I can pick an element."" Literally, I am thinking of the axiom of choice as a black box into which I feed an arbitrary collection of sets from which it spits out picked elements. Of course this would not be in line with usual probability. In particular there would be huge issues with sets such as $[-1,1]$ and $[-\infty,\infty]$ where in the usual theory of probability I CAN define a uniform distribution on $[-1,1]$ but cannot on the latter, even though the two sets have a bijection. I am not sure how to reconcile this. My experience with the axiom of choice has been mostly in proofs that say, involve some collection of equivalence classes so I can pick representatives from each one. The point is in this case I don't care which representatives I pick. So if I were to suddenly care, is there some warped notion of probability that one can invoke to make ""inferences?""","I'm not a logician, so I apologize if what follows translates to nonsense. I would like to try to define a different theory of random choice. I hesitate to call it probability theory because I do not expect it to follow the usual rules of probability. I will however refer to it as a warped theory of probability. For the sake of simplicity take $\mathbb{Z}$ or $[-\infty,\infty]$. It is an easy fact that one CANNOT define a discrete uniform distribution on either of these spaces in the usual sense. One of two things necessarly goes wrong: normalization or countable additivity. However, according to the axiom of choice, I can pick an element of $\mathbb{Z}$ or $[-\infty,\infty]$. Even though these sets are well ordered, I would still like to use the axiom of choice as explained below. In fact, if I have infinitely many copies of $\mathbb{Z}$ or $[-\infty,\infty]$ then I can pick elements from each copy turning it into a product space. Since there is no real recipe for how the axiom of choice picks elements, I would like to think that if I want to define a ""uniform"" distribution on $\mathbb{Z}$ or $[-\infty,\infty]$, then I would invoke the axiom of choice to generate an element. Can any of this be formalized into a useful theory? In short, I would like to pick an element of each set with the underlying notion that I have no preference to the choice I make. I'm invoking the axiom of choice as a means to do so. That is, I am defining the notion of a uniform distribution through the process of saying ""by the axiom of choice I can pick an element."" Literally, I am thinking of the axiom of choice as a black box into which I feed an arbitrary collection of sets from which it spits out picked elements. Of course this would not be in line with usual probability. In particular there would be huge issues with sets such as $[-1,1]$ and $[-\infty,\infty]$ where in the usual theory of probability I CAN define a uniform distribution on $[-1,1]$ but cannot on the latter, even though the two sets have a bijection. I am not sure how to reconcile this. My experience with the axiom of choice has been mostly in proofs that say, involve some collection of equivalence classes so I can pick representatives from each one. The point is in this case I don't care which representatives I pick. So if I were to suddenly care, is there some warped notion of probability that one can invoke to make ""inferences?""",,"['probability', 'probability-theory', 'logic', 'philosophy']"
9,"Probability of finding 2012 before any other occurence of 012 in a random infinite sequence of digits 0,1,2","Probability of finding 2012 before any other occurence of 012 in a random infinite sequence of digits 0,1,2",,"The following problem is from the semifinals of the Federation Francaise des Jeux Mathematiques: One draws randomly an infinite sequence with digits 0, 1 or 2. Afterwards, one reads it in the order of the drawing. What is the probability that one reads ""2,0,1,2"" without having read ""0,1,2"" beforehand? Besides the obvious assumption that digits are drawn independently with equidistribution, I am primarily interested in the following interpretation: *) If the sequence starts with 0,1,2,0,1,2  one regards this as having read 0,1,2 before 2,0,1,2 because the first pattern is finished before the second. In addition, I would also like a solution to the following alternative interpretation, especially if it turns out to be easier to calculate: *) If the sequence starts with 0,1,2,0,1,2 one regards this as NOT read 0,1,2 before 2,0,1,2 at this point because the first pattern has not finished before the second starts.","The following problem is from the semifinals of the Federation Francaise des Jeux Mathematiques: One draws randomly an infinite sequence with digits 0, 1 or 2. Afterwards, one reads it in the order of the drawing. What is the probability that one reads ""2,0,1,2"" without having read ""0,1,2"" beforehand? Besides the obvious assumption that digits are drawn independently with equidistribution, I am primarily interested in the following interpretation: *) If the sequence starts with 0,1,2,0,1,2  one regards this as having read 0,1,2 before 2,0,1,2 because the first pattern is finished before the second. In addition, I would also like a solution to the following alternative interpretation, especially if it turns out to be easier to calculate: *) If the sequence starts with 0,1,2,0,1,2 one regards this as NOT read 0,1,2 before 2,0,1,2 at this point because the first pattern has not finished before the second starts.",,"['probability', 'markov-chains']"
10,Conditional probability Poisson process and dependent random variables,Conditional probability Poisson process and dependent random variables,,"This is for homework, but I'm stuck cause I can't find something like this on my book, or in the internet for that matter. Say I have a restaurant that's open the 24 hours, and we know that costumers enter the establishment according a Poisson process at a rate of 5 costumers/hour. 1. Given that 6 costumers arrived from 1:00 am and 2:30 am, what's the     probability that less than 3 customers arrive from 2:30 am to 4:00     am? I have modeled this question like this: P(C<3|X=6), being C the amount of customers that could arrive and X the customers that have already arrived. so I use the definition of conditional probability: $$\frac{P(C<3\bigcap X=6)}{P(X=6)}$$ I ended up using this property that seems shady: $$P(A\bigcap B)=P(A) P(B)$$ Make the math and I end up with  $$\frac{0.1367 \cdot 0.059}{0.1367}=0.059$$  which seems reasonable, but I don't think is right. So help me here if it's not ok. 2. If we know that 30 customers arrived from 10:00 pm to 4:00 am, what's the probability that 20 customers arrived from 1:30 am to 3:15 am? This questions has me stumped. I think I should break the times in something like: $$[10:00, 1:30)\bigcup [1:30, 3:15]\bigcup (3:15, 4:00]$$ And then do the probabilities separate, and add them up at the end, but that seems wrong, and I don't know what to do... Please help","This is for homework, but I'm stuck cause I can't find something like this on my book, or in the internet for that matter. Say I have a restaurant that's open the 24 hours, and we know that costumers enter the establishment according a Poisson process at a rate of 5 costumers/hour. 1. Given that 6 costumers arrived from 1:00 am and 2:30 am, what's the     probability that less than 3 customers arrive from 2:30 am to 4:00     am? I have modeled this question like this: P(C<3|X=6), being C the amount of customers that could arrive and X the customers that have already arrived. so I use the definition of conditional probability: $$\frac{P(C<3\bigcap X=6)}{P(X=6)}$$ I ended up using this property that seems shady: $$P(A\bigcap B)=P(A) P(B)$$ Make the math and I end up with  $$\frac{0.1367 \cdot 0.059}{0.1367}=0.059$$  which seems reasonable, but I don't think is right. So help me here if it's not ok. 2. If we know that 30 customers arrived from 10:00 pm to 4:00 am, what's the probability that 20 customers arrived from 1:30 am to 3:15 am? This questions has me stumped. I think I should break the times in something like: $$[10:00, 1:30)\bigcup [1:30, 3:15]\bigcup (3:15, 4:00]$$ And then do the probabilities separate, and add them up at the end, but that seems wrong, and I don't know what to do... Please help",,['probability']
11,A Problem of Counting Expectation of Inversions in a Half-Sorted List.,A Problem of Counting Expectation of Inversions in a Half-Sorted List.,,"Has any one got any idea about this problem? I found my formula is too complicated to get a closed form. Let $P_{2n}$ be the set of all $(2n)!$ permutations of $\{1,2,3,···,2n\}$. For any $\sigma = (a_1,a_2,···,a_{2n})$ in $P_{2n}$, a pair of positions $(i,j)$ such that $i < j$ is called an inversion in $\sigma$ if $a_i > a_j$. For example, in the permutation $(a_1,a_2,a_3,a_4) = (2,4,1,3)$, $(2,4)$ is an inversion as $a_2 = 4 > a_4 = 3$; in fact, in this case there are exactly $3$ inversions $(1, 3)$, $(2, 3)$, $(2, 4)$. For any $\sigma = (a_1,a_2,···,a_{2n})$ in $P_{2n}$, let $f(\sigma)$ be the permutation obtained from $\sigma$ by sorting the sublist of odd positions. That is, $f(\sigma) =(b_1,b_2,···,b_{2n}) \in P_{2n}$, where $b_{2k} = a_{2k}$ for $1\le k\le n$, and $b_1 < b_3 < b_5 < ··· < b_{2n-1} $ is the sorted list of $a_1,a_3,···,a_{2n−1}$. For example, for $\sigma = (3,8,2,5,6,7,1,4)$, $f(\sigma) = (1,8,2,5,3,7,6,4)$. For a random $\sigma $ uniformly chosen from $P_{2n}$, let $I_n$ be the random variable corresponding to the number of inversions in the permutation $f(\sigma)$.  Determine $E(I_n)$ and $\text{Var}(I_n)$.","Has any one got any idea about this problem? I found my formula is too complicated to get a closed form. Let $P_{2n}$ be the set of all $(2n)!$ permutations of $\{1,2,3,···,2n\}$. For any $\sigma = (a_1,a_2,···,a_{2n})$ in $P_{2n}$, a pair of positions $(i,j)$ such that $i < j$ is called an inversion in $\sigma$ if $a_i > a_j$. For example, in the permutation $(a_1,a_2,a_3,a_4) = (2,4,1,3)$, $(2,4)$ is an inversion as $a_2 = 4 > a_4 = 3$; in fact, in this case there are exactly $3$ inversions $(1, 3)$, $(2, 3)$, $(2, 4)$. For any $\sigma = (a_1,a_2,···,a_{2n})$ in $P_{2n}$, let $f(\sigma)$ be the permutation obtained from $\sigma$ by sorting the sublist of odd positions. That is, $f(\sigma) =(b_1,b_2,···,b_{2n}) \in P_{2n}$, where $b_{2k} = a_{2k}$ for $1\le k\le n$, and $b_1 < b_3 < b_5 < ··· < b_{2n-1} $ is the sorted list of $a_1,a_3,···,a_{2n−1}$. For example, for $\sigma = (3,8,2,5,6,7,1,4)$, $f(\sigma) = (1,8,2,5,3,7,6,4)$. For a random $\sigma $ uniformly chosen from $P_{2n}$, let $I_n$ be the random variable corresponding to the number of inversions in the permutation $f(\sigma)$.  Determine $E(I_n)$ and $\text{Var}(I_n)$.",,"['probability', 'combinatorics']"
12,Estimating a probability of head of a biased coin,Estimating a probability of head of a biased coin,,"The question is: We assume a uniform (0,1)  prior for the (unknown) probability of a head. A coin is tossed 100 times with 65 of the tosses turning out heads. What is the probability that the next toss will be head? Well, the most obvious answer is of course prob = 0.65, but I am afraid this is too simple. However, I really don't know what is wrong with this answer? I think I need to use the fact that we assume a uniform [0,1] before we begin tossing the coin, but I am not sure how to proceed.","The question is: We assume a uniform (0,1)  prior for the (unknown) probability of a head. A coin is tossed 100 times with 65 of the tosses turning out heads. What is the probability that the next toss will be head? Well, the most obvious answer is of course prob = 0.65, but I am afraid this is too simple. However, I really don't know what is wrong with this answer? I think I need to use the fact that we assume a uniform [0,1] before we begin tossing the coin, but I am not sure how to proceed.",,"['probability', 'statistics']"
13,Correlation between variables,Correlation between variables,,"I asked this question on stats SE but did not find a suitable answer so far. Maybe someone can help. Given n random variables x1,...,xn (one-dimensional).  The following is known (corr() = Pearson correlation): corr(x1,x2) = a corr(x2,x3) = a The actual values of the random variables and their covariances are unkown though. Only some of their correlations are known. From this, is it possible to calculate corr(x3,x1) = ? or give an estimate of the lowest possible correlation coefficient corr(x3,x1) > a More generally: Given set of correlations corr(x_i, x_i+1) with i=[1..c], c<n is it possible to either directly calculate corr(x_1, x_c+1) or give a lower bound a of the coefficient with corr(x_1, x_c+1) > a","I asked this question on stats SE but did not find a suitable answer so far. Maybe someone can help. Given n random variables x1,...,xn (one-dimensional).  The following is known (corr() = Pearson correlation): corr(x1,x2) = a corr(x2,x3) = a The actual values of the random variables and their covariances are unkown though. Only some of their correlations are known. From this, is it possible to calculate corr(x3,x1) = ? or give an estimate of the lowest possible correlation coefficient corr(x3,x1) > a More generally: Given set of correlations corr(x_i, x_i+1) with i=[1..c], c<n is it possible to either directly calculate corr(x_1, x_c+1) or give a lower bound a of the coefficient with corr(x_1, x_c+1) > a",,"['probability', 'statistics', 'regression', 'correlation']"
14,Most and least likely outcomes of a Bernoulli distribution experiment,Most and least likely outcomes of a Bernoulli distribution experiment,,"Let's say I have some experiment that I repeat $n$ times. Each time I repeat it, there is a $p$ chance that the outcome will be successful. If I set $X$ to be the amount of successful trials, how can I find the most probable and least probable $X$? I figured that the most probable would be $np$, but I'm not quite sure.","Let's say I have some experiment that I repeat $n$ times. Each time I repeat it, there is a $p$ chance that the outcome will be successful. If I set $X$ to be the amount of successful trials, how can I find the most probable and least probable $X$? I figured that the most probable would be $np$, but I'm not quite sure.",,"['probability', 'probability-distributions']"
15,probability 2 coins in last box,probability 2 coins in last box,,"We have initially $2n$ boxes and each of them contains initially 1 coin. In each round, we select randomly 2 boxes, if both of the two boxes contain the same number of coins, for example $x$, replace them by 1 box with $x+1$ coins, otherwise, remove the one with the most coins. After $2n-1$ rounds, only 1 box is left, the probability that the box has 2 coins is $p(2n)$ What is $\lim_{n \to \infty}p(2n)$ ? The answer is $\frac{\sqrt{2}}{2}$. I found this question on another forum and it fascinated me, but I don't know how to prove the answer.","We have initially $2n$ boxes and each of them contains initially 1 coin. In each round, we select randomly 2 boxes, if both of the two boxes contain the same number of coins, for example $x$, replace them by 1 box with $x+1$ coins, otherwise, remove the one with the most coins. After $2n-1$ rounds, only 1 box is left, the probability that the box has 2 coins is $p(2n)$ What is $\lim_{n \to \infty}p(2n)$ ? The answer is $\frac{\sqrt{2}}{2}$. I found this question on another forum and it fascinated me, but I don't know how to prove the answer.",,"['probability', 'combinatorics']"
16,Is there a sufficient statistic for shifted exponential distribution?,Is there a sufficient statistic for shifted exponential distribution?,,"Suppose we have $X_1, \ldots, X_n$ i.i.d, $X_i \sim \text{Exp}(1, \mu)$ (pdf is $f_\mu(x) = e^{-(x-\mu)}$ for $x \geq \mu$ and $0$ for $x < \mu$ ). Is there any one dimensional (i.e. $T: \mathbb{R}^n \to \mathbb{R}$ ) sufficient statistic for parameter $\mu$ ? Obvious two dimensional sufficient statistic is $T(x_1, \ldots, x_n) = \left( \sum x_i, \min x_i \right)$ , but I have a hard time finding one dimensional statistic.","Suppose we have i.i.d, (pdf is for and for ). Is there any one dimensional (i.e. ) sufficient statistic for parameter ? Obvious two dimensional sufficient statistic is , but I have a hard time finding one dimensional statistic.","X_1, \ldots, X_n X_i \sim \text{Exp}(1, \mu) f_\mu(x) = e^{-(x-\mu)} x \geq \mu 0 x < \mu T: \mathbb{R}^n \to \mathbb{R} \mu T(x_1, \ldots, x_n) = \left( \sum x_i, \min x_i \right)","['probability', 'statistics']"
17,Probability with Combinations (Coin Toss),Probability with Combinations (Coin Toss),,"Toss a fair coin six times. What is probability of : a- all heads b- one head c- two heads d- an even number of heads e- at least four heads. I have the answers so I ask if you could explain how you should derive rather than just giving me the answers please. I know for a, you just multiple 1/2 6 times. But for the rest I need your help please.","Toss a fair coin six times. What is probability of : a- all heads b- one head c- two heads d- an even number of heads e- at least four heads. I have the answers so I ask if you could explain how you should derive rather than just giving me the answers please. I know for a, you just multiple 1/2 6 times. But for the rest I need your help please.",,"['probability', 'combinatorics']"
18,Minimizing the variance of weighted sum of two random variables with respect to the weights,Minimizing the variance of weighted sum of two random variables with respect to the weights,,"Suppose $X$ and $Y$ are two random variables. I would like to see if the solution to $$ \min_w \quad \mathrm{Var}(wX+(1-w)Y) $$ can be negative. I know that \begin{align*} &\mathrm{Var}(wX+(1-w)Y)  \\ &= w^2 \mathrm{Var} X + 2w(1-w)\mathrm{Cov}(X,Y) + (1-w)^2 \mathrm{Var}Y \\&= w^2 (\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y) + 2w(\mathrm{Cov}(X,Y) - \mathrm{Var}Y) + \mathrm{Var}Y \end{align*} Since $$\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y  \geq \mathrm{Var} X - 2\sqrt{\mathrm{Var} X \, \mathrm{Var} Y}+ \mathrm{Var}Y \geq 0, $$ the minimizer is  $$ w^*=-\frac{\mathrm{Cov}(X,Y) - \mathrm{Var}Y}{\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y} $$ So if I am correct so far, the problem of whether $w^*$ can be negative becomes whether it can be true that $$ \mathrm{Cov}(X,Y) - \mathrm{Var}Y > 0? $$ Thanks!","Suppose $X$ and $Y$ are two random variables. I would like to see if the solution to $$ \min_w \quad \mathrm{Var}(wX+(1-w)Y) $$ can be negative. I know that \begin{align*} &\mathrm{Var}(wX+(1-w)Y)  \\ &= w^2 \mathrm{Var} X + 2w(1-w)\mathrm{Cov}(X,Y) + (1-w)^2 \mathrm{Var}Y \\&= w^2 (\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y) + 2w(\mathrm{Cov}(X,Y) - \mathrm{Var}Y) + \mathrm{Var}Y \end{align*} Since $$\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y  \geq \mathrm{Var} X - 2\sqrt{\mathrm{Var} X \, \mathrm{Var} Y}+ \mathrm{Var}Y \geq 0, $$ the minimizer is  $$ w^*=-\frac{\mathrm{Cov}(X,Y) - \mathrm{Var}Y}{\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y} $$ So if I am correct so far, the problem of whether $w^*$ can be negative becomes whether it can be true that $$ \mathrm{Cov}(X,Y) - \mathrm{Var}Y > 0? $$ Thanks!",,['probability']
19,How many chips drawn with replacement until a duplicate is found?,How many chips drawn with replacement until a duplicate is found?,,"Note - this problem is not homework. I'm studying for an exam and this problem is in our text ( A First Course in Probability by Sheldon Ross) with no listed solution. The problem is: A jar contains n chips. Suppose a boy successively draws a chip from the jar, each time replacing the one drawn before drawing another. The process continues until the boy draws a chip that he has previously drawn. Let X denote the number of draws, and compute its probability mass. So we want the probability that it will take i draws to draw a duplicate, for some fixed $0<=i<=n$. I'm using an unofficial solutions manual which claims the following solution: $P\{X=i\} = \frac{i(i-1)}{2n}$ But that doesn't make sense to me because what if $n=6$, $i=4$? Surely $P\{X=4\}$ isn't 1? My solution is as follows: First we choose $i-1$ unique chips with probability $\frac{\binom{n}{i-1}}{n^{(i-1)}}$ and then we choose a duplicate chip with probability $\frac{i-1}{n}$ to get a final probability of $P\{X=i\} = \frac{\binom{n}{i-1}}{n^{(i-1)}} * \frac{i-1}{n}$. If my solution is incorrect (I am suspicious because of the different solution from the manual), what is the flaw in my reasoning?","Note - this problem is not homework. I'm studying for an exam and this problem is in our text ( A First Course in Probability by Sheldon Ross) with no listed solution. The problem is: A jar contains n chips. Suppose a boy successively draws a chip from the jar, each time replacing the one drawn before drawing another. The process continues until the boy draws a chip that he has previously drawn. Let X denote the number of draws, and compute its probability mass. So we want the probability that it will take i draws to draw a duplicate, for some fixed $0<=i<=n$. I'm using an unofficial solutions manual which claims the following solution: $P\{X=i\} = \frac{i(i-1)}{2n}$ But that doesn't make sense to me because what if $n=6$, $i=4$? Surely $P\{X=4\}$ isn't 1? My solution is as follows: First we choose $i-1$ unique chips with probability $\frac{\binom{n}{i-1}}{n^{(i-1)}}$ and then we choose a duplicate chip with probability $\frac{i-1}{n}$ to get a final probability of $P\{X=i\} = \frac{\binom{n}{i-1}}{n^{(i-1)}} * \frac{i-1}{n}$. If my solution is incorrect (I am suspicious because of the different solution from the manual), what is the flaw in my reasoning?",,"['probability', 'combinatorics']"
20,Question about order statistics,Question about order statistics,,"I saw a paper which says that: Let $Z_i$ be i.i.d. exponential random variables with mean $1$, and let   $S_n = Z_1 + \dots + Z_n$ for all $n$. For a fixed $n$, let $U_j = S_j/S_{n+1}$, then $(U_1,\dots,U_n)$ has the same distribution as the order statistics of a sample of size $n$ from the uniform distribution on $[0,1]$. So my question is how to prove this.","I saw a paper which says that: Let $Z_i$ be i.i.d. exponential random variables with mean $1$, and let   $S_n = Z_1 + \dots + Z_n$ for all $n$. For a fixed $n$, let $U_j = S_j/S_{n+1}$, then $(U_1,\dots,U_n)$ has the same distribution as the order statistics of a sample of size $n$ from the uniform distribution on $[0,1]$. So my question is how to prove this.",,"['probability', 'probability-distributions']"
21,Absolute error loss for a gamma random variable,Absolute error loss for a gamma random variable,,"Let $X \sim \operatorname{Gamma}(2,1)$, I would like to minimize with respect to $a$ $$E|aX-1|=\int_0^{1/a}(1-ax)xe^{-x}dx+\int_{1/a}^\infty (ax-1)xe^{-x}dx$$ Is there some neat way to do this? The only way I know is to use calculus on the RHS to find the minimum with respect to $a$. By neat, I mean a way that use facts from probability or gamma function? Thanks.","Let $X \sim \operatorname{Gamma}(2,1)$, I would like to minimize with respect to $a$ $$E|aX-1|=\int_0^{1/a}(1-ax)xe^{-x}dx+\int_{1/a}^\infty (ax-1)xe^{-x}dx$$ Is there some neat way to do this? The only way I know is to use calculus on the RHS to find the minimum with respect to $a$. By neat, I mean a way that use facts from probability or gamma function? Thanks.",,['probability']
22,Conditional probability problem,Conditional probability problem,,"An Internet search engine looks for a keyword in 9 databases, searching them in random order. Only 5 of these databases contain the given keyword. What is the probability that it will be found in at least 2 of the first 4 searched databases? What I tried is: Let X: the event that the keyword is to be found in at least 2 databases, and Y: the event that we search the first 4 databases, then we need to find a conditional probability  $P(X\geq 2 | Y)=P(X= 2,3,\text{ or }4 | Y)=\frac{P(\{X\geq 2\} \cap Y)}{P(Y)}$  but then I don't know how to continue? Any help...","An Internet search engine looks for a keyword in 9 databases, searching them in random order. Only 5 of these databases contain the given keyword. What is the probability that it will be found in at least 2 of the first 4 searched databases? What I tried is: Let X: the event that the keyword is to be found in at least 2 databases, and Y: the event that we search the first 4 databases, then we need to find a conditional probability  $P(X\geq 2 | Y)=P(X= 2,3,\text{ or }4 | Y)=\frac{P(\{X\geq 2\} \cap Y)}{P(Y)}$  but then I don't know how to continue? Any help...",,['probability']
23,Discovering properties of a graph by means of random walk,Discovering properties of a graph by means of random walk,,"Suppose I have a regular, undirected, non-bipartite, finite, connected graph on $N$ vertices. Some fraction $\frac{c}{N}$ of the vertices are coloured gold, the rest are coloured black. If I let you perform a random walk on my graph, what machinery exists for you to discover what the value of $c$ is?","Suppose I have a regular, undirected, non-bipartite, finite, connected graph on $N$ vertices. Some fraction $\frac{c}{N}$ of the vertices are coloured gold, the rest are coloured black. If I let you perform a random walk on my graph, what machinery exists for you to discover what the value of $c$ is?",,"['probability', 'graph-theory']"
24,How do we arrive at the conclusion that P(Head) =0.5 for a fair coin?,How do we arrive at the conclusion that P(Head) =0.5 for a fair coin?,,"In Feynman's 'Lectures on Physics', I read a chapter on probability which tells that P(Head) for a fair coin 'approaches' 0.5 as no. of trials that we take goes to infinity (well, I tossed the coin 50 times & got heads 17 times, instead of 25 :-) ...). Can someone elaborate?","In Feynman's 'Lectures on Physics', I read a chapter on probability which tells that P(Head) for a fair coin 'approaches' 0.5 as no. of trials that we take goes to infinity (well, I tossed the coin 50 times & got heads 17 times, instead of 25 :-) ...). Can someone elaborate?",,['probability']
25,Consequences of boy/girl probability disparity on population,Consequences of boy/girl probability disparity on population,,"In a population that grows, would a disparity in having a boy/girl probability cause the ratio of males to females tend to the same? e.g. if the probability of having boys was $.49$ and having a girl was $.51$ would that mean a growing population would tend to be $49$% male and $51$% female? What about a non growing population?, would that mean finally one gender will be the only gender left after sufficient amount of time?","In a population that grows, would a disparity in having a boy/girl probability cause the ratio of males to females tend to the same? e.g. if the probability of having boys was $.49$ and having a girl was $.51$ would that mean a growing population would tend to be $49$% male and $51$% female? What about a non growing population?, would that mean finally one gender will be the only gender left after sufficient amount of time?",,['probability']
26,A continuous analogue of the binomial distribution,A continuous analogue of the binomial distribution,,"For any positive integer $N$, the binomial$(N!,p)$ distribution has the following property: for any $1 \leq n \leq N$, there exist i.i.d. random variables $X_1,\ldots,X_n$ such that $X_1 + \cdots + X_n \sim {\rm binomial}(N!,p)$ (specifically, we take $X_1,\ldots,X_n$ to be i.i.d. binomial$(N!/n,p)$ rv's). It may be interesting to consider the following question: given $N \geq 3$, arbitrary but fixed, is there a continuous bounded distribution $\mu = \mu_N$ having the same property? (I stress: continuous and bounded.) EDIT: Well, it turns out this is a really trivial problem, but worth remembering...; see my answer below.","For any positive integer $N$, the binomial$(N!,p)$ distribution has the following property: for any $1 \leq n \leq N$, there exist i.i.d. random variables $X_1,\ldots,X_n$ such that $X_1 + \cdots + X_n \sim {\rm binomial}(N!,p)$ (specifically, we take $X_1,\ldots,X_n$ to be i.i.d. binomial$(N!/n,p)$ rv's). It may be interesting to consider the following question: given $N \geq 3$, arbitrary but fixed, is there a continuous bounded distribution $\mu = \mu_N$ having the same property? (I stress: continuous and bounded.) EDIT: Well, it turns out this is a really trivial problem, but worth remembering...; see my answer below.",,['probability']
27,Expected value and Variance,Expected value and Variance,,"Although this is not actually homework, it's an exercise from the book; I want to rewrite the variance, \begin{equation*} var[f]=E[(f(x)-E[f(x)])^2] \end{equation*} as \begin{equation*} E[f(x)^2]-E[f(x)]^2. \end{equation*} I'm not sure how it reduces, and it has had me stumped for a while.  The answer would be nice. Any insight [a brief, yet, interesting explanation] would be great. Thanks in advance","Although this is not actually homework, it's an exercise from the book; I want to rewrite the variance, \begin{equation*} var[f]=E[(f(x)-E[f(x)])^2] \end{equation*} as \begin{equation*} E[f(x)^2]-E[f(x)]^2. \end{equation*} I'm not sure how it reduces, and it has had me stumped for a while.  The answer would be nice. Any insight [a brief, yet, interesting explanation] would be great. Thanks in advance",,"['statistics', 'probability']"
28,Good SAT learning resources?,Good SAT learning resources?,,"I'm looking to brush up on SAT math.  (That's basic algebra, probability and trigonometry.) I'm interested in books and websites.","I'm looking to brush up on SAT math.  (That's basic algebra, probability and trigonometry.) I'm interested in books and websites.",,"['probability', 'algebra-precalculus', 'trigonometry', 'reference-request', 'self-learning']"
29,Probability of A given B,Probability of A given B,,"In high school, we were often given questions of the form: ""What is the probability of A given B?"" For example: What is the probability that two   people were born on the same day given   that one was born on a Tuesday? Intuitively, most people expect that knowing someone was born on a Tuesday doesn't give you any information, as it is no different from being born on a Monday or Wednesday. However, the answer given is that we are looking at pairs of people with at least one born on Tuesday (13 out of 49) and only one of these pairs has both people born on the same day, so the answer is 1 in 13. If by ""given one was born on Tuesday"", you mean that we the birthdays of the two people are uniformly distributed between all possible pairs where at least one was born on a Tuesday"", then this analysis is correct. However, the question stated just says that we are ""given"" this fact. It doesn't explain how we came to know this fact. Lets suppose someone blurted this fact out randomly. Generally it wouldn't be because they looked at groups of people and discarded them until they found a pair where at least one was born on a Tuesday. Instead, I think it would be better to model it as someone randomly getting a pair of people, then making a true statement about them. For simplicity, we will assume they statements are of the form: ""One of these people was born on a (INSERT DAY)"". We will assume that if they were born on different days, each is equally likely. In this model, the statement that someone was born on a Tuesday actually makes no difference to the chance they were born on the same day. It seems that part of the problem comes from giving the word ""given"" (often represented by the symbol |) a formal definition. People expect it to have the same meaning as the English word given. Anyway: Is there a word I can use instead of ""given"" to be clearer? Do mathematician's object to the problem being stated this way, or is this considered to be clear? If they do, why is the symbol ""|"" often pronounced as ""given""? Have people who attended high school in other countries had this difference made clear to them?","In high school, we were often given questions of the form: ""What is the probability of A given B?"" For example: What is the probability that two   people were born on the same day given   that one was born on a Tuesday? Intuitively, most people expect that knowing someone was born on a Tuesday doesn't give you any information, as it is no different from being born on a Monday or Wednesday. However, the answer given is that we are looking at pairs of people with at least one born on Tuesday (13 out of 49) and only one of these pairs has both people born on the same day, so the answer is 1 in 13. If by ""given one was born on Tuesday"", you mean that we the birthdays of the two people are uniformly distributed between all possible pairs where at least one was born on a Tuesday"", then this analysis is correct. However, the question stated just says that we are ""given"" this fact. It doesn't explain how we came to know this fact. Lets suppose someone blurted this fact out randomly. Generally it wouldn't be because they looked at groups of people and discarded them until they found a pair where at least one was born on a Tuesday. Instead, I think it would be better to model it as someone randomly getting a pair of people, then making a true statement about them. For simplicity, we will assume they statements are of the form: ""One of these people was born on a (INSERT DAY)"". We will assume that if they were born on different days, each is equally likely. In this model, the statement that someone was born on a Tuesday actually makes no difference to the chance they were born on the same day. It seems that part of the problem comes from giving the word ""given"" (often represented by the symbol |) a formal definition. People expect it to have the same meaning as the English word given. Anyway: Is there a word I can use instead of ""given"" to be clearer? Do mathematician's object to the problem being stated this way, or is this considered to be clear? If they do, why is the symbol ""|"" often pronounced as ""given""? Have people who attended high school in other countries had this difference made clear to them?",,['probability']
30,$(1-x)^{n+a} \sum_{j=0}^\infty \binom{n+j-1}{j}\binom{n+j}{a} x^j = \sum_{j=0}^a \binom{n}{a-j}\binom{a-1}{j} x^j$,,(1-x)^{n+a} \sum_{j=0}^\infty \binom{n+j-1}{j}\binom{n+j}{a} x^j = \sum_{j=0}^a \binom{n}{a-j}\binom{a-1}{j} x^j,"Let $n$ and $a$ be natural numbers. How to prove the following for $x \in [0, 1)$ ? $$ (1-x)^{n+a} \sum_{j=0}^\infty \binom{n+j-1}{j}\binom{n+j}{a} x^j = \sum_{j=0}^a \binom{n}{a-j}\binom{a-1}{j} x^j $$ Context: This came up while solving this question . Numerical evidence on Desmos . I tried expanding the $(1-x)^{n+a}$ with binomial formula. Or maybe since we're after a sum from $0$ to $a$ , expand $(1-x)^{n}$ and $(1-x)^{a}$ separately?","Let and be natural numbers. How to prove the following for ? Context: This came up while solving this question . Numerical evidence on Desmos . I tried expanding the with binomial formula. Or maybe since we're after a sum from to , expand and separately?","n a x \in [0, 1) 
(1-x)^{n+a} \sum_{j=0}^\infty \binom{n+j-1}{j}\binom{n+j}{a} x^j = \sum_{j=0}^a \binom{n}{a-j}\binom{a-1}{j} x^j
 (1-x)^{n+a} 0 a (1-x)^{n} (1-x)^{a}","['probability', 'combinatorics', 'power-series', 'binomial-coefficients', 'generating-functions']"
31,Is it weird that my probability theory lecturer thinks that $P(E)=0$ implies that $E=\emptyset$?,Is it weird that my probability theory lecturer thinks that  implies that ?,P(E)=0 E=\emptyset,"I'm an undergraduate student in pure mathematics, and I'm taking a probability theory course based on the book A First Course in Probability by Sheldon Ross. My lecturer defined the conditional probability $P(A|B)$ of two events $A,B$ by $P(A|B)=\frac{P(A\cap B)}{P(B)}$ , provided that $B\neq\emptyset$ . I knew that $P(\emptyset)=0$ , and after some research, I realized that the converse is not true, namely, from $P(E)=0$ we can't conclude that $E=\emptyset$ . I wrote to my lecturer, and among other things, I gave him a simple counterexample. (First I asked him to prove his claim, but instead he ""proved"" to me that $P(\emptyset)=0$ , but he relied on $P(E^c)+P(E)=1$ which was proved in the book by ""the finite version"" of Axiom 3, which was proved using Axiom 3 and the fact that $P(\emptyset)=0$ .) The simple counterexample was the sample space $S=\{1,2\}$ together with the function $P$ defined by $P(\{1\})=0,P(\{2\})=1,P(\{1,2\})=1,P(\emptyset)=0$ , it's a simple matter to verify that $P$ satisfies the three axioms of probability, yet $P(\{1\})=0$ and $\{1\}\neq\emptyset$ . Yet he went in circles claiming that every sample point in the sample space (i.e., a singleton subset of the sample space) needs to have positive probability—which is of course nonsense. I was getting the feeling that he doesn't like rigour, and on further researching, I found out that his background is in engineering and applied statistics. Is it normal that he has this false belief (I mean normal for people who are more interested in applied probability rather than rigorous mathematics)?","I'm an undergraduate student in pure mathematics, and I'm taking a probability theory course based on the book A First Course in Probability by Sheldon Ross. My lecturer defined the conditional probability of two events by , provided that . I knew that , and after some research, I realized that the converse is not true, namely, from we can't conclude that . I wrote to my lecturer, and among other things, I gave him a simple counterexample. (First I asked him to prove his claim, but instead he ""proved"" to me that , but he relied on which was proved in the book by ""the finite version"" of Axiom 3, which was proved using Axiom 3 and the fact that .) The simple counterexample was the sample space together with the function defined by , it's a simple matter to verify that satisfies the three axioms of probability, yet and . Yet he went in circles claiming that every sample point in the sample space (i.e., a singleton subset of the sample space) needs to have positive probability—which is of course nonsense. I was getting the feeling that he doesn't like rigour, and on further researching, I found out that his background is in engineering and applied statistics. Is it normal that he has this false belief (I mean normal for people who are more interested in applied probability rather than rigorous mathematics)?","P(A|B) A,B P(A|B)=\frac{P(A\cap B)}{P(B)} B\neq\emptyset P(\emptyset)=0 P(E)=0 E=\emptyset P(\emptyset)=0 P(E^c)+P(E)=1 P(\emptyset)=0 S=\{1,2\} P P(\{1\})=0,P(\{2\})=1,P(\{1,2\})=1,P(\emptyset)=0 P P(\{1\})=0 \{1\}\neq\emptyset","['probability', 'soft-question', 'axioms']"
32,How many turns will it take for this coin flipping game to end?,How many turns will it take for this coin flipping game to end?,,"Here is a problem (coin flipping game) I recently thought about. Suppose there are 2 Discrete Time Markov Chains: Markov Chain A (3-state chain): $$ X_t  =  \begin{bmatrix} 1/3 & 1/3 & 1/3 \\ 1/3 & 1/3 & 1/3 \\ 0 & 0 & 1 \\ \end{bmatrix} $$ Markov Chain B (4-state chain): $$ Y_t  =  \begin{bmatrix} 1/4 & 1/4 & 1/4 & 1/4 \\ 1/4 & 1/4 & 1/4 & 1/4 \\ 0 & 0 & 1 & 0 \\ 1/4 & 1/4 & 1/4 & 1/4 \\ \end{bmatrix} $$ In this problem, we start in Chain A in state 1. At each new time point, we flip a 2-sided fair coin : If heads, we stay in the same state we are currently in but move to Chain B. If tails, we stay in Chain A. The first time we move from Chain A to Chain B, we permanently stay in Chain B Once we reach State 3 (whether in Chain A or in Chain B), we stop forever. I tried to represent all of this mathematically: $$ B_t =  \begin{cases}  1 & \text{with probability } p \\ 0 & \text{with probability } 1-p  \end{cases} $$ $$ S_t = \sum_{i=0}^{t} B_i $$ $$ Z_t =  \begin{cases}  X_t & \text{if } S_t = 0 \\ Y_t & \text{if } S_t \geq 1  \end{cases} $$ $$ T = \min \{ t \geq 0 : Z_t = 3 \} $$ Based on this, I am interested in answering the following types of questions: On average, what percent of the time will $Z_t$ stop in $X_t$ vs $Y_t$ ? Is it possible to find out the joint probability distribution of (number of steps to switch from $X_t$ to $Y_t$ , number of steps for process to stop)? I am not sure how to answer these questions, so I wrote R simulations to try and answer them numerically. For example: library(tidyverse) library(dplyr) library(ggplot2) library(RColorBrewer)   simulate_markov_chain <- function(simulation_num) {     # Transition matrices     transition_matrix_A <- matrix(c(1/3, 1/3, 1/3,  # probabilities from state 1                                     1/3, 1/3, 1/3,  # probabilities from state 2                                     0,   0,   1),   # probabilities from state 3                                   nrow = 3, byrow = TRUE)          transition_matrix_B <- matrix(c(1/4, 1/4, 1/4, 1/4,  # probabilities from state 1                                     1/4, 1/4, 1/4, 1/4,  # probabilities from state 2                                     0,   0,   1,   0,    # probabilities from state 3                                     1/4, 1/4, 1/4, 1/4), # probabilities from state 4                                   nrow = 4, byrow = TRUE)          # Initial state and chain     state <- 1     chain <- ""A""              path_df <- data.frame(iteration = 1, chain = chain, state = state)          # Simulate      iteration <- 1     while (state != 3) {         # Flip a coin         coin_flip <- sample(c(""heads"", ""tails""), size = 1, prob = c(0.5, 0.5))                  # Check if switch to chain B         if (coin_flip == ""heads"" || chain == ""B"") {             chain <- ""B""             state <- sample(1:4, size = 1, prob = transition_matrix_B[state, ])         } else {             state <- sample(1:3, size = 1, prob = transition_matrix_A[state, ])         }                          iteration <- iteration + 1         path_df <- rbind(path_df, data.frame(iteration = iteration, chain = chain, state = state))     }              path_df$simulation_num <- simulation_num          return(path_df) }    # simulation 1000 times  results <- map_dfr(1:1000, simulate_markov_chain)     ############################################################   results <- results %>%     group_by(simulation_num) %>%     mutate(transition_iteration = ifelse(chain == ""B"" & lag(chain) == ""A"", iteration, NA),            max_iteration = max(iteration)) %>%     ungroup()    transition_iterations <- results %>%      group_by(simulation_num) %>%      summarise(transition_iteration = min(transition_iteration, na.rm = TRUE),               max_iteration = max(iteration))   # Filter out rows with Inf values transition_iterations <- transition_iterations %>% filter(!is.infinite(transition_iteration), !is.infinite(max_iteration))  density_estimate <- MASS::kde2d(x = transition_iterations $transition_iteration,                                  y = transition_iterations$ max_iteration,                                  n = 100)  filled.contour(x = density_estimate $x,                 y = density_estimate$ y,                 z = density_estimate$z,                 color.palette = colorRampPalette(brewer.pal(9, ""Greens"")),                plot.title = title(main = ""Contour Plot of Transition Iteration vs Max Iteration"",                                   xlab = ""Transition Iteration"",                                    ylab = ""Max Iteration""),                plot.axes = {axis(1); axis(2); }) As we can see, the majority of the games finish relatively early on (i.e. bottom left corner of the plot). Note that sometimes $Z_t$ never transitions to $Y_t$ therefore the transition time is Infinite and I had to remove these rows for the simulation. I am not sure if a probability distribution can be defined with such infinite values. But analytically (i.e. without simulations), is it possible to answer the following questions? On average, what percent of the time will $Z_t$ stop in $X_t$ vs $Y_t$ ? (i.e. stopping in Chain A vs stopping in Chain B) Is it possible to find out the joint probability distribution of (number of steps to switch from $X_t$ to $Y_t$ , number of steps for process to stop)? Within a given simulation, after $n$ turns of playing the game, what is the probability we are in Chain A? Normally I would have used the Fundamental Matrix approach (e.g. https://en.wikipedia.org/wiki/Absorbing_Markov_chain ), but I am not sure if it can be applied here. Thanks! Note: I made this visualization for the percent of games in Chain A vs Chain B as the number of turns in a simulation increase: library(ggplot2) chain_counts <- results %>%     group_by(iteration, chain) %>%     summarise(n = n(), .groups = ""drop"")  total_counts <- results %>%     group_by(iteration) %>%     summarise(total = n(), .groups = ""drop"")  percentages <- inner_join(chain_counts, total_counts, by = ""iteration"") %>%     mutate(percentage = n / total * 100)   ggplot(percentages, aes(x = iteration, y = percentage, fill = chain)) +     geom_bar(stat = ""identity"", position = ""dodge"") +     labs(x = ""Simulation Number"", y = ""Percentage"", fill = ""Chain"") +     theme_minimal() +     scale_fill_brewer(palette = ""Set1"") +     scale_x_continuous(breaks = seq(min(percentages $iteration), max(percentages$ iteration), by = 1)) +ggtitle(""Length of Game vs Percentage of Games in Chain A/ Chain B"")","Here is a problem (coin flipping game) I recently thought about. Suppose there are 2 Discrete Time Markov Chains: Markov Chain A (3-state chain): Markov Chain B (4-state chain): In this problem, we start in Chain A in state 1. At each new time point, we flip a 2-sided fair coin : If heads, we stay in the same state we are currently in but move to Chain B. If tails, we stay in Chain A. The first time we move from Chain A to Chain B, we permanently stay in Chain B Once we reach State 3 (whether in Chain A or in Chain B), we stop forever. I tried to represent all of this mathematically: Based on this, I am interested in answering the following types of questions: On average, what percent of the time will stop in vs ? Is it possible to find out the joint probability distribution of (number of steps to switch from to , number of steps for process to stop)? I am not sure how to answer these questions, so I wrote R simulations to try and answer them numerically. For example: library(tidyverse) library(dplyr) library(ggplot2) library(RColorBrewer)   simulate_markov_chain <- function(simulation_num) {     # Transition matrices     transition_matrix_A <- matrix(c(1/3, 1/3, 1/3,  # probabilities from state 1                                     1/3, 1/3, 1/3,  # probabilities from state 2                                     0,   0,   1),   # probabilities from state 3                                   nrow = 3, byrow = TRUE)          transition_matrix_B <- matrix(c(1/4, 1/4, 1/4, 1/4,  # probabilities from state 1                                     1/4, 1/4, 1/4, 1/4,  # probabilities from state 2                                     0,   0,   1,   0,    # probabilities from state 3                                     1/4, 1/4, 1/4, 1/4), # probabilities from state 4                                   nrow = 4, byrow = TRUE)          # Initial state and chain     state <- 1     chain <- ""A""              path_df <- data.frame(iteration = 1, chain = chain, state = state)          # Simulate      iteration <- 1     while (state != 3) {         # Flip a coin         coin_flip <- sample(c(""heads"", ""tails""), size = 1, prob = c(0.5, 0.5))                  # Check if switch to chain B         if (coin_flip == ""heads"" || chain == ""B"") {             chain <- ""B""             state <- sample(1:4, size = 1, prob = transition_matrix_B[state, ])         } else {             state <- sample(1:3, size = 1, prob = transition_matrix_A[state, ])         }                          iteration <- iteration + 1         path_df <- rbind(path_df, data.frame(iteration = iteration, chain = chain, state = state))     }              path_df$simulation_num <- simulation_num          return(path_df) }    # simulation 1000 times  results <- map_dfr(1:1000, simulate_markov_chain)     ############################################################   results <- results %>%     group_by(simulation_num) %>%     mutate(transition_iteration = ifelse(chain == ""B"" & lag(chain) == ""A"", iteration, NA),            max_iteration = max(iteration)) %>%     ungroup()    transition_iterations <- results %>%      group_by(simulation_num) %>%      summarise(transition_iteration = min(transition_iteration, na.rm = TRUE),               max_iteration = max(iteration))   # Filter out rows with Inf values transition_iterations <- transition_iterations %>% filter(!is.infinite(transition_iteration), !is.infinite(max_iteration))  density_estimate <- MASS::kde2d(x = transition_iterations max_iteration,                                  n = 100)  filled.contour(x = density_estimate y,                 z = density_estimate$z,                 color.palette = colorRampPalette(brewer.pal(9, ""Greens"")),                plot.title = title(main = ""Contour Plot of Transition Iteration vs Max Iteration"",                                   xlab = ""Transition Iteration"",                                    ylab = ""Max Iteration""),                plot.axes = {axis(1); axis(2); }) As we can see, the majority of the games finish relatively early on (i.e. bottom left corner of the plot). Note that sometimes never transitions to therefore the transition time is Infinite and I had to remove these rows for the simulation. I am not sure if a probability distribution can be defined with such infinite values. But analytically (i.e. without simulations), is it possible to answer the following questions? On average, what percent of the time will stop in vs ? (i.e. stopping in Chain A vs stopping in Chain B) Is it possible to find out the joint probability distribution of (number of steps to switch from to , number of steps for process to stop)? Within a given simulation, after turns of playing the game, what is the probability we are in Chain A? Normally I would have used the Fundamental Matrix approach (e.g. https://en.wikipedia.org/wiki/Absorbing_Markov_chain ), but I am not sure if it can be applied here. Thanks! Note: I made this visualization for the percent of games in Chain A vs Chain B as the number of turns in a simulation increase: library(ggplot2) chain_counts <- results %>%     group_by(iteration, chain) %>%     summarise(n = n(), .groups = ""drop"")  total_counts <- results %>%     group_by(iteration) %>%     summarise(total = n(), .groups = ""drop"")  percentages <- inner_join(chain_counts, total_counts, by = ""iteration"") %>%     mutate(percentage = n / total * 100)   ggplot(percentages, aes(x = iteration, y = percentage, fill = chain)) +     geom_bar(stat = ""identity"", position = ""dodge"") +     labs(x = ""Simulation Number"", y = ""Percentage"", fill = ""Chain"") +     theme_minimal() +     scale_fill_brewer(palette = ""Set1"") +     scale_x_continuous(breaks = seq(min(percentages iteration), by = 1)) +ggtitle(""Length of Game vs Percentage of Games in Chain A/ Chain B"")","
X_t  = 
\begin{bmatrix}
1/3 & 1/3 & 1/3 \\
1/3 & 1/3 & 1/3 \\
0 & 0 & 1 \\
\end{bmatrix}
 
Y_t  = 
\begin{bmatrix}
1/4 & 1/4 & 1/4 & 1/4 \\
1/4 & 1/4 & 1/4 & 1/4 \\
0 & 0 & 1 & 0 \\
1/4 & 1/4 & 1/4 & 1/4 \\
\end{bmatrix}
 
B_t = 
\begin{cases} 
1 & \text{with probability } p \\
0 & \text{with probability } 1-p 
\end{cases}
 
S_t = \sum_{i=0}^{t} B_i
 
Z_t = 
\begin{cases} 
X_t & \text{if } S_t = 0 \\
Y_t & \text{if } S_t \geq 1 
\end{cases}
 
T = \min \{ t \geq 0 : Z_t = 3 \}
 Z_t X_t Y_t X_t Y_t transition_iteration, 
                                y = transition_iterations x, 
               y = density_estimate Z_t Y_t Z_t X_t Y_t X_t Y_t n iteration), max(percentages",['probability']
33,"Signal processing, vector spaces and probability","Signal processing, vector spaces and probability",,"Given a function $f \in L^2[0, T]$ $$ f(t) = \sum_{n=0}^{N} a_n e_n(t) = \sqrt{\frac{2}{T}}\sum_{n=0}^{N} a_n \sin{\left (\frac{\pi nt}{T} \right)} $$ with the following dot product: $$ \left \langle f, g \right \rangle = \int_0^Tf(t)g(t)\;dt $$ To find $a_n$ is easy to see that: $$ a_n = \left \langle f(t), e_n(t) \right \rangle = \left \langle f(t),\sqrt{\frac{2}{T}} \sin{\left (\frac{\pi nt}{T} \right)}  \right \rangle  $$ Now imagine that the signal is ""contaminated"" with noise. $$ x(t) = f(t) + \varepsilon(t) $$ $$ \varepsilon(t) \sim \mathcal N(0, \sigma) $$ If you want to find the dot product we have: $$ \left \langle x(t), e_n(t) \right \rangle = \left \langle f(t) + \varepsilon(t), e_n(t) \right \rangle = \left \langle f(t), e_n(t) \right \rangle + \left \langle \varepsilon(t), e_n(t) \right \rangle = a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle $$ So finally we have: $$ \left \langle x(t), e_n(t) \right \rangle = a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle $$ $$ \left \langle \varepsilon(t), e_n(t) \right \rangle = \sqrt{\frac{2}{T}}\int_0^T \varepsilon(t) \sin{\left (\frac{\pi nt}{T} \right)} dt $$ Now imagine we are trying to send a signal with the coefficients $a_n$ , which can only take the random values of $1$ and $-1$ . Both values are equiprobable $\left(P(a_n = 1) = P(a_n = -1) = \frac{1}{2} \right)$ . At the arrival of the contaminated signal we will decide we recieved a $1$ if: $$ \left \langle x(t), e_n(t) \right \rangle > 0 $$ and $-1$ if: $$ \left \langle x(t), e_n(t) \right \rangle < 0 $$ Then: $$ P(\text{Error Reciving 1}) = P(\text{Decide -1} | \text{Sent 1}) = P(\left \langle x(t), e_n(t) \right \rangle < 0 | a_n = 1) =\\ \; \\ P(a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle < 0 | a_n = 1) = P(1 + \left \langle \varepsilon(t), e_n(t) \right \rangle < 0) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1)\\  $$ Applying the same reasoning for the error of $-1$ , we finally get: $$ P(\text{Error Reciving 1}) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1) $$ $$ P(\text{Error Reciving -1}) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle > 1) $$ The thing is, how would you find: $$ P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1) \\ \; \\ P(\left \langle \varepsilon(t), e_n(t) \right \rangle > 1) $$ I've tried transforming the probability density function of $\varepsilon(t)$ , but the transofrmation function is very complex to deal with: $$ \delta(t) = g(\varepsilon(t)) = \left \langle \varepsilon(t), e_n(t) \right \rangle = \sqrt{\frac{2}{T}}\int_0^T \varepsilon(t) \sin{\left (\frac{\pi nt}{T} \right)} dt $$ $$ f_\delta (\delta) = \frac{f_\varepsilon(\delta)}{|g'(\delta)|}, \; \; \; \text{where $f$ denotes the probability density function} $$ How should I approach this? Any hint? It is possible to find an analytical form of this transformation?","Given a function with the following dot product: To find is easy to see that: Now imagine that the signal is ""contaminated"" with noise. If you want to find the dot product we have: So finally we have: Now imagine we are trying to send a signal with the coefficients , which can only take the random values of and . Both values are equiprobable . At the arrival of the contaminated signal we will decide we recieved a if: and if: Then: Applying the same reasoning for the error of , we finally get: The thing is, how would you find: I've tried transforming the probability density function of , but the transofrmation function is very complex to deal with: How should I approach this? Any hint? It is possible to find an analytical form of this transformation?","f \in L^2[0, T] 
f(t) = \sum_{n=0}^{N} a_n e_n(t) = \sqrt{\frac{2}{T}}\sum_{n=0}^{N} a_n \sin{\left (\frac{\pi nt}{T} \right)}
 
\left \langle f, g \right \rangle = \int_0^Tf(t)g(t)\;dt
 a_n 
a_n = \left \langle f(t), e_n(t) \right \rangle = \left \langle f(t),\sqrt{\frac{2}{T}} \sin{\left (\frac{\pi nt}{T} \right)}  \right \rangle 
 
x(t) = f(t) + \varepsilon(t)
 
\varepsilon(t) \sim \mathcal N(0, \sigma)
 
\left \langle x(t), e_n(t) \right \rangle = \left \langle f(t) + \varepsilon(t), e_n(t) \right \rangle = \left \langle f(t), e_n(t) \right \rangle + \left \langle \varepsilon(t), e_n(t) \right \rangle = a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle
 
\left \langle x(t), e_n(t) \right \rangle = a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle
 
\left \langle \varepsilon(t), e_n(t) \right \rangle = \sqrt{\frac{2}{T}}\int_0^T \varepsilon(t) \sin{\left (\frac{\pi nt}{T} \right)} dt
 a_n 1 -1 \left(P(a_n = 1) = P(a_n = -1) = \frac{1}{2} \right) 1 
\left \langle x(t), e_n(t) \right \rangle > 0
 -1 
\left \langle x(t), e_n(t) \right \rangle < 0
 
P(\text{Error Reciving 1}) = P(\text{Decide -1} | \text{Sent 1}) = P(\left \langle x(t), e_n(t) \right \rangle < 0 | a_n = 1) =\\ \; \\
P(a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle < 0 | a_n = 1) = P(1 + \left \langle \varepsilon(t), e_n(t) \right \rangle < 0) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1)\\ 
 -1 
P(\text{Error Reciving 1}) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1)
 
P(\text{Error Reciving -1}) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle > 1)
 
P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1) \\ \; \\
P(\left \langle \varepsilon(t), e_n(t) \right \rangle > 1)
 \varepsilon(t) 
\delta(t) = g(\varepsilon(t)) = \left \langle \varepsilon(t), e_n(t) \right \rangle = \sqrt{\frac{2}{T}}\int_0^T \varepsilon(t) \sin{\left (\frac{\pi nt}{T} \right)} dt
 
f_\delta (\delta) = \frac{f_\varepsilon(\delta)}{|g'(\delta)|}, \; \; \; \text{where f denotes the probability density function}
","['probability', 'functional-analysis', 'probability-distributions']"
34,Conjecture: Generalization of the triangle inequality to exponents of the sides,Conjecture: Generalization of the triangle inequality to exponents of the sides,,"Let $(x,y,z)$ be the sides of a triangle whose vertices are uniformly random on the circumference of a circle. Experimental data using a simulation with $10^9$ trails for each tested value of $a \ge 1$ suggests that: When $a \ge 1$ then the probability that $x^a + y^a \ge z^a$ is $P\left(x^a + y^a \ge z^a\right) = \frac{2}{3} + \frac{1}{3a^2}$ ,  or equivalently if $x \le y \le z$ . Then $P\left(x^a + y^a \ge z^a\right) = \frac{1}{a^2}$ . Can this Conjecture be proved or disproved? Related question . Julia source code using Random step = 10^9 while true     a = 1     while true         f = 0         for _ in 1:step             angles = rand(3) .* 6.283185307179586             vertices_x = cos.(angles)             vertices_y = sin.(angles)             push!(vertices_x, vertices_x[1])             push!(vertices_y, vertices_y[1])                          x_diff = diff(vertices_x)             y_diff = diff(vertices_y)             side_lengths = sqrt.(x_diff.^2 .+ y_diff.^2)             x, y, z = side_lengths                          if x^a +y^a >= z^a                 f += 1             end         end         prob = f/step         println((a, prob, prob / (2/3*(1 + 1/2/a^2))))                  a = round(a + 0.1, digits=10)     end end","Let be the sides of a triangle whose vertices are uniformly random on the circumference of a circle. Experimental data using a simulation with trails for each tested value of suggests that: When then the probability that is ,  or equivalently if . Then . Can this Conjecture be proved or disproved? Related question . Julia source code using Random step = 10^9 while true     a = 1     while true         f = 0         for _ in 1:step             angles = rand(3) .* 6.283185307179586             vertices_x = cos.(angles)             vertices_y = sin.(angles)             push!(vertices_x, vertices_x[1])             push!(vertices_y, vertices_y[1])                          x_diff = diff(vertices_x)             y_diff = diff(vertices_y)             side_lengths = sqrt.(x_diff.^2 .+ y_diff.^2)             x, y, z = side_lengths                          if x^a +y^a >= z^a                 f += 1             end         end         prob = f/step         println((a, prob, prob / (2/3*(1 + 1/2/a^2))))                  a = round(a + 0.1, digits=10)     end end","(x,y,z) 10^9 a \ge 1 a \ge 1 x^a + y^a \ge z^a P\left(x^a + y^a \ge z^a\right) = \frac{2}{3} + \frac{1}{3a^2} x \le y \le z P\left(x^a + y^a \ge z^a\right) = \frac{1}{a^2}","['probability', 'geometry', 'inequality', 'numerical-methods', 'triangles']"
35,Expected number of darts thrown in a game,Expected number of darts thrown in a game,,"$A$ and $B$ play a game where they take turns throwing darts at a dart board. The winner is the person to hit first. $A$ hits with probability $a$ and $B$ with probability $b$ . I showed (by computing a sum) that the expected number of darts thrown in one game is $$\frac{\alpha}{a}+\frac{\beta}{b}$$ where $\alpha$ and $\beta$ are the probability $A$ and $B$ win resp. This made me think there should be a solution using the law of total probability (since $\alpha+\beta=1$ ). That would suggest that the expected number of darts thrown given $A$ wins is $\frac{1}{a}$ . This is nonsense, so I dismissed this as a coincidence. However, I ran a simulation for the analogous game for three players $A$ $B$ and $C$ and found that the expected number of darts thrown in the game is $$\frac{\alpha}{a}+\frac{\beta}{b}+\frac{\gamma}{c}$$ Can someone explain whats going on here? I'm expecting someone will be able to arrive at this answer (and presumably the result for $n$ players) in a much more satisfying way than direct computation. EDIT: The result also holds for four players computationally","and play a game where they take turns throwing darts at a dart board. The winner is the person to hit first. hits with probability and with probability . I showed (by computing a sum) that the expected number of darts thrown in one game is where and are the probability and win resp. This made me think there should be a solution using the law of total probability (since ). That would suggest that the expected number of darts thrown given wins is . This is nonsense, so I dismissed this as a coincidence. However, I ran a simulation for the analogous game for three players and and found that the expected number of darts thrown in the game is Can someone explain whats going on here? I'm expecting someone will be able to arrive at this answer (and presumably the result for players) in a much more satisfying way than direct computation. EDIT: The result also holds for four players computationally",A B A a B b \frac{\alpha}{a}+\frac{\beta}{b} \alpha \beta A B \alpha+\beta=1 A \frac{1}{a} A B C \frac{\alpha}{a}+\frac{\beta}{b}+\frac{\gamma}{c} n,"['probability', 'algebra-precalculus', 'conditional-probability']"
36,Biased random walk with unequal step size,Biased random walk with unequal step size,,"Consider an asymmetric random walk $(X_n)$ in which the initial point is one ( $X_0 = 1$ ). It increases by $a$ with a probability of 0.3, remains the same with a probability of 0.4, and decreases by $b$ with a probability of 0.3, where $a<b$ and $a,b \in \mathbb{R}$ . Also, suppose this process stops once $X_n \geq \lambda$ . For example, $a=0.3$ , $b=0.5$ , and $\lambda=1.4$ . How can I calculate the probability of this process stopping? That is, what would be the probability of $X_n$ ever getting bigger than $\lambda=1.4$ ? Since the probability of stopping at the second period is $0.3\cdot 0.3$ , it would be greater than zero. Also, since it is supermartingale, by the maximal inequality for supermartingale, \begin{equation*} P(\sup X_n \geq 1.4) \leq \frac{\mathbb{E} X_0 }{1.4} = \frac{1}{1.4}. \end{equation*} Thus, it would not be one. However, I would like to derive precise predictions about them, which is where I am stuck now. I found other problems with asymmetric random walks with equal integer step sizes. However, I am unsure if I can still use the same ways in this environment. Also, would it be a completely different problem in an environment where the step sizes are irrational numbers?","Consider an asymmetric random walk in which the initial point is one ( ). It increases by with a probability of 0.3, remains the same with a probability of 0.4, and decreases by with a probability of 0.3, where and . Also, suppose this process stops once . For example, , , and . How can I calculate the probability of this process stopping? That is, what would be the probability of ever getting bigger than ? Since the probability of stopping at the second period is , it would be greater than zero. Also, since it is supermartingale, by the maximal inequality for supermartingale, Thus, it would not be one. However, I would like to derive precise predictions about them, which is where I am stuck now. I found other problems with asymmetric random walks with equal integer step sizes. However, I am unsure if I can still use the same ways in this environment. Also, would it be a completely different problem in an environment where the step sizes are irrational numbers?","(X_n) X_0 = 1 a b a<b a,b \in \mathbb{R} X_n \geq \lambda a=0.3 b=0.5 \lambda=1.4 X_n \lambda=1.4 0.3\cdot 0.3 \begin{equation*}
P(\sup X_n \geq 1.4) \leq \frac{\mathbb{E} X_0 }{1.4} = \frac{1}{1.4}.
\end{equation*}","['probability', 'probability-theory', 'martingales', 'random-walk']"
37,Combinations of indistinguishable marbles,Combinations of indistinguishable marbles,,"Let's consider this problem: A bag contains 5 black marbles and 6 white ones. Marbles of the same color are indistinguishable from each other. If I draw two marbles, what is the probability they have different colors? This problem can be trivial if we reason like this: $P(first = black, second=white) = P(first = black)*P(second=white|first = black) = \frac{5}{11} * \frac{6}{10} = \frac{3}{11}$ $P(first = white, second=black) = P(first = white)*P(second=black|first = white) = \frac{6}{11} * \frac{5}{10} = \frac{3}{11}$ Hence summing the two $P(\text{both black and white}) = \frac{6}{11}$ . If we frame the problem using combinations we can get the same result using this: $P(\text{both black and white}) = \frac{\binom{6}{1}\binom{5}{1}}{\binom{11}{2}} = \frac{6}{11}$ This is like the number of combinations of choosing 1 marble from the white, 1 marble from the blacks and divide then by the number of combinations of choosing 2 marbles from the 11. Is it a coincidence or is it correct this way of solving it? I cannot figure out how I should be allowed to use $\binom{11}{2}$ at denominator since to me there are at most 3 different ways to get a group of two marbles from the 11 namely (BB, BW, WW) and not 55 like $\binom{11}{2}$ states. Please clarify this.","Let's consider this problem: A bag contains 5 black marbles and 6 white ones. Marbles of the same color are indistinguishable from each other. If I draw two marbles, what is the probability they have different colors? This problem can be trivial if we reason like this: Hence summing the two . If we frame the problem using combinations we can get the same result using this: This is like the number of combinations of choosing 1 marble from the white, 1 marble from the blacks and divide then by the number of combinations of choosing 2 marbles from the 11. Is it a coincidence or is it correct this way of solving it? I cannot figure out how I should be allowed to use at denominator since to me there are at most 3 different ways to get a group of two marbles from the 11 namely (BB, BW, WW) and not 55 like states. Please clarify this.","P(first = black, second=white) = P(first = black)*P(second=white|first = black) = \frac{5}{11} * \frac{6}{10} = \frac{3}{11} P(first = white, second=black) = P(first = white)*P(second=black|first = white) = \frac{6}{11} * \frac{5}{10} = \frac{3}{11} P(\text{both black and white}) = \frac{6}{11} P(\text{both black and white}) = \frac{\binom{6}{1}\binom{5}{1}}{\binom{11}{2}} = \frac{6}{11} \binom{11}{2} \binom{11}{2}","['probability', 'combinatorics', 'combinations', 'binomial-coefficients']"
38,"The rate at which the expectation of the square of the empirical median of i.i.d. $[-1,1]$-valued uniform random variables goes to zero",The rate at which the expectation of the square of the empirical median of i.i.d. -valued uniform random variables goes to zero,"[-1,1]","Suppose that $X_1,X_2,\dots$ is an i.i.d. sequence of $[-1,1]$ -valued uniform random variables. Let $\bar{X}_t$ be the empircal mean of the sample $X_1,\dots,X_t$ . Then $\mathbb{E}\big[|\bar{X}_t|^2\big] = \operatorname{Var}[\bar{X}_t] = \frac{1}{3t}$ . Hence for the empirical mean we have that $\mathbb{E}\big[|\bar{X}_t|^2\big]$ goes to zero as fast as $t^{-1}$ , for $t \to \infty$ . I'm wondering at which rate the expected value of the square of the empirical median of these random variables goes to zero as the sample grows. Specifically, for each $t \in \mathbb{N}$ (if it helps, assume that in what follows $t$ is odd), let $M_t$ be the empirical median of the sample $X_1,\dots,X_t$ . How fast $\mathbb{E}\big[|M_t|^2\big]$ goes to zero as $t \to \infty$ ? We can interpret formally the question as finding $\alpha>0$ for which, if $0<\beta < \alpha $ then $\mathbb{E}\big[|M_t|^2\big] \cdot t^{\beta} \to 0, t\to\infty$ , while if $\gamma > \alpha$ then $\mathbb{E}\big[|M_t|^2\big] \cdot t^{\gamma} \to \infty, t\to\infty$ . Given that for the empirical median we don't have any simple formula as we do for the empirical mean (where we can leverage the variance to obtain an easy computation), this problem seems way less trivial. Is there a smart way to deduce the rate of convergence?","Suppose that is an i.i.d. sequence of -valued uniform random variables. Let be the empircal mean of the sample . Then . Hence for the empirical mean we have that goes to zero as fast as , for . I'm wondering at which rate the expected value of the square of the empirical median of these random variables goes to zero as the sample grows. Specifically, for each (if it helps, assume that in what follows is odd), let be the empirical median of the sample . How fast goes to zero as ? We can interpret formally the question as finding for which, if then , while if then . Given that for the empirical median we don't have any simple formula as we do for the empirical mean (where we can leverage the variance to obtain an easy computation), this problem seems way less trivial. Is there a smart way to deduce the rate of convergence?","X_1,X_2,\dots [-1,1] \bar{X}_t X_1,\dots,X_t \mathbb{E}\big[|\bar{X}_t|^2\big] = \operatorname{Var}[\bar{X}_t] = \frac{1}{3t} \mathbb{E}\big[|\bar{X}_t|^2\big] t^{-1} t \to \infty t \in \mathbb{N} t M_t X_1,\dots,X_t \mathbb{E}\big[|M_t|^2\big] t \to \infty \alpha>0 0<\beta < \alpha  \mathbb{E}\big[|M_t|^2\big] \cdot t^{\beta} \to 0, t\to\infty \gamma > \alpha \mathbb{E}\big[|M_t|^2\big] \cdot t^{\gamma} \to \infty, t\to\infty","['probability', 'probability-distributions', 'median']"
39,Pólya's urn - Probability first ball is blue given subsequent draws,Pólya's urn - Probability first ball is blue given subsequent draws,,I refer to the solution contained in this post here . I know it must be simple but I cannot deduce why $$ \begin{align*} P(B_1|B_2\cap \dots \cap B_{n+1})&=P(B_{n+1}|B_1\cap\dots\cap B_n) \end{align*} $$ I presume it is using the fact that $P(B_1|B_2)=P(B_2|B_1)$ so there might be some inductive argument being made but can't seem to get this one. Any help would be appreciated.,I refer to the solution contained in this post here . I know it must be simple but I cannot deduce why I presume it is using the fact that so there might be some inductive argument being made but can't seem to get this one. Any help would be appreciated.,"
\begin{align*}
P(B_1|B_2\cap \dots \cap B_{n+1})&=P(B_{n+1}|B_1\cap\dots\cap B_n)
\end{align*}
 P(B_1|B_2)=P(B_2|B_1)","['probability', 'probability-theory', 'induction', 'conditional-probability', 'polya-urn-model']"
40,Show that for $0<b<1<a$: $\mathbb P(\tau_a < \tau_b)=\frac{1-b^4}{a^4-b^4}$,Show that for :,0<b<1<a \mathbb P(\tau_a < \tau_b)=\frac{1-b^4}{a^4-b^4},"$(X_t)_{t \ge 0}$ is a process adapted to $(\mathcal F_t)_{t \ge 0}$ with continuous trajectories and such that $X_0=1, X_t$ is non-negative, $X_t ^4$ is a martingale with respect to $(\mathcal F_t)$ and $\limsup _{t \to \infty} X_t = +\infty$ . Let for $a>0$ : $$\tau_a=\inf \{ t>0: X_t =a\}.$$ Show that for $0<b<1<a$ $$\mathbb P(\tau_a < \tau_b)=\frac{1-b^4}{a^4-b^4}.$$ I have absolutely no idea for this task. $$\mathbb P(\tau_a < \tau_b)=\mathbb P(\inf \{ t>0: X_t =a\}-\inf \{ t>0: X_t =b\}<0)$$ I think you need to make clever use of the stopping time properties and the facts about $X_t$ given in the problem, but I didn't get anything sensible.","is a process adapted to with continuous trajectories and such that is non-negative, is a martingale with respect to and . Let for : Show that for I have absolutely no idea for this task. I think you need to make clever use of the stopping time properties and the facts about given in the problem, but I didn't get anything sensible.","(X_t)_{t \ge 0} (\mathcal F_t)_{t \ge 0} X_0=1, X_t X_t ^4 (\mathcal F_t) \limsup _{t \to \infty} X_t = +\infty a>0 \tau_a=\inf \{ t>0: X_t =a\}. 0<b<1<a \mathbb P(\tau_a < \tau_b)=\frac{1-b^4}{a^4-b^4}. \mathbb P(\tau_a < \tau_b)=\mathbb P(\inf \{ t>0: X_t =a\}-\inf \{ t>0: X_t =b\}<0) X_t","['probability', 'stochastic-processes', 'martingales', 'stochastic-analysis', 'stopping-times']"
41,Binomial distribution where successes increases the number of trials,Binomial distribution where successes increases the number of trials,,"I'm trying to calculate the probability of $k$ successes when the number of trials ( $n$ ) increases by $6$ each time a success occurs (starting at $20$ ): $$ P(X=k) = \ ? \qquad\text{where}\qquad p=.05, \quad n=20. $$ I can't just punch in $n=20+6k$ because that includes impossible scenarios like $X>0$ with no successes in the first $20$ trials. The run ends one you've reached the $(n+6k-k)$ th loss. Edit: Apologies for the lack of clarity. Hopefully these steps will help Begin run Perform $20$ trials Perform check to determine # of successes Perform $6$ additional trials for each success ( $2$ successes = $12 $ add'l trials, totaling $32$ trials) Perform check to determine  # of successes since previous check Perform $6$ additional trials for each success since previous check Repeat steps $5$ and $6$ until # of successes since previous check is $0$ End run See below for an attempted solution and tell me why it's wrong $$\frac{20}{20 + 6k} \binom{20 + 6k}{k} \frac{19^{20+5k}}{20^{20+6k}}$$","I'm trying to calculate the probability of successes when the number of trials ( ) increases by each time a success occurs (starting at ): I can't just punch in because that includes impossible scenarios like with no successes in the first trials. The run ends one you've reached the th loss. Edit: Apologies for the lack of clarity. Hopefully these steps will help Begin run Perform trials Perform check to determine # of successes Perform additional trials for each success ( successes = add'l trials, totaling trials) Perform check to determine  # of successes since previous check Perform additional trials for each success since previous check Repeat steps and until # of successes since previous check is End run See below for an attempted solution and tell me why it's wrong","k n 6 20  P(X=k) = \ ? \qquad\text{where}\qquad p=.05, \quad n=20.  n=20+6k X>0 20 (n+6k-k) 20 6 2 12  32 6 5 6 0 \frac{20}{20 + 6k} \binom{20 + 6k}{k} \frac{19^{20+5k}}{20^{20+6k}}","['probability', 'binomial-distribution']"
42,Gaussian approximation of collision time,Gaussian approximation of collision time,,"In this answer there is a claim that $$\frac{n!}{(n-k)! n^k} \approx e^{-\frac{k^2}{2n}} \tag{1}$$ which is then used to approximate the sum over $k=1,\ldots, n$ via $$\sum_{k=1}^n \frac{n!}{(n-k)! n^k} \approx \sum_{k=1}^n e^{-\frac{k^2}{2n}} \approx \int_0^n e^{-\frac{t^2}{2n}} \, dt \approx \sqrt{\pi n /2}.$$ How is the approximation (1) obtained? I attempted to use Stirling's inequality and some hand-wavey approximations: $$\frac{n!}{(n-k)! n^k} \sim \frac{n^{n+1/2}/e^n}{((n-k)^{n-k+1/2}/e^{n-k}) \cdot n^k} = e^{-k}\left(1-\frac{k}{n}\right)^{-(n-k+1/2)} \sim e^{-k} e^{\frac{n-k+1/2}{n/k}} = e^{-\frac{k^2}{n}+\frac{k}{2n}}.$$ Besides getting the wrong asymptotics, I also recognize that this approximation only works well when $k$ is small compared to $n$ , but in the above application we are considering $k$ close to $n$ as well.","In this answer there is a claim that which is then used to approximate the sum over via How is the approximation (1) obtained? I attempted to use Stirling's inequality and some hand-wavey approximations: Besides getting the wrong asymptotics, I also recognize that this approximation only works well when is small compared to , but in the above application we are considering close to as well.","\frac{n!}{(n-k)! n^k} \approx e^{-\frac{k^2}{2n}} \tag{1} k=1,\ldots, n \sum_{k=1}^n \frac{n!}{(n-k)! n^k} \approx \sum_{k=1}^n e^{-\frac{k^2}{2n}} \approx \int_0^n e^{-\frac{t^2}{2n}} \, dt \approx \sqrt{\pi n /2}. \frac{n!}{(n-k)! n^k} \sim \frac{n^{n+1/2}/e^n}{((n-k)^{n-k+1/2}/e^{n-k}) \cdot n^k} = e^{-k}\left(1-\frac{k}{n}\right)^{-(n-k+1/2)}
\sim e^{-k} e^{\frac{n-k+1/2}{n/k}}
= e^{-\frac{k^2}{n}+\frac{k}{2n}}. k n k n","['probability', 'combinatorics', 'binomial-coefficients', 'stirling-numbers']"
43,$P\left\{\left|\sum_{i=1}^n\left(\xi_{i j k}^2-1\right)\right| \geq n \delta\right\} \leq 2 \exp \left(-\frac{n \delta^2}{32+4 \delta}\right) $,,P\left\{\left|\sum_{i=1}^n\left(\xi_{i j k}^2-1\right)\right| \geq n \delta\right\} \leq 2 \exp \left(-\frac{n \delta^2}{32+4 \delta}\right) ,"This concentraion inequality was found when I read a paper about gaussian graphical model. The author gave this result directly. $$ P\left\{\left|\sum_{i=1}^n\left(\xi_{i j k}^2-1\right)\right| \geq n \delta\right\} \leq 2 \exp \left(-\frac{n \delta^2}{32+4 \delta}\right)  $$ where $\xi_{i j k}$ 's are independent $N\left(0,1\right)$ . I have checked some materials but I cannot get the value $32+4 \delta$ in the denominator.How did the author obtain this result?",This concentraion inequality was found when I read a paper about gaussian graphical model. The author gave this result directly. where 's are independent . I have checked some materials but I cannot get the value in the denominator.How did the author obtain this result?,"
P\left\{\left|\sum_{i=1}^n\left(\xi_{i j k}^2-1\right)\right| \geq n \delta\right\} \leq 2 \exp \left(-\frac{n \delta^2}{32+4 \delta}\right) 
 \xi_{i j k} N\left(0,1\right) 32+4 \delta","['probability', 'statistics', 'inequality']"
44,Calculate $E[\Phi(aX+b)^n]$,Calculate,E[\Phi(aX+b)^n],"I am working on a project, where this expected value shows up again and again, where $X \sim N(0,1)$ and $\Phi$ is the cdf of a standard normal distribution. $$E[\Phi(aX+b)^n]$$ However, I have not yet been able to solve it. I am aware of the solution if $n=1$ , given for instance in the answer to this post . I am also aware that if $a=1$ and $b=0$ , then $\Phi(X)$ would be uniformly distributed and it would then be easy to find. Thank you very much for your time and help!","I am working on a project, where this expected value shows up again and again, where and is the cdf of a standard normal distribution. However, I have not yet been able to solve it. I am aware of the solution if , given for instance in the answer to this post . I am also aware that if and , then would be uniformly distributed and it would then be easy to find. Thank you very much for your time and help!","X \sim N(0,1) \Phi E[\Phi(aX+b)^n] n=1 a=1 b=0 \Phi(X)","['calculus', 'probability', 'integration', 'normal-distribution', 'expected-value']"
45,Evaluating gamma functions.,Evaluating gamma functions.,,"I am a bit lost on Gamma functions and would like to have the following evaluation from a textbook explained to me: $\frac{\Gamma(k+1/2)}{\sqrt{\pi}} = \frac{\Gamma(k+\frac{1}{2})}{\Gamma(\frac{1}{2})} = (k-\frac{1}{2})(k-\frac{3}{2})...\frac{1}{2} = \frac{1}{2^k}(2k-1)!! = \frac{(2k)!}{4^k*k!}$ The first two equalities I understand, but when it comes to evaluating the factorials I'm not sure, since I assume that $\Gamma(1/2)$ is the irrational constant $sqrt(\pi)$ and can't really be neatly factored out.","I am a bit lost on Gamma functions and would like to have the following evaluation from a textbook explained to me: The first two equalities I understand, but when it comes to evaluating the factorials I'm not sure, since I assume that is the irrational constant and can't really be neatly factored out.",\frac{\Gamma(k+1/2)}{\sqrt{\pi}} = \frac{\Gamma(k+\frac{1}{2})}{\Gamma(\frac{1}{2})} = (k-\frac{1}{2})(k-\frac{3}{2})...\frac{1}{2} = \frac{1}{2^k}(2k-1)!! = \frac{(2k)!}{4^k*k!} \Gamma(1/2) sqrt(\pi),"['real-analysis', 'probability', 'analysis', 'probability-distributions', 'gamma-function']"
46,The functional equation $f(x)+f(y)=g(x+y)$ almost everywhere.,The functional equation  almost everywhere.,f(x)+f(y)=g(x+y),"Let $P$ be a probability on $R$ and $f$ and $g$ two  measurable functions such that $f(x)+f(y)=g(x+y)$ almost everywhere for $P(dx)P(dy)$ . How can I prove that there exist two numbers $a$ and $b$ such that $f(x)=ax+b$ almost everywhere for $P(dx)?$ It must be a classical result, but I need some references. Multiplying both sides by $e^{itx+isy} P(dx)Q(dy)$ and integrating does not lead to the solution. Of course if $P$ has a strictly positive density with respect to the Lebesgue measure and if $g=f$ this is the classical Cauchy equation solved ages ago by Mark Kac before 1940.","Let be a probability on and and two  measurable functions such that almost everywhere for . How can I prove that there exist two numbers and such that almost everywhere for It must be a classical result, but I need some references. Multiplying both sides by and integrating does not lead to the solution. Of course if has a strictly positive density with respect to the Lebesgue measure and if this is the classical Cauchy equation solved ages ago by Mark Kac before 1940.",P R f g f(x)+f(y)=g(x+y) P(dx)P(dy) a b f(x)=ax+b P(dx)? e^{itx+isy} P(dx)Q(dy) P g=f,"['real-analysis', 'probability']"
47,Challenging probability exercise,Challenging probability exercise,,"I'm dealing with the following exercise (don't be scared about the lenght of the exercise, it has been almost solved): Mr Smith has 3 boxes of chocolates. The first box contains 20 bars of milk chocolate, 12 bars of dark chocolate and 8 bars of white chocolate. The second box contains 10 bars of milk chocolate, 10 dark chocolates and 10 milk chocolates. The third box has 10 milk and 10 dark chocolates. Mr Smith tosses a fair coin twice for choosing from which box he takes a bar of chocolate. If, by tossing a coin twice, he gets ""Head"" twice in a row, Mr Smith randomly chooses a bar of chocolate from the first box; if he gets tails twice in a row,Mr Smith randomly chooses a bar of chocolate from the second box; otherwise he randomly chooses from the third box. It is clear,that once the box has been chosen, the flavour of the chocolate bar is randomly chosen. (a) What's the probability that the first bar of chocolate is a milk chocolate? My answer: I call $A$ the event of choosing the first box. $P(A)=1/4$ ; I call $B$ the event of choosing the second box. $P(B)=1/4$ ; I call $C$ the event of choosing the second box. $P(B)=1/2$ ; And $P(M|A)=1/2,P(M|B)=1/3,P(M|C)=1/2$ Let P(M) the probability of picking milk as first chocolate flavour, and it is equal to: $P(M)=P(A \cap M)+P(B \cap M)+P(C \cap M)$ And this also reads as: $P(M)=P(M|A)P(A)+P(M|B)P(B)+P(M|C)P(C)=11/24$ Is that correct? (b) Mr Smith has drawn a milk chocolate. What's the probability that it comes from the first box? Applying the Bayes theorem: $P(A|M)=\frac{P(M|A)P(A)}{P(M)}=\frac{(1/2)(1/4)}{11/24}=3/11$ Is that correct? (c) Mr Smith has just eaten the first chocolate bar and it was a milk chocolate. What's the probability that the second chocolate bar taken from the same box is again a milk chocolate? Answer: I define as $P(M_2)$ the probability that the second chocolate bar is milk chocolate. Then, $P(M_2|M)=P(M_2 \cap A|M)+P(M_2 \cap B|M)+P(M_2 \cap C|M)$ which should read as: $P(M_2|M)=P(M_{2} | A \cap M)P(A|M) + P(M_{2} | B \cap M)P(B|M) + P(M_{2} | C \cap M)P(C|M) $ Here I'm stuck because the professor's slides provide an hint, saying that I should end up with computing the following probability: $P(M_2|M)=P(M_2|A)P(A|M) + P(M_2|B)P(B|M) + P(M_2|C)P(C|M)$ And this seems to occur iff $P(M_{2} | A \cap M) = P(M_2|A)$ , and the same for B,C. Why is that possible? I guess, e.g., $P(M_2|A \cap M)=19/39$ . right? Maybe, I can have the equality between $P(M_2|A \cap M)=P(M_2|A)$ , if I interpret the event $M_2$ as the second milk chocolate drawn, and conditioning on $M$ is just redundant. Is that correct?","I'm dealing with the following exercise (don't be scared about the lenght of the exercise, it has been almost solved): Mr Smith has 3 boxes of chocolates. The first box contains 20 bars of milk chocolate, 12 bars of dark chocolate and 8 bars of white chocolate. The second box contains 10 bars of milk chocolate, 10 dark chocolates and 10 milk chocolates. The third box has 10 milk and 10 dark chocolates. Mr Smith tosses a fair coin twice for choosing from which box he takes a bar of chocolate. If, by tossing a coin twice, he gets ""Head"" twice in a row, Mr Smith randomly chooses a bar of chocolate from the first box; if he gets tails twice in a row,Mr Smith randomly chooses a bar of chocolate from the second box; otherwise he randomly chooses from the third box. It is clear,that once the box has been chosen, the flavour of the chocolate bar is randomly chosen. (a) What's the probability that the first bar of chocolate is a milk chocolate? My answer: I call the event of choosing the first box. ; I call the event of choosing the second box. ; I call the event of choosing the second box. ; And Let P(M) the probability of picking milk as first chocolate flavour, and it is equal to: And this also reads as: Is that correct? (b) Mr Smith has drawn a milk chocolate. What's the probability that it comes from the first box? Applying the Bayes theorem: Is that correct? (c) Mr Smith has just eaten the first chocolate bar and it was a milk chocolate. What's the probability that the second chocolate bar taken from the same box is again a milk chocolate? Answer: I define as the probability that the second chocolate bar is milk chocolate. Then, which should read as: Here I'm stuck because the professor's slides provide an hint, saying that I should end up with computing the following probability: And this seems to occur iff , and the same for B,C. Why is that possible? I guess, e.g., . right? Maybe, I can have the equality between , if I interpret the event as the second milk chocolate drawn, and conditioning on is just redundant. Is that correct?","A P(A)=1/4 B P(B)=1/4 C P(B)=1/2 P(M|A)=1/2,P(M|B)=1/3,P(M|C)=1/2 P(M)=P(A \cap M)+P(B \cap M)+P(C \cap M) P(M)=P(M|A)P(A)+P(M|B)P(B)+P(M|C)P(C)=11/24 P(A|M)=\frac{P(M|A)P(A)}{P(M)}=\frac{(1/2)(1/4)}{11/24}=3/11 P(M_2) P(M_2|M)=P(M_2 \cap A|M)+P(M_2 \cap B|M)+P(M_2 \cap C|M) P(M_2|M)=P(M_{2} | A \cap M)P(A|M) + P(M_{2} | B \cap M)P(B|M) + P(M_{2} | C \cap M)P(C|M)  P(M_2|M)=P(M_2|A)P(A|M) + P(M_2|B)P(B|M) + P(M_2|C)P(C|M) P(M_{2} | A \cap M) = P(M_2|A) P(M_2|A \cap M)=19/39 P(M_2|A \cap M)=P(M_2|A) M_2 M","['probability', 'probability-theory', 'logic']"
48,Expected number of minutes for two ants to fall off rope,Expected number of minutes for two ants to fall off rope,,"This question is based off of this post Let's say we have a $1$ foot rope and we randomly and uniformly place $2$ ants on it. They each move $1$ ft per second towards a random end and switch direction upon collision. What would the expected length of time be for the last ant to fall off the rope. Suppose on average the ants will be placed at $\frac13$ and $\frac23$ feet on this rope (since ants are IID). It is with probability $0.5$ that they will go in the same direction in which case it will take $\frac23$ of a minute for the last ant to fall. If the ants travel towards each other (probability $\frac14$ ) it will take $\frac23$ minutes for them to fall. If the ants move away from each other, it will take $\frac13$ for them to fall. This gives us $\frac34\cdot\frac23 + \frac14\cdot\frac13 = \frac7{12}$ However, based off the solution I believe the correct answer is $\frac23$ . Why is this approach invalid?","This question is based off of this post Let's say we have a foot rope and we randomly and uniformly place ants on it. They each move ft per second towards a random end and switch direction upon collision. What would the expected length of time be for the last ant to fall off the rope. Suppose on average the ants will be placed at and feet on this rope (since ants are IID). It is with probability that they will go in the same direction in which case it will take of a minute for the last ant to fall. If the ants travel towards each other (probability ) it will take minutes for them to fall. If the ants move away from each other, it will take for them to fall. This gives us However, based off the solution I believe the correct answer is . Why is this approach invalid?",1 2 1 \frac13 \frac23 0.5 \frac23 \frac14 \frac23 \frac13 \frac34\cdot\frac23 + \frac14\cdot\frac13 = \frac7{12} \frac23,"['probability', 'expected-value', 'independence', 'uniform-distribution']"
49,"Reference for the ""Quotient Variance""?","Reference for the ""Quotient Variance""?",,"I have recently encountered the expression $$\frac{\mathbb{E}[X^2]}{\mathbb{E}[X]^2}$$ in my research. This can be thought of as an analogue of the variance $\mathbb{E}[X^2] - \mathbb{E}[X]^2$ where one divides instead of subtracting. Does this quantity have some well-known name? I recall seeing it before in some probabilist's work, but tracking down a particular reference would take quite some time.","I have recently encountered the expression in my research. This can be thought of as an analogue of the variance where one divides instead of subtracting. Does this quantity have some well-known name? I recall seeing it before in some probabilist's work, but tracking down a particular reference would take quite some time.",\frac{\mathbb{E}[X^2]}{\mathbb{E}[X]^2} \mathbb{E}[X^2] - \mathbb{E}[X]^2,"['probability', 'reference-request']"
50,Conditional probability with unequal probabilities,Conditional probability with unequal probabilities,,"My question is based the scenario in Non-Uniform Probability Without Replacement . Suppose we have probabilities of four letters $$P(A) = 0.1 \quad P(B) = 0.2 \quad P(C) = 0.3 \quad P(D) = 0.4$$ If I were to draw two letters without replacement, and the first letter is A, what is the probability that I will get B on the second draw? That is, what is $P(B | A)$ ? I guess that $P(B | A) = P(B)/(1 - P(A)) = 0.2/0.9$ . But why is that so? Where does the formula come from? Can it be derived from simple conditional probability formula? note: I also tried to simulate this problem, and the relative frequency does approach $0.2/0.9.$ But I still confused where the formula comes from.","My question is based the scenario in Non-Uniform Probability Without Replacement . Suppose we have probabilities of four letters If I were to draw two letters without replacement, and the first letter is A, what is the probability that I will get B on the second draw? That is, what is ? I guess that . But why is that so? Where does the formula come from? Can it be derived from simple conditional probability formula? note: I also tried to simulate this problem, and the relative frequency does approach But I still confused where the formula comes from.",P(A) = 0.1 \quad P(B) = 0.2 \quad P(C) = 0.3 \quad P(D) = 0.4 P(B | A) P(B | A) = P(B)/(1 - P(A)) = 0.2/0.9 0.2/0.9.,"['probability', 'combinatorics', 'statistics', 'conditional-probability']"
51,Find all $f$ such that $X\sim\mathcal{G}(\lambda) \;\Rightarrow\; f(X)\sim \mathcal{G}(\mu)$,Find all  such that,f X\sim\mathcal{G}(\lambda) \;\Rightarrow\; f(X)\sim \mathcal{G}(\mu),"I found a nice problem recently, but could not come up with a solution: Find all functions $f:\mathbb{Z}_{\geq 0}\to\mathbb{Z}_{\geq 0}$ such that for all $0< \lambda < 1$ , if $X\sim G(\lambda)$ , then there exists $0<\mu < 1$ with $f(X) \sim G(\mu)$ . Thanks to the answers below, I was able to understand how to solve it! Spoiler: the solutions are all the functions $f_d:x\mapsto \lfloor x/d\rfloor$ for a fixed $d\geq 1$ .","I found a nice problem recently, but could not come up with a solution: Find all functions such that for all , if , then there exists with . Thanks to the answers below, I was able to understand how to solve it! Spoiler: the solutions are all the functions for a fixed .",f:\mathbb{Z}_{\geq 0}\to\mathbb{Z}_{\geq 0} 0< \lambda < 1 X\sim G(\lambda) 0<\mu < 1 f(X) \sim G(\mu) f_d:x\mapsto \lfloor x/d\rfloor d\geq 1,"['probability', 'functional-analysis', 'probability-theory', 'geometric-distribution']"
52,Different Ways To Calculate Conditional Probabilities,Different Ways To Calculate Conditional Probabilities,,"I thought of the following math problem: Suppose there is a basketball coach that wants to test the following hypothesis: The coach believes that once a player successfully scores a few baskets - the player is then more likely to score more baskets. Suppose the basketball coach then carries out an experiment - the coach asks different players to shoot baskets and records the results. As an example, the data might look something like this (I simulated this using the R programming language): Player                                                               Baskets 1 Player 1                      Miss Miss Miss Miss Hit  Hit  Hit  Miss Miss Hit 2 Player 2                                               Hit  Miss Miss Hit  Hit 3 Player 3            Miss Miss Hit  Hit  Hit  Miss Hit  Miss Hit  Miss Hit  Hit 4 Player 4 Hit  Hit  Hit  Miss Miss Hit  Miss Miss Miss Hit  Hit  Miss Hit  Miss 5 Player 5                               Hit  Hit  Miss Hit  Miss Miss Hit  Miss Based on this format of data - I thought of the 3 following methods to answer the coach's question: Method 1: For each individual player, count the number of times (in general, over all shots) that ""Miss"" follows ""Miss"", ""Miss"" follows ""Hit"", ""Hit"" follows ""Hit"" and ""Hit"" follows ""Hit"". Repeat this for all players, and then you can construct a 4-State Markov Chain with Conditional Probabilities Method 2: For each individual player, ignore everything except the last two shots. Then, count the number of at ""Miss"" follows ""Miss"", ""Miss"" follows ""Hit"", ""Hit"" follows ""Hit"" and ""Hit"" follows ""Hit"". Repeat this for all players, and then you can construct a 4-State Markov Chain with Conditional Probabilities only taking into consideration the last shot. Method 3: For each individual player, assign a value of ""1"" when a basket is ""Hit"" and a value of ""0"" when a basket is missed"". Then calculate the average for each player (e.g. Hit, Hit, Miss, Hit, Hit = 1+1+0+1+1 / 5 = 0.8) but ignore the last basket. The data should now be in the following format: Player Average_of_All_Baskets_Excluding_Last Last_Basket 1 Player 1                                 0.330         Hit 2 Player 2                                 0.500         Hit 3 Player 3                                 0.545         Hit 4 Player 4                                 0.500        Miss 5 Player 5                                 0.570        Miss Based on this approach, a Regression Model (e.g. Logistic Regression)  can be fit that models the probability of making the next basket, based on the scoring average of the player up until that point. We can also add other variables such as the ""result of the second last basket"" or the ""average of the second last and the third last baskets"" that can try to capture and benefit the model with more recent information. As a result, this model will try to estimate the conditional probability of making the next basket based on the history of the player. However, I do not know if using ""lagged values of the response variable"" will violate the assumptions of the Regression Model. Thus, my question is - are all 3 methods valid approaches to estimating the conditional probabilities and testing the hypothesis of the coach? Are some of these methodologies more ""valid"" than others (e.g. perhaps some contain inherent biases and flaws)? Thanks!","I thought of the following math problem: Suppose there is a basketball coach that wants to test the following hypothesis: The coach believes that once a player successfully scores a few baskets - the player is then more likely to score more baskets. Suppose the basketball coach then carries out an experiment - the coach asks different players to shoot baskets and records the results. As an example, the data might look something like this (I simulated this using the R programming language): Player                                                               Baskets 1 Player 1                      Miss Miss Miss Miss Hit  Hit  Hit  Miss Miss Hit 2 Player 2                                               Hit  Miss Miss Hit  Hit 3 Player 3            Miss Miss Hit  Hit  Hit  Miss Hit  Miss Hit  Miss Hit  Hit 4 Player 4 Hit  Hit  Hit  Miss Miss Hit  Miss Miss Miss Hit  Hit  Miss Hit  Miss 5 Player 5                               Hit  Hit  Miss Hit  Miss Miss Hit  Miss Based on this format of data - I thought of the 3 following methods to answer the coach's question: Method 1: For each individual player, count the number of times (in general, over all shots) that ""Miss"" follows ""Miss"", ""Miss"" follows ""Hit"", ""Hit"" follows ""Hit"" and ""Hit"" follows ""Hit"". Repeat this for all players, and then you can construct a 4-State Markov Chain with Conditional Probabilities Method 2: For each individual player, ignore everything except the last two shots. Then, count the number of at ""Miss"" follows ""Miss"", ""Miss"" follows ""Hit"", ""Hit"" follows ""Hit"" and ""Hit"" follows ""Hit"". Repeat this for all players, and then you can construct a 4-State Markov Chain with Conditional Probabilities only taking into consideration the last shot. Method 3: For each individual player, assign a value of ""1"" when a basket is ""Hit"" and a value of ""0"" when a basket is missed"". Then calculate the average for each player (e.g. Hit, Hit, Miss, Hit, Hit = 1+1+0+1+1 / 5 = 0.8) but ignore the last basket. The data should now be in the following format: Player Average_of_All_Baskets_Excluding_Last Last_Basket 1 Player 1                                 0.330         Hit 2 Player 2                                 0.500         Hit 3 Player 3                                 0.545         Hit 4 Player 4                                 0.500        Miss 5 Player 5                                 0.570        Miss Based on this approach, a Regression Model (e.g. Logistic Regression)  can be fit that models the probability of making the next basket, based on the scoring average of the player up until that point. We can also add other variables such as the ""result of the second last basket"" or the ""average of the second last and the third last baskets"" that can try to capture and benefit the model with more recent information. As a result, this model will try to estimate the conditional probability of making the next basket based on the history of the player. However, I do not know if using ""lagged values of the response variable"" will violate the assumptions of the Regression Model. Thus, my question is - are all 3 methods valid approaches to estimating the conditional probabilities and testing the hypothesis of the coach? Are some of these methodologies more ""valid"" than others (e.g. perhaps some contain inherent biases and flaws)? Thanks!",,"['probability', 'statistics']"
53,A random walk on the clock,A random walk on the clock,,"The setting is simple but I just don't know how to calculate a desired quantity, which will be introduced later. Suppose we have a clock with $M$ points on it, i.e. $\{0, 1, 2, ..., M-1\}$ , where $M\in\mathbb N$ . Suppose we starts at some point on the clock, say $a$ , where $0\leq a\leq M-1$ . We have a probability of $1/2$ to stay at point $a$ , and a probability of $1/2$ to move. If we move, then we will have a probability $p$ to move clockwise and a probability $1-p$ to move anti-clockwise, where $0<p<1$ . Let $X_n$ denote our location after $n$ steps. We define $d(x)=\min\{x,M-x\}$ for all $0\leq x \leq M-1$ , i.e. the distance between $x$ and the point $0$ . Question: Calculate $\lim_{n\to \infty} \mathbb E[d(X_n)]$ , where $\mathbb E$ means expectation. I have been thinking this problem for quite a while but don't know how to approach it. We cannot use the same argument as in this problem (cf. @Did 's post in the answer) because $\mathbb E[d(X_n)|X_0=y]$ may be different for different $y$ , where $0\leq y \leq M-1$ . That's, our problem doesn't have ""symmetry"". Also, I don't know if we need to consider $\lim_{n\to \infty} \mathbb E[d(X_n)]$ as a whole or consider the limit and the expectation separately, which means first calculating the expectation and then taking limit. Thanks for help!","The setting is simple but I just don't know how to calculate a desired quantity, which will be introduced later. Suppose we have a clock with points on it, i.e. , where . Suppose we starts at some point on the clock, say , where . We have a probability of to stay at point , and a probability of to move. If we move, then we will have a probability to move clockwise and a probability to move anti-clockwise, where . Let denote our location after steps. We define for all , i.e. the distance between and the point . Question: Calculate , where means expectation. I have been thinking this problem for quite a while but don't know how to approach it. We cannot use the same argument as in this problem (cf. @Did 's post in the answer) because may be different for different , where . That's, our problem doesn't have ""symmetry"". Also, I don't know if we need to consider as a whole or consider the limit and the expectation separately, which means first calculating the expectation and then taking limit. Thanks for help!","M \{0, 1, 2, ..., M-1\} M\in\mathbb N a 0\leq a\leq M-1 1/2 a 1/2 p 1-p 0<p<1 X_n n d(x)=\min\{x,M-x\} 0\leq x \leq M-1 x 0 \lim_{n\to \infty} \mathbb E[d(X_n)] \mathbb E \mathbb E[d(X_n)|X_0=y] y 0\leq y \leq M-1 \lim_{n\to \infty} \mathbb E[d(X_n)]","['probability', 'markov-chains', 'random-walk']"
54,Question about definition of 'distribution',Question about definition of 'distribution',,"If a problem says to find the distribution of an RV, can I take that to mean the CDF, or take it to mean the PDF, OR is it ambiguous? Here is a concrete example: ""If $X_1$ and $X_2$ are independent exponential random variables with respective parameters $a$ and $b$ , find the distribution of $Z = \frac{X_1}{X_2}.$","If a problem says to find the distribution of an RV, can I take that to mean the CDF, or take it to mean the PDF, OR is it ambiguous? Here is a concrete example: ""If and are independent exponential random variables with respective parameters and , find the distribution of",X_1 X_2 a b Z = \frac{X_1}{X_2}.,"['probability', 'statistics', 'probability-distributions', 'density-function', 'cumulative-distribution-functions']"
55,Variance of Sum of independent random variables. Wald's identities.,Variance of Sum of independent random variables. Wald's identities.,,"Let $N: \Omega \rightarrow \mathbb{N}$ be a random variable, and $S_N = \sum_{i=1}^N X_i$ for $(X_n)_n$ i.i.d. Wald id1: $E[S_N] = E[X_1]E[N]$ , Wald id2: $E[S_N^2] = E[X_1^2]E[N]$ . Prove that $Var(S_N) = -Var(N)\mathbb{E}[X_1]^2 + 2Cov(S_N, N)\mathbb{E}[X_1] + Var(X_1)\mathbb{E}[N]$ . Use Walds first and second identity. My attempt: I tried proving the equality from right to left. $$-Var(N)\mathbb{E}[X_1]^2 + 2Cov(S_N, N)\mathbb{E}[X_1] + Var(X_1)\mathbb{E}[N]= $$ $$ = - (E[N^2] - E[N]^2)E[X_1]^2 - 2(E[S_N \cdot N] - E[S_N]E[N])E[X_1] + (E[X_1^2]-E[X_1]^2)E[N]$$ $$=  -E[N^2]E[X_1]^2 + E[S_N]^2 - 2E[S \cdot N ]E[X_1] + 2E[S_n]E[N]E[X_1] + E[X_1^2]E[N] - E[X_1]^2E[N]$$ $$ = -3E[S_N \cdot N]E[X_1] + 3E[S_N]^2 + E[S_N^2] - E[S_N]E[X_1]$$ Any help?","Let be a random variable, and for i.i.d. Wald id1: , Wald id2: . Prove that . Use Walds first and second identity. My attempt: I tried proving the equality from right to left. Any help?","N: \Omega \rightarrow \mathbb{N} S_N = \sum_{i=1}^N X_i (X_n)_n E[S_N] = E[X_1]E[N] E[S_N^2] = E[X_1^2]E[N] Var(S_N) = -Var(N)\mathbb{E}[X_1]^2 + 2Cov(S_N, N)\mathbb{E}[X_1] + Var(X_1)\mathbb{E}[N] -Var(N)\mathbb{E}[X_1]^2 + 2Cov(S_N, N)\mathbb{E}[X_1] + Var(X_1)\mathbb{E}[N]=   = - (E[N^2] - E[N]^2)E[X_1]^2 - 2(E[S_N \cdot N] - E[S_N]E[N])E[X_1] + (E[X_1^2]-E[X_1]^2)E[N] =  -E[N^2]E[X_1]^2 + E[S_N]^2 - 2E[S \cdot N ]E[X_1] + 2E[S_n]E[N]E[X_1] + E[X_1^2]E[N] - E[X_1]^2E[N]  = -3E[S_N \cdot N]E[X_1] + 3E[S_N]^2 + E[S_N^2] - E[S_N]E[X_1]","['probability', 'random-variables', 'expected-value', 'variance']"
56,Proof of the continuity axiom in the classical probability model,Proof of the continuity axiom in the classical probability model,,"I am reading a ""proof"" that in the classical probability model, the probability axioms of Kolmogorov are satisfied. I say ""proof"" because there's a serious flaw there. So I need some clarification i.e. a real rigorous proof (for one of the axioms). Definition: Let $(\Omega, F)$ be a measurable space, where $\Omega = \{w_1, w_2, w_3, ...\}$ is a countable infinite set, and let $F$ be the powerset of $\Omega$ . Let us assume that every elementary event/outcome $w_i$ is mapped to a non-negative number $p(w_i)$ and also let us assume $\sum_{i=1}^n p(w_i) = 1$ (that, I think, means the RHS series is convergent and its sum is 1). Then for every event $A \subseteq \Omega$ we define the probability of $A$ as $P(A) = \sum_{w \in A} p(w)$ OK... now having this definition, we need to prove the following axiom is satisfied. A4: For every sequence of events $A_1 \supseteq A_2 \supseteq A_3 \supseteq ...$ such that $$\bigcap_{i=1}^\infty{A_n} = \emptyset$$ the respective sequence of probabilities $P(A_1), P(A_2), P(A_3), ...$ is decreasing and goes to zero as $n \to \infty$ . Of course proving that the sequence of probabilities $P(A_1), P(A_2), P(A_3), ...$ is decreasing is not a problem. But regarding the limit being zero, I looked in several books, I also searched online. I don't find a decent proof of the fact that the sequence goes to $0$ as $n \to \infty$ . My book basically states that this is obvious because in the series $$P(A_n) = \sum_{w \in A_n} p(w)$$ ""we run out of terms"" as $n \to \infty$ . But that's not really a proof, is it? It's just some intuition-based note. So how do we prove that this axiom A4 is satisfied? Note 1: It seems to me that's actually a real analysis, in particular a series problem but also related to set theory. Somehow I feel like $P(A_n)$ is the remainder term in the series defining $P(A_1)$ which is a convergent series. So $P(A_n)$ must go to zero. But I cannot really formalize this argument, I get confused in my thoughts. For this argument to work, it seems we need to order somehow the elements of $A_1$ by first taking those elements which don't belong to $A_2$ , then those which don't belong to $A_3$ , then those which don't belong to $A_4$ and so on. And then it feels like $P(A_n)$ is somehow that remainder term of the series $P(A_1) = \sum_{w \in A_1} p(w)$ . But as I said, I can't really formalize my intuition. Note 2: Now I am thinking that my major confusion stems from the fact I am not even sure what is the n-th partial sum of this series $$\sum_{w \in A} p(w)$$ E.g. if $A = \{w_1, w_5, w_7, w_{90}, w_{100}, \dots \}$ , is the 5-th partial sum $w_1 + w_5 + w_7 + w_{90} + w_{100}$ , or is it $w_1 + 0 + 0 + 0 + w_5$ ? I think we need to work with the 2nd interpretation when proving that the axioms are satisfied (all axioms, not just A4 which I quoted above). If I use the 1st interpretation (of the partial sum), it's not quite clear how to prove the additivity axiom $P(A \cup B) = P(A) + P(B)$ , when $AB = \emptyset$ . And we must use the additivity axiom to prove A4. Also, it's not clear what is $P(B)$ if $B$ is finite.","I am reading a ""proof"" that in the classical probability model, the probability axioms of Kolmogorov are satisfied. I say ""proof"" because there's a serious flaw there. So I need some clarification i.e. a real rigorous proof (for one of the axioms). Definition: Let be a measurable space, where is a countable infinite set, and let be the powerset of . Let us assume that every elementary event/outcome is mapped to a non-negative number and also let us assume (that, I think, means the RHS series is convergent and its sum is 1). Then for every event we define the probability of as OK... now having this definition, we need to prove the following axiom is satisfied. A4: For every sequence of events such that the respective sequence of probabilities is decreasing and goes to zero as . Of course proving that the sequence of probabilities is decreasing is not a problem. But regarding the limit being zero, I looked in several books, I also searched online. I don't find a decent proof of the fact that the sequence goes to as . My book basically states that this is obvious because in the series ""we run out of terms"" as . But that's not really a proof, is it? It's just some intuition-based note. So how do we prove that this axiom A4 is satisfied? Note 1: It seems to me that's actually a real analysis, in particular a series problem but also related to set theory. Somehow I feel like is the remainder term in the series defining which is a convergent series. So must go to zero. But I cannot really formalize this argument, I get confused in my thoughts. For this argument to work, it seems we need to order somehow the elements of by first taking those elements which don't belong to , then those which don't belong to , then those which don't belong to and so on. And then it feels like is somehow that remainder term of the series . But as I said, I can't really formalize my intuition. Note 2: Now I am thinking that my major confusion stems from the fact I am not even sure what is the n-th partial sum of this series E.g. if , is the 5-th partial sum , or is it ? I think we need to work with the 2nd interpretation when proving that the axioms are satisfied (all axioms, not just A4 which I quoted above). If I use the 1st interpretation (of the partial sum), it's not quite clear how to prove the additivity axiom , when . And we must use the additivity axiom to prove A4. Also, it's not clear what is if is finite.","(\Omega, F) \Omega = \{w_1, w_2, w_3, ...\} F \Omega w_i p(w_i) \sum_{i=1}^n p(w_i) = 1 A \subseteq \Omega A P(A) = \sum_{w \in A} p(w) A_1 \supseteq A_2 \supseteq A_3 \supseteq ... \bigcap_{i=1}^\infty{A_n} = \emptyset P(A_1), P(A_2), P(A_3), ... n \to \infty P(A_1), P(A_2), P(A_3), ... 0 n \to \infty P(A_n) = \sum_{w \in A_n} p(w) n \to \infty P(A_n) P(A_1) P(A_n) A_1 A_2 A_3 A_4 P(A_n) P(A_1) = \sum_{w \in A_1} p(w) \sum_{w \in A} p(w) A = \{w_1, w_5, w_7, w_{90}, w_{100}, \dots \} w_1 + w_5 + w_7 + w_{90} + w_{100} w_1 + 0 + 0 + 0 + w_5 P(A \cup B) = P(A) + P(B) AB = \emptyset P(B) B","['probability', 'sequences-and-series', 'probability-theory', 'measure-theory']"
57,Can de Morgan's laws be applied to probability?,Can de Morgan's laws be applied to probability?,,"I know and understand what de Morgan's laws are in the context of Boolean algebra and set theory, but can they be applied to probability? For example, when calculating the probability of multiple things not happening, would it be reasonable to say, given de Morgan's laws, that: $$ \prod_{n=1}^{k}\left(1-P\left(n\right)\right)=1-\sum_{n=1}^{k}\left(P\left(n\right)\right) $$ With the first representing (for lack of a better phrase) ¬a ∧ ¬b, and the second representing ¬(a ∨ b).","I know and understand what de Morgan's laws are in the context of Boolean algebra and set theory, but can they be applied to probability? For example, when calculating the probability of multiple things not happening, would it be reasonable to say, given de Morgan's laws, that: With the first representing (for lack of a better phrase) ¬a ∧ ¬b, and the second representing ¬(a ∨ b).", \prod_{n=1}^{k}\left(1-P\left(n\right)\right)=1-\sum_{n=1}^{k}\left(P\left(n\right)\right) ,"['probability', 'boolean-algebra']"
58,"Probability of $k \in \{1, 2, \dots, n\}$ people sharing the same birthday in a room of $n$ people",Probability of  people sharing the same birthday in a room of  people,"k \in \{1, 2, \dots, n\} n","In a room of $n$ people, what is the probability that at least $k \in \{1, 2, \dots, n\}$ people all share a common birthday? For example, what is the probability that at least 5 people all share the same birthday in a room of a 1000 people. I have found a formula on Wikipedia for solving this problem when $k = 2$ but I would like to be able to solve for $n > 365$ and $k > 2$ . I know that $p(k \text{ people share the same birthday}) = 1$ for $k = \lceil\frac{n}{365}\rceil$ but I don't know how to solve beyond this point. I assume there are $365^n$ different ways the birthdays of $n$ people can be distributed within a year hence I am struggling to reach an answer using a combinatorial approach. I have researched this problem online but most answers stop at the probability of one or more shared birthday in a group of 60 people max.","In a room of people, what is the probability that at least people all share a common birthday? For example, what is the probability that at least 5 people all share the same birthday in a room of a 1000 people. I have found a formula on Wikipedia for solving this problem when but I would like to be able to solve for and . I know that for but I don't know how to solve beyond this point. I assume there are different ways the birthdays of people can be distributed within a year hence I am struggling to reach an answer using a combinatorial approach. I have researched this problem online but most answers stop at the probability of one or more shared birthday in a group of 60 people max.","n k \in \{1, 2, \dots, n\} k = 2 n > 365 k > 2 p(k \text{ people share the same birthday}) = 1 k = \lceil\frac{n}{365}\rceil 365^n n","['probability', 'combinatorics']"
59,Whats the probability for person A to win the dice game?,Whats the probability for person A to win the dice game?,,"The rules: Two people rolls a single dice. If the dice rolls 1,2,3 or 4, person A gets a point. For the rolls 5 and 6, person B gets a point. One person needs a 2 point lead to win the game. This is a question taken from my math book. The answer says the probability is $\frac{4}{5}$ for person A to win the game. Which I dont understand. My thought process: Lets look at all the four possible outcomes with the two first roles. These would be AA, BB, AB or BA. AA means person A gets a point two times a row. Under is the probability for all these scenarios: $P(AA)=(\frac{2}{3})^2=\frac{4}{9}$ $P(BB)=(\frac{1}{3})^2=\frac{1}{9}$ $P(AB)=\frac{2}{3}\cdot\frac{1}{3}=\frac{2}{9}$ $P(BA)=\frac{1}{3}\cdot\frac{2}{3}=\frac{2}{9}$ If AB or BA happens they have an equal amount of points again, no matter how far they are into the game. The probability of this would then be $2\cdot\frac{2}{9}=\frac{4}{9}$ . Since they have an equal amount of points, you can look at that as the game has restarted. Meaning person A has to get two points a row to win no matter what. Would that not mean the probability is $\frac{4}{9}$ for person A to win? Can someone tell me where my logic is flawed and what the correct logic would be?","The rules: Two people rolls a single dice. If the dice rolls 1,2,3 or 4, person A gets a point. For the rolls 5 and 6, person B gets a point. One person needs a 2 point lead to win the game. This is a question taken from my math book. The answer says the probability is for person A to win the game. Which I dont understand. My thought process: Lets look at all the four possible outcomes with the two first roles. These would be AA, BB, AB or BA. AA means person A gets a point two times a row. Under is the probability for all these scenarios: If AB or BA happens they have an equal amount of points again, no matter how far they are into the game. The probability of this would then be . Since they have an equal amount of points, you can look at that as the game has restarted. Meaning person A has to get two points a row to win no matter what. Would that not mean the probability is for person A to win? Can someone tell me where my logic is flawed and what the correct logic would be?",\frac{4}{5} P(AA)=(\frac{2}{3})^2=\frac{4}{9} P(BB)=(\frac{1}{3})^2=\frac{1}{9} P(AB)=\frac{2}{3}\cdot\frac{1}{3}=\frac{2}{9} P(BA)=\frac{1}{3}\cdot\frac{2}{3}=\frac{2}{9} 2\cdot\frac{2}{9}=\frac{4}{9} \frac{4}{9},"['probability', 'markov-chains']"
60,Mutually Exclusive question,Mutually Exclusive question,,"If we have $P(a)=0.6, P(b)=0.7$ , can we say they are not mutually exclusive? without any further infotmation? For example, is there a possible that $b$ depends on $c$ , like this $p(b \mid c)$ , right now we only have $P(b)=0.7$ and $P(a)=0.6$ , can we say $p(a)$ and $p(b)$ are not mutually exclusive, cause $p(a)+p(b)>1$ ? If event a and b are totally not related, can we still add them? For example,the p(b) is probability that we go to jail if we rob a bank, p(a) is the probability of jack eat an apple today, can we still say they are not mutually exclusive? I understand the math here, but do not understand the jail probability p(b) is dependent on the rob probability, is it right that we add p(b) to p(a) to say they are not mutually exclusive? or the example i made is totally wrong?","If we have , can we say they are not mutually exclusive? without any further infotmation? For example, is there a possible that depends on , like this , right now we only have and , can we say and are not mutually exclusive, cause ? If event a and b are totally not related, can we still add them? For example,the p(b) is probability that we go to jail if we rob a bank, p(a) is the probability of jack eat an apple today, can we still say they are not mutually exclusive? I understand the math here, but do not understand the jail probability p(b) is dependent on the rob probability, is it right that we add p(b) to p(a) to say they are not mutually exclusive? or the example i made is totally wrong?","P(a)=0.6, P(b)=0.7 b c p(b \mid c) P(b)=0.7 P(a)=0.6 p(a) p(b) p(a)+p(b)>1",['probability']
61,Why does calculating probability of 2 pairs seem so different from for a full house?,Why does calculating probability of 2 pairs seem so different from for a full house?,,"For 5 card poker without discards/draws, the probability of being dealt a 2 pair hand is about 0.047539, and for a full house is about 0.001441. 1 I first learned about calculating for a 2 pair hand.  I incorrectly came up with: $${ {{13\choose 1}{4\choose 2}{12\choose 1}{4\choose 2}{44\choose 1}} \over{52\choose 5}}={{(13)(6)(12)(6)(44)}\over2598960}\approx0.095078$$ Notably, my answer is exactly double the correct answer. I learned that the correct way to calculate this is to choose the 2 ranks together that will be the pairs: $${ {{13\choose 2}{4\choose 2}{4\choose 2}{44\choose 1}} \over{52\choose 5}}={{(78)(6)(6)(44)}\over2598960}\approx0.047539$$ So, later, I moved on to calculating for a full house.  I proudly remembered to choose the ranks together and incorrectly came up with: $${ {{13\choose 2}{4\choose 3}{4\choose 2}} \over{52\choose 5}}={{(78)(4)(6)}\over2598960}\approx0.000720$$ I learned that the correct way to calculate this is to choose the 2 ranks separately: $${ {{13\choose 1}{4\choose 3}{12\choose 1}{4\choose 2}} \over{52\choose 5}}={{(13)(4)(12)(6)}\over2598960}\approx0.001441$$ Q1: For a 2 pair hand, why does choosing the ranks separately double count the possibilities?  Why must we choose the 2 ranks together (or divide by 2?) Q2: When we move onto a full house, why does this change?  Why does choosing the ranks together under count the possibilities?  Why must we choose the 2 ranks separately (or multiply by 2?) Q3: I'm having a surprisingly hard time grasping how to come up with these on my own.  Are there any tips or resources to help polish up these issues?","For 5 card poker without discards/draws, the probability of being dealt a 2 pair hand is about 0.047539, and for a full house is about 0.001441. 1 I first learned about calculating for a 2 pair hand.  I incorrectly came up with: Notably, my answer is exactly double the correct answer. I learned that the correct way to calculate this is to choose the 2 ranks together that will be the pairs: So, later, I moved on to calculating for a full house.  I proudly remembered to choose the ranks together and incorrectly came up with: I learned that the correct way to calculate this is to choose the 2 ranks separately: Q1: For a 2 pair hand, why does choosing the ranks separately double count the possibilities?  Why must we choose the 2 ranks together (or divide by 2?) Q2: When we move onto a full house, why does this change?  Why does choosing the ranks together under count the possibilities?  Why must we choose the 2 ranks separately (or multiply by 2?) Q3: I'm having a surprisingly hard time grasping how to come up with these on my own.  Are there any tips or resources to help polish up these issues?","{
{{13\choose 1}{4\choose 2}{12\choose 1}{4\choose 2}{44\choose 1}}
\over{52\choose 5}}={{(13)(6)(12)(6)(44)}\over2598960}\approx0.095078 {
{{13\choose 2}{4\choose 2}{4\choose 2}{44\choose 1}}
\over{52\choose 5}}={{(78)(6)(6)(44)}\over2598960}\approx0.047539 {
{{13\choose 2}{4\choose 3}{4\choose 2}}
\over{52\choose 5}}={{(78)(4)(6)}\over2598960}\approx0.000720 {
{{13\choose 1}{4\choose 3}{12\choose 1}{4\choose 2}}
\over{52\choose 5}}={{(13)(4)(12)(6)}\over2598960}\approx0.001441","['probability', 'combinatorics', 'discrete-mathematics', 'poker']"
62,What is the distribution of the number of boys standing between the leftmost girl and the rightmost girl?,What is the distribution of the number of boys standing between the leftmost girl and the rightmost girl?,,"$10$ Boys and $10$ Girls get ordered in a line.  How is $X$ , the number of boys standing between the leftmost girl and the rightmost girl, distributed? I tried thinking of selecting one place from the $20$ for the leftmost girl, and then selecting k places from the $19$ left for the boys. Or selecting one place from the $19$ left for the rightmost girl. I can't figure how to solve this. Any help is appreciated.","Boys and Girls get ordered in a line.  How is , the number of boys standing between the leftmost girl and the rightmost girl, distributed? I tried thinking of selecting one place from the for the leftmost girl, and then selecting k places from the left for the boys. Or selecting one place from the left for the rightmost girl. I can't figure how to solve this. Any help is appreciated.",10 10 X 20 19 19,"['probability', 'combinatorics', 'statistics', 'probability-distributions']"
63,Independence of diagnostic tests,Independence of diagnostic tests,,"A rare disease afflicts only $1\%$ of the population. Fred gets tested for it with two diagnostic tests. The sensitivity and specificity of the second test are both $0.95$ (so, its overall accuracy is $0.95$ ), and knowing that Fred has the disease makes the second test independent of the first. Let $D$ be the event that Fred has disease, $T_1$ be the event that his first result is positive and $T_2$ be the event that his second result is positive. I would like to know if I am interpreting each of the following correctly: $P(T_1 \cap T_2 | D)$ : Probability that the results are positive in both the tests given Fred has the disease. $P(T_1 \cap T_2)$ : Probability that the results are positive in both the tests taking into account both the cases - when Fred has the disease and when not. Does this mean that $P(T_1 \cap T_2) = P(T_1 \cap T_2 | D) P(D) + P(T_1 \cap T_2 | D^c) P(D^c)$ ? Is it true that $P(T_1 \cap T_2 | D) = P(T_1 | D) P(T_2 | D)$ ? Is it true that $P(T_1 \cap T_2) = P(T_1)P(T_2)$ ? My computations show that $(3)$ holds while $(4)$ does not, but I can't intuit why; an explanation using (conditional) independence would be helpful.","A rare disease afflicts only of the population. Fred gets tested for it with two diagnostic tests. The sensitivity and specificity of the second test are both (so, its overall accuracy is ), and knowing that Fred has the disease makes the second test independent of the first. Let be the event that Fred has disease, be the event that his first result is positive and be the event that his second result is positive. I would like to know if I am interpreting each of the following correctly: : Probability that the results are positive in both the tests given Fred has the disease. : Probability that the results are positive in both the tests taking into account both the cases - when Fred has the disease and when not. Does this mean that ? Is it true that ? Is it true that ? My computations show that holds while does not, but I can't intuit why; an explanation using (conditional) independence would be helpful.",1\% 0.95 0.95 D T_1 T_2 P(T_1 \cap T_2 | D) P(T_1 \cap T_2) P(T_1 \cap T_2) = P(T_1 \cap T_2 | D) P(D) + P(T_1 \cap T_2 | D^c) P(D^c) P(T_1 \cap T_2 | D) = P(T_1 | D) P(T_2 | D) P(T_1 \cap T_2) = P(T_1)P(T_2) (3) (4),"['probability', 'conditional-probability', 'independence']"
64,A question about martingale and Brownian motion,A question about martingale and Brownian motion,,"It is well known that the Brownian motion $B=(B_t)_{t\ge 0}$ is a martingale with respect to its natural filtration $\mathscr{F}_t$ and the fixed probability measure $\mathbb{P}$ , i.e. $$\mathbb{E}(B_t|\mathscr{F}_s)=B_s,\quad s\ge t$$ Now we limit the $t$ in the interval $[0,1]$ and enlarge the filtration with $\sigma(B_1)$ being added into each $\mathscr{F}_t$ , $t\in[0,1]$ , i.e. $$\tilde{\mathscr{F}_t}:=\sigma(\mathscr{F}_t \cup \sigma(B_1)) ,\quad t\in[0,1].$$ My question is how to calculte $\mathbb{E}(B_t|\tilde{\mathscr{F}}_s)$ $~$ for $~$ $0\le s\le t <1$ ? Someone says the result is $\mathbb{E}(B_t|\tilde{\mathscr{F}}_s)=\frac{1-t}{1-s}B_s + \frac{t-s}{1-s} B_1$ but I don't know why and cannot  verify it. I had been stuck by this question for two days long and had no idea. If you know how to solve it , please do not hesitate to help me. I am looking forward to your answers!","It is well known that the Brownian motion is a martingale with respect to its natural filtration and the fixed probability measure , i.e. Now we limit the in the interval and enlarge the filtration with being added into each , , i.e. My question is how to calculte for ? Someone says the result is but I don't know why and cannot  verify it. I had been stuck by this question for two days long and had no idea. If you know how to solve it , please do not hesitate to help me. I am looking forward to your answers!","B=(B_t)_{t\ge 0} \mathscr{F}_t \mathbb{P} \mathbb{E}(B_t|\mathscr{F}_s)=B_s,\quad s\ge t t [0,1] \sigma(B_1) \mathscr{F}_t t\in[0,1] \tilde{\mathscr{F}_t}:=\sigma(\mathscr{F}_t \cup \sigma(B_1)) ,\quad t\in[0,1]. \mathbb{E}(B_t|\tilde{\mathscr{F}}_s) ~ ~ 0\le s\le t <1 \mathbb{E}(B_t|\tilde{\mathscr{F}}_s)=\frac{1-t}{1-s}B_s + \frac{t-s}{1-s} B_1","['probability', 'brownian-motion', 'martingales']"
65,Convergence proof in probability,Convergence proof in probability,,"I would appreciate help with how to proceed to prove the following statement, I have some ideas on how to solve it but do not really get it all together and would appreciate any help/feedback that I can get! Let $X_1, X_2,...$ be random variables defined by the relations $$P(X_n=0)=1-\frac{1}{n}, \ \ P(X_n=1)=\frac{1}{2n}, \ \  P(X_n=-1)=\frac{1}{2n}, \ \ \ n \ge 1.$$ Show that $X_n \xrightarrow[]{p}0$ as $n \rightarrow \infty$ . This is my thoughts : First off, I'm sure we need to use the following definition: Def : $X_n$ converges in probability to the random variables X as $n \rightarrow \infty$ iff, for all $\epsilon >0$ : $P(|X_n-X|>\epsilon)\rightarrow 0 \text{ as } n\rightarrow \infty.$ Hence, we are goin to prove that $P(|X_n|>\epsilon)\rightarrow 0 $ as $n \rightarrow \infty$ . Then I noted that since we want the absolute value of $X_n$ and $P(X_n=1)=P(X_n=-1)$ we only have to apply the definition on $P(X_n=1)$ , is that right? If yes we get that: $$P(|X_n|>\epsilon)=\lim_{n\rightarrow \infty}\frac{1}{2n}=0, \ \ 0<\epsilon<1.$$ And then I noticed that the definition only applies for $\epsilon>0$ . And since our last relation, $P(X_n=0)$ have $X_n=0$ then $Xn>\epsilon$ cannot be achieved and we can exclude this relation. Here, however, I am very unsure if this is correct. This is as long as I have come so far. The problem is that even if the above is correct I still only have a proof for $0<\epsilon<1$ and not for all $\epsilon$ greater than zero as the definition says. How should i continue from here?","I would appreciate help with how to proceed to prove the following statement, I have some ideas on how to solve it but do not really get it all together and would appreciate any help/feedback that I can get! Let be random variables defined by the relations Show that as . This is my thoughts : First off, I'm sure we need to use the following definition: Def : converges in probability to the random variables X as iff, for all : Hence, we are goin to prove that as . Then I noted that since we want the absolute value of and we only have to apply the definition on , is that right? If yes we get that: And then I noticed that the definition only applies for . And since our last relation, have then cannot be achieved and we can exclude this relation. Here, however, I am very unsure if this is correct. This is as long as I have come so far. The problem is that even if the above is correct I still only have a proof for and not for all greater than zero as the definition says. How should i continue from here?","X_1, X_2,... P(X_n=0)=1-\frac{1}{n}, \ \ P(X_n=1)=\frac{1}{2n}, \ \  P(X_n=-1)=\frac{1}{2n}, \ \ \ n \ge 1. X_n \xrightarrow[]{p}0 n \rightarrow \infty X_n n \rightarrow \infty \epsilon >0 P(|X_n-X|>\epsilon)\rightarrow 0 \text{ as } n\rightarrow \infty. P(|X_n|>\epsilon)\rightarrow 0  n \rightarrow \infty X_n P(X_n=1)=P(X_n=-1) P(X_n=1) P(|X_n|>\epsilon)=\lim_{n\rightarrow \infty}\frac{1}{2n}=0, \ \ 0<\epsilon<1. \epsilon>0 P(X_n=0) X_n=0 Xn>\epsilon 0<\epsilon<1 \epsilon","['probability', 'convergence-divergence']"
66,"Probability that out of $n$ bags, at least one contains no black ball, if $n$ of $n^2$ balls are black","Probability that out of  bags, at least one contains no black ball, if  of  balls are black",n n n^2,"I am working on SL Parsonson's Pure Mathematics and I haven't been able to solve this problem: $n^2$ balls, of which $n$ are black and the rest white, are distributed at random into $n$ bags, so that each bag contains $n$ balls. Determine the probability that at least one bag contains no black ball. The answer given in the book is $1-\frac{(n-1)!(n^2-n)!n^{n-1}}{(n^2-1)!}$ . I thought I might start with the fact that there are $\frac{(n^2)!}{n!(n^2-n)!}$ unique arrangements of the balls, and $n-1$ partitions to be placed at intervals of n to divide them into $n$ bags, but I am stuck a little after here.","I am working on SL Parsonson's Pure Mathematics and I haven't been able to solve this problem: balls, of which are black and the rest white, are distributed at random into bags, so that each bag contains balls. Determine the probability that at least one bag contains no black ball. The answer given in the book is . I thought I might start with the fact that there are unique arrangements of the balls, and partitions to be placed at intervals of n to divide them into bags, but I am stuck a little after here.",n^2 n n n 1-\frac{(n-1)!(n^2-n)!n^{n-1}}{(n^2-1)!} \frac{(n^2)!}{n!(n^2-n)!} n-1 n,"['probability', 'combinatorics']"
67,Understanding $\lambda$ in the definition of Poisson distributions,Understanding  in the definition of Poisson distributions,\lambda,"I am trying to understand the meaning of $\lambda$ in Poisson distributions. I know that it is the average rate of occurrences of the event, but I have not been able to fully understand what that means. In ""A First Course in Probability"" by Sheldon Ross, the author says that a Poisson distribution may be used as an approximation for a binomial distribution with parameters $(n,p)$ when $n$ is large and $p$ is small enough so that $np$ is of moderate size. What does $np$ being of moderate size mean? What is considered as of moderate size? Why does $np$ have to be of moderate size? Why can a Poisson distribution not be used as an approximation for a binomial distribution if $np$ is too big or too small? Also, in other books, I read that a Poisson distribution is the limiting case of a binomial distribution when $\lambda=np$ is constant as $n\to\infty$ . Under what conditions, is $\lambda$ constant as $n\to\infty$ ? I am new to probability. If someone can provide the intuition behind Poisson distributions (specifically about $\lambda$ ), I would greatly appreciate it.","I am trying to understand the meaning of in Poisson distributions. I know that it is the average rate of occurrences of the event, but I have not been able to fully understand what that means. In ""A First Course in Probability"" by Sheldon Ross, the author says that a Poisson distribution may be used as an approximation for a binomial distribution with parameters when is large and is small enough so that is of moderate size. What does being of moderate size mean? What is considered as of moderate size? Why does have to be of moderate size? Why can a Poisson distribution not be used as an approximation for a binomial distribution if is too big or too small? Also, in other books, I read that a Poisson distribution is the limiting case of a binomial distribution when is constant as . Under what conditions, is constant as ? I am new to probability. If someone can provide the intuition behind Poisson distributions (specifically about ), I would greatly appreciate it.","\lambda (n,p) n p np np np np \lambda=np n\to\infty \lambda n\to\infty \lambda","['probability', 'probability-distributions', 'poisson-distribution', 'poisson-process']"
68,How do I show that a continuous function preserves a.s. convergence?,How do I show that a continuous function preserves a.s. convergence?,,"I have the following question: We have $(X_n)_{n},X$ a collection of real valued random variables which are defined in $(\Omega, F, \Bbb{P})$ . And $f:(\Bbb{R},B(\Bbb{R}))\rightarrow (\Bbb{R},B(\Bbb{R}))$ a continuous function. I need to show that if $X_n\rightarrow X$ a.s. then $f(X_n)\rightarrow f(X)$ a.s. So I mean if we assume $X_n\rightarrow X$ a.s. this means that there exists $N\in F$ s.t. $\Bbb{P}(N)=0$ and for all $\omega \in \Omega \setminus N$ $$X_n(\omega)\rightarrow X(\omega)$$ I thought maybe I can apply $f$ to $N$ but this confuses me a bit since $f$ is not neccessairly defined on $N$ . Then I thought one could do it by contraposition but also there I got stuck. Could maybe someone help me?",I have the following question: We have a collection of real valued random variables which are defined in . And a continuous function. I need to show that if a.s. then a.s. So I mean if we assume a.s. this means that there exists s.t. and for all I thought maybe I can apply to but this confuses me a bit since is not neccessairly defined on . Then I thought one could do it by contraposition but also there I got stuck. Could maybe someone help me?,"(X_n)_{n},X (\Omega, F, \Bbb{P}) f:(\Bbb{R},B(\Bbb{R}))\rightarrow (\Bbb{R},B(\Bbb{R})) X_n\rightarrow X f(X_n)\rightarrow f(X) X_n\rightarrow X N\in F \Bbb{P}(N)=0 \omega \in \Omega \setminus N X_n(\omega)\rightarrow X(\omega) f N f N","['probability', 'probability-theory', 'convergence-divergence', 'almost-everywhere']"
69,Flajolet & Sedgewick: How to compute the variance of the number of cycles in a random permutation?,Flajolet & Sedgewick: How to compute the variance of the number of cycles in a random permutation?,,"I am reading the book Analytic Combinatorics 4ed by Sedgewick and Flajolet. On page 160 at Example III.4 the authors derive the variance of the number of cycles in a random permutation. I can follow the authors up to the part where the write $$\sigma_n^2 = \biggl(\sum_{k=1}^n \frac{1}{k} \biggr) - \biggl(\sum_{k=1}^n \frac{1}{k^2} \biggr). $$ I do not understand how they arrive at that. If I understand the above part correctly the authors state that $\mathbb{E}_n[\chi] = H_n$ , where $H_n$ is the $n$ -th Harmonic Number, and $\mathbb{E}_n[\chi(\chi-1)] = \sum_{k=1}^n \frac{1}{k^2}$ . I think that it would now suffice to compute $$\mathbb{E}_n[\chi^2] - \mathbb{E}_n[\chi]^2$$ by somehow utilising the above. However, I do not understand how to do that. Could you please help me? Could you please explain this to me?","I am reading the book Analytic Combinatorics 4ed by Sedgewick and Flajolet. On page 160 at Example III.4 the authors derive the variance of the number of cycles in a random permutation. I can follow the authors up to the part where the write I do not understand how they arrive at that. If I understand the above part correctly the authors state that , where is the -th Harmonic Number, and . I think that it would now suffice to compute by somehow utilising the above. However, I do not understand how to do that. Could you please help me? Could you please explain this to me?",\sigma_n^2 = \biggl(\sum_{k=1}^n \frac{1}{k} \biggr) - \biggl(\sum_{k=1}^n \frac{1}{k^2} \biggr).  \mathbb{E}_n[\chi] = H_n H_n n \mathbb{E}_n[\chi(\chi-1)] = \sum_{k=1}^n \frac{1}{k^2} \mathbb{E}_n[\chi^2] - \mathbb{E}_n[\chi]^2,"['probability', 'combinatorics', 'permutations', 'variance', 'analytic-combinatorics']"
70,Derivation of E(X) for a geometric distribution,Derivation of E(X) for a geometric distribution,,"I'm having trouble following the derivation of the expected value for the geometric distribution. I've reached: $$\sum_{k=1}^{\infty}     p \cdot k(1-p)^{k-1} =      p(1 + 2(1-p) + 3(1-p)^2 + ...) $$ The next step rewrites $k$ as an infinite sum of ascending values, that is: $$=p( \sum_{k=1}^{\infty}\ (1-p)^{k-1} + \sum_{k=2}^{\infty}\ (1-p)^{k-1} + \sum_{k=3}^{\infty}\ (1-p)^{k-1} + ...)$$ Why exactly is it that we can represent $k$ as this infinite sum?","I'm having trouble following the derivation of the expected value for the geometric distribution. I've reached: The next step rewrites as an infinite sum of ascending values, that is: Why exactly is it that we can represent as this infinite sum?","\sum_{k=1}^{\infty}
    p \cdot k(1-p)^{k-1} = 
    p(1 + 2(1-p) + 3(1-p)^2 + ...)
 k =p( \sum_{k=1}^{\infty}\ (1-p)^{k-1} + \sum_{k=2}^{\infty}\ (1-p)^{k-1} + \sum_{k=3}^{\infty}\ (1-p)^{k-1} + ...) k","['probability', 'sequences-and-series', 'probability-distributions']"
71,"One red, one green and one blue ball in a box","One red, one green and one blue ball in a box",,"I asked myself a question about probabilities and got pretty confused about it. Let's say there is a box with 1 red ball, 1 green ball and 1 blue ball inside. I pick randomly a ball from the box, then put it back, and repeat the process two more times (so three times at all). So, from the first pick, my chance of picking the red ball is 1/3. And during the second picking, my chance of grabbing the ball is also 1/3. Same for the third time. But if I ask myself this next question : what is my total chance of picking one time the red ball during the three random picks combined ? And here I got confused. Shouldn't my chance of picking the red ball increase everytime I pick randomly one ball ? Let's say the first time is 1/3, then the second time should be 1/3 (from the first time) +1/3 (from the second time) = 2/3 ? And the third time 3/3 ? But if it's 3/3 it means that I have 100% chance to pick the ball after 3 times, which is not realistic in the real life : I could pick 3 times the green ball, or two times the green ball and one time the blue one, etc. I hope you will be able to explain this to me. Thank you!","I asked myself a question about probabilities and got pretty confused about it. Let's say there is a box with 1 red ball, 1 green ball and 1 blue ball inside. I pick randomly a ball from the box, then put it back, and repeat the process two more times (so three times at all). So, from the first pick, my chance of picking the red ball is 1/3. And during the second picking, my chance of grabbing the ball is also 1/3. Same for the third time. But if I ask myself this next question : what is my total chance of picking one time the red ball during the three random picks combined ? And here I got confused. Shouldn't my chance of picking the red ball increase everytime I pick randomly one ball ? Let's say the first time is 1/3, then the second time should be 1/3 (from the first time) +1/3 (from the second time) = 2/3 ? And the third time 3/3 ? But if it's 3/3 it means that I have 100% chance to pick the ball after 3 times, which is not realistic in the real life : I could pick 3 times the green ball, or two times the green ball and one time the blue one, etc. I hope you will be able to explain this to me. Thank you!",,['probability']
72,"Rolling a pair of six-sided dice, what is the probability that the larger number is at least 5?","Rolling a pair of six-sided dice, what is the probability that the larger number is at least 5?",,"You have two six-sided dice. What is the probability that the larger number rolled will be at LEAST 5? I have listed out all the possible rolls. You can set dice 2 equal to 5, and roll dice one. The possible rolls are (1,5), (2,5), (3,5), (4,5). Do the same thing, but this time dice 2 is set to 6. We have (1,6), (2,6), (3,6), (4,6), and (5,6). These 9 possible rolls can happen with setting the 1st dice to both 5 and 6 as well. Giving us a total of 18 possible rolls $$\therefore P=18/36$$ However, the answer I'm given states that $P=20/36$ . I'm having trouble understanding why.","You have two six-sided dice. What is the probability that the larger number rolled will be at LEAST 5? I have listed out all the possible rolls. You can set dice 2 equal to 5, and roll dice one. The possible rolls are (1,5), (2,5), (3,5), (4,5). Do the same thing, but this time dice 2 is set to 6. We have (1,6), (2,6), (3,6), (4,6), and (5,6). These 9 possible rolls can happen with setting the 1st dice to both 5 and 6 as well. Giving us a total of 18 possible rolls However, the answer I'm given states that . I'm having trouble understanding why.",\therefore P=18/36 P=20/36,['probability']
73,Why is my reasoning incorrect - probability?,Why is my reasoning incorrect - probability?,,"In a variant of Russian Roulette, where you put 2 bullets in 2 adjacent chambers, like that: Image credit: Brilliant.org Now, first person shoots and survives, you are the second. The question is: In which scenario are you more likely to survive: You spin the barrel again, assuming a random spin(each chamber has equal probability). Shot, without spinning. I have tried solving it like that: Even though I have gotten the correct result I was reasoning incorrectly I have calculated the probability of 1-st scenario and got 1/3(2 possible ways of killing, 6 barrels), this gives the chance of dying if spin. Then the probability of 2nd scenario, here I got the wrong result. P(dying in second scenario) = P(1st surviving)*P(you being hit) = $$ \frac{4}{6} * \frac25 = \frac4{15}$$ Which is approximately 0.27. Not to forget I have also thought that this answer gives the P(dying), but I need P(dying given 1st survived). So, I thought that I need to calculate how big is the chance of this specific outcome of 2nd dying if first survived. To do that I divided it by 2/3 - because that was the probability of the first one surviving. Also, I don't really know why we are dividing, probability by probability. But the correct answer is 0.25. Reasoning like that: There are 4 ways to get the specific result, and only 1 way this could happen.","In a variant of Russian Roulette, where you put 2 bullets in 2 adjacent chambers, like that: Image credit: Brilliant.org Now, first person shoots and survives, you are the second. The question is: In which scenario are you more likely to survive: You spin the barrel again, assuming a random spin(each chamber has equal probability). Shot, without spinning. I have tried solving it like that: Even though I have gotten the correct result I was reasoning incorrectly I have calculated the probability of 1-st scenario and got 1/3(2 possible ways of killing, 6 barrels), this gives the chance of dying if spin. Then the probability of 2nd scenario, here I got the wrong result. P(dying in second scenario) = P(1st surviving)*P(you being hit) = Which is approximately 0.27. Not to forget I have also thought that this answer gives the P(dying), but I need P(dying given 1st survived). So, I thought that I need to calculate how big is the chance of this specific outcome of 2nd dying if first survived. To do that I divided it by 2/3 - because that was the probability of the first one surviving. Also, I don't really know why we are dividing, probability by probability. But the correct answer is 0.25. Reasoning like that: There are 4 ways to get the specific result, and only 1 way this could happen.", \frac{4}{6} * \frac25 = \frac4{15},"['probability', 'probability-theory', 'problem-solving']"
74,Maximum likelihood estimator and asymptotic distribution,Maximum likelihood estimator and asymptotic distribution,,"Let $X_1,\dots,X_n$ be a random sample from X whose density is given by $$f(x,\theta) = c(\theta)(1-\exp(-|x|))I\{|x|\leq\theta\}$$ Find the maximun likelihood estimator of $\theta$ and show that $n(\hat{\theta}-\theta)$ converges in distribution to a gamma distribution. First we need to find $c(\theta)$ , it's clear that it's a normalization constant, so integrating the density we get that $c(\theta)= 1/2(\theta+e^{-\theta}-1)$ and we may show that \begin{align} \mathcal{L}(\theta;x) &= \prod_{i=1}^n c(\theta)(1-\exp(-|x_i|))I\{|x_i|\leq\theta\} \\  &=c^n(\theta)I_{(0,\theta)}\left(\frac{x_{(n)}-x_{(1)}}{2}\right) \prod_{i=1}^n (1-\exp(-|x_i|)) \\  &=c^n(\theta)I\left(\frac{x_{(n)}-x_{(1)}}{2},+\infty\right)(\theta) \prod_{i=1}^n (1-\exp(-|x_i|)) \end{align} and as $c(\theta)$ is a decreasing function of $\theta$ , we get that $$ \hat{\theta} =\frac{x_{(n)}-x_{(1)}}{2} $$ however I'm stuck at the convergence part, I tried manipulating the expression and applying the Jacobian method. Jacobian yields a quite difficult convolution. Other post shows something similar however the $X$ s are exponentially distributed and the results follow from the memoryless property.","Let be a random sample from X whose density is given by Find the maximun likelihood estimator of and show that converges in distribution to a gamma distribution. First we need to find , it's clear that it's a normalization constant, so integrating the density we get that and we may show that and as is a decreasing function of , we get that however I'm stuck at the convergence part, I tried manipulating the expression and applying the Jacobian method. Jacobian yields a quite difficult convolution. Other post shows something similar however the s are exponentially distributed and the results follow from the memoryless property.","X_1,\dots,X_n f(x,\theta) = c(\theta)(1-\exp(-|x|))I\{|x|\leq\theta\} \theta n(\hat{\theta}-\theta) c(\theta) c(\theta)= 1/2(\theta+e^{-\theta}-1) \begin{align}
\mathcal{L}(\theta;x) &= \prod_{i=1}^n c(\theta)(1-\exp(-|x_i|))I\{|x_i|\leq\theta\} \\
 &=c^n(\theta)I_{(0,\theta)}\left(\frac{x_{(n)}-x_{(1)}}{2}\right) \prod_{i=1}^n (1-\exp(-|x_i|)) \\
 &=c^n(\theta)I\left(\frac{x_{(n)}-x_{(1)}}{2},+\infty\right)(\theta) \prod_{i=1}^n (1-\exp(-|x_i|))
\end{align} c(\theta) \theta 
\hat{\theta} =\frac{x_{(n)}-x_{(1)}}{2}
 X","['probability', 'statistical-inference', 'maximum-likelihood', 'order-statistics']"
75,Ball drawn with replacement - with a twist. Is there an elegant solution I may be missing?,Ball drawn with replacement - with a twist. Is there an elegant solution I may be missing?,,"Here's the question : Suppose there's a bag filled with balls numbered one through fifty.  You reach in and grab three at random, put them to the side, and then replace the ones you took so that the bag is once again filled with fifty distinctly numbered balls.  Do this five times, so you have 5 groups of 3 numbered balls such that within each group every number is distinct from the other, but across groups, the numbers may not necessarily be distinct. What is the probability that you have some three-of-a-kind in your five groups?  That is to say, what is the probability that some number appears at least three times among the selected balls? Now I'm not very good at probability, but I'm pretty sure I know how I would brute-force calculate the probability of this situation, but it would take a ridiculously long time.  Does anyone know a particularly elegant method for solving something like this?  Also, more generally, are there problems of this sort that are fundamentally messy, which require long case-by-case calculations and there's no tidy and pleasing way to answer them? Hope my question makes sense, let me know if there is any clarification needed.  Cheers friends! Edit :  It appears I need to share more context and more of my own work so far.  Briefly, I came up with this question, it's not for a class, just my own curiosity.  It's actually related to character selection in the video game Heroes of the Storm, where each of five players is given a selection of three characters at random.  I was just trying to calculate some probabilities, like - What is the chance you get a particular character you want to play?  What is the chance the character you want to play appears somewhere among the five players?  What is the chance that some character appears twice or more among the five players?  Etc. For the latter question - What is the chance that some character appears twice or more - I managed a fairly straightforward solution that I hope is correct, here is my process: Characters are represented as the numbers 1-50.  Five groups are selected represented as ${(X_1, Y_1, Z_1), (X_2, Y_2, Z_2), ..., (X_5, Y_5, Z_5)}$ s.t $X_n \neq Y_n \neq Z_n$ Let's also call the character set $C_n = (X_n, Y_n, Z_n)$ The probability that some character appears twice or more is the same as 1 minus the probability that all characters are distinct.  So we want to find $ P(C_1, C_2, ..., C_5 $ are distinct $)  = P(C_1 $ is distinct $) * P(C_2 $ is distinct $ | C_1 $ is distinct $) * ... * P(C_5 $ is distinct $ | C_1, C_2, C_3, C_4 $ are distinct $) $ $X_1 \neq Y_1 \neq Z_1$ therefore $C_1$ is distinct always. $P(C_2$ is distict | $C_1$ is distinct) $= (\frac{47}{50})(\frac{46}{49})(\frac{45}{48}) $ since there are three choices that can no longer be taken if distinction is going to be preserved.  Since $X_2 \neq Y_2 \neq Z_2$ , the denominator must decrease by one each time. Similarly, $P(C_3$ is distinct | $C_1, C_2$ are distinct) $= (\frac{44}{50})(\frac{43}{49})(\frac{42}{48})$ $P(C_4$ is distinct | $C_1, C_2, C_3$ are distinct) $= (\frac{41}{50})(\frac{40}{49})(\frac{39}{48})$ $P(C_5$ is distinct | $C_1, C_2, C_3, C_4$ are distinct) $= (\frac{38}{50})(\frac{37}{49})(\frac{36}{48})$ The probability that every character is distinct is the product of all the above terms, so: $(\frac{50}{50})(\frac{49}{49})(\frac{48}{48})(\frac{47}{50})(\frac{46}{49})(\frac{45}{48})(\frac{44}{50})(\frac{43}{49})(\frac{42}{48})(\frac{41}{50})(\frac{40}{49})(\frac{39}{48})(\frac{38}{50})(\frac{37}{49})(\frac{36}{48})$ Or more succinctly, $\frac{50!}{35!*50^5*49^5*48^5} \approx 13.1\%$ It follows then that the probability of having one character appear at least twice would be approximately 86.9%.  I feel fairly confident in this answer but I'm always prone to think I'm right and then be miles off, so if someone sees a mistake in my reasoning (if it's even readable) let me know! I am having a hard time figuring out a solution to the more specific problem of - what is the probability of having one character appear at least three times?  I would approach it a similar way, but it seems to require ridiculous amounts of calculations that I don't really care to do, I'd just rather code a quick simulation to find the answer, haha.  I am interested in the mathematics of it though, and wonder if anyone has any advice on a more elegant way than brute-forcing every conditional case, I would love to hear it!  Hope this clears things up a bit.","Here's the question : Suppose there's a bag filled with balls numbered one through fifty.  You reach in and grab three at random, put them to the side, and then replace the ones you took so that the bag is once again filled with fifty distinctly numbered balls.  Do this five times, so you have 5 groups of 3 numbered balls such that within each group every number is distinct from the other, but across groups, the numbers may not necessarily be distinct. What is the probability that you have some three-of-a-kind in your five groups?  That is to say, what is the probability that some number appears at least three times among the selected balls? Now I'm not very good at probability, but I'm pretty sure I know how I would brute-force calculate the probability of this situation, but it would take a ridiculously long time.  Does anyone know a particularly elegant method for solving something like this?  Also, more generally, are there problems of this sort that are fundamentally messy, which require long case-by-case calculations and there's no tidy and pleasing way to answer them? Hope my question makes sense, let me know if there is any clarification needed.  Cheers friends! Edit :  It appears I need to share more context and more of my own work so far.  Briefly, I came up with this question, it's not for a class, just my own curiosity.  It's actually related to character selection in the video game Heroes of the Storm, where each of five players is given a selection of three characters at random.  I was just trying to calculate some probabilities, like - What is the chance you get a particular character you want to play?  What is the chance the character you want to play appears somewhere among the five players?  What is the chance that some character appears twice or more among the five players?  Etc. For the latter question - What is the chance that some character appears twice or more - I managed a fairly straightforward solution that I hope is correct, here is my process: Characters are represented as the numbers 1-50.  Five groups are selected represented as s.t Let's also call the character set The probability that some character appears twice or more is the same as 1 minus the probability that all characters are distinct.  So we want to find are distinct is distinct is distinct is distinct is distinct are distinct therefore is distinct always. is distict | is distinct) since there are three choices that can no longer be taken if distinction is going to be preserved.  Since , the denominator must decrease by one each time. Similarly, is distinct | are distinct) is distinct | are distinct) is distinct | are distinct) The probability that every character is distinct is the product of all the above terms, so: Or more succinctly, It follows then that the probability of having one character appear at least twice would be approximately 86.9%.  I feel fairly confident in this answer but I'm always prone to think I'm right and then be miles off, so if someone sees a mistake in my reasoning (if it's even readable) let me know! I am having a hard time figuring out a solution to the more specific problem of - what is the probability of having one character appear at least three times?  I would approach it a similar way, but it seems to require ridiculous amounts of calculations that I don't really care to do, I'd just rather code a quick simulation to find the answer, haha.  I am interested in the mathematics of it though, and wonder if anyone has any advice on a more elegant way than brute-forcing every conditional case, I would love to hear it!  Hope this clears things up a bit.","{(X_1, Y_1, Z_1), (X_2, Y_2, Z_2), ..., (X_5, Y_5, Z_5)} X_n \neq Y_n \neq Z_n C_n = (X_n, Y_n, Z_n)  P(C_1, C_2, ..., C_5  )  = P(C_1  ) * P(C_2   | C_1  ) * ... * P(C_5   | C_1, C_2, C_3, C_4  )  X_1 \neq Y_1 \neq Z_1 C_1 P(C_2 C_1 = (\frac{47}{50})(\frac{46}{49})(\frac{45}{48})  X_2 \neq Y_2 \neq Z_2 P(C_3 C_1, C_2 = (\frac{44}{50})(\frac{43}{49})(\frac{42}{48}) P(C_4 C_1, C_2, C_3 = (\frac{41}{50})(\frac{40}{49})(\frac{39}{48}) P(C_5 C_1, C_2, C_3, C_4 = (\frac{38}{50})(\frac{37}{49})(\frac{36}{48}) (\frac{50}{50})(\frac{49}{49})(\frac{48}{48})(\frac{47}{50})(\frac{46}{49})(\frac{45}{48})(\frac{44}{50})(\frac{43}{49})(\frac{42}{48})(\frac{41}{50})(\frac{40}{49})(\frac{39}{48})(\frac{38}{50})(\frac{37}{49})(\frac{36}{48}) \frac{50!}{35!*50^5*49^5*48^5} \approx 13.1\%",['probability']
76,Probability that randomly chosen points on a line segment each has distance > 1 with its adjacent point [closed],Probability that randomly chosen points on a line segment each has distance > 1 with its adjacent point [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Suppose we have chosen $n$ random points in a line segment $[0, t]$ , $n\leq t+1$ . What is the probability that distance between each pair of adjacent points is > 1? Or more formally, let $U_1, U_2, ..., U_n \stackrel{iid}{\sim} U(0,t), n\leq t+1$ , let $U_{(i)}$ denotes $i^{th}$ ordered statistic. Find $P(\cap_{i=1}^{n-1} U_{(i+1)} - U_{(i)} > 1)$ ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Suppose we have chosen random points in a line segment , . What is the probability that distance between each pair of adjacent points is > 1? Or more formally, let , let denotes ordered statistic. Find ?","n [0, t] n\leq t+1 U_1, U_2, ..., U_n \stackrel{iid}{\sim} U(0,t), n\leq t+1 U_{(i)} i^{th} P(\cap_{i=1}^{n-1} U_{(i+1)} - U_{(i)} > 1)","['probability', 'uniform-distribution']"
77,Expected number of throws required so every face of die shows up,Expected number of throws required so every face of die shows up,,"Here's a question from my probability textbook: A die is thrown until every face has turned up at least once. Show that on average $14{7\over{10}}$ throws will be required. The easy way to do this is $$1 + {1\over{5\over6}} + {1\over{4\over6}} + {1\over{3\over6}} + {1\over{2\over6}} + {1\over{1\over6}} = 14 {7\over{10}}.$$ However, this is the solution in the back of my book: If the die be thrown $n$ times the number of ways is $6^n$ . Among which ace will be missing in $5^n$ , ace and deuce in $4^n$ , and so on. Hence the number of ways in which no face will be missing is $$6^n - 6(5^n) + 15(4^n) - 20(3^n) + 15(2^n) - 6(1^n);$$ and the chance of this is $$1 - 6\left({5\over6}\right)^n + 15\left({4\over6}\right)^n - 20\left({3\over6}\right)^n + 15\left({2\over6}\right)^n - 6\left({1\over6}\right)^n;$$ or if $f_n$ be the chance of failing in $n$ throws to turn every face $$f_n = 6\left({5\over6}\right)^n - 15\left({4\over6}\right)^n + 20\left({3\over6}\right)^n - 15\left({2\over6}\right)^n + 6\left({1\over6}\right)^n.$$ (Note that this reduces to unity if $n = 1, 2, 3, 4, 5$ .) I completely follow the solution up to this point. But it's the next claim that I do not follow at all: Hence success will be attained on an average in $s$ trials where $$s = 1 + f_1 + f_2 + \ldots$$ Why is this claim true? I don't see it. Any help would be well-appreciated. For the record, if we assume that claim then I can complete the problem: $$s = 1 + f_1 + f_2 + \ldots = 1 + {{6\left({5\over6}\right)}\over{1 - {5\over6}}} - {{15\left({4\over6}\right)}\over{1 - {4\over6}}} + {{20\left({3\over6}\right)}\over{1 - {3\over6}}} - {{15\left({2\over6}\right)}\over{1 - {2\over6}}} + {{6\left({1\over6}\right)}\over{1 - {1\over6}}} = 1 + 30 - 30 + 20 - {{15}\over2} + {6\over5} = 14{7\over{10}},$$ as desired. So really, I have two questions: Why is the claim that success will be attained on an average in $1 + f_1 + f_2 + \ldots$ trials true (from what follows before in the chronological order of the solution, rather than that the calculation obviously happens to give the desired result)? Can someone walk me step by step with how the book came up with that? What's the precise relationship between the solution I found (the easy way) and the solution in the back of my book (the hard way)? How are they in essence the same at some level? Update: The bounty is about to expire, but nobody has given a clear answer to my satisfaction yet. I just want to understand what's going on, but all the comments and answers so far just muddy the waters further by overcomplicating without giving a clear explanation.","Here's a question from my probability textbook: A die is thrown until every face has turned up at least once. Show that on average throws will be required. The easy way to do this is However, this is the solution in the back of my book: If the die be thrown times the number of ways is . Among which ace will be missing in , ace and deuce in , and so on. Hence the number of ways in which no face will be missing is and the chance of this is or if be the chance of failing in throws to turn every face (Note that this reduces to unity if .) I completely follow the solution up to this point. But it's the next claim that I do not follow at all: Hence success will be attained on an average in trials where Why is this claim true? I don't see it. Any help would be well-appreciated. For the record, if we assume that claim then I can complete the problem: as desired. So really, I have two questions: Why is the claim that success will be attained on an average in trials true (from what follows before in the chronological order of the solution, rather than that the calculation obviously happens to give the desired result)? Can someone walk me step by step with how the book came up with that? What's the precise relationship between the solution I found (the easy way) and the solution in the back of my book (the hard way)? How are they in essence the same at some level? Update: The bounty is about to expire, but nobody has given a clear answer to my satisfaction yet. I just want to understand what's going on, but all the comments and answers so far just muddy the waters further by overcomplicating without giving a clear explanation.","14{7\over{10}} 1 + {1\over{5\over6}} + {1\over{4\over6}} + {1\over{3\over6}} + {1\over{2\over6}} + {1\over{1\over6}} = 14 {7\over{10}}. n 6^n 5^n 4^n 6^n - 6(5^n) + 15(4^n) - 20(3^n) + 15(2^n) - 6(1^n); 1 - 6\left({5\over6}\right)^n + 15\left({4\over6}\right)^n - 20\left({3\over6}\right)^n + 15\left({2\over6}\right)^n - 6\left({1\over6}\right)^n; f_n n f_n = 6\left({5\over6}\right)^n - 15\left({4\over6}\right)^n + 20\left({3\over6}\right)^n - 15\left({2\over6}\right)^n + 6\left({1\over6}\right)^n. n = 1, 2, 3, 4, 5 s s = 1 + f_1 + f_2 + \ldots s = 1 + f_1 + f_2 + \ldots = 1 + {{6\left({5\over6}\right)}\over{1 - {5\over6}}} - {{15\left({4\over6}\right)}\over{1 - {4\over6}}} + {{20\left({3\over6}\right)}\over{1 - {3\over6}}} - {{15\left({2\over6}\right)}\over{1 - {2\over6}}} + {{6\left({1\over6}\right)}\over{1 - {1\over6}}} = 1 + 30 - 30 + 20 - {{15}\over2} + {6\over5} = 14{7\over{10}}, 1 + f_1 + f_2 + \ldots","['probability', 'combinatorics', 'expected-value', 'coupon-collector']"
78,What is the probability that the sum of six rolls of a fair die is divisible by $7$?,What is the probability that the sum of six rolls of a fair die is divisible by ?,7,"$$P(E)=\frac{\text{Favourable outcomes}}{\text{Total outcomes}}$$ Total outcomes $=6^6$ Favourable outcomes means the sum must be $7$ , $14$ , $21,28$ or $35$ Assume $a_1$ , $a_2$ , $a_3$ , $a_4$ , $a_5$ , $a_6$ to be the numbers on the top faces of the dice In case of $7$ and $35$ the number of cases should be $6$ as $0<a_i<7$ . When the sum is $14$ , favourable outcomes are: $${14 \choose 6}-6\left({7 \choose5}+{6 \choose 5}+1\right).$$ I tried this by a variation of beggars method. Let's assume there are $14$ coins, and $6$ beggars. There are $14$ places for the beggars to choose, such that there are $13$ places between two coins and one to the left of the first coin. Each beggar gets all the coins between himself and the beggar just to the right of him. This way we ensure that each beggar at least gets one coin. After this I subtracted the number of cases where one beggar gets more than one coin. Now this is solvable up to this point, but I'm getting a very large equation when I do this for $21$ and $28$ . Is there a better method, since I will most probably only have $5$ min in the upcoming exam on $3^d$ October.","Total outcomes Favourable outcomes means the sum must be , , or Assume , , , , , to be the numbers on the top faces of the dice In case of and the number of cases should be as . When the sum is , favourable outcomes are: I tried this by a variation of beggars method. Let's assume there are coins, and beggars. There are places for the beggars to choose, such that there are places between two coins and one to the left of the first coin. Each beggar gets all the coins between himself and the beggar just to the right of him. This way we ensure that each beggar at least gets one coin. After this I subtracted the number of cases where one beggar gets more than one coin. Now this is solvable up to this point, but I'm getting a very large equation when I do this for and . Is there a better method, since I will most probably only have min in the upcoming exam on October.","P(E)=\frac{\text{Favourable outcomes}}{\text{Total outcomes}} =6^6 7 14 21,28 35 a_1 a_2 a_3 a_4 a_5 a_6 7 35 6 0<a_i<7 14 {14 \choose 6}-6\left({7 \choose5}+{6 \choose 5}+1\right). 14 6 14 13 21 28 5 3^d","['probability', 'combinatorics']"
79,What is the probability of picking a full set from multiset after $m$ draws?,What is the probability of picking a full set from multiset after  draws?,m,"Suppose a bag contains $n$ balls labeled from $1$ to $n$ , and suppose I have $k$ of these bags. If I open all of these $k$ bags into an urn, then the urn is effectively a multiset with $kn$ elements: $k$ balls labeled $1$ , $k$ balls labeled $2$ , and so on up to $n$ . My question is If I were to randomly pick out balls from the urn one by one without replacement, what's the probability of having picked out a complete set of balls labeled $1$ to $n$ after $m$ balls have been pulled out of the urn? I'm not very familiar with probability, so I'm not sure what's the correct setup for the problem. I suspect the answer has to do with the binomial coefficients, as we're choosing $m$ elements from a set with $kn$ things, but I don't know how to account for the repetition of elements. Any and all help is greatly appreciated. Thank you!","Suppose a bag contains balls labeled from to , and suppose I have of these bags. If I open all of these bags into an urn, then the urn is effectively a multiset with elements: balls labeled , balls labeled , and so on up to . My question is If I were to randomly pick out balls from the urn one by one without replacement, what's the probability of having picked out a complete set of balls labeled to after balls have been pulled out of the urn? I'm not very familiar with probability, so I'm not sure what's the correct setup for the problem. I suspect the answer has to do with the binomial coefficients, as we're choosing elements from a set with things, but I don't know how to account for the repetition of elements. Any and all help is greatly appreciated. Thank you!",n 1 n k k kn k 1 k 2 n 1 n m m kn,"['probability', 'combinatorics', 'probability-theory', 'binomial-coefficients', 'recreational-mathematics']"
80,Determining probability of 'thirteen orphans' hand in riichi mahjong,Determining probability of 'thirteen orphans' hand in riichi mahjong,,"For anyone not familiar with how riichi mahjong is played, it uses 34 unique tiles with 4 duplicates of each tile, adding up to 136 in total. There are numbers 1 to 9 in 3 different suits, as well as two types of special honor tiles: winds, which have 4 unique tiles - east, west, south and north, and dragons, which have 3 unique tiles - red, green, and white dragon. This is what they look like: Players discard and draw from this deck and try to build their hand which contains 13 tiles along with 1 tile they have drawn. Can one determine the likelihood of getting a mahjong hand mathematically without using programs to simulate the hands? For instance, such as the thirteen orphans: Discarding and other players can be ignored, I just want to know the the likelihood of it happening from just drawing tiles from the deck. The criteria are as follows: The hand must contain a 1 and a 9 from all 3 numbered suits All four wind tiles All three dragon tiles One duplicate of any wind or dragon tile to complete the hand Calculating the odds of something like the nine gates is fairly straightforward as there is only one suit to choose from which leaves us with something like $\frac{{4 \choose n_1} . . . {4 \choose n_9}}{34 \choose 13}$ where $n_j$ is the amount of duplicates of a tile and $j$ is the number of the number of the tile ( $n_1$ for the first tile, all the way up to $n_9$ ). However, I cannot figure out what to do when honor tiles get involved.","For anyone not familiar with how riichi mahjong is played, it uses 34 unique tiles with 4 duplicates of each tile, adding up to 136 in total. There are numbers 1 to 9 in 3 different suits, as well as two types of special honor tiles: winds, which have 4 unique tiles - east, west, south and north, and dragons, which have 3 unique tiles - red, green, and white dragon. This is what they look like: Players discard and draw from this deck and try to build their hand which contains 13 tiles along with 1 tile they have drawn. Can one determine the likelihood of getting a mahjong hand mathematically without using programs to simulate the hands? For instance, such as the thirteen orphans: Discarding and other players can be ignored, I just want to know the the likelihood of it happening from just drawing tiles from the deck. The criteria are as follows: The hand must contain a 1 and a 9 from all 3 numbered suits All four wind tiles All three dragon tiles One duplicate of any wind or dragon tile to complete the hand Calculating the odds of something like the nine gates is fairly straightforward as there is only one suit to choose from which leaves us with something like where is the amount of duplicates of a tile and is the number of the number of the tile ( for the first tile, all the way up to ). However, I cannot figure out what to do when honor tiles get involved.",\frac{{4 \choose n_1} . . . {4 \choose n_9}}{34 \choose 13} n_j j n_1 n_9,"['probability', 'combinatorics', 'permutations', 'game-theory', 'combinatorial-game-theory']"
81,Does the probability of team A winning a series of seven games depend on whether team A plays until they win the four games needed or all seven?,Does the probability of team A winning a series of seven games depend on whether team A plays until they win the four games needed or all seven?,,"In the World Series of baseball, two teams (call them A and B) play a sequence of games against each other, and the first team to win four games wins the series. Let p be the probability that A wins an individual game, and assume that the games are independent. (a) What is the probability that team A wins the series? (b) Give a clear intuitive explanation of whether the answer to (a) depends on whether the teams always play 7 games (and whoever wins the majority wins the series), or the teams stop playing more games as soon as one team has won 4 games (as is actually the case in practice: once the match is decided, the two teams do not keep playing more games). I fully understand part (a); below is my solution. (a) $$P(\text{A wins}) = P(\text{A winning in 4 games}) + P(\text{A winning in 5 games}) +P(\text{A wins in 6 games}) $$ $$ + P(\text{A winning in 7 games}) = p^4 + \binom{4}{3}p^3qp + \binom{5}{3}p^3q^2p  + \binom{6}{3}p^3q^3p$$ Another solution: Let $X \sim Bin(7,p)$ and $q=1-p$ . \begin{align*}     P(\text{A wins}) &= P(X=4) + P(X=5) + P(X=6)+P(X=7) \\     &= \binom{7}{4}p^4q^3 + \binom{7}{5}p^5q^2+ \binom{7}{6}p^6q + p^7 \end{align*} However, I am quite confused on part (b). I know the two solutions above give the same answer, but I'm not sure why this works. Here is the solution provided by the professor, but I don't totally follow. ""Intuitively, the answer to (a) does not depend on whether the teams play all seven games no matter what. Imagine telling the players to continue playing the games even after the match has been decided, just for fun: the outcome of the match won’t be affected by this, and this also means that the probability that A wins the match won’t be affected by assuming that the teams always play 7 games!"" I know there's a question on this already, but it didn't provide an intuitive explanation.","In the World Series of baseball, two teams (call them A and B) play a sequence of games against each other, and the first team to win four games wins the series. Let p be the probability that A wins an individual game, and assume that the games are independent. (a) What is the probability that team A wins the series? (b) Give a clear intuitive explanation of whether the answer to (a) depends on whether the teams always play 7 games (and whoever wins the majority wins the series), or the teams stop playing more games as soon as one team has won 4 games (as is actually the case in practice: once the match is decided, the two teams do not keep playing more games). I fully understand part (a); below is my solution. (a) Another solution: Let and . However, I am quite confused on part (b). I know the two solutions above give the same answer, but I'm not sure why this works. Here is the solution provided by the professor, but I don't totally follow. ""Intuitively, the answer to (a) does not depend on whether the teams play all seven games no matter what. Imagine telling the players to continue playing the games even after the match has been decided, just for fun: the outcome of the match won’t be affected by this, and this also means that the probability that A wins the match won’t be affected by assuming that the teams always play 7 games!"" I know there's a question on this already, but it didn't provide an intuitive explanation.","P(\text{A wins}) = P(\text{A winning in 4 games}) + P(\text{A winning in 5 games}) +P(\text{A wins in 6 games})   + P(\text{A winning in 7 games}) = p^4 + \binom{4}{3}p^3qp + \binom{5}{3}p^3q^2p  + \binom{6}{3}p^3q^3p X \sim Bin(7,p) q=1-p \begin{align*}
    P(\text{A wins}) &= P(X=4) + P(X=5) + P(X=6)+P(X=7) \\
    &= \binom{7}{4}p^4q^3 + \binom{7}{5}p^5q^2+ \binom{7}{6}p^6q + p^7
\end{align*}",['probability']
82,The frog puzzle: simple probability isn't so simple; intuition and generalization,The frog puzzle: simple probability isn't so simple; intuition and generalization,,"There have been numerous discussions of the frog puzzle. Below is a puzzle followed by some solutions: ""You're poisoned in the jungle and the only way to save yourself is to lick a special kind of frog. To make matters worse, only the female of that species will do. Licking the male frog doesn't do anything. The male and female frogs look identical and appear with equal probabilities. The only difference is that the male frogs sometimes emit a distinctive croak. You spot a frog in front of you, but then you hear a croaking sound behind you. You turn around and spot two frogs there. There's only time to run to one side. Which way should you run?"" (1) The original solution to the puzzle gives the probability 2/3 of survival if you run to two frogs, which is wrong. The original solution assumes that the problem is equivalent to finding a female in a reduced sample space $MM$ $MF$ $FM$ and doesn't take into account the fact that you heard a croaking. (2) Another solution is that since you hear a croaking, you may represent a male frog as $M_c$ if it croaked and $M_n$ if it didn't croak, so the new sample space is $M_cM_n$ $M_nM_c$ $FM_c$ $M_cF$ , which gives a 1/2 probability that there is a female among the two frogs. (3) The correct solution (I believe) is that if the probability that a male frog croaks during a short time interval that you were listening for croaks is $p$ , then the probability that there is a female among the two frogs is $$ \begin{align*} &P(FM\mbox{ or }MF | \mbox{one croak})\\ &=\frac{P(\mbox{one croak}|FM\mbox{ or }MF) P(FM\mbox{ or }MF)}{ P(\mbox{one croak}|FM) P(FM) +  P(\mbox{one croak}|MF) P(MF) + P(\mbox{one croak}|MM)P(MM)}\\ &=\frac{p\cdot0.5}{0.25p+0.25p+0.25p(1-p) + 0.25(1-p)p}\\ &=\frac1{2-p} \end{align*} $$ Here we're using Bayes' Theorem . If we look at the single frog that didn't croak, the probability that it is female is $$ \frac{ P(F)}{ P(M_n) + P(F)} = \frac{0.5}{0.5+0.5(1-p)} = \frac1{2-p} $$ So it doesn't matter which direction you run! Does anyone have a good intuition as to why it doesn't matter which way you run? Does there exist an intuitive way to arrive at the answer in a general case: "" There are $n$ frogs and $m$ of them croak. What is the probability that one of the frogs is female? "" If $m=0$ , we can use the Binomial Theorem to get $$ 1-\frac{(1-p)^n}{{n\choose0} + {n\choose1}(1-p) + {n\choose2}(1-p)^2+\ldots + {n\choose n}(1-p)^n} = 1-\left(\frac{1-p}{2-p}\right)^n $$ I suspect that the answer to the general case is $\displaystyle 1-\left(\frac{1-p}{2-p}\right)^{n-m}$ because we can just ""ignore"" the croaking frogs. I'm looking for a good intuitive explanation as to why that's true (if it is true, of course). A further generalization would be skewing the probability of a male vs. female frog. Let's say that the probability that any given frog is male is $x$ . Then the above formula for the case $m=0$ becomes $$ 1-\frac{x^n(1-p)^n}{{n\choose0}(1-x)^n + {n\choose1}(1-x)^{n-1}x(1-p) + {n\choose2}(1-x)^{n-2}x^2(1-p)^2+\ldots + {n\choose n}x^n(1+p)^n} = 1-\left(\frac{x(1-p)}{1-xp}\right)^n $$ Is there a good answer for this more general case with $n$ frogs, $m$ of which are croaking?","There have been numerous discussions of the frog puzzle. Below is a puzzle followed by some solutions: ""You're poisoned in the jungle and the only way to save yourself is to lick a special kind of frog. To make matters worse, only the female of that species will do. Licking the male frog doesn't do anything. The male and female frogs look identical and appear with equal probabilities. The only difference is that the male frogs sometimes emit a distinctive croak. You spot a frog in front of you, but then you hear a croaking sound behind you. You turn around and spot two frogs there. There's only time to run to one side. Which way should you run?"" (1) The original solution to the puzzle gives the probability 2/3 of survival if you run to two frogs, which is wrong. The original solution assumes that the problem is equivalent to finding a female in a reduced sample space and doesn't take into account the fact that you heard a croaking. (2) Another solution is that since you hear a croaking, you may represent a male frog as if it croaked and if it didn't croak, so the new sample space is , which gives a 1/2 probability that there is a female among the two frogs. (3) The correct solution (I believe) is that if the probability that a male frog croaks during a short time interval that you were listening for croaks is , then the probability that there is a female among the two frogs is Here we're using Bayes' Theorem . If we look at the single frog that didn't croak, the probability that it is female is So it doesn't matter which direction you run! Does anyone have a good intuition as to why it doesn't matter which way you run? Does there exist an intuitive way to arrive at the answer in a general case: "" There are frogs and of them croak. What is the probability that one of the frogs is female? "" If , we can use the Binomial Theorem to get I suspect that the answer to the general case is because we can just ""ignore"" the croaking frogs. I'm looking for a good intuitive explanation as to why that's true (if it is true, of course). A further generalization would be skewing the probability of a male vs. female frog. Let's say that the probability that any given frog is male is . Then the above formula for the case becomes Is there a good answer for this more general case with frogs, of which are croaking?","MM MF FM M_c M_n M_cM_n M_nM_c FM_c M_cF p 
\begin{align*}
&P(FM\mbox{ or }MF | \mbox{one croak})\\
&=\frac{P(\mbox{one croak}|FM\mbox{ or }MF) P(FM\mbox{ or }MF)}{ P(\mbox{one croak}|FM) P(FM) +  P(\mbox{one croak}|MF) P(MF) + P(\mbox{one croak}|MM)P(MM)}\\
&=\frac{p\cdot0.5}{0.25p+0.25p+0.25p(1-p) + 0.25(1-p)p}\\
&=\frac1{2-p}
\end{align*}
 
\frac{ P(F)}{ P(M_n) + P(F)} = \frac{0.5}{0.5+0.5(1-p)} = \frac1{2-p}
 n m m=0 
1-\frac{(1-p)^n}{{n\choose0} + {n\choose1}(1-p) + {n\choose2}(1-p)^2+\ldots + {n\choose n}(1-p)^n}
= 1-\left(\frac{1-p}{2-p}\right)^n
 \displaystyle 1-\left(\frac{1-p}{2-p}\right)^{n-m} x m=0 
1-\frac{x^n(1-p)^n}{{n\choose0}(1-x)^n + {n\choose1}(1-x)^{n-1}x(1-p) + {n\choose2}(1-x)^{n-2}x^2(1-p)^2+\ldots + {n\choose n}x^n(1+p)^n}
= 1-\left(\frac{x(1-p)}{1-xp}\right)^n
 n m","['probability', 'conditional-probability']"
83,Taking infinite-width limit on multilayer perceptrons can simplify Taylor expansion,Taking infinite-width limit on multilayer perceptrons can simplify Taylor expansion,,"Settings When we apply Taylor expansion to a trained network function $f(x; \theta^*)$ around the initialized value of the parameters $\theta$ . Suppose $\theta$ and the derivatives $f(x;\theta)$ are both scalar, we obtain $$ f(x;\theta^{*}) = f(x;\theta) + (\theta^{*}-\theta) \frac{df}{d\theta}+\frac{1}{2}(\theta^{*}-\theta)^2\frac{d^2f}{d\theta^2} $$ Now consider a neural network architecture that has a width of $n$ , and a fixed depth of $L$ . According to The Principles of Deep Learning Theory (PDLT) (p.7) , if we take the limit, a.k.a the infinite-width limit, on an idealized network, $$ \lim_{n\rightarrow \infty} p(f^{*}) $$ we can simplify the distribution over trained networks $p(f^{*})$ . Without giving any proof, the book gives two claims: Claim 1 All the higher derivative terms $\frac{d^kf}{d\theta^k}$ for $k \geq 2$ will effectively vanish, meaning we only need to keep track of two terms, $$ f, \frac{df}{d\theta} $$ Claim 2 The distributions of these random functions will be independent $$ \lim_{n\rightarrow \infty} p \left( f,\frac{df}{d\theta},\frac{d^2f}{d\theta^2}, \ldots \right) =p(f)p \left( \frac{df}{d\theta} \right) $$ Would someone explain the above claims?","Settings When we apply Taylor expansion to a trained network function around the initialized value of the parameters . Suppose and the derivatives are both scalar, we obtain Now consider a neural network architecture that has a width of , and a fixed depth of . According to The Principles of Deep Learning Theory (PDLT) (p.7) , if we take the limit, a.k.a the infinite-width limit, on an idealized network, we can simplify the distribution over trained networks . Without giving any proof, the book gives two claims: Claim 1 All the higher derivative terms for will effectively vanish, meaning we only need to keep track of two terms, Claim 2 The distributions of these random functions will be independent Would someone explain the above claims?","f(x; \theta^*) \theta \theta f(x;\theta) 
f(x;\theta^{*}) = f(x;\theta) + (\theta^{*}-\theta) \frac{df}{d\theta}+\frac{1}{2}(\theta^{*}-\theta)^2\frac{d^2f}{d\theta^2}
 n L 
\lim_{n\rightarrow \infty} p(f^{*})
 p(f^{*}) \frac{d^kf}{d\theta^k} k \geq 2 
f, \frac{df}{d\theta}
 
\lim_{n\rightarrow \infty} p \left( f,\frac{df}{d\theta},\frac{d^2f}{d\theta^2}, \ldots \right) =p(f)p \left( \frac{df}{d\theta} \right)
","['probability', 'taylor-expansion', 'machine-learning', 'neural-networks']"
84,Statistical Brain Teaser - Randomized speed dating,Statistical Brain Teaser - Randomized speed dating,,"You and 25 strangers are in a room for 25 rounds of ""speed dating."" Each round, you are randomly paired with another person, regardless of whether you have seen them before or not. What is the probability that after 25 rounds, you have talked to only 1 person? 2 people? All 25 people? The probability of talking to only 1 person is $\left(\frac{1}{25}\right)^{25} * {25 \choose 1} $ , but after 2 people is where I get lost. Running a simulation, I get about a $25\%$ chance of having talked to exactly 15 people. How do I get to this mathematically? I thought it might be $$ \left(\frac{1}{25}\right)^{25} * (25 * 24 * 23 *...*15)  * {25 \choose 15} ,$$ however it does not get me anywhere close to $25\%$ .","You and 25 strangers are in a room for 25 rounds of ""speed dating."" Each round, you are randomly paired with another person, regardless of whether you have seen them before or not. What is the probability that after 25 rounds, you have talked to only 1 person? 2 people? All 25 people? The probability of talking to only 1 person is , but after 2 people is where I get lost. Running a simulation, I get about a chance of having talked to exactly 15 people. How do I get to this mathematically? I thought it might be however it does not get me anywhere close to .","\left(\frac{1}{25}\right)^{25} * {25 \choose 1}  25\%  \left(\frac{1}{25}\right)^{25} * (25 * 24 * 23 *...*15)  * {25 \choose 15} , 25\%","['probability', 'combinatorics', 'statistics']"
85,Moment generating function of continuous random variable,Moment generating function of continuous random variable,,"I got a problem that said ""find the Moment-generating function of $$f(t)=\frac{1}{4}e^{-t/4}\mathbb{I}_{(0,\infty)}(t)$$ And I solved it like this but I don't know if this' right $$\begin{align*}&M_{T}(y)=E\left [ e^{yt} \right ]\\&=\int_{0}^{\infty}e^{yt}\frac{1}{4}e^{-t/4}\,dt\\&=\frac{1}{4}\int_{0}^{\infty}e^{yt-t/4}\,dt \end{align*}$$ so $\lim_{t\rightarrow \infty}\frac{1}{4}\int_0^\infty e^{yt-t/4} \,dt$ Let $u=yt-\frac{t}{4}\Rightarrow du=(y-\frac{1}{4})dt \Rightarrow \frac{1}{y-\frac{1}{4}}\, du=dt$ $$\begin{align*}&\lim_{t\rightarrow \infty}\frac{1}{4}\int_0^{yt-\frac{t}{4}} e^u \frac{1}{y-\frac{1}{4}} \, du\\&=\lim_{t\rightarrow \infty}\frac{1}{4(y-\frac{1}{4})} \int_0^{yt-\frac{t}{4}} e^u \, du\\&=\lim_{t\rightarrow \infty}\frac{e^{yt-\frac{t}{4}}-1}{4y-1} \end{align*}$$ So $M_T(y)=\lim_{t\rightarrow \infty}\frac{e^{yt-\frac{t}{4}}-1}{4y-1}$","I got a problem that said ""find the Moment-generating function of And I solved it like this but I don't know if this' right so Let So","f(t)=\frac{1}{4}e^{-t/4}\mathbb{I}_{(0,\infty)}(t) \begin{align*}&M_{T}(y)=E\left [ e^{yt} \right ]\\&=\int_{0}^{\infty}e^{yt}\frac{1}{4}e^{-t/4}\,dt\\&=\frac{1}{4}\int_{0}^{\infty}e^{yt-t/4}\,dt \end{align*} \lim_{t\rightarrow \infty}\frac{1}{4}\int_0^\infty e^{yt-t/4} \,dt u=yt-\frac{t}{4}\Rightarrow du=(y-\frac{1}{4})dt \Rightarrow \frac{1}{y-\frac{1}{4}}\, du=dt \begin{align*}&\lim_{t\rightarrow \infty}\frac{1}{4}\int_0^{yt-\frac{t}{4}} e^u \frac{1}{y-\frac{1}{4}} \, du\\&=\lim_{t\rightarrow \infty}\frac{1}{4(y-\frac{1}{4})} \int_0^{yt-\frac{t}{4}} e^u \, du\\&=\lim_{t\rightarrow \infty}\frac{e^{yt-\frac{t}{4}}-1}{4y-1} \end{align*} M_T(y)=\lim_{t\rightarrow \infty}\frac{e^{yt-\frac{t}{4}}-1}{4y-1}","['probability', 'limits', 'random-variables', 'moment-generating-functions']"
86,The day I finally get the second sunny day I leave. What is the probability that I stayed exactly one week?,The day I finally get the second sunny day I leave. What is the probability that I stayed exactly one week?,,"Each day in Iceland, it rains with a probability p=0.8. Denote X the number of days I stay until I've had 2 sunny days in my holidays. What is the p.m.f. of X? The day I finally get the second sunny day I leave. What is the probability that I stayed exactly one week? My Attempt I know I can model this if it was only one sunny day, but I'm not sure how to do it if it were two. For one sunny day, I can model this as a geometric distribution, which is: $X\sim Geom(p)$ where $p=0.8$ . So I need to find the probability of staying for $7$ days: $$\mathbb{P}(X=k)=(1-p)^{k-1}p=(1-0.2)^{7-1}\cdot 0.2$$ But how would I compute it if I wanted to see two sunny days?","Each day in Iceland, it rains with a probability p=0.8. Denote X the number of days I stay until I've had 2 sunny days in my holidays. What is the p.m.f. of X? The day I finally get the second sunny day I leave. What is the probability that I stayed exactly one week? My Attempt I know I can model this if it was only one sunny day, but I'm not sure how to do it if it were two. For one sunny day, I can model this as a geometric distribution, which is: where . So I need to find the probability of staying for days: But how would I compute it if I wanted to see two sunny days?",X\sim Geom(p) p=0.8 7 \mathbb{P}(X=k)=(1-p)^{k-1}p=(1-0.2)^{7-1}\cdot 0.2,['probability']
87,A coin is tossed $10$ times. Find the probability that there exist $7$ consecutive coin tosses with at least $5$ out of the $7$ being heads.,A coin is tossed  times. Find the probability that there exist  consecutive coin tosses with at least  out of the  being heads.,10 7 5 7,"A coin is tossed $10$ times. Find the probability that there exist $7$ consecutive coin tosses with at least $5$ out of the $7$ being heads. So for example, $TTHHTHHTHH$ is one of the outcomes we want. I guess the best way to treat this is as a counting problem; finding the number of outcomes we want and then dividing by $2^{10}.$ $2^{10} = 1024,$ so listing all the outcomes is time-wise expensive. The events, ""The first consecutive $7$ tosses contain at least $5$ heads"", ""The second consecutive $7$ tosses contain at least $5$ heads"", etc. are not mutually exclusive and so the answer is not simply: $P$ (The first consecutive $7$ tosses contain at least $5$ heads) + $P$ (The second consecutive $7$ tosses contain at least $5$ heads) + ... . Similarly, the events, ""The first consecutive $7$ tosses does not contain at least $5$ heads"", ""The second consecutive $7$ tosses does not contain at least $5$ heads"", etc. are also not mutually exclusive and so the answer is not simply: $1 - $ $[P$ (The first consecutive $7$ tosses does not contain at least $5$ heads) + $P$ (The second consecutive $7$ tosses does not contain at least $5$ heads) + ... $]$ . Edit: What about reflecting the $10$ boxes down the middle? This could cut our work in half maybe? For example, $HTTHHTHTHH \equiv HHTHTHHTTH$ . Perhaps figuring out the symmetries is expensive too. I'm also interested in doing a similar problem with larger numbers, e.g.: A coin is tossed $10^{14}$ times. Find the probability that there exist $1000$ consecutive coin tosses with at least $650$ out of the $1000$ being heads. This is probably impractical to calculate using binomial distributions, so how would you find an answer using the Normal distribution as an approximation, or is it not possible to do this? The reason I'm interested in this latter question is that it is the sort of calculation one might make if one wanted to gain statistical evidence that a poker site is rigged against them, although of course the latter question would not be enough evidence to prove a poker site is rigged against a particular player; it could be a reasonable starting point for further calculations. Also, it is not hard to imagine this calculation could have applications in other areas, statistical mechanics or mathematical biology for example.","A coin is tossed times. Find the probability that there exist consecutive coin tosses with at least out of the being heads. So for example, is one of the outcomes we want. I guess the best way to treat this is as a counting problem; finding the number of outcomes we want and then dividing by so listing all the outcomes is time-wise expensive. The events, ""The first consecutive tosses contain at least heads"", ""The second consecutive tosses contain at least heads"", etc. are not mutually exclusive and so the answer is not simply: (The first consecutive tosses contain at least heads) + (The second consecutive tosses contain at least heads) + ... . Similarly, the events, ""The first consecutive tosses does not contain at least heads"", ""The second consecutive tosses does not contain at least heads"", etc. are also not mutually exclusive and so the answer is not simply: (The first consecutive tosses does not contain at least heads) + (The second consecutive tosses does not contain at least heads) + ... . Edit: What about reflecting the boxes down the middle? This could cut our work in half maybe? For example, . Perhaps figuring out the symmetries is expensive too. I'm also interested in doing a similar problem with larger numbers, e.g.: A coin is tossed times. Find the probability that there exist consecutive coin tosses with at least out of the being heads. This is probably impractical to calculate using binomial distributions, so how would you find an answer using the Normal distribution as an approximation, or is it not possible to do this? The reason I'm interested in this latter question is that it is the sort of calculation one might make if one wanted to gain statistical evidence that a poker site is rigged against them, although of course the latter question would not be enough evidence to prove a poker site is rigged against a particular player; it could be a reasonable starting point for further calculations. Also, it is not hard to imagine this calculation could have applications in other areas, statistical mechanics or mathematical biology for example.","10 7 5 7 TTHHTHHTHH 2^{10}. 2^{10} = 1024, 7 5 7 5 P 7 5 P 7 5 7 5 7 5 1 -  [P 7 5 P 7 5 ] 10 HTTHHTHTHH \equiv HHTHTHHTTH 10^{14} 1000 650 1000","['probability', 'combinatorics', 'normal-distribution', 'binomial-distribution', 'inclusion-exclusion']"
88,"$U \sim \text{unif}(0, 1)$ and $3X^2 - 2X^3 - U = 0$. What is the p.d.f. of $X$?",and . What is the p.d.f. of ?,"U \sim \text{unif}(0, 1) 3X^2 - 2X^3 - U = 0 X","Let $U \sim \text{unif}(0, 1)$ and let $X$ be the root of the equation $3t^2 − 2t^3 − U = 0$ . Show that $X$ has p.d.f. $$f(x) = \begin{cases}6x(1-x) & 0\le x\le 1 \\ 0 & \text{otherwise} \end{cases}$$ Since $U \sim \text{unif}(0, 1)$ , we have for $0\le a,b\le 1$ , $P(a\le U\le b) = \frac{1}{b-a}$ . We also have $3X^2 - 2X^3 - U = 0$ . To find the p.d.f. of $X$ , I first try to find the c.d.f. of $X$ (and differentiate it later). In fact one can check that $3x^2 - 2x^3$ is an increasing function in $0 \le x \le 1$ . So, $$P(X \le x) = P(3X^2 - 2X^3 \le 3x^2 - 2x^3)\\ = P(U \le 3x^2 - 2x^3) = \int_0^{3x^2 - 2x^3} \,dx = 3x^2 - 2x^3$$ Then $$P(X \le x) = \begin{cases}3x^2 - 2x^3 & 0 \le x < 1 \\ 1 &x \ge 1 \\0 &x < 0 \end{cases}$$ which gives the desired result on differentiation. I am wondering if there are any more direct approaches to this problem, i.e. without going through the c.d.f. if possible?","Let and let be the root of the equation . Show that has p.d.f. Since , we have for , . We also have . To find the p.d.f. of , I first try to find the c.d.f. of (and differentiate it later). In fact one can check that is an increasing function in . So, Then which gives the desired result on differentiation. I am wondering if there are any more direct approaches to this problem, i.e. without going through the c.d.f. if possible?","U \sim \text{unif}(0, 1) X 3t^2 − 2t^3 − U = 0 X f(x) = \begin{cases}6x(1-x) & 0\le x\le 1 \\ 0 & \text{otherwise} \end{cases} U \sim \text{unif}(0, 1) 0\le a,b\le 1 P(a\le U\le b) = \frac{1}{b-a} 3X^2 - 2X^3 - U = 0 X X 3x^2 - 2x^3 0 \le x \le 1 P(X \le x) = P(3X^2 - 2X^3 \le 3x^2 - 2x^3)\\ = P(U \le 3x^2 - 2x^3) = \int_0^{3x^2 - 2x^3} \,dx = 3x^2 - 2x^3 P(X \le x) = \begin{cases}3x^2 - 2x^3 & 0 \le x < 1 \\
1 &x \ge 1 \\0 &x < 0 \end{cases}",['probability']
89,Intuitive Understanding of Independence of 3 Events,Intuitive Understanding of Independence of 3 Events,,"I understand what it means to say that an even E is independent of an event F, it means that knowing that F has occurred does not change the probability that E will occur. Algebraically, it implies: $$P(E) = P\left(E \mid F\right)   \stackrel{\text{def}}{=} \frac{P\left(E \cap F\right)}{P\left(F\right)} \Leftrightarrow P\left(E \cap F \right) = P\left(E\right)  P\left(F\right)$$ Now I'm trying to tackle what it means for events E, F, and G to be independent, the definition stated in the book says: $$\begin{gathered}   P\left(E \cap F \cap G\right) = P\left(E\right) P\left(F\right) P\left(G\right)\\   P\left(E \cap F\right) = P\left(E\right) P\left(F\right) \\   P\left(E \cap G\right) = P\left(E\right) P\left(G\right) \\   P\left(F \cap G\right) = P\left(F\right) P\left(G\right)\end{gathered}$$ Based on my previous understanding the bottom three lines would be implying that E is independent of F, E is independent of G, and that F is independent of G. But I'm not sure what the first line is saying. The way I've made sense of it so far is that: $$ P\left(E \cap F \cap G\right)= P\left( E \cap \left( F \cap G  \right) \right) \stackrel{?}{=} P\left(E \right) P\left(F \cap G\right) \stackrel{\alpha}{=} P\left(E\right) P\left(F\right)P\left(G\right)$$ (Where $\alpha$ comes from the fact that E and F were independent.) In order for the equality with the question mark to hold, I think we would need $E$ to be independent from $F \cap G$ . I am a little confused by their definition and tried to figure it out algebraically, but that's what I've gotten up to. I am hoping someone can: Give me an intuitive understanding of what it means for 3 events to be independent Help me connect this understanding to the definition they have provided Bonus: Help me take that understanding to the independence of $n$ events","I understand what it means to say that an even E is independent of an event F, it means that knowing that F has occurred does not change the probability that E will occur. Algebraically, it implies: Now I'm trying to tackle what it means for events E, F, and G to be independent, the definition stated in the book says: Based on my previous understanding the bottom three lines would be implying that E is independent of F, E is independent of G, and that F is independent of G. But I'm not sure what the first line is saying. The way I've made sense of it so far is that: (Where comes from the fact that E and F were independent.) In order for the equality with the question mark to hold, I think we would need to be independent from . I am a little confused by their definition and tried to figure it out algebraically, but that's what I've gotten up to. I am hoping someone can: Give me an intuitive understanding of what it means for 3 events to be independent Help me connect this understanding to the definition they have provided Bonus: Help me take that understanding to the independence of events","P(E) = P\left(E \mid F\right)   \stackrel{\text{def}}{=} \frac{P\left(E \cap F\right)}{P\left(F\right)} \Leftrightarrow P\left(E \cap F \right) = P\left(E\right)  P\left(F\right) \begin{gathered}
  P\left(E \cap F \cap G\right) = P\left(E\right) P\left(F\right) P\left(G\right)\\
  P\left(E \cap F\right) = P\left(E\right) P\left(F\right) \\
  P\left(E \cap G\right) = P\left(E\right) P\left(G\right) \\
  P\left(F \cap G\right) = P\left(F\right) P\left(G\right)\end{gathered}  P\left(E \cap F \cap G\right)= P\left( E \cap \left( F \cap G  \right) \right) \stackrel{?}{=} P\left(E \right) P\left(F \cap G\right) \stackrel{\alpha}{=} P\left(E\right) P\left(F\right)P\left(G\right) \alpha E F \cap G n",['probability']
90,"If $X$ and $Z$ are independent: $\mathbb{E}(Y|X) = \mathbb{E}(Y) \implies \mathbb{E}(Y|X,Z) = \mathbb{E}(Y|Z)$?",If  and  are independent: ?,"X Z \mathbb{E}(Y|X) = \mathbb{E}(Y) \implies \mathbb{E}(Y|X,Z) = \mathbb{E}(Y|Z)","My question is, given that $X$ and $Z$ are independent is it true that $$ \mathbb{E}(Y|X) = \mathbb{E}(Y) \implies \mathbb{E}(Y|X,Z) = \mathbb{E}(Y|Z)  $$ I do not seem to be able to prove it but I cannot come up with a counterexample or disprove it. Does the answer change if on top of $X$ and $Z$ being independent we also impose that $\mathbb{E}(Y|Z) \neq \mathbb{E}(Y)$ ?","My question is, given that and are independent is it true that I do not seem to be able to prove it but I cannot come up with a counterexample or disprove it. Does the answer change if on top of and being independent we also impose that ?","X Z 
\mathbb{E}(Y|X) = \mathbb{E}(Y) \implies \mathbb{E}(Y|X,Z) = \mathbb{E}(Y|Z) 
 X Z \mathbb{E}(Y|Z) \neq \mathbb{E}(Y)","['probability', 'independence']"
91,Calculation of probability for random variable,Calculation of probability for random variable,,"The number of the daily car accidents in Luna-land is a random variable with mean 50 and standard deviation 5. Find the probability for the total accidents in the following 25 days to be $\leq 1300$ . I am only familiar with combinatorics, not distributions. I did a bit of reading around and found that probably this must be approached by the normal distribution. So we want $P (X\leq 1300)$ ? (this is not homework!) Thank you! EDIT: I found the formula for the central limit theorem. So, it seems I must calculate $\frac {(1300-25*50)}{\frac{5}{\sqrt25}}$ ?","The number of the daily car accidents in Luna-land is a random variable with mean 50 and standard deviation 5. Find the probability for the total accidents in the following 25 days to be . I am only familiar with combinatorics, not distributions. I did a bit of reading around and found that probably this must be approached by the normal distribution. So we want ? (this is not homework!) Thank you! EDIT: I found the formula for the central limit theorem. So, it seems I must calculate ?",\leq 1300 P (X\leq 1300) \frac {(1300-25*50)}{\frac{5}{\sqrt25}},"['probability', 'probability-distributions']"
92,How to argue that variance integral actually converges?,How to argue that variance integral actually converges?,,"I'm just starting out with a course where were being taught about expectation and variance of continuous distributions via probability density functions. I was given a definition of how the variance of a random variable $X$ is calculated given its probability density function $f(x)$ , but the definition seems all to suspicious to me. In particular, if $X$ is a random variable and its PDF is $f(x)$ , then it's variance is computed via $$ \text{Var}(X) = \int _{\mathbb{R}}x^2 f(x) \, dx $$ where I've assumed the expected value of $X$ is $0$ just to make things a bit simpler. Now, since $f(x)$ is assumed to be a PDF, then you'd expect $$ \int _{\mathbb{R}}f(x) \,dx = 1 $$ which seems to hint that the function is (sort of) integrable. But, how can you even make sure that integration of $x^2 f(x)$ actually yields a finite value? I've tried a back-of-the-envelope calculation using integration by parts, and the situation seems to hinge on whether or not $x^2 f(x) \rightarrow 0$ as $|x| \rightarrow 0$ , yet I can't find how this is justified. Any and all help will be appreciated :)","I'm just starting out with a course where were being taught about expectation and variance of continuous distributions via probability density functions. I was given a definition of how the variance of a random variable is calculated given its probability density function , but the definition seems all to suspicious to me. In particular, if is a random variable and its PDF is , then it's variance is computed via where I've assumed the expected value of is just to make things a bit simpler. Now, since is assumed to be a PDF, then you'd expect which seems to hint that the function is (sort of) integrable. But, how can you even make sure that integration of actually yields a finite value? I've tried a back-of-the-envelope calculation using integration by parts, and the situation seems to hinge on whether or not as , yet I can't find how this is justified. Any and all help will be appreciated :)","X f(x) X f(x) 
\text{Var}(X) = \int _{\mathbb{R}}x^2 f(x) \, dx
 X 0 f(x) 
\int _{\mathbb{R}}f(x) \,dx = 1
 x^2 f(x) x^2 f(x) \rightarrow 0 |x| \rightarrow 0","['probability', 'probability-distributions']"
93,What is the meaning of writing the differential inside of a function?,What is the meaning of writing the differential inside of a function?,,"I am reading through Resnick's ""Extreme Values, Regular Variation and Point Processes"" and have come across some notation that I am not familiar with. In talking about moving a Poisson point process into higher dimensions, we are introduced to the mean measure function: \begin{align*} \mu^*(dx, dy)=\mu(dx) K(x, dy), \end{align*} my question here is strictly about notation like: $\mu(dx)$ . I know the following notation \begin{align*} \int_\Omega f(x)\mu(dx)=\int_\Omega f(x)d\mu(x)=\int_\Omega fd\mu \end{align*} and I know that when we write something like \begin{align*} \int_\Omega f(X, y)K(X, dy) \end{align*} we are freezing $X$ and integrating with respect to $K$ , viewed now as a function only of $y$ . My question here is, what is meant when we write the differential inside a function, like $\mu(dx)$ , outside of the integral?","I am reading through Resnick's ""Extreme Values, Regular Variation and Point Processes"" and have come across some notation that I am not familiar with. In talking about moving a Poisson point process into higher dimensions, we are introduced to the mean measure function: my question here is strictly about notation like: . I know the following notation and I know that when we write something like we are freezing and integrating with respect to , viewed now as a function only of . My question here is, what is meant when we write the differential inside a function, like , outside of the integral?","\begin{align*}
\mu^*(dx, dy)=\mu(dx) K(x, dy),
\end{align*} \mu(dx) \begin{align*}
\int_\Omega f(x)\mu(dx)=\int_\Omega f(x)d\mu(x)=\int_\Omega fd\mu
\end{align*} \begin{align*}
\int_\Omega f(X, y)K(X, dy)
\end{align*} X K y \mu(dx)","['probability', 'probability-theory', 'self-learning', 'poisson-process', 'extreme-value-analysis']"
94,Can random variables be something else other then discrete or continuous?,Can random variables be something else other then discrete or continuous?,,"My textbook asks me the following question as a concept check: Do you think that there are random variables which are neither discrete nor continuous? If yes, try to construct a simple example. If no, then discuss why not. I wrote No, how else can outcomes be measured if they aren't finite or countably infinite (which falls under discrete random variables) or if they can't be measured using a range of values (which falls under continuous random variables)? So the answer is no. My question is, am I right? Can a random variable be described as something other then discrete or continuous? I don't think so based off my reasoning above, but I could be wrong and I'd appreciate it if someone could tell me whether I have this concept check right.","My textbook asks me the following question as a concept check: Do you think that there are random variables which are neither discrete nor continuous? If yes, try to construct a simple example. If no, then discuss why not. I wrote No, how else can outcomes be measured if they aren't finite or countably infinite (which falls under discrete random variables) or if they can't be measured using a range of values (which falls under continuous random variables)? So the answer is no. My question is, am I right? Can a random variable be described as something other then discrete or continuous? I don't think so based off my reasoning above, but I could be wrong and I'd appreciate it if someone could tell me whether I have this concept check right.",,['probability']
95,"Prove that/Explain how for independent random variables $X_i$, we have $f_i(X_i)$ are independent (in particular without measure theory)","Prove that/Explain how for independent random variables , we have  are independent (in particular without measure theory)",X_i f_i(X_i),"I have seen a lot of posts that describe the case for just 2 random variables. Independent random variables and function of them Are functions of independent variables also independent? If $X$ and $Y$ are independent then $f(X)$ and $g(Y)$ are also independent. If $X$ and $Y$ are independent. How about $X^2$ and $Y$? And how about $f(X)$ and $g(Y)$? Are squares of independent random variables independent? Prove that if $X$ and $Y$ are independent, then $h(X)$ and $g(Y)$ are independent in BASIC probability -- can we use double integration? (oh I actually asked the 2 variable elementary case here, but there's no answer) I have yet to see a post that describes the case for at least 3 . Please answer in 2 situations 1 - for advanced probability theory: Let $X_i: \Omega \to \mathbb R$ be independent random variables in $(\Omega, \mathscr F, \mathbb P)$ . Let $i \in I$ for any index set I think (or maybe has to be countable). Of course, assume $card(I) \ge 3$ . Then show $f_i(X_i)$ are independent. Give conditions on $f_i$ such that $f_i(X_i)$ is independent. I read in above posts that the condition is 'measurable', which I guess means $\mathscr F$ - measurable, but I could've sworn that I read before that the condition is supposed to be 'bounded and Borel-measurable', as in bounded and $\mathscr B(\mathbb R)$ -measurable for $(\mathbb R, \mathscr B(\mathbb R), Lebesgue)$ 2 - for elementary probability theory Let $X_i: \Omega \to \mathbb R$ be independent random variables that have pdf's. Use the elementary probability definition of independence that is 'independent if the joint pdf splits up', or something. I guess the index set $I$ need not be finite, in which case I think the definition is that the joint pdf of any finite subset of is independent . Give conditions on $f_i$ such that $f_i(X_i)$ is independent. Of course we can't exactly say that $f_i$ is 'measurable'. Context for the elementary case: I'm trying to justify the computation for the formula for the moment-generating function for linear combination of independent random variables . See here: Proving inequality of probabilty to derive upper bound for moment-generating functions Based on the application of Riemann–Stieltjes integral (or Lebesgue–Stieltjes integral) to probability , I think the condition is any $f_i$ such that $E[f_i(X_i)]$ exists (i.e. $E[|f_i(X_i)|]$ is finite). This is the same condition in Larsen and Marx - Introduction to Mathematical Statistics and Its Applications . I think $f$ bounded implies this but not conversely. Update : Also related through another question If $g$ is a continuous and increasing function of $x$, prove that $g(X)$ is a random variable. --> More generally for what functions $g$ is $g(X)$ is a random variable? Of course in advanced probability just say $g$ is Borel-measurable or $\mathscr F$ -measurable or whatever, but I think in elementary probability we say $g$ such that $E[g(X)]$ exists i.e. $E[|g(X)|] < \infty$ , EVEN THOUGH this is, I believe, a stronger condition than that $g$ is 'measurable', whatever this means in elementary probability. But then again this is kind of weird since we don't even necessarily expect $E[X]$ to exist (i.e. $E[|X|] < \infty$ ) or well any higher moment $E[X^n]$ I guess.","I have seen a lot of posts that describe the case for just 2 random variables. Independent random variables and function of them Are functions of independent variables also independent? If $X$ and $Y$ are independent then $f(X)$ and $g(Y)$ are also independent. If $X$ and $Y$ are independent. How about $X^2$ and $Y$? And how about $f(X)$ and $g(Y)$? Are squares of independent random variables independent? Prove that if $X$ and $Y$ are independent, then $h(X)$ and $g(Y)$ are independent in BASIC probability -- can we use double integration? (oh I actually asked the 2 variable elementary case here, but there's no answer) I have yet to see a post that describes the case for at least 3 . Please answer in 2 situations 1 - for advanced probability theory: Let be independent random variables in . Let for any index set I think (or maybe has to be countable). Of course, assume . Then show are independent. Give conditions on such that is independent. I read in above posts that the condition is 'measurable', which I guess means - measurable, but I could've sworn that I read before that the condition is supposed to be 'bounded and Borel-measurable', as in bounded and -measurable for 2 - for elementary probability theory Let be independent random variables that have pdf's. Use the elementary probability definition of independence that is 'independent if the joint pdf splits up', or something. I guess the index set need not be finite, in which case I think the definition is that the joint pdf of any finite subset of is independent . Give conditions on such that is independent. Of course we can't exactly say that is 'measurable'. Context for the elementary case: I'm trying to justify the computation for the formula for the moment-generating function for linear combination of independent random variables . See here: Proving inequality of probabilty to derive upper bound for moment-generating functions Based on the application of Riemann–Stieltjes integral (or Lebesgue–Stieltjes integral) to probability , I think the condition is any such that exists (i.e. is finite). This is the same condition in Larsen and Marx - Introduction to Mathematical Statistics and Its Applications . I think bounded implies this but not conversely. Update : Also related through another question If $g$ is a continuous and increasing function of $x$, prove that $g(X)$ is a random variable. --> More generally for what functions is is a random variable? Of course in advanced probability just say is Borel-measurable or -measurable or whatever, but I think in elementary probability we say such that exists i.e. , EVEN THOUGH this is, I believe, a stronger condition than that is 'measurable', whatever this means in elementary probability. But then again this is kind of weird since we don't even necessarily expect to exist (i.e. ) or well any higher moment I guess.","X_i: \Omega \to \mathbb R (\Omega, \mathscr F, \mathbb P) i \in I card(I) \ge 3 f_i(X_i) f_i f_i(X_i) \mathscr F \mathscr B(\mathbb R) (\mathbb R, \mathscr B(\mathbb R), Lebesgue) X_i: \Omega \to \mathbb R I f_i f_i(X_i) f_i f_i E[f_i(X_i)] E[|f_i(X_i)|] f g g(X) g \mathscr F g E[g(X)] E[|g(X)|] < \infty g E[X] E[|X|] < \infty E[X^n]","['probability', 'probability-theory', 'measure-theory', 'independence', 'moment-generating-functions']"
96,Show that a.s. $\limsup_n \frac{X_n}{\sqrt{2\log n}} \le 1$,Show that a.s.,\limsup_n \frac{X_n}{\sqrt{2\log n}} \le 1,Let $(X_n)$ be a family of independent gaussians. I am suppose to show that a.s. $$\limsup_n \frac{X_n}{\sqrt{2\log n}} = 1.$$ I was able to show using Borel-Cantelli that $$\limsup_n \frac{X_n}{\sqrt{2\log n}} \ge  1$$ Is it also true that I am a bit clueless about the other direction $$\limsup_n \frac{X_n}{\sqrt{2\log n}} \le  1$$,Let be a family of independent gaussians. I am suppose to show that a.s. I was able to show using Borel-Cantelli that Is it also true that I am a bit clueless about the other direction,(X_n) \limsup_n \frac{X_n}{\sqrt{2\log n}} = 1. \limsup_n \frac{X_n}{\sqrt{2\log n}} \ge  1 \limsup_n \frac{X_n}{\sqrt{2\log n}} \le  1,"['real-analysis', 'probability', 'probability-theory', 'analysis']"
97,STEP 2013 P1 Statistics and Probability Question,STEP 2013 P1 Statistics and Probability Question,,"The aim to the following: From a deck of 52 cards (numbered from 1,2,3,...,52) I pick 7 cards, each card having the same probability of being picked. What is the probability that only two of the selected cards add up to 53? My approach: Say we have the cards $A,B,C,D,E,F \text{ and } G$ . The probability that a randomly selected card, say $A$ , from these $7$ has its pair in the set is $\frac{6}{51}$ . Say this pair is $B$ . Now we need to figure out the number of other possible pairs and the probability that a given number doesn't have its pair. The probability that a number doesn't have its pair (from the $5$ numbers left) is $1-\frac{5}{51}=\frac{46}{51}$ . There are $\binom{5}{2}=10$ many different possible pairs. Thus the probability that exactly one pair add up to $53$ is $$p=\frac{6}{51}(\frac{46}{51})^{10}.$$ According to the markscheme this is wrong. Could somebody let me know why is that?","The aim to the following: From a deck of 52 cards (numbered from 1,2,3,...,52) I pick 7 cards, each card having the same probability of being picked. What is the probability that only two of the selected cards add up to 53? My approach: Say we have the cards . The probability that a randomly selected card, say , from these has its pair in the set is . Say this pair is . Now we need to figure out the number of other possible pairs and the probability that a given number doesn't have its pair. The probability that a number doesn't have its pair (from the numbers left) is . There are many different possible pairs. Thus the probability that exactly one pair add up to is According to the markscheme this is wrong. Could somebody let me know why is that?","A,B,C,D,E,F \text{ and } G A 7 \frac{6}{51} B 5 1-\frac{5}{51}=\frac{46}{51} \binom{5}{2}=10 53 p=\frac{6}{51}(\frac{46}{51})^{10}.","['probability', 'combinatorics', 'statistics', 'solution-verification']"
98,"$\exists$ countably generated $\mathcal F$, s.t. $\sigma(\{ \{\omega \}: \omega\in\Omega \}) \subsetneqq \mathcal F \subsetneqq \mathcal B(\Omega)$?","countably generated , s.t. ?",\exists \mathcal F \sigma(\{ \{\omega \}: \omega\in\Omega \}) \subsetneqq \mathcal F \subsetneqq \mathcal B(\Omega),"Does there exist a countably generated $\sigma$ -field $\mathcal F$ on a second countable space $\Omega$ such that \begin{equation*}   \sigma(\{ \{\omega \}: \omega\in\Omega \}) \subsetneqq \mathcal F \subsetneqq \mathcal B(\Omega)? \end{equation*} Here is the motivation, also some clues. One the one hand, since $\Omega$ is second countable, its Borel $\sigma$ -field $\mathcal B(\Omega)$ is clearly countably generated (by a countable topological base). But the $\sigma$ -field generated by singletons $\sigma(\{ \{\omega \}: \omega\in\Omega \})$ is just the countable co-countable $\sigma$ -field, which is not countably generated in general, say e.g., when $\Omega=\mathbb R$ . On the other hand, $\sigma(\{ \{\omega \}: \omega\in\Omega \})$ is countably generated if and only if $\Omega$ is itself a countable set . In this case, $\sigma(\{ \{\omega \}: \omega\in\Omega \})$ coincides with $\mathcal B(\Omega)$ , and there is no such intermediate $\mathcal F$ . So does such intermediate $\mathcal F$ exist in some general cases? Or it definitely does not exist whenever the second countable space $\Omega$ is? Any comments or hints will be appreciated. TIA... EDIT: There should be some appropriate examples for the intermediate $\mathcal F$ , as shown in the comment by @bof and the answer by @Henno Brandsma. But what happens if we force $\Omega$ to be a Polish space , which is stronger and more commonly used in measure theory than second countable space? I think then there will be no such intermediate $\mathcal F$ , but I don't know how to prove it...","Does there exist a countably generated -field on a second countable space such that Here is the motivation, also some clues. One the one hand, since is second countable, its Borel -field is clearly countably generated (by a countable topological base). But the -field generated by singletons is just the countable co-countable -field, which is not countably generated in general, say e.g., when . On the other hand, is countably generated if and only if is itself a countable set . In this case, coincides with , and there is no such intermediate . So does such intermediate exist in some general cases? Or it definitely does not exist whenever the second countable space is? Any comments or hints will be appreciated. TIA... EDIT: There should be some appropriate examples for the intermediate , as shown in the comment by @bof and the answer by @Henno Brandsma. But what happens if we force to be a Polish space , which is stronger and more commonly used in measure theory than second countable space? I think then there will be no such intermediate , but I don't know how to prove it...","\sigma \mathcal F \Omega \begin{equation*}
  \sigma(\{ \{\omega \}: \omega\in\Omega \}) \subsetneqq \mathcal F \subsetneqq \mathcal B(\Omega)?
\end{equation*} \Omega \sigma \mathcal B(\Omega) \sigma \sigma(\{ \{\omega \}: \omega\in\Omega \}) \sigma \Omega=\mathbb R \sigma(\{ \{\omega \}: \omega\in\Omega \}) \Omega \sigma(\{ \{\omega \}: \omega\in\Omega \}) \mathcal B(\Omega) \mathcal F \mathcal F \Omega \mathcal F \Omega \mathcal F","['probability', 'general-topology', 'probability-theory', 'measure-theory', 'descriptive-set-theory']"
99,Players and tickets,Players and tickets,,"You are among N players that will play a competition. A lottery is used to determine the placement of each player. You have an advantage. Two tickets with your name are put in a hat, while for each of the other players only one ticket with her/his name is put in the hat. The hat is well shaken and tickets are drawn one by one from the hat. The order of names appearing determines the placement of each player. What is the probability that you will get assigned the $n$ th placement for $n = 1, 2, . . . , N$ ? The probability that my name is drawn at $k$ th attempts is $\frac{2}{N}(\frac{N-2}{N})^{k-1}$ (ie to say $k-1$ failures before the first success at $k$ ). I know that the solution is $\prod_{k=1}^{n-1}\frac{2}{2+N-n}\frac{N-k}{2+N-k}$ . Let $A_i$ be the event that my name compairs shows up at $i$ th attempts. So: $\mathbb{P}(A_1)=\frac{2}{N+1}$ ; $\mathbb{P}(A_2)=\mathbb{P}(\bar{A_1})\mathbb{P}(A_2|\bar{A_1})=(\frac{N-1}{N+1})(\frac{2}{N})$ $\mathbb{P}(A_3)=\mathbb{P}(\bar{A_1}\cap \bar{A_2})\mathbb{P}(A_3|\bar{A_1}\cap \bar{A_2})=(\frac{N-1}{N+1})(\frac{N-2}{N})(\frac{2}{N-1})$ . Thus I thought that $\mathbb{P}(A_n)=(\frac{N-1}{N+1})\cdot (\frac{N-2}{N})\cdot ... \cdot (\frac{N-n-1}{N+1-n})\cdot (\frac{2}{N-n})$ but I can't lead me to the product above. Where am I wrong?","You are among N players that will play a competition. A lottery is used to determine the placement of each player. You have an advantage. Two tickets with your name are put in a hat, while for each of the other players only one ticket with her/his name is put in the hat. The hat is well shaken and tickets are drawn one by one from the hat. The order of names appearing determines the placement of each player. What is the probability that you will get assigned the th placement for ? The probability that my name is drawn at th attempts is (ie to say failures before the first success at ). I know that the solution is . Let be the event that my name compairs shows up at th attempts. So: ; . Thus I thought that but I can't lead me to the product above. Where am I wrong?","n n = 1, 2, . . . , N k \frac{2}{N}(\frac{N-2}{N})^{k-1} k-1 k \prod_{k=1}^{n-1}\frac{2}{2+N-n}\frac{N-k}{2+N-k} A_i i \mathbb{P}(A_1)=\frac{2}{N+1} \mathbb{P}(A_2)=\mathbb{P}(\bar{A_1})\mathbb{P}(A_2|\bar{A_1})=(\frac{N-1}{N+1})(\frac{2}{N}) \mathbb{P}(A_3)=\mathbb{P}(\bar{A_1}\cap \bar{A_2})\mathbb{P}(A_3|\bar{A_1}\cap \bar{A_2})=(\frac{N-1}{N+1})(\frac{N-2}{N})(\frac{2}{N-1}) \mathbb{P}(A_n)=(\frac{N-1}{N+1})\cdot (\frac{N-2}{N})\cdot ... \cdot (\frac{N-n-1}{N+1-n})\cdot (\frac{2}{N-n})",['probability']
