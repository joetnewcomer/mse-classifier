,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,finite additivity&countable additivity,finite additivity&countable additivity,,"Let $\tau$ be a semialgebra of subsets of $\Omega$ and let P: $\tau\rightarrow [0,1]$, with $P(\Omega)=1$, and it satisfies finite additivity: $P\big(\bigcup_{i=1}^{n}D_i\big)=\sum_{i=1}^{n}P(D_i)$ for $D_1,..., D_n\in \tau$ disjoint, and $\bigcup_{i=1}^{n}D_i\in \tau$. Suppose we also have for $A_1,..., A_n \in \tau$ such that $A_{n+1}\subseteq A_n$ and $\bigcap_{n=1}^{\infty}A_n=\emptyset$, and $\lim_{n\rightarrow\infty}P(A_n)=0$. Then how can I show that P holds countable additivity property?","Let $\tau$ be a semialgebra of subsets of $\Omega$ and let P: $\tau\rightarrow [0,1]$, with $P(\Omega)=1$, and it satisfies finite additivity: $P\big(\bigcup_{i=1}^{n}D_i\big)=\sum_{i=1}^{n}P(D_i)$ for $D_1,..., D_n\in \tau$ disjoint, and $\bigcup_{i=1}^{n}D_i\in \tau$. Suppose we also have for $A_1,..., A_n \in \tau$ such that $A_{n+1}\subseteq A_n$ and $\bigcap_{n=1}^{\infty}A_n=\emptyset$, and $\lim_{n\rightarrow\infty}P(A_n)=0$. Then how can I show that P holds countable additivity property?",,"['measure-theory', 'elementary-set-theory']"
1,"Caratheodory extension theorem: which is the ""unique extension""","Caratheodory extension theorem: which is the ""unique extension""",,"According to Wikipedia , the constructed measure on $\sigma(R)$ is a unique extension. However, in most situations, the $\sigma$-algebra of Caratheodory-measurable sets $M$ is larger than $\sigma(R)$. So is the constructed measure also a unique extension on $M$ and is there an easy way to see this having done the hard work for $\sigma(R)$? [Or is the actual theorem uniqueness for $M$ and there is an easy way to see uniqueness of extension for $\sigma(R)$?]","According to Wikipedia , the constructed measure on $\sigma(R)$ is a unique extension. However, in most situations, the $\sigma$-algebra of Caratheodory-measurable sets $M$ is larger than $\sigma(R)$. So is the constructed measure also a unique extension on $M$ and is there an easy way to see this having done the hard work for $\sigma(R)$? [Or is the actual theorem uniqueness for $M$ and there is an easy way to see uniqueness of extension for $\sigma(R)$?]",,"['real-analysis', 'measure-theory']"
2,"If a sequence of monotone functions converges in measure, does it also converge almost everywhere?","If a sequence of monotone functions converges in measure, does it also converge almost everywhere?",,"Let $\{f_n\}$ be a sequence of monotone functions from $\Bbb R$ to $\Bbb R$ such that $f_n$ converges in measure to some function $f$ . Is it true that $f_n$ converges to $f$ a.e.? I am sure it has a sub-sequence that converges to $f$ a.e., and intuitively it seems that it must be true, but I am not able to prove it rigorously. Could you please give me some hint?","Let be a sequence of monotone functions from to such that converges in measure to some function . Is it true that converges to a.e.? I am sure it has a sub-sequence that converges to a.e., and intuitively it seems that it must be true, but I am not able to prove it rigorously. Could you please give me some hint?",\{f_n\} \Bbb R \Bbb R f_n f f_n f f,"['real-analysis', 'measure-theory']"
3,Union of Increasing Sequences of Monotone Classes is not a Monotone Class.,Union of Increasing Sequences of Monotone Classes is not a Monotone Class.,,"In my text, we define a Monotone Class $\mathcal{M}$ of a non-empty set $X$ to be a collection of subsets of $X$ that is closed under monotone limits: that is, $(1)$ if $A_{i} \uparrow A$ with $A_{i} \in \mathcal{M}$, then $A \in \mathcal{M}$ and $(2)$ if $A_{i} \downarrow A$ with $A_{i} \in \mathcal{M}$, then $A \in \mathcal{M}$. The exercise for which I am seeking solution verification says the following: If $(\mathcal{M}_{i})$ is an increasing sequence of monotone classes, then is $\mathcal{M} = \bigcup^{\infty}_{i=1} \mathcal{M}_{i}$ a monotone class? Prove or give a counterexample. I want to construct a counterexample as follows. Let $X = \mathbb{N}$. Put $\mathcal{M}_{1} = \{\{1\}\}$, $\mathcal{M}_{2} = \{\{1\}, \{1,2\}\}$, and, in general, $\mathcal{M}_{i} =  \{\{1\}, \{1,2\},\ldots, \{1,2,\ldots, i\} \}$. Then, $(\mathcal{M}_{i})$ is an increasing sequence of monotone classes. Now, let $A_{i}=\{1, \ldots,i\}$. Then, $(A_{i})$ is increasing, and $A_{i}$ belongs to $\mathcal{M}$ since $A_{i} \in \mathcal{M}_{i}$, for each $i$. Notice that $A_{i} \uparrow A$, where  $A = \bigcup A_{i} = \mathbb{N}$. But, $A \notin \mathcal{M}$ since $A \notin \mathcal{M}_{i}$ for any $i$. Is my counterexample constructed correctly? (Note: I have noticed that some defintoins of a monotone class require that the entire set be in the class. If my construct ion above is correct, then we can just add the entire set $X$ to each $\mathcal{M}_{i}$.) Thank you!","In my text, we define a Monotone Class $\mathcal{M}$ of a non-empty set $X$ to be a collection of subsets of $X$ that is closed under monotone limits: that is, $(1)$ if $A_{i} \uparrow A$ with $A_{i} \in \mathcal{M}$, then $A \in \mathcal{M}$ and $(2)$ if $A_{i} \downarrow A$ with $A_{i} \in \mathcal{M}$, then $A \in \mathcal{M}$. The exercise for which I am seeking solution verification says the following: If $(\mathcal{M}_{i})$ is an increasing sequence of monotone classes, then is $\mathcal{M} = \bigcup^{\infty}_{i=1} \mathcal{M}_{i}$ a monotone class? Prove or give a counterexample. I want to construct a counterexample as follows. Let $X = \mathbb{N}$. Put $\mathcal{M}_{1} = \{\{1\}\}$, $\mathcal{M}_{2} = \{\{1\}, \{1,2\}\}$, and, in general, $\mathcal{M}_{i} =  \{\{1\}, \{1,2\},\ldots, \{1,2,\ldots, i\} \}$. Then, $(\mathcal{M}_{i})$ is an increasing sequence of monotone classes. Now, let $A_{i}=\{1, \ldots,i\}$. Then, $(A_{i})$ is increasing, and $A_{i}$ belongs to $\mathcal{M}$ since $A_{i} \in \mathcal{M}_{i}$, for each $i$. Notice that $A_{i} \uparrow A$, where  $A = \bigcup A_{i} = \mathbb{N}$. But, $A \notin \mathcal{M}$ since $A \notin \mathcal{M}_{i}$ for any $i$. Is my counterexample constructed correctly? (Note: I have noticed that some defintoins of a monotone class require that the entire set be in the class. If my construct ion above is correct, then we can just add the entire set $X$ to each $\mathcal{M}_{i}$.) Thank you!",,"['real-analysis', 'measure-theory', 'solution-verification']"
4,"Let $E ⊂ [0,1]$ be a measurable set, $m(E) ≥ \frac{99}{100} .$ Prove that there exists $x ∈ [0,1]$","Let  be a measurable set,  Prove that there exists","E ⊂ [0,1] m(E) ≥ \frac{99}{100} . x ∈ [0,1]","I need some help on the following real analysis past qual problem.  I would appreciate some help. Let $E ⊂ [0,1]$ be a measurable set, $m(E) ≥ \frac{99}{100} .$ Prove that there exists $x ∈ [0,1]$ such that for any $r ∈ (0, 1),$ $m(E ∩ (x − r, x + r)) ≥ \frac{r}{4} .$ Is there a way to use the Hardy-Littlewood maximal inequality?","I need some help on the following real analysis past qual problem.  I would appreciate some help. Let $E ⊂ [0,1]$ be a measurable set, $m(E) ≥ \frac{99}{100} .$ Prove that there exists $x ∈ [0,1]$ such that for any $r ∈ (0, 1),$ $m(E ∩ (x − r, x + r)) ≥ \frac{r}{4} .$ Is there a way to use the Hardy-Littlewood maximal inequality?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
5,"Spivak's ""Calculus in Manifolds"" problems","Spivak's ""Calculus in Manifolds"" problems",,"I have some troubles with this problems. Problem 1.18: If $A \subset [0,1]$ is the union of open intervals $(a_i,b_i)$ such that every rational number of $(0,1)$ is contained in $(a_i,b_i)$ , for some $i$ . Prove that ${\partial}A = [0,1] - A$ Problem 3.11: Let be $A$ the set of the problem 1.18. If $\sum_{i=1}^\infty\,(b_i - a_i) < 1$ then ${\partial}A$ does not have measure $0$ . For problem 1.18, I try to find ${\partial}A = \overline{A} \cap \overline{\mathbb{R} - A}$ , but I always found that ${\partial}A = [0,1]$ , besides I'm not sure if $A = \mathbb{Q} \cap [0,1]$ . For problem 3.11, a friend told me that the measure of $[0,1]$ is 1, and $[0,1] - A$ has, also, measure 1 (I don't know when a set has measure 1), and using the hypothesis I have a contradiction, but I don´t see how. I appreciate all your help. Thanks!!!","I have some troubles with this problems. Problem 1.18: If is the union of open intervals such that every rational number of is contained in , for some . Prove that Problem 3.11: Let be the set of the problem 1.18. If then does not have measure . For problem 1.18, I try to find , but I always found that , besides I'm not sure if . For problem 3.11, a friend told me that the measure of is 1, and has, also, measure 1 (I don't know when a set has measure 1), and using the hypothesis I have a contradiction, but I don´t see how. I appreciate all your help. Thanks!!!","A \subset [0,1] (a_i,b_i) (0,1) (a_i,b_i) i {\partial}A = [0,1] - A A \sum_{i=1}^\infty\,(b_i - a_i) < 1 {\partial}A 0 {\partial}A = \overline{A} \cap \overline{\mathbb{R} - A} {\partial}A = [0,1] A = \mathbb{Q} \cap [0,1] [0,1] [0,1] - A","['real-analysis', 'integration', 'measure-theory', 'vector-analysis']"
6,Countable sum of atomic measures is atomic?,Countable sum of atomic measures is atomic?,,"Let $(X,\Sigma)$ be a measurable space and $(\mu_n)$ a sequence of atomic measures defined on this space. Recall that a measure $\mu$ is atomic if for any measurable $A$ of measure $\mu(A)>0$ there is some measurable $E \subset A$ that is an atom, which means that $\mu(E)>0$ , and for any measurable $F\in X$ , either $\mu(E\cap F)$ or $\mu(E-F)=0$ . Consider the measure $\mu=\sum_{n\in \mathbb{N}} \mu_n$ . Is it true that $\mu$ must be atomic? This question is raised (but not answered) here . EDIT: The answer below by @George reflects the question (here) when it was previously required that the measure not take on infinite value.  This is not the correct definition, and does not reflect the original question of Roy A. Johnson.","Let be a measurable space and a sequence of atomic measures defined on this space. Recall that a measure is atomic if for any measurable of measure there is some measurable that is an atom, which means that , and for any measurable , either or . Consider the measure . Is it true that must be atomic? This question is raised (but not answered) here . EDIT: The answer below by @George reflects the question (here) when it was previously required that the measure not take on infinite value.  This is not the correct definition, and does not reflect the original question of Roy A. Johnson.","(X,\Sigma) (\mu_n) \mu A \mu(A)>0 E \subset A \mu(E)>0 F\in X \mu(E\cap F) \mu(E-F)=0 \mu=\sum_{n\in \mathbb{N}} \mu_n \mu",['measure-theory']
7,$C_c(\mathbb{R})$ is dense in $L^1(\mathbb{R}) \cap L^2(\mathbb{R})$... right?,is dense in ... right?,C_c(\mathbb{R}) L^1(\mathbb{R}) \cap L^2(\mathbb{R}),"The intersection $L^1(\mathbb{R}) \cap L^2(\mathbb{R})$ is (allegedly) a Banach space for the norm $\|f\| = \|f\|_1 + \|f\|_2$.  Is it also true that $C_c(\mathbb{R})$ is dense with respect to this norm? I think it's reasonably clear that simple functions are dense... It's enough to show you can approximate any nonnegative $f \in L^1(\mathbb{R}) \cap L^2(\mathbb{R})$. But, for such $f$, it's not difficult to produce a monotone increasing sequence of simple functions $s_n$ converging pointwise to $f$ from below, and then check $\|f-s_n\|_1 \to 0$ and $\|f-s_n\|_2 \to 0$. OK, so this means we just need to prove that the simple functions are approximable by compactly supported functions in the norm $\| \cdot \|$. Thus, it is enough to take a measureable set $E$ with finite measure and show its characteristic function $\chi_E$ can be approximated. So, I guess, my question reduces to: Question: If $E \subset \mathbb{R}$ is measureable with finite Lebesgue measure, and $\epsilon > 0$, is there always an $f \in C_c(\mathbb{R})$ such that $\| f - \chi_E\|_1 < \epsilon$ and $\|f - \chi_E\|_2 < \epsilon$?","The intersection $L^1(\mathbb{R}) \cap L^2(\mathbb{R})$ is (allegedly) a Banach space for the norm $\|f\| = \|f\|_1 + \|f\|_2$.  Is it also true that $C_c(\mathbb{R})$ is dense with respect to this norm? I think it's reasonably clear that simple functions are dense... It's enough to show you can approximate any nonnegative $f \in L^1(\mathbb{R}) \cap L^2(\mathbb{R})$. But, for such $f$, it's not difficult to produce a monotone increasing sequence of simple functions $s_n$ converging pointwise to $f$ from below, and then check $\|f-s_n\|_1 \to 0$ and $\|f-s_n\|_2 \to 0$. OK, so this means we just need to prove that the simple functions are approximable by compactly supported functions in the norm $\| \cdot \|$. Thus, it is enough to take a measureable set $E$ with finite measure and show its characteristic function $\chi_E$ can be approximated. So, I guess, my question reduces to: Question: If $E \subset \mathbb{R}$ is measureable with finite Lebesgue measure, and $\epsilon > 0$, is there always an $f \in C_c(\mathbb{R})$ such that $\| f - \chi_E\|_1 < \epsilon$ and $\|f - \chi_E\|_2 < \epsilon$?",,"['measure-theory', 'lebesgue-integral']"
8,Set of independent sets is a sigma-algebra?,Set of independent sets is a sigma-algebra?,,"I was wondering whether the set $\{E \in \mathscr{E};A,B,E \text{ are independent} \}$ is always a sigma-algebra, when $A,B$ are two independent sets in some probability space? I know that it is a Dynkin-system but is it also true that it is a sigma-algebra?  Somehow I guess the answer is no, but could not find a counterexample so far.","I was wondering whether the set $\{E \in \mathscr{E};A,B,E \text{ are independent} \}$ is always a sigma-algebra, when $A,B$ are two independent sets in some probability space? I know that it is a Dynkin-system but is it also true that it is a sigma-algebra?  Somehow I guess the answer is no, but could not find a counterexample so far.",,[]
9,A problem on measure theory,A problem on measure theory,,"Suppose $E_1$ and $E_2$ are a pair of compact sets in $\Bbb R^d$ with $E_1 \subset E_2$ and let $a=m(E_1)$ and $b=m(E_2)$. Prove that for any $c$ with $a <c <b$, there is a compact set $E$ with $E_1 \subset E \subset E_2$ and $m(E)=c$. Defining a continuous function using $E_2 \setminus E_1$ which has positive measure (and using Intermediate Value Theorem) I have found a bounded set which satisfies the above property. How to make it closed ?","Suppose $E_1$ and $E_2$ are a pair of compact sets in $\Bbb R^d$ with $E_1 \subset E_2$ and let $a=m(E_1)$ and $b=m(E_2)$. Prove that for any $c$ with $a <c <b$, there is a compact set $E$ with $E_1 \subset E \subset E_2$ and $m(E)=c$. Defining a continuous function using $E_2 \setminus E_1$ which has positive measure (and using Intermediate Value Theorem) I have found a bounded set which satisfies the above property. How to make it closed ?",,['measure-theory']
10,Why is $\mu(E)=0$?,Why is ?,\mu(E)=0,"(Ergoden theorem) Let $(\Omega,\mathcal{A},\mu,T)$ be an ergodic dynamical system and $f\in L_{\mu}^1$. Then     $$ \lim_n \frac{1}{n}\sum_{k=0}^{n-1}f\circ T^k=\int f\, d\mu~~\text{a.s.} $$ Proof. Set $S_nf=\sum_{k=0}^{n-1}f\circ T^k$. Define $E:=\left\{\limsup_n\frac{1}{n}S_n f > \varepsilon\right\}$. Now it is shown that $E=\left\{\sup_n S_ng> 0\right\}$ for $g=(f-\varepsilon)1_E$. With Hopf and Lebesgue it is shown that $$ \mu(E)\leq\int_E f\, d\mu / \varepsilon.~~~(*) $$ Now the argumentation is: $E$ is $T$-invariant and the system is ergodic, so it follows $\mu(E)=0$. I cannot see why in the end it follows from (*) that $\mu(E)=0$.","(Ergoden theorem) Let $(\Omega,\mathcal{A},\mu,T)$ be an ergodic dynamical system and $f\in L_{\mu}^1$. Then     $$ \lim_n \frac{1}{n}\sum_{k=0}^{n-1}f\circ T^k=\int f\, d\mu~~\text{a.s.} $$ Proof. Set $S_nf=\sum_{k=0}^{n-1}f\circ T^k$. Define $E:=\left\{\limsup_n\frac{1}{n}S_n f > \varepsilon\right\}$. Now it is shown that $E=\left\{\sup_n S_ng> 0\right\}$ for $g=(f-\varepsilon)1_E$. With Hopf and Lebesgue it is shown that $$ \mu(E)\leq\int_E f\, d\mu / \varepsilon.~~~(*) $$ Now the argumentation is: $E$ is $T$-invariant and the system is ergodic, so it follows $\mu(E)=0$. I cannot see why in the end it follows from (*) that $\mu(E)=0$.",,['measure-theory']
11,"Generalized Hölder inequality, the case when equality holds","Generalized Hölder inequality, the case when equality holds",,"I know the generalized Hölder inequality sounds like as: Let $1\leq p_1,\ldots,p_n<\infty$ and $p>0$ such that $\frac1p=\frac1{p_1}+\cdots+\frac1{p_n}$.  Then, for all measurable functions $f_1,\ldots,f_n: (X,\mu) → \mathbb C$ we have $\left\|\prod _{{k=1}}^{n}f_{k}\right\|_{p}\leq \prod _{{k=1}}^{n}\|f_{k}\|_{{p_{k}}}$. (see this or this ) My question is: what are conditions on $f_1,\ldots,f_n$ so that the equality holds, ie.. $\left\|\prod _{{k=1}}^{n}f_{k}\right\|_{p}= \prod _{{k=1}}^{n}\|f_{k}\|_{{p_{k}}}$","I know the generalized Hölder inequality sounds like as: Let $1\leq p_1,\ldots,p_n<\infty$ and $p>0$ such that $\frac1p=\frac1{p_1}+\cdots+\frac1{p_n}$.  Then, for all measurable functions $f_1,\ldots,f_n: (X,\mu) → \mathbb C$ we have $\left\|\prod _{{k=1}}^{n}f_{k}\right\|_{p}\leq \prod _{{k=1}}^{n}\|f_{k}\|_{{p_{k}}}$. (see this or this ) My question is: what are conditions on $f_1,\ldots,f_n$ so that the equality holds, ie.. $\left\|\prod _{{k=1}}^{n}f_{k}\right\|_{p}= \prod _{{k=1}}^{n}\|f_{k}\|_{{p_{k}}}$",,"['real-analysis', 'measure-theory', 'inequality']"
12,A question about Jordan measure.,A question about Jordan measure.,,"(a) Suppose that $A \subset [a,b]$ and that exists a partition $P$ of $[a,b]$ such that $c_e(A;P)<\eta$. Show that  exists $\delta>0$ such that, if $Q$ is a partition where $|Q|<\delta$ so $c_e(A;Q)<\eta$ (b)Suppose that $A \subset [a,b]$ and that exists a partition $P$ of $[a,b]$ such that $c_i(A;P)>\eta$. Show that exists $\delta>0$ such that, if $Q$ is a partition where $|Q|<\delta$, so $c_i(A;Q)>\eta$. (c) Show that, if $A\subset [a,b]$ and $\{P_m\}$ are a sequence of partitions of $[a,b]$ such that $|P_m| \rightarrow 0$, so   $$c_e(A)=\lim_{n\rightarrow+\infty}{c_e(A;P_m)}$$$$c_i(A)=\lim_{n\rightarrow+\infty}{c_i(A;P_m)}$$   (d) Show that:    $$c_e(A)=c_i(A)+c_e(\partial A)$$ DEFINITIONS AND ADDITIONAL INFORMATION Def.0: $P$ a partition, so $|P|=\max\{x_{i+1}-x_i: x_i, x_{i+1}\in P\}$ Def.1: $A \subset [a,b]$ is a negligible if, for all $\varepsilon>0$ exists partition $P=\{x_0,...,x_n\}$ of $[a,b]$ such that $\sum_P^*\Delta x_i<\varepsilon$, where this sum are over the indices such that $A \cap [x_{i-1},x_i] \neq \emptyset$ Follows from an exercise in class that:  $A\subset[a,b]$ is negligible is the same that affirm that: for all $\varepsilon>0$ exists $\delta>0$ such that, for all partition $Q$ where $|Q|<\delta$, we have $$\sum_{Q}^* \Delta x_i<\varepsilon$$, where $\sum^*_Q$ denote the sum over the indices such that $A \cap [x_{i-1},x_i] \neq \emptyset$ In this exercise we will generalize this result. Def.2: $c_e(A;P)\dot{=}\sum_{I_k \cap A \neq \emptyset}  c(I_k)=\sum_P^* \Delta x_i$ Def.3: $c_e(A)=\inf\{c_e(A;P):P\in\textrm{Part}([a,b])\}$ Def.4: $c_i(A;P)\dot{=}\sum_{I_k \subset A} c(I_k)$ Def.5: $c_i(A)=\lim_{n\rightarrow+\infty}{c_i(A;P_m)}$ Obs.: I'm using that: $P=\{x_0,...,x_n\}$ and $Q=\{y_0,...,y_m\}$. COMMENTS : This is a long exercise of my course or Measure and Integration. I did but I'm afraid of being too informal in some way. I need someone to look at my answer (especially the item d) and help me to write more clearly my reasoning and correct any possible mistake, I feel that this bad. MY ATTEMPT (a) Let $0<\delta<|P|$, $|Q|<\delta$, $Q=\{y_0,...,y_m\}$ and define:             $$ 			\Lambda_1= \{ i \in \{1,...,m\}: [y_{i-1}, y_i] \subset [x_{j-1}, x_j] \textrm{ for some } j\in \{1,...,n\} \} 			$$             $$ 			\Lambda_2= \{ i \in \{1,...,m\}: [y_{i-1}, y_i] \cap \{x_{j-1}, x_j\} \textrm{ for some } j\in\{1,...,n\}  \neq \emptyset\} 			$$             So,              $$ 			c_e(A;Q)=\sum_{I_{k'} \cap A \neq \emptyset}  c(I_{k'})=\sum_Q^* \Delta y_i=\sum_{\Lambda_1}^* \Delta y_i+\sum_{\Lambda_2}^* \Delta y_i 			$$             Define,              $$ 			\Lambda^1_1= \{ i \in \{1,...,n\}: [y_{j-1}, y_j] \subset [x_{i-1}, x_i] \textrm{ for some } j\in \{1,...,m\} \} 			$$             $$ 			\Lambda^1_2= \{ i \in \{1,...,n\}: [y_{j-1}, y_j] \cap \{x_{i-1}, x_i\} \textrm{ for some } j\in\{1,...,m\}  \neq \emptyset\} 			$$             So,              $$ 			c_e(A;P)=\sum_{I_{k} \cap A \neq \emptyset}  c(I_{k})=\sum_P^* \Delta y_i=\sum_{\Lambda_1^1}^* \Delta y_i+\sum_{\Lambda_2^1}^* \Delta y_i 			$$             Note that:             $$ 			\sum_{\Lambda_1}^* \Delta y_i <\sum_{\Lambda_1^1}^* \Delta y_i 			$$             because each $[y_{j-1},y_j] \subset [y_{i-1},y_i]$ and              $$ 			\sum_{\Lambda_2}^* \Delta y_i <\sum_{\Lambda_1^2}^* \Delta y_i 			$$             because $|Q|<\delta$. So, $c_e(A,Q)<c_e(A,P)=\eta$ (b)Let $0<\delta<|P|$, $|Q|<\delta$, $Q=\{y_0,...,y_m\}$. As $\{ \bigcup [x_{i-1}, x_i]:  [x_{i-1}, x_i] \subset A\} \subset \{ \bigcup [y_{j-1}, y_j]:  [y_{j-1}, y_j] \subset A\}$ follows that             $$ 			\eta<c_i(A;P)<c_i(A;Q) 			$$ (c) Note that, for all partition $P$ such that $\eta>c_e(A;P)>0$,let $|P|>\delta>0$ and $0<|Q|<\delta \Rightarrow c_e(A,Q)<\eta$, and using ""(a)"",  $c_e(A;Q)<\eta$. So we can write that $P_m$ with $|P_m| \rightarrow 0$, exists subsequence $P_{i_k}$ such that for all $i_k$             $$ 			c_e(P_{ik})>c_e(P_{i_k+1}) 			$$             So, $ \lim_{n\rightarrow+\infty}{c_e(A,P_m)}=\inf\{c_e(A;P):P\in\textrm{Part}([a,b])\}=c_e(A)$ Now note that, using ""(b)"", for all partition $P$ such that $c_i(A;P)>\eta>0$, let $|P|>\delta>0$ and $0<|Q|<\delta \Rightarrow c_i(A,Q)>\eta$. So we can write that $P_m$ where $|P_m| \rightarrow 0$, exists subsequence $P_{i_k}$ such that for all $i_k$             $$ 			c_i(P_{ik})<c_i(P_{i_k+1}) 			$$             So, $ \lim_{n\rightarrow+\infty}{c_i(A,P_m)}=\sup\{c_e(A;P):P\in\textrm{Part}([a,b])\}=c_i(A)$ (d)$$ c_e(A)-c_e(\partial A)=\lim_{n\rightarrow +\infty}{c_e(A;P_m)}-\lim_{n \rightarrow +\infty}c_e(\partial A;P_m)=$$             $$ 			=\lim_{n\rightarrow+\infty}{c_e(A \backslash \partial A;P_m)}=\lim_{n\rightarrow+\infty} c_i(A,P_m)=c_i(A) 			$$","(a) Suppose that $A \subset [a,b]$ and that exists a partition $P$ of $[a,b]$ such that $c_e(A;P)<\eta$. Show that  exists $\delta>0$ such that, if $Q$ is a partition where $|Q|<\delta$ so $c_e(A;Q)<\eta$ (b)Suppose that $A \subset [a,b]$ and that exists a partition $P$ of $[a,b]$ such that $c_i(A;P)>\eta$. Show that exists $\delta>0$ such that, if $Q$ is a partition where $|Q|<\delta$, so $c_i(A;Q)>\eta$. (c) Show that, if $A\subset [a,b]$ and $\{P_m\}$ are a sequence of partitions of $[a,b]$ such that $|P_m| \rightarrow 0$, so   $$c_e(A)=\lim_{n\rightarrow+\infty}{c_e(A;P_m)}$$$$c_i(A)=\lim_{n\rightarrow+\infty}{c_i(A;P_m)}$$   (d) Show that:    $$c_e(A)=c_i(A)+c_e(\partial A)$$ DEFINITIONS AND ADDITIONAL INFORMATION Def.0: $P$ a partition, so $|P|=\max\{x_{i+1}-x_i: x_i, x_{i+1}\in P\}$ Def.1: $A \subset [a,b]$ is a negligible if, for all $\varepsilon>0$ exists partition $P=\{x_0,...,x_n\}$ of $[a,b]$ such that $\sum_P^*\Delta x_i<\varepsilon$, where this sum are over the indices such that $A \cap [x_{i-1},x_i] \neq \emptyset$ Follows from an exercise in class that:  $A\subset[a,b]$ is negligible is the same that affirm that: for all $\varepsilon>0$ exists $\delta>0$ such that, for all partition $Q$ where $|Q|<\delta$, we have $$\sum_{Q}^* \Delta x_i<\varepsilon$$, where $\sum^*_Q$ denote the sum over the indices such that $A \cap [x_{i-1},x_i] \neq \emptyset$ In this exercise we will generalize this result. Def.2: $c_e(A;P)\dot{=}\sum_{I_k \cap A \neq \emptyset}  c(I_k)=\sum_P^* \Delta x_i$ Def.3: $c_e(A)=\inf\{c_e(A;P):P\in\textrm{Part}([a,b])\}$ Def.4: $c_i(A;P)\dot{=}\sum_{I_k \subset A} c(I_k)$ Def.5: $c_i(A)=\lim_{n\rightarrow+\infty}{c_i(A;P_m)}$ Obs.: I'm using that: $P=\{x_0,...,x_n\}$ and $Q=\{y_0,...,y_m\}$. COMMENTS : This is a long exercise of my course or Measure and Integration. I did but I'm afraid of being too informal in some way. I need someone to look at my answer (especially the item d) and help me to write more clearly my reasoning and correct any possible mistake, I feel that this bad. MY ATTEMPT (a) Let $0<\delta<|P|$, $|Q|<\delta$, $Q=\{y_0,...,y_m\}$ and define:             $$ 			\Lambda_1= \{ i \in \{1,...,m\}: [y_{i-1}, y_i] \subset [x_{j-1}, x_j] \textrm{ for some } j\in \{1,...,n\} \} 			$$             $$ 			\Lambda_2= \{ i \in \{1,...,m\}: [y_{i-1}, y_i] \cap \{x_{j-1}, x_j\} \textrm{ for some } j\in\{1,...,n\}  \neq \emptyset\} 			$$             So,              $$ 			c_e(A;Q)=\sum_{I_{k'} \cap A \neq \emptyset}  c(I_{k'})=\sum_Q^* \Delta y_i=\sum_{\Lambda_1}^* \Delta y_i+\sum_{\Lambda_2}^* \Delta y_i 			$$             Define,              $$ 			\Lambda^1_1= \{ i \in \{1,...,n\}: [y_{j-1}, y_j] \subset [x_{i-1}, x_i] \textrm{ for some } j\in \{1,...,m\} \} 			$$             $$ 			\Lambda^1_2= \{ i \in \{1,...,n\}: [y_{j-1}, y_j] \cap \{x_{i-1}, x_i\} \textrm{ for some } j\in\{1,...,m\}  \neq \emptyset\} 			$$             So,              $$ 			c_e(A;P)=\sum_{I_{k} \cap A \neq \emptyset}  c(I_{k})=\sum_P^* \Delta y_i=\sum_{\Lambda_1^1}^* \Delta y_i+\sum_{\Lambda_2^1}^* \Delta y_i 			$$             Note that:             $$ 			\sum_{\Lambda_1}^* \Delta y_i <\sum_{\Lambda_1^1}^* \Delta y_i 			$$             because each $[y_{j-1},y_j] \subset [y_{i-1},y_i]$ and              $$ 			\sum_{\Lambda_2}^* \Delta y_i <\sum_{\Lambda_1^2}^* \Delta y_i 			$$             because $|Q|<\delta$. So, $c_e(A,Q)<c_e(A,P)=\eta$ (b)Let $0<\delta<|P|$, $|Q|<\delta$, $Q=\{y_0,...,y_m\}$. As $\{ \bigcup [x_{i-1}, x_i]:  [x_{i-1}, x_i] \subset A\} \subset \{ \bigcup [y_{j-1}, y_j]:  [y_{j-1}, y_j] \subset A\}$ follows that             $$ 			\eta<c_i(A;P)<c_i(A;Q) 			$$ (c) Note that, for all partition $P$ such that $\eta>c_e(A;P)>0$,let $|P|>\delta>0$ and $0<|Q|<\delta \Rightarrow c_e(A,Q)<\eta$, and using ""(a)"",  $c_e(A;Q)<\eta$. So we can write that $P_m$ with $|P_m| \rightarrow 0$, exists subsequence $P_{i_k}$ such that for all $i_k$             $$ 			c_e(P_{ik})>c_e(P_{i_k+1}) 			$$             So, $ \lim_{n\rightarrow+\infty}{c_e(A,P_m)}=\inf\{c_e(A;P):P\in\textrm{Part}([a,b])\}=c_e(A)$ Now note that, using ""(b)"", for all partition $P$ such that $c_i(A;P)>\eta>0$, let $|P|>\delta>0$ and $0<|Q|<\delta \Rightarrow c_i(A,Q)>\eta$. So we can write that $P_m$ where $|P_m| \rightarrow 0$, exists subsequence $P_{i_k}$ such that for all $i_k$             $$ 			c_i(P_{ik})<c_i(P_{i_k+1}) 			$$             So, $ \lim_{n\rightarrow+\infty}{c_i(A,P_m)}=\sup\{c_e(A;P):P\in\textrm{Part}([a,b])\}=c_i(A)$ (d)$$ c_e(A)-c_e(\partial A)=\lim_{n\rightarrow +\infty}{c_e(A;P_m)}-\lim_{n \rightarrow +\infty}c_e(\partial A;P_m)=$$             $$ 			=\lim_{n\rightarrow+\infty}{c_e(A \backslash \partial A;P_m)}=\lim_{n\rightarrow+\infty} c_i(A,P_m)=c_i(A) 			$$",,"['real-analysis', 'integration', 'measure-theory', 'lebesgue-measure']"
13,Show identity between product-$\sigma$-algebra and a set,Show identity between product--algebra and a set,\sigma,"Let $T$ be any index set and $(\Omega_i,\mathcal{A}_i)_{i\in T}$ a family of measurable spaces and $\mathcal{A}:=\bigotimes_{i\in T}\mathcal{A}_i$. Show that     $$ \mathcal{A}=\left\{A\subset  \times_{i\in T}\Omega_i | \exists R\subset T\text{ countable} : A\in\pi_R^{-1}\left(\bigotimes_{i\in R}\mathcal{A}_i\right)\right\}=:\mathcal{B}, $$     whereat      $$ \pi_R\colon \times_{i\in T}\Omega_i\to\times_{i\in R}\Omega_i, (\omega_i)_{i\in T}\mapsto (\omega_i)_{i\in R}. $$ (Sorry,  I do not know how to write the big times here so I used the small \times.) Hello! $\subseteq$: My assumption is that $\mathcal{B}$ is a $\sigma$-algebra, is that right? ( Iwas not able to show it yet.) Let $\mathcal{F}(T)$ be the set of the finite subsets of $T$. Then in our lecture we had, that $\mathcal{A}$ is generated by $$ \mathcal{Z}=\mathcal{Z}(\mathcal{A}_t: t\in T):=\bigcup_{S\in\mathcal{F}(T)}\mathcal{Z}_S,~~~\mathcal{Z}_S:=\pi_S^{-1}\left(\bigotimes_{t\in S}\mathcal{A}_t\right), $$ so $\sigma(\mathcal{Z})=\mathcal{A}$. When I see it right, then $\mathcal{Z}\subset \mathcal{B}$. If my assumption that $\mathcal{B}$ is a $\sigma$-Algebra is right, then it follows $\mathcal{A}=\sigma(\mathcal{Z})\subset \mathcal{B}$. $\supseteq$: Consider $A\in \mathcal{B}$. Then there exists a countable $R\subset T$ so that $A\in\pi_R^{-1}\left(\bigotimes_{i\in R}\mathcal{A}_i\right)$. Now I think one has to distinguish (i) $R$ is finite and (ii) $R$ is countably infinite. Case (i): Then $A\in\mathcal{Z}_{R}\subset\mathcal{Z}\subset\sigma(\mathcal{Z})=\mathcal{A}$. I am not able to handle case (ii). Would be great if you could help me.","Let $T$ be any index set and $(\Omega_i,\mathcal{A}_i)_{i\in T}$ a family of measurable spaces and $\mathcal{A}:=\bigotimes_{i\in T}\mathcal{A}_i$. Show that     $$ \mathcal{A}=\left\{A\subset  \times_{i\in T}\Omega_i | \exists R\subset T\text{ countable} : A\in\pi_R^{-1}\left(\bigotimes_{i\in R}\mathcal{A}_i\right)\right\}=:\mathcal{B}, $$     whereat      $$ \pi_R\colon \times_{i\in T}\Omega_i\to\times_{i\in R}\Omega_i, (\omega_i)_{i\in T}\mapsto (\omega_i)_{i\in R}. $$ (Sorry,  I do not know how to write the big times here so I used the small \times.) Hello! $\subseteq$: My assumption is that $\mathcal{B}$ is a $\sigma$-algebra, is that right? ( Iwas not able to show it yet.) Let $\mathcal{F}(T)$ be the set of the finite subsets of $T$. Then in our lecture we had, that $\mathcal{A}$ is generated by $$ \mathcal{Z}=\mathcal{Z}(\mathcal{A}_t: t\in T):=\bigcup_{S\in\mathcal{F}(T)}\mathcal{Z}_S,~~~\mathcal{Z}_S:=\pi_S^{-1}\left(\bigotimes_{t\in S}\mathcal{A}_t\right), $$ so $\sigma(\mathcal{Z})=\mathcal{A}$. When I see it right, then $\mathcal{Z}\subset \mathcal{B}$. If my assumption that $\mathcal{B}$ is a $\sigma$-Algebra is right, then it follows $\mathcal{A}=\sigma(\mathcal{Z})\subset \mathcal{B}$. $\supseteq$: Consider $A\in \mathcal{B}$. Then there exists a countable $R\subset T$ so that $A\in\pi_R^{-1}\left(\bigotimes_{i\in R}\mathcal{A}_i\right)$. Now I think one has to distinguish (i) $R$ is finite and (ii) $R$ is countably infinite. Case (i): Then $A\in\mathcal{Z}_{R}\subset\mathcal{Z}\subset\sigma(\mathcal{Z})=\mathcal{A}$. I am not able to handle case (ii). Would be great if you could help me.",,['measure-theory']
14,Show that a function almost everywhere continuous is measurable,Show that a function almost everywhere continuous is measurable,,"I want to prove that a function $f:\mathbb{R}^n\rightarrow \overline{\mathbb{R}}$ that is continuous everywhere except for a set $E$ of Lebesgue measure zero is a Lebesgue measurable function. We know that $f$ is not continuous, so there are some open sets ${U_k}$ in $\overline{\mathbb{R}}$ such that $f^{-1}(U_k)$ is not open in $\mathbb{R}^n$. But $f^{-1}(U_k)\subseteq E$, and so $f^{-1}(U_k)$ is still measurable because it has measure zero. I don't know if this works, because I'm not sure if $E$ contains actually the preimage of those open sets $U_k$.","I want to prove that a function $f:\mathbb{R}^n\rightarrow \overline{\mathbb{R}}$ that is continuous everywhere except for a set $E$ of Lebesgue measure zero is a Lebesgue measurable function. We know that $f$ is not continuous, so there are some open sets ${U_k}$ in $\overline{\mathbb{R}}$ such that $f^{-1}(U_k)$ is not open in $\mathbb{R}^n$. But $f^{-1}(U_k)\subseteq E$, and so $f^{-1}(U_k)$ is still measurable because it has measure zero. I don't know if this works, because I'm not sure if $E$ contains actually the preimage of those open sets $U_k$.",,"['measure-theory', 'lebesgue-measure']"
15,"How to show that $\{(a,a) : a \in A\}$ is a null set of $A \times A$?",How to show that  is a null set of ?,"\{(a,a) : a \in A\} A \times A","Let $A \subset \mathbb{R}^n$. How do i show that $\{(a,b) : a,b \in A \text{ and } a=b\}$ is a null set of $A\times A$? It is easy to see for intervals but the general case I don't know.","Let $A \subset \mathbb{R}^n$. How do i show that $\{(a,b) : a,b \in A \text{ and } a=b\}$ is a null set of $A\times A$? It is easy to see for intervals but the general case I don't know.",,['measure-theory']
16,Definition of Integral in Measure Theory,Definition of Integral in Measure Theory,,"I am trying to understand how ""the"" general integral is defined in measure theory but I just don't get it. I'm using Friedman's ""Foundations of Modern Analysis"". A simple function $g=\sum \beta_i 1_{E_i}$ is integrable if $\mu(E_i)<\infty$ for all $i$, and the integral of $g$ is $\int g \space d\mu := \sum \beta_i \mu(E_i)$. If $E$ is a measurable set and $f$ an integrable simple function, the integral of $f$ over $E$ is $\int_E f \space d\mu := \int f \space 1_E \space d\mu$. Since $f$ is simple, it can be written as $f=\sum \alpha_i 1_{E_i}$ (for what $E_i$?). We then have $\int_E f \space d\mu= \int 1_E (\sum \alpha_i 1_{E_i})d\mu$. The presence of both $1_E$ and the $1_{E_i}$ causes me some trouble but I think the integral comes out as $\sum \alpha_i \mu(E \cap E_i)$. This is quite constructive. Now then, a measurable function $f:\Box \rightarrow \bar{\mathbb{R}}$ is said to be integrable if there exists a sequence $\{f_n\}$ of simple integrable function such that $\{f_n\}$ is a Cauchy sequence in the mean and $\mathrm{lim} f_n(x)=f(x)$ a.e. (or the sequence converges in measure to $f$). This is not quite as constructive. Forgetting the high school stuff for a moment, none of this really tells me how to integrate even a constant function, how would I do that with the above information? Or is that focusing on the wrong thing? Is the important thing, from a course as this (I assume first courses in measure theory are the same around the world), mainly to learn the qualitative aspects of measure theory and how it encompasses Riemann integration etc, rather than knowing how to do actual integration?","I am trying to understand how ""the"" general integral is defined in measure theory but I just don't get it. I'm using Friedman's ""Foundations of Modern Analysis"". A simple function $g=\sum \beta_i 1_{E_i}$ is integrable if $\mu(E_i)<\infty$ for all $i$, and the integral of $g$ is $\int g \space d\mu := \sum \beta_i \mu(E_i)$. If $E$ is a measurable set and $f$ an integrable simple function, the integral of $f$ over $E$ is $\int_E f \space d\mu := \int f \space 1_E \space d\mu$. Since $f$ is simple, it can be written as $f=\sum \alpha_i 1_{E_i}$ (for what $E_i$?). We then have $\int_E f \space d\mu= \int 1_E (\sum \alpha_i 1_{E_i})d\mu$. The presence of both $1_E$ and the $1_{E_i}$ causes me some trouble but I think the integral comes out as $\sum \alpha_i \mu(E \cap E_i)$. This is quite constructive. Now then, a measurable function $f:\Box \rightarrow \bar{\mathbb{R}}$ is said to be integrable if there exists a sequence $\{f_n\}$ of simple integrable function such that $\{f_n\}$ is a Cauchy sequence in the mean and $\mathrm{lim} f_n(x)=f(x)$ a.e. (or the sequence converges in measure to $f$). This is not quite as constructive. Forgetting the high school stuff for a moment, none of this really tells me how to integrate even a constant function, how would I do that with the above information? Or is that focusing on the wrong thing? Is the important thing, from a course as this (I assume first courses in measure theory are the same around the world), mainly to learn the qualitative aspects of measure theory and how it encompasses Riemann integration etc, rather than knowing how to do actual integration?",,['measure-theory']
17,Approximating a product-measurable function from below,Approximating a product-measurable function from below,,"On page 198 of Dunford and Schwartz, Vol. I, in the proof of part (b) of Lemma III.11.16, the following assertion is made without proof (or reference).  Let $(X,\mathscr{X},\mu)$ and $(Y,\mathscr{Y},\nu)$ be finite measure spaces, and $(X\times Y, \mathscr{X}\otimes\mathscr{Y},\mu\times\nu)$ be their product space.  If $f\colon X\times Y\to [0,\infty)$ is measurable with respect to the product $\sigma$-algebra $\mathscr{X}\otimes\mathscr{Y}$, then $f$ can be approximated a.e. by a sequence $f_n$ of finite linear combinations of characteristic functions of sets of the form $A\times B$, $A\in\mathscr{X}$, $B\in\mathscr{Y}$ (this is standard so far), and one may in addition assume that $f_n\leqslant f $ a.e. for all $n$.  Is this (last statement) entirely obvious?","On page 198 of Dunford and Schwartz, Vol. I, in the proof of part (b) of Lemma III.11.16, the following assertion is made without proof (or reference).  Let $(X,\mathscr{X},\mu)$ and $(Y,\mathscr{Y},\nu)$ be finite measure spaces, and $(X\times Y, \mathscr{X}\otimes\mathscr{Y},\mu\times\nu)$ be their product space.  If $f\colon X\times Y\to [0,\infty)$ is measurable with respect to the product $\sigma$-algebra $\mathscr{X}\otimes\mathscr{Y}$, then $f$ can be approximated a.e. by a sequence $f_n$ of finite linear combinations of characteristic functions of sets of the form $A\times B$, $A\in\mathscr{X}$, $B\in\mathscr{Y}$ (this is standard so far), and one may in addition assume that $f_n\leqslant f $ a.e. for all $n$.  Is this (last statement) entirely obvious?",,['measure-theory']
18,Prove that the $\sigma$ - algebras are equal,Prove that the  - algebras are equal,\sigma,"I want to show that $\sigma$-algebras on $\mathbb{R}$ generated by $(a,b), \ (a,b], [a, b), [a,b], (-\infty, a), (-\infty, a], (b, +\infty), [b, +\infty)$ for $a,b \in \mathbb{R}$ and $a,b \in \mathbb{Q}$ are all equal. Here is what I've come up with so far: ($\mathcal{M} $ - sigma-algebra) Would it suffice to say that $\sigma$-algebras generated by $(a,b), \ (a,b], [a, b), [a,b], \ a,b \in \mathbb{R}$ are the same because $(a,b) \in \mathcal{M} \ \Rightarrow \mathbb{R} \setminus (a,b) = (-\infty, a] \cup [b, +\infty) \in \mathcal{M}$, so $[a,b] = \bigcap_{n \in \mathbb{N_+}} (a-\frac{1}{n}, b+\frac{1}{n}) = \bigcap_{n \in \mathbb{N_+}} (\mathbb{R} \setminus (-\infty, a-\frac{1}{n}] \cup [ b+\frac{1}{n}, +\infty) )=$ $ = \mathbb{R} \setminus(\bigcup_{n \in \mathbb{N_+}}  (-\infty, a-\frac{1}{n}] \cup [ b+\frac{1}{n}, +\infty) ) \in \mathcal{M}$ Similarly, $[a,b) = \bigcap_{n \in \mathbb{N_+}} (a-\frac{1}{n}, b)$, $(a,b] = \bigcap_{n \in \mathbb{N_+}} (a, b +\frac{1}{n})$. When it comes to $(-\infty, a), (-\infty, a], (b, +\infty), [b, +\infty)$ for $a,b \in \mathbb{R}$, would it be enough to say that $(-\infty, a) = \bigcup_{n \in \mathbb{N}}(-n, a)$ and etc? In case of $a,b \in \mathbb{Q}$ would it be all right to say that $\mathbb{Q}$ is dense in $\mathbb{R}$ so for every $r \in \mathbb{R}$ we will find a sequence $\{q_n\}_{n \in \mathbb{N}}$ that converges to $r$, so for example $(r, b) = \bigcup_{n \in \mathbb{N}}(q_n, b)$ ? Could you tell me if my approach is right? Please, help. Thank you.","I want to show that $\sigma$-algebras on $\mathbb{R}$ generated by $(a,b), \ (a,b], [a, b), [a,b], (-\infty, a), (-\infty, a], (b, +\infty), [b, +\infty)$ for $a,b \in \mathbb{R}$ and $a,b \in \mathbb{Q}$ are all equal. Here is what I've come up with so far: ($\mathcal{M} $ - sigma-algebra) Would it suffice to say that $\sigma$-algebras generated by $(a,b), \ (a,b], [a, b), [a,b], \ a,b \in \mathbb{R}$ are the same because $(a,b) \in \mathcal{M} \ \Rightarrow \mathbb{R} \setminus (a,b) = (-\infty, a] \cup [b, +\infty) \in \mathcal{M}$, so $[a,b] = \bigcap_{n \in \mathbb{N_+}} (a-\frac{1}{n}, b+\frac{1}{n}) = \bigcap_{n \in \mathbb{N_+}} (\mathbb{R} \setminus (-\infty, a-\frac{1}{n}] \cup [ b+\frac{1}{n}, +\infty) )=$ $ = \mathbb{R} \setminus(\bigcup_{n \in \mathbb{N_+}}  (-\infty, a-\frac{1}{n}] \cup [ b+\frac{1}{n}, +\infty) ) \in \mathcal{M}$ Similarly, $[a,b) = \bigcap_{n \in \mathbb{N_+}} (a-\frac{1}{n}, b)$, $(a,b] = \bigcap_{n \in \mathbb{N_+}} (a, b +\frac{1}{n})$. When it comes to $(-\infty, a), (-\infty, a], (b, +\infty), [b, +\infty)$ for $a,b \in \mathbb{R}$, would it be enough to say that $(-\infty, a) = \bigcup_{n \in \mathbb{N}}(-n, a)$ and etc? In case of $a,b \in \mathbb{Q}$ would it be all right to say that $\mathbb{Q}$ is dense in $\mathbb{R}$ so for every $r \in \mathbb{R}$ we will find a sequence $\{q_n\}_{n \in \mathbb{N}}$ that converges to $r$, so for example $(r, b) = \bigcup_{n \in \mathbb{N}}(q_n, b)$ ? Could you tell me if my approach is right? Please, help. Thank you.",,"['measure-theory', 'solution-verification']"
19,Showing set not in $M\times M$ for Lebesgue measure,Showing set not in  for Lebesgue measure,M\times M,"Let $M$ be the Lebesgue-measurable subsets of $\mathbb{R}$. Suppose $E\subseteq [0,1]$ and $E\not\in M$. Then I want to show that $E\times\{0\}\not\in M\times M$, where $M\times M$ is the smallest $\sigma$-field generated by the sets $A\times B$ with $A,B\in M$. Well, the $\sigma$-field operations are countable unions, set difference, and complementation. Certainly $E\times\{0\}$ is not of the form $A\times B$ with $A,B\in M$, because $E\not\in M$. But how would I prove $E\times\{0\}\not\in M\times M$? I don't quite see how I could take into account the three operations mentioned above.","Let $M$ be the Lebesgue-measurable subsets of $\mathbb{R}$. Suppose $E\subseteq [0,1]$ and $E\not\in M$. Then I want to show that $E\times\{0\}\not\in M\times M$, where $M\times M$ is the smallest $\sigma$-field generated by the sets $A\times B$ with $A,B\in M$. Well, the $\sigma$-field operations are countable unions, set difference, and complementation. Certainly $E\times\{0\}$ is not of the form $A\times B$ with $A,B\in M$, because $E\not\in M$. But how would I prove $E\times\{0\}\not\in M\times M$? I don't quite see how I could take into account the three operations mentioned above.",,"['real-analysis', 'measure-theory']"
20,Finding simple functions to bound $\frac{xy}{(x^2+y^2)^2}$,Finding simple functions to bound,\frac{xy}{(x^2+y^2)^2},"I want to show that $$ \int\limits_{[0,1]\times[0,1]}\frac{xy}{(x^2+y^2)^2}\,d(\mu\times\mu). $$ equals $\infty$, where $\mu$ is the Lebesgue measure. I've tried to find simple functions that give lower bounds to $\dfrac{xy}{(x^2+y^2)^2}$ in the area close to $(0,0)$. I want to split up $[0,1]\times[0,1]$ into $R_1,R_2,\ldots$, where $R_i$ is the region such that $\dfrac{1}{i+1}\leq \max(x,y)\leq \dfrac{1}{i}$. The area of the region $R_i$ is $\dfrac{2i+1}{i^2(i+1)^2}$. I want to find an lower bound for $\dfrac{xy}{(x^2+y^2)^2}$ in the region $R_i$, so that the eventual sum of the simple function diverges. But I can't seem to find a bound that works.","I want to show that $$ \int\limits_{[0,1]\times[0,1]}\frac{xy}{(x^2+y^2)^2}\,d(\mu\times\mu). $$ equals $\infty$, where $\mu$ is the Lebesgue measure. I've tried to find simple functions that give lower bounds to $\dfrac{xy}{(x^2+y^2)^2}$ in the area close to $(0,0)$. I want to split up $[0,1]\times[0,1]$ into $R_1,R_2,\ldots$, where $R_i$ is the region such that $\dfrac{1}{i+1}\leq \max(x,y)\leq \dfrac{1}{i}$. The area of the region $R_i$ is $\dfrac{2i+1}{i^2(i+1)^2}$. I want to find an lower bound for $\dfrac{xy}{(x^2+y^2)^2}$ in the region $R_i$, so that the eventual sum of the simple function diverges. But I can't seem to find a bound that works.",,"['measure-theory', 'lebesgue-integral']"
21,A neat proof that the Lebesgue measure is rigid motion invariant.,A neat proof that the Lebesgue measure is rigid motion invariant.,,I'm busy doing a small undergraduate maths project on the Banach Tarski paradox and I was hoping I could prove that a lebesgue measure is rigid motion invariant but I can't find an eloquent proof online that isn't too long and cumbersome. I need it to be realtively short because I have a word limit and don't want too much of my project to be devoted to proving something that isn't one of the main results. I was wondering if anybody new of a relatively short self contained proof. If this proof works for $\mathbb{R}^3$ only that would be fine.,I'm busy doing a small undergraduate maths project on the Banach Tarski paradox and I was hoping I could prove that a lebesgue measure is rigid motion invariant but I can't find an eloquent proof online that isn't too long and cumbersome. I need it to be realtively short because I have a word limit and don't want too much of my project to be devoted to proving something that isn't one of the main results. I was wondering if anybody new of a relatively short self contained proof. If this proof works for $\mathbb{R}^3$ only that would be fine.,,"['measure-theory', 'proof-writing']"
22,On differentiability of a certain function,On differentiability of a certain function,,Let $f(x)$ be real-valued continuous function on the real line satisfying $$\sup_{y \in \mathbb{R}}\textrm{ card}(f^{-1}(\{y\}))<\infty$$ where card denotes the cardinality of set. This means there exists certain $N \in \mathbb{N}$ such that $f^{-1}(\{y\})$ contains at most $N$ elements for every $y \in \mathbb{R}$. Now I want to show $f'$ exists almost everywhere (with respect to canonical Lebesgue measure on the real line). I guess the set containing points that cannot be differentiated should be at most countable but have no idea of where to start. Any hint shall be greatly appreciated!,Let $f(x)$ be real-valued continuous function on the real line satisfying $$\sup_{y \in \mathbb{R}}\textrm{ card}(f^{-1}(\{y\}))<\infty$$ where card denotes the cardinality of set. This means there exists certain $N \in \mathbb{N}$ such that $f^{-1}(\{y\})$ contains at most $N$ elements for every $y \in \mathbb{R}$. Now I want to show $f'$ exists almost everywhere (with respect to canonical Lebesgue measure on the real line). I guess the set containing points that cannot be differentiated should be at most countable but have no idea of where to start. Any hint shall be greatly appreciated!,,"['real-analysis', 'measure-theory']"
23,Fixed point set of a measurable map,Fixed point set of a measurable map,,"Let $X$ be a set and  $\Sigma$ be a $\sigma$-algebra on $X$. If $f:X\rightarrow X$ is a measurable map, does it follow that the set of fixed points of $f$ is an element of $\Sigma$. If this not true, what conditions on $X$ and $\Sigma$ can ensure this? Is this true, for example if we let $X$ be a (Hausdorff) topological space and $\Sigma$ be the Borel $\sigma$ algebra?","Let $X$ be a set and  $\Sigma$ be a $\sigma$-algebra on $X$. If $f:X\rightarrow X$ is a measurable map, does it follow that the set of fixed points of $f$ is an element of $\Sigma$. If this not true, what conditions on $X$ and $\Sigma$ can ensure this? Is this true, for example if we let $X$ be a (Hausdorff) topological space and $\Sigma$ be the Borel $\sigma$ algebra?",,['measure-theory']
24,Convergence in $L_1$ and Convergence of the Integrals,Convergence in  and Convergence of the Integrals,L_1,"Am I right with the following argument? (I am a bit confused by all those types of convergence.) Let $f, f_n \in L_1(a,b)$ with $f_n$ converging to $f$ in $L_1$, meaning $$\lVert f_n-f  \rVert_1 = \int_a^b |f_n(x)-f(x)|dx \rightarrow 0 \ , $$ Then the integral $\int_a^b f_n dx$ converges to $\int_a^b f dx$. To show this we look at$$\left| \int_a^b f_n(x) dx - \int_a^b f(x) dx \right | \leq \int_a^b | f_n(x) - f(x)| dx \rightarrow 0 \ .$$ If this is indeed true, is there something similar for the other $L_p(a,b)$ spaces, or is this something special to $L_1(a,b)$?","Am I right with the following argument? (I am a bit confused by all those types of convergence.) Let $f, f_n \in L_1(a,b)$ with $f_n$ converging to $f$ in $L_1$, meaning $$\lVert f_n-f  \rVert_1 = \int_a^b |f_n(x)-f(x)|dx \rightarrow 0 \ , $$ Then the integral $\int_a^b f_n dx$ converges to $\int_a^b f dx$. To show this we look at$$\left| \int_a^b f_n(x) dx - \int_a^b f(x) dx \right | \leq \int_a^b | f_n(x) - f(x)| dx \rightarrow 0 \ .$$ If this is indeed true, is there something similar for the other $L_p(a,b)$ spaces, or is this something special to $L_1(a,b)$?",,"['measure-theory', 'convergence-divergence', 'lp-spaces']"
25,A problem about mollification,A problem about mollification,,"The  problem is : Given $M > 0$ a constant, show that exists  $\phi \in C^{\infty}(R)$ with the following properties: i) $\phi(x) = x , \forall x \in [-M,M] $ ii) $ 0 \leq\varphi^{'}(x) \leq 1,  \forall \  x $ This question arises form my question in the link In the previous link the user 79635 says : let $M$ be a constant , mollifing the function $f(x) =  \min ( \max (x, M+1), -M-1 )$ , you obtain a function $\phi$ with the properties said above. I am trying to do the mollifcation, but i am not getting anywhere. Someone can give me a hand ? Thanks in advance.","The  problem is : Given $M > 0$ a constant, show that exists  $\phi \in C^{\infty}(R)$ with the following properties: i) $\phi(x) = x , \forall x \in [-M,M] $ ii) $ 0 \leq\varphi^{'}(x) \leq 1,  \forall \  x $ This question arises form my question in the link In the previous link the user 79635 says : let $M$ be a constant , mollifing the function $f(x) =  \min ( \max (x, M+1), -M-1 )$ , you obtain a function $\phi$ with the properties said above. I am trying to do the mollifcation, but i am not getting anywhere. Someone can give me a hand ? Thanks in advance.",,"['real-analysis', 'measure-theory', 'partial-differential-equations']"
26,The semifinite portion of a measure $\mu$,The semifinite portion of a measure,\mu,"Let $\mu$ be a measure and define $\mu_1$ such that $\mu(E)=\mu_1(E)$ for $\mu(E)$ finite.  And for $\mu(E)$ infinite definite $\mu_1$ such that: (i) if $E$ contains finite subsets of arbitrarily large measure then $\mu_1(E)=\infty.$ (ii) and if not then $\mu_1(E)=0$. Prove $\mu_1$ is a measure.$$$$ So I'm really having trouble seeing how countable (even finite) additivity holds for sets $E$ such that $\mu(E)=\infty$ but which don't contain finite subsets of arbitrarily large measure.  For instance if $E$ can be partitioned into $A\cup B$ with $\mu(A)=1$ and $\mu(B)=\infty$, then $$0=\mu_1(E)=\mu_1(A\cup B)\neq\mu_1(A)+\mu_1(B)=1 + 0 = 1.$$","Let $\mu$ be a measure and define $\mu_1$ such that $\mu(E)=\mu_1(E)$ for $\mu(E)$ finite.  And for $\mu(E)$ infinite definite $\mu_1$ such that: (i) if $E$ contains finite subsets of arbitrarily large measure then $\mu_1(E)=\infty.$ (ii) and if not then $\mu_1(E)=0$. Prove $\mu_1$ is a measure.$$$$ So I'm really having trouble seeing how countable (even finite) additivity holds for sets $E$ such that $\mu(E)=\infty$ but which don't contain finite subsets of arbitrarily large measure.  For instance if $E$ can be partitioned into $A\cup B$ with $\mu(A)=1$ and $\mu(B)=\infty$, then $$0=\mu_1(E)=\mu_1(A\cup B)\neq\mu_1(A)+\mu_1(B)=1 + 0 = 1.$$",,['measure-theory']
27,"Minimizing the expectation over a set, wrt to the Gaussian measure","Minimizing the expectation over a set, wrt to the Gaussian measure",,"I have recently read a proof [1] where, at the last step, the authors use an inequality which basically amounts to a lower bound on $\int_\mathbb{R} \mathbf{1}_A(x)|x| \phi(x)dx$, where $\phi$ is the Gaussian pdf ($\phi(x)=\frac{e^{-x^2/2}}{\sqrt{2\pi}}$) and $A$ is a Borel set subject to $\int_\mathbb{R} \mathbf{1}_A(x)\phi(x)dx = p$. The bound they use is $p^2/2$; I was wondering if this was tight (up to a constant factor), or if one could improve this to get better than a square dependence on $p$: $$ \min_{A\in\mathcal{B}_\mathbb{R}} \int_\mathbb{R} \mathbf{1}_A(x)|x| \phi(x)dx\qquad\\ \text{s.t.} \int_\mathbb{R} \mathbf{1}_A(x)\phi(x)dx = p $$ Does anyone know if a result of this type is known? Any help or suggestion is welcome. Clement. [1] Theorem 4 of Testing halfspaces In In Proc. 20th Annual Symposium on Discrete Algorithms (SODA (2009) by Kevin Matulef, Rocco A. Servedio, Ronitt Rubinfeld","I have recently read a proof [1] where, at the last step, the authors use an inequality which basically amounts to a lower bound on $\int_\mathbb{R} \mathbf{1}_A(x)|x| \phi(x)dx$, where $\phi$ is the Gaussian pdf ($\phi(x)=\frac{e^{-x^2/2}}{\sqrt{2\pi}}$) and $A$ is a Borel set subject to $\int_\mathbb{R} \mathbf{1}_A(x)\phi(x)dx = p$. The bound they use is $p^2/2$; I was wondering if this was tight (up to a constant factor), or if one could improve this to get better than a square dependence on $p$: $$ \min_{A\in\mathcal{B}_\mathbb{R}} \int_\mathbb{R} \mathbf{1}_A(x)|x| \phi(x)dx\qquad\\ \text{s.t.} \int_\mathbb{R} \mathbf{1}_A(x)\phi(x)dx = p $$ Does anyone know if a result of this type is known? Any help or suggestion is welcome. Clement. [1] Theorem 4 of Testing halfspaces In In Proc. 20th Annual Symposium on Discrete Algorithms (SODA (2009) by Kevin Matulef, Rocco A. Servedio, Ronitt Rubinfeld",,"['measure-theory', 'normal-distribution']"
28,Definition of complete in the context of Lebesgue measurable sets,Definition of complete in the context of Lebesgue measurable sets,,I came across this statement on Lebesgue measurable sets. The Lebesgue measurable sets are said to be complete because every subset of a null set is again measurable and the lebesgue measurable sets are a completion of the Borel sets. What does complete and completion mean in this context? Any help with this doubt is appreciated.,I came across this statement on Lebesgue measurable sets. The Lebesgue measurable sets are said to be complete because every subset of a null set is again measurable and the lebesgue measurable sets are a completion of the Borel sets. What does complete and completion mean in this context? Any help with this doubt is appreciated.,,"['measure-theory', 'definition']"
29,Help! I have proven that the Area of a $1\times 1$ Square is $0$,Help! I have proven that the Area of a  Square is,1\times 1 0,"Let the square $S$ be the set of points $(x,y) \in [0,1]^2$ Let $R \subset S = S \cap \mathbb{Q}^2$, that is, the ""rational pairs"" in the square. To each of these points $r_i \in $ R, we can associate a small square $s_i$ of area $\epsilon / 2^i$, centered at $r_i$. Now the collection $\{s_i\}$ must cover $S$ because if any region of $S$ is uncovered, then that region contains a rational pair that is uncovered which is a contradiction. So since we covered $S$ with a buch of small squares $s_i$, then $\text{area}(S) \le \sum \text{area}(s_i) = \epsilon$ Since $\epsilon$ was arbitrary, the area of a square is $0$! So what went wrong here?","Let the square $S$ be the set of points $(x,y) \in [0,1]^2$ Let $R \subset S = S \cap \mathbb{Q}^2$, that is, the ""rational pairs"" in the square. To each of these points $r_i \in $ R, we can associate a small square $s_i$ of area $\epsilon / 2^i$, centered at $r_i$. Now the collection $\{s_i\}$ must cover $S$ because if any region of $S$ is uncovered, then that region contains a rational pair that is uncovered which is a contradiction. So since we covered $S$ with a buch of small squares $s_i$, then $\text{area}(S) \le \sum \text{area}(s_i) = \epsilon$ Since $\epsilon$ was arbitrary, the area of a square is $0$! So what went wrong here?",,['measure-theory']
30,Lebesgue integration: $f = g$ a.e. $ \Rightarrow \int_\Omega f = \int_\Omega g$,Lebesgue integration:  a.e.,f = g  \Rightarrow \int_\Omega f = \int_\Omega g,"Let $f,g : \Omega \subseteq \mathbb R^n \rightarrow [0,+\infty]$ be measurable functions with $f(x) = g(x)$ a.e. . Then I have to show that $\int_\Omega  f = \int_\Omega g$. I may not assume that $\int_\Omega (f+g) = \int_\Omega f + \int_\Omega g$. This task is from Tao Proposition 19.2.6.","Let $f,g : \Omega \subseteq \mathbb R^n \rightarrow [0,+\infty]$ be measurable functions with $f(x) = g(x)$ a.e. . Then I have to show that $\int_\Omega  f = \int_\Omega g$. I may not assume that $\int_\Omega (f+g) = \int_\Omega f + \int_\Omega g$. This task is from Tao Proposition 19.2.6.",,['real-analysis']
31,"For measurable $f_n : X \to [0, \infty)$ show that $\sum_{n=1}^\infty f_n < \infty$ almost everywhere",For measurable  show that  almost everywhere,"f_n : X \to [0, \infty) \sum_{n=1}^\infty f_n < \infty","Let $f_n : X \to [0 \infty)$ be a sequence of measurable functions on the measure space $(X, \mathcal{F}, \mu)$. Suppose there is an $M > 0$ such that the functions $g_n = f_n\chi_{\{f_n \le M\}}$ satisfy $||g_n||_1 \le An^{-\frac{4}{3}}$ and for which $\mu\{f_n > M\} \le Bn^{-\frac{5}{3}}$. Here, $A$ and $B$ are positive constants independent of $n$. Prove that $h(x) = \displaystyle \sum_{n=1}^\infty f_n(x) < \infty$ for almost all $x \in X$.","Let $f_n : X \to [0 \infty)$ be a sequence of measurable functions on the measure space $(X, \mathcal{F}, \mu)$. Suppose there is an $M > 0$ such that the functions $g_n = f_n\chi_{\{f_n \le M\}}$ satisfy $||g_n||_1 \le An^{-\frac{4}{3}}$ and for which $\mu\{f_n > M\} \le Bn^{-\frac{5}{3}}$. Here, $A$ and $B$ are positive constants independent of $n$. Prove that $h(x) = \displaystyle \sum_{n=1}^\infty f_n(x) < \infty$ for almost all $x \in X$.",,['measure-theory']
32,Absolutely continuous functions with derivatives in $L^p$,Absolutely continuous functions with derivatives in,L^p,"Suppose you have an absolutely continuous function $f$, with derivative $f'\in L^p(\mathbb R)$ for some $p>1$. Then I would like to show that there exist constants $L$ and $\alpha$ such that $$|f(x)-f(y)| \leq L |x-y|^{\alpha}, \forall x,y.$$ Since $f$ is absolutely continuous, we have that $f(x) - f(y) = \int_y^x f'(t) dt$. Then I should maybe use Hölder inequality, but I don't know how to apply it in this case. Any help would be appreciated! Thanks!","Suppose you have an absolutely continuous function $f$, with derivative $f'\in L^p(\mathbb R)$ for some $p>1$. Then I would like to show that there exist constants $L$ and $\alpha$ such that $$|f(x)-f(y)| \leq L |x-y|^{\alpha}, \forall x,y.$$ Since $f$ is absolutely continuous, we have that $f(x) - f(y) = \int_y^x f'(t) dt$. Then I should maybe use Hölder inequality, but I don't know how to apply it in this case. Any help would be appreciated! Thanks!",,"['real-analysis', 'measure-theory']"
33,"Proving a sufficient and necessary condition for $f:\, X\to\mathbb{R}\cup\{\pm\infty\}$ to be measurable",Proving a sufficient and necessary condition for  to be measurable,"f:\, X\to\mathbb{R}\cup\{\pm\infty\}","I saw the following question: Denote $\overline{\mathbb{R}}=\mathbb{R}\cup\{\pm\infty\}$, the open   sets containing $x\in\mathbb{R}$ are the open sets in $\mathbb{R}$   containing $x$. The open sets containing $\pm\infty$ are the sets of   the form $V\cup\{\infty\}$ or $V\cup\{-\infty\}$ accordingly. Let $(X,S)$ be a measurable space. Prove that $f:\,  X\to\overline{\mathbb{R}}$ is measurable iff the following conditions   hold: $f^{-1}(\{\infty\}),f^{-1}(\{-\infty\})\in S$ $f$ is measurable as a function $f^{-1}(\mathbb{R})\to\mathbb{R}$ My work: I started with assuming that both conditions hold and I took some $B\in\mathcal{B}(\overline{\mathbb{R}})$ and I wanted to prove that $f^{-1}(B)\in S$, but the problem I have here that I don't really understand how those sets $B\in\mathcal{B}(\overline{\mathbb{R}})$ look like. So I thought that if I will understand what $S'$ generates $\mathcal{B}(\overline{\mathbb{R}})$ I could use that. I know that the open rays of the form $(-\infty,a)$ or $(a,\infty)$ generate $\mathcal{B}(\mathbb{R})$, and it seems that the sets of the form $(-\infty,a)\cup\{\infty\}$ plus the sets of the form $(a,\infty)\cup\{\infty\}$. Since $$f^{-1}((-\infty,a)\cup\{\infty\})=f^{-1}((-\infty,a))\cup f^{-1}(\{\infty\})$$ and I know that $f^{-1}(\{\infty\})\in S$ and since its a $\sigma-$algebra I need to prove that $f^{-1}((-\infty,a))\in S$. I'm guessing this follows from the second condition somehow, but I don't understand how being measurable in $\mathcal{B}(\overline{\mathbb{R}})$ have anything to do with being in $S$ which is a collection of subsets of some space $X$. Can someone please help me with this question ? am I even on the right track ?","I saw the following question: Denote $\overline{\mathbb{R}}=\mathbb{R}\cup\{\pm\infty\}$, the open   sets containing $x\in\mathbb{R}$ are the open sets in $\mathbb{R}$   containing $x$. The open sets containing $\pm\infty$ are the sets of   the form $V\cup\{\infty\}$ or $V\cup\{-\infty\}$ accordingly. Let $(X,S)$ be a measurable space. Prove that $f:\,  X\to\overline{\mathbb{R}}$ is measurable iff the following conditions   hold: $f^{-1}(\{\infty\}),f^{-1}(\{-\infty\})\in S$ $f$ is measurable as a function $f^{-1}(\mathbb{R})\to\mathbb{R}$ My work: I started with assuming that both conditions hold and I took some $B\in\mathcal{B}(\overline{\mathbb{R}})$ and I wanted to prove that $f^{-1}(B)\in S$, but the problem I have here that I don't really understand how those sets $B\in\mathcal{B}(\overline{\mathbb{R}})$ look like. So I thought that if I will understand what $S'$ generates $\mathcal{B}(\overline{\mathbb{R}})$ I could use that. I know that the open rays of the form $(-\infty,a)$ or $(a,\infty)$ generate $\mathcal{B}(\mathbb{R})$, and it seems that the sets of the form $(-\infty,a)\cup\{\infty\}$ plus the sets of the form $(a,\infty)\cup\{\infty\}$. Since $$f^{-1}((-\infty,a)\cup\{\infty\})=f^{-1}((-\infty,a))\cup f^{-1}(\{\infty\})$$ and I know that $f^{-1}(\{\infty\})\in S$ and since its a $\sigma-$algebra I need to prove that $f^{-1}((-\infty,a))\in S$. I'm guessing this follows from the second condition somehow, but I don't understand how being measurable in $\mathcal{B}(\overline{\mathbb{R}})$ have anything to do with being in $S$ which is a collection of subsets of some space $X$. Can someone please help me with this question ? am I even on the right track ?",,"['real-analysis', 'measure-theory']"
34,Volume is a Continuous Function,Volume is a Continuous Function,,"I am working on the following problem: Suppose $C  \subset \mathbb{R}^d$ is a compact and non-empty set.  Let $C_0 = C$ and let $C_t = \{x \in \mathbb{R}^d : d(x,C) \leq t \}$ for all $t >0$.  Also, let $g(t) = m(C_t)$, where $m$ is the Lebesgue measure. (i)  Prove that g is right continuous. (ii)  Prove that for $t > 0$, the set $\{x \in \mathbb{R}^d : d(x,C) = t \}$ has Lebesgue measure $0$. (iii)  Using part (ii), show that $g$ is also left continuous. For part (i), I am thinking to use the fact that the limit of $m(C_t)$ as $T$ goes to 0 is $m(C)$ (I believe that this is true, for example see a very similar claim in Stein and Shakarchi, Measure Theory, chapter 1 exercise 5).  Also, for part (ii) I believe that a sketch of the proof is the following: consider a point $x_0$ such that $d(x_0,C)=t$ and then show that the density of ${x: d(x_0,C)<t}$ at a is $\geq 1/2$. We then need to apply the Lebesgue Differentiation Theorem to ${ x: d(x,C)=t }$.  I am not sure how to complete this argument.  Thank you.","I am working on the following problem: Suppose $C  \subset \mathbb{R}^d$ is a compact and non-empty set.  Let $C_0 = C$ and let $C_t = \{x \in \mathbb{R}^d : d(x,C) \leq t \}$ for all $t >0$.  Also, let $g(t) = m(C_t)$, where $m$ is the Lebesgue measure. (i)  Prove that g is right continuous. (ii)  Prove that for $t > 0$, the set $\{x \in \mathbb{R}^d : d(x,C) = t \}$ has Lebesgue measure $0$. (iii)  Using part (ii), show that $g$ is also left continuous. For part (i), I am thinking to use the fact that the limit of $m(C_t)$ as $T$ goes to 0 is $m(C)$ (I believe that this is true, for example see a very similar claim in Stein and Shakarchi, Measure Theory, chapter 1 exercise 5).  Also, for part (ii) I believe that a sketch of the proof is the following: consider a point $x_0$ such that $d(x_0,C)=t$ and then show that the density of ${x: d(x_0,C)<t}$ at a is $\geq 1/2$. We then need to apply the Lebesgue Differentiation Theorem to ${ x: d(x,C)=t }$.  I am not sure how to complete this argument.  Thank you.",,"['real-analysis', 'measure-theory', 'geometric-measure-theory']"
35,Variant of the Vitali Covering Lemma,Variant of the Vitali Covering Lemma,,"I am working on the following problem, which is based on a problem from Stein and Shakarchi: Prove the following variant of the Vitali Covering Lemma: If E is a set of finite Lebesgue measure in $\mathbb{R}^n$, then for every $\eta > 0$ there exists a disjoint collection of balls $\{B_j \}^{\infty}_{j=1}$ such that $m(E / \bigcup_{j=1}^\infty B_j) = 0$ and $\sum_{j=1}^\infty m(B_j) \leq (1+\eta)m(E)$. It seems that the best place to start this is to look at Stein and Shakarchi's proof of the Vitali convering lemma (or another proof) and then somehow modify this, although I can't seem to bridge the gap.  Any help with this would be greatly appreciated.  Thank you.","I am working on the following problem, which is based on a problem from Stein and Shakarchi: Prove the following variant of the Vitali Covering Lemma: If E is a set of finite Lebesgue measure in $\mathbb{R}^n$, then for every $\eta > 0$ there exists a disjoint collection of balls $\{B_j \}^{\infty}_{j=1}$ such that $m(E / \bigcup_{j=1}^\infty B_j) = 0$ and $\sum_{j=1}^\infty m(B_j) \leq (1+\eta)m(E)$. It seems that the best place to start this is to look at Stein and Shakarchi's proof of the Vitali convering lemma (or another proof) and then somehow modify this, although I can't seem to bridge the gap.  Any help with this would be greatly appreciated.  Thank you.",,"['real-analysis', 'measure-theory']"
36,Why is the Fourier Transform of a Lévy Process a continuous function? What about the inverse? (Bochners Theorem),Why is the Fourier Transform of a Lévy Process a continuous function? What about the inverse? (Bochners Theorem),,"I was confronted with this question when reading ""Stochastic Integration and Differential Equations"" by Protter. Just after the definition of a Lévy process he says the following: If $X_t$ is a Lévy-process and we consider the function $f_t(u)=\mathbb{E}(e^{iuX_t})$ where $f_0(u)=1$ and $f_{t+s}(u)=f_t(u)f_s(u)$, and $f_t(u) \neq 0$ for every $(t,u)$. Then, using the right continuity in probability we conclude that there exists a continuous function $\psi$ with $\psi(0)=0$ such that $f_t(u)=\text{exp}(-t\psi(u))$. How can one prove this? (Right) continuity in probability seems a rather weak notion to me for the existence of a fully continuous $\psi(u)$. It would mean that also $f_t(u)$ is continuous right? So what we need is that the Fourier transform of a Lévy process is continuous i think. Any hints on that? (Probably its a well-known fact and I am missing something obvious here) In the same section the so-called ""Bochners Theorem"" is also mentioned. Could anyone share a resource for me with the details and the sketch of proof?","I was confronted with this question when reading ""Stochastic Integration and Differential Equations"" by Protter. Just after the definition of a Lévy process he says the following: If $X_t$ is a Lévy-process and we consider the function $f_t(u)=\mathbb{E}(e^{iuX_t})$ where $f_0(u)=1$ and $f_{t+s}(u)=f_t(u)f_s(u)$, and $f_t(u) \neq 0$ for every $(t,u)$. Then, using the right continuity in probability we conclude that there exists a continuous function $\psi$ with $\psi(0)=0$ such that $f_t(u)=\text{exp}(-t\psi(u))$. How can one prove this? (Right) continuity in probability seems a rather weak notion to me for the existence of a fully continuous $\psi(u)$. It would mean that also $f_t(u)$ is continuous right? So what we need is that the Fourier transform of a Lévy process is continuous i think. Any hints on that? (Probably its a well-known fact and I am missing something obvious here) In the same section the so-called ""Bochners Theorem"" is also mentioned. Could anyone share a resource for me with the details and the sketch of proof?",,"['measure-theory', 'stochastic-processes', 'fourier-analysis']"
37,"Prove that $\frac{1}{2h}\int_a^b\mu(A\cap(x-h,x+h))\,\text{d}x\le \mu(A)$",Prove that,"\frac{1}{2h}\int_a^b\mu(A\cap(x-h,x+h))\,\text{d}x\le \mu(A)","I'm preparing to the second mini-test in measure theory. Here is one of the problems I cannot deal with. I would appreciate any help, thank you. Let $\mu$ be a Radon measure on $\mathbb{R}$, suppose that $A$ is a $\mu$–measurable subset of $[a,b]$ and let $h$ be a positive number. Prove that $$\frac{1}{2h}\int_a^b\mu(A\cap(x-h,x+h))\,\text{d}x\le \mu(A).$$","I'm preparing to the second mini-test in measure theory. Here is one of the problems I cannot deal with. I would appreciate any help, thank you. Let $\mu$ be a Radon measure on $\mathbb{R}$, suppose that $A$ is a $\mu$–measurable subset of $[a,b]$ and let $h$ be a positive number. Prove that $$\frac{1}{2h}\int_a^b\mu(A\cap(x-h,x+h))\,\text{d}x\le \mu(A).$$",,['measure-theory']
38,weak convergence $\mathbb{R}^2$,weak convergence,\mathbb{R}^2,"When we have two independent sequences or random variables $\{X_{n}\}$ and $\{Y_{n}\}$ for which $X_{n}$ converges weakly to $X$ ( $X_n \overset{w}{\rightarrow}X$) and $Y_n \overset{w}{\rightarrow}Y$ I want to show that holds $$(X_n,Y_n) \overset{w}{\rightarrow}(X,Y)$$ I know that holds for $f\in C_{b}$:  $\mathbb{E}_{X}f(X_n)\rightarrow \mathbb{E}f(X)$ and the same for $Y$. I want to show that $\mathbb{E}_{X\times Y}f(X_n,Y_n)\rightarrow \mathbb{E}_{X\times Y}f(X,Y)$ As $X_n$ and $Y_n$ are independent I can write $\mathbb{E}_{X\times Y} = \mathbb{E}_X \times \mathbb{E}_Y$, the product measure. So $$\mathbb{E}_{X\times Y}f(X_n,Y_n)=\mathbb{E}_X (X_n,Y_n)\times \mathbb{E}_Y (X_n,Y_n)=\mathbb{E}_{X}(X,Y_{n})\times \mathbb{E}_Y (X_n,Y)$$ I now need some help making the last step to get $\mathbb{E}_{X\times Y}(X,Y)$. Could anyone help me with this? I'd really prefer to do it without using characteristic functions if possible.","When we have two independent sequences or random variables $\{X_{n}\}$ and $\{Y_{n}\}$ for which $X_{n}$ converges weakly to $X$ ( $X_n \overset{w}{\rightarrow}X$) and $Y_n \overset{w}{\rightarrow}Y$ I want to show that holds $$(X_n,Y_n) \overset{w}{\rightarrow}(X,Y)$$ I know that holds for $f\in C_{b}$:  $\mathbb{E}_{X}f(X_n)\rightarrow \mathbb{E}f(X)$ and the same for $Y$. I want to show that $\mathbb{E}_{X\times Y}f(X_n,Y_n)\rightarrow \mathbb{E}_{X\times Y}f(X,Y)$ As $X_n$ and $Y_n$ are independent I can write $\mathbb{E}_{X\times Y} = \mathbb{E}_X \times \mathbb{E}_Y$, the product measure. So $$\mathbb{E}_{X\times Y}f(X_n,Y_n)=\mathbb{E}_X (X_n,Y_n)\times \mathbb{E}_Y (X_n,Y_n)=\mathbb{E}_{X}(X,Y_{n})\times \mathbb{E}_Y (X_n,Y)$$ I now need some help making the last step to get $\mathbb{E}_{X\times Y}(X,Y)$. Could anyone help me with this? I'd really prefer to do it without using characteristic functions if possible.",,"['measure-theory', 'convergence-divergence', 'weak-convergence']"
39,A question on semifinite measures,A question on semifinite measures,,"First, I give the definition from Folland, Definition: Let $(X, \mathcal{M}, \mu)$ be a measure space. If for   each $E \in \mathcal{M}$ with $\mu(E) = \infty$, there exists $F \in \mathcal{M}$ with $F \subset E$ and $0 < \mu(F) < \infty$, $\mu$ is   called semifinite. Now problem: Let X be any nonempty set, $\mathcal{M} = \mathcal{P}(X)$, and $f$ any function from $X$ to $[0, \infty]$. Then $f$ determines a measure $\mu$ on $\mathcal{M}$ by the formula $\mu(E) = \sum_{x \in E} f(x)$. In the later paragraph, Folland states that, The reader may verify that $\mu$ is semifinite iff $f(x) < \infty$ for every $x \in X$. I ask that, how to verify that? Thanks.","First, I give the definition from Folland, Definition: Let $(X, \mathcal{M}, \mu)$ be a measure space. If for   each $E \in \mathcal{M}$ with $\mu(E) = \infty$, there exists $F \in \mathcal{M}$ with $F \subset E$ and $0 < \mu(F) < \infty$, $\mu$ is   called semifinite. Now problem: Let X be any nonempty set, $\mathcal{M} = \mathcal{P}(X)$, and $f$ any function from $X$ to $[0, \infty]$. Then $f$ determines a measure $\mu$ on $\mathcal{M}$ by the formula $\mu(E) = \sum_{x \in E} f(x)$. In the later paragraph, Folland states that, The reader may verify that $\mu$ is semifinite iff $f(x) < \infty$ for every $x \in X$. I ask that, how to verify that? Thanks.",,['real-analysis']
40,The General Lebesgue Integral,The General Lebesgue Integral,,"For a measurable function, $f$, on $[1, \infty)$ which is bounded on bounded sets, define $a_n = \int_n^{n+1} f$ for each natural number $n$. Is it true that $f$ is integrable over $[1, \infty)$ if and only if the series $\sum_{n=1}^\infty a_n$ converges? Is it true that $f$ is integrable over $[1, \infty)$ if and only if the series $\sum_{n=1}^\infty a_n$ converges absolutely? Here is what I am thinking: Let $\sum_1^\infty a_n$ be convergent. $\sum_1^\infty a_n$ = $\sum_1^\infty (\int_n^{n+1}f)$. Since n are natural numbers, $n<n+1$, then $\sum_1^\infty (\int_n^{n+1}f)$ = $\int_1^2 f + \int_2^3 f + $... = $ \int_1^\infty f$. Can we say then, that since f is measurable on $[1, \infty)$ and bounded that ${f_n} -> {f}$ a.e. and by the Lebesgue Dominated Convergence Theorem, f is integrable? Conversely, let f be integrable over $[1, \infty)$. Given the above is true. To show for absolute convergence we would need to show for $\sum_1^\infty |a_n|$. Am I headed in the right direction?","For a measurable function, $f$, on $[1, \infty)$ which is bounded on bounded sets, define $a_n = \int_n^{n+1} f$ for each natural number $n$. Is it true that $f$ is integrable over $[1, \infty)$ if and only if the series $\sum_{n=1}^\infty a_n$ converges? Is it true that $f$ is integrable over $[1, \infty)$ if and only if the series $\sum_{n=1}^\infty a_n$ converges absolutely? Here is what I am thinking: Let $\sum_1^\infty a_n$ be convergent. $\sum_1^\infty a_n$ = $\sum_1^\infty (\int_n^{n+1}f)$. Since n are natural numbers, $n<n+1$, then $\sum_1^\infty (\int_n^{n+1}f)$ = $\int_1^2 f + \int_2^3 f + $... = $ \int_1^\infty f$. Can we say then, that since f is measurable on $[1, \infty)$ and bounded that ${f_n} -> {f}$ a.e. and by the Lebesgue Dominated Convergence Theorem, f is integrable? Conversely, let f be integrable over $[1, \infty)$. Given the above is true. To show for absolute convergence we would need to show for $\sum_1^\infty |a_n|$. Am I headed in the right direction?",,"['real-analysis', 'measure-theory', 'convergence-divergence', 'lebesgue-integral']"
41,Limit and Lebesgue integral in a compact,Limit and Lebesgue integral in a compact,,"I have problem with the exercise that follows. Let $(z_m)_m \in R^n$ so that $\Vert z_m \Vert \rightarrow \infty$ when $m\to \infty$.   Let $f:R^n \rightarrow [-\infty;+\infty]$ integrable. Show that if $K \subset R^n$ is a compact $\lim_{m\rightarrow\infty} \int_{z_m+K}f d\lambda=0$. I manage to find the result for $\vert f \vert$. But I can find a way to get to result for f, as asked in the exercise.I thought about using the result for $\vert f \vert$ but then I stuck..so maybe there's another way If someone can help me. Update: Also because then I've another problem related to the first one and I found a way to show it related to the exercise before with $\vert f \vert$ instead of $f$.But maybe there's a better way to show it.","I have problem with the exercise that follows. Let $(z_m)_m \in R^n$ so that $\Vert z_m \Vert \rightarrow \infty$ when $m\to \infty$.   Let $f:R^n \rightarrow [-\infty;+\infty]$ integrable. Show that if $K \subset R^n$ is a compact $\lim_{m\rightarrow\infty} \int_{z_m+K}f d\lambda=0$. I manage to find the result for $\vert f \vert$. But I can find a way to get to result for f, as asked in the exercise.I thought about using the result for $\vert f \vert$ but then I stuck..so maybe there's another way If someone can help me. Update: Also because then I've another problem related to the first one and I found a way to show it related to the exercise before with $\vert f \vert$ instead of $f$.But maybe there's a better way to show it.",,"['measure-theory', 'convergence-divergence', 'lebesgue-integral']"
42,Knopp's Lemma - Show T is ergodic,Knopp's Lemma - Show T is ergodic,,"Be $\beta > 1$ non-integer. $T_{\beta}: [0,1)\rightarrow[0,1)$ with $T_{\beta}x = \beta x$ mod$(1) = \beta x-\lfloor\beta x\rfloor$. Show with Knopp's Lemma that $T_{\beta}$ is ergodic with respect to $\lambda$ Lebesgue measure. (If $T_{\beta}^{-1}A = A$, then $\lambda(A)=0$ or $1$). $\underline{\textrm{Knopp's Lemma:}}$ $B$ Lebesgue set. $\mathscr{C}$ is class of subintervals of $[0,1)$ with a) $\forall$ open subinterval of $[0,1)$ is at most a countable union of disjoint elements from $\mathscr{C}$ b) $\forall A\in\mathscr{C}$: $\lambda(A\cap B)\geq \gamma\lambda(A)$ with $\gamma>0$ independent of A. Then $\lambda(B)=1$.","Be $\beta > 1$ non-integer. $T_{\beta}: [0,1)\rightarrow[0,1)$ with $T_{\beta}x = \beta x$ mod$(1) = \beta x-\lfloor\beta x\rfloor$. Show with Knopp's Lemma that $T_{\beta}$ is ergodic with respect to $\lambda$ Lebesgue measure. (If $T_{\beta}^{-1}A = A$, then $\lambda(A)=0$ or $1$). $\underline{\textrm{Knopp's Lemma:}}$ $B$ Lebesgue set. $\mathscr{C}$ is class of subintervals of $[0,1)$ with a) $\forall$ open subinterval of $[0,1)$ is at most a countable union of disjoint elements from $\mathscr{C}$ b) $\forall A\in\mathscr{C}$: $\lambda(A\cap B)\geq \gamma\lambda(A)$ with $\gamma>0$ independent of A. Then $\lambda(B)=1$.",,"['measure-theory', 'ergodic-theory']"
43,Using LDCT to show a function is continuous and differentiable,Using LDCT to show a function is continuous and differentiable,,"We have the following test prep question, for a measure theory course: $\forall s\geq 0$, define $$F(s)=\int_0^\infty \frac{\sin(x)}{x}e^{-sx}\ dx.$$ a) Show that, for $s>0$, $F$ is differentiable and find explicitly its derivative. b) Keeping in mind that $$F(s)=\int_0^\pi \frac{\sin(x)}{x}e^{-sx}\ \ dx\ +\int_\pi^\infty \frac{\sin(x)}{x}e^{-sx}\ dx,$$ and conveniently doing integration by parts on the second integral on the right hand side of the previous equation, show that $F(s)$ is continuous at $s=0$.  Calculate $F(s)\ (s\geq 0)$. Since it's a measure theory course, I'm thinking there are methods involving the things you typically learn in these courses, and I think Lebesgue's Dominated Convergence Theorem will play a role, because I was looking at books by Bartle and Apostol, and they both have similar exercises or theorems, and both use LDCT. Also, I suppose these proofs regarding continuity or differentiability could be done with standard calculus stuff (like $\epsilon$'s and $\delta$'s or the actual definition of a derivative), but I want to avoid these methods and focus on what I should be learning from the class. I think I have part (a), or at least a good idea, based on the Bartle book.  If I let $f(x,s)=\frac{\sin(x)}{x}e^{-sx}$, I just need to find an integrable function $g$ such that $\big|\frac{\partial f}{\partial s}\big|\leq g(x)$ (after showing that partial does exist, of course :) ). And then, $$\frac d{ds}F(s)=\int _{\mathbb{R}^+}\frac{\partial f}{\partial s}\ dx.$$ Please correct me if I'm mistaken, or missing something. Now, for part (b) I'm a little stumped.  In the Apostol book, the case $s>0$ is done explicitly, but I read through it and it didn't help me.  Looking at the Bartle book, I get the idea of defining $f_n=(x,s_n)$, where $s_n=\frac1{n+1}$ or some such sequence that goes to zero.  Then, somehow, maybe, LDCT kicks in (but I guess I'd have to find a function what would dominate these $f_n$).  I also don't really see the point in dividing the integral into the two parts up there, so I must be missing something.","We have the following test prep question, for a measure theory course: $\forall s\geq 0$, define $$F(s)=\int_0^\infty \frac{\sin(x)}{x}e^{-sx}\ dx.$$ a) Show that, for $s>0$, $F$ is differentiable and find explicitly its derivative. b) Keeping in mind that $$F(s)=\int_0^\pi \frac{\sin(x)}{x}e^{-sx}\ \ dx\ +\int_\pi^\infty \frac{\sin(x)}{x}e^{-sx}\ dx,$$ and conveniently doing integration by parts on the second integral on the right hand side of the previous equation, show that $F(s)$ is continuous at $s=0$.  Calculate $F(s)\ (s\geq 0)$. Since it's a measure theory course, I'm thinking there are methods involving the things you typically learn in these courses, and I think Lebesgue's Dominated Convergence Theorem will play a role, because I was looking at books by Bartle and Apostol, and they both have similar exercises or theorems, and both use LDCT. Also, I suppose these proofs regarding continuity or differentiability could be done with standard calculus stuff (like $\epsilon$'s and $\delta$'s or the actual definition of a derivative), but I want to avoid these methods and focus on what I should be learning from the class. I think I have part (a), or at least a good idea, based on the Bartle book.  If I let $f(x,s)=\frac{\sin(x)}{x}e^{-sx}$, I just need to find an integrable function $g$ such that $\big|\frac{\partial f}{\partial s}\big|\leq g(x)$ (after showing that partial does exist, of course :) ). And then, $$\frac d{ds}F(s)=\int _{\mathbb{R}^+}\frac{\partial f}{\partial s}\ dx.$$ Please correct me if I'm mistaken, or missing something. Now, for part (b) I'm a little stumped.  In the Apostol book, the case $s>0$ is done explicitly, but I read through it and it didn't help me.  Looking at the Bartle book, I get the idea of defining $f_n=(x,s_n)$, where $s_n=\frac1{n+1}$ or some such sequence that goes to zero.  Then, somehow, maybe, LDCT kicks in (but I guess I'd have to find a function what would dominate these $f_n$).  I also don't really see the point in dividing the integral into the two parts up there, so I must be missing something.",,"['measure-theory', 'integration', 'derivatives', 'continuity']"
44,Equality in the Isoperimetric Inequality,Equality in the Isoperimetric Inequality,,"Stein and Shakarchi, in their book Real Analysis , the third volume of the Princeton Lectures in Analysis series, give a proof of the isoperimetric inequality for closed rectifiable curves in $\mathbb{R}^2$ using the Brunn-Minkowski inequality. The argument may be found here: http://mathproblems123.wordpress.com/2012/05/09/minkowski-content-and-the-isoperimetric-inequality/ My question: How does one establish that equality holds if and only if the region is a disk? The ""if"" part is of course trivial, so really I am concerned about the ""only if"" part.","Stein and Shakarchi, in their book Real Analysis , the third volume of the Princeton Lectures in Analysis series, give a proof of the isoperimetric inequality for closed rectifiable curves in $\mathbb{R}^2$ using the Brunn-Minkowski inequality. The argument may be found here: http://mathproblems123.wordpress.com/2012/05/09/minkowski-content-and-the-isoperimetric-inequality/ My question: How does one establish that equality holds if and only if the region is a disk? The ""if"" part is of course trivial, so really I am concerned about the ""only if"" part.",,"['measure-theory', 'inequality', 'optimization', 'geometric-measure-theory']"
45,"product sigma algebra, approximation by simple functions","product sigma algebra, approximation by simple functions",,"For $i=1,2$, let $\Sigma_i$ be two $\sigma$-algebras of subsets of some sets $S_i$. Denote by $\Sigma_1\otimes\Sigma_2$ their product $\sigma$-algebra. It is well known that any bounded, $\Sigma_1\otimes\Sigma_2$-measurable function can be approximated in the $\sup$-norm  by simple functions $\sum_{k=1}^{n}a_k\cdot 1_{A_k}$, where $A_k\in \Sigma_1\otimes\Sigma_2$. Let $A\in \Sigma_1\otimes\Sigma_2$. Is it possible to approximate the characteristic function $1_A$ by simple functions of the form $1_{E\times F}$, where $E\in\Sigma_1$ and $F\in\Sigma_2$, i.e. for any $\varepsilon>0$, does there exist $n\in\mathbb{N}$, real numbers $a_1,...,a_n\in\mathbb{R}$ and sets $E_k\times F_k\in \Sigma_1\times\Sigma_2$, $k=1,...,n$ such that $$\sup_{(x,y)\in S_1\times S_2}\vert1_A(x,y)-\sum_{k=1}^{n}a_k\cdot 1_{E_k\times F_k}(x,y)\vert <\varepsilon\ ?$$","For $i=1,2$, let $\Sigma_i$ be two $\sigma$-algebras of subsets of some sets $S_i$. Denote by $\Sigma_1\otimes\Sigma_2$ their product $\sigma$-algebra. It is well known that any bounded, $\Sigma_1\otimes\Sigma_2$-measurable function can be approximated in the $\sup$-norm  by simple functions $\sum_{k=1}^{n}a_k\cdot 1_{A_k}$, where $A_k\in \Sigma_1\otimes\Sigma_2$. Let $A\in \Sigma_1\otimes\Sigma_2$. Is it possible to approximate the characteristic function $1_A$ by simple functions of the form $1_{E\times F}$, where $E\in\Sigma_1$ and $F\in\Sigma_2$, i.e. for any $\varepsilon>0$, does there exist $n\in\mathbb{N}$, real numbers $a_1,...,a_n\in\mathbb{R}$ and sets $E_k\times F_k\in \Sigma_1\times\Sigma_2$, $k=1,...,n$ such that $$\sup_{(x,y)\in S_1\times S_2}\vert1_A(x,y)-\sum_{k=1}^{n}a_k\cdot 1_{E_k\times F_k}(x,y)\vert <\varepsilon\ ?$$",,['measure-theory']
46,Dirac measure and counting measure,Dirac measure and counting measure,,"Let $X$ be a nonempty set. I would like hints in showing the following: (a) every extended real valued function on $X$ is measurable with respect to the measurable space  $(X,2^X)$. (b) Let $x\in X$. Let $\delta_x$ be the Dirac measure at $x$ on $2^X$. Then two functions on $X$ are equal almost everywhere $[\delta_x]$ if and only if they take the same value at $x$. (c) Let $\alpha$ be the counting measure on $2^X$. Then two functions on $X$ are equal almost everywhere $[\alpha]$ if and only if they take the same value at every point in $X$. Following Davide's hints, (a) Let $\mathcal{B}=2^X$. Then $2^X$ is a sigma algebra and by definition the if $(X,2^X)$ is a measure space, then $f:X\to \overline{\mathbb{R}}$ is measurable since the the set $\{x\in X : f(x) < c\} \in 2^X$ for every $c\in \mathbb{R}$. (b) Here, it suffices to show that the sets which have measure zero are the sets which does not contain $x$. So suppose $f=g$ a.e. then there is a set $N$ with measure zero such that $A=\{x\in X : f(x)\ne g(x)\} \subset N$. But these are precisely those  points which don't contain $x$. So $f(x)=g(x)$ on $N^c$. (c) By definition of the counting measure , the empty set is the only set with counting measure zero. So $f=g$ a.e. $\Leftrightarrow f(x)=g(x)$ at every point in $X$.","Let $X$ be a nonempty set. I would like hints in showing the following: (a) every extended real valued function on $X$ is measurable with respect to the measurable space  $(X,2^X)$. (b) Let $x\in X$. Let $\delta_x$ be the Dirac measure at $x$ on $2^X$. Then two functions on $X$ are equal almost everywhere $[\delta_x]$ if and only if they take the same value at $x$. (c) Let $\alpha$ be the counting measure on $2^X$. Then two functions on $X$ are equal almost everywhere $[\alpha]$ if and only if they take the same value at every point in $X$. Following Davide's hints, (a) Let $\mathcal{B}=2^X$. Then $2^X$ is a sigma algebra and by definition the if $(X,2^X)$ is a measure space, then $f:X\to \overline{\mathbb{R}}$ is measurable since the the set $\{x\in X : f(x) < c\} \in 2^X$ for every $c\in \mathbb{R}$. (b) Here, it suffices to show that the sets which have measure zero are the sets which does not contain $x$. So suppose $f=g$ a.e. then there is a set $N$ with measure zero such that $A=\{x\in X : f(x)\ne g(x)\} \subset N$. But these are precisely those  points which don't contain $x$. So $f(x)=g(x)$ on $N^c$. (c) By definition of the counting measure , the empty set is the only set with counting measure zero. So $f=g$ a.e. $\Leftrightarrow f(x)=g(x)$ at every point in $X$.",,"['real-analysis', 'measure-theory']"
47,Cardinality of Sigma Algebra,Cardinality of Sigma Algebra,,"I had some doubt with my proof, but I'll list the question here along with the proof: Claim: Show that the cardinality of a finite $\sigma$-algebra $\mathfrak{M}$ on a set $X$ is $2^n$ for $n \in \mathbb{N}$. Describe the exponent $n$ in terms of $\sigma$-algebra. Proof: For each member in $\mathfrak{M}$, we can pair it with its complement by properties of $\mathfrak{M}$. This pairing gives a specific partition. Using this idea, we can pick any combination of members of $X$ such that these sets of members of $X$ forms a partition of $X$.  Just observing the collection of partitions of $X$, we consider the partition which has the most cells by superimposing all of the partition on top of each other. So suppose there are $n$ cells for a specific partition of $X$. Let $S$ be the set that contains these $n$ cells. So $\mathcal{P}(S) = 2^n$, where $n$ is the maximum number of cells one can achieve through all possible partition of $X$. From $\mathcal{P}(S)$, we get the other partition of $X$. Hence, $S$ generates $\mathfrak{M}$. On a similar note, there's a question that is similar to the one I am posing: If we are given any infinite ($|\mathfrak{M}| =$ is infinite) $\sigma$-algebra $\mathfrak{M}$ on set $X$, then there is a subset with cardinality of the real numbers $2^{\aleph_{0}}$. Proof: I don't think my argument would work in the infinite case, but I'll give it a go. So I thought that $\mathfrak{M}$ has infinitely many partition of $X$, so if we were to countably infinitely take intersection of the partitions of $X$, we get a countably infinite cells of a partition of $X$. Using the argument by the previous problem, we take the power set of the natural number, which gives us $2^{\aleph_{0}}$. For some reason, I am unsure how this infinite case would work out. -Thanks in advance","I had some doubt with my proof, but I'll list the question here along with the proof: Claim: Show that the cardinality of a finite $\sigma$-algebra $\mathfrak{M}$ on a set $X$ is $2^n$ for $n \in \mathbb{N}$. Describe the exponent $n$ in terms of $\sigma$-algebra. Proof: For each member in $\mathfrak{M}$, we can pair it with its complement by properties of $\mathfrak{M}$. This pairing gives a specific partition. Using this idea, we can pick any combination of members of $X$ such that these sets of members of $X$ forms a partition of $X$.  Just observing the collection of partitions of $X$, we consider the partition which has the most cells by superimposing all of the partition on top of each other. So suppose there are $n$ cells for a specific partition of $X$. Let $S$ be the set that contains these $n$ cells. So $\mathcal{P}(S) = 2^n$, where $n$ is the maximum number of cells one can achieve through all possible partition of $X$. From $\mathcal{P}(S)$, we get the other partition of $X$. Hence, $S$ generates $\mathfrak{M}$. On a similar note, there's a question that is similar to the one I am posing: If we are given any infinite ($|\mathfrak{M}| =$ is infinite) $\sigma$-algebra $\mathfrak{M}$ on set $X$, then there is a subset with cardinality of the real numbers $2^{\aleph_{0}}$. Proof: I don't think my argument would work in the infinite case, but I'll give it a go. So I thought that $\mathfrak{M}$ has infinitely many partition of $X$, so if we were to countably infinitely take intersection of the partitions of $X$, we get a countably infinite cells of a partition of $X$. Using the argument by the previous problem, we take the power set of the natural number, which gives us $2^{\aleph_{0}}$. For some reason, I am unsure how this infinite case would work out. -Thanks in advance",,['measure-theory']
48,"A Lebesgue measure question involving a dense subset of R, translates of a measurable set, etc.","A Lebesgue measure question involving a dense subset of R, translates of a measurable set, etc.",,"Let $\{b_n\}_{n=1}^\infty$ be a dense subset of $\mathbb{R}$ and let $D \subseteq \mathbb{R}$ be a measurable set such that $m(D \triangle (D + b_n))=0$ for all $n \in \mathbb{N}$ (here, the $\triangle$ denotes the symmetric difference of the two sets, $D+ b_n = \{d + b_n : d \in D\}$, and $m$ stands for the Lebesgue measure). Prove that $m(D)=0$ or $m(D^c)=0$ (here $D^c$ is the complement of $D$ in  $\mathbb{R}$). I am having trouble getting a proof off the ground! In particular, it is not clear to me how and where the dense hypothesis would come in. Any help would be greatly appreciated.","Let $\{b_n\}_{n=1}^\infty$ be a dense subset of $\mathbb{R}$ and let $D \subseteq \mathbb{R}$ be a measurable set such that $m(D \triangle (D + b_n))=0$ for all $n \in \mathbb{N}$ (here, the $\triangle$ denotes the symmetric difference of the two sets, $D+ b_n = \{d + b_n : d \in D\}$, and $m$ stands for the Lebesgue measure). Prove that $m(D)=0$ or $m(D^c)=0$ (here $D^c$ is the complement of $D$ in  $\mathbb{R}$). I am having trouble getting a proof off the ground! In particular, it is not clear to me how and where the dense hypothesis would come in. Any help would be greatly appreciated.",,['measure-theory']
49,Is $f$ non-decreasing a.e. if its primitive is convex?,Is  non-decreasing a.e. if its primitive is convex?,f,"The subsequent statement can be regarded as a follow-up to If $\int_0^x f \ dm$ is zero everywhere then $f$ is zero almost everywhere Is $f$ non-negative a.e. if its primitive is non-decreasing? Let $f:[a,b]\to\mathbb{R}$ be Lebesgue integrable.   Furthemore, let   $$ g:[a,b]\ni x\mapsto\int_a^x f(t)\,\mathrm{d}t\in\mathbb{R} $$   be convex. Then $f$ is non-decreasing almost everywhere. Let $a\le x_0<x_1<x_2\le b$. Since $f$ is convex, we have $$ \frac{g(x_2)-g(x_1)}{x_2-x_1}-\frac{g(x_1)-g(x_0)}{x_1-x_0}\ge 0\text{.} $$ This can be reduced to $$ \int_{x_1}^{x_2} \frac{f(t)}{x_2-x_1}\,\mathrm{d}t \ge\int_{x_0}^{x_1} \frac{f(t)}{x_1-x_0}\,\mathrm{d}t\text{.} $$ The last formula roughly shows that the 'average' $f$ on $[x_0,x_1]$ does not exceed the 'average' of $f$ on $[x_1,x_2]$. Do you know a rigorous argument showing that $f$ is non-decreasing a.e.?","The subsequent statement can be regarded as a follow-up to If $\int_0^x f \ dm$ is zero everywhere then $f$ is zero almost everywhere Is $f$ non-negative a.e. if its primitive is non-decreasing? Let $f:[a,b]\to\mathbb{R}$ be Lebesgue integrable.   Furthemore, let   $$ g:[a,b]\ni x\mapsto\int_a^x f(t)\,\mathrm{d}t\in\mathbb{R} $$   be convex. Then $f$ is non-decreasing almost everywhere. Let $a\le x_0<x_1<x_2\le b$. Since $f$ is convex, we have $$ \frac{g(x_2)-g(x_1)}{x_2-x_1}-\frac{g(x_1)-g(x_0)}{x_1-x_0}\ge 0\text{.} $$ This can be reduced to $$ \int_{x_1}^{x_2} \frac{f(t)}{x_2-x_1}\,\mathrm{d}t \ge\int_{x_0}^{x_1} \frac{f(t)}{x_1-x_0}\,\mathrm{d}t\text{.} $$ The last formula roughly shows that the 'average' $f$ on $[x_0,x_1]$ does not exceed the 'average' of $f$ on $[x_1,x_2]$. Do you know a rigorous argument showing that $f$ is non-decreasing a.e.?",,"['real-analysis', 'integration', 'measure-theory']"
50,"If $G$ is a locally compact Hausdorff group, when does $G/Z$ have a probability Haar measure?","If  is a locally compact Hausdorff group, when does  have a probability Haar measure?",G G/Z,"I am reading an introductory material about topological groups and the question in the tittle comes up. Due this Proposition Proposition. A locally compact Hausdorff topological group $G$ is compact, if and only if, $\mu(G)<+\infty\qquad $ ($\mu$ is the Haar measure of $G$). it is enough to know what are the groups $G$ for which $G/Z$, where $Z$ is the center of $G$, is a compact group. Are those groups well-known ?","I am reading an introductory material about topological groups and the question in the tittle comes up. Due this Proposition Proposition. A locally compact Hausdorff topological group $G$ is compact, if and only if, $\mu(G)<+\infty\qquad $ ($\mu$ is the Haar measure of $G$). it is enough to know what are the groups $G$ for which $G/Z$, where $Z$ is the center of $G$, is a compact group. Are those groups well-known ?",,"['measure-theory', 'topological-groups']"
51,"Are two interpretations of ""differentiation of measures"" related?","Are two interpretations of ""differentiation of measures"" related?",,"As Wikipedia mentioned, there are two interpretation of "" differentiation of measures "": the problem of differentiation of integrals , also known as the differentiation problem for measures; the Radon–Nikodym derivative of one measure with respect to another. I was wondering if they are related to each other, or unrelated concepts? if there are other concepts that can also be viewed as differentiation of measures? Thanks and regards!","As Wikipedia mentioned, there are two interpretation of "" differentiation of measures "": the problem of differentiation of integrals , also known as the differentiation problem for measures; the Radon–Nikodym derivative of one measure with respect to another. I was wondering if they are related to each other, or unrelated concepts? if there are other concepts that can also be viewed as differentiation of measures? Thanks and regards!",,"['integration', 'measure-theory']"
52,Stochastics problem: give an example,Stochastics problem: give an example,,"Give an example on $\Omega = \{a, b, c\}$ in which $E(E(X|F_{1})|F_{2}) \neq E(E(X|F_{2})|F_{1})$ -- Obviously X is a random variable and $F_{1}$ and $F_{2}$ are sigma-algebras... but I'm not even sure how to get started on the actual example. Any help is appreciated. Thanks.","Give an example on $\Omega = \{a, b, c\}$ in which $E(E(X|F_{1})|F_{2}) \neq E(E(X|F_{2})|F_{1})$ -- Obviously X is a random variable and $F_{1}$ and $F_{2}$ are sigma-algebras... but I'm not even sure how to get started on the actual example. Any help is appreciated. Thanks.",,"['stochastic-processes', 'measure-theory']"
53,Absolute continuity of measures,Absolute continuity of measures,,"Suppose $u$ and $v$ are measures on a measurable space $E$. Further suppose $u$ is finite and absolutely continuous with respect to v ($v(S)=0 \implies u(S)=0$). The problem is: Show that $\forall \epsilon>0 \;\;\;\exists \delta: v(S)<\delta \implies u(S)<\epsilon.$ I've tried the following: Fix $\epsilon>0$. Let $S_n=\{measurable\;\; B\in E|u(B)>\epsilon, v(B)<1/n\}$. If $S_n$ is finite for some n we are done ($v(S)=0 \implies u(S)=0$). Now what I am trying to show is that the other case, $S_n$ is infinite $\forall n\in\mathbb{N}$, leads to a contradiction. Any suggestions?","Suppose $u$ and $v$ are measures on a measurable space $E$. Further suppose $u$ is finite and absolutely continuous with respect to v ($v(S)=0 \implies u(S)=0$). The problem is: Show that $\forall \epsilon>0 \;\;\;\exists \delta: v(S)<\delta \implies u(S)<\epsilon.$ I've tried the following: Fix $\epsilon>0$. Let $S_n=\{measurable\;\; B\in E|u(B)>\epsilon, v(B)<1/n\}$. If $S_n$ is finite for some n we are done ($v(S)=0 \implies u(S)=0$). Now what I am trying to show is that the other case, $S_n$ is infinite $\forall n\in\mathbb{N}$, leads to a contradiction. Any suggestions?",,[]
54,Convergence of the difference of the convolution of sequence of functions and a function,Convergence of the difference of the convolution of sequence of functions and a function,,Let $(g_j)_{j \in \mathbb{N}} \subseteq \mathscr{L}_1(\mathbb{R}^n)$ with $\|g_j\| = 1$ and $g_j \geq 0$ for all $j \in \mathbb{N}$ . Suppose that $\lim_{j \to \infty} d_j = 0$ where $d_j := \sup\{\|x\| \mid x \in \operatorname{supp}(g_j)\}$ . I want to prove that for all $f \in \mathscr{L}_1(\mathbb{R}^n)$ it is true that $$ \lim_{j \to \infty} \|f * g_j - f\|_1 = 0. $$ So far I've proved that for all $f \in \mathscr{L}_1(\mathbb{R}^n)$ and all $\epsilon > 0$ there exist some $\delta > 0$ such that $\|f - \tau_a f\|_1 < \epsilon$ for all $a \in \mathbb{R}^n$ with $\|a\| < \delta$ where $\tau_a f(x) = f(x - a)$ . It is not clear to me the path to follow. I think I can use the distributivity of the convolution to product to obtain \begin{align*} \|f * g_j - f\|_1 &= \|f * g_j - h * g_j\|_1 + \|h * g_j  - f\|_1\\ &\leq \|(f - h)* g_j\|_1 + \|h * g_j  - f\|_1\\ &\leq \|(f - h)\|_1 \|g_j\|_1 + \|h * g_j  - f\|_1 \end{align*} for some suitable function $h \in \mathscr{L}_1(\mathbb{R}^n)$ .,Let with and for all . Suppose that where . I want to prove that for all it is true that So far I've proved that for all and all there exist some such that for all with where . It is not clear to me the path to follow. I think I can use the distributivity of the convolution to product to obtain for some suitable function .,"(g_j)_{j \in \mathbb{N}} \subseteq \mathscr{L}_1(\mathbb{R}^n) \|g_j\| = 1 g_j \geq 0 j \in \mathbb{N} \lim_{j \to \infty} d_j = 0 d_j := \sup\{\|x\| \mid x \in \operatorname{supp}(g_j)\} f \in \mathscr{L}_1(\mathbb{R}^n) 
\lim_{j \to \infty} \|f * g_j - f\|_1 = 0.
 f \in \mathscr{L}_1(\mathbb{R}^n) \epsilon > 0 \delta > 0 \|f - \tau_a f\|_1 < \epsilon a \in \mathbb{R}^n \|a\| < \delta \tau_a f(x) = f(x - a) \begin{align*}
\|f * g_j - f\|_1 &= \|f * g_j - h * g_j\|_1 + \|h * g_j  - f\|_1\\
&\leq \|(f - h)* g_j\|_1 + \|h * g_j  - f\|_1\\
&\leq \|(f - h)\|_1 \|g_j\|_1 + \|h * g_j  - f\|_1
\end{align*} h \in \mathscr{L}_1(\mathbb{R}^n)","['measure-theory', 'lebesgue-integral', 'convolution']"
55,Uniform convergence and Lebesgue integral (Bogachev 10.4),Uniform convergence and Lebesgue integral (Bogachev 10.4),,"I was reading chapter 10.4 of Bogachev's Measure Theory book, when this definition is given: And, after this definition, he does the following observation: My issues are: what does he mean when he says ""by mean of uniform approximations""? And, more precisely, what is he effectively doing? It seems to me that he's somehow bringing the limit inside of the integral (in the sense that, since $f$ is bounded, there exists a sequence of simple functions $(f_n)_n$ that converges uniformly to $f$ , and he's bringing the limit for $n\rightarrow +\infty$ inside the integral), but why can he do it? Why can we put the limit inside the integral for all the integrals involved (with respect to $\mu, |\mu|$ and $\mu^{\mathcal{B}}(\cdot,x)$ )? I thought about some sort of application of the dominated convergence theorem, which explains also the $|\mu|$ -integrability of the function $x \mapsto \|\mu^{\mathcal{B}}(\cdot, x)\|$ , since this hypothesis gives the finiteness of the measure $\mu^{\mathcal{B}}(\cdot,x)$ for $|\mu|$ -almost every $x$ , but is not clear to me how to precisely use this fact. Just to make it clear: if $\mu$ is a measure on a space $X$ , then $\|\mu\|:=|\mu|(X)$ , where $|\mu|$ is the total variation of $\mu$ .","I was reading chapter 10.4 of Bogachev's Measure Theory book, when this definition is given: And, after this definition, he does the following observation: My issues are: what does he mean when he says ""by mean of uniform approximations""? And, more precisely, what is he effectively doing? It seems to me that he's somehow bringing the limit inside of the integral (in the sense that, since is bounded, there exists a sequence of simple functions that converges uniformly to , and he's bringing the limit for inside the integral), but why can he do it? Why can we put the limit inside the integral for all the integrals involved (with respect to and )? I thought about some sort of application of the dominated convergence theorem, which explains also the -integrability of the function , since this hypothesis gives the finiteness of the measure for -almost every , but is not clear to me how to precisely use this fact. Just to make it clear: if is a measure on a space , then , where is the total variation of .","f (f_n)_n f n\rightarrow +\infty \mu, |\mu| \mu^{\mathcal{B}}(\cdot,x) |\mu| x \mapsto \|\mu^{\mathcal{B}}(\cdot, x)\| \mu^{\mathcal{B}}(\cdot,x) |\mu| x \mu X \|\mu\|:=|\mu|(X) |\mu| \mu","['measure-theory', 'lebesgue-integral', 'uniform-convergence']"
56,"If $\{f_n\}$ is uniformly integrable, then there's a subsequence $(f_{k_n})$ of $(f_n)$ such that $\big(\int _Ef_{k_n}d\mu \big)$ is a Cauchy sequence","If  is uniformly integrable, then there's a subsequence  of  such that  is a Cauchy sequence",\{f_n\} (f_{k_n}) (f_n) \big(\int _Ef_{k_n}d\mu \big),"The page 20 of the book "" Topological Fixed Point Theory for Singlevalued and Multivalued Mappings and Applications "" (written by Ben Amar and O'Regan) has the following lemma. Lemma: Let $(X,\Sigma,\mu )$ be a finite measure space and $\{f_n\}_{n\in\mathbb{N}}\subseteq \mathcal{L}^1_\mathbb{R}(\mu )$ . Suppose that $\sup_{n\in\mathbb{N}}\Vert f_n\Vert _{L^1}<\infty$ $(\forall \varepsilon >0)(\exists \delta >0)(\forall E\in \Sigma )\left(\mu (E)<\delta\Rightarrow \sup_{n\in\mathbb{N}}\int _E|f_n|d\mu  <\varepsilon \right)$ . Then there's a subsequence $(f_{k_n})_{n\in\mathbb{N}}$ of $(f_n)_{n\in\mathbb{N}}$ such that $\left(\int _Ef_{k_n}d\mu  \right)_{n\in\mathbb{N}}$ is a Cauchy sequence for all $E\in \Sigma$ . Unfortunately, the book doesn't give any tips on how to prove this lemma. My question is: how can I prove that lemma? I couldn't do anything worth mentioning, but I know that the conclusion of that lemma is true if and only if there's a subsequence $(f_{k_n})_{n\in\mathbb{N}}$ of $(f_n)_{n\in\mathbb{N}}$ that converges weakly. Thank for your attention! EDIT: Please don't use the Dunford-Pettis Theorem because I want to use that lemma to prove this theorem. Please don’t use either the Eberlein-Smulian Theorem, because I want to avoid advanced theorems of functional analysis.","The page 20 of the book "" Topological Fixed Point Theory for Singlevalued and Multivalued Mappings and Applications "" (written by Ben Amar and O'Regan) has the following lemma. Lemma: Let be a finite measure space and . Suppose that . Then there's a subsequence of such that is a Cauchy sequence for all . Unfortunately, the book doesn't give any tips on how to prove this lemma. My question is: how can I prove that lemma? I couldn't do anything worth mentioning, but I know that the conclusion of that lemma is true if and only if there's a subsequence of that converges weakly. Thank for your attention! EDIT: Please don't use the Dunford-Pettis Theorem because I want to use that lemma to prove this theorem. Please don’t use either the Eberlein-Smulian Theorem, because I want to avoid advanced theorems of functional analysis.","(X,\Sigma,\mu ) \{f_n\}_{n\in\mathbb{N}}\subseteq \mathcal{L}^1_\mathbb{R}(\mu ) \sup_{n\in\mathbb{N}}\Vert f_n\Vert _{L^1}<\infty (\forall \varepsilon >0)(\exists \delta >0)(\forall E\in \Sigma )\left(\mu (E)<\delta\Rightarrow \sup_{n\in\mathbb{N}}\int _E|f_n|d\mu
 <\varepsilon \right) (f_{k_n})_{n\in\mathbb{N}} (f_n)_{n\in\mathbb{N}} \left(\int _Ef_{k_n}d\mu
 \right)_{n\in\mathbb{N}} E\in \Sigma (f_{k_n})_{n\in\mathbb{N}} (f_n)_{n\in\mathbb{N}}","['measure-theory', 'lp-spaces', 'measurable-functions', 'uniform-integrability']"
57,How to understand the $\infty$-Wasserstein distance,How to understand the -Wasserstein distance,\infty,"For two probability distributions $\mu$ and $\nu$ defined on $X$ , the $p$ -th Wasserstein distance between the two of them is defined as $$W_p(\mu,\nu) = \left(\inf_{\pi\in\Pi(\mu,\nu)}\int_{X\times X}c(x,x')^{p}\,\mathrm{d}\pi(x,x')\right)^{1/p}.  $$ We also have $\infty$ -Wasserstein distance defined as the limit of p-th Wasserstein distance, i.e., $$W_\infty(\mu,\nu) = lim_{p \rightarrow \infty} W_p(\mu,\nu).$$ However, I am having a hard time understanding this $\infty$ -Wasserstein distance. We know $\infty$ -norm is the element with the largest absolute value, for $\infty$ -Wasserstein distance do we have such a simplification as well?","For two probability distributions and defined on , the -th Wasserstein distance between the two of them is defined as We also have -Wasserstein distance defined as the limit of p-th Wasserstein distance, i.e., However, I am having a hard time understanding this -Wasserstein distance. We know -norm is the element with the largest absolute value, for -Wasserstein distance do we have such a simplification as well?","\mu \nu X p W_p(\mu,\nu) = \left(\inf_{\pi\in\Pi(\mu,\nu)}\int_{X\times X}c(x,x')^{p}\,\mathrm{d}\pi(x,x')\right)^{1/p}.
  \infty W_\infty(\mu,\nu) = lim_{p \rightarrow \infty} W_p(\mu,\nu). \infty \infty \infty","['measure-theory', 'probability-distributions', 'metric-spaces', 'matrix-norms']"
58,Is a full specification of a family of subsets also a full specification of the sigma-algebra it generates?,Is a full specification of a family of subsets also a full specification of the sigma-algebra it generates?,,"Let $C$ be a family of subsets of $\Omega$ , and $G(C)$ the $\sigma$ -algebra generated by $C$ . Assume that $f \in C$ is a ""full specification"" for $C$ , meaning that for all $s \in C$ either $f \subseteq s$ or $f \subseteq \Omega \backslash s$ . Can we prove that is also a full specification for $G(C)$ (meaning that for all $s \in G(C)$ either $f \subseteq s$ or $f \subseteq \Omega \backslash s$ )? If so, how? Some extra background: it seems intuitively clear to me that this should be true. But I'm struggling to prove it rigorously. My issue is that I don't really understand what explicit recipe we use to calculate $G(C)$ . I know that it's something like $C$ together with everything obtained from $C$ via complements and countable unions"". But this definition still seems a bit vague. For example, is it enough to first take the closure of $C$ under countable unions, and then the closure of that larger family under complements? Or do I have to keep on going iteratively, taking unions, then complements, then unions, then complements? And then if so, is it enough to iterate a finite number of times, or a countable number of times, or might I need an uncountable number of these steps?","Let be a family of subsets of , and the -algebra generated by . Assume that is a ""full specification"" for , meaning that for all either or . Can we prove that is also a full specification for (meaning that for all either or )? If so, how? Some extra background: it seems intuitively clear to me that this should be true. But I'm struggling to prove it rigorously. My issue is that I don't really understand what explicit recipe we use to calculate . I know that it's something like together with everything obtained from via complements and countable unions"". But this definition still seems a bit vague. For example, is it enough to first take the closure of under countable unions, and then the closure of that larger family under complements? Or do I have to keep on going iteratively, taking unions, then complements, then unions, then complements? And then if so, is it enough to iterate a finite number of times, or a countable number of times, or might I need an uncountable number of these steps?",C \Omega G(C) \sigma C f \in C C s \in C f \subseteq s f \subseteq \Omega \backslash s G(C) s \in G(C) f \subseteq s f \subseteq \Omega \backslash s G(C) C C C,['measure-theory']
59,If $f^{-1}(A)=A$ a.e. then show there is $B$ with $f^{-1}(B)=B$,If  a.e. then show there is  with,f^{-1}(A)=A B f^{-1}(B)=B,"$f$ is a measurable mapping on $(X,\mu)$ , and is measure-preserving, i.e.  for all measurable set $E$ , $\mu (f^{-1}(E))=\mu(E)$ . There is a measurable set $A$ ，s.t. $f^{-1}(A) =A$ , a.e. which means $\mu(A\bigtriangleup f^{-1}(A))=0.$ Then there exists $B$ measurable  s.t. $A=B$ , a.e. and $f^{-1}(B)=B$ . I find this problem is similar to Poincare's Theorem, but I was not able to imitate its proof. I tried to let $B= A \cap f^{-1}(A)\cap f^{-2}(A)\cdots$ but failed.","is a measurable mapping on , and is measure-preserving, i.e.  for all measurable set , . There is a measurable set ，s.t. , a.e. which means Then there exists measurable  s.t. , a.e. and . I find this problem is similar to Poincare's Theorem, but I was not able to imitate its proof. I tried to let but failed.","f (X,\mu) E \mu (f^{-1}(E))=\mu(E) A f^{-1}(A) =A \mu(A\bigtriangleup f^{-1}(A))=0. B A=B f^{-1}(B)=B B= A \cap f^{-1}(A)\cap f^{-2}(A)\cdots","['measure-theory', 'dynamical-systems']"
60,"Lebesgue measurable function in $\mathbb{R}^d$ is almost everywhere pointwise limit of step functions (Stein & Shakarchi, Real Analysis)","Lebesgue measurable function in  is almost everywhere pointwise limit of step functions (Stein & Shakarchi, Real Analysis)",\mathbb{R}^d,"Please see this SE post for a full quote of Theorem 4.3, which, in summary, states that a measurable function is an almost everywhere pointwise limit of a sequence of step functions. I have a question about this excerpt of the theorem: To this end, we recall part (iv) of Theorem 3.4, which states that for every $\epsilon$ there exist cubes $Q_1, \ldots, Q_N$ such that $m(E \Delta \bigcup_{j=1}^N Q_j) \leq \epsilon$ . By considering the grid formed by extending the sides of these cubes , we see that there exist almost disjoint rectangles $\tilde R_1, \ldots, \tilde R_M$ such that $\bigcup_{j=1}^N Q_j = \bigcup_{j=1}^M \tilde R_j$ . By taking rectangles $R_j$ contained in $\tilde R_j$ , and slightly smaller in size, we find a collection of disjoint rectangles that satisfy $m(E \Delta \bigcup_{j=1}^M R_j) \leq 2 \epsilon$ . For context, this idea of ""extending the sides of these cubes"" comes from the proof of Lemma 1.1 in the same textbook: (Lemma 1.1) If a rectangle is the almost disjoint union of finitely many other rectangles, say $R = \bigcup_{k=1}^N R_k$ , then $|R| = \sum_{k=1}^N |R_k|$ . The relevant part of the proof is: We consider the grid formed by extending indefinitely the sides of all rectangles $R_1, \ldots, R_N$ . This construction yields finitely many rectangles $\tilde R_1, \ldots, \tilde R_M$ , and a partition $J_1, \ldots, J_N$ of the integers between 1 and $M$ , such that the unions $R = \bigcup_{j=1}^M \tilde R_j$ and $R_k = \bigcup_{j \in J_k} \tilde R_j$ , for $k = 1,\ldots, N$ , are almost disjoint. My issue is: While I understand this grid extension idea, it seems a bit overkill. In theorem 4.3, all we care about is that we can take a slightly smaller subset of the almost disjoint union of closed cubes so that we have a strictly disjoint union of closed cubes. But there are much simpler ways to achieve this compared to the rectangular grid extension. For example, because we are starting from an almost disjoint union of cubes, then we can just shrink each side of cube $Q_j$ ""towards its midpoint,"" so that the boundary of every cube no longer intersects. E.g., in 1-D, $[2, 3]$ and $[3, 4]$ are almost disjoint cubes. Suppose I want to decrease the total volume by $\epsilon = 0.4$ . If I scale each side length by $1 - \epsilon/2 = 0.8$ ""towards its midpoint"" (so, now the cubes are $[2.1, 2.9]$ and $[3.1, 3.9]$ ), then the total volume is $(1 - \epsilon/2) * 2 = 2 - \epsilon$ , which is exactly the desired reduction in volume. This shrinkage extends to $\mathbb{R}^d$ because we know that cube $Q_j$ has sides defined by $[a^{j}_i, b^{j}_i], i = 1,\ldots, d$ , with side length $s_j := b^{j}_i - a^{j}_i > 0$ , so there always exists some scaling factor $c_j > 0$ so that the resulting closed cubes are well-defined (i.e., non-empty interior and strictly disjoint). In summary, why bother with the grid extension idea? We kind of get for free an easy way to get a strictly disjoint union of closed cubes with a precise reduction in volume, since the closed cubes are almost disjoint to begin with. Is my thinking correct, or is the grid extension idea necessary to conclude the proof of Theorem 4.3 ? Thanks","Please see this SE post for a full quote of Theorem 4.3, which, in summary, states that a measurable function is an almost everywhere pointwise limit of a sequence of step functions. I have a question about this excerpt of the theorem: To this end, we recall part (iv) of Theorem 3.4, which states that for every there exist cubes such that . By considering the grid formed by extending the sides of these cubes , we see that there exist almost disjoint rectangles such that . By taking rectangles contained in , and slightly smaller in size, we find a collection of disjoint rectangles that satisfy . For context, this idea of ""extending the sides of these cubes"" comes from the proof of Lemma 1.1 in the same textbook: (Lemma 1.1) If a rectangle is the almost disjoint union of finitely many other rectangles, say , then . The relevant part of the proof is: We consider the grid formed by extending indefinitely the sides of all rectangles . This construction yields finitely many rectangles , and a partition of the integers between 1 and , such that the unions and , for , are almost disjoint. My issue is: While I understand this grid extension idea, it seems a bit overkill. In theorem 4.3, all we care about is that we can take a slightly smaller subset of the almost disjoint union of closed cubes so that we have a strictly disjoint union of closed cubes. But there are much simpler ways to achieve this compared to the rectangular grid extension. For example, because we are starting from an almost disjoint union of cubes, then we can just shrink each side of cube ""towards its midpoint,"" so that the boundary of every cube no longer intersects. E.g., in 1-D, and are almost disjoint cubes. Suppose I want to decrease the total volume by . If I scale each side length by ""towards its midpoint"" (so, now the cubes are and ), then the total volume is , which is exactly the desired reduction in volume. This shrinkage extends to because we know that cube has sides defined by , with side length , so there always exists some scaling factor so that the resulting closed cubes are well-defined (i.e., non-empty interior and strictly disjoint). In summary, why bother with the grid extension idea? We kind of get for free an easy way to get a strictly disjoint union of closed cubes with a precise reduction in volume, since the closed cubes are almost disjoint to begin with. Is my thinking correct, or is the grid extension idea necessary to conclude the proof of Theorem 4.3 ? Thanks","\epsilon Q_1, \ldots, Q_N m(E \Delta \bigcup_{j=1}^N Q_j) \leq \epsilon \tilde R_1, \ldots, \tilde R_M \bigcup_{j=1}^N Q_j = \bigcup_{j=1}^M \tilde R_j R_j \tilde R_j m(E \Delta \bigcup_{j=1}^M R_j) \leq 2 \epsilon R = \bigcup_{k=1}^N R_k |R| = \sum_{k=1}^N |R_k| R_1, \ldots, R_N \tilde R_1, \ldots, \tilde R_M J_1, \ldots, J_N M R = \bigcup_{j=1}^M \tilde R_j R_k = \bigcup_{j \in J_k} \tilde R_j k = 1,\ldots, N Q_j [2, 3] [3, 4] \epsilon = 0.4 1 - \epsilon/2 = 0.8 [2.1, 2.9] [3.1, 3.9] (1 - \epsilon/2) * 2 = 2 - \epsilon \mathbb{R}^d Q_j [a^{j}_i, b^{j}_i], i = 1,\ldots, d s_j := b^{j}_i - a^{j}_i > 0 c_j > 0","['real-analysis', 'measure-theory']"
61,Is $\frac{1}{x^2+1/n}$ uniformly integrable?,Is  uniformly integrable?,\frac{1}{x^2+1/n},"For a set of functions $f_n\in F$ my definition of uniform integrability over the range $[-1,1]$ is $$\forall \epsilon>0, \exists M_{\epsilon}>0 : \sup_{f_n\in F}\int_{\{|f_n|\geq M_{\epsilon}\}}|f_n|\,d\mu<\epsilon$$ where $n=1,2,3...$ . My function of interest is confusing though, $$f_n(x)=\frac{1}{x^2+1/n}$$ because it is integrable over $x\in [-1,1]$ for any finite $n$ , but its limit in $n\rightarrow\infty$ is not integrable. Using the definition of uniform integrability, for any $\epsilon$ and any arbitrarily large $n$ , I can find an $M_{\epsilon}$ that makes the statement true. But on the contrary, for any $\epsilon$ and any $M_{\epsilon}$ , I can find an $n$ that makes it false.  This seems like a problem of which infinity grows faster.  How can I resolve whether my test function is uniformly integrable or not?","For a set of functions my definition of uniform integrability over the range is where . My function of interest is confusing though, because it is integrable over for any finite , but its limit in is not integrable. Using the definition of uniform integrability, for any and any arbitrarily large , I can find an that makes the statement true. But on the contrary, for any and any , I can find an that makes it false.  This seems like a problem of which infinity grows faster.  How can I resolve whether my test function is uniformly integrable or not?","f_n\in F [-1,1] \forall \epsilon>0, \exists M_{\epsilon}>0 : \sup_{f_n\in F}\int_{\{|f_n|\geq M_{\epsilon}\}}|f_n|\,d\mu<\epsilon n=1,2,3... f_n(x)=\frac{1}{x^2+1/n} x\in [-1,1] n n\rightarrow\infty \epsilon n M_{\epsilon} \epsilon M_{\epsilon} n","['measure-theory', 'uniform-integrability']"
62,Semifinite measure induced by a measure,Semifinite measure induced by a measure,,"Define $\mu_0: \mathcal{M} \longrightarrow [0,\infty]$ by $$ \mu_0(E) = \sup\{ \mu(F) \mid F \subseteq E, \mu(F) < \infty \}, $$ prove that $\mu_0$ is a measure on $\mathcal{M}$ . My attempt: Obviously $\mu_0(\emptyset)=0$ . Then let $E_i \in \mathcal{M}, \, i \in \mathbb{N}^+$ be pairwisely disjoint. $$ \begin{aligned} \mu_0(\bigsqcup_{i=1}^{\infty}E_i) =&   \sup \{ \mu(F) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i, \mu(F) < \infty \} \\ %%%%%%%%%%%%%% %%%%%%%%%%% =& \sup \{ \mu(\bigsqcup_{i=1}^{\infty}(F \cap E_i)) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i, \mu(F) < \infty \} \\ %%%%%%%%%%%%%% %%%%%%%%%%%% =& \sup \{ \sum_{i=1}^{\infty}\mu(F \cap E_i) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i, \mu(F) < \infty \} \\ %%%%%%%%%%%% %%%%%%%%%%%%%%% \leq& \sup \{ \sum_{i=1}^{\infty}\mu(F_i) \mid F_i \subseteq E_i, \mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \}  \\ %%%%%%%%%%%% %%%%%%%%%%%%% =& \sum_{i=1}^{\infty} \sup \{\mu(F_i) \mid F_i \subseteq E_i, \mu(F_i) < \infty \}  \\ %%%%%%%%%% %%%%%%%%%%% =& \sum_{i=1}^{\infty}  \mu_0(E_i)  \; . \end{aligned} $$ On the other hand, $$ \begin{aligned} \sum_{i=1}^{\infty}  \mu_0(E_i) =&   \sum_{i=1}^{\infty} \sup \{\mu(F_i) \mid F_i \subseteq E_i, \mu(F_i) < \infty \}  \\ %%%%%%%%%%%%%% %%%%%%%%%%% =& \sup \{ \sum_{i=1}^{\infty}\mu(F_i) \mid F_i \subseteq E_i, \mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \} \\ %%%%%%%%%%%%%% %%%%%%%%%%%% %%%%%%%%%%%%%%% =& \sup \{ \mu(\bigsqcup_{i=1}^{\infty}F_i) \mid F_i \subseteq E_i, \mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \} \;. \end{aligned} $$ But we can't get $$ \begin{aligned} &  \sup \{ \mu(\bigsqcup_{i=1}^{\infty}F_i) \mid F_i \subseteq E_i,     \mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \}     \\ %%%%%%%%%%%%%% %%%%%%%%%%% \leq& \sup \{ \mu(F) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i, \mu(F) < \infty \} \;,  \end{aligned} $$ because $\mu(\bigsqcup_{i=1}^{\infty}F_i)$ might be $\infty$ .","Define by prove that is a measure on . My attempt: Obviously . Then let be pairwisely disjoint. On the other hand, But we can't get because might be .","\mu_0: \mathcal{M} \longrightarrow [0,\infty] 
\mu_0(E) = \sup\{ \mu(F) \mid F \subseteq E, \mu(F) < \infty \},
 \mu_0 \mathcal{M} \mu_0(\emptyset)=0 E_i \in \mathcal{M}, \, i \in \mathbb{N}^+ 
\begin{aligned}
\mu_0(\bigsqcup_{i=1}^{\infty}E_i) =&  
\sup \{ \mu(F) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i,
\mu(F) < \infty \} \\
%%%%%%%%%%%%%%
%%%%%%%%%%%
=& \sup \{ \mu(\bigsqcup_{i=1}^{\infty}(F \cap E_i)) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i,
\mu(F) < \infty \} \\
%%%%%%%%%%%%%%
%%%%%%%%%%%%
=& \sup \{ \sum_{i=1}^{\infty}\mu(F \cap E_i) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i,
\mu(F) < \infty \} \\
%%%%%%%%%%%%
%%%%%%%%%%%%%%%
\leq& \sup \{ \sum_{i=1}^{\infty}\mu(F_i) \mid F_i \subseteq E_i,
\mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \}  \\
%%%%%%%%%%%%
%%%%%%%%%%%%%
=& \sum_{i=1}^{\infty} \sup \{\mu(F_i) \mid F_i \subseteq E_i,
\mu(F_i) < \infty \}  \\
%%%%%%%%%%
%%%%%%%%%%%
=& \sum_{i=1}^{\infty}  \mu_0(E_i)  \; .
\end{aligned}
 
\begin{aligned}
\sum_{i=1}^{\infty}  \mu_0(E_i) =&  
\sum_{i=1}^{\infty} \sup \{\mu(F_i) \mid F_i \subseteq E_i,
\mu(F_i) < \infty \}  \\
%%%%%%%%%%%%%%
%%%%%%%%%%%
=& \sup \{ \sum_{i=1}^{\infty}\mu(F_i) \mid F_i \subseteq E_i,
\mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \} \\
%%%%%%%%%%%%%%
%%%%%%%%%%%%
%%%%%%%%%%%%%%%
=& \sup \{ \mu(\bigsqcup_{i=1}^{\infty}F_i) \mid F_i \subseteq E_i,
\mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \} \;.
\end{aligned}
 
\begin{aligned}
&  \sup \{ \mu(\bigsqcup_{i=1}^{\infty}F_i) \mid F_i \subseteq E_i,
    \mu(F_i) < \infty, \forall i \in \mathbb{N}^+ \}   
 \\
%%%%%%%%%%%%%%
%%%%%%%%%%%
\leq& \sup \{ \mu(F) \mid F \subseteq \bigsqcup_{i=1}^{\infty}E_i,
\mu(F) < \infty \} \;, 
\end{aligned}
 \mu(\bigsqcup_{i=1}^{\infty}F_i) \infty",[]
63,A Cantor-type set,A Cantor-type set,,"Let $A=\{\sum_{k=1}^\infty \frac{a_k}{k!} : a_k\in\{0,\,1\}\}$ . We can prove that $A$ is a closed set with $\operatorname{int}(A)=\emptyset$ and Lebesgue measure of $0$ . Is there a $m \in \mathbb{N}$ s.t. $A+A+\cdots+A$ ( $m$ times) is of positive Lebesgue measure? (Note that for the Cantor set $C$ we have $C+C=[0,\,2]$ .)",Let . We can prove that is a closed set with and Lebesgue measure of . Is there a s.t. ( times) is of positive Lebesgue measure? (Note that for the Cantor set we have .),"A=\{\sum_{k=1}^\infty \frac{a_k}{k!} : a_k\in\{0,\,1\}\} A \operatorname{int}(A)=\emptyset 0 m \in \mathbb{N} A+A+\cdots+A m C C+C=[0,\,2]",['measure-theory']
64,"If a set $A\subseteq[0,1]$ contains a large subinterval of every interval, must $A$ have full measure?","If a set  contains a large subinterval of every interval, must  have full measure?","A\subseteq[0,1] A","Suppose that $A$ is a subset of $[0,1]$ such that $A$ is open in $[0,1]$ , and there exists fixed constants $C, \mu > 0$ with $1\leq \mu < 2$ so that whenever $I$ is a sub-interval of $[0,1]$ , say $[a,b]$ , then $(A \cap I)$ contains an open subinterval of length at least $C(b-a)^{\mu}$ . Does $A$ have full measure in $[0,1]$ ? Note that when $\mu = 1$ the result is true by the Lebesgue density theorem. I chose $\mu < 2$ because I did not want ""trivial"" counterexamples (not that I know of any as of right now). This is not an assignment problem.","Suppose that is a subset of such that is open in , and there exists fixed constants with so that whenever is a sub-interval of , say , then contains an open subinterval of length at least . Does have full measure in ? Note that when the result is true by the Lebesgue density theorem. I chose because I did not want ""trivial"" counterexamples (not that I know of any as of right now). This is not an assignment problem.","A [0,1] A [0,1] C, \mu > 0 1\leq \mu < 2 I [0,1] [a,b] (A \cap I) C(b-a)^{\mu} A [0,1] \mu = 1 \mu < 2","['measure-theory', 'lebesgue-measure']"
65,Question regarding convergence in the pth mean,Question regarding convergence in the pth mean,,"Here's what I am trying to prove: Let $\Omega = [0,1]$ , $1<p <\infty$ . Let $\{ f_n \}$ be a sequence in $L^p [0,1]$ such that $f_n \to f$ almost everywhere and $f \in L^p [0,1]$ . Suppose that there is some $M \in \mathbb R$ such that $\lVert f_n \rVert _p \le M$ for all $n$ . Prove that for $g\in L^q [0,1]$ where $1/p + 1/q =1$ , we have $\lim \int f_n g  d\lambda = \int fg d\lambda$ . Here $\lambda$ is the Lebesgue measure. Here's my poor attempt: Let $\{ f_n  \}$ be a sequence of functions in $L_p [0,1]$ . Since $\lVert \cdot \rVert _p$ is a continuous function on $L^p [0,1]$ and $\lVert f_n \rVert _p \le M$ for all $n$ , we have that $\lVert f \rVert _p \le M$ . If we try to estimate $\lvert \int f_n g d\lambda - \int fg d\lambda \rvert \le \lVert f_n -f \rVert _p \lVert g \rVert _q$ . If we could somehow how that $\lVert f_n - f \rVert _p \to 0$ as $n \to \infty$ , we will be done. There are certain things that I observe: we have a finite measure space and so almost everywhere convergence implies convergence in measure. However, convergence in measure will not possibly imply convergence in the $p$ th mean. So we are hopeless at this certain point.  However, I notice that I am not using the fact that $\lVert f_n \rVert \le M$ and $\lVert f \rVert \le M$ for each $n \in \mathbb N$ . I do not see how to use it as well. I am looking for hints that could possibly lead me to a solution to this problem. Any series of hints will be appreciated.","Here's what I am trying to prove: Let , . Let be a sequence in such that almost everywhere and . Suppose that there is some such that for all . Prove that for where , we have . Here is the Lebesgue measure. Here's my poor attempt: Let be a sequence of functions in . Since is a continuous function on and for all , we have that . If we try to estimate . If we could somehow how that as , we will be done. There are certain things that I observe: we have a finite measure space and so almost everywhere convergence implies convergence in measure. However, convergence in measure will not possibly imply convergence in the th mean. So we are hopeless at this certain point.  However, I notice that I am not using the fact that and for each . I do not see how to use it as well. I am looking for hints that could possibly lead me to a solution to this problem. Any series of hints will be appreciated.","\Omega = [0,1] 1<p <\infty \{ f_n \} L^p [0,1] f_n \to f f \in L^p [0,1] M \in \mathbb R \lVert f_n \rVert _p \le M n g\in L^q [0,1] 1/p + 1/q =1 \lim \int f_n g  d\lambda = \int fg d\lambda \lambda \{ f_n  \} L_p [0,1] \lVert \cdot \rVert _p L^p [0,1] \lVert f_n \rVert _p \le M n \lVert f \rVert _p \le M \lvert \int f_n g d\lambda - \int fg d\lambda \rvert \le \lVert f_n -f \rVert _p \lVert g \rVert _q \lVert f_n - f \rVert _p \to 0 n \to \infty p \lVert f_n \rVert \le M \lVert f \rVert \le M n \in \mathbb N","['real-analysis', 'measure-theory']"
66,Showing that if $f$ vanishes locally almost everywhere then integral of $|f|$ is 0,Showing that if  vanishes locally almost everywhere then integral of  is 0,f |f|,"I am studying measure theory from Cohn's Measure theory textbook. If $(X, \scr A, \mu)$ is a measure space then a subset $N$ of $X$ is said to be locally null if for every $A \in \scr A $ with $\mu (A) < + \infty$ , we have that $A \cap N$ is null set. Also, subset $B$ of $X$ is said to be null set if there is a set $A \in \scr A$ such that $B \subset A$ and $\mu (A) = 0$ . Now, here's what I am trying to prove: if $f: X \to \mathbb C$ and $f=0$ locally almost everywhere, that is, $\{ x\in X : |f(x)| >0 \}$ is locally null then $\int |f| \,d\mu = 0$ . This claim would be true if $f=0$ almost everywhere, that is, the $\{ x\in X : |f(x)| >0 \}$ is null. This holds true if $X$ is $\sigma$ -finite. Because $\sigma$ -finiteness would imply that every locally null set is null and we would be done. The claim remains to be proved when $X$ is not $\sigma$ -finite. I tried my best to prove it but could not reach anywhere. Hints to prove or disprove it will be appreciated!","I am studying measure theory from Cohn's Measure theory textbook. If is a measure space then a subset of is said to be locally null if for every with , we have that is null set. Also, subset of is said to be null set if there is a set such that and . Now, here's what I am trying to prove: if and locally almost everywhere, that is, is locally null then . This claim would be true if almost everywhere, that is, the is null. This holds true if is -finite. Because -finiteness would imply that every locally null set is null and we would be done. The claim remains to be proved when is not -finite. I tried my best to prove it but could not reach anywhere. Hints to prove or disprove it will be appreciated!","(X, \scr A, \mu) N X A \in \scr A  \mu (A) < + \infty A \cap N B X A \in \scr A B \subset A \mu (A) = 0 f: X \to \mathbb C f=0 \{ x\in X : |f(x)| >0 \} \int |f| \,d\mu = 0 f=0 \{ x\in X : |f(x)| >0 \} X \sigma \sigma X \sigma","['real-analysis', 'measure-theory']"
67,"On proving the following inequality: $ \int_X \text{min}(f,g) \ d\mu \geq \frac{1}{2} (\int_X \sqrt{fg} \ d\mu)^2. $",On proving the following inequality:," \int_X \text{min}(f,g) \ d\mu \geq \frac{1}{2} (\int_X \sqrt{fg} \ d\mu)^2. ","Let $f,g: X \rightarrow \mathbb{R}$ denote bounded, non-negative, measurable functions and $\mu$ a measure on $X$ . Then I would like to prove that $$ \int_X \text{min}(f,g) \ d\mu \geq \frac{1}{2} (\int_X \sqrt{fg} \ d\mu)^2. $$ What I have tried so far is writing $\text{min}(f,g)= \frac{f+g}{2} - \frac{\vert f - g \vert}{2}$ . Then it is a well-known result that $\frac{f+g}{2} \geq \sqrt{fg}$ which seems promising (but might not be what we need though). I am not sure what to do about the second term. Also there needs to appear a square outside the integral which could be achieved with for instance Jensen's Inequality due to the convexity of $x \mapsto x^2$ . Then it would suffice to prove that $$ \int_X f+g - \vert f - g \vert \ d\mu \geq \int_X fg \ d\mu. $$ Here I am stuck. Can anyone help me? Am I on the right track? As a final remark, it would be okay if we need to assume that $f,g$ integrate to 1 and $\mu(X)=1$ (as they will be densities for probability measures in the context I will be using this inequality). However I am not sure whether or not this is a necessary assumption and hence I have stated the problem without it initially.","Let denote bounded, non-negative, measurable functions and a measure on . Then I would like to prove that What I have tried so far is writing . Then it is a well-known result that which seems promising (but might not be what we need though). I am not sure what to do about the second term. Also there needs to appear a square outside the integral which could be achieved with for instance Jensen's Inequality due to the convexity of . Then it would suffice to prove that Here I am stuck. Can anyone help me? Am I on the right track? As a final remark, it would be okay if we need to assume that integrate to 1 and (as they will be densities for probability measures in the context I will be using this inequality). However I am not sure whether or not this is a necessary assumption and hence I have stated the problem without it initially.","f,g: X \rightarrow \mathbb{R} \mu X 
\int_X \text{min}(f,g) \ d\mu \geq \frac{1}{2} (\int_X \sqrt{fg} \ d\mu)^2.
 \text{min}(f,g)= \frac{f+g}{2} - \frac{\vert f - g \vert}{2} \frac{f+g}{2} \geq \sqrt{fg} x \mapsto x^2 
\int_X f+g - \vert f - g \vert \ d\mu \geq \int_X fg \ d\mu.
 f,g \mu(X)=1","['measure-theory', 'inequality', 'lebesgue-integral']"
68,Obtaining Classical Wiener Space from abstract Wiener measure,Obtaining Classical Wiener Space from abstract Wiener measure,,"The question I'm working on understanding the Abstract Wiener Space construction and wanted to rederive the defining property of the classical counterpart, $$\require{cancel} \xcancel{\xi_{t+s} - \xi_t}\ B_{t+s} - B_t\sim \mathcal{N}(0, s) \quad(\text{for } s> 0), \tag{1}$$ from the Abstract Wiener Space as constructed on the Wikipedia page and here . The setup That is, I assume to know that $\xi \in W^{2,1}_0[0,T] =: \mathcal{H}$ , i.e., $\xi: [0,T] \to \mathbb{R}$ is an absolutely continuous path with square-integrable first derivative and $\xi(0) = 0$ . The inner product on $\mathcal{H}$ shall be defined as $$(\xi, \zeta) = \int_0^T \dot{\xi}(t) \dot{\zeta}(t) \,\mathrm{d}t, \tag{a}$$ and from the construction we know there exists a measure $\mu$ which acts on the algebraic dual space $E^a$ and which has the properties (Defs. 20 and 25 of Velhinho) $$\forall\, \xi \in \mathcal{H}: \quad \chi(\xi) := \int_{E^a} e^{i\phi(\xi)}\, \mathrm{d}\mu(\phi) = e^{-\frac{1}{2}(\xi,\xi)} \tag{b}$$ and (Theorem 11, which I believe is a special case of the cylinder set measure property, correct me if I'm wrong) $$\forall\, \xi \in \mathcal{H}, A \in \mathcal{B}(\mathbb{R}): \quad \mu_\xi(A) := \mu(\{\phi \in E^a \mid \phi(\xi) \in A \}) = \frac{1}{\sqrt{2\pi (\xi,\xi)}} \int_A e^{-\frac{x^2}{2(\xi,\xi)}} \,\mathrm{d}x. \tag{c}$$ My attempt at a solution ( see edit below! ) I have the following idea, but I'm not sure if it's right: What we want to show in (1) is equivalent to $$P(\{\xi(t+s) - \xi(t) \in A\}) = \frac{1}{\sqrt{2\pi s}}\int_A e^{-\frac{x^2}{2s}} \,\mathrm{d}x$$ for any Borel set $A \in \mathcal{B}(\mathbb{R})$ . We may note that $$\xi(t+s) - \xi(t) =  \int_t^{t+s} \dot{\xi}(\tau)\, \mathrm{d}\tau = \int_0^{T} \dot{f}(t) \dot{\xi}(\tau)\, \mathrm{d}\tau \quad \text{with } \dot{f}(\tau) = 1_{[t,t+s]}(\tau).$$ Now, since every $\xi \in \mathcal{H}$ will also have a dual element $\phi_\xi \in E^a$ and $f$ as implicitly defined above is a valid element of $\mathcal{H}$ , we can swap the roles of $\xi$ and $f$ to define $$\xi(t+s) - \xi(t) =: \phi_\xi(f).$$ Then we can apply (c) to find that $$\mu_f(A) = \frac{1}{\sqrt{2\pi (f,f)}}\int_A e^{-\frac{a^2}{2(f,f)}}\,\mathrm{d}x = \frac{1}{\sqrt{2\pi s}}\int_A e^{-\frac{a^2}{2s}}\,\mathrm{d}x,$$ where we used $(f,f) = s$ via definition (a). This looks like the right result, but the way there seems a bit odd, and it also glosses over the fact that the set that is measured in (c) includes $\phi$ that are not duals $\phi_\xi$ of some $\xi$ . Is it obvious that these will contribute with measure zero? Feel free to point me to a good introductory text that gives more context, if necessary! Edit: Revised attempt I found part of the problem: In (1), $\xi$ was the Brownian motion itself, whereas in (a) through (c), $\xi$ was an element of the Cameron–Martin Hilbert space. However, the Brownian motion sample paths are not elements of the Hilbert space, but rather of the Banach space $E^a$ . Thus, I should replace (1) with $$B_{t+s} - B_t \sim \mathcal{N}(0, s)$$ to make the distinction between $\xi$ and $B$ obvious. Then the rest of the argument continues as before, i.e. $$ B(t+s) - B(t) = \int_0^T \dot{B}(\tau) \dot{\xi}(\tau)\, \mathrm{d}\tau \quad \text{with } \dot{\xi}(\tau) = 1_{[t,t+s]}(\tau) \implies \mu_\xi(A) = \frac{1}{\sqrt{2\pi s}} \int_A e^{-x^2/(2s)} \,\mathrm{d} x, $$ but we now face a different problem, namely that $B(\tau)$ is a.s. not differentiable and that hence the integral that I just wrote does not exist for a.e. $B$ . I've considered interpreting $\dot{B}$ in the distributional sense, but $\xi$ is not a test function, so that doesn't seem to work, I don't know if there's some closure/completion/limiting property that can be used instead.","The question I'm working on understanding the Abstract Wiener Space construction and wanted to rederive the defining property of the classical counterpart, from the Abstract Wiener Space as constructed on the Wikipedia page and here . The setup That is, I assume to know that , i.e., is an absolutely continuous path with square-integrable first derivative and . The inner product on shall be defined as and from the construction we know there exists a measure which acts on the algebraic dual space and which has the properties (Defs. 20 and 25 of Velhinho) and (Theorem 11, which I believe is a special case of the cylinder set measure property, correct me if I'm wrong) My attempt at a solution ( see edit below! ) I have the following idea, but I'm not sure if it's right: What we want to show in (1) is equivalent to for any Borel set . We may note that Now, since every will also have a dual element and as implicitly defined above is a valid element of , we can swap the roles of and to define Then we can apply (c) to find that where we used via definition (a). This looks like the right result, but the way there seems a bit odd, and it also glosses over the fact that the set that is measured in (c) includes that are not duals of some . Is it obvious that these will contribute with measure zero? Feel free to point me to a good introductory text that gives more context, if necessary! Edit: Revised attempt I found part of the problem: In (1), was the Brownian motion itself, whereas in (a) through (c), was an element of the Cameron–Martin Hilbert space. However, the Brownian motion sample paths are not elements of the Hilbert space, but rather of the Banach space . Thus, I should replace (1) with to make the distinction between and obvious. Then the rest of the argument continues as before, i.e. but we now face a different problem, namely that is a.s. not differentiable and that hence the integral that I just wrote does not exist for a.e. . I've considered interpreting in the distributional sense, but is not a test function, so that doesn't seem to work, I don't know if there's some closure/completion/limiting property that can be used instead.","\require{cancel} \xcancel{\xi_{t+s} - \xi_t}\ B_{t+s} - B_t\sim \mathcal{N}(0, s) \quad(\text{for } s> 0), \tag{1} \xi \in W^{2,1}_0[0,T] =: \mathcal{H} \xi: [0,T] \to \mathbb{R} \xi(0) = 0 \mathcal{H} (\xi, \zeta) = \int_0^T \dot{\xi}(t) \dot{\zeta}(t) \,\mathrm{d}t, \tag{a} \mu E^a \forall\, \xi \in \mathcal{H}: \quad \chi(\xi) := \int_{E^a} e^{i\phi(\xi)}\, \mathrm{d}\mu(\phi) = e^{-\frac{1}{2}(\xi,\xi)} \tag{b} \forall\, \xi \in \mathcal{H}, A \in \mathcal{B}(\mathbb{R}): \quad \mu_\xi(A) := \mu(\{\phi \in E^a \mid \phi(\xi) \in A \}) = \frac{1}{\sqrt{2\pi (\xi,\xi)}} \int_A e^{-\frac{x^2}{2(\xi,\xi)}} \,\mathrm{d}x. \tag{c} P(\{\xi(t+s) - \xi(t) \in A\}) = \frac{1}{\sqrt{2\pi s}}\int_A e^{-\frac{x^2}{2s}} \,\mathrm{d}x A \in \mathcal{B}(\mathbb{R}) \xi(t+s) - \xi(t) =  \int_t^{t+s} \dot{\xi}(\tau)\, \mathrm{d}\tau = \int_0^{T} \dot{f}(t) \dot{\xi}(\tau)\, \mathrm{d}\tau \quad \text{with } \dot{f}(\tau) = 1_{[t,t+s]}(\tau). \xi \in \mathcal{H} \phi_\xi \in E^a f \mathcal{H} \xi f \xi(t+s) - \xi(t) =: \phi_\xi(f). \mu_f(A) = \frac{1}{\sqrt{2\pi (f,f)}}\int_A e^{-\frac{a^2}{2(f,f)}}\,\mathrm{d}x = \frac{1}{\sqrt{2\pi s}}\int_A e^{-\frac{a^2}{2s}}\,\mathrm{d}x, (f,f) = s \phi \phi_\xi \xi \xi \xi E^a B_{t+s} - B_t \sim \mathcal{N}(0, s) \xi B 
B(t+s) - B(t) = \int_0^T \dot{B}(\tau) \dot{\xi}(\tau)\, \mathrm{d}\tau \quad \text{with } \dot{\xi}(\tau) = 1_{[t,t+s]}(\tau)
\implies \mu_\xi(A) = \frac{1}{\sqrt{2\pi s}} \int_A e^{-x^2/(2s)} \,\mathrm{d} x,
 B(\tau) B \dot{B} \xi","['measure-theory', 'stochastic-processes', 'wiener-measure']"
69,Support of the invariant measures of the logistic family,Support of the invariant measures of the logistic family,,"Let $a\in (0,4]$ be the logistic family $Q_a:[0,1] \to [0,1]$ , $Q_a(x) = ax(1-x).$ In the book ""One-Dimensional Dynamics - W. de Melo, S. van Strien"", it is stated that the set $$\mathcal C =\{a\in (0,4]; \mbox{ $Q_a$ admits an invariant measure $\mu_a$, such that   $\mu_a(\mathrm dx) \ll \mathrm{Lebesgue}(\mathrm dx)$}\},$$ has $4$ as an accumulation point (see the result at the end of this question). I searched online if there is any information about the support of the measures $\{\mu_a\}_{a\in \mathcal C}.$ I believe that there exists a subsequence $\{a_n\}_{n\in\mathbb N} \subset \mathcal C,$ such that $\lim_{n\to \infty} a_n= 4$ and supp $(\mu_{a_n}) \to [0,1]$ (in the Hausforff metric ), however I could neither find a proof from this fact nor prove it by myself. Does anyone have any suggestions for attacking this problem or a reference? Corollary (Jakobson). Let $Q_a : [0,1] \to [0,1]$ , $a \in (0,4]$ , be the quadratic family $Q_a(x) = ax(1-x)$ . There exists a subset $\mathcal{C} \subset (0,4]$ of positive Lebesgue measure with the following properties: If $a \in \mathcal{C}$ then $Q_a$ has an absolutely continuous invariant probability measure with positive entropy. The parameter value $a=4$ is a Lebesgue density point of $\mathcal{C}$ , namely, $$\lim_{\epsilon \to 0} \frac{\lambda(\mathcal{C} \cap [4-\epsilon,4])}{\epsilon} = 1.$$","Let be the logistic family , In the book ""One-Dimensional Dynamics - W. de Melo, S. van Strien"", it is stated that the set has as an accumulation point (see the result at the end of this question). I searched online if there is any information about the support of the measures I believe that there exists a subsequence such that and supp (in the Hausforff metric ), however I could neither find a proof from this fact nor prove it by myself. Does anyone have any suggestions for attacking this problem or a reference? Corollary (Jakobson). Let , , be the quadratic family . There exists a subset of positive Lebesgue measure with the following properties: If then has an absolutely continuous invariant probability measure with positive entropy. The parameter value is a Lebesgue density point of , namely,","a\in (0,4] Q_a:[0,1] \to [0,1] Q_a(x) = ax(1-x). \mathcal C =\{a\in (0,4]; \mbox{ Q_a admits an invariant measure \mu_a, such that 
 \mu_a(\mathrm dx) \ll \mathrm{Lebesgue}(\mathrm dx)}\}, 4 \{\mu_a\}_{a\in \mathcal C}. \{a_n\}_{n\in\mathbb N} \subset \mathcal C, \lim_{n\to \infty} a_n= 4 (\mu_{a_n}) \to [0,1] Q_a : [0,1] \to [0,1] a \in (0,4] Q_a(x) = ax(1-x) \mathcal{C} \subset (0,4] a \in \mathcal{C} Q_a a=4 \mathcal{C} \lim_{\epsilon \to 0} \frac{\lambda(\mathcal{C} \cap [4-\epsilon,4])}{\epsilon} = 1.","['measure-theory', 'dynamical-systems', 'ergodic-theory']"
70,Rotating spherical shells doesn't change volume,Rotating spherical shells doesn't change volume,,"Let $\gamma\colon \mathbb R\to SO(n)$ be a path (but not necessarily a one-parameter group). It leads to a diffeomorphism $f\colon \mathbb R^n\to \mathbb R^n$ $$f(x) = \gamma\left(\lVert x \rVert^2\right)x,$$ which rotates around the origin every spherical shell, according to a rotation specified by the distance from the origin. I wonder if $f$ is volume-preserving, i.e., at every point $\vert\det f'(x)\vert = 1$ . This is what I know: Proof that $f$ is a diffeomorphism is easy, as its inverse is just $x\mapsto \gamma(\lVert x \rVert ^2)^{-1}x$ . For $n=2$ this is easy, but tedious – $SO(2)\simeq S^1$ and I was able to write a general $\gamma$ as $t\mapsto \exp(i u(t))$ for some function $u\colon \mathbb R\to \mathbb R$ and verify the required identity manually. I'm speculating now, but the Borel algebra on $\mathbb R^n$ has a basis being (a high-dimensional analogue of) a steradian spanned between radii $r_1$ and $r_2$ . I think it may be possible to prove using Fubini's theorem something like the Cavalieri's principle – the area of each ""steradian"" doesn't change (as we are rigidly rotating it by an element of $SO(n)$ ) so that the total volume doesn't change either. (And pass from this basis to arbitrary Borel sets). I however wasn't able to fill in the details and turn this intuition into a formal proof. In general, $f'(x) \neq \gamma(\lVert x \rVert^2)$ , but I believe that $\det f'(x) = 1 = \det \gamma(\lVert x \rVert^2)$ .","Let be a path (but not necessarily a one-parameter group). It leads to a diffeomorphism which rotates around the origin every spherical shell, according to a rotation specified by the distance from the origin. I wonder if is volume-preserving, i.e., at every point . This is what I know: Proof that is a diffeomorphism is easy, as its inverse is just . For this is easy, but tedious – and I was able to write a general as for some function and verify the required identity manually. I'm speculating now, but the Borel algebra on has a basis being (a high-dimensional analogue of) a steradian spanned between radii and . I think it may be possible to prove using Fubini's theorem something like the Cavalieri's principle – the area of each ""steradian"" doesn't change (as we are rigidly rotating it by an element of ) so that the total volume doesn't change either. (And pass from this basis to arbitrary Borel sets). I however wasn't able to fill in the details and turn this intuition into a formal proof. In general, , but I believe that .","\gamma\colon \mathbb R\to SO(n) f\colon \mathbb R^n\to \mathbb R^n f(x) = \gamma\left(\lVert x \rVert^2\right)x, f \vert\det f'(x)\vert = 1 f x\mapsto \gamma(\lVert x \rVert ^2)^{-1}x n=2 SO(2)\simeq S^1 \gamma t\mapsto \exp(i u(t)) u\colon \mathbb R\to \mathbb R \mathbb R^n r_1 r_2 SO(n) f'(x) \neq \gamma(\lVert x \rVert^2) \det f'(x) = 1 = \det \gamma(\lVert x \rVert^2)","['measure-theory', 'differential-geometry', 'lie-groups']"
71,A definition of outer measure in $\mathbb{R}^d$ by using closed boxes,A definition of outer measure in  by using closed boxes,\mathbb{R}^d,"In my text, the outer measure of a set $E \subseteq \mathbb{R}^d$ is defined using closed boxes or rectangles ${Q_k} = \prod [a_i, b_i]$ via: $$ m^*(E) = \inf \left\{ \sum \text{vol}(Q_k); E \subseteq \cup_k Q_k \right\} $$ The problem is to show that the usual definition is equivalent to the above: instead of requiring that $E \subseteq \cup Q_k$ , we could have $E \subseteq\cup Q_k^\circ$ just as well. I know simply that that since $E \subseteq \cup_k  Q_k^\circ\subseteq \cup_k{Q_k} $ we have $$ m^*(E) \leq \inf \left\{ \sum \text{vol}(Q_k); E \subseteq \cup_k Q_k^\circ \right\}   $$ how to go about in the reverse direction? Edit: My (incomplete) Solution Consider any cover $\{Q_k\}$ such that $E \subseteq \cup Q_k^\circ$ . Take closed boxes $\{Q_k'\}$ in the interior of $\{Q_k\}$ such that $E \subseteq \cup Q_k' \subseteq \cup Q_k^\circ$ and $\text{vol}(Q_k') + \epsilon/2^k \geq \text{vol}(Q_k)$ , then: $$ \sum_k \text{vol}(Q_k')\geq \sum_k\left(\text{vol}(Q_k)-\frac{\epsilon}{2^k}\right)=\sum_k \text{vol}(Q_k)-\epsilon \geq \inf \sum_k \text{vol}(Q_k)-\epsilon  $$ at which point I am stuck.","In my text, the outer measure of a set is defined using closed boxes or rectangles via: The problem is to show that the usual definition is equivalent to the above: instead of requiring that , we could have just as well. I know simply that that since we have how to go about in the reverse direction? Edit: My (incomplete) Solution Consider any cover such that . Take closed boxes in the interior of such that and , then: at which point I am stuck.","E \subseteq \mathbb{R}^d {Q_k} = \prod [a_i, b_i] 
m^*(E) = \inf \left\{ \sum \text{vol}(Q_k); E \subseteq \cup_k Q_k \right\}
 E \subseteq \cup Q_k E \subseteq\cup Q_k^\circ E \subseteq \cup_k  Q_k^\circ\subseteq \cup_k{Q_k}  
m^*(E) \leq \inf \left\{ \sum \text{vol}(Q_k); E \subseteq \cup_k Q_k^\circ \right\}  
 \{Q_k\} E \subseteq \cup Q_k^\circ \{Q_k'\} \{Q_k\} E \subseteq \cup Q_k' \subseteq \cup Q_k^\circ \text{vol}(Q_k') + \epsilon/2^k \geq \text{vol}(Q_k) 
\sum_k \text{vol}(Q_k')\geq \sum_k\left(\text{vol}(Q_k)-\frac{\epsilon}{2^k}\right)=\sum_k \text{vol}(Q_k)-\epsilon \geq \inf \sum_k \text{vol}(Q_k)-\epsilon 
","['real-analysis', 'measure-theory', 'lebesgue-measure', 'self-learning']"
72,Sets of Unambiguous Measure,Sets of Unambiguous Measure,,"Here is a fictionalised history of measure on $[0,1]$ . We started with intervals and assigned them lengths. We noticed the properties of these lengths regarding disjoint unions and complements, and, wanting these to hold for arbitrary sets, came to the Borel measure $\mu$ . We then asked if there was a natural way to extend this measure. The Lebesgue measure was natural because its sets $S$ , in some sense, had to have the measure $\lambda(S)$ . They are all disjoint unions of Borel sets $B$ and null sets $N$ , which in any possible extension of the Borel measure, had to be assigned measure $\mu(B)$ . My question is, can we go any further in this fashion? Formally, let $(\Omega,\mathcal{F},\mu)$ be a measure space and $(\Omega,\mathcal{F}_0,\mu_0)$ its completion. Call a measure space $(\Omega,\mathcal{F}',\mu')$ such that $\mathcal{F}\subseteq\mathcal{F}'$ and $\mu'|_\mathcal{F}=\mu$ an extension of $(\Omega,\mathcal{F},\mu)$ . Suppose that for the set $S\subseteq\Omega$ there exists an extension $(\Omega,\mathcal{F}',\mu')$ of $(\Omega,\mathcal{F},\mu)$ such that $S\in\mathcal{F}'$ and for any two such extensions $(\Omega,\mathcal{F}',\mu')$ and $(\Omega,\mathcal{F}'',\mu'')$ , $\mu'(S)=\mu''(S)$ . Then is it necessarily the case that $S\in\mathcal{F}_0$ ? If not, is it at least true for $\mathbb{R}$ as the Borel or Lebesgue measure space?","Here is a fictionalised history of measure on . We started with intervals and assigned them lengths. We noticed the properties of these lengths regarding disjoint unions and complements, and, wanting these to hold for arbitrary sets, came to the Borel measure . We then asked if there was a natural way to extend this measure. The Lebesgue measure was natural because its sets , in some sense, had to have the measure . They are all disjoint unions of Borel sets and null sets , which in any possible extension of the Borel measure, had to be assigned measure . My question is, can we go any further in this fashion? Formally, let be a measure space and its completion. Call a measure space such that and an extension of . Suppose that for the set there exists an extension of such that and for any two such extensions and , . Then is it necessarily the case that ? If not, is it at least true for as the Borel or Lebesgue measure space?","[0,1] \mu S \lambda(S) B N \mu(B) (\Omega,\mathcal{F},\mu) (\Omega,\mathcal{F}_0,\mu_0) (\Omega,\mathcal{F}',\mu') \mathcal{F}\subseteq\mathcal{F}' \mu'|_\mathcal{F}=\mu (\Omega,\mathcal{F},\mu) S\subseteq\Omega (\Omega,\mathcal{F}',\mu') (\Omega,\mathcal{F},\mu) S\in\mathcal{F}' (\Omega,\mathcal{F}',\mu') (\Omega,\mathcal{F}'',\mu'') \mu'(S)=\mu''(S) S\in\mathcal{F}_0 \mathbb{R}",['measure-theory']
73,Lebesgue Measure on $\mathbb{R}^n$,Lebesgue Measure on,\mathbb{R}^n,"I know that the n-dimensional Lebesgue-Measure $\lambda^n$ is defined at least on all Borel Sets $\mathcal{B}^n= \mathcal{B}(\mathbb{R}^n)$ . Let's assume $A=(a,b) \subseteq \mathbb{R}^n$ . (i) My first question is whether it is possible to define $\lambda^n(A)$ ? I suppose that this leads to $\lambda^n(A)=0$ ? (ii) Is it allowed to use the 1-dimensional Lebesgue-Measure here or can we do no other than using $\lambda^n$ since the space is $\mathbb{R}^n$ ? May anybody have an answer/explanation to this?",I know that the n-dimensional Lebesgue-Measure is defined at least on all Borel Sets . Let's assume . (i) My first question is whether it is possible to define ? I suppose that this leads to ? (ii) Is it allowed to use the 1-dimensional Lebesgue-Measure here or can we do no other than using since the space is ? May anybody have an answer/explanation to this?,"\lambda^n \mathcal{B}^n= \mathcal{B}(\mathbb{R}^n) A=(a,b) \subseteq \mathbb{R}^n \lambda^n(A) \lambda^n(A)=0 \lambda^n \mathbb{R}^n","['measure-theory', 'lebesgue-measure']"
74,The Lebesgue $\sigma$-algebra $L(\mathbb{R}^n)$ is the completion of the Borel $\sigma$-algebra $B(\mathbb{R}^n)$,The Lebesgue -algebra  is the completion of the Borel -algebra,\sigma L(\mathbb{R}^n) \sigma B(\mathbb{R}^n),"I came across the following proof of the completion of Borel $\sigma$ -algebra to $\sigma$ -algebra comprised of Lebesgue measurable sets which I cannot understand quite clearly. Can anyone elaborate this proof in a detailed manner and what is the whole point of the proof? Theorem 2.28. The Lebesgue $\sigma$ -algebra $L(\mathbb{R}^n)$ is the completion of the Borel $\sigma$ -algebra $B(\mathbb{R}^n)$ . Proof . Lebesgue measure is complete. If $A \subset \mathbb{R}^n$ is Lebesgue measurable, then there is an $F_\sigma$ set $F \subset A$ such that $M = A \setminus F$ has Lebesgue measure zero. It follows by the approximation theorem that there is a Borel set $N \in G_\delta$ with $\mu (N) = 0$ and $M \subset N$ . Thus, $A = F\cup M$ where $F \in B$ and $M \subset N \in B$ with $\mu (N ) = 0$ , which proves that $L(\mathbb{R}^n)$ is the completion of $B(\mathbb{R}^n)$ .","I came across the following proof of the completion of Borel -algebra to -algebra comprised of Lebesgue measurable sets which I cannot understand quite clearly. Can anyone elaborate this proof in a detailed manner and what is the whole point of the proof? Theorem 2.28. The Lebesgue -algebra is the completion of the Borel -algebra . Proof . Lebesgue measure is complete. If is Lebesgue measurable, then there is an set such that has Lebesgue measure zero. It follows by the approximation theorem that there is a Borel set with and . Thus, where and with , which proves that is the completion of .",\sigma \sigma \sigma L(\mathbb{R}^n) \sigma B(\mathbb{R}^n) A \subset \mathbb{R}^n F_\sigma F \subset A M = A \setminus F N \in G_\delta \mu (N) = 0 M \subset N A = F\cup M F \in B M \subset N \in B \mu (N ) = 0 L(\mathbb{R}^n) B(\mathbb{R}^n),"['measure-theory', 'borel-measures']"
75,Can we think of the Fourier series as a Bochner integral?,Can we think of the Fourier series as a Bochner integral?,,"$\newcommand{\norm}[1]{\|#1\|}$ $\newcommand{\vp}{\varphi}$ $\newcommand{\Z}{\mathbb Z}$ $\newcommand{\T}{\mathbf T}$ $\newcommand{\C}{\mathbf C}$ Let $\T$ denote the unit circle and $\lambda$ denote the normalized Haar measure on $\T$ . For each $n\in \Z$ let $\chi_n:\T\to \C$ be the function which takes $z$ to $z^n$ . For any $f\in L^2(\T, \lambda)$ we know that $$ f = \sum_{n\in \Z} \hat f(n) \chi_n $$ in $L^2(\T, \lambda)$ . This means that $$ \norm{f - \sum_{n=-N}^N \hat f(n)\chi_n}_2 \to 0 $$ as $N\to \infty$ . Question. My question is can we think of the sum $\sum_{n\in \Z} \hat f(n) \chi_n$ as a Bochner integral ? Here is the natural thing to go for. Let $c$ be the counting measure on $\Z$ and let $\vp:\Z\to L^2(\T, \lambda)$ be the function defined by $$ \vp(n) = \hat f(n) \chi_n $$ If $\vp$ were Bochner integrable then the integral $\int_\Z \vp\ dc$ exists and is nothing but $\sum_{n\in \Z} \hat f(n) \chi_n$ and things are fine. However, the Bochner integrability criterion asks for the finiteness of $\int_\Z \norm{\vp}_2\ dc$ , which is same as asking for the finiteness of $$ \sum_{n\in \Z} |\hat f(n)| $$ But since $\hat f$ is not necessarily in $\ell^1(\Z)$ , we cannot say that $\vp$ is Bochner integrable. In general, I would like to think of any infinite sum as an integral under the counting measure of a suitable function. The fact that I am unable to do this for the Fourier series is a bit disconcerting. Perhaps I am making a mistake somewhere?","Let denote the unit circle and denote the normalized Haar measure on . For each let be the function which takes to . For any we know that in . This means that as . Question. My question is can we think of the sum as a Bochner integral ? Here is the natural thing to go for. Let be the counting measure on and let be the function defined by If were Bochner integrable then the integral exists and is nothing but and things are fine. However, the Bochner integrability criterion asks for the finiteness of , which is same as asking for the finiteness of But since is not necessarily in , we cannot say that is Bochner integrable. In general, I would like to think of any infinite sum as an integral under the counting measure of a suitable function. The fact that I am unable to do this for the Fourier series is a bit disconcerting. Perhaps I am making a mistake somewhere?","\newcommand{\norm}[1]{\|#1\|} \newcommand{\vp}{\varphi} \newcommand{\Z}{\mathbb Z} \newcommand{\T}{\mathbf T} \newcommand{\C}{\mathbf C} \T \lambda \T n\in \Z \chi_n:\T\to \C z z^n f\in L^2(\T, \lambda) 
f = \sum_{n\in \Z} \hat f(n) \chi_n
 L^2(\T, \lambda) 
\norm{f - \sum_{n=-N}^N \hat f(n)\chi_n}_2 \to 0
 N\to \infty \sum_{n\in \Z} \hat f(n) \chi_n c \Z \vp:\Z\to L^2(\T, \lambda) 
\vp(n) = \hat f(n) \chi_n
 \vp \int_\Z \vp\ dc \sum_{n\in \Z} \hat f(n) \chi_n \int_\Z \norm{\vp}_2\ dc 
\sum_{n\in \Z} |\hat f(n)|
 \hat f \ell^1(\Z) \vp","['measure-theory', 'fourier-series']"
76,"The smallest $\sigma$-algebra in $X=\{1,2,3,4\}$ that contains a collection of subsets of $X$",The smallest -algebra in  that contains a collection of subsets of,"\sigma X=\{1,2,3,4\} X","I would like to find an efficient way to determine the smallest $\sigma$ -algebra $\sigma(F)$ in $X=\{1,2,3,4\}$ that contains one of the following $F$ 's: (a) $F=\{\{1\},\{2,3\}\}$ (b) $F=\{\{1,3\},\{2,3\}\}$ (c) $F=\{\{1\},\{1,3\}\}$ Before we begin our discussion, let us review some definitions related to $\sigma$ -algebra. We define a $\sigma$ -algebra in $X$ to be a collection of subsets of $X$ that is closed under complements, countable unions, and countable intersections. As for what is meant by $\sigma(F)$ , we define $$\sigma(F)=\bigcap\{\Lambda:\text{$\Lambda$ is a $\sigma$-algebra in $X$ containing $F$}\}.\tag{$*$}$$ For (a), I simply considered what it would be like to have $\Lambda_a$ as a $\sigma$ -algebra in $X$ containing $\{\{1\},\{2,3\}\}$ . For example, because $\{1\}\in\Lambda_a$ , we must have $\{1\}^c=\{2,3,4\}\in\Lambda_a$ . Likewise, we must have $\{2,3\}^c=\{1,4\}\in\Lambda_a$ , thereby leading to $\{2,3,4\}\cap\{1,4\}=\{4\}\in\Lambda_a$ . Continuing in this manner, I got $$\Lambda_a=\{\emptyset,\{1\},\{4\},\{2,3\},\{1,4\},\{1,2,3\},\{2,3,4\},X\}.$$ I claim that $\Lambda_a=\sigma(F)$ because if any set in $\Lambda_a$ is removed, the resulting product $\Lambda_a'$ will no longer be a $\sigma$ -algebra in $X$ containing $F$ . Now let me ask two questions : Is $\Lambda_a$ really equal to $\sigma(F)$ ? I did NOT even make use of ( $*$ ) to get $\sigma(F)$ ! Even if my approach is correct, it is kind of time-consuming. Is there any other approach that is both effective and efficient ? Thank you for your patience.","I would like to find an efficient way to determine the smallest -algebra in that contains one of the following 's: (a) (b) (c) Before we begin our discussion, let us review some definitions related to -algebra. We define a -algebra in to be a collection of subsets of that is closed under complements, countable unions, and countable intersections. As for what is meant by , we define For (a), I simply considered what it would be like to have as a -algebra in containing . For example, because , we must have . Likewise, we must have , thereby leading to . Continuing in this manner, I got I claim that because if any set in is removed, the resulting product will no longer be a -algebra in containing . Now let me ask two questions : Is really equal to ? I did NOT even make use of ( ) to get ! Even if my approach is correct, it is kind of time-consuming. Is there any other approach that is both effective and efficient ? Thank you for your patience.","\sigma \sigma(F) X=\{1,2,3,4\} F F=\{\{1\},\{2,3\}\} F=\{\{1,3\},\{2,3\}\} F=\{\{1\},\{1,3\}\} \sigma \sigma X X \sigma(F) \sigma(F)=\bigcap\{\Lambda:\text{\Lambda is a \sigma-algebra in X containing F}\}.\tag{*} \Lambda_a \sigma X \{\{1\},\{2,3\}\} \{1\}\in\Lambda_a \{1\}^c=\{2,3,4\}\in\Lambda_a \{2,3\}^c=\{1,4\}\in\Lambda_a \{2,3,4\}\cap\{1,4\}=\{4\}\in\Lambda_a \Lambda_a=\{\emptyset,\{1\},\{4\},\{2,3\},\{1,4\},\{1,2,3\},\{2,3,4\},X\}. \Lambda_a=\sigma(F) \Lambda_a \Lambda_a' \sigma X F \Lambda_a \sigma(F) * \sigma(F)","['real-analysis', 'measure-theory']"
77,Prove $\mu^*(A)=\nu(A)$ if there exists a cover $A\subset \cup_{n\geq1} B_n$ and $\mu^*(B_n)<\infty \;\forall n\geq 1$,Prove  if there exists a cover  and,\mu^*(A)=\nu(A) A\subset \cup_{n\geq1} B_n \mu^*(B_n)<\infty \;\forall n\geq 1,"Given $\mu : \mathscr{H} \to \mathbb{R}$ a pre-measure on $\mathscr{H}\subset X$ a semiring and $\mu^*$ the outer measure defined by $\mu$ , $\mathscr{A}=\sigma(\mathscr{H})$ and $\nu$ a measure such that $\nu|_\mathscr{H}=\mu$ , I want to show that If for $A\in\mathscr{A}$ there exist $B_n\subset X$ such that $A\subset\cup_{n\geq 1}B_n$ and $\mu^*(B_n)<\infty$ for all $n\geq 1$ , then $\mu^*(A)=\nu(A)$ . My attempt: I have already proven that $\mu^*(A)=\nu(A)$ for all $A\in\mathscr{A}$ that satisfy $\mu^*(A)<\infty$ but I am struggling to prove that this holds. (Original title edited)","Given a pre-measure on a semiring and the outer measure defined by , and a measure such that , I want to show that If for there exist such that and for all , then . My attempt: I have already proven that for all that satisfy but I am struggling to prove that this holds. (Original title edited)",\mu : \mathscr{H} \to \mathbb{R} \mathscr{H}\subset X \mu^* \mu \mathscr{A}=\sigma(\mathscr{H}) \nu \nu|_\mathscr{H}=\mu A\in\mathscr{A} B_n\subset X A\subset\cup_{n\geq 1}B_n \mu^*(B_n)<\infty n\geq 1 \mu^*(A)=\nu(A) \mu^*(A)=\nu(A) A\in\mathscr{A} \mu^*(A)<\infty,"['measure-theory', 'outer-measure']"
78,Measure of an interval contained in a Borel set,Measure of an interval contained in a Borel set,,"Let $\mathbb{Q}\cap [0,1]=\{x_1,x_2,x_3,\dots\}$ and define the open interval $$G_n=\left(x_n-\frac{1}{2^{n+2}},x_n+\frac{1}{2^{n+2}}\right),\,n\in\mathbb{N}.$$ Putting $G=\bigcup_{n=1}^{\infty}G_n$ , define the Borel set $B$ as $$B=[0,1]\cap G^c.$$ Consider the Lebesgue measure space $(\mathbb{R},\Lambda,\lambda).$ If $I\subset B\cup E$ , where $I$ is an interval and $\lambda(E)=0$ , then $\lambda(I)=0$ . The book in whick this question appears provides the following hint: ""If $I\subset [0,1]$ and $I$ is open, then $I\cap B^c\neq\emptyset$ "". To solve this exercise, I suspect it would be necessary to use the following result (which I've already proved): Let $G\subset \mathbb{R}$ be an open set and $E\subset G$ such that $\lambda(E)=0$ . Then $G\backslash E$ is dense in $G$ . However, I can't see how to proceed from here. Thanks in advance!","Let and define the open interval Putting , define the Borel set as Consider the Lebesgue measure space If , where is an interval and , then . The book in whick this question appears provides the following hint: ""If and is open, then "". To solve this exercise, I suspect it would be necessary to use the following result (which I've already proved): Let be an open set and such that . Then is dense in . However, I can't see how to proceed from here. Thanks in advance!","\mathbb{Q}\cap [0,1]=\{x_1,x_2,x_3,\dots\} G_n=\left(x_n-\frac{1}{2^{n+2}},x_n+\frac{1}{2^{n+2}}\right),\,n\in\mathbb{N}. G=\bigcup_{n=1}^{\infty}G_n B B=[0,1]\cap G^c. (\mathbb{R},\Lambda,\lambda). I\subset B\cup E I \lambda(E)=0 \lambda(I)=0 I\subset [0,1] I I\cap B^c\neq\emptyset G\subset \mathbb{R} E\subset G \lambda(E)=0 G\backslash E G","['measure-theory', 'lebesgue-measure']"
79,Using the Dominated convergence theorem in a sequence of Indicator functions,Using the Dominated convergence theorem in a sequence of Indicator functions,,"Let $Z_t\sim WN(0,\sigma^2)$ be a white noise. Consider a $\text{MA}(q)$ process: \begin{equation} X_t^q = \sum_{j=0}^{q} \theta_j Z_{t-j}, \quad X_t = \sum_{j=0}^{\infty} \theta_j Z_{t-j} \end{equation} where $\sum_{j=0}^{\infty} \theta_j^2 < \infty$ . Fix any $t$ and any $x$ , I want to show that: $$\lim_{q \to \infty}P(X_t^q \leq x ) = P(X_t \leq x)$$ For this, I tried the Dominated convergence theorem: Define $f_q = I_{[\,X_q \, \leq \, x\,]}$ and $f = I_{[\,X \, \leq \, x\,]}$ . It's easy to show that: $$\int f_q\,dP = P(X_t^q \leq x ), \quad \int f\, dP = P(X_t \leq x ) $$ Also, it's easy to show that $|f_q| \leq 1$ . It only remains to show that  the sequence $f_q$ converges pointwise to $f$ and I'm having a little trouble showing this. I think that the solution have to do with this two items questions: $X^q_t \to X_t$ pointwise? How I can show this? The first item implies that $f_q \to f$ pointwise? Some help, pls!","Let be a white noise. Consider a process: where . Fix any and any , I want to show that: For this, I tried the Dominated convergence theorem: Define and . It's easy to show that: Also, it's easy to show that . It only remains to show that  the sequence converges pointwise to and I'm having a little trouble showing this. I think that the solution have to do with this two items questions: pointwise? How I can show this? The first item implies that pointwise? Some help, pls!","Z_t\sim WN(0,\sigma^2) \text{MA}(q) \begin{equation}
X_t^q = \sum_{j=0}^{q} \theta_j Z_{t-j}, \quad X_t = \sum_{j=0}^{\infty} \theta_j Z_{t-j}
\end{equation} \sum_{j=0}^{\infty} \theta_j^2 < \infty t x \lim_{q \to \infty}P(X_t^q \leq x ) = P(X_t \leq x) f_q = I_{[\,X_q \, \leq \, x\,]} f = I_{[\,X \, \leq \, x\,]} \int f_q\,dP = P(X_t^q \leq x ), \quad \int f\, dP = P(X_t \leq x )  |f_q| \leq 1 f_q f X^q_t \to X_t f_q \to f","['measure-theory', 'stochastic-processes']"
80,Proving (non)existence of a measure space and sequence satisfying two properties,Proving (non)existence of a measure space and sequence satisfying two properties,,"Setting Let $\mathbb N_0 = \mathbb Z_{\geq 0}$ be the natural numbers including zero. Let $(X, \Sigma, \mu)$ be a measure space and $(p_i)_{i=0}^\infty$ be a sequence of measurable maps $p_i\colon X \to [0,1]$ satisfying $$\forall x \in X\colon ~\sum_{i=0}^\infty p_i(x) = 1, \tag{1}$$ and $$\forall i,j\in \mathbb N_0\colon~ \int_X p_i(x)p_j(x) \mathop{}\!\mathrm{d}\mu(x) = \begin{cases}    1/2&\text{if } i \neq j\\   1&\text{if } i = j. \end{cases}\tag{2}$$ Questions Can we prove that a pair $\left[(X, \Sigma, \mu), (p_i)_{i=0}^\infty \right]$ satisfying (1) and (2) can or cannot exist? If it can exist, can we construct an example? If it can exist, can we prove that the space could be $\sigma$ -finite or can we prove that it must not be $\sigma$ -finite? If it can exist, can we say anything about the uniform integrability of $p_i$ ? Any other interesting properties we can say about the pair? More generally, is this question even well-posed? Hopefully it's not trivial :) Attempts By summing over $i, j$ in (2), we find that $\mu(X)$ cannot be finite. Using the $L^p$ Dominated Convergence Theorem, we can prove that, for example, for a fixed $i$ , $$\lim_{j \to \infty}\int_X \left(p_i(x) p_j(x)\right)^2 \mathop{}\!\mathrm{d}\mu(x) = 0,$$ but this doesn't (at least I don't think) tell us that $$\lim_{j \to \infty} \int_X p_i(x) p_j(x) \mathop{}\!\mathrm{d}\mu(x) = 0,$$ which would prove nonexistence. This theorem can almost be applied, but not quite because I see no reason why $p_i(x)p_j(x)$ cannot be zero for some $x$ . I'm very unsure about this one, but looking at Vitali's convergence theorem and this paper , it seems like we can possibly apply them to say that either the measure space is not $\sigma$ -finite or $p_i$ is not uniformly integrable? Thanks! Any solutions or suggestions for how to proceed would be greatly appreciated :) Even a list of potentially relevant theorems and lemmas in measure theory would also be helpful.","Setting Let be the natural numbers including zero. Let be a measure space and be a sequence of measurable maps satisfying and Questions Can we prove that a pair satisfying (1) and (2) can or cannot exist? If it can exist, can we construct an example? If it can exist, can we prove that the space could be -finite or can we prove that it must not be -finite? If it can exist, can we say anything about the uniform integrability of ? Any other interesting properties we can say about the pair? More generally, is this question even well-posed? Hopefully it's not trivial :) Attempts By summing over in (2), we find that cannot be finite. Using the Dominated Convergence Theorem, we can prove that, for example, for a fixed , but this doesn't (at least I don't think) tell us that which would prove nonexistence. This theorem can almost be applied, but not quite because I see no reason why cannot be zero for some . I'm very unsure about this one, but looking at Vitali's convergence theorem and this paper , it seems like we can possibly apply them to say that either the measure space is not -finite or is not uniformly integrable? Thanks! Any solutions or suggestions for how to proceed would be greatly appreciated :) Even a list of potentially relevant theorems and lemmas in measure theory would also be helpful.","\mathbb N_0 = \mathbb Z_{\geq 0} (X, \Sigma, \mu) (p_i)_{i=0}^\infty p_i\colon X \to [0,1] \forall x \in X\colon ~\sum_{i=0}^\infty p_i(x) = 1, \tag{1} \forall i,j\in \mathbb N_0\colon~ \int_X p_i(x)p_j(x) \mathop{}\!\mathrm{d}\mu(x) = \begin{cases} 
  1/2&\text{if } i \neq j\\
  1&\text{if } i = j.
\end{cases}\tag{2} \left[(X, \Sigma, \mu), (p_i)_{i=0}^\infty \right] \sigma \sigma p_i i, j \mu(X) L^p i \lim_{j \to \infty}\int_X \left(p_i(x) p_j(x)\right)^2 \mathop{}\!\mathrm{d}\mu(x) = 0, \lim_{j \to \infty} \int_X p_i(x) p_j(x) \mathop{}\!\mathrm{d}\mu(x) = 0, p_i(x)p_j(x) x \sigma p_i","['measure-theory', 'sequence-of-function']"
81,Is unimodular stable under local isomorphisms?,Is unimodular stable under local isomorphisms?,,"Let $G$ and $H$ be locally compact groups. Suppose that $G$ and $H$ are locally isomorphic. If $G$ is unimodular, is it true that $H$ is unimodular ? Two topological groups $G$ and $H$ are said locally isomorphic if there exists open neighborhoods $V_G$ , $V_H$ of $e_G$ and $e_H$ and a homeomorphism $f:V_G \to V_H$ such that for all $x,y \in V_G$ such $xy \in V_G$ we have $f(xy)=f(x)f(y)$ and similarly for $f^{-1}$ .","Let and be locally compact groups. Suppose that and are locally isomorphic. If is unimodular, is it true that is unimodular ? Two topological groups and are said locally isomorphic if there exists open neighborhoods , of and and a homeomorphism such that for all such we have and similarly for .","G H G H G H G H V_G V_H e_G e_H f:V_G \to V_H x,y \in V_G xy \in V_G f(xy)=f(x)f(y) f^{-1}","['measure-theory', 'lie-groups', 'topological-groups', 'locally-compact-groups']"
82,To show countable sub-additivity of the Hausdorff measure on $\mathbb R^n$,To show countable sub-additivity of the Hausdorff measure on,\mathbb R^n,"For all $F\subset \mathbb R^n$ , we define $$\mathcal H_\delta^s(F) = \inf\left\{\sum_{i=1}^\infty |U_i|^s : F \subset \bigcup_{i=1}^\infty U_i, 0 \le |U_i| \le \delta \right\}$$ where $|U_i|$ is the diameter of the set $U_i$ , defined in the usual way. We also define $$\mathcal H^s(F) = \lim_{\delta\to 0} \mathcal H_\delta^s(F)$$ for every $F\subset\mathbb R^n$ . To show that $\mathcal H^s(F)$ is a measure, it is enough to prove that the following three properties are satisfied: (a) $\mathcal H^s(\varnothing) = 0$ , (b) $A \subset B \implies \mathcal H^s(A) \le \mathcal H^s(B)$ , (c) $\mathcal H^s\left(\bigcup_{i=1}^\infty A_i\right) \le \sum_{i=1}^\infty \mathcal H^s(A_i)$ with equality if $A_i$ 's are disjoint Borel sets. I need help with (c). (c) Following the ideas of the previous two parts, I would first like to show that $\mathcal H^s_\delta\left(\bigcup_{i=1}^\infty A_i\right) \le \sum_{i=1}^\infty \mathcal H^s_\delta(A_i)$ and then take limits as $\delta\to 0$ . Consider $A_i$ for some $i$ . Let $\{U_{ij}\}_{j=1}^\infty$ be a $\delta$ -cover of $A_i$ , i.e. $A_i \subset \bigcup_{j=1}^\infty U_{ij}$ . Then, $$\bigcup_{i=1}^\infty A_i \subset \bigcup_{i=1}^\infty \bigcup_{j=1}^\infty U_{ij}$$ i.e. the union of all covers is a cover for the union of $A_i$ . How do I proceed from here? I also need to show that equality holds if $A_i$ 's are disjoint Borel sets. Thanks for your help!","For all , we define where is the diameter of the set , defined in the usual way. We also define for every . To show that is a measure, it is enough to prove that the following three properties are satisfied: (a) , (b) , (c) with equality if 's are disjoint Borel sets. I need help with (c). (c) Following the ideas of the previous two parts, I would first like to show that and then take limits as . Consider for some . Let be a -cover of , i.e. . Then, i.e. the union of all covers is a cover for the union of . How do I proceed from here? I also need to show that equality holds if 's are disjoint Borel sets. Thanks for your help!","F\subset \mathbb R^n \mathcal H_\delta^s(F) = \inf\left\{\sum_{i=1}^\infty |U_i|^s : F \subset \bigcup_{i=1}^\infty U_i, 0 \le |U_i| \le \delta \right\} |U_i| U_i \mathcal H^s(F) = \lim_{\delta\to 0} \mathcal H_\delta^s(F) F\subset\mathbb R^n \mathcal H^s(F) \mathcal H^s(\varnothing) = 0 A \subset B \implies \mathcal H^s(A) \le \mathcal H^s(B) \mathcal H^s\left(\bigcup_{i=1}^\infty A_i\right) \le \sum_{i=1}^\infty \mathcal H^s(A_i) A_i \mathcal H^s_\delta\left(\bigcup_{i=1}^\infty A_i\right) \le \sum_{i=1}^\infty \mathcal H^s_\delta(A_i) \delta\to 0 A_i i \{U_{ij}\}_{j=1}^\infty \delta A_i A_i \subset \bigcup_{j=1}^\infty U_{ij} \bigcup_{i=1}^\infty A_i \subset \bigcup_{i=1}^\infty \bigcup_{j=1}^\infty U_{ij} A_i A_i","['real-analysis', 'measure-theory', 'hausdorff-measure']"
83,Showing a convolution of a $f\in C_c(\mathbb{R}^n)$ with $g\in L^p_{loc}(\mathbb{R}^n)$s continuous,Showing a convolution of a  with s continuous,f\in C_c(\mathbb{R}^n) g\in L^p_{loc}(\mathbb{R}^n),"I am trying to use Lebesgue's dominated convergence theorem to show that if $f\in C_c(\mathbb{R}^k)$ and $g\in L_{loc}^{1}(\mathbb{R}^k)$ then we will have that $f* g\in C(\mathbb{R}^k)$ . Now my idea was to take a sequence $x_n\rightarrow x$ and show that $(f*g)(x_n)\rightarrow (f*g)(x)$ . We have that $(f*g)(x_n)=\int_{\mathbb{R}^n}f(x_n-y)g(y)\,dy$ and $(f*g)(x)=\int_{\mathbb{R}^n}f(x-y)g(y)\,dy$ , and so we want to see that $\lim_{n\rightarrow \infty}\int_{\mathbb{R}^n}f(x_n-y)g(y)\,dy=\int_{\mathbb{R}^n}f(x-y)g(y)\,dy$ , and so the idea would be to apply the dominated convergence theorem to $h_n(y):=f(x_n-y)g(y)$ and $h(y):=f(x-y)g(y)$ Now Using the fact $f$ has compact support and is continuous, I was able to prove that $f(x_n-y)\rightarrow f(x-y)$ uniformly. First we check that we have that $f(x_n-y)\rightarrow f(x-y)$ uniformly. Since the function $f$ is continuous we have that for every fixed $y$ , $f(x_n-y)\rightarrow f(x-y)$ , and around each point we can find a neighborhood $V_y$ such that if $y'\in V_y$ , $|f(x_n-y')-f(x_n-y)|<\epsilon_y/3$ and $|f(x-y')-f(x-y)|<\epsilon_y/3$ . Now since $f(x_n-y)\rightarrow f(x-y)$ there exists $N_y\in \mathbb{N}$ such that for every $n>N_y$ we will have that $|f(x_n-y)-f(x-y)|<\epsilon_y/3$ . Using the triangle inequality we see that for every $y'\in V_y$ we have that $|f(x_n-y)-f(x-y)|<\epsilon_y$ for every $n>N_y$ . Now since the support of $f$ is compact , we can take a finite subcovering of this covering by open sets $\{V_y\}$ and choose $N:=\max N_y$ and $\epsilon:=\min \epsilon_y$ , so that for every $z\in K:=supp f$ and $n>N$ we have that $|f(x_n-z)-f(x-z)|<\epsilon$ . Since the choice of $\epsilon$ was arbitrary we get that $f(x_n-y)\rightarrow f(x-y)$ uniformly. Now I am not sure this can give me that $h_n\rightarrow h$ almost everywhere.And also we would need the fact that there exists an $h'\in L^1(\mathbb{R}^n)$ such that $|h_n(x)|\leq |h'(x)|$ almost everywhere in $\mathbb{R}^n$ for every $n$ , but this seems to be a bit hard since I only know that $g\in L_\text{loc}^1(\mathbb{R}^n)$ . Does anyone have any suggestions ? Thanks in advance. Attempt at solving this difficulties : Since $x_n\rightarrow x$ we can find an $N$ such that $x_n\in K$ for every $n\geq N$ , where $K$ is a compact set and so since $f$ has compact support we will have that $h_n$ will have it's support inside a compact set $K'$ for every $n$ greater than $N$ . And so know we can use the hypothesis that $g\in L_{loc}^1(\mathbb{R}^n)$ to get that there exists $M>0$ such that $|g(y)|\leq M$ for every $y\in K'$ , and so we can get that $h_n\rightarrow h$ since $|f(x_n-y)g(y)-f(x-y)g(y)|\leq |f(x_n-y)-f(x-y)||M|$ for every $x\in \mathbb{R}^n$ , and that $|h_n|\leq M'$ for every $n$ since $f$ has compact support. What do you guys think ? I would appreciate some input just to see if I made any mistake or not.","I am trying to use Lebesgue's dominated convergence theorem to show that if and then we will have that . Now my idea was to take a sequence and show that . We have that and , and so we want to see that , and so the idea would be to apply the dominated convergence theorem to and Now Using the fact has compact support and is continuous, I was able to prove that uniformly. First we check that we have that uniformly. Since the function is continuous we have that for every fixed , , and around each point we can find a neighborhood such that if , and . Now since there exists such that for every we will have that . Using the triangle inequality we see that for every we have that for every . Now since the support of is compact , we can take a finite subcovering of this covering by open sets and choose and , so that for every and we have that . Since the choice of was arbitrary we get that uniformly. Now I am not sure this can give me that almost everywhere.And also we would need the fact that there exists an such that almost everywhere in for every , but this seems to be a bit hard since I only know that . Does anyone have any suggestions ? Thanks in advance. Attempt at solving this difficulties : Since we can find an such that for every , where is a compact set and so since has compact support we will have that will have it's support inside a compact set for every greater than . And so know we can use the hypothesis that to get that there exists such that for every , and so we can get that since for every , and that for every since has compact support. What do you guys think ? I would appreciate some input just to see if I made any mistake or not.","f\in C_c(\mathbb{R}^k) g\in L_{loc}^{1}(\mathbb{R}^k) f* g\in C(\mathbb{R}^k) x_n\rightarrow x (f*g)(x_n)\rightarrow (f*g)(x) (f*g)(x_n)=\int_{\mathbb{R}^n}f(x_n-y)g(y)\,dy (f*g)(x)=\int_{\mathbb{R}^n}f(x-y)g(y)\,dy \lim_{n\rightarrow \infty}\int_{\mathbb{R}^n}f(x_n-y)g(y)\,dy=\int_{\mathbb{R}^n}f(x-y)g(y)\,dy h_n(y):=f(x_n-y)g(y) h(y):=f(x-y)g(y) f f(x_n-y)\rightarrow f(x-y) f(x_n-y)\rightarrow f(x-y) f y f(x_n-y)\rightarrow f(x-y) V_y y'\in V_y |f(x_n-y')-f(x_n-y)|<\epsilon_y/3 |f(x-y')-f(x-y)|<\epsilon_y/3 f(x_n-y)\rightarrow f(x-y) N_y\in \mathbb{N} n>N_y |f(x_n-y)-f(x-y)|<\epsilon_y/3 y'\in V_y |f(x_n-y)-f(x-y)|<\epsilon_y n>N_y f \{V_y\} N:=\max N_y \epsilon:=\min \epsilon_y z\in K:=supp f n>N |f(x_n-z)-f(x-z)|<\epsilon \epsilon f(x_n-y)\rightarrow f(x-y) h_n\rightarrow h h'\in L^1(\mathbb{R}^n) |h_n(x)|\leq |h'(x)| \mathbb{R}^n n g\in L_\text{loc}^1(\mathbb{R}^n) x_n\rightarrow x N x_n\in K n\geq N K f h_n K' n N g\in L_{loc}^1(\mathbb{R}^n) M>0 |g(y)|\leq M y\in K' h_n\rightarrow h |f(x_n-y)g(y)-f(x-y)g(y)|\leq |f(x_n-y)-f(x-y)||M| x\in \mathbb{R}^n |h_n|\leq M' n f","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'convolution']"
84,When is a locally Borel set Borel?,When is a locally Borel set Borel?,,"Let $X$ be a LCH space. Call $E\subseteq X$ locally Borel if $E\cap K$ is Borel for all compact $K\subseteq X$ . Evidently, locally Borel sets form a $\sigma$ -algebra and every Borel set is locally Borel. My question is the following. Suppose $X$ is a group, or more generally there is a Radon measure $\mu$ on $X$ (using, say, the definition in Folland: finite on compact sets, outer regular on all Borel sets, and inner regular on all open sets) such that $\mathrm{supp}\,\mu=X$ . Does it follow that every locally Borel set is Borel? Note some assumption on $X$ like this is necessary: for example, the first uncountable ordinal has subsets which are locally Borel but not Borel. On the other hand, if $X$ is $\sigma$ -compact, a set is Borel if and only if it is locally Borel.","Let be a LCH space. Call locally Borel if is Borel for all compact . Evidently, locally Borel sets form a -algebra and every Borel set is locally Borel. My question is the following. Suppose is a group, or more generally there is a Radon measure on (using, say, the definition in Folland: finite on compact sets, outer regular on all Borel sets, and inner regular on all open sets) such that . Does it follow that every locally Borel set is Borel? Note some assumption on like this is necessary: for example, the first uncountable ordinal has subsets which are locally Borel but not Borel. On the other hand, if is -compact, a set is Borel if and only if it is locally Borel.","X E\subseteq X E\cap K K\subseteq X \sigma X \mu X \mathrm{supp}\,\mu=X X X \sigma","['measure-theory', 'borel-sets', 'locally-compact-groups']"
85,Non-atomic measure on $\mathbb{Z}\cup\{\pm\infty\}$?,Non-atomic measure on ?,\mathbb{Z}\cup\{\pm\infty\},"I have a rather naive question? Is there a non-atomic measure on $\bar{Z}:=\mathbb{Z}\cup\{\pm\infty\}$ ? For example, the counting measure is atomic.","I have a rather naive question? Is there a non-atomic measure on ? For example, the counting measure is atomic.",\bar{Z}:=\mathbb{Z}\cup\{\pm\infty\},['measure-theory']
86,"Subsequence such that integrals converge over any Borel set in $[0,1]$",Subsequence such that integrals converge over any Borel set in,"[0,1]","I was reading this question: Existence of subsequence such that integration converge The idea is this. I have a sequence of uniformly bounded measurable functions $\{f_{n}\}$ on $[0,1]$ and I want to find a subsequence $f_{n_{j}}$ such that $\lim_{n \to \infty} \int_{A} f_{n_{j}}$ exists for all Borel sets $A$ . I can show the following: (1) If $\{S_{i}\}_{i}$ is a countable collection of Borel sets, then we can find a subsequence so that $\int_{S_{i}} f_{n_{j}}$ has a limit for all $S_{i}$ . (2) That this holds for all half-open half-closed intervals $(a_{i}, b_{i}]$ with rational endpoints. e know that the collection of half-open half-closed intervals with rational endpoints is countable and generates the Borel $\sigma$ -algebra, so the idea is now to approximate every Borel set using sets in this algebra and show that the result holds for them. In particular if $A \subset [0,1]$ is a Borel subset then we can find a sequence $I_{i}$ of half-open half-closed intervals with rational endpoints such that $I_{i} \downarrow A$ , but I'm not able to proceed further. Is it true that if $\int f_{n_{j}}$ has a limit on each $I_{i}$ , and $I_{i}$ is a decreasing sequence of sets, then $\int f_{n_{j}}$ has a limit on $\bigcap_{i} I_{i}$ ?","I was reading this question: Existence of subsequence such that integration converge The idea is this. I have a sequence of uniformly bounded measurable functions on and I want to find a subsequence such that exists for all Borel sets . I can show the following: (1) If is a countable collection of Borel sets, then we can find a subsequence so that has a limit for all . (2) That this holds for all half-open half-closed intervals with rational endpoints. e know that the collection of half-open half-closed intervals with rational endpoints is countable and generates the Borel -algebra, so the idea is now to approximate every Borel set using sets in this algebra and show that the result holds for them. In particular if is a Borel subset then we can find a sequence of half-open half-closed intervals with rational endpoints such that , but I'm not able to proceed further. Is it true that if has a limit on each , and is a decreasing sequence of sets, then has a limit on ?","\{f_{n}\} [0,1] f_{n_{j}} \lim_{n \to \infty} \int_{A} f_{n_{j}} A \{S_{i}\}_{i} \int_{S_{i}} f_{n_{j}} S_{i} (a_{i}, b_{i}] \sigma A \subset [0,1] I_{i} I_{i} \downarrow A \int f_{n_{j}} I_{i} I_{i} \int f_{n_{j}} \bigcap_{i} I_{i}","['sequences-and-series', 'measure-theory', 'lebesgue-integral', 'borel-sets']"
87,Conditions for equivalent definition of absolutely continuous measures,Conditions for equivalent definition of absolutely continuous measures,,"Let $\lambda, \mu$ be two real valued measures in the measurable space $(X, \mathcal{A})$ . Bartle's ""Elements of Integration"" Lemma 8.8 says that, if both are finite measures, then $\lambda \ll \mu$ if, and only if, for every $\varepsilon > 0$ , there exists $\delta > 0$ such that, for all $E \in \mathcal{A}$ , if $\mu(E)< \delta$ , then $\lambda(E)< \epsilon$ . The $(\Leftarrow)$ side of the proof is obvious, because if $\mu(E) = 0$ , then $\mu(E)< \delta$ for each $\delta > 0$ , which implies $\lambda(E) < \varepsilon$ for each $\varepsilon > 0$ . Then we have $\lambda(E) = 0$ . This proves that $\lambda \ll \mu$ . The other side of the proof goes as follows: suppose the conclusion of $(\Rightarrow)$ is false. Then there is $\varepsilon > 0 $ such that for each $n \in \mathbb{N}$ , there is $E_n \in \mathcal{A}$ with $\mu(E_n)< 2^{-n}$ and $\lambda(E_n) \geq \varepsilon$ . Define $F_n = \bigcup_{k=n}^\infty E_n$ . Then $F_n$ is a decreasing sequence of sets, $\mu(F_n) \leq 2^{-n + 1}$ , $\mu(F_1) \leq 1 < \infty$ and $\lambda(F_1)< \infty$ , because $\lambda$ is finite. Then $\mu(\bigcap F_n) = \lim \mu(F_n) = 0$ and $\lambda(\bigcap F_n) = \lim \lambda(F_n) \geq \varepsilon$ . It seems to me that the hypothesis that $\mu$ is finite can be dropped. Is this the case?","Let be two real valued measures in the measurable space . Bartle's ""Elements of Integration"" Lemma 8.8 says that, if both are finite measures, then if, and only if, for every , there exists such that, for all , if , then . The side of the proof is obvious, because if , then for each , which implies for each . Then we have . This proves that . The other side of the proof goes as follows: suppose the conclusion of is false. Then there is such that for each , there is with and . Define . Then is a decreasing sequence of sets, , and , because is finite. Then and . It seems to me that the hypothesis that is finite can be dropped. Is this the case?","\lambda, \mu (X, \mathcal{A}) \lambda \ll \mu \varepsilon > 0 \delta > 0 E \in \mathcal{A} \mu(E)< \delta \lambda(E)< \epsilon (\Leftarrow) \mu(E) = 0 \mu(E)< \delta \delta > 0 \lambda(E) < \varepsilon \varepsilon > 0 \lambda(E) = 0 \lambda \ll \mu (\Rightarrow) \varepsilon > 0  n \in \mathbb{N} E_n \in \mathcal{A} \mu(E_n)< 2^{-n} \lambda(E_n) \geq \varepsilon F_n = \bigcup_{k=n}^\infty E_n F_n \mu(F_n) \leq 2^{-n + 1} \mu(F_1) \leq 1 < \infty \lambda(F_1)< \infty \lambda \mu(\bigcap F_n) = \lim \mu(F_n) = 0 \lambda(\bigcap F_n) = \lim \lambda(F_n) \geq \varepsilon \mu","['measure-theory', 'absolute-continuity']"
88,"$\sum_n(-1)^n\int_Xf_n \, d\mu=\int_X\sum_n(-1)^nf_n \, d\mu$",,"\sum_n(-1)^n\int_Xf_n \, d\mu=\int_X\sum_n(-1)^nf_n \, d\mu","Let $(X,\mathcal{F},\mu)$ be measure space, $(f_n)_n$ be a non-increasing sequence of functions in $L^1(\mu)$ , converging $\mu$ -a.e to $0.$ Prove that $$\sum_n(-1)^n\int_Xf_n \, d\mu=\int_X\sum_n(-1)^nf_n \, d\mu.$$ To prove it, it's evident that we should use the dominated convergence theorem on $\sum_{k=1}^n(-1)^kf_k:$ $$\sum_{k=1}^n(-1)^k\int_Xf_k \, d\mu=\int_X\sum_{k=1}^n(-1)^kf_k \, d\mu$$ Since $(f_n)_n$ is a non-increasing sequence converging $\mu$ -a.e to $0$ (which means $f_n$ are non-negative $\mu$ -a.e), this shows that $(\sum_{k=1}^n(-1)^kf_k)_n$ converges $\mu$ -a.e (to $\sum_n(-1)^nf_n$ ), it remains to prove that $\sum_{k=1}^n(-1)^kf_k$ is dominated by a function $\phi \in L^1.$ Do you know how to have a verification?","Let be measure space, be a non-increasing sequence of functions in , converging -a.e to Prove that To prove it, it's evident that we should use the dominated convergence theorem on Since is a non-increasing sequence converging -a.e to (which means are non-negative -a.e), this shows that converges -a.e (to ), it remains to prove that is dominated by a function Do you know how to have a verification?","(X,\mathcal{F},\mu) (f_n)_n L^1(\mu) \mu 0. \sum_n(-1)^n\int_Xf_n \, d\mu=\int_X\sum_n(-1)^nf_n \, d\mu. \sum_{k=1}^n(-1)^kf_k: \sum_{k=1}^n(-1)^k\int_Xf_k \, d\mu=\int_X\sum_{k=1}^n(-1)^kf_k \, d\mu (f_n)_n \mu 0 f_n \mu (\sum_{k=1}^n(-1)^kf_k)_n \mu \sum_n(-1)^nf_n \sum_{k=1}^n(-1)^kf_k \phi \in L^1.","['real-analysis', 'measure-theory', 'sequence-of-function']"
89,variation of Vitali in $\mathbb{R}^2$,variation of Vitali in,\mathbb{R}^2,"Let $B(x, r)$ , be a two dimensional open disc with center $x \in \mathbb{R}^2$ and radius $r > 0$ . Consider a set $E \subset \mathbb{R}^2$ such that $E \subset \bigcup_{i = 1}^n B(x_i, r_i)$ and $\sum_{i = 1}^n r_i \leq 1$ Show that then there exists a collection of non-overlapping open discs $B(y_i, R_i)$ such that $E \subset \bigcup_{i = 1}^n B(y_i, R_i)$ and $\sum_{i = 1}^n R_i \leq 1$ Clearly if the balls $B(x_i, r_i)$ are non overlapping then we are done. If not then at least $2$ balls must overlap. First attempt Let $B(x_1,r_1)$ be the ball whose radius is the smallest such that $B(x_1,r_1)$ overlaps with at least one other ball. Pick $B(x_j,r_j)$ whose radius is maximal among all the balls overlapping with $B(x_1,r_1)$ , and note that the sums of the radius of the balls in $B(x_{j},r_{j} + r_1) \bigcup_{i = 2, i \neq j}^n B(x_i,r_i)$ is the same as the sum of the radius of the balls in $\bigcup_{i = 1}^n B(x_i, r_i)$ . The problem here is that $B(x_1,r_1)$ is not necessarily contained in $B(x_j,r_j + r_1)$ . Second attempt Let $B(x_1,r_1)$ be the ball whose radius is the smallest such that $B(x_1,r_1)$ overlaps with at least one other ball. Pick $B(x_j,r_j)$ whose radius is maximal among all the balls overlapping with $B(x_1,r_1)$ , and note that $B(x_1, r_1)$ is contained in $B(x_j, r_j + 2r_1)$ . The problem here is that the sums of the radius of the balls in $B(x_{j},r_{j} + 2r_1) \bigcup_{i = 2, i \neq j}^n B(x_i,r_i)$ is Not the same as the sum of the radius of the balls in $\bigcup_{i = 1}^n B(x_i, r_i)$ and therefore not necessarily less then or equal to $1$ . Since I want to cover $E$ and have radius that sum up to be less then or equal to $1$ , I know I want to maximize surface area while keeping the sum of the radi as small as possible so it dose feel logical to get rid of smaller circles while expanding upon larger once. Any help would be appreciated. Edit So after thinking about it a little longer I realized it might be impossible to create the disjoint collection of balls $B(y_i,R_i)$ such that each $y_i = x_i$ and I might have to move the discs. For example if $E$ was the union of $2$ balls of each radius $1/2$ , one centered at the origin and one centered at $(7/8,0)$ then there is no way to just expand one ball without moving it so that its radius remains $1$ but it covers the other ball. So now I am thinking start with letting $B(x_1,r_1)$ be the ball whose radius is the smallest such that $B(x_1,r_1)$ overlaps with at least one other ball. Pick $B(x_j,r_j)$ whose radius is maximal among all the balls overlapping with $B(x_1,r_1)$ , Consider the ball $B( ?,r_1 + r_j)$ so I need to find a suitable value for $?$ . I am temped to average the two centers $x_1, x_j$ but I know it should be closer to $x_j$ , but then that makes this really complicated.","Let , be a two dimensional open disc with center and radius . Consider a set such that and Show that then there exists a collection of non-overlapping open discs such that and Clearly if the balls are non overlapping then we are done. If not then at least balls must overlap. First attempt Let be the ball whose radius is the smallest such that overlaps with at least one other ball. Pick whose radius is maximal among all the balls overlapping with , and note that the sums of the radius of the balls in is the same as the sum of the radius of the balls in . The problem here is that is not necessarily contained in . Second attempt Let be the ball whose radius is the smallest such that overlaps with at least one other ball. Pick whose radius is maximal among all the balls overlapping with , and note that is contained in . The problem here is that the sums of the radius of the balls in is Not the same as the sum of the radius of the balls in and therefore not necessarily less then or equal to . Since I want to cover and have radius that sum up to be less then or equal to , I know I want to maximize surface area while keeping the sum of the radi as small as possible so it dose feel logical to get rid of smaller circles while expanding upon larger once. Any help would be appreciated. Edit So after thinking about it a little longer I realized it might be impossible to create the disjoint collection of balls such that each and I might have to move the discs. For example if was the union of balls of each radius , one centered at the origin and one centered at then there is no way to just expand one ball without moving it so that its radius remains but it covers the other ball. So now I am thinking start with letting be the ball whose radius is the smallest such that overlaps with at least one other ball. Pick whose radius is maximal among all the balls overlapping with , Consider the ball so I need to find a suitable value for . I am temped to average the two centers but I know it should be closer to , but then that makes this really complicated.","B(x, r) x \in \mathbb{R}^2 r > 0 E \subset \mathbb{R}^2 E \subset \bigcup_{i = 1}^n B(x_i, r_i) \sum_{i = 1}^n r_i \leq 1 B(y_i, R_i) E \subset \bigcup_{i = 1}^n B(y_i, R_i) \sum_{i = 1}^n R_i \leq 1 B(x_i, r_i) 2 B(x_1,r_1) B(x_1,r_1) B(x_j,r_j) B(x_1,r_1) B(x_{j},r_{j} + r_1) \bigcup_{i = 2, i \neq j}^n B(x_i,r_i) \bigcup_{i = 1}^n B(x_i, r_i) B(x_1,r_1) B(x_j,r_j + r_1) B(x_1,r_1) B(x_1,r_1) B(x_j,r_j) B(x_1,r_1) B(x_1, r_1) B(x_j, r_j + 2r_1) B(x_{j},r_{j} + 2r_1) \bigcup_{i = 2, i \neq j}^n B(x_i,r_i) \bigcup_{i = 1}^n B(x_i, r_i) 1 E 1 B(y_i,R_i) y_i = x_i E 2 1/2 (7/8,0) 1 B(x_1,r_1) B(x_1,r_1) B(x_j,r_j) B(x_1,r_1) B( ?,r_1 + r_j) ? x_1, x_j x_j","['real-analysis', 'measure-theory']"
90,Understanding the Lebesgue's Decomposition Theorem,Understanding the Lebesgue's Decomposition Theorem,,"In his book Bauer proves the Lebesgue's decomposition theorem . Actually he proves it only in the case where $\mu$ and $\nu$ are finite, leaving the $\sigma$ -finite case as an exercise. Looking at the proof however I don't see anywhere where the finiteness of $\mu$ is used. For the $\sigma$ -finite case I did the following: Since $\nu$ is $\sigma$ -finite we can find a partition $(A_n)$ of $\Omega$ into sets of finite $\nu$ measure.  For each $n$ , let $\nu_n$ denote the finite measure defined by $\nu_n(A):=\nu(A\cap A_n)$ for measurable $A$ . From the finite measure case there is a unique decomposition $$\nu_n=\nu_n^c+\nu_n^s \hspace{0.7cm}\nu_n^c\ll\mu \hspace{0.7cm} \nu_n^s\perp\mu.$$ For each $n$ , let $N_n$ be such that $\mu(N_n)=0=\nu_n^s(N_n^c)$ and let $N=\bigcup_{n\in\mathbb{N}}N_n$ . Define the measures $\nu_c$ and $\nu_s$ by $\nu_c(A):=\nu(A\cap N^c)$ and $\nu_s(A):=\nu(A\cap N)$ for measurable $A$ . We see that $\nu=\nu_c+\nu_s$ and $\nu_s \perp\mu$ . Also $\nu_c\ll\mu $ , since $\mu(A)=0$ implies $$\nu_c(A)=\nu(A \cap N^c)=\sum_{n=1}^\infty \nu_n(A\cap N^c)=\sum_{n=1}^\infty \nu^c_n(A\cap N^c)+\sum_{n=1}^\infty \nu^s_n(A\cap N^c)$$ $$\leq \sum_{n=1}^\infty \nu^c_n(A)+\sum_{n=1}^\infty \nu^s_n( N_n^c)=0$$ This shows existence as well as uniqueness, because if $\nu=\nu'_c+\nu'_s$ is any such decomposition, then defining the measures $\nu_n^{'c}(A):=\nu'_c(A\cap A_n)$ and $\nu_n^{'s}(A):=\nu'_s(A\cap A_n)$ for measurable $A$ and $n\in\mathbb{N}$ we get $$\nu_n=\nu_n^c+\nu_n^s=\nu_n^{'c}+\nu_n^{'s} \hspace{0.7cm}\nu_n^{'c}\ll\mu \hspace{0.7cm} \nu_n^{'s}\perp\mu $$ which implies $\nu_n^c=\nu_n^{'c}$ and $\nu_n^s=\nu_n^{'s}$ for each $n$ by uniqueness. Hence $\nu'_c=\sum_{n=1}^\infty \nu_n^{'c}$ and $\nu'_s=\sum_{n=1}^\infty \nu_n^{'s}$ are completely determined. Again I don't see where the $\sigma$ -finiteness of $\mu$ is needed in the argument. I also get confused by the hint Bauer gives for the exercise: Hint. For the existence proof use 17.6 . For the uniqueness proof choose a sequence $(A_n)$ of measurable sets with $A_n \uparrow \Omega$ and $\mu(A_n),\nu(A_n)$ finite for each $n$ , and consider the measures $\nu_n(A):=\nu(A\cap A_n)$ for mesurable $A$ and $n\in\mathbb{N}$ . EDIT: I think the requirement that $\mu$ be $\sigma$ -finite is due to the fact that Lebesgue's decomposition theorem is usually proven in conjunction with the Radon-Nikodym theorem. See my answer below. Still I don't get how to use the hint provided to prove existence and uniqueness. Any help is appreciated.","In his book Bauer proves the Lebesgue's decomposition theorem . Actually he proves it only in the case where and are finite, leaving the -finite case as an exercise. Looking at the proof however I don't see anywhere where the finiteness of is used. For the -finite case I did the following: Since is -finite we can find a partition of into sets of finite measure.  For each , let denote the finite measure defined by for measurable . From the finite measure case there is a unique decomposition For each , let be such that and let . Define the measures and by and for measurable . We see that and . Also , since implies This shows existence as well as uniqueness, because if is any such decomposition, then defining the measures and for measurable and we get which implies and for each by uniqueness. Hence and are completely determined. Again I don't see where the -finiteness of is needed in the argument. I also get confused by the hint Bauer gives for the exercise: Hint. For the existence proof use 17.6 . For the uniqueness proof choose a sequence of measurable sets with and finite for each , and consider the measures for mesurable and . EDIT: I think the requirement that be -finite is due to the fact that Lebesgue's decomposition theorem is usually proven in conjunction with the Radon-Nikodym theorem. See my answer below. Still I don't get how to use the hint provided to prove existence and uniqueness. Any help is appreciated.","\mu \nu \sigma \mu \sigma \nu \sigma (A_n) \Omega \nu n \nu_n \nu_n(A):=\nu(A\cap A_n) A \nu_n=\nu_n^c+\nu_n^s \hspace{0.7cm}\nu_n^c\ll\mu \hspace{0.7cm} \nu_n^s\perp\mu. n N_n \mu(N_n)=0=\nu_n^s(N_n^c) N=\bigcup_{n\in\mathbb{N}}N_n \nu_c \nu_s \nu_c(A):=\nu(A\cap N^c) \nu_s(A):=\nu(A\cap N) A \nu=\nu_c+\nu_s \nu_s \perp\mu \nu_c\ll\mu  \mu(A)=0 \nu_c(A)=\nu(A \cap N^c)=\sum_{n=1}^\infty \nu_n(A\cap N^c)=\sum_{n=1}^\infty \nu^c_n(A\cap N^c)+\sum_{n=1}^\infty \nu^s_n(A\cap N^c) \leq \sum_{n=1}^\infty \nu^c_n(A)+\sum_{n=1}^\infty \nu^s_n( N_n^c)=0 \nu=\nu'_c+\nu'_s \nu_n^{'c}(A):=\nu'_c(A\cap A_n) \nu_n^{'s}(A):=\nu'_s(A\cap A_n) A n\in\mathbb{N} \nu_n=\nu_n^c+\nu_n^s=\nu_n^{'c}+\nu_n^{'s} \hspace{0.7cm}\nu_n^{'c}\ll\mu \hspace{0.7cm} \nu_n^{'s}\perp\mu  \nu_n^c=\nu_n^{'c} \nu_n^s=\nu_n^{'s} n \nu'_c=\sum_{n=1}^\infty \nu_n^{'c} \nu'_s=\sum_{n=1}^\infty \nu_n^{'s} \sigma \mu (A_n) A_n \uparrow \Omega \mu(A_n),\nu(A_n) n \nu_n(A):=\nu(A\cap A_n) A n\in\mathbb{N} \mu \sigma","['measure-theory', 'lebesgue-measure', 'radon-nikodym']"
91,"Show that $F(x)=o(x^{1/q} )$, where $x \to +\infty$, whith $q=\frac{p-1}{p}.$","Show that , where , whith",F(x)=o(x^{1/q} ) x \to +\infty q=\frac{p-1}{p}.,"Let $f \in \mathcal{L}^p$ , with $1<p<+\infty$ . For all $x\geqslant 0$ , we define $\displaystyle{F(x)= \int_0^x f(t)dt}$ . Show that $F$ is uniformely continuous on $\mathbb{R}$ . Show that $F(x)=o(x^{1/q} )$ , where $x \to +\infty$ , whith $q=\frac{p}{1-p}.$ My attempt : let $0\leqslant x \leqslant y,$ \begin{align*}|F(y)-F(x)|&=\left|\int_x^yf(t)dt\right|\\&\leqslant\int_{\mathbb{R}}1_{[x,y]}(t)|f(t)|dt\\&  \leqslant (y-x)^{1/q} \left(\int_{\mathbb{R}} |f(t)|^p dt \right)^{1/p} \text{(by Hölder's inequality)} \\&\leqslant(y-x)^{1/q}\; ||f||p.\end{align*} Let $a>0$ (fixed) and $x>a$ , $|F(x)-F(a)|\leqslant (x-a)^{1/q}\; ||f||p$ , then $|F(x)|\leqslant  |F(a)|+(x-a)^{1/q}\; ||f||p$ $\implies $ $\dfrac{|F(x)|}{x^{1/q}}\leqslant  \dfrac{|F(a)|}{x^{1/q}}+(1-\frac{a}{x})^{1/q}\; ||f||p$ . I got stuck here, any help is highly appreciated.","Let , with . For all , we define . Show that is uniformely continuous on . Show that , where , whith My attempt : let Let (fixed) and , , then . I got stuck here, any help is highly appreciated.","f \in \mathcal{L}^p 1<p<+\infty x\geqslant 0 \displaystyle{F(x)= \int_0^x f(t)dt} F \mathbb{R} F(x)=o(x^{1/q} ) x \to +\infty q=\frac{p}{1-p}. 0\leqslant x \leqslant y, \begin{align*}|F(y)-F(x)|&=\left|\int_x^yf(t)dt\right|\\&\leqslant\int_{\mathbb{R}}1_{[x,y]}(t)|f(t)|dt\\&  \leqslant (y-x)^{1/q} \left(\int_{\mathbb{R}} |f(t)|^p dt \right)^{1/p} \text{(by Hölder's inequality)} \\&\leqslant(y-x)^{1/q}\; ||f||p.\end{align*} a>0 x>a |F(x)-F(a)|\leqslant (x-a)^{1/q}\; ||f||p |F(x)|\leqslant  |F(a)|+(x-a)^{1/q}\; ||f||p \implies  \dfrac{|F(x)|}{x^{1/q}}\leqslant  \dfrac{|F(a)|}{x^{1/q}}+(1-\frac{a}{x})^{1/q}\; ||f||p","['integration', 'measure-theory', 'lebesgue-integral']"
92,if continuous function $f$ is zero almost everywhere then $f = 0$ everywhere,if continuous function  is zero almost everywhere then  everywhere,f f = 0,"If the function $f:G \to \mathbb{R}$ with $G$ a domain in $\mathbb{R}^n$ ,and $f$ is continuous. Prove if $f = 0$ almost everywhere(In Lebesgue measure) then $f = 0$ everywhere. My attempt: w.l.o.g assume $f(x)>0$ for some $x$ ,since $f$ is continuous ,there exist a neighborhood of $x$ with all $f(y)>0$ on the neighborhood,and the neighborhood is not measure zero.So we have the result. Is my proof correct?","If the function with a domain in ,and is continuous. Prove if almost everywhere(In Lebesgue measure) then everywhere. My attempt: w.l.o.g assume for some ,since is continuous ,there exist a neighborhood of with all on the neighborhood,and the neighborhood is not measure zero.So we have the result. Is my proof correct?",f:G \to \mathbb{R} G \mathbb{R}^n f f = 0 f = 0 f(x)>0 x f x f(y)>0,"['real-analysis', 'measure-theory', 'solution-verification']"
93,Volume / measure of Minkowski sum $C+C$ (e.g. if $C$ is star-shaped),Volume / measure of Minkowski sum  (e.g. if  is star-shaped),C+C C,"Let $C \subset \Bbb R^d$ be a Lebesgue-measurable subset such that $C+C = \{x+y \mid  x,y\in C\}$ is measurable. What can we say about the measure (the volume) of $C+C$ ? I know that if $C$ is convex, then $C+C=2C$ , so $m(C+C)=2^d m(C)$ . Is this still true if $C$ is star-shaped , i.e. $[x,y] \subset C$ for every $x,\in C$ ? This is the most interesting case to me. (Some other questions are: What are some other sufficient conditions to have $m(C+C)=2^d m(C)$ ? I know that $2C \subset C+C$ so $2^d m(C) \leq m(C+C)$ always holds).","Let be a Lebesgue-measurable subset such that is measurable. What can we say about the measure (the volume) of ? I know that if is convex, then , so . Is this still true if is star-shaped , i.e. for every ? This is the most interesting case to me. (Some other questions are: What are some other sufficient conditions to have ? I know that so always holds).","C \subset \Bbb R^d C+C = \{x+y \mid  x,y\in C\} C+C C C+C=2C m(C+C)=2^d m(C) C [x,y] \subset C x,\in C m(C+C)=2^d m(C) 2C \subset C+C 2^d m(C) \leq m(C+C)","['measure-theory', 'lebesgue-measure', 'convex-geometry']"
94,First moment of the measure and interval escaping to infinity,First moment of the measure and interval escaping to infinity,,"Let $\mu$ be a finite Borel measure on $\mathbb{R}$ , and $$L = \lim_{t \to +\infty} \int_{t-1}^{t+1} x d \mu (x).$$ If $\displaystyle  \int_\mathbb{R} |x| d \mu (x) < \infty$ , then by Dominated Convergence $L<\infty$ . What would be an example of $\mu$ for which $L=\infty$ ? I tried $$d \mu (x) = \frac{d x}{(1+|x|)^p},$$ then the conditions $\mu$ being finite and its first moment infinite imply $p \in (1,2]$ , however for this $L<\infty$ .","Let be a finite Borel measure on , and If , then by Dominated Convergence . What would be an example of for which ? I tried then the conditions being finite and its first moment infinite imply , however for this .","\mu \mathbb{R} L = \lim_{t \to +\infty} \int_{t-1}^{t+1} x d \mu (x). \displaystyle  \int_\mathbb{R} |x| d \mu (x) < \infty L<\infty \mu L=\infty d \mu (x) = \frac{d x}{(1+|x|)^p}, \mu p \in (1,2] L<\infty","['real-analysis', 'measure-theory', 'convergence-divergence']"
95,Is the Jordan content a pre-measure?,Is the Jordan content a pre-measure?,,"I am currently dealing with the theory of the Jordan content $\iota: \mathcal{J}(\mathbb{R}^n) \rightarrow [0,\infty]$ where $\mathcal{J}(\mathbb{R}^n)$ denotes the ring of Jordan-measurable sets. I asked myself the question, whether it is a pre-measure. Let $(A_k) \in \mathcal{J}(\mathbb{R}^n)^{\mathbb{N}}$ be a disjoint set-sequence such that $\biguplus_{k=1}^\infty A_k \in \mathcal{J}(\mathbb{R}^n)$ . From finite additivity and monotonicity of the Jordan content, we obtain: $$\sum_{k=1}^n \iota(A_k)=\iota \left( \biguplus_{k=1}^n A_k \right) \leq \iota \left( \biguplus_{k=1}^\infty A_k \right)$$ and thus $\sum_{k=1}^\infty \iota(A_k) \leq \iota( \biguplus_{k=1}^\infty A_k)$ . Unfortunately I have no clue how to prove the other ineqality (or provide a counterexample) and would appreciate any hint you could give me.","I am currently dealing with the theory of the Jordan content where denotes the ring of Jordan-measurable sets. I asked myself the question, whether it is a pre-measure. Let be a disjoint set-sequence such that . From finite additivity and monotonicity of the Jordan content, we obtain: and thus . Unfortunately I have no clue how to prove the other ineqality (or provide a counterexample) and would appreciate any hint you could give me.","\iota: \mathcal{J}(\mathbb{R}^n) \rightarrow [0,\infty] \mathcal{J}(\mathbb{R}^n) (A_k) \in \mathcal{J}(\mathbb{R}^n)^{\mathbb{N}} \biguplus_{k=1}^\infty A_k \in \mathcal{J}(\mathbb{R}^n) \sum_{k=1}^n \iota(A_k)=\iota \left( \biguplus_{k=1}^n A_k \right) \leq \iota \left( \biguplus_{k=1}^\infty A_k \right) \sum_{k=1}^\infty \iota(A_k) \leq \iota( \biguplus_{k=1}^\infty A_k)",['measure-theory']
96,"If $π$ is the projection of a surface $M$ onto the 2-sphere $S^2$, then $σ_{S^2}(B)=\int_{π^{-1}(B)}σ_M(dy)\frac{|⟨ν_M(y),π(y)⟩|}{|y|^2}$","If  is the projection of a surface  onto the 2-sphere , then","π M S^2 σ_{S^2}(B)=\int_{π^{-1}(B)}σ_M(dy)\frac{|⟨ν_M(y),π(y)⟩|}{|y|^2}","Let $U\subseteq\mathbb R^2$ be open, $\phi:U\to\mathbb R^3$ be an immersion and a topological embedding of $U$ onto $M:=\phi(U)$$^1$ , $\nu_M(x)$ denote the unit normal vector of $M$ with $$\det\left({\rm D}\phi(u),\nu_M(x)\right)>0\tag1$$ for all $x\in M$ and $u=\phi^{-1}(x)$$^2$ , $\sigma_M$ denote the surface measure on $M$$^3$ and $$\pi:\mathbb R^3\setminus\{0\}\to S^2\;,\;\;\;x\mapsto\frac x{|x|}$$ denote the projection of $\mathbb R^3\setminus\{0\}$ onto the unit 2-sphere $S^2$ . Assume $\left.\pi\right|_M$ is injective. How can we show that $$\sigma_{S^2}(B)=\int_{\pi^{-1}(B)}\sigma_M({\rm d}y)\frac{\left|\langle\nu_M(y),\pi(y)\rangle\right|}{|y|^2}\tag5$$ for all $B\in\mathcal B(S^2)$ with $B\subseteq\pi(M)$ ? $^1$ which is to say that $M$ is a 2-dimensional embedded submanifold of $\mathbb R^3$ with global chart $\phi$ . $^2$ i.e. $$\nu_M\circ\phi=\frac{\partial_1\phi\times\partial_2\phi}{\left|\partial_1\phi\times\partial_2\phi\right|}\tag2.$$ $^3$ i.e. $$\sigma_M=\sqrt{g_\phi}\left.\lambda^2\right|_U\circ\phi^{-1}\tag3,$$ where $J_\phi$ is the Jacobian of $\phi$ and $$g_\phi:=\det\left(J_\phi^TJ_\phi\right)=\left|\partial_1\phi\times\partial_2\phi\right|^2\tag4.$$","Let be open, be an immersion and a topological embedding of onto , denote the unit normal vector of with for all and , denote the surface measure on and denote the projection of onto the unit 2-sphere . Assume is injective. How can we show that for all with ? which is to say that is a 2-dimensional embedded submanifold of with global chart . i.e. i.e. where is the Jacobian of and","U\subseteq\mathbb R^2 \phi:U\to\mathbb R^3 U M:=\phi(U)^1 \nu_M(x) M \det\left({\rm D}\phi(u),\nu_M(x)\right)>0\tag1 x\in M u=\phi^{-1}(x)^2 \sigma_M M^3 \pi:\mathbb R^3\setminus\{0\}\to S^2\;,\;\;\;x\mapsto\frac x{|x|} \mathbb R^3\setminus\{0\} S^2 \left.\pi\right|_M \sigma_{S^2}(B)=\int_{\pi^{-1}(B)}\sigma_M({\rm d}y)\frac{\left|\langle\nu_M(y),\pi(y)\rangle\right|}{|y|^2}\tag5 B\in\mathcal B(S^2) B\subseteq\pi(M) ^1 M \mathbb R^3 \phi ^2 \nu_M\circ\phi=\frac{\partial_1\phi\times\partial_2\phi}{\left|\partial_1\phi\times\partial_2\phi\right|}\tag2. ^3 \sigma_M=\sqrt{g_\phi}\left.\lambda^2\right|_U\circ\phi^{-1}\tag3, J_\phi \phi g_\phi:=\det\left(J_\phi^TJ_\phi\right)=\left|\partial_1\phi\times\partial_2\phi\right|^2\tag4.","['measure-theory', 'differential-geometry', 'surfaces', 'geometric-measure-theory', 'submanifold']"
97,When am I allowed to integrate by parts?,When am I allowed to integrate by parts?,,"My book, on general integration, builds a lot of theory around e.g. the Fubini-Tonelli theorem and when it can/can't be applied, but does not do the same for integration by parts. Perhaps it's just always allowed, but it does not say that explicitly either. In particular, when evaluating ""real integrals"", my professor and others on the internet seem to just use it without justification. So my question is: What are the necessary and sufficient conditions for using integration by parts? Searching the internet does not particularly help, because the wording of the question is similar to that of ""when is it helpful to integrate by parts"", as opposed to ""when am I allowed to integrate by parts"".","My book, on general integration, builds a lot of theory around e.g. the Fubini-Tonelli theorem and when it can/can't be applied, but does not do the same for integration by parts. Perhaps it's just always allowed, but it does not say that explicitly either. In particular, when evaluating ""real integrals"", my professor and others on the internet seem to just use it without justification. So my question is: What are the necessary and sufficient conditions for using integration by parts? Searching the internet does not particularly help, because the wording of the question is similar to that of ""when is it helpful to integrate by parts"", as opposed to ""when am I allowed to integrate by parts"".",,"['real-analysis', 'integration', 'measure-theory']"
98,Pointwise approximation of a nested function by simple functions,Pointwise approximation of a nested function by simple functions,,"Let $(\Omega,\mathscr F)$ be a measurable space and $\mathscr G\subseteq\mathscr F$ a $\sigma$ -subalgebra of $\mathscr F$ . Let $(Y,\mathscr Y)$ be another measurable space. Suppose that $f:\Omega\times Y\to\mathbb R$ is a real-valued function measurable with respect to the product $\sigma$ -algebra $\mathscr F\otimes\mathscr Y$ (where $\mathbb R$ is endowed with the Borel $\sigma$ -algebra). Finally, suppose that $g:\Omega\to Y$ is a $\mathscr G/\mathscr Y$ - measurable function (note that $\mathscr G$ is the $\sigma$ -subalgebra here). Now consider the following nested function mapping from $\Omega$ to $\mathbb R$ : \begin{align*} \omega\mapsto f(\omega,g(\omega)) \end{align*} I am wondering whether this nested function can be approximated by simple functions of sorts of the following form: \begin{align*} f(\omega,g(\omega))\approx\sum_{i=1}^n I_{G_i}(\omega)f(\omega,y_i)\quad\text{for each $\omega\in\Omega$,}\tag{$*$} \end{align*} where $n$ is a positive integer; $y_1,\ldots,y_n$ are elements of the set $Y$ ; $G_1,\ldots, G_n$ are disjoint sets in $\mathscr G$ whose union is $\Omega$ ; and $I_{G_i}$ is the indicator function of $G_i$ for each $i\in\{1,\ldots,n\}$ . The “ $\approx$ ” in ( $*$ ) is in the usual sense: there exists a sequence of functions of the form on the right-hand side converging pointwise (for each $\omega\in\Omega$ ) to the left-hand side. Note that no topological structure on $(Y,\mathscr Y)$ is assumed. Any suggestion about or reference to a proof or a counterexample would be greatly appreciated. UPDATE: The original conjecture is false (see below), so I am going to refine it as follows. Let $\mathbb P$ be a probability measure on $(\Omega,\mathscr F)$ and suppose that $f$ is bounded. Can the integral of $\omega\mapsto f(\omega,g(\omega))$ be approximated by integrals of functions of the form on the right-hand side of ( $*$ )? More precisely, let \begin{align*} \mathcal H\equiv\{h:\Omega\to\mathbb R\mid&\bullet h(\omega)=\sum_{i=1}^nI_{G_i}(\omega)f(\omega,y_i)\text{ for each $\omega\in\Omega$},\\ &\bullet n\in\mathbb N,\\ &\bullet y_1,\ldots,y_n\in Y,\\ &\bullet \text{$G_1,\ldots, G_n$ are disjoint sets in $\mathscr G$ whose union is $\Omega$}\}. \end{align*} Does there exist a sequence $(h_m)_{m\in\mathbb N}$ in $\mathcal H$ such that \begin{align*} \lim_{m\to\infty}\left\{\int_{\Omega}h_m(\omega)\,\mathrm d\mathbb P(\omega)\right\}=\int_{\Omega}f(\omega,g(\omega))\,\mathrm d\mathbb P(\omega)? \end{align*} My hunch (and hope, indeed) is that some kind of countability argument due to the ( $\sigma$ -)finiteness of $\mathbb P$ may make the approximation for at least integrals work. To see why pointwise approximation does not work, let $(\Omega,\mathscr F)$ and $(Y,\mathscr Y)$ both be $\mathbb R$ endowed with the discrete $\sigma$ -algebra and $\mathscr G=\mathscr F$ . Let $g$ be the identity function and $f$ the indicator function of the diagonal $$D\equiv\{(x,x)\,|\,x\in\mathbb R\}.$$ Note that the diagonal is $\mathscr F\otimes\mathscr F$ -measurable, since it is of the form $$D=\bigcap_{m\in\mathbb N}\bigcup_{q\in\mathbb Q}\left[q-\frac{1}{m},q+\frac{1}{m}\right]\times\left[q-\frac{1}{m},q+\frac{1}{m}\right].$$ Then, $$f(\omega,g(\omega))=1\quad\text{for each $\omega\in\mathbb R$}.$$ For any sequence $(h_m)_{m\in\mathbb N}$ of functions in $\mathcal H$ , let $\widetilde Y$ denote the union of all the $y_i$ ’s appearing in the definition of the $h_m$ ’s. Then, $\widetilde Y$ is a countable union of finite sets, so it is countable. Taking $\widetilde\omega\in\mathbb R\setminus\widetilde Y$ , one can see that $h_m(\widetilde\omega)=0$ for each $m\in\mathbb N$ , so pointwise convergence fails at $\widetilde\omega$ .","Let be a measurable space and a -subalgebra of . Let be another measurable space. Suppose that is a real-valued function measurable with respect to the product -algebra (where is endowed with the Borel -algebra). Finally, suppose that is a - measurable function (note that is the -subalgebra here). Now consider the following nested function mapping from to : I am wondering whether this nested function can be approximated by simple functions of sorts of the following form: where is a positive integer; are elements of the set ; are disjoint sets in whose union is ; and is the indicator function of for each . The “ ” in ( ) is in the usual sense: there exists a sequence of functions of the form on the right-hand side converging pointwise (for each ) to the left-hand side. Note that no topological structure on is assumed. Any suggestion about or reference to a proof or a counterexample would be greatly appreciated. UPDATE: The original conjecture is false (see below), so I am going to refine it as follows. Let be a probability measure on and suppose that is bounded. Can the integral of be approximated by integrals of functions of the form on the right-hand side of ( )? More precisely, let Does there exist a sequence in such that My hunch (and hope, indeed) is that some kind of countability argument due to the ( -)finiteness of may make the approximation for at least integrals work. To see why pointwise approximation does not work, let and both be endowed with the discrete -algebra and . Let be the identity function and the indicator function of the diagonal Note that the diagonal is -measurable, since it is of the form Then, For any sequence of functions in , let denote the union of all the ’s appearing in the definition of the ’s. Then, is a countable union of finite sets, so it is countable. Taking , one can see that for each , so pointwise convergence fails at .","(\Omega,\mathscr F) \mathscr G\subseteq\mathscr F \sigma \mathscr F (Y,\mathscr Y) f:\Omega\times Y\to\mathbb R \sigma \mathscr F\otimes\mathscr Y \mathbb R \sigma g:\Omega\to Y \mathscr G/\mathscr Y \mathscr G \sigma \Omega \mathbb R \begin{align*}
\omega\mapsto f(\omega,g(\omega))
\end{align*} \begin{align*}
f(\omega,g(\omega))\approx\sum_{i=1}^n I_{G_i}(\omega)f(\omega,y_i)\quad\text{for each \omega\in\Omega,}\tag{*}
\end{align*} n y_1,\ldots,y_n Y G_1,\ldots, G_n \mathscr G \Omega I_{G_i} G_i i\in\{1,\ldots,n\} \approx * \omega\in\Omega (Y,\mathscr Y) \mathbb P (\Omega,\mathscr F) f \omega\mapsto f(\omega,g(\omega)) * \begin{align*}
\mathcal H\equiv\{h:\Omega\to\mathbb R\mid&\bullet h(\omega)=\sum_{i=1}^nI_{G_i}(\omega)f(\omega,y_i)\text{ for each \omega\in\Omega},\\
&\bullet n\in\mathbb N,\\
&\bullet y_1,\ldots,y_n\in Y,\\
&\bullet \text{G_1,\ldots, G_n are disjoint sets in \mathscr G whose union is \Omega}\}.
\end{align*} (h_m)_{m\in\mathbb N} \mathcal H \begin{align*}
\lim_{m\to\infty}\left\{\int_{\Omega}h_m(\omega)\,\mathrm d\mathbb P(\omega)\right\}=\int_{\Omega}f(\omega,g(\omega))\,\mathrm d\mathbb P(\omega)?
\end{align*} \sigma \mathbb P (\Omega,\mathscr F) (Y,\mathscr Y) \mathbb R \sigma \mathscr G=\mathscr F g f D\equiv\{(x,x)\,|\,x\in\mathbb R\}. \mathscr F\otimes\mathscr F D=\bigcap_{m\in\mathbb N}\bigcup_{q\in\mathbb Q}\left[q-\frac{1}{m},q+\frac{1}{m}\right]\times\left[q-\frac{1}{m},q+\frac{1}{m}\right]. f(\omega,g(\omega))=1\quad\text{for each \omega\in\mathbb R}. (h_m)_{m\in\mathbb N} \mathcal H \widetilde Y y_i h_m \widetilde Y \widetilde\omega\in\mathbb R\setminus\widetilde Y h_m(\widetilde\omega)=0 m\in\mathbb N \widetilde\omega","['real-analysis', 'measure-theory', 'reference-request', 'conditional-expectation']"
99,Proving outer measure property,Proving outer measure property,,"I am self-studying analysis by Sheldon Axler. This is the one of exercise problem in his book. He uses $|\cdot|$ to indicate the outer measure. Prove that if $A\subset \mathbb{R}$ and $t>0$ , then $|A|=|A\cap(-t, t)|+|A\cap(\mathbb{R}\setminus(-t, t))|$ . $|A|\leq|A\cap(-t, t)|+|A\cap(\mathbb{R}\setminus(-t, t))|$ is obvious. But how do I prove inequality from the opposite side? And in his next exercise, he somehow extends the property: Prove that $|A|=\lim_{t\rightarrow\infty}|A\cap(-t, t)|$ for all $A\subset\mathbb{R}$ . Does this problem related to the previous problem? Any hints would be appreciated. Thanks","I am self-studying analysis by Sheldon Axler. This is the one of exercise problem in his book. He uses to indicate the outer measure. Prove that if and , then . is obvious. But how do I prove inequality from the opposite side? And in his next exercise, he somehow extends the property: Prove that for all . Does this problem related to the previous problem? Any hints would be appreciated. Thanks","|\cdot| A\subset \mathbb{R} t>0 |A|=|A\cap(-t, t)|+|A\cap(\mathbb{R}\setminus(-t, t))| |A|\leq|A\cap(-t, t)|+|A\cap(\mathbb{R}\setminus(-t, t))| |A|=\lim_{t\rightarrow\infty}|A\cap(-t, t)| A\subset\mathbb{R}",['real-analysis']
