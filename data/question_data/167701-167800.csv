,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Poker dice probability,Poker dice probability,,"I am working on a maths excersice and got stuck on this question where I need to calculate the probability of poker dice. The game poker dice is played with 5 dice. It's possible to get one of the following hands: Poker: All dice have the same value (ie 3,3,3,3,3). Four of a kind: 4 of the 5 dice have the same value (ie 3,3,3,3,1). Three of a kind Two of a kind Street: (1,2,3,4,5 or 2,3,4,5,6) Full House: (333,22) Two pair: (1,1,2,2,3) Now I have to find the probability of these hands. I know there are 6^5 = 7776 different throws. For the poker there are 6 different values possible (111111,222222,333333 etc) so the probability is 6/7776 For the four of a kind theres 6*5*5 = 150  150/7776 But at the three of a kind is where I get stuck (and the other hands), wikipedia tells me there is an probability of 1200/7776. I don't know how they got the 1200. If there is someone who could help me I would be very thankful. Thanks, Rico (Ps English isn't my first language)","I am working on a maths excersice and got stuck on this question where I need to calculate the probability of poker dice. The game poker dice is played with 5 dice. It's possible to get one of the following hands: Poker: All dice have the same value (ie 3,3,3,3,3). Four of a kind: 4 of the 5 dice have the same value (ie 3,3,3,3,1). Three of a kind Two of a kind Street: (1,2,3,4,5 or 2,3,4,5,6) Full House: (333,22) Two pair: (1,1,2,2,3) Now I have to find the probability of these hands. I know there are 6^5 = 7776 different throws. For the poker there are 6 different values possible (111111,222222,333333 etc) so the probability is 6/7776 For the four of a kind theres 6*5*5 = 150  150/7776 But at the three of a kind is where I get stuck (and the other hands), wikipedia tells me there is an probability of 1200/7776. I don't know how they got the 1200. If there is someone who could help me I would be very thankful. Thanks, Rico (Ps English isn't my first language)",,"['probability', 'statistics', 'dice']"
1,How to efficiently estimate quantile function of Gamma distribution,How to efficiently estimate quantile function of Gamma distribution,,"I have an application that analyzes datasets comprised mostly of samples from a Gamma distribution. Mixed in with the data are an unknown number ($>= 0$) of outlier samples (which are actually taken from a scaled noncentral chi-squared distribution with unknown centrality parameter) that are significantly larger in magnitude than the samples from the Gamma distribution. I would like to locate these values with as high of a detection probability as possible, under the constraint that the probability of falsely choosing one of the Gamma-distributed samples as an outlier is bounded by a specified probability $P_{f}$ (where $P_f$ is on the order of $10^{-8}$ to $10^{-12}$ or so). The shape parameter $k$ of the Gamma distribution is known. I've developed the following method of approaching the problem: Fit a Gamma distribution to the data using a method that attempts to be robust to outliers: Since the shape parameter is known, I just need the scale parameter $\theta$ in order to describe the distribution. The mode of the distribution is equal to $(k-1)\theta$, so estimating the distribution's mode will provide a way to estimate $\theta$. I'm using the half-sample range method to estimate the distribution's mode (i.e. the PDF's peak). Given the mode estimate $m$, estimate the scale paramter as $\tilde \theta = \frac{m}{k-1}$. Given the desired false-detection probability $P_f$, calculate the threshold $x$ where $F_x(x) = 1 - P_f$, where $F_x(x)$ is the CDF of the fitted Gamma distribution. Declare all values in the sample greater than $x$ as outliers. I'm looking for a computationally efficient way to estimate the appropriate threshold $x$. This is intended for a real-time processing application, and the method of directly inverting the Gamma distribution's CDF requires me to perform root-finding on special functions that are relatively expensive to compute. If there is a more efficient way to estimate (even approximately) the desired threshold in terms of the distribution parameters, that would help a lot.","I have an application that analyzes datasets comprised mostly of samples from a Gamma distribution. Mixed in with the data are an unknown number ($>= 0$) of outlier samples (which are actually taken from a scaled noncentral chi-squared distribution with unknown centrality parameter) that are significantly larger in magnitude than the samples from the Gamma distribution. I would like to locate these values with as high of a detection probability as possible, under the constraint that the probability of falsely choosing one of the Gamma-distributed samples as an outlier is bounded by a specified probability $P_{f}$ (where $P_f$ is on the order of $10^{-8}$ to $10^{-12}$ or so). The shape parameter $k$ of the Gamma distribution is known. I've developed the following method of approaching the problem: Fit a Gamma distribution to the data using a method that attempts to be robust to outliers: Since the shape parameter is known, I just need the scale parameter $\theta$ in order to describe the distribution. The mode of the distribution is equal to $(k-1)\theta$, so estimating the distribution's mode will provide a way to estimate $\theta$. I'm using the half-sample range method to estimate the distribution's mode (i.e. the PDF's peak). Given the mode estimate $m$, estimate the scale paramter as $\tilde \theta = \frac{m}{k-1}$. Given the desired false-detection probability $P_f$, calculate the threshold $x$ where $F_x(x) = 1 - P_f$, where $F_x(x)$ is the CDF of the fitted Gamma distribution. Declare all values in the sample greater than $x$ as outliers. I'm looking for a computationally efficient way to estimate the appropriate threshold $x$. This is intended for a real-time processing application, and the method of directly inverting the Gamma distribution's CDF requires me to perform root-finding on special functions that are relatively expensive to compute. If there is a more efficient way to estimate (even approximately) the desired threshold in terms of the distribution parameters, that would help a lot.",,"['statistics', 'probability-distributions', 'gamma-function', 'estimation']"
2,Estimation of $\mathbb{P}(X > t)$,Estimation of,\mathbb{P}(X > t),"Let $X_1, \ldots, X_n \sim X$ be iid random variables. The goal is to find an estimator of $\theta = \mathbb{P}(X > t)$ for a given $t > 0$. 1) Show that $\hat{\theta}_1 = 1 - F_n(t)$ is an unbiased estimator of $\theta$ and find its MSE ($F_n$ is the empirical distribution function). 2) Let now $X_1, \ldots, X_n$ be exponential($\lambda$). Find the UMVUE of $\theta$. (Hint: $X_1$ and $X_1/\sum_{i=1}^n X_i$ are independent and the pdf of $X_1/\sum_{i=1}^n X_i$ is : $(n-1)(1-x)^{n-2} \mathbb{I}_{ x \in (0,1) }$) Some thoughts 1) If I'm not wrong: $$ \hat{\theta}_1 = 1 - F_n(t) = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}_{\{X_i > t \}} $$ Therefore $n \hat{\theta}_1 \sim \mathrm{Binomial}(n, 1 - F_X(x))$ and then: $$ \mathbb{E}(\hat{\theta}_1) = \frac{1}{n}\mathbb{E}(n\hat{\theta}_1) = 1 - F_X(x) = \mathbb{P}(X > x) = \theta \qquad \mathrm{(unbiased)} $$ $$ \mathrm{MSE}(\hat{\theta}_1) = \mathbb{V}(\hat{\theta}_1) = \frac{1}{n^2}\mathbb{V}(n\hat{\theta}_1) = \frac{\theta(1-\theta)}{n} $$ 2) We know that $\hat{\theta}_1$ is an unbiased estimator of $\theta = e^{-t/ \lambda}$ and $S = \sum_{i=1}^n X_i$ is a complete sufficient statistic of $\lambda$. Therefore $U = \mathbb{E}(\hat{\theta}_1 \, | \, S)$ is the UMVUE of $\theta$. The problem is that I'm unable to ""compute"" $U$ or find an alternative solution. Edit: Alternative solution I think I've found an alternative (and rather tedious) solution which doesn't make use of the hint. I was trying to write it as a comment, but it was too long. Mr. Hardy's answer is clearer and better in any sense, so I apologize in advance. From Michael Hardy's answer: Notice that $W=\mathbb{I}_{\{X_1>t\}}$ is an unbiased estimator of   $\theta$, so the Rao-Blackwell estimator is $\mathbb{E}(W\mid S)$.    Because of completeness, [...] all unbiased estimators   based on the sufficient statistic $S$ will be the same. So we seek $\mathbb{E}(W\mid S) = > \Pr(X_1>t\mid S)$, and this must be equal to $\mathbb{E}(\hat{\theta}_1 \mid S)$. The conditional pdf of $X_1$ given $S = s$ is: $$f_{X_1 | S = s}(x) = \frac{f_{X_1,S}(x,s)}{f_S(s)} $$ We know that $S$ is a Gamma r.v. because it is the sum of $n$ Exponential r.v. : $$f_S(s) = \frac{\lambda^{-n} s^{n-1} e^{-s/\lambda}}{(n-1)!} $$ The joint distribution can be rewritten as $f_{X_1,S}(x,s) = f_{X_1}(x)f_{S | X_1 = x}(s)$. It should also be noted that: $$ \begin{align} \mathbb{P}(S \leq s | X_1 = x) &= \mathbb{P} \left(\left. x + \sum_{i=2}^n X_i \leq s \; \right|\; X_1 = x \right) \\ &= \mathbb{P} \left(\left. \sum_{i=2}^n X_i \leq s -x \; \right|\; X_1 = x\right) \\ &= \mathbb{P} \left(\sum_{i=2}^n X_i \leq s -x\right)  \end{align} $$ Where $\sum_{i=2}^n X_i$ is a Gamma r.v.. Thus: $$ f_{S | X_1 = x}(s) = f_{\sum_{i=2}^n X_i}(s-x) = \frac{\lambda^{-(n-1)} (s-x)^{n-2}e^{-(s-x)/\lambda}}{(n-2)!} $$ If $S = s$, then $0 \leq X_1 \leq s$. If we simplify it turns out that: $$ f_{X_1 | S = s}(x) = (n-1) \frac{(s-x)^{n-2}}{s^{n-1}} \,  \, \mathbb{I}_{\{0 \leq x \leq s\}} $$ Finally: $$ \mathbb{P}(X_1 > t | S = s) = \int_{t=1}^S (n-1)\frac{(s-x)^{n-2}}{s^{n-1}} \, \mathrm{d}x = \frac{n-1}{s^{n-1}}\left[- \frac{(s-x)^{n-1}}{n-1} \right]^{s}_{t} = \left(1 - \frac{t}{s}\right)^{n-1}$$ Which is exactly the same thing.","Let $X_1, \ldots, X_n \sim X$ be iid random variables. The goal is to find an estimator of $\theta = \mathbb{P}(X > t)$ for a given $t > 0$. 1) Show that $\hat{\theta}_1 = 1 - F_n(t)$ is an unbiased estimator of $\theta$ and find its MSE ($F_n$ is the empirical distribution function). 2) Let now $X_1, \ldots, X_n$ be exponential($\lambda$). Find the UMVUE of $\theta$. (Hint: $X_1$ and $X_1/\sum_{i=1}^n X_i$ are independent and the pdf of $X_1/\sum_{i=1}^n X_i$ is : $(n-1)(1-x)^{n-2} \mathbb{I}_{ x \in (0,1) }$) Some thoughts 1) If I'm not wrong: $$ \hat{\theta}_1 = 1 - F_n(t) = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}_{\{X_i > t \}} $$ Therefore $n \hat{\theta}_1 \sim \mathrm{Binomial}(n, 1 - F_X(x))$ and then: $$ \mathbb{E}(\hat{\theta}_1) = \frac{1}{n}\mathbb{E}(n\hat{\theta}_1) = 1 - F_X(x) = \mathbb{P}(X > x) = \theta \qquad \mathrm{(unbiased)} $$ $$ \mathrm{MSE}(\hat{\theta}_1) = \mathbb{V}(\hat{\theta}_1) = \frac{1}{n^2}\mathbb{V}(n\hat{\theta}_1) = \frac{\theta(1-\theta)}{n} $$ 2) We know that $\hat{\theta}_1$ is an unbiased estimator of $\theta = e^{-t/ \lambda}$ and $S = \sum_{i=1}^n X_i$ is a complete sufficient statistic of $\lambda$. Therefore $U = \mathbb{E}(\hat{\theta}_1 \, | \, S)$ is the UMVUE of $\theta$. The problem is that I'm unable to ""compute"" $U$ or find an alternative solution. Edit: Alternative solution I think I've found an alternative (and rather tedious) solution which doesn't make use of the hint. I was trying to write it as a comment, but it was too long. Mr. Hardy's answer is clearer and better in any sense, so I apologize in advance. From Michael Hardy's answer: Notice that $W=\mathbb{I}_{\{X_1>t\}}$ is an unbiased estimator of   $\theta$, so the Rao-Blackwell estimator is $\mathbb{E}(W\mid S)$.    Because of completeness, [...] all unbiased estimators   based on the sufficient statistic $S$ will be the same. So we seek $\mathbb{E}(W\mid S) = > \Pr(X_1>t\mid S)$, and this must be equal to $\mathbb{E}(\hat{\theta}_1 \mid S)$. The conditional pdf of $X_1$ given $S = s$ is: $$f_{X_1 | S = s}(x) = \frac{f_{X_1,S}(x,s)}{f_S(s)} $$ We know that $S$ is a Gamma r.v. because it is the sum of $n$ Exponential r.v. : $$f_S(s) = \frac{\lambda^{-n} s^{n-1} e^{-s/\lambda}}{(n-1)!} $$ The joint distribution can be rewritten as $f_{X_1,S}(x,s) = f_{X_1}(x)f_{S | X_1 = x}(s)$. It should also be noted that: $$ \begin{align} \mathbb{P}(S \leq s | X_1 = x) &= \mathbb{P} \left(\left. x + \sum_{i=2}^n X_i \leq s \; \right|\; X_1 = x \right) \\ &= \mathbb{P} \left(\left. \sum_{i=2}^n X_i \leq s -x \; \right|\; X_1 = x\right) \\ &= \mathbb{P} \left(\sum_{i=2}^n X_i \leq s -x\right)  \end{align} $$ Where $\sum_{i=2}^n X_i$ is a Gamma r.v.. Thus: $$ f_{S | X_1 = x}(s) = f_{\sum_{i=2}^n X_i}(s-x) = \frac{\lambda^{-(n-1)} (s-x)^{n-2}e^{-(s-x)/\lambda}}{(n-2)!} $$ If $S = s$, then $0 \leq X_1 \leq s$. If we simplify it turns out that: $$ f_{X_1 | S = s}(x) = (n-1) \frac{(s-x)^{n-2}}{s^{n-1}} \,  \, \mathbb{I}_{\{0 \leq x \leq s\}} $$ Finally: $$ \mathbb{P}(X_1 > t | S = s) = \int_{t=1}^S (n-1)\frac{(s-x)^{n-2}}{s^{n-1}} \, \mathrm{d}x = \frac{n-1}{s^{n-1}}\left[- \frac{(s-x)^{n-1}}{n-1} \right]^{s}_{t} = \left(1 - \frac{t}{s}\right)^{n-1}$$ Which is exactly the same thing.",,[]
3,Question about posterior distributions and sufficient statistics,Question about posterior distributions and sufficient statistics,,"1. If $X_1,X_2,\ldots,X_n$ are discrete r.v.'s with joint pmf $f(x_1,\ldots,x_n|\theta)$. Let theta be a discrete random variable with prior pmf $\pi(\theta)$. Let $H(x_1,x_2,\ldots,x_n)$ be a sufficient statistic. Show that $\pi(\theta|x_1=x_1,\ldots,x_n=x_n) = \pi(\theta|H=h)$. Attempt: Basically the posterior distribution of theta given the sample is equivalent to the posterior of theta given a sufficient statistic of the sample as a sufficient statistic contains all the relevant information about the sample.","1. If $X_1,X_2,\ldots,X_n$ are discrete r.v.'s with joint pmf $f(x_1,\ldots,x_n|\theta)$. Let theta be a discrete random variable with prior pmf $\pi(\theta)$. Let $H(x_1,x_2,\ldots,x_n)$ be a sufficient statistic. Show that $\pi(\theta|x_1=x_1,\ldots,x_n=x_n) = \pi(\theta|H=h)$. Attempt: Basically the posterior distribution of theta given the sample is equivalent to the posterior of theta given a sufficient statistic of the sample as a sufficient statistic contains all the relevant information about the sample.",,['statistics']
4,what is the interpretation of the following matrix?,what is the interpretation of the following matrix?,,"Let $X = (X_1,...,X_n)$ and $Y=(Y_1,...,Y_m)$ be two random vectors. Let $C_{XY}$ be the covariance matrix of two random vectors $X$ and $Y$. What is the interpretation of the matrix $A = C_{XX}^{-1/2} C_{XY} C_{YY}^{-1/2}$? It seems to me like it is very much related to the correlation matrix, but it is not exactly a correlation matrix (because its elements are actually not $Corr(X_i,X_j)$). However, if $m=n=1$, then we get that $A$ is exactly a 1 x 1 matrix that corresponds to the correlation between $X$ and $Y$.","Let $X = (X_1,...,X_n)$ and $Y=(Y_1,...,Y_m)$ be two random vectors. Let $C_{XY}$ be the covariance matrix of two random vectors $X$ and $Y$. What is the interpretation of the matrix $A = C_{XX}^{-1/2} C_{XY} C_{YY}^{-1/2}$? It seems to me like it is very much related to the correlation matrix, but it is not exactly a correlation matrix (because its elements are actually not $Corr(X_i,X_j)$). However, if $m=n=1$, then we get that $A$ is exactly a 1 x 1 matrix that corresponds to the correlation between $X$ and $Y$.",,"['probability', 'statistics']"
5,"Grouped data median, using lower class limit or lower class boundary?","Grouped data median, using lower class limit or lower class boundary?",,"In statistics, for grouped data, when calculating the median based on formula $Median = L_m + \left [ \frac { \frac{n}{2} - F_{m-1} }{f_m} \right ] \times c$ where $c$ is the size of the median class $F_{m-1}$ is the cumulative frequency of the class before median class $f_m$ is the frequency of the median class $n$ is the total number of the data I noticed some resources mentioned $L_m$ as lower class limit, but some lower class boundary. Which one is correct?","In statistics, for grouped data, when calculating the median based on formula $Median = L_m + \left [ \frac { \frac{n}{2} - F_{m-1} }{f_m} \right ] \times c$ where $c$ is the size of the median class $F_{m-1}$ is the cumulative frequency of the class before median class $f_m$ is the frequency of the median class $n$ is the total number of the data I noticed some resources mentioned $L_m$ as lower class limit, but some lower class boundary. Which one is correct?",,['statistics']
6,Shortest Confidence interval for $\sigma^2$,Shortest Confidence interval for,\sigma^2,"I have a $X_1, \cdots , X_n$ random samples from a $N(\mu,\sigma^2)$. $\mu$ is known, but $\sigma^2$ is  unknown. I would like to know how to go about constructing a $(1-\alpha)$100% shortest confidence interval for $\sigma^2$. I know how how to construct that of a known variance, but unknown mean. I'm bit confused as how to proceed when the situation is reversed. Thank you.","I have a $X_1, \cdots , X_n$ random samples from a $N(\mu,\sigma^2)$. $\mu$ is known, but $\sigma^2$ is  unknown. I would like to know how to go about constructing a $(1-\alpha)$100% shortest confidence interval for $\sigma^2$. I know how how to construct that of a known variance, but unknown mean. I'm bit confused as how to proceed when the situation is reversed. Thank you.",,"['probability', 'statistics']"
7,Finding the population size from the common elements of multiple samples,Finding the population size from the common elements of multiple samples,,"A coworker of mine has taken a certification exam twice and has seen the same ten questions on both exams. I am curious if it is possible to determine the total number of questions in the question pool from the number of questions per exam and the number questions common to both exams. The exam has fifty-one questions, and in taking it twice for a total of one hundred and two questions, it was determined that ten of the questions appeared on both exams. Also, I am curious if this is even enough information to determine the answer. Mathematics has never been my strong point. Thank you!","A coworker of mine has taken a certification exam twice and has seen the same ten questions on both exams. I am curious if it is possible to determine the total number of questions in the question pool from the number of questions per exam and the number questions common to both exams. The exam has fifty-one questions, and in taking it twice for a total of one hundred and two questions, it was determined that ten of the questions appeared on both exams. Also, I am curious if this is even enough information to determine the answer. Mathematics has never been my strong point. Thank you!",,"['statistics', 'sampling']"
8,The relationship between mean and variance in the context of system energy and the partition function,The relationship between mean and variance in the context of system energy and the partition function,,I'm looking at a specific derivation on wikipedia relevant to statistical mechanics and I don't understand a step. $$ Z = \sum_s{e^{-\beta E_s}} $$ $Z$ (the partition function) encodes information about a physical system. $E_s$ is the energy of a particular system state. $Z$ is found by summing over all possible system states. The expected value of $E$ is found to be: $$ \langle E \rangle = -\frac{\partial \ln Z}{\partial \beta} $$ Why is the variance of $E$ simply defined as: $$ \langle(E - \langle E\rangle)^2\rangle = \frac{\partial^2 \ln Z}{\partial \beta^2} $$ just a partial derivative of the mean. What about this problem links the variance and mean in this way?,I'm looking at a specific derivation on wikipedia relevant to statistical mechanics and I don't understand a step. $$ Z = \sum_s{e^{-\beta E_s}} $$ $Z$ (the partition function) encodes information about a physical system. $E_s$ is the energy of a particular system state. $Z$ is found by summing over all possible system states. The expected value of $E$ is found to be: $$ \langle E \rangle = -\frac{\partial \ln Z}{\partial \beta} $$ Why is the variance of $E$ simply defined as: $$ \langle(E - \langle E\rangle)^2\rangle = \frac{\partial^2 \ln Z}{\partial \beta^2} $$ just a partial derivative of the mean. What about this problem links the variance and mean in this way?,,"['calculus', 'statistics', 'physics']"
9,Showing consistency of an estimator,Showing consistency of an estimator,,I have $\log X \sim Exp(\vartheta - 1)$ and I would like to show $$ P \Big [ \Big |\frac{1}{\frac{1}{n} \sum_{i=1}^n \log X_i} - (\vartheta - 1) \Big | > \varepsilon \Big ] \rightarrow 0  \hspace{5 mm} \forall \vartheta (n \rightarrow \infty)$$ In the answer to this question it states that all moments of the exponential distribution that are necessary for the strong law of large numbers exist. Therefore $\frac{1}{\frac{1}{n} \sum_{i=1}^n \log X_i}$ converges almost surely towards $\frac{1}{\vartheta - 1}$. Can someone explain to me why the moments need to exist for the law of large numbers? And how this proof works? Many thanks for your help!,I have $\log X \sim Exp(\vartheta - 1)$ and I would like to show $$ P \Big [ \Big |\frac{1}{\frac{1}{n} \sum_{i=1}^n \log X_i} - (\vartheta - 1) \Big | > \varepsilon \Big ] \rightarrow 0  \hspace{5 mm} \forall \vartheta (n \rightarrow \infty)$$ In the answer to this question it states that all moments of the exponential distribution that are necessary for the strong law of large numbers exist. Therefore $\frac{1}{\frac{1}{n} \sum_{i=1}^n \log X_i}$ converges almost surely towards $\frac{1}{\vartheta - 1}$. Can someone explain to me why the moments need to exist for the law of large numbers? And how this proof works? Many thanks for your help!,,"['probability', 'statistics']"
10,Finding conditional probability with Gamma distribution,Finding conditional probability with Gamma distribution,,"While I tagged this question homework, it's not really homework. I'm really studying for a test and don't understand how to do something. I have the answer to the question, so the important part is for my to understand how to get there. X has distribution Gamma(2,4) X = Y-3 Find: P(Y>11|Y>7) Which I know is equals to: (1-P(X<8))/(1-P(X<4)) = (1-Fx(8))/(1-Fx(4)) I have been told that Fx(a) = 1-e^(-a/4)-(a/4)*e^(-a/4) So I can clearly solve the problem now it's just algebra. But how do we know what Fx(a) equals??? Thanks!","While I tagged this question homework, it's not really homework. I'm really studying for a test and don't understand how to do something. I have the answer to the question, so the important part is for my to understand how to get there. X has distribution Gamma(2,4) X = Y-3 Find: P(Y>11|Y>7) Which I know is equals to: (1-P(X<8))/(1-P(X<4)) = (1-Fx(8))/(1-Fx(4)) I have been told that Fx(a) = 1-e^(-a/4)-(a/4)*e^(-a/4) So I can clearly solve the problem now it's just algebra. But how do we know what Fx(a) equals??? Thanks!",,['statistics']
11,What is the formula for $P(|a-b| > c)$ in a normal distribution?,What is the formula for  in a normal distribution?,P(|a-b| > c),"Given two random samples $a$ and $b$ of a normal distribution, how can I calculate the probability that their difference $|a-b|$ is bigger (or lesser) than $c$?","Given two random samples $a$ and $b$ of a normal distribution, how can I calculate the probability that their difference $|a-b|$ is bigger (or lesser) than $c$?",,"['statistics', 'normal-distribution']"
12,Find an unbiased estimate for λs (Poisson distribution),Find an unbiased estimate for λs (Poisson distribution),,"So I have this problem to solve... Let X denote the number of paint defects found in a square yard section of a car body painted by a robot. These data are obtained: 8, 5, 0, 10, 0, 3, 1, 12, 2, 7, 9, 6 Assume that X has a Poisson distribution with parameter λs. a) Find an unbiased estimate for λs. b) Find an unbiased estimate for the average number of flaws per square yard. c) Find an unbiased estimate for the average number of flaws per square foot. I have no idea where to begin. I mean, how do I even find ANY unbiased estimate? The textbook is worthless imo and I can't find any good readings on the web either... please help.","So I have this problem to solve... Let X denote the number of paint defects found in a square yard section of a car body painted by a robot. These data are obtained: 8, 5, 0, 10, 0, 3, 1, 12, 2, 7, 9, 6 Assume that X has a Poisson distribution with parameter λs. a) Find an unbiased estimate for λs. b) Find an unbiased estimate for the average number of flaws per square yard. c) Find an unbiased estimate for the average number of flaws per square foot. I have no idea where to begin. I mean, how do I even find ANY unbiased estimate? The textbook is worthless imo and I can't find any good readings on the web either... please help.",,"['probability', 'statistics', 'discrete-mathematics']"
13,How to analyze risk vs. reward for spending on research and development work?,How to analyze risk vs. reward for spending on research and development work?,,"Imagine I have a company that makes widgets, where each widget costs me A dollars to make. Each month I can allocate money toward research and development with the aim of finding a new process that will allow me to build widgets for a cost of A/B dollars. Presume that I know that for each C dollars I spend on research and development there's a D% chance of finding a breakthrough. Of course, spending money on research and development means that I have less to spend on building widgets. I have a monthly budget of E dollars. This budget is not directly tied to my profit margin, but it is safe to say that it my profit margins influence future budgets (i.e., if I make no widgets for three straight months b/c I do all research and development, it's likely that my budget will be reduced, whereas if I discover a breakthrough the first month my profits will skyrocket and I'll likely see that budget grow over time). In case that is too abstract, here's the real world scenario I'm interested in solving (although I'd like a more general approach, as well): A = 15 dollars B = 3 C = 5 dollars D = 2.75% E = 30 dollars That is, today widgets cost me 15 dollars to build but if I can find a breakthrough I know I can make them at 1/3 the cost (5 dollars). For each 5 dollars I spend on research and development there is a 2.75% chance I'll find the breakthrough. However, I have only 30 dollars to spend each month. If I spend it all on research and development and have no success then I have made no widgets for sale. If I spend it all on widget construction I have no chance of finding a breakthrough. Is there some statistical distribution or formula that can let me plug in these variables and see some sort of breakdown that gives me an idea of whether it's a good idea to spend any money on research and development each month and, if so, how much?","Imagine I have a company that makes widgets, where each widget costs me A dollars to make. Each month I can allocate money toward research and development with the aim of finding a new process that will allow me to build widgets for a cost of A/B dollars. Presume that I know that for each C dollars I spend on research and development there's a D% chance of finding a breakthrough. Of course, spending money on research and development means that I have less to spend on building widgets. I have a monthly budget of E dollars. This budget is not directly tied to my profit margin, but it is safe to say that it my profit margins influence future budgets (i.e., if I make no widgets for three straight months b/c I do all research and development, it's likely that my budget will be reduced, whereas if I discover a breakthrough the first month my profits will skyrocket and I'll likely see that budget grow over time). In case that is too abstract, here's the real world scenario I'm interested in solving (although I'd like a more general approach, as well): A = 15 dollars B = 3 C = 5 dollars D = 2.75% E = 30 dollars That is, today widgets cost me 15 dollars to build but if I can find a breakthrough I know I can make them at 1/3 the cost (5 dollars). For each 5 dollars I spend on research and development there is a 2.75% chance I'll find the breakthrough. However, I have only 30 dollars to spend each month. If I spend it all on research and development and have no success then I have made no widgets for sale. If I spend it all on widget construction I have no chance of finding a breakthrough. Is there some statistical distribution or formula that can let me plug in these variables and see some sort of breakdown that gives me an idea of whether it's a good idea to spend any money on research and development each month and, if so, how much?",,['statistics']
14,Why do randomly drawn numbers tend to repeat themselves?,Why do randomly drawn numbers tend to repeat themselves?,,"I track the behavior of random numbers and I have discovered that once a number appears, it tends to reappear again shortly thereafter. For example, I've been tracking the Red Powerball in the Powerball lottery, it's the single red ball from a pool of $1$ through $26$ numbers. The plot below is a gap chart or plot ... a consolidation of the distance between when a number is drawn and the next time it is drawn again. For example, at position $1$ on the horizontal axis, indicates that $37$ times balls repeat on the next drawing. Positions $2$ and $3$ on the horizontal axis indicate that balls have appeared $40$ times once again $2$ and $3$ draws later respectively. As we move toward the right, we see the lengths of gaps between repeats increase gradually. At the very far right, there was a gap of a ball repeating after 198 draws, that's a drought. A Suspect Chart is also included to indicate a gap chart that would indicate manufactured repeats at locations $44$ through $50$ . Is there a statistical explanation for this phenomena? The number of games (aka draws) represented in the Powerball plot is $969$ and the number of draws in the Megemilions plot is $605$ . A chart of a Suspect Drawing . If one were to see this when analyzing gap analysis , then one could assert that the drawing was not random? Also added for completeness, is the Megamilions Blue Ball MB, which has the range $1$ through $25$ . It also indicates that when any given MB is drawn, it's likely to be drawn again within the next few draws. It would be nice if I could attach text data to this question for reviewers to download. Here is an example of $35$ random numbers (pool size $1$ through $10$ ) drawn in an Excel spreadsheet taken out to gap of $5$ . Horizontal position $1$ in my plot is gap $0$ , horizontal position $2$ in my plot is gap $1$ , ... and so on.","I track the behavior of random numbers and I have discovered that once a number appears, it tends to reappear again shortly thereafter. For example, I've been tracking the Red Powerball in the Powerball lottery, it's the single red ball from a pool of through numbers. The plot below is a gap chart or plot ... a consolidation of the distance between when a number is drawn and the next time it is drawn again. For example, at position on the horizontal axis, indicates that times balls repeat on the next drawing. Positions and on the horizontal axis indicate that balls have appeared times once again and draws later respectively. As we move toward the right, we see the lengths of gaps between repeats increase gradually. At the very far right, there was a gap of a ball repeating after 198 draws, that's a drought. A Suspect Chart is also included to indicate a gap chart that would indicate manufactured repeats at locations through . Is there a statistical explanation for this phenomena? The number of games (aka draws) represented in the Powerball plot is and the number of draws in the Megemilions plot is . A chart of a Suspect Drawing . If one were to see this when analyzing gap analysis , then one could assert that the drawing was not random? Also added for completeness, is the Megamilions Blue Ball MB, which has the range through . It also indicates that when any given MB is drawn, it's likely to be drawn again within the next few draws. It would be nice if I could attach text data to this question for reviewers to download. Here is an example of random numbers (pool size through ) drawn in an Excel spreadsheet taken out to gap of . Horizontal position in my plot is gap , horizontal position in my plot is gap , ... and so on.",1 26 1 37 2 3 40 2 3 44 50 969 605 1 25 35 1 10 5 1 0 2 1,"['statistics', 'probability-distributions', 'random', 'clustering']"
15,Looking for another explanation for the Gambler's Fallacy [duplicate],Looking for another explanation for the Gambler's Fallacy [duplicate],,"This question already has answers here : Past coin tosses affect the latest one if you know about them? [duplicate] (4 answers) Closed 5 months ago . I'm a laymen, and the Gambler's fallacy has bothered me for decades. I'm looking for someone to help me look at it from another perspective. Here's why it confuses me: Of course, if you were to flip a coin 100 times, none of those results should be affecting the 101th flip. The 101th flip is 50/50 Statistically, if you flipped a coin 100 times, you would expect around 50 heads and 50 tails. So here's the question... why is it if you flipped 99 coins: 50 Heads and 49 Tails, why are we allowed to say that the 100th coin is still 50/50? Or put in another way, if we flipped 99 coins, and they were all 99 heads, why are we not allowed to say that the 100th coin is going to likely be a tails? I logically understand that it will always be a 50/50 chance, but where I get confused is when we introduce a set of coin flips (like say we are going to flip 100 coins total), my mind wants to believe that the flips will be distributed 50/50 across the set. I dug around this stackexchange and did find this answer which sort of helps: https://math.stackexchange.com/a/845405/1276792 His third point i think is the closest I've been to understanding it, that there is no expected difference between the number of heads and tails... but it's still hard for me to reconcile the fact that the 100th toss is 50/50 still. Maybe just a rephrase would help me Mods feel free to close this question if it is not in the correct spirit of the community","This question already has answers here : Past coin tosses affect the latest one if you know about them? [duplicate] (4 answers) Closed 5 months ago . I'm a laymen, and the Gambler's fallacy has bothered me for decades. I'm looking for someone to help me look at it from another perspective. Here's why it confuses me: Of course, if you were to flip a coin 100 times, none of those results should be affecting the 101th flip. The 101th flip is 50/50 Statistically, if you flipped a coin 100 times, you would expect around 50 heads and 50 tails. So here's the question... why is it if you flipped 99 coins: 50 Heads and 49 Tails, why are we allowed to say that the 100th coin is still 50/50? Or put in another way, if we flipped 99 coins, and they were all 99 heads, why are we not allowed to say that the 100th coin is going to likely be a tails? I logically understand that it will always be a 50/50 chance, but where I get confused is when we introduce a set of coin flips (like say we are going to flip 100 coins total), my mind wants to believe that the flips will be distributed 50/50 across the set. I dug around this stackexchange and did find this answer which sort of helps: https://math.stackexchange.com/a/845405/1276792 His third point i think is the closest I've been to understanding it, that there is no expected difference between the number of heads and tails... but it's still hard for me to reconcile the fact that the 100th toss is 50/50 still. Maybe just a rephrase would help me Mods feel free to close this question if it is not in the correct spirit of the community",,"['probability', 'statistics']"
16,Find conditional MLE of AR time series,Find conditional MLE of AR time series,,"I was given a model $r_{t} = ϕ_{0} + ϕ_{2}r_{t-2} + ϵ_{t}$ with $\epsilon_t \sim N(0,\sigma^2)$ and have to derive the likelihood of $(r_{3}, r_{4}, . . . , r_{T})$ conditional on $(r_{1}, r_{2})$ and find $ϕ_{0}$ and $ϕ_2$ that maximize the likelihood function given $σ^2$ is known I think I managed to get the conditional likelihood function as followed: $$\begin{aligned} \ln L(r_{3}, r_{4}, . . . , r_{T}|r_{1},r_{2};\sigma^2) &= -\displaystyle\frac{T-2}{2}\ln(2\pi)-\displaystyle\frac{T-2}{2}\ln(\sigma^2)\\ \\ &-\displaystyle\sum_{t=3}^{T} \displaystyle\frac{(r_{t}-\phi_{0}-\phi_{2}r_{t-2})^2}{2\sigma^2}\\ \\ &=-\displaystyle\frac{T-2}{2}\ln(2\pi)-\displaystyle\frac{T-2}{2}\ln(\sigma^2)-\displaystyle\sum_{t=3}^{T} \displaystyle\frac{\epsilon_{t}^2}{2\sigma^2} \end{aligned}$$ However I am not sure how to derive MLE from this. Could someone let me know how to proceed further?",I was given a model with and have to derive the likelihood of conditional on and find and that maximize the likelihood function given is known I think I managed to get the conditional likelihood function as followed: However I am not sure how to derive MLE from this. Could someone let me know how to proceed further?,"r_{t} = ϕ_{0} + ϕ_{2}r_{t-2} + ϵ_{t} \epsilon_t \sim N(0,\sigma^2) (r_{3}, r_{4}, . . . , r_{T}) (r_{1}, r_{2}) ϕ_{0} ϕ_2 σ^2 \begin{aligned}
\ln L(r_{3}, r_{4}, . . . , r_{T}|r_{1},r_{2};\sigma^2) &= -\displaystyle\frac{T-2}{2}\ln(2\pi)-\displaystyle\frac{T-2}{2}\ln(\sigma^2)\\
\\
&-\displaystyle\sum_{t=3}^{T} \displaystyle\frac{(r_{t}-\phi_{0}-\phi_{2}r_{t-2})^2}{2\sigma^2}\\
\\
&=-\displaystyle\frac{T-2}{2}\ln(2\pi)-\displaystyle\frac{T-2}{2}\ln(\sigma^2)-\displaystyle\sum_{t=3}^{T} \displaystyle\frac{\epsilon_{t}^2}{2\sigma^2}
\end{aligned}","['statistics', 'maximum-likelihood', 'time-series', 'log-likelihood']"
17,Are these two definitions of the coefficient of determination $R^2$ equal?,Are these two definitions of the coefficient of determination  equal?,R^2,"I want to do multiple linear regression as explained on this Wikipedia site : I am given data $$ yx=(~(y_1,x_{11},\ldots,x_{1p}),\ldots, (y_n,x_{n1},\ldots,x_{np})~) $$ of $n$ -many samples where for each sample $(y_i,x_{i1},\ldots,x_{ip})$ the variable $y_i\in\mathbb{R}$ is ''dependent'' (the ''dependent variable'') from $x_{i1},\ldots,x_{ip} \in\mathbb{R}$ . We want to find a hyperplane in $\mathbb{R}^{n+1}$ through these points as one does in (multiple/multivariate) linear regression and as it is explained e.g. here on Wikipedia . How good or bad such a hyperplane describes the points of the sample is measured e.g. by the $R^2$ -factor or ''coefficient of determination''. This is, as explained here on Wikipedia , defined as $$ R^2 = 1-\frac{SS_{res}}{SS_{tot}} $$ where the values $SS_{res}$ and $SS_{tot}$ depend on the data as explained on the linked Wikipedia-page. (As the notation with the square does not suggest, this may take values in $(-\infty,1]$ . If $\bar y=\frac{1}{n}\sum y_i=0$ , then this may be equally defined as $R^2=\frac{SS_{reg}}{SS_{tot}}\in[0,1]$ .) My problem is as follows: There is another definition of $R^2$ - call it temporarily $R_2^2$ - which is given by $$ R^2_2 = (r_{1y},\ldots, r_{py}) \begin{pmatrix} r_{11}=1 & \cdots & r_{1p}\\                                                 \vdots & \ddots & \vdots\\                                                r_p1 & \cdots & r_{pp}=1 \end{pmatrix}^{-1}\begin{pmatrix}r_{1y}\\\vdots\\r_{py}\end{pmatrix} $$ where the $(p\times p)$ -matrix in the middle is called the correlation matrix with $$ r_{ij} = \frac{s_{ij}}{s_{i}s_{j}}\quad\quad\text{and}\quad\quad r_{iy} = \frac{s_{iy}}{s_{i}s_{y}} $$ the respective correlation coefficients with respective sample variances $$ s_{ij} = \frac{1}{n-1}\sum_{k=1}^n (x_{ki}-\bar{x_{\bullet i}})(x_{kj}-\bar{x_{\bullet j}})\quad\text{and}\quad s_{i} = \sqrt{s_{ii}} \quad\text{and}\quad s_{iy}  = \frac{1}{n-1}\sum_{k=1}^n (x_{ki}-\bar{x_{\bullet i}})(y_{k}-\bar{y}) \quad\text{etc.} $$ Are these numbers $R^2$ and $R^2_2$ the same and, if yes, why? Thank you! (I would prefer a linear-algebra-argument without involving probability theory and distributions, etc. - everything is empirical and given here.)","I want to do multiple linear regression as explained on this Wikipedia site : I am given data of -many samples where for each sample the variable is ''dependent'' (the ''dependent variable'') from . We want to find a hyperplane in through these points as one does in (multiple/multivariate) linear regression and as it is explained e.g. here on Wikipedia . How good or bad such a hyperplane describes the points of the sample is measured e.g. by the -factor or ''coefficient of determination''. This is, as explained here on Wikipedia , defined as where the values and depend on the data as explained on the linked Wikipedia-page. (As the notation with the square does not suggest, this may take values in . If , then this may be equally defined as .) My problem is as follows: There is another definition of - call it temporarily - which is given by where the -matrix in the middle is called the correlation matrix with the respective correlation coefficients with respective sample variances Are these numbers and the same and, if yes, why? Thank you! (I would prefer a linear-algebra-argument without involving probability theory and distributions, etc. - everything is empirical and given here.)","
yx=(~(y_1,x_{11},\ldots,x_{1p}),\ldots, (y_n,x_{n1},\ldots,x_{np})~)
 n (y_i,x_{i1},\ldots,x_{ip}) y_i\in\mathbb{R} x_{i1},\ldots,x_{ip} \in\mathbb{R} \mathbb{R}^{n+1} R^2 
R^2 = 1-\frac{SS_{res}}{SS_{tot}}
 SS_{res} SS_{tot} (-\infty,1] \bar y=\frac{1}{n}\sum y_i=0 R^2=\frac{SS_{reg}}{SS_{tot}}\in[0,1] R^2 R_2^2 
R^2_2 = (r_{1y},\ldots, r_{py}) \begin{pmatrix} r_{11}=1 & \cdots & r_{1p}\\
                                                \vdots & \ddots & \vdots\\
                                               r_p1 & \cdots & r_{pp}=1
\end{pmatrix}^{-1}\begin{pmatrix}r_{1y}\\\vdots\\r_{py}\end{pmatrix}
 (p\times p) 
r_{ij} = \frac{s_{ij}}{s_{i}s_{j}}\quad\quad\text{and}\quad\quad r_{iy} = \frac{s_{iy}}{s_{i}s_{y}}
 
s_{ij} = \frac{1}{n-1}\sum_{k=1}^n (x_{ki}-\bar{x_{\bullet i}})(x_{kj}-\bar{x_{\bullet j}})\quad\text{and}\quad s_{i} = \sqrt{s_{ii}} \quad\text{and}\quad s_{iy}  = \frac{1}{n-1}\sum_{k=1}^n (x_{ki}-\bar{x_{\bullet i}})(y_{k}-\bar{y}) \quad\text{etc.}
 R^2 R^2_2","['statistics', 'regression', 'linear-regression']"
18,Empirical distribution learns w.r.t total variation distance,Empirical distribution learns w.r.t total variation distance,,"I am trying to prove or disprove that the empirical distribution can learn any continuous distribution w.r.t the total variation distance. The context is the one of statistical learning. I am quite sure that the proposition is false, but I might likely be wrong. I have looked online and into some books, but I couldn't find a similar formulation for the problem, so if you know some literature  that would also be appreciated. (edit: as pointed out in the comment, the distance I am defining here coincides with the total variation distance in this context.) I am considering distributions on the real numbers and the set $$ \mathcal F = \{ g \in \mathcal C^b(\mathbb R) \ \mid \ \lVert {g}\rVert_\infty \leq 1 \} $$ and the corresponding F-divergence $$ d_\mathcal F (\mu \mid \nu ) = \sup_{g \in \mathcal F} \Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\nu \  \Big |  .$$ I need to prove (or negate) the following: For any $\mu$ continuous probability distribution, given i.i.d samples $X_1, \dots , X_n$ from $\mu$ , prove that the empirical distribution $\tilde \mu _n = \frac{1}{n} \sum_{i=1}^n \delta_{X_i} $ converges in probability to $\mu$ w.r.t $d_\mathcal F $ , i.e. $$ P( d_\mathcal F (\mu \mid \tilde \mu_n ) > \epsilon) \xrightarrow[ n \to \infty ]{} 0, \text{   } \ \forall \epsilon>0 $$ With $\delta_x$ I am denoting Dirac's delta. Some more information and my considerations It can be proved that convergence w.r.t to $d_\mathcal F$ is equivalent to convergence with respect to $$ \tilde d (\mu \mid \nu ) = \sup_{g \in \mathcal C^c(\mathbb R) \\ \lVert {g}\rVert_\infty \leq 1 } \Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\nu \  \Big |  .$$ This might be helpful in proving the proposition, since $\mathcal C^c(\mathbb R)$ is separable: the countable and dense subset could be used to take care of the $\sup$ I believe, but I don't exactly see how. Moreover, I don't see how am I supposed to use the density of $\mu$ . Despite Chebyshev's inequality/WLLN proves convergence for any single $g \in \mathcal F$ , with rate indipendent from $g$ $$ P\Big (\Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\tilde \mu_n \  \Big | > \epsilon \Big ) \leq \frac{Var(g(X_1))}{\epsilon^2 n} \stackrel{g(X) \in [-1,1] \ P \ a.s. }{\leq} \frac{1}{\epsilon^2 n}  $$ it seems quite hard to me that such convergence can happen uniformly over $g$ . One could restrict the problem to the subset of functions in $\mathcal F$ s.t. $\mathbb E [g(X_1)] = 0 $ by taking the expected value inside the random variable, but that isn't much and I'm not even sure if that would be a good idea. I have been thinking of using some trivial continuous distribution (such as the gaussian or uniform distributions) as a counterexample, but proving that converge doesn't happen in such case is still hard: my main problem is taking care of the $\sup$ inside the probability. Maybe there's some known theorem which can be used and is going over my head: Glivenko-Cantelli guarantees that $\tilde \mu _n $ learns any probability distribution w.r.t to the divergence corresponding to the half-line's indicators, but I don't think that helps.","I am trying to prove or disprove that the empirical distribution can learn any continuous distribution w.r.t the total variation distance. The context is the one of statistical learning. I am quite sure that the proposition is false, but I might likely be wrong. I have looked online and into some books, but I couldn't find a similar formulation for the problem, so if you know some literature  that would also be appreciated. (edit: as pointed out in the comment, the distance I am defining here coincides with the total variation distance in this context.) I am considering distributions on the real numbers and the set and the corresponding F-divergence I need to prove (or negate) the following: For any continuous probability distribution, given i.i.d samples from , prove that the empirical distribution converges in probability to w.r.t , i.e. With I am denoting Dirac's delta. Some more information and my considerations It can be proved that convergence w.r.t to is equivalent to convergence with respect to This might be helpful in proving the proposition, since is separable: the countable and dense subset could be used to take care of the I believe, but I don't exactly see how. Moreover, I don't see how am I supposed to use the density of . Despite Chebyshev's inequality/WLLN proves convergence for any single , with rate indipendent from it seems quite hard to me that such convergence can happen uniformly over . One could restrict the problem to the subset of functions in s.t. by taking the expected value inside the random variable, but that isn't much and I'm not even sure if that would be a good idea. I have been thinking of using some trivial continuous distribution (such as the gaussian or uniform distributions) as a counterexample, but proving that converge doesn't happen in such case is still hard: my main problem is taking care of the inside the probability. Maybe there's some known theorem which can be used and is going over my head: Glivenko-Cantelli guarantees that learns any probability distribution w.r.t to the divergence corresponding to the half-line's indicators, but I don't think that helps."," \mathcal F = \{ g \in \mathcal C^b(\mathbb R) \ \mid \ \lVert {g}\rVert_\infty \leq 1 \}   d_\mathcal F (\mu \mid \nu ) = \sup_{g \in \mathcal F} \Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\nu \  \Big |  . \mu X_1, \dots , X_n \mu \tilde \mu _n = \frac{1}{n} \sum_{i=1}^n \delta_{X_i}  \mu d_\mathcal F   P( d_\mathcal F (\mu \mid \tilde \mu_n ) > \epsilon) \xrightarrow[ n \to \infty ]{} 0, \text{   } \ \forall \epsilon>0  \delta_x d_\mathcal F  \tilde d (\mu \mid \nu ) = \sup_{g \in \mathcal C^c(\mathbb R) \\ \lVert {g}\rVert_\infty \leq 1 } \Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\nu \  \Big |  . \mathcal C^c(\mathbb R) \sup \mu g \in \mathcal F g  P\Big (\Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\tilde \mu_n \  \Big | > \epsilon \Big ) \leq \frac{Var(g(X_1))}{\epsilon^2 n} \stackrel{g(X) \in [-1,1] \ P \ a.s. }{\leq} \frac{1}{\epsilon^2 n}   g \mathcal F \mathbb E [g(X_1)] = 0  \sup \tilde \mu _n ","['functional-analysis', 'statistics', 'machine-learning', 'borel-measures']"
19,Show that $T$ is an unbiased estimator,Show that  is an unbiased estimator,T,"I'm given the following exercise; Let $X_1$ , $X_2$ ,..., $X_n$ a sample from Uniform distribution $U(\theta,2\theta)$ , $\theta>0$ , with PDF $$f(x)=\frac{1}{\theta}, \theta<x<2\theta$$ and $$T=\frac{n+1}{2n+1}X_{(n)}$$ where $X_{(n)}=max{X_i}, i=1,2,....,n$ . I 'm instructed to show that $T$ is an unbiased estimator for $\theta$ , and determine its variance ( $Var(T)$ ). The only step I 'm sure of, is that I need to show $E[T]=\theta$ , the definiton of an unbiased estimator. From there, I am not sure how to continue. Normally I would have to simplify $E[T]$ , which might go like this; $$E[T]=E[\frac{n+1}{2n+1}X_{(n)}]=\frac{n+1}{2n+1}E[X_{(n)}]$$ ... and that's it. Even if I take $E[X_{(n)}]=E[X]=\frac{3\theta}{2}$ (where the first equality is probably not correct / the second equality derives from the fact that $E[X]=\frac{a+b}{2}$ for the uniform distribution in a domain $(a,b)$ ), I don't see the path that would lead me to $E[T]=\theta$ . Any help would be really appreciated, I 'm just getting started with statistics on Uni and only at the beginning of getting the hang of it.","I'm given the following exercise; Let , ,..., a sample from Uniform distribution , , with PDF and where . I 'm instructed to show that is an unbiased estimator for , and determine its variance ( ). The only step I 'm sure of, is that I need to show , the definiton of an unbiased estimator. From there, I am not sure how to continue. Normally I would have to simplify , which might go like this; ... and that's it. Even if I take (where the first equality is probably not correct / the second equality derives from the fact that for the uniform distribution in a domain ), I don't see the path that would lead me to . Any help would be really appreciated, I 'm just getting started with statistics on Uni and only at the beginning of getting the hang of it.","X_1 X_2 X_n U(\theta,2\theta) \theta>0 f(x)=\frac{1}{\theta}, \theta<x<2\theta T=\frac{n+1}{2n+1}X_{(n)} X_{(n)}=max{X_i}, i=1,2,....,n T \theta Var(T) E[T]=\theta E[T] E[T]=E[\frac{n+1}{2n+1}X_{(n)}]=\frac{n+1}{2n+1}E[X_{(n)}] E[X_{(n)}]=E[X]=\frac{3\theta}{2} E[X]=\frac{a+b}{2} (a,b) E[T]=\theta",['statistics']
20,Variance of the Norm of a Gaussian Random Vector,Variance of the Norm of a Gaussian Random Vector,,"If $\mathbf{X} \sim \mathcal{N}_N(\mathbf{m}, \mathbf{C})$ is an $N$ -dimensional gaussian vector, where $\mathbf{m} \in \mathbb{R}^N$ and $\mathbf{C} \in \mathbb{R}^{N \times N}$ , what is the variance of $$ Y=\|\mathbf{X}\|^2 $$ where $\|\cdot\|$ denotes the $L_2$ -norm (Euclidean norm) ? As pointed out by this question , $Y$ has a generalised chi-squared distribution and its mean can be obtained easily. However, I want to know what is its variance. Can anybody please give some help?","If is an -dimensional gaussian vector, where and , what is the variance of where denotes the -norm (Euclidean norm) ? As pointed out by this question , has a generalised chi-squared distribution and its mean can be obtained easily. However, I want to know what is its variance. Can anybody please give some help?","\mathbf{X} \sim \mathcal{N}_N(\mathbf{m}, \mathbf{C}) N \mathbf{m} \in \mathbb{R}^N \mathbf{C} \in \mathbb{R}^{N \times N}  Y=\|\mathbf{X}\|^2  \|\cdot\| L_2 Y","['probability', 'statistics', 'normal-distribution']"
21,Inequality of $k$-th moment of independent sum,Inequality of -th moment of independent sum,k,"Recently, I am self-studying Stanford Stat 300B and encounter an exercise in the problem set, which is to prove the following: Suppose that $X_i$ are independent mean-zero random variables with $\mathbb{E}[|X_i|^k]<\infty$ , let $S_n=\sum_{i=1}^n X_i$ and prove that: $$ \mathbb{E}[|S_n|^k]\leqslant C_k \mathbb{E}\left[\left(\sum_{i=1}^n X_i^2\right)^{\frac{k}{2}}\right]. $$ I have tried to expand left hand side into terms of $X_{i_1}^{\alpha_1}\cdots X_{i_t}^{\alpha_t}$ and use the fact of independency, but in vain. Can any body give me some hints on this problem, or provide the solution provided in https://web.stanford.edu/class/stats300b/exercise.html , since I don't have access to the solution link. Thank you very much!","Recently, I am self-studying Stanford Stat 300B and encounter an exercise in the problem set, which is to prove the following: Suppose that are independent mean-zero random variables with , let and prove that: I have tried to expand left hand side into terms of and use the fact of independency, but in vain. Can any body give me some hints on this problem, or provide the solution provided in https://web.stanford.edu/class/stats300b/exercise.html , since I don't have access to the solution link. Thank you very much!","X_i \mathbb{E}[|X_i|^k]<\infty S_n=\sum_{i=1}^n X_i 
\mathbb{E}[|S_n|^k]\leqslant C_k \mathbb{E}\left[\left(\sum_{i=1}^n X_i^2\right)^{\frac{k}{2}}\right].
 X_{i_1}^{\alpha_1}\cdots X_{i_t}^{\alpha_t}","['probability', 'statistics']"
22,Comparing two hypothetical investment opportunities.,Comparing two hypothetical investment opportunities.,,"I came across a problem comparing two hypothetical investment opportunities. in both cases, you will invest some money and get a daily return on it. However, the return will follow one of these roles: You will get $\$35$ each day. You will have a $36\%$ probability of getting $\$70$ each day, however, if you did not receive it, the probability the next day will increase by $20\%$ . and if you receive it, the probability will reset back to $36\%$ . (for example, if you did not receive money on day $1$ , you will have a probability of $56\%$ of getting the $\$70$ . And if you did not get any money on days $1$ and $2$ , the probability of getting $\$70$ on the third day is $76\%$ . and so on) I tried to formulate it mathematically and found that the second option is better, On the other hand, I model the problem in Excel and found that both of them are equal. my mathematical solution was based on: First: find the success probability of some sequenced days, and then average the $\$70$ on these days. \begin{align*} \Bbb{P}(\text{return at day 1}) &= 36\%\\ \Bbb{P}(\text{return at day 2}) &= \Bbb{P}(\text{no return at day 1})\cdot (36\% + 20\%) = 35.84\%\\ \Bbb{P}(\text{return at day 3}) &= \Bbb{P}(\text{no return at day 1})\cdot\Bbb{P}(\text{no return at day 2}) \cdot (36\% +2 \cdot 20\%)= 21.4016\%\\ \Bbb{P}(\text{return at day 4}) &= 6.488\%\\ \Bbb{P}(\text{return at day 5}) &= 0.27\% \end{align*} Second, find the equivalent daily return after getting the \$70, which is: $\$70$ if you get the return on the first day. $\$35(70/2)$ if you get the return on the second day. $\$23.33(70/3)$ if you get the return on the third day. $\$17.5 then \$14$ for the fourth and fifth days. finally, the total equivalent daily return of the second option is: $$Eq_r = \sum_{i=1}^5  P(\text{return at day i}) \cdot \frac{70}{i} =43.91 $$ What option will result in more return over time? Notes: The probabilities in the second option will increase by $20$ until it reaches $100\%$ , so they are $\{36,56,76,96,100\}$ . The investment in both cases will go on forever.","I came across a problem comparing two hypothetical investment opportunities. in both cases, you will invest some money and get a daily return on it. However, the return will follow one of these roles: You will get each day. You will have a probability of getting each day, however, if you did not receive it, the probability the next day will increase by . and if you receive it, the probability will reset back to . (for example, if you did not receive money on day , you will have a probability of of getting the . And if you did not get any money on days and , the probability of getting on the third day is . and so on) I tried to formulate it mathematically and found that the second option is better, On the other hand, I model the problem in Excel and found that both of them are equal. my mathematical solution was based on: First: find the success probability of some sequenced days, and then average the on these days. Second, find the equivalent daily return after getting the \$70, which is: if you get the return on the first day. if you get the return on the second day. if you get the return on the third day. for the fourth and fifth days. finally, the total equivalent daily return of the second option is: What option will result in more return over time? Notes: The probabilities in the second option will increase by until it reaches , so they are . The investment in both cases will go on forever.","\35 36\% \70 20\% 36\% 1 56\% \70 1 2 \70 76\% \70 \begin{align*}
\Bbb{P}(\text{return at day 1}) &= 36\%\\
\Bbb{P}(\text{return at day 2}) &= \Bbb{P}(\text{no return at day 1})\cdot (36\% + 20\%) = 35.84\%\\
\Bbb{P}(\text{return at day 3}) &= \Bbb{P}(\text{no return at day 1})\cdot\Bbb{P}(\text{no return at day 2}) \cdot (36\% +2 \cdot 20\%)= 21.4016\%\\
\Bbb{P}(\text{return at day 4}) &= 6.488\%\\
\Bbb{P}(\text{return at day 5}) &= 0.27\%
\end{align*} \70 \35(70/2) \23.33(70/3) \17.5 then \14 Eq_r = \sum_{i=1}^5  P(\text{return at day i}) \cdot \frac{70}{i} =43.91  20 100\% \{36,56,76,96,100\}","['probability', 'statistics']"
23,The Probability of Getting a Repeated Digit in a Random 4-Digit PIN Code,The Probability of Getting a Repeated Digit in a Random 4-Digit PIN Code,,"I just wanted to check if my thinking is correct regarding a probability problem. The problem is as follows: You are randomly selecting a 4-digit PIN code. What is the probability that at least 2 of the digits are the same? My approach was to use the complement event, which means finding the probability that all 4 digits are unique. The number of possible combinations where all 4 digits are unique is: 10 * 9 * 8 * 7 = 5040 And since there are 10,000 possible combinations in total (10 options for each digit), the probability of getting a PIN code with all unique digits is: 5040/10000 = 0.504 Therefore, the probability of getting a PIN code with at least 2 of the digits being the same is: 1 - 0.504 = 0.496 or approximately 49.6% Could someone please confirm if my thinking and calculation are correct? Thank you in advance!","I just wanted to check if my thinking is correct regarding a probability problem. The problem is as follows: You are randomly selecting a 4-digit PIN code. What is the probability that at least 2 of the digits are the same? My approach was to use the complement event, which means finding the probability that all 4 digits are unique. The number of possible combinations where all 4 digits are unique is: 10 * 9 * 8 * 7 = 5040 And since there are 10,000 possible combinations in total (10 options for each digit), the probability of getting a PIN code with all unique digits is: 5040/10000 = 0.504 Therefore, the probability of getting a PIN code with at least 2 of the digits being the same is: 1 - 0.504 = 0.496 or approximately 49.6% Could someone please confirm if my thinking and calculation are correct? Thank you in advance!",,"['probability', 'combinatorics', 'statistics', 'discrete-mathematics']"
24,How to differentiate this integral with variable limits?,How to differentiate this integral with variable limits?,,"Source of the question: the exercise 2.18 of Statistical Inference Book by Casella and Berger. Show that if X is a continuous random variable, then $$\min_a E|X-a|=E|X-m|$$ , where m is the median. My attempt: $$E|X-a|=\int_{-\infty}^\infty |x-a|f(x)dx=  \int_{-\infty}^a -(x-a)f(x)dx + \int_a^\infty (x-a)f(x)dx$$ . Then $$\frac{d}{da} E|X-a|=$$ I don't know how to do this differentiation. I need to set it to zero. By using herb steinberg's hint, $$E|X-a|=-\int_{-\infty}^a xf(x)dx + a \int_{-\infty}^af(x)dx+\int_a^\infty xf(x)dx-a\int_a^\infty f(x)dx$$ Then by using Henry's hint, $$\frac{d}{da} E|X-a|= -af(a)+af(a)-af(a)+af(a)$$ . But this is always zero. Somewhere must go wrong.","Source of the question: the exercise 2.18 of Statistical Inference Book by Casella and Berger. Show that if X is a continuous random variable, then , where m is the median. My attempt: . Then I don't know how to do this differentiation. I need to set it to zero. By using herb steinberg's hint, Then by using Henry's hint, . But this is always zero. Somewhere must go wrong.",\min_a E|X-a|=E|X-m| E|X-a|=\int_{-\infty}^\infty |x-a|f(x)dx=  \int_{-\infty}^a -(x-a)f(x)dx + \int_a^\infty (x-a)f(x)dx \frac{d}{da} E|X-a|= E|X-a|=-\int_{-\infty}^a xf(x)dx + a \int_{-\infty}^af(x)dx+\int_a^\infty xf(x)dx-a\int_a^\infty f(x)dx \frac{d}{da} E|X-a|= -af(a)+af(a)-af(a)+af(a),"['calculus', 'probability', 'integration', 'statistics']"
25,Finding variance of an estimator,Finding variance of an estimator,,"I'm not sure how to express the variance of this estimator. Here's the setup. We have $X\sim N(0,\sigma^2)$ and want to estimate $\mathbb{E}[\phi(X)]$ where $\phi : \mathbb{R}\to\mathbb{R}$ is some function such that $\mathbb{E}[\phi(X)]$ has finite mean and variance. We have iid samples $Y_1,\dots, Y_n \sim N(0,1)$ . This is the estimator proposed: $$\hat{\theta} = \frac{1}{n\sigma}\sum_{i=1}^{n} \exp\left[-Y_i^2\left(\frac{1}{2\sigma^2}-\frac{1}{2}\right)\right]\phi(Y_i)$$ . I have shown this estimator is unbiased. But I'm not sure how to express its variance. The most I can say is that since the $Y_i$ are iid, we have $$Var(\hat{\theta})=\frac{1}{n^2\sigma^2}\sum_{i=1}^{n} Var\left(\exp \left[-Y_i^2\left(\frac{1}{2\sigma^2}-\frac{1}{2}\right)\right]\phi(Y_i)\right)$$ . How can I express this further?","I'm not sure how to express the variance of this estimator. Here's the setup. We have and want to estimate where is some function such that has finite mean and variance. We have iid samples . This is the estimator proposed: . I have shown this estimator is unbiased. But I'm not sure how to express its variance. The most I can say is that since the are iid, we have . How can I express this further?","X\sim N(0,\sigma^2) \mathbb{E}[\phi(X)] \phi : \mathbb{R}\to\mathbb{R} \mathbb{E}[\phi(X)] Y_1,\dots, Y_n \sim N(0,1) \hat{\theta} = \frac{1}{n\sigma}\sum_{i=1}^{n} \exp\left[-Y_i^2\left(\frac{1}{2\sigma^2}-\frac{1}{2}\right)\right]\phi(Y_i) Y_i Var(\hat{\theta})=\frac{1}{n^2\sigma^2}\sum_{i=1}^{n} Var\left(\exp \left[-Y_i^2\left(\frac{1}{2\sigma^2}-\frac{1}{2}\right)\right]\phi(Y_i)\right)","['probability', 'statistics', 'statistical-inference', 'variance', 'parameter-estimation']"
26,Deriving marginal distribution from a joint distribution,Deriving marginal distribution from a joint distribution,,"Let the joint distribution of a random vector be $$f(x,y)=\begin{cases}1,\enspace 0<x<1, x<y<x+1&\\0, \enspace {\rm otherwise}\end{cases}$$ The marginal pdf of $X$ is $Uni(0,1)$ , but what is the distribution of $Y$ ? By definition it should be $$f_Y(y)=\int_0^1 f(x,y){\rm d}x=1$$ but this is not correct. Integration is done over the bounds of $X$ , and when $x\in(0,1)$ then $f(x,y)=1$ . Is this not correct?","Let the joint distribution of a random vector be The marginal pdf of is , but what is the distribution of ? By definition it should be but this is not correct. Integration is done over the bounds of , and when then . Is this not correct?","f(x,y)=\begin{cases}1,\enspace 0<x<1, x<y<x+1&\\0, \enspace {\rm otherwise}\end{cases} X Uni(0,1) Y f_Y(y)=\int_0^1 f(x,y){\rm d}x=1 X x\in(0,1) f(x,y)=1","['integration', 'statistics', 'marginal-distribution']"
27,Statistics/combinatorics question relating to Enigma rotors,Statistics/combinatorics question relating to Enigma rotors,,"I would be grateful of some advice on what I hope is a straightforward matter for mathematicians with a sound knowledge of statistics and probability/combinatorics. Context I am investigating Enigma rotors, which cause the 26 letters of the alphabet to become permuted between input and output. There are therefore 26! possible rotors. But what seems to be important in terms of the Enigma producing random permutations is that the number of permutation offsets is as large as possible. By permutation offset, I mean the difference in position between the output letter and the input letter. So for example, if A permutes to E, then the resulting difference is 5-1=4. If H permutes to D then the resulting difference is 4-8=-4=22mod26. So collectively there are 26 permutation offsets for an Enigma rotor. However, it can be shown that it is impossible for all 26 different offsets i.e. the set of integers from 0-25 inclusive to be present. So I am interested in estimating how many different rotors are possible with 25 different offsets. Computationally, I don't think it is possible to assess all 26! permutations and keep a count of the ones that result in 25 offsets. So I have resorted to creating random permutations using the Python random.shuffle function. Over 5 billion random samples (which takes 12 hours to run on my admittedly old PC), I have measured anything between 48 and 75 of these permutations, so we are talking order of 10-15 per billion random permutations. So, these permutations are very rare, but in the context of 26!, there are also a lot of them (order 10^18) So my question is: how many random samples would I need to test before I could be confident that my estimate of the frequency of these permutations is correct within +/-5%? What about +/-1%? I have tried dividing the sample space into smaller intervals eg of 100 million and then using the resulting data to produce a confidence interval. But I doubt that approach has any mathematical validity. Any help or advice gratefully appreciated. I suspect this is a fairly generic problem in statistics, but I haven't been able to find an answer using Google.","I would be grateful of some advice on what I hope is a straightforward matter for mathematicians with a sound knowledge of statistics and probability/combinatorics. Context I am investigating Enigma rotors, which cause the 26 letters of the alphabet to become permuted between input and output. There are therefore 26! possible rotors. But what seems to be important in terms of the Enigma producing random permutations is that the number of permutation offsets is as large as possible. By permutation offset, I mean the difference in position between the output letter and the input letter. So for example, if A permutes to E, then the resulting difference is 5-1=4. If H permutes to D then the resulting difference is 4-8=-4=22mod26. So collectively there are 26 permutation offsets for an Enigma rotor. However, it can be shown that it is impossible for all 26 different offsets i.e. the set of integers from 0-25 inclusive to be present. So I am interested in estimating how many different rotors are possible with 25 different offsets. Computationally, I don't think it is possible to assess all 26! permutations and keep a count of the ones that result in 25 offsets. So I have resorted to creating random permutations using the Python random.shuffle function. Over 5 billion random samples (which takes 12 hours to run on my admittedly old PC), I have measured anything between 48 and 75 of these permutations, so we are talking order of 10-15 per billion random permutations. So, these permutations are very rare, but in the context of 26!, there are also a lot of them (order 10^18) So my question is: how many random samples would I need to test before I could be confident that my estimate of the frequency of these permutations is correct within +/-5%? What about +/-1%? I have tried dividing the sample space into smaller intervals eg of 100 million and then using the resulting data to produce a confidence interval. But I doubt that approach has any mathematical validity. Any help or advice gratefully appreciated. I suspect this is a fairly generic problem in statistics, but I haven't been able to find an answer using Google.",,"['probability', 'combinatorics', 'statistics', 'permutations', 'sampling']"
28,Statistical guarantee on the effectiveness of a kernel density estimation,Statistical guarantee on the effectiveness of a kernel density estimation,,"I have recently started studying about kernel density estimations. For reference, if one is given if $(x_1,x_2,...,x_n)$ is an i. i. d. sample drawn from an (unknown) distribution with an unknown $f$ density function, then the kernel density estimator of $f$ is the following: $$\hat{f}_h(x) := \frac{1}{nh}\sum_{i=1}^n K \Big(\frac{x-x_i}{h} \Big),$$ where $K$ is the kernel. I started to look for any literature, which states something about the ""effectiveness"" of this estimation, such as 1 and 2 . What I seem unanble to find is a theoretical guarantee for the norm of the difference between the original and the estimated density function, namely the term $||\hat{f}_h - f||_p$ for some $p$ . Is there a theorem that states something as follows: for every $\varepsilon > 0$ , there exists a $\delta > 0$ , such that $$\mathbb{P}(||\hat{f}_h - f||_p > \varepsilon) < 1-\delta?$$ Any help is greatly appreciated!","I have recently started studying about kernel density estimations. For reference, if one is given if is an i. i. d. sample drawn from an (unknown) distribution with an unknown density function, then the kernel density estimator of is the following: where is the kernel. I started to look for any literature, which states something about the ""effectiveness"" of this estimation, such as 1 and 2 . What I seem unanble to find is a theoretical guarantee for the norm of the difference between the original and the estimated density function, namely the term for some . Is there a theorem that states something as follows: for every , there exists a , such that Any help is greatly appreciated!","(x_1,x_2,...,x_n) f f \hat{f}_h(x) := \frac{1}{nh}\sum_{i=1}^n K \Big(\frac{x-x_i}{h} \Big), K ||\hat{f}_h - f||_p p \varepsilon > 0 \delta > 0 \mathbb{P}(||\hat{f}_h - f||_p > \varepsilon) < 1-\delta?","['statistics', 'normed-spaces', 'density-function', 'estimation', 'reproducing-kernel-hilbert-spaces']"
29,Analyzing the probability of this event,Analyzing the probability of this event,,"Consider a set $S$ of $n$ different elements. Sample $f(n)$ different elements from $S$ to get a new set $S'$ such that $\lim_{n\to\infty}\frac{f(n)}{n} = 0$ . Now pick uniformly at random one element $x$ from $S'$ and suppose it lies in the middle third of $S'$ . We want to find the probability that $x$ is also in the middle third of $S$ and show that $x$ is also likely to be in the middle third of $S$ . This is my attempt. First, we find the probability that $x$ is the element of rank $i$ in $S$ given that $x$ is in the middle third of $S'$ $$ P_i = \frac{3}{f(n)}\frac{1}{n \choose f(n)}\sum^{\frac{2f(n)}{3}}_{j=\frac{f(n)}{3}+1} {i-1\choose j-1} {n-i\choose f(n)-j}.$$ So the probability we want to look at is $\sum^{\frac{2n}{3}}_{i=\frac{n}{3}+1}P_i$ but I find this expression hard to work with and find a bound for it, what else can I do?","Consider a set of different elements. Sample different elements from to get a new set such that . Now pick uniformly at random one element from and suppose it lies in the middle third of . We want to find the probability that is also in the middle third of and show that is also likely to be in the middle third of . This is my attempt. First, we find the probability that is the element of rank in given that is in the middle third of So the probability we want to look at is but I find this expression hard to work with and find a bound for it, what else can I do?",S n f(n) S S' \lim_{n\to\infty}\frac{f(n)}{n} = 0 x S' S' x S x S x i S x S'  P_i = \frac{3}{f(n)}\frac{1}{n \choose f(n)}\sum^{\frac{2f(n)}{3}}_{j=\frac{f(n)}{3}+1} {i-1\choose j-1} {n-i\choose f(n)-j}. \sum^{\frac{2n}{3}}_{i=\frac{n}{3}+1}P_i,"['probability', 'combinatorics', 'statistics', 'probability-distributions']"
30,Averaging Distances - Valid Comparasions?,Averaging Distances - Valid Comparasions?,,"As we know, there are many different ways to compare the level of similarity between two strings of text (e.g. https://en.wikipedia.org/wiki/String_metric ). I have often found myself confused as to which of metrics are better suited for different problems (e.g. a certain metric might say that two strings are very similar, but a different metric might say that the same two strings are very different) - this led me to the following idea: For a given problem, perhaps I could try to take the average for multiple metrics and get a more ""balanced"" metric - is this a mathematically valid approach?? As an example, I simulated this dataset in R: set.seed(123)  myFun <- function(n = 5000) {   a <- do.call(paste0, replicate(5, sample(LETTERS, n, TRUE), FALSE))   paste0(a, sprintf(""%04d"", sample(9999, n, TRUE)), sample(LETTERS, n, TRUE)) }  col1 = myFun(10) col2 = myFun(10) col3 = myFun(10) col4 = myFun(10)  example = data.frame(col1, col2, col3, col4)           col1       col2       col3       col4 1  ONHGW1599P VTYUV6387G LPTDH0712U KYIQF7684P 2  SVZUU4237T RVNEL9039J NMYTN9644I ATIZR2378Q 3  NYGLG3937F QYCHT7281E SSPLU5370G YZEQQ5509U 4  CZJOU4089K BNNSN9175F YXXVM3501G SGWZE4213M 5  JEIJF2907H DYGJQ4715P GTVQB3069Z JYNUY9271U 6  RSSMY0294V MWCRN0151X VOKJK8720J UWNGT9433H 7  VYDGB8469V ECWJV6810U ZGPTM4055X VZFUC7826U 8  KYNIE0041G VHVLC9830W IDTKN9761V MTAZY1706G 9  EIQIH8508P SPZBH8174K GAHYF0473W KXZIN7879T 10 TCKJL7391Q YLOJN6911D BHCWY6098Z KYJTA9065R Suppose I am interested in comparing all possible comparisons between (col1,col2) and (col3,col4). The R programming language is able to evaluate the following distance metrics: method = c(""osa"", ""lv"", ""dl"", ""hamming"", ""lcs"", ""qgram"", ""cosine"", ""jaccard"", ""jw"",""soundex"") I wrote this loop that can calculate all these metrics for all possible combinations: method = c(""osa"", ""lv"", ""dl"", ""hamming"", ""lcs"", ""qgram"", ""cosine"", ""jaccard"", ""jw"",""soundex"")  library(stringdist)  results = list()  for (i in 1:length(method))  {  method_i = method[i] name_1_i = paste0(""col1_col_2"", method_i)  name_2_i = paste0(""col3_col_4"", method_i)  p1_i = stringdistmatrix(col1, col2, method =  method_i, useNames = ""string"") %>%             as_tibble(rownames = ""a"") %>%             pivot_longer(-1, names_to = ""b"", values_to = name_1_i)  p2_i = stringdistmatrix(col3, col4, method =  method_i, useNames = ""string"") %>%             as_tibble(rownames = ""a"") %>%             pivot_longer(-1, names_to = ""b"", values_to = name_2_i)  p1_i = p1_i[,3] p2_i = p2_i[,3]  final_i = cbind(p1_i, p2_i)  results[[i]] = final_i }  final = do.call(cbind.data.frame, results) final = cbind(col1,col2, col3,col4, final) I can now proceed to take these averages as follows and append them to the original data: average_col1_col2_dist = (final $col1_col_2osa  + final$ col1_col_2lv + final $col1_col_2dl      + final$ col1_col_2hamming + final $col1_col_2lcs +     final$ col1_col_2qgram  + final $col1_col_2cosine    + final$ col1_col_2jaccard + final $col1_col_2jw   + final$ col1_col_2soundex)/10   average_col3_col4_dist =  ( final $col3_col_4osa     +    final$ col3_col_4lv       +     final $col3_col_4dl  +     final$ col3_col_4hamming +  final $col3_col_4lcs +  final$ col3_col_4qgram  +   final $col3_col_4cosine +    final$ col3_col_4jaccard  +    final $col3_col_4jw     +   final$ col3_col_4soundex)/10  final = data.frame( col1, col2, col3, col4, average_col1_col2_dist,  average_col3_col4_dist)          col1       col2       col3       col4 average_col1_col2_dist average_col3_col4_dist 1 ONHGW1599P VTYUV6387G LPTDH0712U KYIQF7684P               7.985784               7.728889 2 SVZUU4237T RVNEL9039J NMYTN9644I ATIZR2378Q               6.692500               7.310131 3 NYGLG3937F QYCHT7281E SSPLU5370G YZEQQ5509U               7.523311               7.123930 4 CZJOU4089K BNNSN9175F YXXVM3501G SGWZE4213M               6.471213               7.338889 5 JEIJF2907H DYGJQ4715P GTVQB3069Z JYNUY9271U               6.276818               6.181671 6 RSSMY0294V MWCRN0151X VOKJK8720J UWNGT9433H               6.578095               7.313864 Now my question - is this approach that I have outlined mathematically valid? I know that you can take the average of any set of measurements, but the resulting average might not always be ""logical"" (e.g. measurements in different units). Inspecting the results, I see that ""qgram distances"" appear to be significantly larger than ""cosine distances"" - this makes me think that perhaps I might be able to ""normalize"" each column (e.g. final = scale(final) ) - but again, I am not sure if this is a mathematically valid approach. Does anyone have any ideas if it is mathematically valid to compare the average of multiple string metrics? Thank you!","As we know, there are many different ways to compare the level of similarity between two strings of text (e.g. https://en.wikipedia.org/wiki/String_metric ). I have often found myself confused as to which of metrics are better suited for different problems (e.g. a certain metric might say that two strings are very similar, but a different metric might say that the same two strings are very different) - this led me to the following idea: For a given problem, perhaps I could try to take the average for multiple metrics and get a more ""balanced"" metric - is this a mathematically valid approach?? As an example, I simulated this dataset in R: set.seed(123)  myFun <- function(n = 5000) {   a <- do.call(paste0, replicate(5, sample(LETTERS, n, TRUE), FALSE))   paste0(a, sprintf(""%04d"", sample(9999, n, TRUE)), sample(LETTERS, n, TRUE)) }  col1 = myFun(10) col2 = myFun(10) col3 = myFun(10) col4 = myFun(10)  example = data.frame(col1, col2, col3, col4)           col1       col2       col3       col4 1  ONHGW1599P VTYUV6387G LPTDH0712U KYIQF7684P 2  SVZUU4237T RVNEL9039J NMYTN9644I ATIZR2378Q 3  NYGLG3937F QYCHT7281E SSPLU5370G YZEQQ5509U 4  CZJOU4089K BNNSN9175F YXXVM3501G SGWZE4213M 5  JEIJF2907H DYGJQ4715P GTVQB3069Z JYNUY9271U 6  RSSMY0294V MWCRN0151X VOKJK8720J UWNGT9433H 7  VYDGB8469V ECWJV6810U ZGPTM4055X VZFUC7826U 8  KYNIE0041G VHVLC9830W IDTKN9761V MTAZY1706G 9  EIQIH8508P SPZBH8174K GAHYF0473W KXZIN7879T 10 TCKJL7391Q YLOJN6911D BHCWY6098Z KYJTA9065R Suppose I am interested in comparing all possible comparisons between (col1,col2) and (col3,col4). The R programming language is able to evaluate the following distance metrics: method = c(""osa"", ""lv"", ""dl"", ""hamming"", ""lcs"", ""qgram"", ""cosine"", ""jaccard"", ""jw"",""soundex"") I wrote this loop that can calculate all these metrics for all possible combinations: method = c(""osa"", ""lv"", ""dl"", ""hamming"", ""lcs"", ""qgram"", ""cosine"", ""jaccard"", ""jw"",""soundex"")  library(stringdist)  results = list()  for (i in 1:length(method))  {  method_i = method[i] name_1_i = paste0(""col1_col_2"", method_i)  name_2_i = paste0(""col3_col_4"", method_i)  p1_i = stringdistmatrix(col1, col2, method =  method_i, useNames = ""string"") %>%             as_tibble(rownames = ""a"") %>%             pivot_longer(-1, names_to = ""b"", values_to = name_1_i)  p2_i = stringdistmatrix(col3, col4, method =  method_i, useNames = ""string"") %>%             as_tibble(rownames = ""a"") %>%             pivot_longer(-1, names_to = ""b"", values_to = name_2_i)  p1_i = p1_i[,3] p2_i = p2_i[,3]  final_i = cbind(p1_i, p2_i)  results[[i]] = final_i }  final = do.call(cbind.data.frame, results) final = cbind(col1,col2, col3,col4, final) I can now proceed to take these averages as follows and append them to the original data: average_col1_col2_dist = (final col1_col_2lv + final col1_col_2hamming + final col1_col_2qgram  + final col1_col_2jaccard + final col1_col_2soundex)/10   average_col3_col4_dist =  ( final col3_col_4lv       +     final col3_col_4hamming +  final col3_col_4qgram  +   final col3_col_4jaccard  +    final col3_col_4soundex)/10  final = data.frame( col1, col2, col3, col4, average_col1_col2_dist,  average_col3_col4_dist)          col1       col2       col3       col4 average_col1_col2_dist average_col3_col4_dist 1 ONHGW1599P VTYUV6387G LPTDH0712U KYIQF7684P               7.985784               7.728889 2 SVZUU4237T RVNEL9039J NMYTN9644I ATIZR2378Q               6.692500               7.310131 3 NYGLG3937F QYCHT7281E SSPLU5370G YZEQQ5509U               7.523311               7.123930 4 CZJOU4089K BNNSN9175F YXXVM3501G SGWZE4213M               6.471213               7.338889 5 JEIJF2907H DYGJQ4715P GTVQB3069Z JYNUY9271U               6.276818               6.181671 6 RSSMY0294V MWCRN0151X VOKJK8720J UWNGT9433H               6.578095               7.313864 Now my question - is this approach that I have outlined mathematically valid? I know that you can take the average of any set of measurements, but the resulting average might not always be ""logical"" (e.g. measurements in different units). Inspecting the results, I see that ""qgram distances"" appear to be significantly larger than ""cosine distances"" - this makes me think that perhaps I might be able to ""normalize"" each column (e.g. final = scale(final) ) - but again, I am not sure if this is a mathematically valid approach. Does anyone have any ideas if it is mathematically valid to compare the average of multiple string metrics? Thank you!",col1_col_2osa  + final col1_col_2dl      + final col1_col_2lcs +     final col1_col_2cosine    + final col1_col_2jw   + final col3_col_4osa     +    final col3_col_4dl  +     final col3_col_4lcs +  final col3_col_4cosine +    final col3_col_4jw     +   final,"['statistics', 'average', 'means']"
31,combinatorics: deck of cards and suits,combinatorics: deck of cards and suits,,"I feel confused about selecting suits and cards that each suit corresponds to. Suppose we have a standard deck of cards, and we want to form a 6 hands with at most 3 suits. I understand this needs to be spliced into 3 cases to discuss, which are 1 suit case, 2 suits case, and 3 suits case. But I feel confused when it comes to select cards. For example, I am not sure if I understand this correctly, but I feel like if we only need to form cards with a single suit, then this can be done by $4(13 * 12 * 11 * 10 * 9 * 8)$ ways, since each suit has 13 cards, and we have 4 suits here. And when it comes to the 2 suits case, I feel like we only need to draw from the total of 26 cards to form such hands, and there are 6 ways to do this, but I am not sure if my understanding about the 26 cards is right or what. And for the 3 suits case, I feel like it's just choose 3 suits out of 4, and draw cards from total of 39 cards. Is my understanding towards the total number of cards in each case correct? If not, why so?","I feel confused about selecting suits and cards that each suit corresponds to. Suppose we have a standard deck of cards, and we want to form a 6 hands with at most 3 suits. I understand this needs to be spliced into 3 cases to discuss, which are 1 suit case, 2 suits case, and 3 suits case. But I feel confused when it comes to select cards. For example, I am not sure if I understand this correctly, but I feel like if we only need to form cards with a single suit, then this can be done by ways, since each suit has 13 cards, and we have 4 suits here. And when it comes to the 2 suits case, I feel like we only need to draw from the total of 26 cards to form such hands, and there are 6 ways to do this, but I am not sure if my understanding about the 26 cards is right or what. And for the 3 suits case, I feel like it's just choose 3 suits out of 4, and draw cards from total of 39 cards. Is my understanding towards the total number of cards in each case correct? If not, why so?",4(13 * 12 * 11 * 10 * 9 * 8),"['combinatorics', 'statistics', 'card-games']"
32,Using exponential family to find the derivate of the partition function [closed],Using exponential family to find the derivate of the partition function [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 1 year ago . Improve this question Distributions that follow the exponential family have the following form \begin{equation} p(x) = h(x)\exp \left[\theta^T T(x) - H(\theta)\right] \end{equation} and $\frac{\partial}{\partial \theta}H(\theta) = \mathbb E_p[T(X)]$ . I have the following function \begin{equation} H(\theta) = \log \int_z \exp \left[\log P(y|z) - \frac{z^2}{2v} + \frac{mz}{2v}\right] \end{equation} I want to find $\frac{\partial}{\partial m}H(\theta)$ . For this define $T(z) = \begin{bmatrix} 1 & z/v & z^2 \end{bmatrix}^T$ and $\theta = \begin{bmatrix} \log P(y|z) & m & -1/2v \end{bmatrix}^T$ . Is it correct that $\frac{\partial}{\partial m}H(\theta) = \mathbb E[T_2(z)|\theta] = \mathbb E[\frac{z}{v}|\theta]$ ?,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 1 year ago . Improve this question Distributions that follow the exponential family have the following form and . I have the following function I want to find . For this define and . Is it correct that ?,"\begin{equation}
p(x) = h(x)\exp \left[\theta^T T(x) - H(\theta)\right]
\end{equation} \frac{\partial}{\partial \theta}H(\theta) = \mathbb E_p[T(X)] \begin{equation}
H(\theta) = \log \int_z \exp \left[\log P(y|z) - \frac{z^2}{2v} + \frac{mz}{2v}\right]
\end{equation} \frac{\partial}{\partial m}H(\theta) T(z) = \begin{bmatrix} 1 & z/v & z^2 \end{bmatrix}^T \theta = \begin{bmatrix} \log P(y|z) & m & -1/2v \end{bmatrix}^T \frac{\partial}{\partial m}H(\theta) = \mathbb E[T_2(z)|\theta] = \mathbb E[\frac{z}{v}|\theta]","['statistics', 'exponential-function', 'normal-distribution', 'exponential-distribution', 'maximum-likelihood']"
33,What does $\frac{X_n}n$ converge to in distribution for $X_n \sim \chi^2_n$?,What does  converge to in distribution for ?,\frac{X_n}n X_n \sim \chi^2_n,"Problem I have been working through a probability question, where I am supposed to show that the following claim is not true. I believe I am supposed to use the Weak Law of Large Numbers in order to induce a contradiction, however, I'm not sure how to make progress here. Claim: For $X_n$ following the Chi Square distribution with $n$ degrees of freedom, $\frac{X_n}{n}$ converges in distribution to $X$ with $P(X=0)=1$ . We want to show that this claim is false. Attempt As $X_n$ follows the Chi Square distribution, we know that $$X_n=Z_1^2+Z_2^2+\cdots+Z_n^2$$ where each $Z_i$ follows the standard normal distribution. I don't think each $X_i$ will be independent because $$X_i=X_{i-1}+Z_i^2$$ However, without assuming independence, I'm completely unsure of how to to proceed from here. If we then assume independence, then the Weak Law of Large Numbers states: Weak Law of Large Numbers: for independent $X_1,  X_2, X_3$ ... with common mean and variance, then for all $\epsilon >0$ , the probability $$P \Big{(} \Bigl{|} \frac{\sum_{1}^nX_k}{n}-\mu \Bigl{|} \ge \epsilon \Big{)} \rightarrow 0$$ $$\text{or alternatively}$$ $$P \big{(}\bigl{|}X_n-X \bigl{|} \ge \epsilon \big{)} \rightarrow 0$$ We can rewrite $$P\big{(}\bigl{|}X_n-X \bigl{|} \ge \epsilon \big{)} = P \big{(} \bigl{|}X_n \bigl{|} \ge \epsilon \big{)}$$ as $X=0$ with probability $1$ . I am unsure of how to proceed from here (or if what I have done is correct). I would be grateful for any further guidance as I am not sure if my assumption of independence is correct.","Problem I have been working through a probability question, where I am supposed to show that the following claim is not true. I believe I am supposed to use the Weak Law of Large Numbers in order to induce a contradiction, however, I'm not sure how to make progress here. Claim: For following the Chi Square distribution with degrees of freedom, converges in distribution to with . We want to show that this claim is false. Attempt As follows the Chi Square distribution, we know that where each follows the standard normal distribution. I don't think each will be independent because However, without assuming independence, I'm completely unsure of how to to proceed from here. If we then assume independence, then the Weak Law of Large Numbers states: Weak Law of Large Numbers: for independent ... with common mean and variance, then for all , the probability We can rewrite as with probability . I am unsure of how to proceed from here (or if what I have done is correct). I would be grateful for any further guidance as I am not sure if my assumption of independence is correct.","X_n n \frac{X_n}{n} X P(X=0)=1 X_n X_n=Z_1^2+Z_2^2+\cdots+Z_n^2 Z_i X_i X_i=X_{i-1}+Z_i^2 X_1,  X_2, X_3 \epsilon >0 P \Big{(} \Bigl{|} \frac{\sum_{1}^nX_k}{n}-\mu \Bigl{|} \ge \epsilon \Big{)} \rightarrow 0 \text{or alternatively} P \big{(}\bigl{|}X_n-X \bigl{|} \ge \epsilon \big{)} \rightarrow 0 P\big{(}\bigl{|}X_n-X \bigl{|} \ge \epsilon \big{)} = P \big{(} \bigl{|}X_n \bigl{|} \ge \epsilon \big{)} X=0 1","['probability', 'statistics', 'probability-distributions', 'convergence-divergence', 'law-of-large-numbers']"
34,Confusion on using central limit theorem on uniform distribution,Confusion on using central limit theorem on uniform distribution,,"In lectures we said that if $X$ is independently uniformly distributed, the CLI statest that: $$\lim_{n\rightarrow \infty}   (\frac{\sum_{n=1}^{i}(x_i - \mu)}{\sqrt{n}\sigma}) =^{d} N(0,1)$$ However, I don't understand, what is $\sqrt{n}$ doing there, because we also did an example of binomial distribution (let's call it $S_n$ ), and we said: $$\lim_{n\rightarrow \infty}   (\frac{S_n-np}{\sqrt{np(1-p)}}) =^{d} N(0,1)$$ From which I would conclude that the correct formula would be: $$\lim_{n\rightarrow \infty}   (\frac{Distr - expectation }{\sqrt{variance}}) =^{d} N(0,1)$$ What is correct and why?","In lectures we said that if is independently uniformly distributed, the CLI statest that: However, I don't understand, what is doing there, because we also did an example of binomial distribution (let's call it ), and we said: From which I would conclude that the correct formula would be: What is correct and why?","X \lim_{n\rightarrow \infty}   (\frac{\sum_{n=1}^{i}(x_i - \mu)}{\sqrt{n}\sigma}) =^{d} N(0,1) \sqrt{n} S_n \lim_{n\rightarrow \infty}   (\frac{S_n-np}{\sqrt{np(1-p)}}) =^{d} N(0,1) \lim_{n\rightarrow \infty}   (\frac{Distr - expectation }{\sqrt{variance}}) =^{d} N(0,1)","['probability', 'statistics', 'probability-distributions', 'central-limit-theorem']"
35,Distribution of N balls in N buckets in descending order?,Distribution of N balls in N buckets in descending order?,,"Let's suppose I have $N$ buckets and $N$ balls, and I add a ball to a uniformly random bucket, N times. (So, for example, it's possible each bucket contains one ball.  It's also possible that one of the buckets has N balls, and the others have 0.) After this, lets suppose I rearrange the buckets in a descending order of how many balls they hold, and label (one of) the buckets with the most balls 1, the next 2 and so on until N is (one of) the buckets with the least balls. What is the expected value $E_N(i)$ of the number of balls that the ith bucket has? For $N=1$ its trivial: $$ E_1(1) = 1 $$ For $N=2$ , either they will fall 1-1 or they will fall 2-0, both with equal probability, so: $$     E_2(1) = (2 + 1) / 2 = 1.5\\     E_2(2) = (0 + 1) / 2 = 0.5 $$ Is there a general solution for $E_N(i)$ ?  and what about as N approaches infinity? Does the distribution/function have a name?","Let's suppose I have buckets and balls, and I add a ball to a uniformly random bucket, N times. (So, for example, it's possible each bucket contains one ball.  It's also possible that one of the buckets has N balls, and the others have 0.) After this, lets suppose I rearrange the buckets in a descending order of how many balls they hold, and label (one of) the buckets with the most balls 1, the next 2 and so on until N is (one of) the buckets with the least balls. What is the expected value of the number of balls that the ith bucket has? For its trivial: For , either they will fall 1-1 or they will fall 2-0, both with equal probability, so: Is there a general solution for ?  and what about as N approaches infinity? Does the distribution/function have a name?","N N E_N(i) N=1 
E_1(1) = 1
 N=2 
    E_2(1) = (2 + 1) / 2 = 1.5\\
    E_2(2) = (0 + 1) / 2 = 0.5
 E_N(i)","['probability', 'combinatorics', 'statistics', 'balls-in-bins']"
36,Understanding random variables as functions,Understanding random variables as functions,,"First of all, I have read What is a function and I have understood it basically and it is clear to me that in order to caluclate statistics ""things"" have to be transformed or mapped to numbers. I have read that a random variable $X$ is (or can be thought) as a function. $X:\Omega\rightarrow\mathbb{R}$ and then $X(\omega) = ...$ Say we have a coin with $\Omega = \{H,T\}$ then we could do $X:\{H,T\} = \{0,1\}$ . My question is here about the meaning of $X$ or how to ""pronouce"" it. I would say $X$ is just a placeholder or short for ""map (or transform) the character ""H"" into 0 and ""T"" into 1. Or if we wean to count the numbers of getting tails then X:{H,T} = if tails is facing upwards increase the counter by 1. And $X$ is just short for the if sentene. Is this right? Second, say I have a data set like this \begin{array}{|c|c|c|} \hline id& coin & value \\ \hline  1& H & 0\\ \hline  2& H & 0\\ \hline  3& T & 1\\ \hline \end{array} then ""coin"" is no random variable because it isn't a number and only ""value"" is. Is this true?","First of all, I have read What is a function and I have understood it basically and it is clear to me that in order to caluclate statistics ""things"" have to be transformed or mapped to numbers. I have read that a random variable is (or can be thought) as a function. and then Say we have a coin with then we could do . My question is here about the meaning of or how to ""pronouce"" it. I would say is just a placeholder or short for ""map (or transform) the character ""H"" into 0 and ""T"" into 1. Or if we wean to count the numbers of getting tails then X:{H,T} = if tails is facing upwards increase the counter by 1. And is just short for the if sentene. Is this right? Second, say I have a data set like this then ""coin"" is no random variable because it isn't a number and only ""value"" is. Is this true?","X X:\Omega\rightarrow\mathbb{R} X(\omega) = ... \Omega = \{H,T\} X:\{H,T\} = \{0,1\} X X X \begin{array}{|c|c|c|}
\hline
id& coin & value \\ \hline
 1& H & 0\\ \hline
 2& H & 0\\ \hline
 3& T & 1\\ \hline
\end{array}","['statistics', 'functions', 'notation', 'random-variables']"
37,"Can Machine Learning models be considered as ""Approximate Dynamic Programming""?","Can Machine Learning models be considered as ""Approximate Dynamic Programming""?",,"In the context of certain statistical/machine learning models, such as models that are trying to estimate ""optimal policies"" (e.g. reinforcement learning) - can we consider these models as ""approximate dynamic programming""? My understanding is that the principle of ""Bellman Optimality"" states that in optimization problems in which ""optimal substructure"" is believed to exist* - Dynamic Programming in theory is able to provide a globally optimal solution by breaking the original problem into multiple smaller problems and solve the original problem by solving all the smaller problems. I am not sure if I understood this correctly - but Bellman Optimality also states that for problems with Optimal Substructure, Dynamic Programming can work recursively with ""limited lookahead"", implying that Optimal Solutions can be found without spending ""too much time"" moving backwards/forwards and reconsidering policies at previous steps. However, Dynamic Programming in the classical sense is unable to work effectively in larger problems - therefore, a ""Value Function"" is created to estimate the approximate value of different states, and then Dynamic Programming can be used to approximate a globally optimal solution. Dynamic Programming in this approximate form (i.e. Approximate Dynamic Programming) is implemented through a Statistical/Machine Learning model. Is my understanding of this correct - can certain Statistical/Machine Learning Models be considered as Approximate Dynamic Programming? Thanks! *Note: I am told that there is no real way to determine if an optimization problem indeed has ""optimal substructure"" - we often assume that they do and solve them under this assumption. This results in solutions in real world problems being locally optimal instead of globally optimal. Note : I think that the main difference between Greedy Search and Dynamic Programming is that Greedy Search returns an optimal solution only at each subproblem and reaches the final solution by joining all these optimal solution together - this only results in a globally optimal solution in some problems. Dynamic Programming tries to calculate optimal solutions at each time point by considering/projecting the effect of these solutions at future time points, and can reconsider previously chosen solutions. In short, Dynamic Programming returns optimal solutions on all problems that Greedy Search returns optimal solutions - but there are some problems in which Greedy Search will not return an Optimal Solution but Dynamic Programming will return an Optimal Solution.","In the context of certain statistical/machine learning models, such as models that are trying to estimate ""optimal policies"" (e.g. reinforcement learning) - can we consider these models as ""approximate dynamic programming""? My understanding is that the principle of ""Bellman Optimality"" states that in optimization problems in which ""optimal substructure"" is believed to exist* - Dynamic Programming in theory is able to provide a globally optimal solution by breaking the original problem into multiple smaller problems and solve the original problem by solving all the smaller problems. I am not sure if I understood this correctly - but Bellman Optimality also states that for problems with Optimal Substructure, Dynamic Programming can work recursively with ""limited lookahead"", implying that Optimal Solutions can be found without spending ""too much time"" moving backwards/forwards and reconsidering policies at previous steps. However, Dynamic Programming in the classical sense is unable to work effectively in larger problems - therefore, a ""Value Function"" is created to estimate the approximate value of different states, and then Dynamic Programming can be used to approximate a globally optimal solution. Dynamic Programming in this approximate form (i.e. Approximate Dynamic Programming) is implemented through a Statistical/Machine Learning model. Is my understanding of this correct - can certain Statistical/Machine Learning Models be considered as Approximate Dynamic Programming? Thanks! *Note: I am told that there is no real way to determine if an optimization problem indeed has ""optimal substructure"" - we often assume that they do and solve them under this assumption. This results in solutions in real world problems being locally optimal instead of globally optimal. Note : I think that the main difference between Greedy Search and Dynamic Programming is that Greedy Search returns an optimal solution only at each subproblem and reaches the final solution by joining all these optimal solution together - this only results in a globally optimal solution in some problems. Dynamic Programming tries to calculate optimal solutions at each time point by considering/projecting the effect of these solutions at future time points, and can reconsider previously chosen solutions. In short, Dynamic Programming returns optimal solutions on all problems that Greedy Search returns optimal solutions - but there are some problems in which Greedy Search will not return an Optimal Solution but Dynamic Programming will return an Optimal Solution.",,"['statistics', 'optimization', 'machine-learning', 'dynamic-programming']"
38,Least squares: can't find why $SSR = a_1 \sum Y_i + b_1 \sum Y_i X_i - n\overline Y^2$. Would anyone have references?,Least squares: can't find why . Would anyone have references?,SSR = a_1 \sum Y_i + b_1 \sum Y_i X_i - n\overline Y^2,"A past lecture introduced the concept of the sum of the squared differences between the dependent variable's mean and its estimated values, $SSR := \sum \left(\hat Y_i - \overline Y\right)^2$ . My lecturer's notes offer the additional following formula for the sum of squares due to regression: $$SSR = a_1 \sum Y_i + b_1 \sum Y_i X_i - n\overline Y^2$$ where $a_1, b_1$ are the coefficients for the regression line $\hat Y_i = a_1 + b_1 X_i$ , and $\overline X, \overline Y$ are the arithmetic means for the values of the data set, $X_i, Y_i$ . My lecturer's notes offer no additional explanations (it's a statistics for economics class), and no matter how much I try to tinker with Gauss' normal equations, I can't figure out how exactly they arrive at this result. Would anyone have a reference I could use, or an explanation of how this equation comes about?","A past lecture introduced the concept of the sum of the squared differences between the dependent variable's mean and its estimated values, . My lecturer's notes offer the additional following formula for the sum of squares due to regression: where are the coefficients for the regression line , and are the arithmetic means for the values of the data set, . My lecturer's notes offer no additional explanations (it's a statistics for economics class), and no matter how much I try to tinker with Gauss' normal equations, I can't figure out how exactly they arrive at this result. Would anyone have a reference I could use, or an explanation of how this equation comes about?","SSR := \sum \left(\hat Y_i - \overline Y\right)^2 SSR = a_1 \sum Y_i + b_1 \sum Y_i X_i - n\overline Y^2 a_1, b_1 \hat Y_i = a_1 + b_1 X_i \overline X, \overline Y X_i, Y_i","['statistics', 'reference-request', 'regression', 'least-squares']"
39,"If task start time is chosen from a uniform random distribution, is inter-arrival time exponentially distributed","If task start time is chosen from a uniform random distribution, is inter-arrival time exponentially distributed",,"Question: If the start time is generated from uniform random distribution, is the inter arrival time exponentially distributed? Context: We have a number of tasks to be run every day (and we have the flexibility to set the actual start time). To avoid overloading the system by running everything at a fixed time, and we want to spread the load through out the day. And everyday we want to run the task at the same time. To spread the load, we hash the taskid to generate the start time. (Almost equivalent to generating from uniform random distribution) The question is, since the arrival time is uniformly distributed and independent of each other, does the inter arrival time follow exponential distribution? I want to use queueing theory to model the system performance, since exponentially distributed inter arrival time is the most studied distribution, I want to see if I can use M/M/1 queuing model. I understand there are some differences. The start time generated is discrete, but the exponential distribution is continuous. I assume, I can increase the granularity of the time to approximate continuous time. Another option is to generate the start time as a Poisson process (At every t, decide whether to run or not with probability p. ) But at some point, we want to ensure the task runs every day, so we might have to force it to run at midnight eventually. So this might get a bit weird.","Question: If the start time is generated from uniform random distribution, is the inter arrival time exponentially distributed? Context: We have a number of tasks to be run every day (and we have the flexibility to set the actual start time). To avoid overloading the system by running everything at a fixed time, and we want to spread the load through out the day. And everyday we want to run the task at the same time. To spread the load, we hash the taskid to generate the start time. (Almost equivalent to generating from uniform random distribution) The question is, since the arrival time is uniformly distributed and independent of each other, does the inter arrival time follow exponential distribution? I want to use queueing theory to model the system performance, since exponentially distributed inter arrival time is the most studied distribution, I want to see if I can use M/M/1 queuing model. I understand there are some differences. The start time generated is discrete, but the exponential distribution is continuous. I assume, I can increase the granularity of the time to approximate continuous time. Another option is to generate the start time as a Poisson process (At every t, decide whether to run or not with probability p. ) But at some point, we want to ensure the task runs every day, so we might have to force it to run at midnight eventually. So this might get a bit weird.",,"['probability', 'statistics', 'probability-distributions', 'markov-chains', 'queueing-theory']"
40,"""Consistency"" vs. ""Convergence"" of Estimators : Are ALL ""MLE's"" ALWAYS Consistent?","""Consistency"" vs. ""Convergence"" of Estimators : Are ALL ""MLE's"" ALWAYS Consistent?",,"I have heard the terms ""Consistency"" vs. ""Convergence"" being used interchangeably - for example: In Machine Learning applications, I have heard the term ""Convergence"" describe a situation where successive differences in iterations becomes smaller than some threshold. For example, when we say that a ""Machine Learning Model converged"" - this means that the value of the Loss Function at ""iteration n"" versus the value at ""iteration n+1"" is almost identical. In Statistics and Probability, I have heard a similar concept being used to describe the properties of estimators. For example, we can say that that the Maximum Likelihood Estimator of the ""sample average"" is ""Consistent"" with the ""population average"" - this means that as the number of observations in our sample get larger and larger, the value of the ""sample average"" will become closer and closer to the ""population average"". (I suppose we could say that as the number of samples become larger and larger, the value of the ""sample average converges to the population average""). Regarding this, I had the following question: When we consider the Maximum Likelihood Estimator for any Probability Distribution Function (e.g. ""Mu-hat-MLE"" from a Normal Distribution, ""Lambda-hat-MLE"" from an Exponential Distribution, ""p-hat-MLE"" from a Binomial Distribution, etc.) - do we know if ALL Maximum Likelihood Estimators (in theory) are ALWAYS ""Consistent""? For example, suppose we have some never-before-seen Probability Distribution Function, yet we somehow manage to maximize the corresponding likelihood function and obtain a maximum likelihood estimate for its parameters (e.g. ""mu"", ""lambda"",etc.) - by virtue of the fact that we have the MLE, will this MLE automatically be Consistent? Or do we still have to prove that this MLE will be Consistent? Thank you!","I have heard the terms ""Consistency"" vs. ""Convergence"" being used interchangeably - for example: In Machine Learning applications, I have heard the term ""Convergence"" describe a situation where successive differences in iterations becomes smaller than some threshold. For example, when we say that a ""Machine Learning Model converged"" - this means that the value of the Loss Function at ""iteration n"" versus the value at ""iteration n+1"" is almost identical. In Statistics and Probability, I have heard a similar concept being used to describe the properties of estimators. For example, we can say that that the Maximum Likelihood Estimator of the ""sample average"" is ""Consistent"" with the ""population average"" - this means that as the number of observations in our sample get larger and larger, the value of the ""sample average"" will become closer and closer to the ""population average"". (I suppose we could say that as the number of samples become larger and larger, the value of the ""sample average converges to the population average""). Regarding this, I had the following question: When we consider the Maximum Likelihood Estimator for any Probability Distribution Function (e.g. ""Mu-hat-MLE"" from a Normal Distribution, ""Lambda-hat-MLE"" from an Exponential Distribution, ""p-hat-MLE"" from a Binomial Distribution, etc.) - do we know if ALL Maximum Likelihood Estimators (in theory) are ALWAYS ""Consistent""? For example, suppose we have some never-before-seen Probability Distribution Function, yet we somehow manage to maximize the corresponding likelihood function and obtain a maximum likelihood estimate for its parameters (e.g. ""mu"", ""lambda"",etc.) - by virtue of the fact that we have the MLE, will this MLE automatically be Consistent? Or do we still have to prove that this MLE will be Consistent? Thank you!",,"['probability', 'statistics', 'convergence-divergence', 'estimation', 'maximum-likelihood']"
41,What is the common $t$-test for $H_0: \mu = \mu_0 \ \text{ and } \ H_A:\mu > \mu_0$?,What is the common -test for ?,t H_0: \mu = \mu_0 \ \text{ and } \ H_A:\mu > \mu_0,"The following remark came up in my lecture: Let $X_1,X_2,\ldots,X_n$ be normally distributed with known variance $\sigma^2 > 0$ . For testing $$H_0: \mu = \mu_0 \ \text{ and } \ H_A:\mu > \mu_0.$$ we use the ""common level- $\alpha$ -test"". (If I am not mistaken my teachter meant the $t$ -test with this.) In the lecture we only did tests where the alternative hypothesis was the complement of the hypothesis, so I do not understand what the ""common level- $\alpha$ -test"" is supposed to be. Could you please explain this to me? To clearify: My problem here is that I do not understand how to formulate a test where $H_A$ is not complementary to $H_0$ .","The following remark came up in my lecture: Let be normally distributed with known variance . For testing we use the ""common level- -test"". (If I am not mistaken my teachter meant the -test with this.) In the lecture we only did tests where the alternative hypothesis was the complement of the hypothesis, so I do not understand what the ""common level- -test"" is supposed to be. Could you please explain this to me? To clearify: My problem here is that I do not understand how to formulate a test where is not complementary to .","X_1,X_2,\ldots,X_n \sigma^2 > 0 H_0: \mu = \mu_0 \ \text{ and } \ H_A:\mu > \mu_0. \alpha t \alpha H_A H_0","['statistics', 'hypothesis-testing']"
42,"Is it possible for a set of random variables to each be highly correlated with another variable, but not highly correlated with each other?","Is it possible for a set of random variables to each be highly correlated with another variable, but not highly correlated with each other?",,"Let $X_1, ..., X_n$ and $Y$ be random variables. Is it possible for the $X_i$ 's to all have a high magnitude of correlation against $Y$ (absolute value of Pearson's $r$ ), but not be strongly correlated with each other?","Let and be random variables. Is it possible for the 's to all have a high magnitude of correlation against (absolute value of Pearson's ), but not be strongly correlated with each other?","X_1, ..., X_n Y X_i Y r","['probability', 'statistics', 'random-variables', 'correlation']"
43,Implementing binary logistic regression from scratch,Implementing binary logistic regression from scratch,,"Background knowledge: To train a logistic regression model for a classification problem with two classes (called class $0$ and class $1$ ), we are given a training dataset consisting of feature vectors $x_1, x_2, \ldots, x_N \in \mathbb R^d$ and corresponding target values $y_1, y_2, \ldots, y_N \in \{0,1\}$ . Our goal is to find numbers $\beta_0, \beta_1, \ldots, \beta_d \in \mathbb R$ such that $$ \tag{1} y_i \approx \sigma(\beta_0 + \beta_1 x_{i1} + \cdots + \beta_d x_{id}) \quad \text{for } i = 1, \ldots, N. $$ Here $x_{i1}, \ldots, x_{id}$ are the components of the feature vector $x_i$ , and $\sigma:\mathbb R \to \mathbb R$ is the sigmoid function (also called ""logistic function"") defined by $$ \sigma(u) = \frac{e^u}{1 + e^u} \quad \text{for all } u \in \mathbb R. $$ The sigmoid function is useful in machine learning because it converts a real number into a probability (that is, a number between $0$ and $1$ ). Equation (1) can be expressed more concisely using vector notation: we hope that $$ y_i \approx \sigma(\hat x_i^T \beta) \quad \text{for } i = 1, \ldots N $$ where $$ \hat x_i = \begin{bmatrix} 1 \\ x_{i1} \\ \vdots \\ x_{id} \end{bmatrix} \quad \text{and} \quad \beta = \begin{bmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_d \end{bmatrix}. $$ (The vector $\hat x_i$ is called an ""augmented"" feature vector. It's the vector you get by prepending a $1$ to $x_i$ .) I think of $\sigma(\hat x_i^T \beta)$ as being a ""predicted probability"" which tells you how strongly our model believes that example $i$ belongs to class $1$ . And $y_i$ is a ""ground truth"" probability which reflects certainty about whether or not example $i$ belongs to class $1$ . We will use the binary cross-entropy loss function $$ \ell(p,q) = -p \log(q) - (1 - p) \log(1 - q) $$ to measure how well a predicted probability $q \in (0,1)$ agrees with a ground truth probability $p \in [0,1]$ . Here $\log$ denotes the natural logarithm. The vector $\beta$ will be chosen to minimize the average cross-entropy $$ \tag{2} L(\beta) = \frac{1}{N} \sum_{i=1}^N \ell(y_i, \sigma(\hat x_i^T \beta)). $$ We can minimize $L(\beta)$ using an optimization algorithm such as gradient descent, stochastic gradient descent, or Newton's method. In order to use such methods, we need to know how to compute the gradient of $L$ . For Newton's method, we also need to know how to compute the Hessian of $L$ . Question: How can we compute the gradient and the Hessian of the average cross-entropy function $L(\beta)$ defined in equation (2)? The goal is to compute the gradient and the Hessian of $L$ with finesse , making good use of vector notation. (I'll post an answer below.)","Background knowledge: To train a logistic regression model for a classification problem with two classes (called class and class ), we are given a training dataset consisting of feature vectors and corresponding target values . Our goal is to find numbers such that Here are the components of the feature vector , and is the sigmoid function (also called ""logistic function"") defined by The sigmoid function is useful in machine learning because it converts a real number into a probability (that is, a number between and ). Equation (1) can be expressed more concisely using vector notation: we hope that where (The vector is called an ""augmented"" feature vector. It's the vector you get by prepending a to .) I think of as being a ""predicted probability"" which tells you how strongly our model believes that example belongs to class . And is a ""ground truth"" probability which reflects certainty about whether or not example belongs to class . We will use the binary cross-entropy loss function to measure how well a predicted probability agrees with a ground truth probability . Here denotes the natural logarithm. The vector will be chosen to minimize the average cross-entropy We can minimize using an optimization algorithm such as gradient descent, stochastic gradient descent, or Newton's method. In order to use such methods, we need to know how to compute the gradient of . For Newton's method, we also need to know how to compute the Hessian of . Question: How can we compute the gradient and the Hessian of the average cross-entropy function defined in equation (2)? The goal is to compute the gradient and the Hessian of with finesse , making good use of vector notation. (I'll post an answer below.)","0 1 x_1, x_2, \ldots, x_N \in \mathbb R^d y_1, y_2, \ldots, y_N \in \{0,1\} \beta_0, \beta_1, \ldots, \beta_d \in \mathbb R 
\tag{1} y_i \approx \sigma(\beta_0 + \beta_1 x_{i1} + \cdots + \beta_d x_{id}) \quad \text{for } i = 1, \ldots, N.
 x_{i1}, \ldots, x_{id} x_i \sigma:\mathbb R \to \mathbb R 
\sigma(u) = \frac{e^u}{1 + e^u} \quad \text{for all } u \in \mathbb R.
 0 1 
y_i \approx \sigma(\hat x_i^T \beta) \quad \text{for } i = 1, \ldots N
 
\hat x_i = \begin{bmatrix} 1 \\ x_{i1} \\ \vdots \\ x_{id} \end{bmatrix} \quad \text{and} \quad \beta = \begin{bmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_d \end{bmatrix}.
 \hat x_i 1 x_i \sigma(\hat x_i^T \beta) i 1 y_i i 1 
\ell(p,q) = -p \log(q) - (1 - p) \log(1 - q)
 q \in (0,1) p \in [0,1] \log \beta 
\tag{2} L(\beta) = \frac{1}{N} \sum_{i=1}^N \ell(y_i, \sigma(\hat x_i^T \beta)).
 L(\beta) L L L(\beta) L","['statistics', 'multivariable-calculus', 'optimization', 'machine-learning', 'logistic-regression']"
44,Twin Births Casella Berger Probability Question,Twin Births Casella Berger Probability Question,,"I was reading through Casella and Berger's Statistical Inference when I came across the following problem: The probability of a twin birth is approximately 1 /90, and we can assume that an elementary school will have approximately 60 children entering kindergarten (three classes of 20 each) . Explain how our ""statistically impossible"" event can be thought of as the probability of 5 or more successes from a binomial(60, 1 /90). Is this even rare enough to be newsworthy? I'm struggling to understand how this is a binomial distribution. I looked up explanations for this online and got limited results. In my understanding, the probability of there being a pair of twins would be the probability of choosing two people to be twins, with the remaining $60-2 = 58$ people being twin-less. Basically, if $X$ is the random variable indicating how many sets of twins are in the incoming class, then $$P(X = x) = {60 \choose 2x} \Big(\frac{1}{90}\Big)^x \Big(\frac{89}{90}\Big)^{\frac{60-2x}{2}}$$ since we would choose $2x$ people to be twins, with each pair having $\frac{1}{90}$ people being twins, and then the rest of the remaining pairs ( $\frac{60 - 2x}{2}$ ) would have probability $\frac{89}{90}$ of not being twins. I found an explanation here that I don't understand: I think the book is correct ""in the first order""; you are double counting. Suppose there are n students in a classroom. We ask each student: ""do you have a twin sibling?"" If the the student answers ""no,"" he or she leaves the classroom. If the student answers ""yes,"" we ask the student to identify the sibling. Then both of them leave. If all students were to answer ""no,"" the combinatorial coefficient would be 0Cn. If only one student answered ""yes,"" then the combinatorial coefficient isn't 2Cn, it is 1C(n-1). If exactly k students answered yes, then the combinatorial coefficient isn't (2k)Cn, it is kC(n - k). I know something is wrong with my approach, but I don't understand how I would be ""double counting"" the number of twins. Thank you for any help.","I was reading through Casella and Berger's Statistical Inference when I came across the following problem: The probability of a twin birth is approximately 1 /90, and we can assume that an elementary school will have approximately 60 children entering kindergarten (three classes of 20 each) . Explain how our ""statistically impossible"" event can be thought of as the probability of 5 or more successes from a binomial(60, 1 /90). Is this even rare enough to be newsworthy? I'm struggling to understand how this is a binomial distribution. I looked up explanations for this online and got limited results. In my understanding, the probability of there being a pair of twins would be the probability of choosing two people to be twins, with the remaining people being twin-less. Basically, if is the random variable indicating how many sets of twins are in the incoming class, then since we would choose people to be twins, with each pair having people being twins, and then the rest of the remaining pairs ( ) would have probability of not being twins. I found an explanation here that I don't understand: I think the book is correct ""in the first order""; you are double counting. Suppose there are n students in a classroom. We ask each student: ""do you have a twin sibling?"" If the the student answers ""no,"" he or she leaves the classroom. If the student answers ""yes,"" we ask the student to identify the sibling. Then both of them leave. If all students were to answer ""no,"" the combinatorial coefficient would be 0Cn. If only one student answered ""yes,"" then the combinatorial coefficient isn't 2Cn, it is 1C(n-1). If exactly k students answered yes, then the combinatorial coefficient isn't (2k)Cn, it is kC(n - k). I know something is wrong with my approach, but I don't understand how I would be ""double counting"" the number of twins. Thank you for any help.",60-2 = 58 X P(X = x) = {60 \choose 2x} \Big(\frac{1}{90}\Big)^x \Big(\frac{89}{90}\Big)^{\frac{60-2x}{2}} 2x \frac{1}{90} \frac{60 - 2x}{2} \frac{89}{90},"['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'binomial-distribution']"
45,Subgaussianity of the Mixture of Gaussian Random Variables,Subgaussianity of the Mixture of Gaussian Random Variables,,"Is a mixture distribution of gaussian subgaussian? We know that if $X$ follows a normal distribution $\mathcal{N} (0, \sigma^2)$ , then it is automatically $\sigma$ -subgaussian by definition. Suppose we have a mixture of normal random variables $X_1, X_2$ . Then does the mixture of these two also have subgaussianity? Suppose the mixture has distribution $f_x(x)$ , then: $$f_X(x) = \alpha f_1(x) + (1-\alpha)f_2(x),$$ where $\alpha$ is the probability assigned to a component. Subgaussianity: Suppose random variable $X$ follows the inequality below: $$\mathbf{\mathbb{E}[e^{\lambda X}]\leq \exp(\lambda^2 \sigma^2)},$$ then we say that $X$ is $\boldsymbol{\sigma}$ -subgaussian.","Is a mixture distribution of gaussian subgaussian? We know that if follows a normal distribution , then it is automatically -subgaussian by definition. Suppose we have a mixture of normal random variables . Then does the mixture of these two also have subgaussianity? Suppose the mixture has distribution , then: where is the probability assigned to a component. Subgaussianity: Suppose random variable follows the inequality below: then we say that is -subgaussian.","X \mathcal{N} (0, \sigma^2) \sigma X_1, X_2 f_x(x) f_X(x) = \alpha f_1(x) + (1-\alpha)f_2(x), \alpha X \mathbf{\mathbb{E}[e^{\lambda X}]\leq \exp(\lambda^2 \sigma^2)}, X \boldsymbol{\sigma}","['probability', 'statistics', 'gaussian']"
46,Flip a Coin 100 times - Heads then Tails,Flip a Coin 100 times - Heads then Tails,,"If I flip a fair coin 100 times, and each time I get a heads immediately followed by tails, I win $5. How much am I expected to win during the game? I know that the probability of getting a head = probability of getting a tail = $\frac{1}{2}$ , so the probability of a heads then a tails = $\frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}$ . But this is the same probability as any combination of two flips (i.e. two heads, two tails, or tails then a heads). So how can I determine how many of the desired combination would be expected in 100 flips?","If I flip a fair coin 100 times, and each time I get a heads immediately followed by tails, I win $5. How much am I expected to win during the game? I know that the probability of getting a head = probability of getting a tail = , so the probability of a heads then a tails = . But this is the same probability as any combination of two flips (i.e. two heads, two tails, or tails then a heads). So how can I determine how many of the desired combination would be expected in 100 flips?",\frac{1}{2} \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4},['probability']
47,Why is the $L_2$ regularization squared while the $L_1$ is not?,Why is the  regularization squared while the  is not?,L_2 L_1,"Best example to demonstate my question is the elastic net, which has the Risk (here for linear regression). For some $D=\{(x_i,y_i)\}_{i=1}^n$ with $ x_i\in \mathbb{R}^d, y_i\in\mathbb{R}$ and some $ \lambda_1, \lambda_2 \geq 0$ . $$R(w) = \sum_{i=1}^n (w^Tx_i -y_i)^2  + \lambda_1 ||w||_1 + \lambda_2 ||w||_2^2$$ Why is the $L_2$ norm squared, just because of the derivative, or is there some reason behind this?","Best example to demonstate my question is the elastic net, which has the Risk (here for linear regression). For some with and some . Why is the norm squared, just because of the derivative, or is there some reason behind this?","D=\{(x_i,y_i)\}_{i=1}^n  x_i\in \mathbb{R}^d, y_i\in\mathbb{R}  \lambda_1, \lambda_2 \geq 0 R(w) = \sum_{i=1}^n (w^Tx_i -y_i)^2  + \lambda_1 ||w||_1 + \lambda_2 ||w||_2^2 L_2","['statistics', 'normed-spaces', 'regularization']"
48,How to show implication for equivalent equations?,How to show implication for equivalent equations?,,"What does it mean for one event 𝐶 to cause another event 𝐸 — for example, smoking (𝐶) to cause cancer (𝐸)? There is a long history in philosophy, statistics, and the sciences of trying to clearly analyze the concept of a cause. One tradition says that causes raise the probability of their effects; we may write this symbolically is 𝑃(𝐸|𝐶)>𝑃(𝐸).(1) Another way to formulate a probabilistic theory of causation is to say that 𝑃(𝐸|𝐶)>𝑃(𝐸|𝐶^𝐶).(2) I know that equation (1) implies that 𝑃(𝐶|𝐸)>𝑃(𝐶). Show that equation (1) implies equation (2)","What does it mean for one event 𝐶 to cause another event 𝐸 — for example, smoking (𝐶) to cause cancer (𝐸)? There is a long history in philosophy, statistics, and the sciences of trying to clearly analyze the concept of a cause. One tradition says that causes raise the probability of their effects; we may write this symbolically is 𝑃(𝐸|𝐶)>𝑃(𝐸).(1) Another way to formulate a probabilistic theory of causation is to say that 𝑃(𝐸|𝐶)>𝑃(𝐸|𝐶^𝐶).(2) I know that equation (1) implies that 𝑃(𝐶|𝐸)>𝑃(𝐶). Show that equation (1) implies equation (2)",,"['probability', 'statistics', 'conditional-probability']"
49,Finding a distribution with Bayesian statistics,Finding a distribution with Bayesian statistics,,"Suppose $X$ is a random variable that follows a binomial distribution with parameters $n = 5$ and $p$ where $0 \leq p \leq 1$ is unknown. Through a Bayesian approach, $p$ is modeled with a random variable $P$ . Some researchers have established that it is very likely that $p$ is close to $1$ and not likely that $p$ is close to $0$ . (i) Which of the following densities is the best choice of prior for $P$ : $f(p) = 1, 0 \leq p \leq 1$ , $g(p) = 2p, 0 \leq p \leq 1$ , or $h(p) = e^{-p}, p \geq 0$ . Justify. (ii) Let $f_P(p)$ be the prior you chose in (i) and you observe that $X = 5$ . Given this observation, find the posterior density $P$ . (iii) Between the prior and posterior densities of $P$ in (ii), which has more density near $1$ ? Explain why the density you identify should have more density near $1$ ? My attempt: (i) I am not quite sure which prior is the best. I eliminated the third one $h(p)$ due to the support being too large. Then, the first one $f(p)$ seems to assume that it is always $1$ , which doesn't seem consistent. The third one also seems most likely as it only multiplies the values by $2$ which corresponds to the fact that the researchers already established that $p$ is close to $1$ . I also recall that usually, the prior and posterior of a binomial tend to be beta. The general beta distribution support is $0$ to $1$ which eliminates $h(p)$ . (ii) The chosen prior is $f_P(p) = 2p, 0 \leq p \leq 1$ The pdf of $X$ is: $$f(x\mid p) = \frac{5!}{x!(5-x)!} p^x (1-p)^{5-x},$$ $x = 0, 1, 2, 3, 4, 5$ . The posterior is then: $$f(p\mid x) = \frac{f(x\mid p)\cdot f_P(p)}{f_X(x)} = \frac{f(x\mid p)\cdot f_P(p)}{f_X(x)} = \frac{f(x\mid p)\cdot f_P(p)}{\int_{-\infty}^\infty f(x\mid p) \cdot f_P(p) \,dp}$$ We apply proportionality: $$\frac{f(x\mid p)\cdot f_P(p)}{\int_{-\infty}^\infty f(x\mid p) \cdot f_P(p) \,dp} \propto f(x\mid p)\cdot f_P(p) = f(x\mid p) = \frac{5!}{x!(5-x)!} p^x (1-p)^{5-x} \cdot 2p = \frac{2\cdot 5!}{x!(5-x)!} p^{x + 1} (1-p)^{5-x}$$ As I stated before, the posterior of a binomial is often beta, and both the appearance of the pdf and support seem to agree with this. So I conclude that the posterior distribution is Beta with parameters $\alpha$ as $x + 2$ and $\beta$ as $6 - x$ . The posterior pdf: $f(p\mid x) = \frac{\Gamma (8)}{\Gamma (x + 2) \Gamma (6 - x)} p^{x + 1} (1 - p)^{5 - x}$ , $0 < p < 1$ . Letting $X = 5$ , $f(p\mid 5) = \frac{\Gamma (8)}{\Gamma (7) \Gamma (1)} p^{6} (1 - p)^{0} = \frac{\Gamma (8)}{\Gamma (7) \Gamma (1)} p^{6}$ (iii) Not sure about this one. Any assistance is much appreciated. Also, if anyone can provide a better explanation for (i), that would be great.","Suppose is a random variable that follows a binomial distribution with parameters and where is unknown. Through a Bayesian approach, is modeled with a random variable . Some researchers have established that it is very likely that is close to and not likely that is close to . (i) Which of the following densities is the best choice of prior for : , , or . Justify. (ii) Let be the prior you chose in (i) and you observe that . Given this observation, find the posterior density . (iii) Between the prior and posterior densities of in (ii), which has more density near ? Explain why the density you identify should have more density near ? My attempt: (i) I am not quite sure which prior is the best. I eliminated the third one due to the support being too large. Then, the first one seems to assume that it is always , which doesn't seem consistent. The third one also seems most likely as it only multiplies the values by which corresponds to the fact that the researchers already established that is close to . I also recall that usually, the prior and posterior of a binomial tend to be beta. The general beta distribution support is to which eliminates . (ii) The chosen prior is The pdf of is: . The posterior is then: We apply proportionality: As I stated before, the posterior of a binomial is often beta, and both the appearance of the pdf and support seem to agree with this. So I conclude that the posterior distribution is Beta with parameters as and as . The posterior pdf: , . Letting , (iii) Not sure about this one. Any assistance is much appreciated. Also, if anyone can provide a better explanation for (i), that would be great.","X n = 5 p 0 \leq p \leq 1 p P p 1 p 0 P f(p) = 1, 0 \leq p \leq 1 g(p) = 2p, 0 \leq p \leq 1 h(p) = e^{-p}, p \geq 0 f_P(p) X = 5 P P 1 1 h(p) f(p) 1 2 p 1 0 1 h(p) f_P(p) = 2p, 0 \leq p \leq 1 X f(x\mid p) = \frac{5!}{x!(5-x)!} p^x (1-p)^{5-x}, x = 0, 1, 2, 3, 4, 5 f(p\mid x) = \frac{f(x\mid p)\cdot f_P(p)}{f_X(x)} = \frac{f(x\mid p)\cdot f_P(p)}{f_X(x)} = \frac{f(x\mid p)\cdot f_P(p)}{\int_{-\infty}^\infty f(x\mid p) \cdot f_P(p) \,dp} \frac{f(x\mid p)\cdot f_P(p)}{\int_{-\infty}^\infty f(x\mid p) \cdot f_P(p) \,dp} \propto f(x\mid p)\cdot f_P(p) = f(x\mid p) = \frac{5!}{x!(5-x)!} p^x (1-p)^{5-x} \cdot 2p = \frac{2\cdot 5!}{x!(5-x)!} p^{x + 1} (1-p)^{5-x} \alpha x + 2 \beta 6 - x f(p\mid x) = \frac{\Gamma (8)}{\Gamma (x + 2) \Gamma (6 - x)} p^{x + 1} (1 - p)^{5 - x} 0 < p < 1 X = 5 f(p\mid 5) = \frac{\Gamma (8)}{\Gamma (7) \Gamma (1)} p^{6} (1 - p)^{0} = \frac{\Gamma (8)}{\Gamma (7) \Gamma (1)} p^{6}","['statistics', 'probability-distributions', 'solution-verification', 'bayesian', 'parameter-estimation']"
50,What is the probability the sample mean is more than 10 words?,What is the probability the sample mean is more than 10 words?,,"The distribution of the number of words in text messages between employees at a large company is skewed right with a mean of $8.6$ words and a standard deviation of $4.3$ words. If a random sample of $39$ messages is selected, what is the probability the sample mean is more than $10$ words? Firstly, I used the z-score formula, substituting $8.6$ as the population mean, $10$ as the observed value, and $4.3$ as the standard deviation. The equation is set up as the following: $(10-8.6)/4.3$ . Secondly, the equation calculates to approx. $0.3255$ and its probability, using a z-table, is approx. $0.6276$ . I subtracted this value from $1$ because the prompt asks to find the probability of ""more than 10 words"" not less than. The final value then is approx. $0.3724$ . My answer is $0.3724$ as the probability of the sample mean being more than $10$ words. However, I believe there is an extra step using the sample size. If this is correct, how do I use the sample size to find the correct answer? Do I, instead of substituting $4.3$ as the standard deviation in the z-score formula, substitute $4.3\sqrt39$ , which, after going through the listed steps, have the probability as approx. $0.0210$ ?","The distribution of the number of words in text messages between employees at a large company is skewed right with a mean of words and a standard deviation of words. If a random sample of messages is selected, what is the probability the sample mean is more than words? Firstly, I used the z-score formula, substituting as the population mean, as the observed value, and as the standard deviation. The equation is set up as the following: . Secondly, the equation calculates to approx. and its probability, using a z-table, is approx. . I subtracted this value from because the prompt asks to find the probability of ""more than 10 words"" not less than. The final value then is approx. . My answer is as the probability of the sample mean being more than words. However, I believe there is an extra step using the sample size. If this is correct, how do I use the sample size to find the correct answer? Do I, instead of substituting as the standard deviation in the z-score formula, substitute , which, after going through the listed steps, have the probability as approx. ?",8.6 4.3 39 10 8.6 10 4.3 (10-8.6)/4.3 0.3255 0.6276 1 0.3724 0.3724 10 4.3 4.3\sqrt39 0.0210,"['probability', 'statistics', 'probability-distributions']"
51,How to calculate confidence interval (normal distribution)?,How to calculate confidence interval (normal distribution)?,,"There seems to be two formulas for calculating confidence interval of a sample with a normal distribution (in both cases, $P$ refers to the sample proportion): Method A: $$P \pm \frac{1}{\sqrt n}$$ where $n$ is the population sample size Method B: $$P \pm z \cdot \sqrt{\frac{P (1-P)} n}$$ where $n$ is the population sample size and $z$ is the $z$ -score radius for the intended confidence level (for example $1.96$ for $95\%$ ) Which method should I use or when should I use each method? What is the difference between the confidence level of the two formulae?","There seems to be two formulas for calculating confidence interval of a sample with a normal distribution (in both cases, refers to the sample proportion): Method A: where is the population sample size Method B: where is the population sample size and is the -score radius for the intended confidence level (for example for ) Which method should I use or when should I use each method? What is the difference between the confidence level of the two formulae?",P P \pm \frac{1}{\sqrt n} n P \pm z \cdot \sqrt{\frac{P (1-P)} n} n z z 1.96 95\%,"['statistics', 'normal-distribution', 'statistical-inference']"
52,P-value changes based on removed variable?,P-value changes based on removed variable?,,"Problem Setting: Assuming that we have $p$ variables $x_1, x_2, ..., x_p$ and a response vector $y$ with length $n$ , and the p-value is associated with the F-test with the null hypothesis $H_0: \beta_j = 0$ , I am wondering whether we can simulate these cases: (1). the $j$ th variable has a p-value < 0.05 in the linear model with $y$ and all $p$ variables, but its p-value increases above 0.05 if we remove the $k$ th variable from the model; (2). the $j$ th variable has a p-value > 0.05 in the linear model with $y$ and all $p$ variables, but its p-value decreases below 0.05 if we remove the $k$ th variable from the model. I think the second case the is multicollinearity problem, so under (2). we can simulate a multicollinearity dataset, and we expect remove one of the multicolinear column can achieve desired property in (2). However, I can not figure out the first case that what kinds of problem related with it.","Problem Setting: Assuming that we have variables and a response vector with length , and the p-value is associated with the F-test with the null hypothesis , I am wondering whether we can simulate these cases: (1). the th variable has a p-value < 0.05 in the linear model with and all variables, but its p-value increases above 0.05 if we remove the th variable from the model; (2). the th variable has a p-value > 0.05 in the linear model with and all variables, but its p-value decreases below 0.05 if we remove the th variable from the model. I think the second case the is multicollinearity problem, so under (2). we can simulate a multicollinearity dataset, and we expect remove one of the multicolinear column can achieve desired property in (2). However, I can not figure out the first case that what kinds of problem related with it.","p x_1, x_2, ..., x_p y n H_0: \beta_j = 0 j y p k j y p k","['statistics', 'hypothesis-testing', 'linear-regression', 'simulation']"
53,Confidence interval and moment,Confidence interval and moment,,"Suppose a random sample of size $n = 9$ is taken, where $X$ is normally distributed with unknown mean $\mu$ and unknown variance $\sigma^2$ . Consider the following cases (a) Before the sample is taken, it is noted that the endpoints of a two-sided $90$ % confidence interval are random variables derived from the sample mean $\bar{X}$ and sample standard deviation $S$ . If $L$ is the length of the interval, find the second moment of $L$ in terms of the variance $\sigma^2$ . (b) The sample is taken and we find that $\bar{x} = 1.56$ and $s^2 = 0.68$ . Determine the approximate one-sided confidence interval for $\mu$ . My attempt: (a) The population variance is unknown. So we find the t value. Using the tables or an online tool with $\alpha = 0.1 \implies \frac{\alpha}{2} = 0.05$ and $8$ degrees of freedom gives $t_{0.05} = 1.8595480$ . (If I am not wrong then) Length = $2 \cdot t_{0.05} \cdot \frac{s}{\sqrt{n}} = 2 \cdot 1.8595480 \cdot \frac{s}{\sqrt{9}} \approx 1.2397s$ . The second moment is given by $E(L^2) = E((1.2397s)^2) = 1.5369E(s^2)$ From this point I am not sure how to write this in terms of $\sigma^2$ . I read of a similar problem that used unbiased estimators but I cannot see what conditions $E(ks^2)$ (where $k$ is a constant) needs to be considered an unbiased estimator of $\sigma^2$ . (b) We have an unknown mean and variance so we use $t$ rather than $z$ . Note that $\alpha = 0.1$ and there are $8$ degrees of freedom. The lower bound, $m$ , is given by $m = \bar{x} - t_{0.1} \cdot \frac{s}{\sqrt{n}}$ . With the tables or the use of an online tool, we get that $t_{0.1} \approx 1.3968153$ . Hence $m = 1.56 - 1.3968153 \cdot \sqrt{\frac{0.68}{9}} = 1.176052$ . Is this correct thus far? Any assistance you could provide with (a) is appreciated.","Suppose a random sample of size is taken, where is normally distributed with unknown mean and unknown variance . Consider the following cases (a) Before the sample is taken, it is noted that the endpoints of a two-sided % confidence interval are random variables derived from the sample mean and sample standard deviation . If is the length of the interval, find the second moment of in terms of the variance . (b) The sample is taken and we find that and . Determine the approximate one-sided confidence interval for . My attempt: (a) The population variance is unknown. So we find the t value. Using the tables or an online tool with and degrees of freedom gives . (If I am not wrong then) Length = . The second moment is given by From this point I am not sure how to write this in terms of . I read of a similar problem that used unbiased estimators but I cannot see what conditions (where is a constant) needs to be considered an unbiased estimator of . (b) We have an unknown mean and variance so we use rather than . Note that and there are degrees of freedom. The lower bound, , is given by . With the tables or the use of an online tool, we get that . Hence . Is this correct thus far? Any assistance you could provide with (a) is appreciated.",n = 9 X \mu \sigma^2 90 \bar{X} S L L \sigma^2 \bar{x} = 1.56 s^2 = 0.68 \mu \alpha = 0.1 \implies \frac{\alpha}{2} = 0.05 8 t_{0.05} = 1.8595480 2 \cdot t_{0.05} \cdot \frac{s}{\sqrt{n}} = 2 \cdot 1.8595480 \cdot \frac{s}{\sqrt{9}} \approx 1.2397s E(L^2) = E((1.2397s)^2) = 1.5369E(s^2) \sigma^2 E(ks^2) k \sigma^2 t z \alpha = 0.1 8 m m = \bar{x} - t_{0.1} \cdot \frac{s}{\sqrt{n}} t_{0.1} \approx 1.3968153 m = 1.56 - 1.3968153 \cdot \sqrt{\frac{0.68}{9}} = 1.176052,"['statistics', 'solution-verification']"
54,If $P(Y=y\mid X=x)=\chi_{\{c(x)=y\}}$ why is $E[Y\mid X]=Y$,If  why is,P(Y=y\mid X=x)=\chi_{\{c(x)=y\}} E[Y\mid X]=Y,"Let $X$ be a random variable on $\mathcal{X}$ while $Y$ is a random variable on $\mathcal{Y}$ . Further $c$ is a map: $c:\mathcal{X}\to \mathcal{Y}$ If $P(Y=y\mid X=x)=\chi_{\{c(x)=y\}} \; \; (*)$ where $\chi$ is the characteristic/indicator function, why is $E[Y\lvert X]=Y$ ? My idea: For any $x\in \mathcal{X}$ , we have on the event $\{X=x\}$ that $Y=c(x)\; \; (**)$ For me it seems clear that then $c(X)=Y$ , and if I were to be able to assume that $c$ is measurable I could simply state: $E[Y\mid X]=E[c(X)\mid X]=c(X)=Y$ . Is there more rigourous reasoning why $(**)$ would imply that $c(X)=Y$ ?","Let be a random variable on while is a random variable on . Further is a map: If where is the characteristic/indicator function, why is ? My idea: For any , we have on the event that For me it seems clear that then , and if I were to be able to assume that is measurable I could simply state: . Is there more rigourous reasoning why would imply that ?",X \mathcal{X} Y \mathcal{Y} c c:\mathcal{X}\to \mathcal{Y} P(Y=y\mid X=x)=\chi_{\{c(x)=y\}} \; \; (*) \chi E[Y\lvert X]=Y x\in \mathcal{X} \{X=x\} Y=c(x)\; \; (**) c(X)=Y c E[Y\mid X]=E[c(X)\mid X]=c(X)=Y (**) c(X)=Y,"['probability', 'statistics', 'expected-value', 'conditional-expectation']"
55,Ask the detail of Neyman-Pearson Lemma (Necessity Part),Ask the detail of Neyman-Pearson Lemma (Necessity Part),,"This is Theorem 8.3.12 (Neyman-Pearson Lemma) in George Casella stat inference. Consider testing $H_0: \theta=\theta_0$ versus $H_1: \theta=\theta_1$ , where the pdf pr pmf corresponding to $\theta_i$ is $f(\textbf{x}|\theta_i),i=0,1.$ , using a test with rejection region R that satisfies (8.3.1) \begin{align} \begin{matrix} x\in R & \text{if}& f(\textbf{x}|\theta_1)>kf(\textbf{x}|\theta_0)\\ x\in R^c & \text{if} & f(\textbf{x}|\theta_1)<kf(\textbf{x}|\theta_0) \end{matrix}\tag{8.3.1}\label{8.3.1} \end{align} for some $k \geq 0$ , and \begin{align} \alpha=P_{\theta_0}(\textbf{x}\in R)\tag{8.3.2}\label{8.3.2} \end{align} Then (Sufficiency): Any test that satisfies the above is a UMP level $\alpha$ test. (Necessity): If there exists a test satisfying (8.3.1) and (8.3.2) with k >0, then every UMP level $\alpha$ test is a size $\alpha$ test (satisfies (8.3.2)) and every UMP level $\alpha$ test satisfies (8.3.1) except perhaps on a set A satisfying $P_{\theta_0}(\textbf{x}\in A)=P_{\theta_1}(\textbf{x}\in A)=0.$ I feel difficulty to understand this Necessity. In the proof, it is clear that any test satisfying (8.3.2) is a  size $\alpha$ test. So I don't know why in the Necessity part, we say it again: If there exists a test satisfying (8.3.1) and (8.3.2) with k >0, then every UMP level $\alpha$ test is a size $\alpha$ test (satisfies (8.3.2)) . And the expressions are different. It says we need to satisfy (8.3.1) and (8.3.2). But don't the truth be we only need to satisfy (8.3.2)?","This is Theorem 8.3.12 (Neyman-Pearson Lemma) in George Casella stat inference. Consider testing versus , where the pdf pr pmf corresponding to is , using a test with rejection region R that satisfies (8.3.1) for some , and Then (Sufficiency): Any test that satisfies the above is a UMP level test. (Necessity): If there exists a test satisfying (8.3.1) and (8.3.2) with k >0, then every UMP level test is a size test (satisfies (8.3.2)) and every UMP level test satisfies (8.3.1) except perhaps on a set A satisfying I feel difficulty to understand this Necessity. In the proof, it is clear that any test satisfying (8.3.2) is a  size test. So I don't know why in the Necessity part, we say it again: If there exists a test satisfying (8.3.1) and (8.3.2) with k >0, then every UMP level test is a size test (satisfies (8.3.2)) . And the expressions are different. It says we need to satisfy (8.3.1) and (8.3.2). But don't the truth be we only need to satisfy (8.3.2)?","H_0: \theta=\theta_0 H_1: \theta=\theta_1 \theta_i f(\textbf{x}|\theta_i),i=0,1. \begin{align}
\begin{matrix}
x\in R & \text{if}& f(\textbf{x}|\theta_1)>kf(\textbf{x}|\theta_0)\\
x\in R^c & \text{if} & f(\textbf{x}|\theta_1)<kf(\textbf{x}|\theta_0)
\end{matrix}\tag{8.3.1}\label{8.3.1}
\end{align} k \geq 0 \begin{align}
\alpha=P_{\theta_0}(\textbf{x}\in R)\tag{8.3.2}\label{8.3.2}
\end{align} \alpha \alpha \alpha \alpha P_{\theta_0}(\textbf{x}\in A)=P_{\theta_1}(\textbf{x}\in A)=0. \alpha \alpha \alpha","['probability', 'statistics', 'statistical-inference']"
56,What is the new pdf after making the transformation?,What is the new pdf after making the transformation?,,"My question is from George Casella statistical inference textbook Question 8.9 (b). I know how to do this question and I worked out. But I don't agree with the solution. In the question, it said ""make the transformation $X_i = 1/Y_i$ . Then I just replace $Y_i$ with $1/X_i$ in the original pdf $\lambda_i e^{-\lambda_i y_i}$ . So my new pdf is just $\lambda_i e^{-\lambda_i/x_i}$ . However, the solution said the new pdf is $(\lambda_i/x_i^2) e^{-\lambda_i/x_i}$ . Does the solution have the typo? I used my pdf and I can solve out the problem.","My question is from George Casella statistical inference textbook Question 8.9 (b). I know how to do this question and I worked out. But I don't agree with the solution. In the question, it said ""make the transformation . Then I just replace with in the original pdf . So my new pdf is just . However, the solution said the new pdf is . Does the solution have the typo? I used my pdf and I can solve out the problem.",X_i = 1/Y_i Y_i 1/X_i \lambda_i e^{-\lambda_i y_i} \lambda_i e^{-\lambda_i/x_i} (\lambda_i/x_i^2) e^{-\lambda_i/x_i},"['probability', 'statistics', 'statistical-inference']"
57,Statistics question in cosmology,Statistics question in cosmology,,"The following are the approximate parameters for the Benchmark model in cosmology: $H_0 = 73.8 km s^{-1} Mpc^{-1})$ , $\Omega_{m,0} = 0.266$ , and $\Omega_{\Lambda,0} = 0.734$ . Given that we know $H_0$ very precisely to this value in a flat universe (meaning neglecting the negligible contribution from radiation, $\Omega_{m,0} + \Omega_{\Lambda,0} = 1$ ) with $\Omega_{\Lambda,0}$ being an unknown value very close to the given number, if we want to make a measurement of $\Omega_{\Lambda,0}$ with an accuracy of 5%, what is the maximum percent error we can tolerate on our measurement of luminosity distance at z = 0.5, 1.0, and 1.5? Extra note: luminosity distance can be approximated as $$d_L \approx \frac{c}{H_0} z (1 + \frac{1 - q_0}{2} z)$$ Where $$q_0 = \frac{1}{2} \Omega_{m,0} - \Omega_{\Lambda,0}$$ Due to covid, I've been unable to take the statistical physics course that was part of my plan, so it has been since the mid 2000's since I've had a stats course. There are a bunch of follow-up questions, but I'm hoping once I grasp the approach to this one I will be able to do them myself.","The following are the approximate parameters for the Benchmark model in cosmology: , , and . Given that we know very precisely to this value in a flat universe (meaning neglecting the negligible contribution from radiation, ) with being an unknown value very close to the given number, if we want to make a measurement of with an accuracy of 5%, what is the maximum percent error we can tolerate on our measurement of luminosity distance at z = 0.5, 1.0, and 1.5? Extra note: luminosity distance can be approximated as Where Due to covid, I've been unable to take the statistical physics course that was part of my plan, so it has been since the mid 2000's since I've had a stats course. There are a bunch of follow-up questions, but I'm hoping once I grasp the approach to this one I will be able to do them myself.","H_0 = 73.8 km s^{-1} Mpc^{-1}) \Omega_{m,0} = 0.266 \Omega_{\Lambda,0} = 0.734 H_0 \Omega_{m,0} + \Omega_{\Lambda,0} = 1 \Omega_{\Lambda,0} \Omega_{\Lambda,0} d_L \approx \frac{c}{H_0} z (1 + \frac{1 - q_0}{2} z) q_0 = \frac{1}{2} \Omega_{m,0} - \Omega_{\Lambda,0}",['statistics']
58,How to Calculate a Weighted GPA,How to Calculate a Weighted GPA,,How would I be able to calculate my overall average grade (or grade point average) for these courses? Course Course Credit (weight) Course Grade Biology 101 45 86 Psychology 210 30 74 Chemistry 250 45 88 English 200 60 77 My understanding is by simply adding the course grades column together and dividing by the total cumulative possible marks. (86+74+88+77)/400 = 0.8125 But this number seems very strange in the 0 to 4 GPA.,How would I be able to calculate my overall average grade (or grade point average) for these courses? Course Course Credit (weight) Course Grade Biology 101 45 86 Psychology 210 30 74 Chemistry 250 45 88 English 200 60 77 My understanding is by simply adding the course grades column together and dividing by the total cumulative possible marks. (86+74+88+77)/400 = 0.8125 But this number seems very strange in the 0 to 4 GPA.,,['statistics']
59,Draw 3 card simultaneously from a standard deck without replacement.,Draw 3 card simultaneously from a standard deck without replacement.,,"I have this the following question with 4 parts, but I don't know how the numbers are calculated for parts 1,3,4. Can anyone help me. We simulteneously draw three cards: A-) Probability of observing exactly 2 diffrent shapes: ANSWER: 0.551-->HOW B-) Probability of Observing at least one king and one queen. --> I know how to do this part. C-) Probability of observing 2 jacks and diamond as the third card. -->ANSWER: 0.0034 -->HOW D-)Probability of observing 3 different face value. --> ANSWER: 0.83  --> NO IDEA HOW For part A, I remember there was a method with combinations but I don't remember the method. Does anyone know how? I tried 39/51 but it is not correct. I thought 1st could be anything 2nd should be one of the remaining 39 cards from shapes that are not the same as the shape of first. For C I did: (4x3x12)/(52x51x50) + (3x2x13)/(52x51x50) --> 2 jacks including  diamond + 2 jack no diamond But the answer is 4 times the number I found. Where does *4 coming from.","I have this the following question with 4 parts, but I don't know how the numbers are calculated for parts 1,3,4. Can anyone help me. We simulteneously draw three cards: A-) Probability of observing exactly 2 diffrent shapes: ANSWER: 0.551-->HOW B-) Probability of Observing at least one king and one queen. --> I know how to do this part. C-) Probability of observing 2 jacks and diamond as the third card. -->ANSWER: 0.0034 -->HOW D-)Probability of observing 3 different face value. --> ANSWER: 0.83  --> NO IDEA HOW For part A, I remember there was a method with combinations but I don't remember the method. Does anyone know how? I tried 39/51 but it is not correct. I thought 1st could be anything 2nd should be one of the remaining 39 cards from shapes that are not the same as the shape of first. For C I did: (4x3x12)/(52x51x50) + (3x2x13)/(52x51x50) --> 2 jacks including  diamond + 2 jack no diamond But the answer is 4 times the number I found. Where does *4 coming from.",,"['probability', 'statistics', 'card-games']"
60,"Closed-form formula for $E_{x}[\max(u^\top x,0)\max(v^\top x ,0)]$ where $u,v$ are fixed vectors in $\mathbb R^d$ and $x$ is uniform on the sphere",Closed-form formula for  where  are fixed vectors in  and  is uniform on the sphere,"E_{x}[\max(u^\top x,0)\max(v^\top x ,0)] u,v \mathbb R^d x","Let $x$ be uniformly distributed on the unit-sphere in $\mathbb R^d$ and let $u,v$ be fixed nonparallel vectors in $\mathbb R^d$ Question. Is there a closed-form formula for $f(u,v) := \mathbb E_{x}[\max(u^\top x,0)\max(v^\top x ,0)]$ ? Due to rotationational symmetry of the distribution of $x$ , my guess is that $f(u,v)$ admits a simple expression in terms of the angle between $u$ and $v$ .","Let be uniformly distributed on the unit-sphere in and let be fixed nonparallel vectors in Question. Is there a closed-form formula for ? Due to rotationational symmetry of the distribution of , my guess is that admits a simple expression in terms of the angle between and .","x \mathbb R^d u,v \mathbb R^d f(u,v) := \mathbb E_{x}[\max(u^\top x,0)\max(v^\top x ,0)] x f(u,v) u v","['probability', 'statistics', 'geometric-probability']"
61,How to find estimator for $\lambda$ for $X\sim \operatorname{Poisson}(\lambda)$ using the 2nd method of moment?,How to find estimator for  for  using the 2nd method of moment?,\lambda X\sim \operatorname{Poisson}(\lambda),"So an estimator for for $\lambda$ using the first method of moment is simply the sample mean: $$\mu_1 = E(X) = \lambda = \bar{X} = \hat{\mu_2}$$ For the second moment, $$\operatorname{Var}(X) = E(X^2) - E(X)^2$$ $$\lambda = E(X^2) - \lambda^2$$ $$\mu_2 = E(X^2) = \lambda + \lambda^2$$ $$s^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2$$ $$s^2 = \frac{1}{n}\sum_{i=1}^n X_i^2 - \bar{X}^2$$ $$\frac{1}{n}\sum_{i=1}^n X_i^2 = s^2 + \bar{X}^2$$ $$\hat{\mu_2} = s^2 + \bar{X}^2$$ Making $\mu_2 = \hat{\mu_2}$ , we get: $$\mu_2 = \lambda + \lambda^2 = s^2 + \bar{X}^2 = \hat{\mu_2}$$ $$ \lambda + \lambda^2 = s^2 + \bar{X}^2$$ From here I've no idea how to factorise it so I have $\lambda$ all on one side.","So an estimator for for using the first method of moment is simply the sample mean: For the second moment, Making , we get: From here I've no idea how to factorise it so I have all on one side.",\lambda \mu_1 = E(X) = \lambda = \bar{X} = \hat{\mu_2} \operatorname{Var}(X) = E(X^2) - E(X)^2 \lambda = E(X^2) - \lambda^2 \mu_2 = E(X^2) = \lambda + \lambda^2 s^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2 s^2 = \frac{1}{n}\sum_{i=1}^n X_i^2 - \bar{X}^2 \frac{1}{n}\sum_{i=1}^n X_i^2 = s^2 + \bar{X}^2 \hat{\mu_2} = s^2 + \bar{X}^2 \mu_2 = \hat{\mu_2} \mu_2 = \lambda + \lambda^2 = s^2 + \bar{X}^2 = \hat{\mu_2}  \lambda + \lambda^2 = s^2 + \bar{X}^2 \lambda,"['statistics', 'statistical-inference', 'poisson-distribution', 'parameter-estimation']"
62,Random graph properties: understanding role of expectation,Random graph properties: understanding role of expectation,,"It is often in the random graph theory proofs that we are looking at the expectation. But why? Why is it not the probability that we studying. To clarify my question, look at the following example. Assume we are working in the $G(n,p)$ model. What is the probability that we have an induced cycle with t edges in $G(n,p)$ ? My approach would be. Fix $t$ vertices. The probability of having induced cycle on these $t$ vertices is $p^t(1-p)^{\binom{n}{2}-t}$ . Now consider all possible $\binom{n}{t}$ subsets of $t$ vertices. Probability of having an induced cycle in a graph is equal to probability that at least one of these $t$ -subsets of vertices has an induced cycle, which is the sum of the probabilities over all $t$ -sets to have an induced cycle which is: $$\text{Probability of having an induced cycle in G(n,p)}= \binom{n}{t} p^t(1-p)^{\binom{n}{2}-t}$$ Suppose, I choose $N=N(p)$ such that this quantity is $<1$ . Then MY QUESTION IS: can I conclude that there exists a graph on $N$ vertices having no induced cycle, because the probability above is <1? Why do people even consider expectation? I know that it is possible to define indicator random variables for each $t$ -set and then calculate the expected number of induced cycles. Provided that this expected number is $<1$ , we can say that there will be a graph on $N$ vertices with no induced cycle. TL;DR Why just considering a probability alone would not be enough? Why do we even need expectation? Many thanks!","It is often in the random graph theory proofs that we are looking at the expectation. But why? Why is it not the probability that we studying. To clarify my question, look at the following example. Assume we are working in the model. What is the probability that we have an induced cycle with t edges in ? My approach would be. Fix vertices. The probability of having induced cycle on these vertices is . Now consider all possible subsets of vertices. Probability of having an induced cycle in a graph is equal to probability that at least one of these -subsets of vertices has an induced cycle, which is the sum of the probabilities over all -sets to have an induced cycle which is: Suppose, I choose such that this quantity is . Then MY QUESTION IS: can I conclude that there exists a graph on vertices having no induced cycle, because the probability above is <1? Why do people even consider expectation? I know that it is possible to define indicator random variables for each -set and then calculate the expected number of induced cycles. Provided that this expected number is , we can say that there will be a graph on vertices with no induced cycle. TL;DR Why just considering a probability alone would not be enough? Why do we even need expectation? Many thanks!","G(n,p) G(n,p) t t p^t(1-p)^{\binom{n}{2}-t} \binom{n}{t} t t t \text{Probability of having an induced cycle in G(n,p)}= \binom{n}{t} p^t(1-p)^{\binom{n}{2}-t} N=N(p) <1 N t <1 N","['probability', 'statistics', 'graph-theory', 'expected-value', 'random-graphs']"
63,What types of integrals are these?,What types of integrals are these?,,"What kind of integral is this? It pops up in Pattern Recognition and Machine Learning, Chapter 1.2, when the author is talking about multivariate probability densities. $$ \int p(\vec{x}) d\vec{x} = 1$$ The author states ""the integral is taken over the whole of $\vec{x}$ space."" I've heard of line integrals of vector fields and surface integrals of vector fields, are there other types of weird integrals that pop up where you are taking the integral with respect to a vector or matrix for example? Another integral (1.45) pops up again in Chapter 1.2 when the author is talking about Bayes theorem, the posterior, likelihood and prior. $$p(D) = \int p(D|\vec{w})p(\vec{w}) d\vec{w} $$ Is this different to the previous integral?","What kind of integral is this? It pops up in Pattern Recognition and Machine Learning, Chapter 1.2, when the author is talking about multivariate probability densities. The author states ""the integral is taken over the whole of space."" I've heard of line integrals of vector fields and surface integrals of vector fields, are there other types of weird integrals that pop up where you are taking the integral with respect to a vector or matrix for example? Another integral (1.45) pops up again in Chapter 1.2 when the author is talking about Bayes theorem, the posterior, likelihood and prior. Is this different to the previous integral?", \int p(\vec{x}) d\vec{x} = 1 \vec{x} p(D) = \int p(D|\vec{w})p(\vec{w}) d\vec{w} ,"['probability', 'integration', 'statistics']"
64,Expected value of MSB in one-way ANOVA,Expected value of MSB in one-way ANOVA,,"Suppose we have $k$ many machines each producing iron balls and we are interested in weights of the balls. Let $y_{ij}$ be the weight of the $j$ th ball produced by $i$ th machine,where $i=1,2,...,k$ and $j=1,2,...,n_i$ . Let $\mu_i$ be the average weight of a ball produced by machine $i$ . Now let us focus on the following hypothesis. We know that if $H_0: \mu_1=\dots=\mu_k$ is assumed to be true, then we have $E(MSB)=\sigma^2$ . Where $$ MSB  = \sum_i n_i \frac{(\overline y_{i0}-\overline y_{00})^2}                    {\sigma^2(k-1)}$$ is the Mean Square Between . Now, when $H_0$ is true, its expected value is $\sigma^2$ . But when $H_0$ is not true, then $$ E(MSB)=\sigma^2+\frac{1}{k-1} \sum n_i \alpha^2_i. $$ Where $\alpha_i=\mu_i-\mu$ .I am a newcomer in statistics and I know the result only, not its proof. So how to prove this equation using basic knowledge of statistics? Please note that I am considering one-way ANOVA.","Suppose we have many machines each producing iron balls and we are interested in weights of the balls. Let be the weight of the th ball produced by th machine,where and . Let be the average weight of a ball produced by machine . Now let us focus on the following hypothesis. We know that if is assumed to be true, then we have . Where is the Mean Square Between . Now, when is true, its expected value is . But when is not true, then Where .I am a newcomer in statistics and I know the result only, not its proof. So how to prove this equation using basic knowledge of statistics? Please note that I am considering one-way ANOVA.","k y_{ij} j i i=1,2,...,k j=1,2,...,n_i \mu_i i H_0: \mu_1=\dots=\mu_k E(MSB)=\sigma^2 
MSB
 = \sum_i n_i \frac{(\overline y_{i0}-\overline y_{00})^2}
                   {\sigma^2(k-1)} H_0 \sigma^2 H_0 
E(MSB)=\sigma^2+\frac{1}{k-1} \sum n_i \alpha^2_i.
 \alpha_i=\mu_i-\mu","['probability', 'statistics', 'normal-distribution', 'expected-value', 'anova']"
65,Conditional expectation with multiple conditioning,Conditional expectation with multiple conditioning,,"For any r.v.s $X$ and $Y$ : $$E(Y|E(Y|X)) = E(Y|X)$$ But I cannot seem to be able to prove this. I tried using Adam's Law with extra conditioning ( $E(Y|X) = E(E(Y|X,Z)|Z)$ ) but I don't seem to get anywhere with it. What I tried is the following: $$g(X) = E(Y|X)$$ $$E(Y|g(X)) = E(E(Y|X,g(X))|g(X))$$ Since the event $X$ happened and $g(X)$ happened are equivalent, conditioning on both $X$ and $g(X)$ is the same as conditioning on only one of them. Is there any intuitive interpretation of this ? Does this also mean that conditioning on $X$ or any function $g$ of $X$ is the same ?","For any r.v.s and : But I cannot seem to be able to prove this. I tried using Adam's Law with extra conditioning ( ) but I don't seem to get anywhere with it. What I tried is the following: Since the event happened and happened are equivalent, conditioning on both and is the same as conditioning on only one of them. Is there any intuitive interpretation of this ? Does this also mean that conditioning on or any function of is the same ?","X Y E(Y|E(Y|X)) = E(Y|X) E(Y|X) = E(E(Y|X,Z)|Z) g(X) = E(Y|X) E(Y|g(X)) = E(E(Y|X,g(X))|g(X)) X g(X) X g(X) X g X","['probability', 'statistics', 'conditional-expectation']"
66,Is it possible to put inequality to null hypothesis?,Is it possible to put inequality to null hypothesis?,,"Based on a sample of i.i.d. Normal random variables $X_1, . . . , X_n$ with mean µ and variance $σ^2$ , propose a test with asymptotic level 5% for the hypotheses: $$ H_0: µ > σ$$ $$ H_1: µ \leq σ$$ What is the p-value of your test if the sample has size n = 100, the sample average is 2.41 and the sample variance is 5.20 ? If the sample size is n = 100, the sample average is 3.28 and the sample variance is 15.95 ? In the latter case, do you reject H0 at level 5% ? At level 10% ?","Based on a sample of i.i.d. Normal random variables with mean µ and variance , propose a test with asymptotic level 5% for the hypotheses: What is the p-value of your test if the sample has size n = 100, the sample average is 2.41 and the sample variance is 5.20 ? If the sample size is n = 100, the sample average is 3.28 and the sample variance is 15.95 ? In the latter case, do you reject H0 at level 5% ? At level 10% ?","X_1, . . . , X_n σ^2  H_0: µ > σ  H_1: µ \leq σ","['statistics', 'normal-distribution', 'p-value']"
67,Question about how to use Z-score to help us determine which test the student did better,Question about how to use Z-score to help us determine which test the student did better,,"Here is the question: A student scores 56 on a geography test and 267 on a mathematics test. The geography test has a mean of 80 and a standard deviation of 20. The mathematics test has a mean of 300 and a standard deviation of 22. If the data for both tests are normally distributed, on which test did the student score better? You can find the solution here: https://study.com/academy/answer/a-student-scores-56-on-a-geography-test-and-267-on-a-mathematics-test-the-geography-test-has-a-mean-of-80-and-a-standard-deviation-of-20-the-mathematics-test-has-a-mean-of-300-and-a-standard-deviati.html My problem: Q1: I attempted the problem without looking at the answer. I do not understand why the solution use z-score here and not use the numbers: 56 and 261. Why can I just use the numbers 56 and 267? Since 267>56, the student did better in math. \ Q2: I do not understand how the z scores help determine which test the student did better. I realize I do not understand z scores. Thank you so much.","Here is the question: A student scores 56 on a geography test and 267 on a mathematics test. The geography test has a mean of 80 and a standard deviation of 20. The mathematics test has a mean of 300 and a standard deviation of 22. If the data for both tests are normally distributed, on which test did the student score better? You can find the solution here: https://study.com/academy/answer/a-student-scores-56-on-a-geography-test-and-267-on-a-mathematics-test-the-geography-test-has-a-mean-of-80-and-a-standard-deviation-of-20-the-mathematics-test-has-a-mean-of-300-and-a-standard-deviati.html My problem: Q1: I attempted the problem without looking at the answer. I do not understand why the solution use z-score here and not use the numbers: 56 and 261. Why can I just use the numbers 56 and 267? Since 267>56, the student did better in math. \ Q2: I do not understand how the z scores help determine which test the student did better. I realize I do not understand z scores. Thank you so much.",,"['statistics', 'normal-distribution']"
68,Adding Background Evidence Variable to Bayes' Theorem,Adding Background Evidence Variable to Bayes' Theorem,,"A geometric interpretation of the Bayes' Theorem formula $$\Pr(H \mid E) = \frac{\Pr(H)\ \Pr(E\mid  H)}{\Pr(H)\ \Pr(E\mid  H)\ +\ \Pr(H^c)\ \Pr(E\mid  H^c)}$$ takes place in a unit square.  First, draw a vertical line through the square so that your assessment of a hypothesis's prior probability, $\Pr(H)$ , is the distance left of the line, and $\Pr(H^c)$ is the distance right of the line, as shown below in the left figure.  Then draw horizontal lines through the left rectangle at height $\Pr(E\mid  H)$ , and the right rectangle at height $\Pr(E\mid  H^c)$ , as in the center figure.  If the left line is higher, then the new evidence increased your epistemic probability of $H$ , and vice-versa. The areas of the new rectangles correspond to the above Bayes' Theorem formula, according to the pattern displayed in the right figure.  The numeric output is your new epistemic probability of $H$ . This output can then be treated as a new prior probability to be assessed against a new piece of evidence.  If the original was your prior probability at time $t_0$ , now your prior probability at $t_1$ is visualized by drawing a vertical line in a fresh unit square, as far to the right as necessary to match the output of the previous Bayes' Theorem iteration.  This process can continue indefinitely, assigning a new time step for each incoming piece of evidence. An alternative Bayes' Theorem formula $$\Pr(H\mid  (B\ \cap\ E)) = \frac{\Pr(H\mid  B)\ \Pr(E\mid (B\ \cap\ H))}{\Pr(H\mid  B)\ \Pr(E\mid  (B\ \cap\ H)) + \Pr(H^c\mid  B)\ \Pr(E\mid  (B\ \cap\ H^c))}$$ includes the variable $B$ to represent background evidence. This answer explains how to algebraically derive the alternative formula from the initial formula.  What I don't understand is $B$ 's purpose.  It seems to me that the initial Bayes's Theorem formula already described the iterable progression of the epistemic probability of $H$ from one time step to the next.  The notion of background evidence must have already been accounted for implicitly in $Pr(H)$ . How. if at all, does switching to the Bayes' Theorem formula with $B$ change the conceptual and/or geometric evolution described above?  Is the inclusion of $B$ a mathematically irrelevant substitution, similar to how differential equations are sometimes written with constants such as $\frac{k}{m}$ , even when they could be simplified by lumping, or should the presence of $B$ add something to the way the above mathematics is understood?","A geometric interpretation of the Bayes' Theorem formula takes place in a unit square.  First, draw a vertical line through the square so that your assessment of a hypothesis's prior probability, , is the distance left of the line, and is the distance right of the line, as shown below in the left figure.  Then draw horizontal lines through the left rectangle at height , and the right rectangle at height , as in the center figure.  If the left line is higher, then the new evidence increased your epistemic probability of , and vice-versa. The areas of the new rectangles correspond to the above Bayes' Theorem formula, according to the pattern displayed in the right figure.  The numeric output is your new epistemic probability of . This output can then be treated as a new prior probability to be assessed against a new piece of evidence.  If the original was your prior probability at time , now your prior probability at is visualized by drawing a vertical line in a fresh unit square, as far to the right as necessary to match the output of the previous Bayes' Theorem iteration.  This process can continue indefinitely, assigning a new time step for each incoming piece of evidence. An alternative Bayes' Theorem formula includes the variable to represent background evidence. This answer explains how to algebraically derive the alternative formula from the initial formula.  What I don't understand is 's purpose.  It seems to me that the initial Bayes's Theorem formula already described the iterable progression of the epistemic probability of from one time step to the next.  The notion of background evidence must have already been accounted for implicitly in . How. if at all, does switching to the Bayes' Theorem formula with change the conceptual and/or geometric evolution described above?  Is the inclusion of a mathematically irrelevant substitution, similar to how differential equations are sometimes written with constants such as , even when they could be simplified by lumping, or should the presence of add something to the way the above mathematics is understood?",\Pr(H \mid E) = \frac{\Pr(H)\ \Pr(E\mid  H)}{\Pr(H)\ \Pr(E\mid  H)\ +\ \Pr(H^c)\ \Pr(E\mid  H^c)} \Pr(H) \Pr(H^c) \Pr(E\mid  H) \Pr(E\mid  H^c) H H t_0 t_1 \Pr(H\mid  (B\ \cap\ E)) = \frac{\Pr(H\mid  B)\ \Pr(E\mid (B\ \cap\ H))}{\Pr(H\mid  B)\ \Pr(E\mid  (B\ \cap\ H)) + \Pr(H^c\mid  B)\ \Pr(E\mid  (B\ \cap\ H^c))} B B H Pr(H) B B \frac{k}{m} B,"['probability', 'geometry', 'statistics', 'conditional-probability', 'bayes-theorem']"
69,Why do absorbing Markov chains appear to violate the law of total expectation?,Why do absorbing Markov chains appear to violate the law of total expectation?,,"Following up on two previous questions: Expected number of steps for reaching a specific absorbing state in an absorbing Markov chain and Expected time till absorption in specific state of a Markov chain Suppose you have an absorbing Markov chain with two absorbing states. You can calculate the probability of reaching either absorbing state, you can calculate the expected number of steps before being absorbed, you can construct a conditional matrix that removes an absorbing state, and you can calculate expected step count for that. For example, consider a minimal drunkard's walk with four states, A, B, C, and D, where A and D are absorbing. We have $$ P = \begin{bmatrix}0 && 0.5 && 0.5 && 0 \\ 0.5 && 0 && 0 && 0.5 \\ 0 && 0 && 1 && 0 \\ 0 && 0 && 0 && 1 \end{bmatrix}, N = \begin{bmatrix}4/3 && 2/3 \\ 2/3 && 4/3\end{bmatrix}, NR = \begin{bmatrix}2/3 && 1/3 \\ 1/3 && 2/3\end{bmatrix}  $$ Or if we eliminate column three $$ P = \begin{bmatrix}0 && 1 && 0 \\ 0.5 && 0 && 0.5 \\ 0 && 0 && 1 \end{bmatrix}, N = \begin{bmatrix}2&&2\\1&&2\end{bmatrix}, NR = \begin{bmatrix}1\\1\end{bmatrix}  $$ Skipping some of the other math, we eventually get P(reach A from B) = 2/3, P(reach D from B) = 1/3, E(steps starting from B) = 2, E(steps starting from B|end in A) = 3, and E(steps starting from B|end in D) = 4. But 2/3 * 3 + 1/3 * 4 is an expected 10/3 steps, not the 2 from the unconditional matrix. Is there something wrong about the conditional matrix logic? Or else why does this appear to violate the law of total expectation?","Following up on two previous questions: Expected number of steps for reaching a specific absorbing state in an absorbing Markov chain and Expected time till absorption in specific state of a Markov chain Suppose you have an absorbing Markov chain with two absorbing states. You can calculate the probability of reaching either absorbing state, you can calculate the expected number of steps before being absorbed, you can construct a conditional matrix that removes an absorbing state, and you can calculate expected step count for that. For example, consider a minimal drunkard's walk with four states, A, B, C, and D, where A and D are absorbing. We have Or if we eliminate column three Skipping some of the other math, we eventually get P(reach A from B) = 2/3, P(reach D from B) = 1/3, E(steps starting from B) = 2, E(steps starting from B|end in A) = 3, and E(steps starting from B|end in D) = 4. But 2/3 * 3 + 1/3 * 4 is an expected 10/3 steps, not the 2 from the unconditional matrix. Is there something wrong about the conditional matrix logic? Or else why does this appear to violate the law of total expectation?","
P = \begin{bmatrix}0 && 0.5 && 0.5 && 0 \\ 0.5 && 0 && 0 && 0.5 \\ 0 && 0 && 1 && 0 \\ 0 && 0 && 0 && 1 \end{bmatrix}, N = \begin{bmatrix}4/3 && 2/3 \\ 2/3 && 4/3\end{bmatrix}, NR = \begin{bmatrix}2/3 && 1/3 \\ 1/3 && 2/3\end{bmatrix} 
 
P = \begin{bmatrix}0 && 1 && 0 \\ 0.5 && 0 && 0.5 \\ 0 && 0 && 1 \end{bmatrix}, N = \begin{bmatrix}2&&2\\1&&2\end{bmatrix}, NR = \begin{bmatrix}1\\1\end{bmatrix} 
","['probability', 'statistics', 'markov-chains']"
70,Is a 99% confidence level more precise than 95%?,Is a 99% confidence level more precise than 95%?,,"Hi. I'm confused by 'significance level'. If significance level is lower, is the result of test more reliable? I think it's the opposite, so it makes me so confused. Look at the picture and assume that $H_0$ is null hypothesis, $\alpha$ is the 'significance level'. Let's test this, by sample size is 40, as a result sample mean is $\mu_1$ . If the given 'confidence level'( $1-\alpha$ ) is 95%, z value of 'c' would be 1.96.  If given 99%, 'c' would be 2.56 Here is the problem. If confidence level is 99%, is the result more reliable than confidence level 95%? If c level is 99%, more error would be included in null hypothesis area, than level 95%. if c level is 99%, it means '99% of deviation would be regarded as in the null area anyway. So actually, c level 99% means it's less precise than 95%, right? Rather, if confidence level is very small like 5%, so the 'c' value goes closer to $\mu_0$ , it would mean that we will regard more values to be error. So it must be more precise. Am I wrong? The textbook seems to say i'm wrong. And hope you genius explain it.. Thank you!","Hi. I'm confused by 'significance level'. If significance level is lower, is the result of test more reliable? I think it's the opposite, so it makes me so confused. Look at the picture and assume that is null hypothesis, is the 'significance level'. Let's test this, by sample size is 40, as a result sample mean is . If the given 'confidence level'( ) is 95%, z value of 'c' would be 1.96.  If given 99%, 'c' would be 2.56 Here is the problem. If confidence level is 99%, is the result more reliable than confidence level 95%? If c level is 99%, more error would be included in null hypothesis area, than level 95%. if c level is 99%, it means '99% of deviation would be regarded as in the null area anyway. So actually, c level 99% means it's less precise than 95%, right? Rather, if confidence level is very small like 5%, so the 'c' value goes closer to , it would mean that we will regard more values to be error. So it must be more precise. Am I wrong? The textbook seems to say i'm wrong. And hope you genius explain it.. Thank you!",H_0 \alpha \mu_1 1-\alpha \mu_0,"['statistics', 'statistical-inference', 'hypothesis-testing', 'confidence-interval']"
71,Real-world application where strong LLN is needed (weak LLN is not enough) [closed],Real-world application where strong LLN is needed (weak LLN is not enough) [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question Do you know of any real world (algorithm, physics, ...) application of the law of large numbers where we need the strong LLN and the weak LLN by itself is not enough to prove that the application is working as expected ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question Do you know of any real world (algorithm, physics, ...) application of the law of large numbers where we need the strong LLN and the weak LLN by itself is not enough to prove that the application is working as expected ?",,"['probability', 'statistics', 'weak-convergence', 'applications', 'law-of-large-numbers']"
72,The discard limit in fish containing mercury is too high. How should it be chosen such that average levels are as small as possible?,The discard limit in fish containing mercury is too high. How should it be chosen such that average levels are as small as possible?,,"This is a question I'm trying to answer for my probability homework. I've been looking at it for the last 2 days and I'm not getting anywhere so I ask for help. Below is the question. After are my thoughts which i have moved from a comment into the main body. The mercury content in swordfish sold in some parts of the US is known   to be normally distributed with mean 1.1 ppm and variance 0.25 pp $m^2$ (see e.g. Lee and Krutchkoff and/or exercises 5.2 and 5.3 in Larsen),   but according to the health authorities the average level of mercury   in fish for consumption should not exceed 1 ppm. Fish sold through   authorised retailers are always controlled by the FDA, and if the   mercury content is too high, the lot is discarded. However, about $25\%$ of the fish caught is sold on the black market, that is, $25\%$ of the fish does not go through the control. Therefore the rule   ""discard if the mercury content exceeds $1 ppm$ "" is not sufficient.   How should the ""discard limit"" be chosen to ensure that the average   level of mercury in the fish actually bought by the consumers is as   small as possible? Basically, I'm not sure about what is expected from me here. The 75% of fish tested have a mean mercury content above the allowed limit. So is it possible to somehow make the mean lower by by having a cutoff at a high point to lower the average? Is that even what they mean by 'choosing the discard limit'? If we discard the top end and somehow truncate the normal distribution will we then have a lower mean? Is that even a legal move? Furthermore I don't like the sentence 'How should the discard limit be chosen'. Surely its chosen by the medically qualified and isn't something you can just change? I feel like the wording is also causing some miscommunication.","This is a question I'm trying to answer for my probability homework. I've been looking at it for the last 2 days and I'm not getting anywhere so I ask for help. Below is the question. After are my thoughts which i have moved from a comment into the main body. The mercury content in swordfish sold in some parts of the US is known   to be normally distributed with mean 1.1 ppm and variance 0.25 pp (see e.g. Lee and Krutchkoff and/or exercises 5.2 and 5.3 in Larsen),   but according to the health authorities the average level of mercury   in fish for consumption should not exceed 1 ppm. Fish sold through   authorised retailers are always controlled by the FDA, and if the   mercury content is too high, the lot is discarded. However, about of the fish caught is sold on the black market, that is, of the fish does not go through the control. Therefore the rule   ""discard if the mercury content exceeds "" is not sufficient.   How should the ""discard limit"" be chosen to ensure that the average   level of mercury in the fish actually bought by the consumers is as   small as possible? Basically, I'm not sure about what is expected from me here. The 75% of fish tested have a mean mercury content above the allowed limit. So is it possible to somehow make the mean lower by by having a cutoff at a high point to lower the average? Is that even what they mean by 'choosing the discard limit'? If we discard the top end and somehow truncate the normal distribution will we then have a lower mean? Is that even a legal move? Furthermore I don't like the sentence 'How should the discard limit be chosen'. Surely its chosen by the medically qualified and isn't something you can just change? I feel like the wording is also causing some miscommunication.",m^2 25\% 25\% 1 ppm,"['probability', 'statistics']"
73,Exponential Likelihood Function,Exponential Likelihood Function,,"Suppose $X_1, ..., X_n \stackrel{iid}{\sim}$ Exponential(rate = $\lambda$ ) independent of $Y_1, ..., Y_n \stackrel{iid}{\sim}$ Exponential $(1)$ . Define $Z_i \equiv \min\{X_i, Y_i\}$ I want to find the maximum likelihood estimator for $\lambda$ in the following scenario:  I observe $Z_1, ..., Z_n$ and $Y_1, ..., Y_n$ but NOT any of the $X_i$ . First I need to determine the likelihood and then maximize it over $\theta > 0$ , but I'm not really sure of the right approach.  I calculate the joint cdf as follows: $$P(Z_i \leq z, Y_i \leq y) = \begin{cases} P(Y_i \leq y), & y \leq z \\ P(Y_i \leq z, Y_i \leq X_i) + P(Y_i \leq y, X_i \leq z, X_i < Y_i), & y > z\end{cases} \\ = \begin{cases} 1- e^{-y}, & y \leq z \\ 1-e^{-z} + (e^{-z}-e^{-y})(1-e^{-\lambda z}), & y > z \end{cases}$$ This is because $Z_i \leq Y_i$ always.  Would the likelihood function therefore be: $$L(\lambda |Y_i, Z_i, i \in \{1,...n\}) = \prod_{\{i : Y_i = Z_i\}} (1-e^{-Y_i}) \prod_{\{i:Y_i > Z_i\}}  \lambda e^{-Y_i}e^{-\lambda Z_i}$$ splitting into the ""discrete"" and ""continuous"" parts?  Or am I getting this wrong?  Or should I be doing something like here or here ?  I should note my scenario is different than theirs, as intuitively at least, observing the magnitude of the difference between the minimum and the maximum (in the cases where $Z_i$ and $Y_i$ differ) should give us more information about $\lambda$ , right?","Suppose Exponential(rate = ) independent of Exponential . Define I want to find the maximum likelihood estimator for in the following scenario:  I observe and but NOT any of the . First I need to determine the likelihood and then maximize it over , but I'm not really sure of the right approach.  I calculate the joint cdf as follows: This is because always.  Would the likelihood function therefore be: splitting into the ""discrete"" and ""continuous"" parts?  Or am I getting this wrong?  Or should I be doing something like here or here ?  I should note my scenario is different than theirs, as intuitively at least, observing the magnitude of the difference between the minimum and the maximum (in the cases where and differ) should give us more information about , right?","X_1, ..., X_n \stackrel{iid}{\sim} \lambda Y_1, ..., Y_n \stackrel{iid}{\sim} (1) Z_i \equiv \min\{X_i, Y_i\} \lambda Z_1, ..., Z_n Y_1, ..., Y_n X_i \theta > 0 P(Z_i \leq z, Y_i \leq y) = \begin{cases} P(Y_i \leq y), & y \leq z \\ P(Y_i \leq z, Y_i \leq X_i) + P(Y_i \leq y, X_i \leq z, X_i < Y_i), & y > z\end{cases} \\
= \begin{cases} 1- e^{-y}, & y \leq z \\
1-e^{-z} + (e^{-z}-e^{-y})(1-e^{-\lambda z}), & y > z \end{cases} Z_i \leq Y_i L(\lambda |Y_i, Z_i, i \in \{1,...n\}) = \prod_{\{i : Y_i = Z_i\}} (1-e^{-Y_i}) \prod_{\{i:Y_i > Z_i\}}  \lambda e^{-Y_i}e^{-\lambda Z_i} Z_i Y_i \lambda","['statistics', 'probability-distributions', 'statistical-inference', 'maximum-likelihood', 'exponential-distribution']"
74,"MLE of Uniform on $(\theta, \theta +1)$ and consistency/bias",MLE of Uniform on  and consistency/bias,"(\theta, \theta +1)","I see there were a few questions on SE about MLE of Uniform already but none of them helped me with this one: We are to compute MLE of $U(\theta, \theta +1)$ and check if it is biased and consistent . I tried by making a spin-off of an example with $U(0, \theta)$ but I am not sure if it is correct. Suppose there's $X_1, X_2, \dots, X_n$ i.i.d with $U(\theta, \theta +1)$ , $T(X_1, \dots, X_n)$ is the statistic and $(x_1, \dots, x_n)$ a sample from that statistic. I start of with computing $L(\theta)$ $$ L(\theta)=\prod_{i=1}^n\mathbb{1}_{[\theta, \theta +1]}(x_i) = \mathbb{1}_{(-\infty, X(1)]}(\theta)\cdot\mathbb{1}_{[X(n),\infty)}(\theta+1) $$ Since $P(x_i \geq \theta) = 1$ this is just $$ L(\theta)=\mathbb{1}_{[X(n),\infty)}(\theta+1) = \begin{cases}       1, & \text{if}\ \theta + 1 \geq X(n) \\       0, & \text{otherwise}     \end{cases} $$ The smallest value of $\theta = 1$ is then $\frac{X(n) - 1 + X(1)}{2}$ and this is our MLE. As @StubbornAtom pointed out in comments, this is not the only MLE possible. How can I calculate bias and consistency of the $\hat{\theta}^{MLE}$ of my choosing?","I see there were a few questions on SE about MLE of Uniform already but none of them helped me with this one: We are to compute MLE of and check if it is biased and consistent . I tried by making a spin-off of an example with but I am not sure if it is correct. Suppose there's i.i.d with , is the statistic and a sample from that statistic. I start of with computing Since this is just The smallest value of is then and this is our MLE. As @StubbornAtom pointed out in comments, this is not the only MLE possible. How can I calculate bias and consistency of the of my choosing?","U(\theta, \theta +1) U(0, \theta) X_1, X_2, \dots, X_n U(\theta, \theta +1) T(X_1, \dots, X_n) (x_1, \dots, x_n) L(\theta) 
L(\theta)=\prod_{i=1}^n\mathbb{1}_{[\theta, \theta +1]}(x_i) = \mathbb{1}_{(-\infty, X(1)]}(\theta)\cdot\mathbb{1}_{[X(n),\infty)}(\theta+1)
 P(x_i \geq \theta) = 1 
L(\theta)=\mathbb{1}_{[X(n),\infty)}(\theta+1) = \begin{cases}
      1, & \text{if}\ \theta + 1 \geq X(n) \\
      0, & \text{otherwise}
    \end{cases}
 \theta = 1 \frac{X(n) - 1 + X(1)}{2} \hat{\theta}^{MLE}","['probability', 'statistics', 'maximum-likelihood', 'parameter-estimation']"
75,An Indentity of Poisson process,An Indentity of Poisson process,,"Question: Suppose buses arrive at a bus stop according to a Poisson process $N_t$ with parameter . Given a fixed $t > 0$ . The time of the last bus before t is $S_{N_t}$ , and the time of the next bus after $t$ is $S_{N_{t+1}}$ . Show the following identity: $E(S_{N_{t+1}}-S_{N_t})=(2-e^{-\lambda t})/{\lambda}$ . My attempt: One basic conclusion about Poisson proccess is that:  the time interval between two arrivals follows $Expo(\lambda)$ . But here,as t is a fixed time point,it can be any point in the interval $S_{N_t}$ and $S_{N_{t+1}}$ .Thus I found it impossible to use the above assumption.So what should I do next?","Question: Suppose buses arrive at a bus stop according to a Poisson process with parameter . Given a fixed . The time of the last bus before t is , and the time of the next bus after is . Show the following identity: . My attempt: One basic conclusion about Poisson proccess is that:  the time interval between two arrivals follows . But here,as t is a fixed time point,it can be any point in the interval and .Thus I found it impossible to use the above assumption.So what should I do next?",N_t t > 0 S_{N_t} t S_{N_{t+1}} E(S_{N_{t+1}}-S_{N_t})=(2-e^{-\lambda t})/{\lambda} Expo(\lambda) S_{N_t} S_{N_{t+1}},"['probability', 'statistics', 'stochastic-processes', 'poisson-process', 'renewal-processes']"
76,Mode of a dataset having distinct numbers,Mode of a dataset having distinct numbers,,"I am actually a bit confused... about the definition of a mode . According to the definition I read, it came to my notice that the number with highest frequency has to be a mode for a given data set , but then what if I have all the numbers as distinct... In that scenario we won't have a particular number having a frequency more than other elements in the data set...   Now if I consider a case when we have 2 numbers in a dataset with same max number of occurrences like: $$2,3,4,5,3,2$$ Here 2, 3 both happen to have same maximum frequency and thus we say there are 2 modes...   The above is stated similar in case we have 3 modes or multi modes ...   So if there are all distinct numbers then we would have each number having the same maximum frequency as 1 ..so we can say all the numbers are modes ...for that dataset...But then I have seen on some websites claiming that such data sets have ""NO MODE"". So again my thought process is contradicting...what claims I am seeing on websites... So plz some one help me get this basic concept resolved ...","I am actually a bit confused... about the definition of a mode . According to the definition I read, it came to my notice that the number with highest frequency has to be a mode for a given data set , but then what if I have all the numbers as distinct... In that scenario we won't have a particular number having a frequency more than other elements in the data set...   Now if I consider a case when we have 2 numbers in a dataset with same max number of occurrences like: Here 2, 3 both happen to have same maximum frequency and thus we say there are 2 modes...   The above is stated similar in case we have 3 modes or multi modes ...   So if there are all distinct numbers then we would have each number having the same maximum frequency as 1 ..so we can say all the numbers are modes ...for that dataset...But then I have seen on some websites claiming that such data sets have ""NO MODE"". So again my thought process is contradicting...what claims I am seeing on websites... So plz some one help me get this basic concept resolved ...","2,3,4,5,3,2","['combinatorics', 'statistics']"
77,Upper bound for Rademacher complexity,Upper bound for Rademacher complexity,,"Given $x_1^n=\{x_1,...,x_n\}$ with $x_j\in R^p$ and $\mathcal{F}$ a class of real-valued functions defined in $R^p$ , define $\mathcal{F}(x_1^n)$ as $$\mathcal{F}(x_1^n)=\{(f(x_1),...,f(x_n)):f\in\mathcal{F}\}.$$ Suppose that card $(\mathcal{F}(x_1^n))\leq (n+1)^v$ with $v\geq 1$ . For $\epsilon=(\epsilon_1,...,\epsilon_n)$ with $\{\epsilon_j\}$ i.i.d. Rademacher random variables I want to show that \begin{align*} E_{\epsilon}\sup_{f\in\mathcal{F}}\Big|\dfrac{1}{n}\sum_{j=1}^n\epsilon_jf(x_j)\Big|\leq 4\sqrt{\dfrac{v\log(n+1)}{n}}\sup_{f\in\mathcal{F}}\sqrt{\dfrac{\sum_{j=1}^nf^2(x_j)}{n}}. \end{align*} This is Lemma 4.14 from High-dimensional statistics from M.J. Wainwright. My attempt was to use Cauchy-Schwartz: we know that $4\sqrt{v\log(n+1)}\geq 1$ , so \begin{align*} \Big|\sum_{j=1}^n\epsilon_jf(x_j)\Big|&\leq 4\sqrt{v\log(n+1)}\left(\sum_{j=1}^n\epsilon_j^2\right)^{1/2}\left(\sum_{j=1}^nf^2(x_j)\right)^{1/2}\\ &=4\sqrt{v\log(n+1)}\sqrt{n}\left(\sum_{j=1}^nf^2(x_j)\right)^{1/2}.\\ \end{align*} Dividing by $n$ and taking the supremum I get \begin{align*} E_{\epsilon}\sup_{f\in\mathcal{F}}\Big|\dfrac{1}{n}\sum_{j=1}^n\epsilon_jf(x_j)\Big|\leq 4\sqrt{v\log(n+1)}\sup_{f\in\mathcal{F}}\sqrt{\dfrac{\sum_{j=1}^nf^2(x_j)}{n}}. \end{align*} So I have a $\sqrt{n}$ missing in the denominator. Is there another way to prove it?","Given with and a class of real-valued functions defined in , define as Suppose that card with . For with i.i.d. Rademacher random variables I want to show that This is Lemma 4.14 from High-dimensional statistics from M.J. Wainwright. My attempt was to use Cauchy-Schwartz: we know that , so Dividing by and taking the supremum I get So I have a missing in the denominator. Is there another way to prove it?","x_1^n=\{x_1,...,x_n\} x_j\in R^p \mathcal{F} R^p \mathcal{F}(x_1^n) \mathcal{F}(x_1^n)=\{(f(x_1),...,f(x_n)):f\in\mathcal{F}\}. (\mathcal{F}(x_1^n))\leq (n+1)^v v\geq 1 \epsilon=(\epsilon_1,...,\epsilon_n) \{\epsilon_j\} \begin{align*}
E_{\epsilon}\sup_{f\in\mathcal{F}}\Big|\dfrac{1}{n}\sum_{j=1}^n\epsilon_jf(x_j)\Big|\leq 4\sqrt{\dfrac{v\log(n+1)}{n}}\sup_{f\in\mathcal{F}}\sqrt{\dfrac{\sum_{j=1}^nf^2(x_j)}{n}}.
\end{align*} 4\sqrt{v\log(n+1)}\geq 1 \begin{align*}
\Big|\sum_{j=1}^n\epsilon_jf(x_j)\Big|&\leq 4\sqrt{v\log(n+1)}\left(\sum_{j=1}^n\epsilon_j^2\right)^{1/2}\left(\sum_{j=1}^nf^2(x_j)\right)^{1/2}\\
&=4\sqrt{v\log(n+1)}\sqrt{n}\left(\sum_{j=1}^nf^2(x_j)\right)^{1/2}.\\
\end{align*} n \begin{align*}
E_{\epsilon}\sup_{f\in\mathcal{F}}\Big|\dfrac{1}{n}\sum_{j=1}^n\epsilon_jf(x_j)\Big|\leq 4\sqrt{v\log(n+1)}\sup_{f\in\mathcal{F}}\sqrt{\dfrac{\sum_{j=1}^nf^2(x_j)}{n}}.
\end{align*} \sqrt{n}","['probability', 'statistics', 'machine-learning', 'expected-value', 'concentration-of-measure']"
78,A normal distribution question is this the correct way of going about it?,A normal distribution question is this the correct way of going about it?,,"A study of data collected at a company manufacturing flashlight   batteries shows that a batch of 8000 batteries have a mean life of 250   minutes with a standard deviation of 20 minutes. Assuming a Normal   Distribution, estimate: (i) How many batteries will fail before 220 minutes? This is my answer to this question does it look correct or are there any improvements I can make? Batch: 8000 Mean: 250 minutes  SD: 20 minutes  (250-220)/20 = 1.5  Z-score of 1.5 = .4332  (.5-.4332)8000 = 534.4 will fail after 220 minutes","A study of data collected at a company manufacturing flashlight   batteries shows that a batch of 8000 batteries have a mean life of 250   minutes with a standard deviation of 20 minutes. Assuming a Normal   Distribution, estimate: (i) How many batteries will fail before 220 minutes? This is my answer to this question does it look correct or are there any improvements I can make? Batch: 8000 Mean: 250 minutes  SD: 20 minutes  (250-220)/20 = 1.5  Z-score of 1.5 = .4332  (.5-.4332)8000 = 534.4 will fail after 220 minutes",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
79,When to use Pooled Variance?,When to use Pooled Variance?,,"In the following examples, why is pooled variance used in the first video but not in the other? When do you use pooled variance? https://classroom.udacity.com/courses/ud257/lessons/4018018619/concepts/40043987120923 The last example in this page: https://newonlinecourses.science.psu.edu/stat414/node/306/","In the following examples, why is pooled variance used in the first video but not in the other? When do you use pooled variance? https://classroom.udacity.com/courses/ud257/lessons/4018018619/concepts/40043987120923 The last example in this page: https://newonlinecourses.science.psu.edu/stat414/node/306/",,"['statistics', 'variance', 'experimental-mathematics']"
80,"Sample all elements from a set at least once, with replacement","Sample all elements from a set at least once, with replacement",,"I've seen the Coupon collector's problem and I believe this is a variant of it but I can't quite wrap my head around it. This is not a homework assignment. I have a set of k elements. I randomly sample s elements from the set and then replace them. If I do this n times, what is the probability that I will have sampled every single element at least once?","I've seen the Coupon collector's problem and I believe this is a variant of it but I can't quite wrap my head around it. This is not a homework assignment. I have a set of k elements. I randomly sample s elements from the set and then replace them. If I do this n times, what is the probability that I will have sampled every single element at least once?",,"['probability', 'combinatorics', 'statistics', 'coupon-collector']"
81,Confidence Intervals - Doubts on Interpretations,Confidence Intervals - Doubts on Interpretations,,"Suppose we use a sample mean $\bar{X}$ to construct a $95\%$ confidence interval $[a, b]$ . I was told that it is incorrect to say that there is a $95\%$ probability that the population mean lies between $a$ and $b$ . Because the population mean is a constant and not a random variable. The probability that a constant falls within any given range is either $0$ or $1$ . However, from the textbook it is said that we expect $95\%$ of the confidence intervals to include the population mean . If $95\%$ of the confidence intervals are expected to include the population mean, then each confidence interval has $95\%$ probability to include the population mean. Therefore I think it is correct to say there is a $95\%$ probability that the population mean lies between $a$ and $b$ . Where did I make mistakes?","Suppose we use a sample mean to construct a confidence interval . I was told that it is incorrect to say that there is a probability that the population mean lies between and . Because the population mean is a constant and not a random variable. The probability that a constant falls within any given range is either or . However, from the textbook it is said that we expect of the confidence intervals to include the population mean . If of the confidence intervals are expected to include the population mean, then each confidence interval has probability to include the population mean. Therefore I think it is correct to say there is a probability that the population mean lies between and . Where did I make mistakes?","\bar{X} 95\% [a, b] 95\% a b 0 1 95\% 95\% 95\% 95\% a b","['probability', 'statistics', 'confidence-interval']"
82,How the α affects the solution path in the elastic net?,How the α affects the solution path in the elastic net?,,"The following Quiz is the rough translation (with minor modifications) of Quiz No.10-2 of the exam of the ""2018's semi-first grade of Japan Statistical Society Certificate"" (see Ref (1)) "".  According to the official answer, the  correct  answer is (A) (See Fig (A) below.). However, I cannot imagine how to achieve the correct answer. My question: How to achieve the correct answer of following Quiz? How the α affects the solution path in the elastic net?   Which α correspond to Figures (B), (C), and (D) ?(As described in official answer, the α of Fig (A) is 0.5. However, There is no description about ""What are the α corresponding to other figures?"") I recognized the following features. These features might be the key to discriminate α … . However, I cannot imagine how to achieve the correct answer. As lambda gets larger, the parameter estimates get smaller (Ref (2)). Only in Figure (C), the shape of the graph seems very different. Only Figure (C) seems roughly symmetrically in the vertical direction with the  ""y = 0 line (hereinafter x-axis) ""but not otherwise. In Fig (A),(B), and (D), the ""bundle of curves"" (see green box and orange box in Fig (A)') is asymmetry with the x-axis: The convergence of the negative part (see the orange box in Fig (A)') is faster than that of the positive part(see green rectangle). At first glance, Figure (C) seems to converge faster than others, but in fact, the convergence of Figure (C) is the slowest. (Note that, in Figure (B)-(D), the x-axis starts at 2, but in A the x-axis starts at 4.)The point where the “bundle of curves"" converge to 0 is around x=4 for (B), around x=4.5 for (D), and around x=5 for (A). Fig (A)':Fig (A) 'is an annotated version of following Fig (A). Quiz: In Japan, if you make a donation to a local government using the program called ""Furusato Tax Payment (hometown tax donation program),"" you can receive a return gift.  A total of 1,741 local governments accept the Furusato Tax Payment program. Return gifts are classified into 166 categories. The number of categories of return gifts offered vary for each local government.  For example, some local governments offer three categories out of 166 categories of return gifts, and other local governments only provide one category. The following model formula expresses the amount of donation collected by each local government using this system: Hereinafter, the following formula is referred to as (Formula 1). Here, ${y}_{i}$ are objective variable represent the the amount of donation   collected by $i$ th local government. ${x}_{1,i}$ are explanatory   variable represent the population of $i$ th local government. ${x}_{2,i}$ are explanatory variable represent the number of return   gifts offered by $i$ th local government. ${x}_{k,i}$ ( $k=3,4,...,166+3-1$ ) are explanatory variable (dummy   variables). If the $i$ th local government can offer the $l$ th   ( $l=1,2,...,166$ )  return gift, then ${x}_{l+3-1,i}=1$ and   otherwise, ${x}_{l+3-1,i}=0$ . ${u}_{i}$ are error term. All explanatory variables are standardized to mean 0 and variance 1. Regression coefficients were estimated by elastic net regression that minimizes the following equation: Hereinafter, the following formula is referred to as (Formula 2). The following Figs (A) to (D) are solution paths in which the estimated regression coefficients are plotted against log (λ). The numerical value at the top of each graph represents the number of explanatory variables with nonzero regression coefficients.  For Figs A to D, the α is any one of 0, 0.5, 0.7, and 1. Select the best answer from Figures (A) to (D) as the solution path when α = 0.5. Figs. (A)-(D). Reference: (Ref.1) . Quiz No.10-2 of the exam of the ""2018's semi-first grade of Japan Statistical Society Certificate"" is stored in the following URL. (Written in Japanease) That is an excerpt of only the part related to this quiz. Link (Ref.2) . StatQuest with Josh Starmer; Regularization Part 3: Elastic Net Regression. P.S. I'm not very good at English, so I'm sorry if I have some impolite or unclear expressions.","The following Quiz is the rough translation (with minor modifications) of Quiz No.10-2 of the exam of the ""2018's semi-first grade of Japan Statistical Society Certificate"" (see Ref (1)) "".  According to the official answer, the  correct  answer is (A) (See Fig (A) below.). However, I cannot imagine how to achieve the correct answer. My question: How to achieve the correct answer of following Quiz? How the α affects the solution path in the elastic net?   Which α correspond to Figures (B), (C), and (D) ?(As described in official answer, the α of Fig (A) is 0.5. However, There is no description about ""What are the α corresponding to other figures?"") I recognized the following features. These features might be the key to discriminate α … . However, I cannot imagine how to achieve the correct answer. As lambda gets larger, the parameter estimates get smaller (Ref (2)). Only in Figure (C), the shape of the graph seems very different. Only Figure (C) seems roughly symmetrically in the vertical direction with the  ""y = 0 line (hereinafter x-axis) ""but not otherwise. In Fig (A),(B), and (D), the ""bundle of curves"" (see green box and orange box in Fig (A)') is asymmetry with the x-axis: The convergence of the negative part (see the orange box in Fig (A)') is faster than that of the positive part(see green rectangle). At first glance, Figure (C) seems to converge faster than others, but in fact, the convergence of Figure (C) is the slowest. (Note that, in Figure (B)-(D), the x-axis starts at 2, but in A the x-axis starts at 4.)The point where the “bundle of curves"" converge to 0 is around x=4 for (B), around x=4.5 for (D), and around x=5 for (A). Fig (A)':Fig (A) 'is an annotated version of following Fig (A). Quiz: In Japan, if you make a donation to a local government using the program called ""Furusato Tax Payment (hometown tax donation program),"" you can receive a return gift.  A total of 1,741 local governments accept the Furusato Tax Payment program. Return gifts are classified into 166 categories. The number of categories of return gifts offered vary for each local government.  For example, some local governments offer three categories out of 166 categories of return gifts, and other local governments only provide one category. The following model formula expresses the amount of donation collected by each local government using this system: Hereinafter, the following formula is referred to as (Formula 1). Here, are objective variable represent the the amount of donation   collected by th local government. are explanatory   variable represent the population of th local government. are explanatory variable represent the number of return   gifts offered by th local government. ( ) are explanatory variable (dummy   variables). If the th local government can offer the th   ( )  return gift, then and   otherwise, . are error term. All explanatory variables are standardized to mean 0 and variance 1. Regression coefficients were estimated by elastic net regression that minimizes the following equation: Hereinafter, the following formula is referred to as (Formula 2). The following Figs (A) to (D) are solution paths in which the estimated regression coefficients are plotted against log (λ). The numerical value at the top of each graph represents the number of explanatory variables with nonzero regression coefficients.  For Figs A to D, the α is any one of 0, 0.5, 0.7, and 1. Select the best answer from Figures (A) to (D) as the solution path when α = 0.5. Figs. (A)-(D). Reference: (Ref.1) . Quiz No.10-2 of the exam of the ""2018's semi-first grade of Japan Statistical Society Certificate"" is stored in the following URL. (Written in Japanease) That is an excerpt of only the part related to this quiz. Link (Ref.2) . StatQuest with Josh Starmer; Regularization Part 3: Elastic Net Regression. P.S. I'm not very good at English, so I'm sorry if I have some impolite or unclear expressions.","{y}_{i} i {x}_{1,i} i {x}_{2,i} i {x}_{k,i} k=3,4,...,166+3-1 i l l=1,2,...,166 {x}_{l+3-1,i}=1 {x}_{l+3-1,i}=0 {u}_{i}","['statistics', 'regression', 'machine-learning', 'linear-regression']"
83,how do you prove that the MLE is sufficient for an exponential family?,how do you prove that the MLE is sufficient for an exponential family?,,"I read (sorry only found such theorem in french https://perso.math.univ-toulouse.fr/jydauxoi/files/2013/11/cours_stat_inf_Master.pdf ) that whenever there exists an sufficient statistics for an exponential familly, then the maximum likelihood estimator is a function of it. I'd like to prove something lighter, how do you prove that the MLE of an exponential family is sufficient ? thank you.","I read (sorry only found such theorem in french https://perso.math.univ-toulouse.fr/jydauxoi/files/2013/11/cours_stat_inf_Master.pdf ) that whenever there exists an sufficient statistics for an exponential familly, then the maximum likelihood estimator is a function of it. I'd like to prove something lighter, how do you prove that the MLE of an exponential family is sufficient ? thank you.",,"['probability', 'statistics', 'statistical-inference']"
84,Prove that $\hat{\sigma^2}=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2$ is not an efficient estimator.,Prove that  is not an efficient estimator.,\hat{\sigma^2}=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2,"I am asked to show that the unbiased estimator $\hat{\sigma^2}=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2$ is not efficient. So far I was able to show that the Rao-Cramer Lower Bound is $\frac{2\sigma^4}{n}$ so I know that I need to find $Var[\hat{\sigma^2}]>RCLB$ . What I have tried here is to simply plug it in using the identity $$\sum_{i=1}^n (X_i-\bar{X})^2 = \sum_{i=1}^n X_i^2 - n\bar{X}^2$$ What makes me uncomfortable is that unlike expectation, I need to know whether these two terms are independent or not, and I do not know how to find $Var[\bar{X}^2]$ even if they were. I also tried to express the sum of square as $$\sum_{i=1}^n (X_i-\mu +\mu-\bar{X})^2 = \sigma^2 \left[ \sum_{i=1}^n\left(\frac{X_i-\bar{X}}{\sigma}\right)^2 - 2\left(\frac{X_i-\bar{X}}{\sigma}\right)\sum_{i=1}^n\left( \frac{X_i-\mu}{\sigma} \right) + n\left( \frac{\bar{X}-\mu}{\sigma} \right)^2 \right]$$ hoping that $\chi_{n}^2$ and $N(0,1)$ could come into play but I face the same issue again. I would appreciate your input.","I am asked to show that the unbiased estimator is not efficient. So far I was able to show that the Rao-Cramer Lower Bound is so I know that I need to find . What I have tried here is to simply plug it in using the identity What makes me uncomfortable is that unlike expectation, I need to know whether these two terms are independent or not, and I do not know how to find even if they were. I also tried to express the sum of square as hoping that and could come into play but I face the same issue again. I would appreciate your input.","\hat{\sigma^2}=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2 \frac{2\sigma^4}{n} Var[\hat{\sigma^2}]>RCLB \sum_{i=1}^n (X_i-\bar{X})^2 = \sum_{i=1}^n X_i^2 - n\bar{X}^2 Var[\bar{X}^2] \sum_{i=1}^n (X_i-\mu +\mu-\bar{X})^2 = \sigma^2 \left[ \sum_{i=1}^n\left(\frac{X_i-\bar{X}}{\sigma}\right)^2 - 2\left(\frac{X_i-\bar{X}}{\sigma}\right)\sum_{i=1}^n\left( \frac{X_i-\mu}{\sigma} \right) + n\left( \frac{\bar{X}-\mu}{\sigma} \right)^2 \right] \chi_{n}^2 N(0,1)","['statistics', 'variance', 'parameter-estimation']"
85,"If $Y \sim \operatorname{Gamma}(a+1, 1), U_0 \sim \operatorname{Unif}(0, 1), U = U_0^\frac1a$, why $YU \sim \operatorname{Gamma} (a, 1)$?","If , why ?","Y \sim \operatorname{Gamma}(a+1, 1), U_0 \sim \operatorname{Unif}(0, 1), U = U_0^\frac1a YU \sim \operatorname{Gamma} (a, 1)","Given random variables like below: $Y \sim \operatorname{Gamma}(a + 1, 1)$ $U_0 \sim \operatorname{Unif}(0,1)$ $U = U_0^\frac1a$ If $Y$ and $U_0$ is independent, How can I proof $X=YU \sim \operatorname{Gamma}(a, 1)$ ? I tried to solve this problem with theorem $f_{U,V}(u,v) = f_{X,Y}(h_1(u,v), h_2(u,v))|J|$ But I'm confusing what should be preimage.","Given random variables like below: If and is independent, How can I proof ? I tried to solve this problem with theorem But I'm confusing what should be preimage.","Y \sim \operatorname{Gamma}(a + 1, 1) U_0 \sim \operatorname{Unif}(0,1) U = U_0^\frac1a Y U_0 X=YU \sim \operatorname{Gamma}(a, 1) f_{U,V}(u,v) = f_{X,Y}(h_1(u,v), h_2(u,v))|J|","['statistics', 'probability-distributions']"
86,"Show that $\min\{X_{1},X_{2},\ldots,X_{n}\}$ is sufficient for $\mu$ when $\sigma$ is fixed",Show that  is sufficient for  when  is fixed,"\min\{X_{1},X_{2},\ldots,X_{n}\} \mu \sigma","Let $X_{1},X_{2},\ldots,X_{n}$ be a sample from a population with density $p(x,\theta)$ given by \begin{align*} p(x,\theta) = \frac{1}{\sigma}\exp\left\{-\left(\frac{x-\mu}{\sigma}\right)\right\} \end{align*} if $x\geq \mu$ and $0$ otherwise. Here $\theta = (\mu,\sigma)$ with $-\infty < \mu < \infty$ and $\sigma > 0$ . (a) Show that $\min\{X_{1},X_{2},\ldots,X_{n}\}$ is sufficient for $\mu$ when $\sigma$ is fixed. (b) Find a one-dimensional sufficient statistic for $\sigma$ when $\mu$ is fixed. (c) Exhibit a two-dimensional sufficient statistic for $\theta$ . MY ATTEMPT (b) In the first place, let us determine the maximum likelihood function for this sample considering that $\mu$ is fixed: \begin{align*} L(\textbf{x},\theta) = \prod_{i=1}^{n}\frac{1}{\sigma}\exp\left\{-\left(\frac{x_{i}-\mu}{\sigma}\right)\right\} = \frac{1}{\sigma^{n}}\exp\left\{-\frac{1}{\sigma}\left(\sum_{i=1}^{n}x_{i} - n\mu\right)\right\} \end{align*} In this case, we can factor $L(\textbf{x},\theta) = h(x)g_{\sigma}(T(\textbf{x}))$ , where \begin{align*} h(x) = 1\quad\text{and}\quad g_{\sigma}(T(\textbf{x})) = \frac{1}{\sigma^{n}}\exp\left\{-\frac{1}{\sigma}\left(\sum_{i=1}^{n}x_{i} - n\mu\right)\right\} \end{align*} Therefore the statistic $T(\textbf{x}) = \sum_{i=1}^{n}x_{i}$ is sufficient for $\sigma$ . But I do not know if this is right neither do I know how to approach the other two items. Can somebody help me out? Thanks in advance!","Let be a sample from a population with density given by if and otherwise. Here with and . (a) Show that is sufficient for when is fixed. (b) Find a one-dimensional sufficient statistic for when is fixed. (c) Exhibit a two-dimensional sufficient statistic for . MY ATTEMPT (b) In the first place, let us determine the maximum likelihood function for this sample considering that is fixed: In this case, we can factor , where Therefore the statistic is sufficient for . But I do not know if this is right neither do I know how to approach the other two items. Can somebody help me out? Thanks in advance!","X_{1},X_{2},\ldots,X_{n} p(x,\theta) \begin{align*}
p(x,\theta) = \frac{1}{\sigma}\exp\left\{-\left(\frac{x-\mu}{\sigma}\right)\right\}
\end{align*} x\geq \mu 0 \theta = (\mu,\sigma) -\infty < \mu < \infty \sigma > 0 \min\{X_{1},X_{2},\ldots,X_{n}\} \mu \sigma \sigma \mu \theta \mu \begin{align*}
L(\textbf{x},\theta) = \prod_{i=1}^{n}\frac{1}{\sigma}\exp\left\{-\left(\frac{x_{i}-\mu}{\sigma}\right)\right\} = \frac{1}{\sigma^{n}}\exp\left\{-\frac{1}{\sigma}\left(\sum_{i=1}^{n}x_{i} - n\mu\right)\right\}
\end{align*} L(\textbf{x},\theta) = h(x)g_{\sigma}(T(\textbf{x})) \begin{align*}
h(x) = 1\quad\text{and}\quad g_{\sigma}(T(\textbf{x})) = \frac{1}{\sigma^{n}}\exp\left\{-\frac{1}{\sigma}\left(\sum_{i=1}^{n}x_{i} - n\mu\right)\right\}
\end{align*} T(\textbf{x}) = \sum_{i=1}^{n}x_{i} \sigma","['statistics', 'self-learning', 'statistical-inference', 'maximum-likelihood']"
87,Comparing the Markov and Chebyshev's inequalities,Comparing the Markov and Chebyshev's inequalities,,"This question was given to me as a review for an upcoming exam. Let X be a positive random variable with mean 3 and variance $\frac{1}{4}$ . Use Chebyshev's and Markov's inequalities to obtain the probability that $X \geq 6$ . Also give an example of such an X My work thus far: Chebyshev's $P(|X-\overline{x}| \geq a) \leq \frac{\sigma^{2}}{a^2} $ $P(X -3 \geq6-3) \leq \frac{\frac{1}{4}}{3^2} = \frac{1}{36}$ Markov's $P(X \gt a) \leq \frac{E[X]}{a}$ $P(X \gt 6) \leq \frac{3}{6}= \frac{1}{2}$ I feel as though I've made an error somewhere, could someone help me figure out where?","This question was given to me as a review for an upcoming exam. Let X be a positive random variable with mean 3 and variance . Use Chebyshev's and Markov's inequalities to obtain the probability that . Also give an example of such an X My work thus far: Chebyshev's Markov's I feel as though I've made an error somewhere, could someone help me figure out where?",\frac{1}{4} X \geq 6 P(|X-\overline{x}| \geq a) \leq \frac{\sigma^{2}}{a^2}  P(X -3 \geq6-3) \leq \frac{\frac{1}{4}}{3^2} = \frac{1}{36} P(X \gt a) \leq \frac{E[X]}{a} P(X \gt 6) \leq \frac{3}{6}= \frac{1}{2},"['probability', 'statistics']"
88,Population vs Sampling Frame vs Sample,Population vs Sampling Frame vs Sample,,"Could someone please explain how the sampling frame is different from population and sample? I understand that the population is all the sampling unit that match our criteria for the study. And the sample is those select few who participate in the study. Now, the different answers I have gone through suggests that the sampling frame is from where you draw your sample. But don't we draw our sample from the population? And if the sampling frame defines the criteria for sampling, then how that criterion is different from the criteria we laid down to define our population. Hope I am clear with the question!! Thanks in advance!!","Could someone please explain how the sampling frame is different from population and sample? I understand that the population is all the sampling unit that match our criteria for the study. And the sample is those select few who participate in the study. Now, the different answers I have gone through suggests that the sampling frame is from where you draw your sample. But don't we draw our sample from the population? And if the sampling frame defines the criteria for sampling, then how that criterion is different from the criteria we laid down to define our population. Hope I am clear with the question!! Thanks in advance!!",,"['statistics', 'sampling']"
89,Are are infinitely many intimate pairs of integers?,Are are infinitely many intimate pairs of integers?,,"Using the standard statistical definitions, the variance of $x_1, x_2, \ldots, x_n$ and the squared errors about its mean $\mu$ are given by $\sigma^2 = \sum_i(x_i - \mu)^2/n$ and $\delta_2 = \sum_i(x_i - \mu)^2 = n\sigma^2$ respectively. Definition 1 : The variance and the squared error of an integer is defined as the variance and the squared error of its positive divisors   respectively. I found that: There are distinct integer pairs whose variances are equal. The smallest such pair is $(691, 817)$ . Let us call them equivarient integers. There are integer pairs whose squared errors are equal. The smallest such pair is $(45, 53)$ . The more interesting fact is that there are equivarient pairs which have the same number of divisors and hence their squared errors are also equal. We define: Definition 2 : Two distinct integers are said to be an intimate pair if they are have the same number of divisors and the same   variance. The first few intimate pairs are $(1403,1461)$ , $(1564,1572)$ , $(2068,2076)$ , $(2249,2305)$ , $(3397,3493)$ , $(7871,8193)$ , $ (23903,24101)$ , $(61769, 64443)$ . Questions : Are there infinitely many intimate pairs? Are there three or more integers that are intimate ( and what should we call them hahaha) Note : Please let me know in case there is any reference in literature. I could not find any. Posted to MO since it is unanswered in MSE","Using the standard statistical definitions, the variance of and the squared errors about its mean are given by and respectively. Definition 1 : The variance and the squared error of an integer is defined as the variance and the squared error of its positive divisors   respectively. I found that: There are distinct integer pairs whose variances are equal. The smallest such pair is . Let us call them equivarient integers. There are integer pairs whose squared errors are equal. The smallest such pair is . The more interesting fact is that there are equivarient pairs which have the same number of divisors and hence their squared errors are also equal. We define: Definition 2 : Two distinct integers are said to be an intimate pair if they are have the same number of divisors and the same   variance. The first few intimate pairs are , , , , , , , . Questions : Are there infinitely many intimate pairs? Are there three or more integers that are intimate ( and what should we call them hahaha) Note : Please let me know in case there is any reference in literature. I could not find any. Posted to MO since it is unanswered in MSE","x_1, x_2, \ldots, x_n \mu \sigma^2 = \sum_i(x_i - \mu)^2/n \delta_2 = \sum_i(x_i - \mu)^2 = n\sigma^2 (691, 817) (45, 53) (1403,1461) (1564,1572) (2068,2076) (2249,2305) (3397,3493) (7871,8193)  (23903,24101) (61769, 64443)","['number-theory', 'elementary-number-theory', 'statistics', 'prime-numbers', 'divisibility']"
90,How many degrees of freedom does a rank-1 matrix have?,How many degrees of freedom does a rank-1 matrix have?,,"Perhaps a stupid question, but I never formally learned exactly what ""degrees of freedom"" are. Let $X = a b^T$ where $a \in \mathbf{R}^m$ and $b \in \mathbf{R}^n$ . Am I correct in thinking that $X$ has $m+n$ degrees of freedom since it's specified by $m+n$ numbers?","Perhaps a stupid question, but I never formally learned exactly what ""degrees of freedom"" are. Let where and . Am I correct in thinking that has degrees of freedom since it's specified by numbers?",X = a b^T a \in \mathbf{R}^m b \in \mathbf{R}^n X m+n m+n,"['linear-algebra', 'statistics']"
91,Average more accurate than individual guesses,Average more accurate than individual guesses,,I once saw a documentary where a man enters building with a big jar filled with candies and he would go person to person asking them how much candies they believe were in the jar. The building had little over 200 people. From those 200 none got the number right. Not even close. But then he did something. He added up all the numbers that were given to him and calculated the average. The number was almost spot on! Is this principla actually real and if it is what is it called and how does it work?,I once saw a documentary where a man enters building with a big jar filled with candies and he would go person to person asking them how much candies they believe were in the jar. The building had little over 200 people. From those 200 none got the number right. Not even close. But then he did something. He added up all the numbers that were given to him and calculated the average. The number was almost spot on! Is this principla actually real and if it is what is it called and how does it work?,,['statistics']
92,Normal Distribution Or Student Distribution?,Normal Distribution Or Student Distribution?,,"If you throw a coin in a vending machine, the coin is being weighed by the machine to determine its value. For statistical purposes, you decide to throw $10$ fifty-cent coins in vending machine A. This results in a sample mean of $7.49$ $g$ and a sample variance of $0.011$ $g^2$ . You may assume a normal distribution as model distribution for the measurements. Construct a $95%$ confidence interval for the mean weight $μ_A$ of a fity-cent coin thrown in machine $A$ . In this exercise, you'll use the student distribution or the standard normal distribution to construct the confidence interval? I know that they say 'You may assume a normal distribution as model distribution for the measurements' but they also give you the sample variance (that is used with the student distribution) and not the variance. Furthermore, $n=10$ is quite small, so, in my opinion, I should use the student distribution, it's correct?","If you throw a coin in a vending machine, the coin is being weighed by the machine to determine its value. For statistical purposes, you decide to throw fifty-cent coins in vending machine A. This results in a sample mean of and a sample variance of . You may assume a normal distribution as model distribution for the measurements. Construct a confidence interval for the mean weight of a fity-cent coin thrown in machine . In this exercise, you'll use the student distribution or the standard normal distribution to construct the confidence interval? I know that they say 'You may assume a normal distribution as model distribution for the measurements' but they also give you the sample variance (that is used with the student distribution) and not the variance. Furthermore, is quite small, so, in my opinion, I should use the student distribution, it's correct?",10 7.49 g 0.011 g^2 95% μ_A A n=10,['statistics']
93,What is the relationship between probability densities and mass densities?,What is the relationship between probability densities and mass densities?,,"In statistics we have probability distribution functions which give us likelihood that some random variable ( $X$ ) will equal a particular value. Assuming this variable is continuous, the distribution satisfies: $$ \int f_{X}(x) \ dx = 1 $$ and can be used to obtain the moments of the variable \begin{align} \mu'_i = \int X^i f_x(x) dx \end{align} In physics we often work with the mass distribution function which describes the distribution of mass. For example the total mass across a system is given by: $$ M_{tot} = \int g_M(m) \ dm $$ and like the statistical PDF we can also derive moments of this mass distribution function by integrating across the distribution function: $$ \mu'_i = \int m g_M(m) \ dm $$ I am wondering what the connection between these two concepts is and if there is any way to move between them?","In statistics we have probability distribution functions which give us likelihood that some random variable ( ) will equal a particular value. Assuming this variable is continuous, the distribution satisfies: and can be used to obtain the moments of the variable In physics we often work with the mass distribution function which describes the distribution of mass. For example the total mass across a system is given by: and like the statistical PDF we can also derive moments of this mass distribution function by integrating across the distribution function: I am wondering what the connection between these two concepts is and if there is any way to move between them?","X 
\int f_{X}(x) \ dx = 1
 \begin{align}
\mu'_i = \int X^i f_x(x) dx
\end{align} 
M_{tot} = \int g_M(m) \ dm
 
\mu'_i = \int m g_M(m) \ dm
","['statistics', 'probability-distributions', 'physics']"
94,How to find the probability of a 'mean shift' in a random process?,How to find the probability of a 'mean shift' in a random process?,,"How would I go about calculating the probability that the observed mean of a collection of data generated by a random process, which is governed by a particular statistical model, would deviate from the theoretical mean by a given amount? For example, the sum of the rolls of two six-sided dice in theory follows a statistical model that resembles a Gaussian probability distribution curve, between the numbers 2 and 12, with a mean of 7. If I was to roll and sum the results of two dice 100 times, how can I calculate the probability that the observed mean of data would be 6, rather than 7? In other words, if I was to do that test 100 times and the observed mean was calculated to be 6, how can I calculate the probability that the deviation in the mean could be because of random chance, as opposed to the underlying (assumed) statistical model being incorrect (i.e. the dice being biased)? I know some basic statistics, but I'm far from an expert. I would think that the observed mean of a particular statistical sample would have a probability distribution of its own, but I'm not sure how it could be calculated.","How would I go about calculating the probability that the observed mean of a collection of data generated by a random process, which is governed by a particular statistical model, would deviate from the theoretical mean by a given amount? For example, the sum of the rolls of two six-sided dice in theory follows a statistical model that resembles a Gaussian probability distribution curve, between the numbers 2 and 12, with a mean of 7. If I was to roll and sum the results of two dice 100 times, how can I calculate the probability that the observed mean of data would be 6, rather than 7? In other words, if I was to do that test 100 times and the observed mean was calculated to be 6, how can I calculate the probability that the deviation in the mean could be because of random chance, as opposed to the underlying (assumed) statistical model being incorrect (i.e. the dice being biased)? I know some basic statistics, but I'm far from an expert. I would think that the observed mean of a particular statistical sample would have a probability distribution of its own, but I'm not sure how it could be calculated.",,"['statistics', 'means']"
95,Combining chi square charecterisitc,Combining chi square charecterisitc,,"I am reading Statistics by David Freedman Suppose the same die had been used to generate the data in tables 4A and 4C   (p. 531), rolling it first 60 times for table 4A, and then 600 times for table 4C. Can   you pool the results of the two tests? If so, how? The author then pools the two tests as Pooled $\chi^2$ = 13.2 + 10 = 23.2, d = 5 + 5 = 10, p $\approx$ 1 %. My question is, why can't we sum the two table to create new frequency table like this(since same dice is used) and then compute the $\chi^2$ statistic with 5 degree of freedom?","I am reading Statistics by David Freedman Suppose the same die had been used to generate the data in tables 4A and 4C   (p. 531), rolling it first 60 times for table 4A, and then 600 times for table 4C. Can   you pool the results of the two tests? If so, how? The author then pools the two tests as Pooled = 13.2 + 10 = 23.2, d = 5 + 5 = 10, p 1 %. My question is, why can't we sum the two table to create new frequency table like this(since same dice is used) and then compute the statistic with 5 degree of freedom?",\chi^2 \approx \chi^2,"['statistics', 'hypothesis-testing', 'chi-squared']"
96,When an MLE attains the Cramer-Rao bound for an exponential family.,When an MLE attains the Cramer-Rao bound for an exponential family.,,"I'm trying to do the following exercise: Let $$\delta_\theta(x)=S(x)\exp (\theta T(x)-f(\theta))$$ be a family of densities for a random variable $X:\Omega\rightarrow   \mathbb{R}$ , where $\theta$ takes values in an open interval, and $T:\mathbb{R}\rightarrow \mathbb{R}$ is a non-constant function.    Suppose the maximum likelihood estimator $\hat{\theta}(x)$ exists and has   finite variance for all $\theta$ .  Prove that $\hat{\theta}(x)$ attains   the Cramer-Rao lower bound for all $\theta$ if and only if $f'(\theta)$ has the form $\alpha \theta+\beta$ for constants $\alpha$ and $\beta$ . At present, all i know about the MLE $\hat\theta$ is that, for given $x\in \mathbb{R}$ , it is the solution to $$f'(\hat\theta) = T(x) \label{a}\tag{1}$$ On its face, the question doesn't make much sense to me, since the book hasn't given me any information about the bias of $\hat{\theta}$ .  So in principle, the Cramer-Rao lower bound $$Var(\hat{\theta})\geq \frac{[\frac{d}{d\theta}(\mathbb{E}_\theta[\hat{\theta}(x)])]^2}{\mathbb{E}_\theta[( \frac{\partial}{\partial\theta}\log \delta_\theta(x))^2]}$$ isn't really a lower bound, since the numerator depends on the estimator $\hat{\theta}$ .  And the numerator could be zero, in principle. Setting that aside, I think what the question wants me to do is just to write down the condition where the Cauchy-Schwarz inequality (used in the proof of the Cramer-Rao lower bound) gives equality:  We have $$\frac{d}{d\theta}\mathbb{E}_\theta[\hat \theta(x)]=\frac{d}{d\theta}\int_\mathbb{R}\hat \theta(x) \delta_\theta(x) ~~dx=\int_\mathbb{R}\hat \theta(x)~\cdot~\frac{\partial}{\partial \theta} \delta_\theta(x)~\cdot~\delta_\theta(x)^{-1}~\cdot~\delta_\theta(x)~~dx=$$ $$\int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])~\cdot~\frac{\partial}{\partial \theta} \delta_\theta(x)~\cdot~\delta_\theta(x)^{-1}~\cdot~\delta_\theta(x)~~dx ~~~\text{(since}\int_\mathbb{R}[\frac{\partial}{\partial \theta} \delta_\theta(x)]\delta_\theta(x)^{-1}\cdot~\delta_\theta(x)dx=0 \text{)}$$ $$= \int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])~\cdot~[T(x)-f'(\theta)]~\cdot~\delta_\theta(x)~~dx\leq \sqrt{\int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])^2~ \delta_\theta(x)~dx \cdot  \int_\mathbb{R}[T(x)-f'(\theta)]^2~\delta_\theta(x)~~dx}=$$ $$\sqrt{Var(\hat \theta) \cdot  \int_\mathbb{R}[T(x)-f'(\theta)]^2~\delta_\theta(x)~~dx}$$ Whereas if we wanted equality we would need $$\hat \theta(x)-\mathbb{E}_\theta[\hat \theta]= C(\theta)\cdot[T(x)-f'(\theta)] $$ where $C(\theta)$ is a constant depending only on $\theta$ . At this point I am totally stuck. And I haven't even used equation \ref{a}.","I'm trying to do the following exercise: Let be a family of densities for a random variable , where takes values in an open interval, and is a non-constant function.    Suppose the maximum likelihood estimator exists and has   finite variance for all .  Prove that attains   the Cramer-Rao lower bound for all if and only if has the form for constants and . At present, all i know about the MLE is that, for given , it is the solution to On its face, the question doesn't make much sense to me, since the book hasn't given me any information about the bias of .  So in principle, the Cramer-Rao lower bound isn't really a lower bound, since the numerator depends on the estimator .  And the numerator could be zero, in principle. Setting that aside, I think what the question wants me to do is just to write down the condition where the Cauchy-Schwarz inequality (used in the proof of the Cramer-Rao lower bound) gives equality:  We have Whereas if we wanted equality we would need where is a constant depending only on . At this point I am totally stuck. And I haven't even used equation \ref{a}.","\delta_\theta(x)=S(x)\exp (\theta T(x)-f(\theta)) X:\Omega\rightarrow 
 \mathbb{R} \theta T:\mathbb{R}\rightarrow \mathbb{R} \hat{\theta}(x) \theta \hat{\theta}(x) \theta f'(\theta) \alpha \theta+\beta \alpha \beta \hat\theta x\in \mathbb{R} f'(\hat\theta) = T(x) \label{a}\tag{1} \hat{\theta} Var(\hat{\theta})\geq \frac{[\frac{d}{d\theta}(\mathbb{E}_\theta[\hat{\theta}(x)])]^2}{\mathbb{E}_\theta[( \frac{\partial}{\partial\theta}\log \delta_\theta(x))^2]} \hat{\theta} \frac{d}{d\theta}\mathbb{E}_\theta[\hat \theta(x)]=\frac{d}{d\theta}\int_\mathbb{R}\hat \theta(x) \delta_\theta(x) ~~dx=\int_\mathbb{R}\hat \theta(x)~\cdot~\frac{\partial}{\partial \theta} \delta_\theta(x)~\cdot~\delta_\theta(x)^{-1}~\cdot~\delta_\theta(x)~~dx= \int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])~\cdot~\frac{\partial}{\partial \theta} \delta_\theta(x)~\cdot~\delta_\theta(x)^{-1}~\cdot~\delta_\theta(x)~~dx ~~~\text{(since}\int_\mathbb{R}[\frac{\partial}{\partial \theta} \delta_\theta(x)]\delta_\theta(x)^{-1}\cdot~\delta_\theta(x)dx=0 \text{)} = \int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])~\cdot~[T(x)-f'(\theta)]~\cdot~\delta_\theta(x)~~dx\leq \sqrt{\int_\mathbb{R}(\hat \theta(x)-\mathbb{E}_\theta[\hat \theta])^2~ \delta_\theta(x)~dx \cdot  \int_\mathbb{R}[T(x)-f'(\theta)]^2~\delta_\theta(x)~~dx}= \sqrt{Var(\hat \theta) \cdot  \int_\mathbb{R}[T(x)-f'(\theta)]^2~\delta_\theta(x)~~dx} \hat \theta(x)-\mathbb{E}_\theta[\hat \theta]= C(\theta)\cdot[T(x)-f'(\theta)]  C(\theta) \theta","['probability', 'statistics']"
97,What is log-utility?,What is log-utility?,,"I came across this problem today: Calculate the log-utility optimal fraction of your capital to bet on a fair coin flip where you win $x$ on heads and lose $y$ on tails. What is the meaning of log-utility in log-utility optimal fraction? Is this an portfolio management term or a statistics term? Apologies if this is in the wrong SE, please close this if it’s irrelevant!","I came across this problem today: Calculate the log-utility optimal fraction of your capital to bet on a fair coin flip where you win on heads and lose on tails. What is the meaning of log-utility in log-utility optimal fraction? Is this an portfolio management term or a statistics term? Apologies if this is in the wrong SE, please close this if it’s irrelevant!",x y,"['probability', 'statistics', 'utility']"
98,Conjugate Prior for Gamma Distribution,Conjugate Prior for Gamma Distribution,,"This is very basic, but I have been stuck on this problem for a while. Suppose $Y_1, \dots, Y_n|\alpha,\beta\sim Gamma(\alpha, \beta)$ is iid with $\alpha$ known. I want conjugate prior for $\beta$ and the posterior. My work: $p(\beta|y_1, \dots, y_n)=p(y_1, \dots, y_n|\beta)p(\beta)=(\prod_{i=1}^{n} y_i)^{\alpha-1} \exp(-\beta\sum_{i} y_i) p(\beta)$ $\propto \exp(-\beta\sum_{i} y_i) p(\beta)$ . Therefore, the conjugate prior for $\beta$ would be gamma $(\alpha_0, \beta_0)$ . In this case, we can derive the posterior as: $p(\beta|y_1,\dots, y_n)\propto \beta^{\alpha_0 -1} \exp(-\beta(\sum_{i} y_i+\beta_0))$ . So, the posterior is gamma $(\alpha_0 , \sum_{i} y_i+\beta_0)$ . However, Wikipedia says the posterior should be gamma $(\alpha_0 +n\alpha, \sum_{i} y_i+\beta_0)$ . I don't understand where does $n\alpha$ come from. I also don't understand why my derivation is not correct. Thanks in advance!","This is very basic, but I have been stuck on this problem for a while. Suppose is iid with known. I want conjugate prior for and the posterior. My work: . Therefore, the conjugate prior for would be gamma . In this case, we can derive the posterior as: . So, the posterior is gamma . However, Wikipedia says the posterior should be gamma . I don't understand where does come from. I also don't understand why my derivation is not correct. Thanks in advance!","Y_1, \dots, Y_n|\alpha,\beta\sim Gamma(\alpha, \beta) \alpha \beta p(\beta|y_1, \dots, y_n)=p(y_1, \dots, y_n|\beta)p(\beta)=(\prod_{i=1}^{n} y_i)^{\alpha-1} \exp(-\beta\sum_{i} y_i) p(\beta) \propto \exp(-\beta\sum_{i} y_i) p(\beta) \beta (\alpha_0, \beta_0) p(\beta|y_1,\dots, y_n)\propto \beta^{\alpha_0 -1} \exp(-\beta(\sum_{i} y_i+\beta_0)) (\alpha_0 , \sum_{i} y_i+\beta_0) (\alpha_0 +n\alpha, \sum_{i} y_i+\beta_0) n\alpha","['statistics', 'probability-distributions', 'conditional-probability', 'bayesian', 'gamma-distribution']"
99,UMVUE of $E[X^2]$ where $X_i$ is Poisson $(\lambda)$,UMVUE of  where  is Poisson,E[X^2] X_i (\lambda),"I am working on a problem to find the UMVUE of a function. Let $X_1, X_2, ..., X_n$ be i.i.d. Poison $(\lambda)$ . Find the UMVUE of E[ $X^2$ ]. So far I understand that $$E[X^2]=Var[X]+E[X]^2=\lambda+\lambda^2$$ and thus $$\begin{align}  E[\hat{\lambda}_{MLE}^2] & = \bar{X}(1+\bar{X})\\ \end{align}$$ Now the goal is to adjust this so that it is unbiased, so I did $$\begin{align} E[\bar{X}(1+\bar{X})] &= E[\bar{X}]+Var[\bar{X}]+E[\bar{X}]^2\\ &= \lambda +\lambda/n +\lambda^2 \end{align} $$ And then I could not proceed from there. The notes that I received mentions that we do something from here but it was not explicit and I am not sure how to make this unbiased. Thank you in advance.","I am working on a problem to find the UMVUE of a function. Let be i.i.d. Poison . Find the UMVUE of E[ ]. So far I understand that and thus Now the goal is to adjust this so that it is unbiased, so I did And then I could not proceed from there. The notes that I received mentions that we do something from here but it was not explicit and I am not sure how to make this unbiased. Thank you in advance.","X_1, X_2, ..., X_n (\lambda) X^2 E[X^2]=Var[X]+E[X]^2=\lambda+\lambda^2 \begin{align}
 E[\hat{\lambda}_{MLE}^2] & = \bar{X}(1+\bar{X})\\
\end{align} \begin{align}
E[\bar{X}(1+\bar{X})] &= E[\bar{X}]+Var[\bar{X}]+E[\bar{X}]^2\\
&= \lambda +\lambda/n +\lambda^2
\end{align}
","['statistics', 'statistical-inference', 'poisson-distribution', 'parameter-estimation']"
