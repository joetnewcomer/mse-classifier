,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Proof: $Y$ stochastically dominates $X$ implies $E[\phi(Y)]\geq E[\phi(X)]$ for increasing $\phi$,Proof:  stochastically dominates  implies  for increasing,Y X E[\phi(Y)]\geq E[\phi(X)] \phi,"Suppose $X$ and $Y$ are real random variables with CDF $F$ and $G$ such that $F(x)\geq G(x)$ (i.e. $Y$ exhibits (first-order) stochastic dominance over $X$). Then, for all increasing function $\phi$, we have $E[\phi(Y)]\geq E[\phi(X)]$. I would like to find a rigorous proof of this. Can you please provide one or point me to a reference? For the special case in which both $F$ and $G$ are continuous, one can consider the integral $$ \int \phi(y)dG(y) $$ and employ the substitution $y\to\varphi(x)$ where $\varphi(x)\equiv G^{-1}[F(x)]$ to infer that $$ E[\phi(Y)]=\int\phi(y)dG(y){\color{red}=}\int\phi[\varphi(x)]dF(x)\geq\int\phi(x)dF(x)=E[\phi(X)]. $$ The inequality above is because $$ F(x)\geq G(x)\implies\varphi(x)=G^{-1}[F(x)]\geq G^{-1}[G(x)]{\color{blue}=}x;\quad \phi\text{ is increasing.} $$ I've made some attempt for when $F$ and $G$ are general by considering $\varphi(x)=G^*[F(x)]$ where $G^*$ now is the (left-continuous) quantile function of $Y$. I've run into at least 2 problems: (i) I don't think the equality ${\color{red}=}$ above continues to hold; (ii) $G^*[G(x)]\leq x$ so ${\color{blue}=}$ above is turned into $\leq$ which breaks the inequality chain. A rigorous proof can also follow from a different direction. But this different direction relies on a construction I don't know how to do.","Suppose $X$ and $Y$ are real random variables with CDF $F$ and $G$ such that $F(x)\geq G(x)$ (i.e. $Y$ exhibits (first-order) stochastic dominance over $X$). Then, for all increasing function $\phi$, we have $E[\phi(Y)]\geq E[\phi(X)]$. I would like to find a rigorous proof of this. Can you please provide one or point me to a reference? For the special case in which both $F$ and $G$ are continuous, one can consider the integral $$ \int \phi(y)dG(y) $$ and employ the substitution $y\to\varphi(x)$ where $\varphi(x)\equiv G^{-1}[F(x)]$ to infer that $$ E[\phi(Y)]=\int\phi(y)dG(y){\color{red}=}\int\phi[\varphi(x)]dF(x)\geq\int\phi(x)dF(x)=E[\phi(X)]. $$ The inequality above is because $$ F(x)\geq G(x)\implies\varphi(x)=G^{-1}[F(x)]\geq G^{-1}[G(x)]{\color{blue}=}x;\quad \phi\text{ is increasing.} $$ I've made some attempt for when $F$ and $G$ are general by considering $\varphi(x)=G^*[F(x)]$ where $G^*$ now is the (left-continuous) quantile function of $Y$. I've run into at least 2 problems: (i) I don't think the equality ${\color{red}=}$ above continues to hold; (ii) $G^*[G(x)]\leq x$ so ${\color{blue}=}$ above is turned into $\leq$ which breaks the inequality chain. A rigorous proof can also follow from a different direction. But this different direction relies on a construction I don't know how to do.",,"['probability', 'probability-theory', 'reference-request']"
1,Poisson processes and coin flips,Poisson processes and coin flips,,"At time $0$, a coin that lands on heads with probability $p$ is flipped and lands on heads. At times chosen with a Poisson process of rate $\lambda$, the coin is flipped again. What is the probability that the coin is on its head at time $t$? Note: Flip means I toss the coin again. I'm having trouble with parsing this question, but also I don't know how I'd solve it any way I think about it. Am I renewing the Poisson process every time I flip? As in, flip, generate Poisson random number, flip again, generate Poison random number, flip again, etc. Or is the number generated by the Poisson process the regular interval between flips? And either way, how would I solve it?","At time $0$, a coin that lands on heads with probability $p$ is flipped and lands on heads. At times chosen with a Poisson process of rate $\lambda$, the coin is flipped again. What is the probability that the coin is on its head at time $t$? Note: Flip means I toss the coin again. I'm having trouble with parsing this question, but also I don't know how I'd solve it any way I think about it. Am I renewing the Poisson process every time I flip? As in, flip, generate Poisson random number, flip again, generate Poison random number, flip again, etc. Or is the number generated by the Poisson process the regular interval between flips? And either way, how would I solve it?",,"['probability', 'statistics', 'poisson-distribution']"
2,Find the probability that a geometric random variable $X$ is an even number,Find the probability that a geometric random variable  is an even number,X,"Let $\alpha$ be the probability that a geometric random variable $X$ with parameter p is an even number a) Find $\alpha$ using the identity $\alpha=\sum_{i=1}^{\infty}P[X=2i]$ b)Find $\alpha$ by conditioning on wether $X=1$ or $X>1$ My attempt for a): $$\alpha=\sum_{i=1}^{\infty}P[X=2i]=\sum_{i=1}^{\infty}p(1-p)^{2i-1}=p(1-p)\sum_{i=1}^{\infty}(1-p)^{2(i-1)}$$ Letting $j=i-1$ $$p(1-p)\sum_{i=1}^{\infty}(1-p)^{2(i-1)}=p(1-p)\sum_{j=0}^{\infty}(1-p)^{2j}={{p(1-p)}\over {1-(1-p)^2}}$$ hence $$\alpha={{1-p}\over {2-p}}$$ The thing is that I´m having trouble for b): Let $E$ be the event that a geometric random variable $X$ with parameter p is an even number, so : $P(E)=\alpha$ I need to find this probability by conditioning on wether $X=1$ or $X>1$ therefore: $$P(E)=P(E|X=1)P(X=1)+P(E|X>1)P(X>1)$$ but $P(E|X=1)=0$ hence $P(E)=P(E|X>1)P(X>1)$ then we have that $$P(X>1)=1-P(X\le 1)=1-p$$ But I´m having trouble computing $P(E|X>1)$ Can you help me please? I would really appreciate it :)","Let $\alpha$ be the probability that a geometric random variable $X$ with parameter p is an even number a) Find $\alpha$ using the identity $\alpha=\sum_{i=1}^{\infty}P[X=2i]$ b)Find $\alpha$ by conditioning on wether $X=1$ or $X>1$ My attempt for a): $$\alpha=\sum_{i=1}^{\infty}P[X=2i]=\sum_{i=1}^{\infty}p(1-p)^{2i-1}=p(1-p)\sum_{i=1}^{\infty}(1-p)^{2(i-1)}$$ Letting $j=i-1$ $$p(1-p)\sum_{i=1}^{\infty}(1-p)^{2(i-1)}=p(1-p)\sum_{j=0}^{\infty}(1-p)^{2j}={{p(1-p)}\over {1-(1-p)^2}}$$ hence $$\alpha={{1-p}\over {2-p}}$$ The thing is that I´m having trouble for b): Let $E$ be the event that a geometric random variable $X$ with parameter p is an even number, so : $P(E)=\alpha$ I need to find this probability by conditioning on wether $X=1$ or $X>1$ therefore: $$P(E)=P(E|X=1)P(X=1)+P(E|X>1)P(X>1)$$ but $P(E|X=1)=0$ hence $P(E)=P(E|X>1)P(X>1)$ then we have that $$P(X>1)=1-P(X\le 1)=1-p$$ But I´m having trouble computing $P(E|X>1)$ Can you help me please? I would really appreciate it :)",,"['probability', 'random-variables']"
3,Finding a specific sequence of digits in pi,Finding a specific sequence of digits in pi,,"Looking at the pifs project on GitHub and this question on SO has made me curious as to how feasible it is to find a specific sequence of digits within Pi. Essentially, on average, how many digits of pi would you have to have to go through to find a specific sequence of a given length? Assuming the digits of pi to be normal and otherwise random, I would assume that the difficulty of finding a specific sequence increases exponentially(?) as the length of the sequence increases. For instance, just trying to find a short sequence like '12345' is fairly easy, occurring at position 49702. However, just one more digit, say, '123456', brings you up to position 2458885. Of course, it differs by specific sequence; '314159' is much easier to find in terms of the work you have to do (especially computationally, where runtimes and memory usage make a difference). There's probably still a way to find an average digit of pi on which any given sequence would start, but it's beyond the scope of my mathematical ability. Another interesting question is whether there's a specific formula for average position in pi for a sequence of a given length. For instance, if you took a specific 256 kb sequence, it would take an absurd number of digits of pi to find it, but how would that absurd number compare the the far more absurd number of digits you would need to find a specific 512 kb sequence in pi? I suppose one could also take information theory into account, because since pi is effectively random, at first glance it seems like it might take longer to identify a sequence that has a repeating pattern. Thinking more about it, I don't think that it would be any more difficult to find than any other specific sequence, but I'm not certain. As you can probably tell by the horribly imprecise language above and my complete lack of reputation on this site, I'm not that familiar with these types of math, so if the tags below are inappropriate, please help me out by editing them.","Looking at the pifs project on GitHub and this question on SO has made me curious as to how feasible it is to find a specific sequence of digits within Pi. Essentially, on average, how many digits of pi would you have to have to go through to find a specific sequence of a given length? Assuming the digits of pi to be normal and otherwise random, I would assume that the difficulty of finding a specific sequence increases exponentially(?) as the length of the sequence increases. For instance, just trying to find a short sequence like '12345' is fairly easy, occurring at position 49702. However, just one more digit, say, '123456', brings you up to position 2458885. Of course, it differs by specific sequence; '314159' is much easier to find in terms of the work you have to do (especially computationally, where runtimes and memory usage make a difference). There's probably still a way to find an average digit of pi on which any given sequence would start, but it's beyond the scope of my mathematical ability. Another interesting question is whether there's a specific formula for average position in pi for a sequence of a given length. For instance, if you took a specific 256 kb sequence, it would take an absurd number of digits of pi to find it, but how would that absurd number compare the the far more absurd number of digits you would need to find a specific 512 kb sequence in pi? I suppose one could also take information theory into account, because since pi is effectively random, at first glance it seems like it might take longer to identify a sequence that has a repeating pattern. Thinking more about it, I don't think that it would be any more difficult to find than any other specific sequence, but I'm not certain. As you can probably tell by the horribly imprecise language above and my complete lack of reputation on this site, I'm not that familiar with these types of math, so if the tags below are inappropriate, please help me out by editing them.",,"['probability', 'sequences-and-series', 'pi', 'entropy']"
4,Elevator Probability Question,Elevator Probability Question,,"There are four people in an elevator, four floors in the building, and each person exits at random. Find the probability that: a) all exit at different floors b) all exit at the same floor c) two get off at one floor and two get off at another For a) I found $4!$ ways for the passengers to get off at different floors, so $$\frac{4!}{4^4} \text{would be the probability} = \frac{3}{32}$$ For b) there are only four ways for them to all exit on the same floor, so $$\frac{4}{256} = \frac{1}{64}$$ For c) am I allowed to group the $4$ people so that I am solving for $2$ people technically? For two people there would be $12$ possibilities, and there are three ways to group the $4$ individuals, so $$\frac{12 \cdot 3}{256} = \frac{9}{64}$$ I'm not sure if I'm doing these right, can you please check? Thank you.","There are four people in an elevator, four floors in the building, and each person exits at random. Find the probability that: a) all exit at different floors b) all exit at the same floor c) two get off at one floor and two get off at another For a) I found $4!$ ways for the passengers to get off at different floors, so $$\frac{4!}{4^4} \text{would be the probability} = \frac{3}{32}$$ For b) there are only four ways for them to all exit on the same floor, so $$\frac{4}{256} = \frac{1}{64}$$ For c) am I allowed to group the $4$ people so that I am solving for $2$ people technically? For two people there would be $12$ possibilities, and there are three ways to group the $4$ individuals, so $$\frac{12 \cdot 3}{256} = \frac{9}{64}$$ I'm not sure if I'm doing these right, can you please check? Thank you.",,['probability']
5,"Show that, $\lvert\mathbb P(A\cap B)-\mathbb P(A)\mathbb P(B)\rvert \le \dfrac{1}{4}$","Show that,",\lvert\mathbb P(A\cap B)-\mathbb P(A)\mathbb P(B)\rvert \le \dfrac{1}{4},"If $(\Omega,\mathcal A,\mathbb P)$ is a probability space, show that for $A,B\in\mathcal A$ $\lvert\mathbb P(A\cap B)-\mathbb P(A)\mathbb P(B)\rvert \le \dfrac{1}{4}$ If $A, B$ are independent then the inequality is correct (LHS is 0). If not how can we express this dependency ? Does it attain its maximum, if $\mathbb P(B)$ is 1 ?","If is a probability space, show that for If are independent then the inequality is correct (LHS is 0). If not how can we express this dependency ? Does it attain its maximum, if is 1 ?","(\Omega,\mathcal A,\mathbb P) A,B\in\mathcal A \lvert\mathbb P(A\cap B)-\mathbb P(A)\mathbb P(B)\rvert \le \dfrac{1}{4} A, B \mathbb P(B)","['probability', 'probability-theory']"
6,Probability problem - 3 hunters and a boar,Probability problem - 3 hunters and a boar,,"3 hunters fire simultaneously at a boar. One bullet hits the boar. What probability is for each hunter to be the one who hit the boar, when hunter A hits with accuracy of 0.2, B 0.4, C 0.6? I see 2 possible solutions: The first one is simple. When I take 10 average bullets of hunter A, I've got 2 bullets that hit, 4 for B and 6 for C. If I take all 30 imaginary bullets, I put the bullets that missed away and have 12 left. This leads me to $$\frac{2}{12},\frac{4}{12},\frac{6}{12}=\frac1{6}, \frac1{3}, \frac1{2}$$The second one is that for each hunter, I take probability of the fact that his bullets hit and the other hunters' did not and divide it by probability that this occured or one of the others got lucky. This is basically dividing the 'good' possibilities by all possibilities. I get the numerator for the first hunter by multiplying his accuracy (0.2) by inverses of accuracies of the other guys (0.6 and 0.4). The denominator is the same for all of them and contains the sum of nominators for each hunter. So for A, it is $$\frac{0.2\cdot0.6\cdot0.4}{0.2\cdot0.6\cdot0.4+0.4\cdot0.8\cdot0.4+0.6\cdot0.8\cdot0.6}$$The results are $\frac{48}{464},\frac{128}{464},\frac{288}{464}=\frac{3}{29},\frac{8}{29},\frac{18}{29}$ Now, which one of these methods is correct? And maybe even more importantly, why the other one isn't?","3 hunters fire simultaneously at a boar. One bullet hits the boar. What probability is for each hunter to be the one who hit the boar, when hunter A hits with accuracy of 0.2, B 0.4, C 0.6? I see 2 possible solutions: The first one is simple. When I take 10 average bullets of hunter A, I've got 2 bullets that hit, 4 for B and 6 for C. If I take all 30 imaginary bullets, I put the bullets that missed away and have 12 left. This leads me to $$\frac{2}{12},\frac{4}{12},\frac{6}{12}=\frac1{6}, \frac1{3}, \frac1{2}$$The second one is that for each hunter, I take probability of the fact that his bullets hit and the other hunters' did not and divide it by probability that this occured or one of the others got lucky. This is basically dividing the 'good' possibilities by all possibilities. I get the numerator for the first hunter by multiplying his accuracy (0.2) by inverses of accuracies of the other guys (0.6 and 0.4). The denominator is the same for all of them and contains the sum of nominators for each hunter. So for A, it is $$\frac{0.2\cdot0.6\cdot0.4}{0.2\cdot0.6\cdot0.4+0.4\cdot0.8\cdot0.4+0.6\cdot0.8\cdot0.6}$$The results are $\frac{48}{464},\frac{128}{464},\frac{288}{464}=\frac{3}{29},\frac{8}{29},\frac{18}{29}$ Now, which one of these methods is correct? And maybe even more importantly, why the other one isn't?",,"['probability', 'combinatorics']"
7,Probability measure on subset of natural numbers...,Probability measure on subset of natural numbers...,,"How one would define a probability measure on all subsets of natural numbers, which is finite-additive and such that the variables $\chi_p(n)=\left\{\begin{matrix} 1 & p|n \\  0 & \text{esle} \end{matrix}\right.$ are independent. Any help you can give will be greatly appreciated.","How one would define a probability measure on all subsets of natural numbers, which is finite-additive and such that the variables $\chi_p(n)=\left\{\begin{matrix} 1 & p|n \\  0 & \text{esle} \end{matrix}\right.$ are independent. Any help you can give will be greatly appreciated.",,"['probability', 'measure-theory', 'reference-request']"
8,Approximating hypergeometric distribution with poisson,Approximating hypergeometric distribution with poisson,,"I'm am currently trying to show that the hypergeometric distribution converges to the Poisson distribution. $$ \lim_{n,r,s \to \infty, \frac{n \cdot r}{r+s} \to \lambda} \frac{\binom{r}{k} \binom{s}{n-k}}{\binom{r+s}{n}} = \frac{\lambda^k}{k!}e^{-\lambda}   $$ I know, how to show for specific values, that the hypergeometric distribution converges to the binomial distribution and from there we proved in our script that the binomial distribution converges to the Poisson distribution for specific values. No the question is, can i show the approximation directly via the limit above? I came from the limit above to $$ \lim_{n,r,s \to \infty, \frac{n \cdot r}{r+s} \to \lambda} \frac{\binom{r}{k} \binom{s}{n-k}}{\binom{r+s}{n}} = \cdots = \frac{\lambda^k}{k!}\frac{\frac{(r-1)!}{(r-k)!}\binom{s}{n-k}}{\binom{r+s-1}{n-1}}\left(\frac{1}{\lambda}\right)^{k-1} $$ But how to show that ? $$ \frac{\frac{(r-1)!}{(r-k)!}\binom{s}{n-k}}{\binom{r+s-1}{n-1}}\left(\frac{1}{\lambda}\right)^{k-1} = e^{-\lambda} $$","I'm am currently trying to show that the hypergeometric distribution converges to the Poisson distribution. $$ \lim_{n,r,s \to \infty, \frac{n \cdot r}{r+s} \to \lambda} \frac{\binom{r}{k} \binom{s}{n-k}}{\binom{r+s}{n}} = \frac{\lambda^k}{k!}e^{-\lambda}   $$ I know, how to show for specific values, that the hypergeometric distribution converges to the binomial distribution and from there we proved in our script that the binomial distribution converges to the Poisson distribution for specific values. No the question is, can i show the approximation directly via the limit above? I came from the limit above to $$ \lim_{n,r,s \to \infty, \frac{n \cdot r}{r+s} \to \lambda} \frac{\binom{r}{k} \binom{s}{n-k}}{\binom{r+s}{n}} = \cdots = \frac{\lambda^k}{k!}\frac{\frac{(r-1)!}{(r-k)!}\binom{s}{n-k}}{\binom{r+s-1}{n-1}}\left(\frac{1}{\lambda}\right)^{k-1} $$ But how to show that ? $$ \frac{\frac{(r-1)!}{(r-k)!}\binom{s}{n-k}}{\binom{r+s-1}{n-1}}\left(\frac{1}{\lambda}\right)^{k-1} = e^{-\lambda} $$",,"['probability', 'convergence-divergence', 'binomial-coefficients']"
9,Counting exercise,Counting exercise,,"Three players a,b,c take turns in a game according to the following rules: At the start A and B play (so C does not play). The winner of the first trial plays against C and so on until one of the players wins two trials in a row.   Possible outcomes are   aa,acc,acbb,acbaa,   bb,bcc,bcaa,bcabb etc. We have to prove that probability of A winning equals p(A) = 5/14, p(B) = 5/14, p(C) = 2/7 I have been stuck on this problem for a long time. The only thing I have been able to find out so far is that C can never win on even turns. Re-edit Players continue to play until one of them wins two times consecutively and all players are equally good at playing the game. Apologies for leaving such crucial information. I have finally solved this problem with a different approach Sample space aa ,acc ,acbb ,acbaa ,acbacc ,acbacbb ,acbabcaa ,... bb ,bcc ,bcaa ,bcabb ,bcabcc ,bcabcaa ,bcabcabb ,... Each point in the sample space has a probability (1/2^k) associated with it where k is the number of turns. For example probability of point (aa) = 1/4 Now let us construct a table enumerating probabilities - Let us consider the event that C wins overall. But C can only win if k = 3,6,9,12,... P(C) = P(C3) + P(C6) + P(C9) ...... where P(Ck) = Probability of C winning overall after k turns. P(C) = 1/4 + 1/32  ..... P(C) = a / (1 - r)       ( Sum of an infinite GP ) a = 1/4                  ( First Term ) r = 1/8                  ( Ratio ) P(C) = 2/7 P(A) = 5/14 = P(B)","Three players a,b,c take turns in a game according to the following rules: At the start A and B play (so C does not play). The winner of the first trial plays against C and so on until one of the players wins two trials in a row.   Possible outcomes are   aa,acc,acbb,acbaa,   bb,bcc,bcaa,bcabb etc. We have to prove that probability of A winning equals p(A) = 5/14, p(B) = 5/14, p(C) = 2/7 I have been stuck on this problem for a long time. The only thing I have been able to find out so far is that C can never win on even turns. Re-edit Players continue to play until one of them wins two times consecutively and all players are equally good at playing the game. Apologies for leaving such crucial information. I have finally solved this problem with a different approach Sample space aa ,acc ,acbb ,acbaa ,acbacc ,acbacbb ,acbabcaa ,... bb ,bcc ,bcaa ,bcabb ,bcabcc ,bcabcaa ,bcabcabb ,... Each point in the sample space has a probability (1/2^k) associated with it where k is the number of turns. For example probability of point (aa) = 1/4 Now let us construct a table enumerating probabilities - Let us consider the event that C wins overall. But C can only win if k = 3,6,9,12,... P(C) = P(C3) + P(C6) + P(C9) ...... where P(Ck) = Probability of C winning overall after k turns. P(C) = 1/4 + 1/32  ..... P(C) = a / (1 - r)       ( Sum of an infinite GP ) a = 1/4                  ( First Term ) r = 1/8                  ( Ratio ) P(C) = 2/7 P(A) = 5/14 = P(B)",,['probability']
10,Expected value of $|H-T|$ in $n$ coin flips,Expected value of  in  coin flips,|H-T| n,"Let $H_n$ be the number of heads in $n$ coin flips. Let $T_n$ be the number of tails in $n$ coins flips. Is there a good way to calculate $E_n = E[|H-T|]$ that isn't brute force computation, i.e. directly evaluating $$E[|H-T|] = \frac{1}{2^n} \sum {n \choose r} |n-2r|. $$ I don't see any approach that can simplify this calculation.","Let $H_n$ be the number of heads in $n$ coin flips. Let $T_n$ be the number of tails in $n$ coins flips. Is there a good way to calculate $E_n = E[|H-T|]$ that isn't brute force computation, i.e. directly evaluating $$E[|H-T|] = \frac{1}{2^n} \sum {n \choose r} |n-2r|. $$ I don't see any approach that can simplify this calculation.",,['probability']
11,Proof of Frechet-Hoeffding Copula bounds,Proof of Frechet-Hoeffding Copula bounds,,"How is the lower Frechet-Hoeffding copula bound proved? In the bivariate case, it follows from $C(u_1,u_2)-C(u_1,v_2)-C(v_1,u_2)+C(v_1,v_2)\geq0$ by setting $(v_1,v_2)=(1,1)$. I'm struggling to prove it in higher dimensions.","How is the lower Frechet-Hoeffding copula bound proved? In the bivariate case, it follows from $C(u_1,u_2)-C(u_1,v_2)-C(v_1,u_2)+C(v_1,v_2)\geq0$ by setting $(v_1,v_2)=(1,1)$. I'm struggling to prove it in higher dimensions.",,"['probability', 'inequality', 'copula']"
12,Uniform measure on the rationals between 0 and 1,Uniform measure on the rationals between 0 and 1,,"I am trying to think of a probability measure on the set of rationals between 0 and 1 ($X:=\mathbb{Q}\cap[0,1]$). I want to achieve something like a uniform measure, i.e. every number should have the same probability. Of course from the fact, that there are infinitely many atoms, it follows, that the measure has to be zero for every rational, which in turn yields a zero probability for any event, even the whole space, which is bad. So is something wrong about my idea of uniformity? What kind of measures can be defined on $X$? How could one design a ""completely random drawing of rationals""? (Do we appreciate what we have with the reals, when we talk about uniformly distributed random number?)","I am trying to think of a probability measure on the set of rationals between 0 and 1 ($X:=\mathbb{Q}\cap[0,1]$). I want to achieve something like a uniform measure, i.e. every number should have the same probability. Of course from the fact, that there are infinitely many atoms, it follows, that the measure has to be zero for every rational, which in turn yields a zero probability for any event, even the whole space, which is bad. So is something wrong about my idea of uniformity? What kind of measures can be defined on $X$? How could one design a ""completely random drawing of rationals""? (Do we appreciate what we have with the reals, when we talk about uniformly distributed random number?)",,"['probability', 'measure-theory', 'probability-theory', 'probability-distributions']"
13,functional analytic interpretation of the (co)variation and the doob decompostion,functional analytic interpretation of the (co)variation and the doob decompostion,,"I have a question concerning the covariation of two time-discrete stochastic processes. Let $(\mathcal{F}_i)_{i\in T}$ be a filtration. We  call a time-discrete, real-valued, adapted process $X$ (e.i. $X : \mathbb{N} \to \mathbb{R}^{\Omega}$ and $X_i$ is $\mathcal{F}_i$-measurable) a discrete semi-martingale. A theorem from Doob states, that every discrete semi-martingale $X$ can be uniquely represented as $X = M + A + X_0$, where $M$ is a Martingale, $A$ is a predictable process and $M_0 = A_0 = 0$. This representation is called the Doob decomposition of $X$. The process $A$ is called the compensator of $X$. For two discrete semi-martingales $X,Y$ we call $[X,Y]_n := \sum_{i=1}^n \Delta X_i\Delta Y_i$ the variation of $X$ and $Y$. The compensator of the discrete semi-martingale $[X,Y]:=([X,Y]_n)_{n\in \mathbb{N}}$ is called the covariation of $X$ and $Y$ andis denoted by $\langle X,Y \rangle$. One can show that the variation as well as the covariation are symmetric and bilinear. The variation maps a tuple of discrete semi-martingales onto a discrete semi-martingale. The covariation maps a tuple of discrete semi-martingales onto a predictable process. Here is my first question: Is there any connection between a scalar product (or even a Hilbertspace) and the variation or covariation? Here is my second question: Is there any functional analytic interpretation of the Doob decomposition (e.g. in words of projections) ?(Answered, thank you A Blumenthal!)","I have a question concerning the covariation of two time-discrete stochastic processes. Let $(\mathcal{F}_i)_{i\in T}$ be a filtration. We  call a time-discrete, real-valued, adapted process $X$ (e.i. $X : \mathbb{N} \to \mathbb{R}^{\Omega}$ and $X_i$ is $\mathcal{F}_i$-measurable) a discrete semi-martingale. A theorem from Doob states, that every discrete semi-martingale $X$ can be uniquely represented as $X = M + A + X_0$, where $M$ is a Martingale, $A$ is a predictable process and $M_0 = A_0 = 0$. This representation is called the Doob decomposition of $X$. The process $A$ is called the compensator of $X$. For two discrete semi-martingales $X,Y$ we call $[X,Y]_n := \sum_{i=1}^n \Delta X_i\Delta Y_i$ the variation of $X$ and $Y$. The compensator of the discrete semi-martingale $[X,Y]:=([X,Y]_n)_{n\in \mathbb{N}}$ is called the covariation of $X$ and $Y$ andis denoted by $\langle X,Y \rangle$. One can show that the variation as well as the covariation are symmetric and bilinear. The variation maps a tuple of discrete semi-martingales onto a discrete semi-martingale. The covariation maps a tuple of discrete semi-martingales onto a predictable process. Here is my first question: Is there any connection between a scalar product (or even a Hilbertspace) and the variation or covariation? Here is my second question: Is there any functional analytic interpretation of the Doob decomposition (e.g. in words of projections) ?(Answered, thank you A Blumenthal!)",,"['probability', 'probability-theory', 'stochastic-processes', 'hilbert-spaces', 'martingales']"
14,Expected value of largest integer in a draw,Expected value of largest integer in a draw,,"Suppose I pick $k$ integers without replacement from $\{1, \ldots, n\}$. Let $I$ be the value of the highest integer. A calculation with binomials reveals $$E[I] = \frac{k}{k+1}(n+1)$$  This is a very simple formula - does it have a simple calculation-free proof?","Suppose I pick $k$ integers without replacement from $\{1, \ldots, n\}$. Let $I$ be the value of the highest integer. A calculation with binomials reveals $$E[I] = \frac{k}{k+1}(n+1)$$  This is a very simple formula - does it have a simple calculation-free proof?",,['probability']
15,Probability of a nonnegative integer-valued random variable being zero,Probability of a nonnegative integer-valued random variable being zero,,"I'm trying to teach myself probability theory, and an exercise has me stumped. This exercise comes from Alon & Spencer 4.8, in the chapter on the second moment method. Let $X$ be a random variable taking values in $\mathbb{Z}_{\geq 0}$. Let $E[X^2]$ denote the expectation of its square. Prove that $\displaystyle Pr[X=0] \leq \frac{Var[X]}{E[X^2]}$ In particular, they prove in the chapter that this is true by replacing $E[X^2]$ with $E[X]^2$ by using a simple application of Chebyshev's inequality (they set $\lambda$ in the theorem to $E[X]/Var[X]$). However, this bound is easily seen to be tighter, and so it seems I need to come up with a shrewder application of the inequality by redefining the random variable or choosing an appropriate constant. Any hints?","I'm trying to teach myself probability theory, and an exercise has me stumped. This exercise comes from Alon & Spencer 4.8, in the chapter on the second moment method. Let $X$ be a random variable taking values in $\mathbb{Z}_{\geq 0}$. Let $E[X^2]$ denote the expectation of its square. Prove that $\displaystyle Pr[X=0] \leq \frac{Var[X]}{E[X^2]}$ In particular, they prove in the chapter that this is true by replacing $E[X^2]$ with $E[X]^2$ by using a simple application of Chebyshev's inequality (they set $\lambda$ in the theorem to $E[X]/Var[X]$). However, this bound is easily seen to be tighter, and so it seems I need to come up with a shrewder application of the inequality by redefining the random variable or choosing an appropriate constant. Any hints?",,['probability']
16,Finite sum and gamma function identity,Finite sum and gamma function identity,,"I am trying to prove the following equality (which has arised when I was trying to prove that $E|S_n| \rightarrow \sqrt{\frac{2n}{\pi}}$): $$ \sum_{x=1}^k \frac{x}{(k+x)!(k-x)! } = \frac{1}{2 \Gamma(k+1)\Gamma(k)}.$$ I tried to expanding the left side different ways but the closest I got is this: $$\frac{1}{2 \Gamma(k+1)\Gamma(k)} = \frac{k}{2 (k!)^2}, \quad \sum_{x=1}^k \frac{x}{(k+x)!(k-x)! } = \frac{k}{(k!)^2}\left( 1\cdot\frac{1}{k+1} + 2\cdot\frac{(k-1)}{(k+1)(k+2)}  +...+k \cdot \frac{(k-1)!}{(k+1)(k+2)...(2k)}\right).$$ So, now I am stuck proving that latter sum is $\frac{1}{2}.$","I am trying to prove the following equality (which has arised when I was trying to prove that $E|S_n| \rightarrow \sqrt{\frac{2n}{\pi}}$): $$ \sum_{x=1}^k \frac{x}{(k+x)!(k-x)! } = \frac{1}{2 \Gamma(k+1)\Gamma(k)}.$$ I tried to expanding the left side different ways but the closest I got is this: $$\frac{1}{2 \Gamma(k+1)\Gamma(k)} = \frac{k}{2 (k!)^2}, \quad \sum_{x=1}^k \frac{x}{(k+x)!(k-x)! } = \frac{k}{(k!)^2}\left( 1\cdot\frac{1}{k+1} + 2\cdot\frac{(k-1)}{(k+1)(k+2)}  +...+k \cdot \frac{(k-1)!}{(k+1)(k+2)...(2k)}\right).$$ So, now I am stuck proving that latter sum is $\frac{1}{2}.$",,"['probability', 'combinatorics', 'gamma-function']"
17,Expected Value of Brownian motion using ito isometry,Expected Value of Brownian motion using ito isometry,,"Find  $$ E\ \left[\left(\int_{0}^T e^{s+W_s}dW_s \right)^2\right], $$  where $(W_s)$ is a Brownian  motion. I tried to use Ito isometry to solve this question, but still not yet to find the right path.  Appreciate if you could shed the light on this question.  Thanks.","Find  $$ E\ \left[\left(\int_{0}^T e^{s+W_s}dW_s \right)^2\right], $$  where $(W_s)$ is a Brownian  motion. I tried to use Ito isometry to solve this question, but still not yet to find the right path.  Appreciate if you could shed the light on this question.  Thanks.",,"['probability', 'stochastic-processes', 'brownian-motion', 'stochastic-calculus']"
18,Probability of Selecting A Random Set in Graph with $k$ Edges That is Independent.,Probability of Selecting A Random Set in Graph with  Edges That is Independent.,k,"In a graph with $k$ edges, if we pick every vertex randomly and independently with a probability of $\frac{1}{2}$, prove that the probability that this set of randomly chosen vertices is an independent set is greater than $\frac{1}{2^k}$. The approach I am using involves considering all possible selections of vertices, and bounding the probability that those selections have an independent set. Thanks so much!","In a graph with $k$ edges, if we pick every vertex randomly and independently with a probability of $\frac{1}{2}$, prove that the probability that this set of randomly chosen vertices is an independent set is greater than $\frac{1}{2^k}$. The approach I am using involves considering all possible selections of vertices, and bounding the probability that those selections have an independent set. Thanks so much!",,"['probability', 'graph-theory']"
19,A book of probability puzzles,A book of probability puzzles,,"I would like to train some recreational probability (Puzzles). Does any of you know a good collection? Preferably with hints or answers. I've been studying quite a bit of probability theory, but I don't suspect that will do me any real good. Thanks in advance,","I would like to train some recreational probability (Puzzles). Does any of you know a good collection? Preferably with hints or answers. I've been studying quite a bit of probability theory, but I don't suspect that will do me any real good. Thanks in advance,",,"['probability', 'reference-request', 'recreational-mathematics']"
20,Probability of winning a best of 3 out of 5 game,Probability of winning a best of 3 out of 5 game,,"Two people play a series of independent games. Person 1's probability of winning any game is 0.6, which leaves 0.4 for Person 2. If they play a best of 5 tournament (3/5), find the following. (1)Probability that person 1 wins the tournament in 3 games. (2) Probability that the tournament lasts exactly 3 games. (3) probability that the tournament lasts exactly 4 games. (4) Probability that Person 1 wins the tournament. (5) Probability that it lasts only 3 games if won by person 1. (6) Probability that person 1 won the tournament if it lasted exactly 3 games. So, I'm pretty lost on how to even start with these problems. I was thinking that for (1) it would be (3/5)*(3/5) -- Person1's probability of winning times the best of 5 wins. Is that even on the right track? And how would you start the others?","Two people play a series of independent games. Person 1's probability of winning any game is 0.6, which leaves 0.4 for Person 2. If they play a best of 5 tournament (3/5), find the following. (1)Probability that person 1 wins the tournament in 3 games. (2) Probability that the tournament lasts exactly 3 games. (3) probability that the tournament lasts exactly 4 games. (4) Probability that Person 1 wins the tournament. (5) Probability that it lasts only 3 games if won by person 1. (6) Probability that person 1 won the tournament if it lasted exactly 3 games. So, I'm pretty lost on how to even start with these problems. I was thinking that for (1) it would be (3/5)*(3/5) -- Person1's probability of winning times the best of 5 wins. Is that even on the right track? And how would you start the others?",,['probability']
21,Conditioned Maximum of Brownian Motion,Conditioned Maximum of Brownian Motion,,Let $W_t$ be a Brownian motion and $$ M_t = \max_{o<s<t} W_s $$ Can anyone give me some insights on how to prove: $$ P[M_t >a  \mid  W_t=M_t]= \exp(-a^2/2t) \quad;\quad a>0 $$ Many thanks in advance.,Let $W_t$ be a Brownian motion and $$ M_t = \max_{o<s<t} W_s $$ Can anyone give me some insights on how to prove: $$ P[M_t >a  \mid  W_t=M_t]= \exp(-a^2/2t) \quad;\quad a>0 $$ Many thanks in advance.,,"['probability', 'stochastic-processes']"
22,Delta Function as The Probability Distribution Function.,Delta Function as The Probability Distribution Function.,,"When a random variable $X$ has only one possible outcome $x_0$, the probability density function at $X=x_0$ is infinite, while the probability density at other locations is zero. Then the p.d.f is exactly a delta function $\Pr(X=x) = \delta(x=x_0)$. However, when I tried to calculate the entropy of the random variable, the problem arises. How can I calculate the integral $\int_{-\infty}^{+\infty}{\delta(x-x_0)\log\delta(x-x_0) \, dx}$?","When a random variable $X$ has only one possible outcome $x_0$, the probability density function at $X=x_0$ is infinite, while the probability density at other locations is zero. Then the p.d.f is exactly a delta function $\Pr(X=x) = \delta(x=x_0)$. However, when I tried to calculate the entropy of the random variable, the problem arises. How can I calculate the integral $\int_{-\infty}^{+\infty}{\delta(x-x_0)\log\delta(x-x_0) \, dx}$?",,['probability']
23,Probability/Combinatorics Problem. A closet containing n pairs of shoes.,Probability/Combinatorics Problem. A closet containing n pairs of shoes.,,"A closet contains n pairs of shoes. If 2r shoes are chosen at random, (where 2r < n), what is the probability that the chosen shoes will contain no matching pair? I have tried thinking about this problem on my own and have not gotten much farther than deducing that there are ${2n \choose 2r}$ possible combinations that could be chosen. When I did some searching I found two different solutions for this same problem and I am having trouble discerning which would be correct. No explanation is given with either solution and I am relatively new to probability and combinations so any help from someone with a bit more experience would be much appreciated. Solution 1: The probability is computed as $$ {n \choose 2r}2^{2r}/{2n \choose 2r} $$ Solution 2: The probability is computed as $$ {n \choose r}2^{r}/{2n \choose 2r} $$ If anyone could tell me which of these two is correct and why. I understand that the probability is given as a certain number of combinations out of the total number of possible combinations. What do the two different factors in the numerators represent, and how do they differ in the two solutions?","A closet contains n pairs of shoes. If 2r shoes are chosen at random, (where 2r < n), what is the probability that the chosen shoes will contain no matching pair? I have tried thinking about this problem on my own and have not gotten much farther than deducing that there are ${2n \choose 2r}$ possible combinations that could be chosen. When I did some searching I found two different solutions for this same problem and I am having trouble discerning which would be correct. No explanation is given with either solution and I am relatively new to probability and combinations so any help from someone with a bit more experience would be much appreciated. Solution 1: The probability is computed as $$ {n \choose 2r}2^{2r}/{2n \choose 2r} $$ Solution 2: The probability is computed as $$ {n \choose r}2^{r}/{2n \choose 2r} $$ If anyone could tell me which of these two is correct and why. I understand that the probability is given as a certain number of combinations out of the total number of possible combinations. What do the two different factors in the numerators represent, and how do they differ in the two solutions?",,"['probability', 'combinatorics', 'statistics']"
24,Why is this equation $\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=\lambda +\lambda^2$ true?,Why is this equation  true?,\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=\lambda +\lambda^2,"Why is $$\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=\lambda +\lambda^2$$ For the context: I am trying to calculate $E(X^2)$, where X is a poisson distributed random variable. All my calculations lead to a dead end. Is there a trick to process the $k^2$? The only thing I see worth doing is pulling out $1/e^\lambda$. Edit: Considering @Srivatsan's hint I got: $$\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=e^{-\lambda}\sum_{k=0}^{\infty}(k(k-1)+k)\frac{\lambda^k}{k!}=e^{-\lambda}\left( \sum_{k=0}^{\infty}k(k-1)\frac{\lambda^k}{k!}+\sum_{k=0}^{\infty}k\frac{\lambda^k}{k!}\right)$$ $$=e^{-\lambda}\sum_{k=0}^{\infty}k(k-1)\frac{\lambda^k}{k!}+e^{-\lambda}\sum_{k=0}^{\infty}k\frac{\lambda^k}{k!}=e^{-\lambda}\lambda^2\sum_{k=2}^{\infty}\frac{\lambda^{k-2}}{(k-2)!}+e^{-\lambda}\lambda\sum_{k=1}^{\infty}\frac{\lambda^{k-1}}{(k-1)!}$$ $$=e^{-\lambda}\lambda^2\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}+e^{-\lambda}\lambda\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}$$ $$=\lambda^2+\lambda$$ And here we are! Thank you very much, @Srivatsan!","Why is $$\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=\lambda +\lambda^2$$ For the context: I am trying to calculate $E(X^2)$, where X is a poisson distributed random variable. All my calculations lead to a dead end. Is there a trick to process the $k^2$? The only thing I see worth doing is pulling out $1/e^\lambda$. Edit: Considering @Srivatsan's hint I got: $$\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=e^{-\lambda}\sum_{k=0}^{\infty}(k(k-1)+k)\frac{\lambda^k}{k!}=e^{-\lambda}\left( \sum_{k=0}^{\infty}k(k-1)\frac{\lambda^k}{k!}+\sum_{k=0}^{\infty}k\frac{\lambda^k}{k!}\right)$$ $$=e^{-\lambda}\sum_{k=0}^{\infty}k(k-1)\frac{\lambda^k}{k!}+e^{-\lambda}\sum_{k=0}^{\infty}k\frac{\lambda^k}{k!}=e^{-\lambda}\lambda^2\sum_{k=2}^{\infty}\frac{\lambda^{k-2}}{(k-2)!}+e^{-\lambda}\lambda\sum_{k=1}^{\infty}\frac{\lambda^{k-1}}{(k-1)!}$$ $$=e^{-\lambda}\lambda^2\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}+e^{-\lambda}\lambda\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}$$ $$=\lambda^2+\lambda$$ And here we are! Thank you very much, @Srivatsan!",,"['probability', 'sequences-and-series']"
25,Expected Value of a Continuous Random Variable,Expected Value of a Continuous Random Variable,,"I've been reviewing my probability and statistics book and just got up to continuous distributions. The book defines the expected value of a continuous random variable as: $E[H(X)] = \int_{-\infty}^{\infty} H(x)f(x)~dx$ provided that $\int_{-\infty}^{\infty} |H(x)|f(x)~dx$ is finite. While I understand the integral to calculate the expected value, I'm failing to see why the 'provided' takes the absolute value of $H(X)$. Why isn't it enough to just define is as: $E[H(X)] = \int_{-\infty}^{\infty} H(x)f(x)~dx$ provided that it is finite.","I've been reviewing my probability and statistics book and just got up to continuous distributions. The book defines the expected value of a continuous random variable as: $E[H(X)] = \int_{-\infty}^{\infty} H(x)f(x)~dx$ provided that $\int_{-\infty}^{\infty} |H(x)|f(x)~dx$ is finite. While I understand the integral to calculate the expected value, I'm failing to see why the 'provided' takes the absolute value of $H(X)$. Why isn't it enough to just define is as: $E[H(X)] = \int_{-\infty}^{\infty} H(x)f(x)~dx$ provided that it is finite.",,"['probability', 'statistics']"
26,What is the probability that a quadrilateral is convex?,What is the probability that a quadrilateral is convex?,,"Given $4$ distinct randomly chosen points $x_1$, $x_2$, $x_3$, and $x_4$ in the plane such that the polygonal path from $x_1$ to $x_2$ to $x_3$ to $x_4$ to $x_1$ describes a non-self-intersecting quadrilateral, what is the probability that the quadrilateral is convex? This question is prompted by the observation that, although arrowheads, darts and chevrons are not rare, the corresponding quadrilateral is seldom mentioned/encountered in the study of elementary geometry.","Given $4$ distinct randomly chosen points $x_1$, $x_2$, $x_3$, and $x_4$ in the plane such that the polygonal path from $x_1$ to $x_2$ to $x_3$ to $x_4$ to $x_1$ describes a non-self-intersecting quadrilateral, what is the probability that the quadrilateral is convex? This question is prompted by the observation that, although arrowheads, darts and chevrons are not rare, the corresponding quadrilateral is seldom mentioned/encountered in the study of elementary geometry.",,"['probability', 'geometry', 'geometric-probability']"
27,Comparing Poisson variables,Comparing Poisson variables,,Let $X$ and $Y$ be two Poisson variables with different mean. Is there a better (as in more concise or numerically faster) way to compute $P(X\leq Y)$ than using $$ P(X\leq Y) = \sum_{y=0}^\infty P(Y=y) P(X\leq y) $$,Let $X$ and $Y$ be two Poisson variables with different mean. Is there a better (as in more concise or numerically faster) way to compute $P(X\leq Y)$ than using $$ P(X\leq Y) = \sum_{y=0}^\infty P(Y=y) P(X\leq y) $$,,['probability']
28,"Probability of subsequence 123456 in $n$ rolls, combinatorics approach?","Probability of subsequence 123456 in  rolls, combinatorics approach?",n,"I was trying to solve this problem: We roll a 6-sided die n times. What is the probability that all faces have appeared in order, in some six consecutive rolls (i.e., what is the probability that the subsequence 123456 appears among the n rolls)? My immediate reflex was to use Markov chains, but I soon backed down because of how tedious the calculations seemed. I know that it's supposed to be the correct way to tackle it but I've tried something different that ended up being wrong and I'd really appreciate it if you could help pointing out my mistakes. So I decided to count the number of sequences containing the subsequence 123456. Indeed, any sequence of $n$ numbers is equiprobable of probability $\frac{1}{6^n}$ . When we consider such we can pick any of $n-5$ starting point for the subsequence 123456, the rest of the sequence doesn't matter and each term can be any number of $\left\{1,2,3,4,5,6\right\}$ so we've got $6^{n-6}$ ways to pick the remaining numbers. So following this reasoning, I would be tempted to say that the wanted probability is $\frac{(n-5)6^{n-6}}{6^n} = \frac{n-5}{6^6}$ which obviously doesn't make sense because I could take an $n$ that's strictly greater than $6^6$ and it would be a probability strictly greater than $1$ ... I really struggle with combinatorics like that and I never know why my reasoning is wrong.","I was trying to solve this problem: We roll a 6-sided die n times. What is the probability that all faces have appeared in order, in some six consecutive rolls (i.e., what is the probability that the subsequence 123456 appears among the n rolls)? My immediate reflex was to use Markov chains, but I soon backed down because of how tedious the calculations seemed. I know that it's supposed to be the correct way to tackle it but I've tried something different that ended up being wrong and I'd really appreciate it if you could help pointing out my mistakes. So I decided to count the number of sequences containing the subsequence 123456. Indeed, any sequence of numbers is equiprobable of probability . When we consider such we can pick any of starting point for the subsequence 123456, the rest of the sequence doesn't matter and each term can be any number of so we've got ways to pick the remaining numbers. So following this reasoning, I would be tempted to say that the wanted probability is which obviously doesn't make sense because I could take an that's strictly greater than and it would be a probability strictly greater than ... I really struggle with combinatorics like that and I never know why my reasoning is wrong.","n \frac{1}{6^n} n-5 \left\{1,2,3,4,5,6\right\} 6^{n-6} \frac{(n-5)6^{n-6}}{6^n} = \frac{n-5}{6^6} n 6^6 1","['probability', 'combinatorics', 'dice']"
29,Flipping $n$ coins until they're all heads,Flipping  coins until they're all heads,n,"Suppose you have $n$ (fair) coins: You flip them until they're all heads in the following sense: Suppose you flip all of them first and get $k$ heads. This is round $1$ You remove these heads from the board and now you flip the remaining $n- k$ heads. This is round $2$ . Suppose you get $k_1$ heads. You remove these heads and flip the remaining $n- k - k_1$ heads. This is round $3$ . And so on. Continue doing this until you've got an empty board/all the coins have reached heads. Now there's two quantities I want to observe: Expected value of total number of flips performed from start to finish. 2. The number of rounds. In particular I want to see that with high probability the # of rounds is $\leq c \log n$ for some constant $c$ (This is the one I'm more interested in) I sort of have an idea for 1 and am struggling with 2. For $1$ we define $X_i = \#$ of flips coin $i$ needs to get to heads. So $\mathbb{P}[X_i = j] = 0.5(1-0.5)^{j-1} = 0.5^j$ and $\mathbb{P}[X_i \leq j] = \sum_{k = 1}^j0.5^k = 1 - 0.5^{j+1}$ Then the thing we're looking for is $X = \max X_i$ and so $\mathbb{P}[X \leq j] = (1-0.5^{j + 1})^n$ (independence). From this finally we get that $\mathbb{P}[X = j] = (1- 0.5^{j + 1})^n - (1-0.5^j)^n$ . This I think is right, but given this expression I can't find a neat way to express $\mathbb{E}[X]$ . Is this the best I can hope for? But what I'm more interested in is 2 I want to see that with high probability the number of rounds is $\leq c \log n$ . I'm not sure where to begin with this one. Is it just a matter of saying that roughly every round we half the number of coins on the table and so we take $\log_2 n$ turns? Is this a way to make this more rigorous (""with high probability"")","Suppose you have (fair) coins: You flip them until they're all heads in the following sense: Suppose you flip all of them first and get heads. This is round You remove these heads from the board and now you flip the remaining heads. This is round . Suppose you get heads. You remove these heads and flip the remaining heads. This is round . And so on. Continue doing this until you've got an empty board/all the coins have reached heads. Now there's two quantities I want to observe: Expected value of total number of flips performed from start to finish. 2. The number of rounds. In particular I want to see that with high probability the # of rounds is for some constant (This is the one I'm more interested in) I sort of have an idea for 1 and am struggling with 2. For we define of flips coin needs to get to heads. So and Then the thing we're looking for is and so (independence). From this finally we get that . This I think is right, but given this expression I can't find a neat way to express . Is this the best I can hope for? But what I'm more interested in is 2 I want to see that with high probability the number of rounds is . I'm not sure where to begin with this one. Is it just a matter of saying that roughly every round we half the number of coins on the table and so we take turns? Is this a way to make this more rigorous (""with high probability"")",n k 1 n- k 2 k_1 n- k - k_1 3 \leq c \log n c 1 X_i = \# i \mathbb{P}[X_i = j] = 0.5(1-0.5)^{j-1} = 0.5^j \mathbb{P}[X_i \leq j] = \sum_{k = 1}^j0.5^k = 1 - 0.5^{j+1} X = \max X_i \mathbb{P}[X \leq j] = (1-0.5^{j + 1})^n \mathbb{P}[X = j] = (1- 0.5^{j + 1})^n - (1-0.5^j)^n \mathbb{E}[X] \leq c \log n \log_2 n,"['probability', 'combinatorics', 'probability-theory', 'probability-distributions', 'expected-value']"
30,Is the inequality in Hoeffding's lemma ever tight?,Is the inequality in Hoeffding's lemma ever tight?,,"The Hoeffding Lemma asserts that $X$ is a random variable bounded between $[a,b]$ then $$\mathbf{E}[e^{\lambda (X - \mathbf{E}[X])}] \leq e^{\lambda^2(b-a)^2/8}$$ A typical example which asks us to show tightness of the above bound is using symmetric random variables. $X$ s.t. $X$ takes value $a$ w.p. $1/2$ and $b$ w.p. $1/2$ . WLOG Lets take $a$ and $b$ to be $-1$ and $1$ . Thus a symmetric rademacher variable. The LHS of the Hoeffding inequality gives us $\frac{e^\lambda + e^{-\lambda}}{2}$ and the RHS gives us $e^{\lambda^2/2}$ . I dont see any way how these expressions can be same. More generally except for constant random variables I dont see anyway this inequality could hold as an equality. Are there non trivial examples where the above inequality holds with equality",The Hoeffding Lemma asserts that is a random variable bounded between then A typical example which asks us to show tightness of the above bound is using symmetric random variables. s.t. takes value w.p. and w.p. . WLOG Lets take and to be and . Thus a symmetric rademacher variable. The LHS of the Hoeffding inequality gives us and the RHS gives us . I dont see any way how these expressions can be same. More generally except for constant random variables I dont see anyway this inequality could hold as an equality. Are there non trivial examples where the above inequality holds with equality,"X [a,b] \mathbf{E}[e^{\lambda (X - \mathbf{E}[X])}] \leq e^{\lambda^2(b-a)^2/8} X X a 1/2 b 1/2 a b -1 1 \frac{e^\lambda + e^{-\lambda}}{2} e^{\lambda^2/2}","['probability', 'probability-theory', 'inequality', 'random-variables']"
31,"Does ""probability distribution"" refer to the PDF or CDF","Does ""probability distribution"" refer to the PDF or CDF",,"In my work and studies, I keep coming across statements that are similar to the following: Quote from one source: A better angle, at least from the perspective of GANs, is to define similarity in the sense of probability distribution. Two data sets are considered similar if they are samples from the same (or approximately same) probability distribution. Thus more specifically we have our training data set X ⊂Rn consisting of samples from a probability distribution μ (with density p(x)), and we would like to find a probability distribution ν (with density q(x)) such that ν is a good approximation of μ. By taking samples from the distribution ν we obtain generated objects that are “similar” to the objects in X. Quote from a different source: The graph of a continuous probability distribution is a curve. Probability is represented by area under the curve. We have already met this concept when we developed relative frequencies with histograms in Chapter 2. The relative area for a range of values was the probability of drawing at random an observation in that group. Again with the Poisson distribution in Chapter 4, the graph in Example 4.14 used boxes to represent the probability of specific values of the random variable. In this case, we were being a bit casual because the random variables of a Poisson distribution are discrete, whole numbers, and a box has width. Notice that the horizontal axis, the random variable x, purposefully did not mark the points along the axis. The probability of a specific value of a continuous random variable will be zero because the area under a point is zero. Probability is area. The curve is called the probability density function (abbreviated as pdf). We use the symbol f(x) to represent the curve. f(x) is the function that corresponds to the graph; we use the density function f(x) to draw the graph of the probability distribution. I have been trying to really understand at more than a surface level the mathematics behind generative models, but a roadblock has been trying to determine what authors mean by ""probability distribution"". I am fairly certain that ""probability distribution"" in the first quote is referring to the CDF, since the author specifically denotes the density as p(x), which I think refers to the PDF. In the second quote, the author portrays ""the curve"" is a probability distribution, and taking an integral over it results in a probability, obviously conveying it is the PDF. Maybe ""probability distribution"" in fact has no concrete definition and the reader is left to figure out what it is referring to themselves, but it would make my life a lot easier if I knew it referred to one or the other.","In my work and studies, I keep coming across statements that are similar to the following: Quote from one source: A better angle, at least from the perspective of GANs, is to define similarity in the sense of probability distribution. Two data sets are considered similar if they are samples from the same (or approximately same) probability distribution. Thus more specifically we have our training data set X ⊂Rn consisting of samples from a probability distribution μ (with density p(x)), and we would like to find a probability distribution ν (with density q(x)) such that ν is a good approximation of μ. By taking samples from the distribution ν we obtain generated objects that are “similar” to the objects in X. Quote from a different source: The graph of a continuous probability distribution is a curve. Probability is represented by area under the curve. We have already met this concept when we developed relative frequencies with histograms in Chapter 2. The relative area for a range of values was the probability of drawing at random an observation in that group. Again with the Poisson distribution in Chapter 4, the graph in Example 4.14 used boxes to represent the probability of specific values of the random variable. In this case, we were being a bit casual because the random variables of a Poisson distribution are discrete, whole numbers, and a box has width. Notice that the horizontal axis, the random variable x, purposefully did not mark the points along the axis. The probability of a specific value of a continuous random variable will be zero because the area under a point is zero. Probability is area. The curve is called the probability density function (abbreviated as pdf). We use the symbol f(x) to represent the curve. f(x) is the function that corresponds to the graph; we use the density function f(x) to draw the graph of the probability distribution. I have been trying to really understand at more than a surface level the mathematics behind generative models, but a roadblock has been trying to determine what authors mean by ""probability distribution"". I am fairly certain that ""probability distribution"" in the first quote is referring to the CDF, since the author specifically denotes the density as p(x), which I think refers to the PDF. In the second quote, the author portrays ""the curve"" is a probability distribution, and taking an integral over it results in a probability, obviously conveying it is the PDF. Maybe ""probability distribution"" in fact has no concrete definition and the reader is left to figure out what it is referring to themselves, but it would make my life a lot easier if I knew it referred to one or the other.",,"['probability', 'probability-theory', 'measure-theory', 'statistics', 'probability-distributions']"
32,Where are the imaginary components in a moment generating function (MGF) of a distribution?,Where are the imaginary components in a moment generating function (MGF) of a distribution?,,"An MGF is $$M_X(t)=E(e^{tX})=\int_{-\infty}^\infty e^{tx}f_X(x) dx$$ whereas a Laplace transform is $$\mathcal L\{f_X(x)\}(s)= \int_0^\infty e^{-sx}f_X(x)dx$$ I am not referring to the sign difference, or the limits of integration. My question is about $s\in \mathbb C$ being a complex number in the Laplace transform, whereas I only see real numbers in the idea of the MGF (i.e. series expansion of $e^{tx}$ ). Indeed, $M_X:\mathbb R \to [0,\infty]$ with the domain of $M_X$ defined as the set $D_X=\{t \mid M_X(t)<\infty\}.$ In characteristic functions complex numbers are introduced, but they are Fourier transforms, not Laplace. Obviously nobody really cares, but I don't understand why: the LT captures oscillations and exponential decay (in standard engineering uses), whereas the FT only captures sinusoidal components as in this presentation : The imaginary numbers do surface, but in the characteristic function of a distribution. THE QUESTION: So is there really an imaginary component in the MGF (like in the Laplace), and if there is not, why is it taught that the MGF is the Laplace transform of the pdf? My intuition is that in probability the Laplace transform with domain in the complex numbers has been somewhat limited to $t\in \mathbb R,$ corresponding to a segment of the real line around zero in which the $E[e^{tX}]$ for different reasons: To be able to extract moments through the Taylor series. To classify distributions in relation to the exponential distribution, which is very useful in extreme value theory - analysis of the tails. This is best exemplified in the Chernoff inequality: $$\Pr(X \geq a) = \Pr\left(e^{tX} \geq e^{ta}\right)\leq \frac{E[e^{tX}]}{e^{ta}}= \frac{M_X(t)}{e^{ta}}=e^{-ta}M_X(t)$$ which indicates that a finite MGF will result in exponentially tapering tails. The third reason (to uniquely determine the distribution) would not really be a reason to keep the MGF: The characteristic function does have this role with the additional advantage that it exists for all distributions. So it is as if the Laplace transform was somehow limited to the real numbers (needless to say the usual random variables are real, but the domain of the MGF is not the random variable), so as to capture the exponential nature of the distribution, while the characteristic function deals with the complex part.","An MGF is whereas a Laplace transform is I am not referring to the sign difference, or the limits of integration. My question is about being a complex number in the Laplace transform, whereas I only see real numbers in the idea of the MGF (i.e. series expansion of ). Indeed, with the domain of defined as the set In characteristic functions complex numbers are introduced, but they are Fourier transforms, not Laplace. Obviously nobody really cares, but I don't understand why: the LT captures oscillations and exponential decay (in standard engineering uses), whereas the FT only captures sinusoidal components as in this presentation : The imaginary numbers do surface, but in the characteristic function of a distribution. THE QUESTION: So is there really an imaginary component in the MGF (like in the Laplace), and if there is not, why is it taught that the MGF is the Laplace transform of the pdf? My intuition is that in probability the Laplace transform with domain in the complex numbers has been somewhat limited to corresponding to a segment of the real line around zero in which the for different reasons: To be able to extract moments through the Taylor series. To classify distributions in relation to the exponential distribution, which is very useful in extreme value theory - analysis of the tails. This is best exemplified in the Chernoff inequality: which indicates that a finite MGF will result in exponentially tapering tails. The third reason (to uniquely determine the distribution) would not really be a reason to keep the MGF: The characteristic function does have this role with the additional advantage that it exists for all distributions. So it is as if the Laplace transform was somehow limited to the real numbers (needless to say the usual random variables are real, but the domain of the MGF is not the random variable), so as to capture the exponential nature of the distribution, while the characteristic function deals with the complex part.","M_X(t)=E(e^{tX})=\int_{-\infty}^\infty e^{tx}f_X(x) dx \mathcal L\{f_X(x)\}(s)= \int_0^\infty e^{-sx}f_X(x)dx s\in \mathbb C e^{tx} M_X:\mathbb R \to [0,\infty] M_X D_X=\{t \mid M_X(t)<\infty\}. t\in \mathbb R, E[e^{tX}] \Pr(X \geq a) = \Pr\left(e^{tX} \geq e^{ta}\right)\leq \frac{E[e^{tX}]}{e^{ta}}= \frac{M_X(t)}{e^{ta}}=e^{-ta}M_X(t)","['probability', 'probability-distributions', 'laplace-transform', 'moment-generating-functions']"
33,Expected number of moves desperate help,Expected number of moves desperate help,,"Question:You're trying to get a cat, a fish, a dog, and your lunch across a river, but there's a troll in the way. The troll says, ""I'll allow you to cross the river, but only if you play this game with me. I have a die here showing a cat, a fish, a dog, and your lunch. I'll roll that die, and then you must bring that item across the river, no matter which side it's on. Once you do that, I'll roll the die again. If you can get everything to the other side, I'll let you go."" You quickly realize this is a bad idea: If you leave the cat and fish alone on one side, the cat will eat the fish, and if you leave the dog and lunch alone on one side, the dog will eat your lunch. (If the cat, the fish, and something else are alone on one side, nothing will be eaten. Likewise, if the dog, your lunch, and something else are alone on one side, nothing will be eaten.) You tell this to the troll, who says, ""Fine. When I absolutely need to, I'll re-roll the die to make sure none of your precious cargo is harmed."" Suppose that you make a move when you bring something from one side of the river to the other. (If the troll re-rolls their die, the original roll is disposed of, and this does not count as a move.) Find the expected number of moves you'll need to make before everything is on the other side of the river. So, this is what I have so far: I let $e_i$ represent the expected value of the number of moves in order for all $i$ items to be on the other side of the bridge. Therefore our goal is to find $e_4.$ However, I am having trouble forming the linear recurrences and it's really frustrating me. Can anybody help? Thanks! I also know the problem involves states therefore letting me make the states where 4,3,2 or 1 of the things are on the starting side. However, I am also having trouble connecting the relations.","Question:You're trying to get a cat, a fish, a dog, and your lunch across a river, but there's a troll in the way. The troll says, ""I'll allow you to cross the river, but only if you play this game with me. I have a die here showing a cat, a fish, a dog, and your lunch. I'll roll that die, and then you must bring that item across the river, no matter which side it's on. Once you do that, I'll roll the die again. If you can get everything to the other side, I'll let you go."" You quickly realize this is a bad idea: If you leave the cat and fish alone on one side, the cat will eat the fish, and if you leave the dog and lunch alone on one side, the dog will eat your lunch. (If the cat, the fish, and something else are alone on one side, nothing will be eaten. Likewise, if the dog, your lunch, and something else are alone on one side, nothing will be eaten.) You tell this to the troll, who says, ""Fine. When I absolutely need to, I'll re-roll the die to make sure none of your precious cargo is harmed."" Suppose that you make a move when you bring something from one side of the river to the other. (If the troll re-rolls their die, the original roll is disposed of, and this does not count as a move.) Find the expected number of moves you'll need to make before everything is on the other side of the river. So, this is what I have so far: I let represent the expected value of the number of moves in order for all items to be on the other side of the bridge. Therefore our goal is to find However, I am having trouble forming the linear recurrences and it's really frustrating me. Can anybody help? Thanks! I also know the problem involves states therefore letting me make the states where 4,3,2 or 1 of the things are on the starting side. However, I am also having trouble connecting the relations.",e_i i e_4.,"['probability', 'combinatorics', 'contest-math']"
34,What is the probability that the $i$-th best student in a class of $m$ students do better than the $j$-th best student in a class of $n$ students?,What is the probability that the -th best student in a class of  students do better than the -th best student in a class of  students?,i m j n,"Suppose I am a student in a class of $m$ students and I rank $i$ -th among them, what is the probability that I do better than a student that ranks $j$ -th in a class of $n$ different students? I modelled this problem assigning to each student his ""incompetency"", measured by a real number (so a student is better than another student if in this scale he scores less) and assuming that these scores are extracted for each student in i.i.d. manner from a fixed continuous distribution. Formally, suppose $X_1,X_2, X_3,\dots,Y_1,Y_2,Y_3,\dots$ are i.i.d. real random variables with common distribution $\mu$ , that we assume continuous, i.e. $\forall x \in \mathbb{R}, \mu(\{x\}) = 0$ . If $m\in \mathbb{N}$ , let $X^1_m,X^2_m,\dots,X^m_m$ denote respectively the reordering from $X_1,\dots,X_m$ such that $X^1_m$ is the smallest in the set $\{X_1,\dots,X_m\}$ , $X^2_m$ is the second smallest in the set $\{X_1,\dots,X_m\}$ , and so on (and so $X^1_m \le X^2_m \le \dots \le X^m_m$ and ties appear with zero probability, since $\mu$ is continuous). If $n \in \mathbb{N}$ , define analogously $Y_n^1,\dots,Y^n_n$ . Given $m,n \in \mathbb{N}, i \in \{1,\dots,m\}, j \in \{1,\dots,n\}$ , what it the probability of the event $$\{X^i_m \le Y^j_n\}?$$ Actually, I have in mind a simple strategy using brute force (i.e. disintegration, independence and integration by parts) to get to the result, but the calculations are a bit cumbersome... has anyone any idea how to get to the result in a simpler manner?","Suppose I am a student in a class of students and I rank -th among them, what is the probability that I do better than a student that ranks -th in a class of different students? I modelled this problem assigning to each student his ""incompetency"", measured by a real number (so a student is better than another student if in this scale he scores less) and assuming that these scores are extracted for each student in i.i.d. manner from a fixed continuous distribution. Formally, suppose are i.i.d. real random variables with common distribution , that we assume continuous, i.e. . If , let denote respectively the reordering from such that is the smallest in the set , is the second smallest in the set , and so on (and so and ties appear with zero probability, since is continuous). If , define analogously . Given , what it the probability of the event Actually, I have in mind a simple strategy using brute force (i.e. disintegration, independence and integration by parts) to get to the result, but the calculations are a bit cumbersome... has anyone any idea how to get to the result in a simpler manner?","m i j n X_1,X_2, X_3,\dots,Y_1,Y_2,Y_3,\dots \mu \forall x \in \mathbb{R}, \mu(\{x\}) = 0 m\in \mathbb{N} X^1_m,X^2_m,\dots,X^m_m X_1,\dots,X_m X^1_m \{X_1,\dots,X_m\} X^2_m \{X_1,\dots,X_m\} X^1_m \le X^2_m \le \dots \le X^m_m \mu n \in \mathbb{N} Y_n^1,\dots,Y^n_n m,n \in \mathbb{N}, i \in \{1,\dots,m\}, j \in \{1,\dots,n\} \{X^i_m \le Y^j_n\}?","['probability', 'combinatorics', 'probability-distributions', 'recreational-mathematics']"
35,What is the expected volume of the simplex formed by $n+1$ points independently uniformly distributed on $\mathbb S^{n-1}$?,What is the expected volume of the simplex formed by  points independently uniformly distributed on ?,n+1 \mathbb S^{n-1},"I was surprised that I couldn’t find this question answered on this site (not for lack of trying). I need the result for answering Probability of random sphere lying inside the unit ball , so I’m posting it as a separate question and answer for future reference. What is the expected volume of the simplex formed by $n+1$ points independently uniformly distributed on $\mathbb S^{n-1}$ ? MathWorld has the answers $\frac3{2\pi}$ for $n=2$ under Circle Triangle Picking and $\frac{4\pi}{105}$ for $n=3$ under Sphere Tetrahedron Picking , but the general result is surprisingly hard to find.","I was surprised that I couldn’t find this question answered on this site (not for lack of trying). I need the result for answering Probability of random sphere lying inside the unit ball , so I’m posting it as a separate question and answer for future reference. What is the expected volume of the simplex formed by points independently uniformly distributed on ? MathWorld has the answers for under Circle Triangle Picking and for under Sphere Tetrahedron Picking , but the general result is surprisingly hard to find.",n+1 \mathbb S^{n-1} \frac3{2\pi} n=2 \frac{4\pi}{105} n=3,"['probability', 'geometry', 'volume', 'spheres', 'geometric-probability']"
36,Random Walk on Clock,Random Walk on Clock,,"With each step, we move either clockwise or counterclockwise each with probability $\frac{1}{2}$ independent of the previous steps. Starting at 6 o’clock, what is the probability that we visit all the hours from 1 o’clock to 11 o’clock before visiting 12 o’clock? Solving this numerically I arrive at an approximation of $\approx 0.04$ . My code is provided below. import random   clock = [12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] N = 100000 success = 0  for _ in range(N):   index = 6   touches = []    while True:     U = random.uniform(0,1)      if U < 0.5:       index -= 1     else:       index += 1      if clock[index] == 1 and 1 not in touches:       touches.append(1)     elif clock[index] == 11 and 11 not in touches:       touches.append(11)     elif 1 in touches and 11 in touches:         success += 1       break     elif clock[index] == 12:       break     else:       pass  print(round(success/N,4)) However, I was unsure as to how to verify this output provided the study of random walks. I have that given a simple symmetric random walk, the probability of reaching some $\ b$ before $\ 0$ is defined as: $$\ P[W(a) \ hit \ 0 \ before \ b] = 1 - \frac{a}{b}$$ This, however, does not produce 0.04 when substituting $\ a, b$ in the argument. Any help in guiding the probabilistic set up is much appreciated.","With each step, we move either clockwise or counterclockwise each with probability independent of the previous steps. Starting at 6 o’clock, what is the probability that we visit all the hours from 1 o’clock to 11 o’clock before visiting 12 o’clock? Solving this numerically I arrive at an approximation of . My code is provided below. import random   clock = [12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] N = 100000 success = 0  for _ in range(N):   index = 6   touches = []    while True:     U = random.uniform(0,1)      if U < 0.5:       index -= 1     else:       index += 1      if clock[index] == 1 and 1 not in touches:       touches.append(1)     elif clock[index] == 11 and 11 not in touches:       touches.append(11)     elif 1 in touches and 11 in touches:         success += 1       break     elif clock[index] == 12:       break     else:       pass  print(round(success/N,4)) However, I was unsure as to how to verify this output provided the study of random walks. I have that given a simple symmetric random walk, the probability of reaching some before is defined as: This, however, does not produce 0.04 when substituting in the argument. Any help in guiding the probabilistic set up is much appreciated.","\frac{1}{2} \approx 0.04 \ b \ 0 \ P[W(a) \ hit \ 0 \ before \ b] = 1 - \frac{a}{b} \ a, b","['probability', 'stochastic-processes', 'random-variables']"
37,Dungeons and Dragons: Ability Score combinations,Dungeons and Dragons: Ability Score combinations,,"I am trying to figure out how likely it is to roll a certain combination of 6 ability scores in Dungeons and Dragons. edit: Dungeons and Dragons is a tabletop role-playing game. You create a character in a fantasy world which has 6 main statistics, Strength, Dexterity, Constitution, Intelligence, Wisdom, and Charisma. Those ability scores determine the powers that a certain character can use and how strong they are. The ability scores are rolled using 4 6-sided dice (4d6) and then using the 3 highest scores, giving you values $\in [3, 18]$ for the possible values. My goal is to compute the likelihood of getting a combination like (8, 8, 8, 8, 8, 8) or (15, 14, 13, 12, 10, 8). /edit I already worked out the probabilities for rolling a single stat and a question on here confirmed that I did the math right: 3: $\frac{1}{1296}$ , 4: $\frac{4}{1296}$ , 5: $\frac{10}{1296}$ , 6: $\frac{21}{1296}$ , 7: $\frac{38}{1296}$ , 8: $\frac{62}{1296}$ , 9: $\frac{91}{1296}$ , 10: $\frac{122}{1296}$ , 11: $\frac{148}{1296}$ , 12: $\frac{167}{1296}$ , 13: $\frac{172}{1296}$ , 14: $\frac{160}{1296}$ , 15: $\frac{131}{1296}$ , 16: $\frac{94}{1296}$ , 17: $\frac{54}{1296}$ , 18: $\frac{21}{1296}$ Now using the same reasoning I managed to work out the probabilities of combinations based on the sum of ability scores, but only if the outcomes are equally likely. I used Python to compute the probabilities like this: def probability_of_outcomes(outcomes, repetitions, subsum=slice(None, None, None)):     probability_dict = {}     sum_combinations = 0     for c in combinations_with_replacement(outcomes, repetitions):         for p in set(permutations(c, repetitions)):             s = sum(sorted(p)[subsum])             if s in probability_dict:                 probability_dict[s] += 1             else:                 probability_dict[s] = 1             sum_combinations += 1  return probability_dict, sum_combinations   if __name__ == ""__main__"":     all_comb, num_combinations_stats = probability_of_outcomes(range(1, 7) 4, subsum=slice(1, None, None)) in the same way I can compute: abilities_comb, num_combinations_ability = probability_of_outcomes(range(3, 19) 6) Now with the first computation I can already see that not every number is equally likely, but I am unsure where to add that probability in. Also the approach is not very elegant, as I simply try out every possible combination. Any ideas?","I am trying to figure out how likely it is to roll a certain combination of 6 ability scores in Dungeons and Dragons. edit: Dungeons and Dragons is a tabletop role-playing game. You create a character in a fantasy world which has 6 main statistics, Strength, Dexterity, Constitution, Intelligence, Wisdom, and Charisma. Those ability scores determine the powers that a certain character can use and how strong they are. The ability scores are rolled using 4 6-sided dice (4d6) and then using the 3 highest scores, giving you values for the possible values. My goal is to compute the likelihood of getting a combination like (8, 8, 8, 8, 8, 8) or (15, 14, 13, 12, 10, 8). /edit I already worked out the probabilities for rolling a single stat and a question on here confirmed that I did the math right: 3: , 4: , 5: , 6: , 7: , 8: , 9: , 10: , 11: , 12: , 13: , 14: , 15: , 16: , 17: , 18: Now using the same reasoning I managed to work out the probabilities of combinations based on the sum of ability scores, but only if the outcomes are equally likely. I used Python to compute the probabilities like this: def probability_of_outcomes(outcomes, repetitions, subsum=slice(None, None, None)):     probability_dict = {}     sum_combinations = 0     for c in combinations_with_replacement(outcomes, repetitions):         for p in set(permutations(c, repetitions)):             s = sum(sorted(p)[subsum])             if s in probability_dict:                 probability_dict[s] += 1             else:                 probability_dict[s] = 1             sum_combinations += 1  return probability_dict, sum_combinations   if __name__ == ""__main__"":     all_comb, num_combinations_stats = probability_of_outcomes(range(1, 7) 4, subsum=slice(1, None, None)) in the same way I can compute: abilities_comb, num_combinations_ability = probability_of_outcomes(range(3, 19) 6) Now with the first computation I can already see that not every number is equally likely, but I am unsure where to add that probability in. Also the approach is not very elegant, as I simply try out every possible combination. Any ideas?","\in [3, 18] \frac{1}{1296} \frac{4}{1296} \frac{10}{1296} \frac{21}{1296} \frac{38}{1296} \frac{62}{1296} \frac{91}{1296} \frac{122}{1296} \frac{148}{1296} \frac{167}{1296} \frac{172}{1296} \frac{160}{1296} \frac{131}{1296} \frac{94}{1296} \frac{54}{1296} \frac{21}{1296}","['probability', 'combinatorics', 'dice']"
38,Posterior mean if signal is an interval rather than a realization,Posterior mean if signal is an interval rather than a realization,,"Suppose that a signal or observation $s_1$ is drawn from the normal distribution $\mathcal{N}(\mu,\sigma^2)$, where $\sigma^2$ is known but $\mu$ is not. We want to estimate $\mu$ based on $s_1$. Suppose further we have a normal prior distribution for $\mu$, which is $\mathcal{N}(\mu_0,\sigma_0^2)$. In this case it is easy to determine the posterior distribution given $s_1$, which is normal (normal is a conjugate prior), and the posterior mean is also easy to determine as $$E[\mu|s_1]=\frac{\mu_0/\sigma_0^2+s_1/\sigma^2}{1/\sigma_0^2+1/\sigma^2}.$$ Now to my question : But what if we cannot observe $s_1$ directly; instead, we only know whether the realization of $s_1$ is above or below a certain threshold $t\in\mathbb{R}$. That is, instead of observing $s_1$, we only observe $\mathbf{1}\{s_1\ge t\}$ ($\mathbf{1}$ is the indicator function). Since the ""evidence"" is now an interval rather than a point realization, how to compute the posterior mean $E[\mu|\mathbf{1}\{s_1\ge t\}]$? Is the posterior distribution even normal? I am at a loss here. Any help or references to help would be greatly appreciated. Edit : I computed the posterior distribution numerically. See the plot below (where the ""signal"" indicates the realization is above a threshold). The posterior density is clearly not symmetric, hence not normal. So the question remains: Is there a closed form expression for the posterior density, or a somewhat simple expression for the posterior mean?","Suppose that a signal or observation $s_1$ is drawn from the normal distribution $\mathcal{N}(\mu,\sigma^2)$, where $\sigma^2$ is known but $\mu$ is not. We want to estimate $\mu$ based on $s_1$. Suppose further we have a normal prior distribution for $\mu$, which is $\mathcal{N}(\mu_0,\sigma_0^2)$. In this case it is easy to determine the posterior distribution given $s_1$, which is normal (normal is a conjugate prior), and the posterior mean is also easy to determine as $$E[\mu|s_1]=\frac{\mu_0/\sigma_0^2+s_1/\sigma^2}{1/\sigma_0^2+1/\sigma^2}.$$ Now to my question : But what if we cannot observe $s_1$ directly; instead, we only know whether the realization of $s_1$ is above or below a certain threshold $t\in\mathbb{R}$. That is, instead of observing $s_1$, we only observe $\mathbf{1}\{s_1\ge t\}$ ($\mathbf{1}$ is the indicator function). Since the ""evidence"" is now an interval rather than a point realization, how to compute the posterior mean $E[\mu|\mathbf{1}\{s_1\ge t\}]$? Is the posterior distribution even normal? I am at a loss here. Any help or references to help would be greatly appreciated. Edit : I computed the posterior distribution numerically. See the plot below (where the ""signal"" indicates the realization is above a threshold). The posterior density is clearly not symmetric, hence not normal. So the question remains: Is there a closed form expression for the posterior density, or a somewhat simple expression for the posterior mean?",,"['probability', 'statistics', 'normal-distribution', 'conditional-expectation', 'bayesian']"
39,Proof that $\sigma$-algebra is closed under intersection,Proof that -algebra is closed under intersection,\sigma,"I want to show in this proof that a $\sigma$-algebra is closed under intersection. But I am not sure if my second to last implication is true? Let $\mathcal{F}$ be a subset of the sample space $\Omega$ with the three properties of a $\sigma$-algebra. Prove that an event $A_k\in\mathcal{F}$ is also closed under countable intersection for all $k\in\mathbb{N}$. Properties 1) $\emptyset\in\mathcal{F}$ 2) $A\in\mathcal{F}\implies A^C\in\mathcal{F} \quad \text{(closed under complementation)}$ 3) $A_k\in\mathcal{F}\implies \bigcup_{k\in I} A_k\in\mathcal{F}$ for all $k\in I \quad\text{(closed under countable union)}$ My Solution If $\mathcal{F}$ is modeled as a $\sigma$-algebra, using the second property and third property yields $$ \begin{align} A_k\in\mathcal{F}&\implies\bigcup_{k\in\mathbb{N}}A_k\in\mathcal{F} &&\text{(closed under union)}\\ &\implies\left(\bigcup_{k\in\mathbb{N}}A_k\right)^C\in\mathcal{F} && \text{(closed under complementation)}\\ &\implies\bigcap_{k\in\mathbb{N}}A_k^C\in\mathcal{F} && \text{(de Morgan's Law)}\\ &\implies\bigcap_{k\in\mathbb{N}}(A_k^C)^C\in\mathcal{F} && (A_k^C\in\mathcal{F} \text{ closed under complementation) }\\ &\implies \bigcap_{k\in\mathbb{N}}A_k\in\mathcal{F}\\ &\implies \mathcal{F}\;\textit{is closed under intersection.} \end{align} $$ New Solution Taking @AnyAD's advice into consideration: $$ \begin{align} A_k\in\mathcal{F}&\implies A_k^C\in\mathcal{F} && \text{(closed under complementation)}\\ &\implies\left(\bigcup_{k\in I} A_k^C\right)\in\mathcal{F} && \text{(closed under union)}\\ &\implies\left(\bigcup_{k\in I} A_k^C\right)^C\in\mathcal{F} && \text{(closed under complementation)}\\ &\implies\left(\bigcap_{k\in I} (A_k^C)^C\right)\in\mathcal{F} && \text{(de Morgan's Law)}\\ &\implies\bigcap_{k\in I}A_k\in\mathcal{F}\\ &\implies \mathcal{F}\;\textit{is closed under intersection.} \end{align} $$","I want to show in this proof that a $\sigma$-algebra is closed under intersection. But I am not sure if my second to last implication is true? Let $\mathcal{F}$ be a subset of the sample space $\Omega$ with the three properties of a $\sigma$-algebra. Prove that an event $A_k\in\mathcal{F}$ is also closed under countable intersection for all $k\in\mathbb{N}$. Properties 1) $\emptyset\in\mathcal{F}$ 2) $A\in\mathcal{F}\implies A^C\in\mathcal{F} \quad \text{(closed under complementation)}$ 3) $A_k\in\mathcal{F}\implies \bigcup_{k\in I} A_k\in\mathcal{F}$ for all $k\in I \quad\text{(closed under countable union)}$ My Solution If $\mathcal{F}$ is modeled as a $\sigma$-algebra, using the second property and third property yields $$ \begin{align} A_k\in\mathcal{F}&\implies\bigcup_{k\in\mathbb{N}}A_k\in\mathcal{F} &&\text{(closed under union)}\\ &\implies\left(\bigcup_{k\in\mathbb{N}}A_k\right)^C\in\mathcal{F} && \text{(closed under complementation)}\\ &\implies\bigcap_{k\in\mathbb{N}}A_k^C\in\mathcal{F} && \text{(de Morgan's Law)}\\ &\implies\bigcap_{k\in\mathbb{N}}(A_k^C)^C\in\mathcal{F} && (A_k^C\in\mathcal{F} \text{ closed under complementation) }\\ &\implies \bigcap_{k\in\mathbb{N}}A_k\in\mathcal{F}\\ &\implies \mathcal{F}\;\textit{is closed under intersection.} \end{align} $$ New Solution Taking @AnyAD's advice into consideration: $$ \begin{align} A_k\in\mathcal{F}&\implies A_k^C\in\mathcal{F} && \text{(closed under complementation)}\\ &\implies\left(\bigcup_{k\in I} A_k^C\right)\in\mathcal{F} && \text{(closed under union)}\\ &\implies\left(\bigcup_{k\in I} A_k^C\right)^C\in\mathcal{F} && \text{(closed under complementation)}\\ &\implies\left(\bigcap_{k\in I} (A_k^C)^C\right)\in\mathcal{F} && \text{(de Morgan's Law)}\\ &\implies\bigcap_{k\in I}A_k\in\mathcal{F}\\ &\implies \mathcal{F}\;\textit{is closed under intersection.} \end{align} $$",,"['probability', 'proof-verification']"
40,Rolling two dices n-times. Probabillity of getting doubles,Rolling two dices n-times. Probabillity of getting doubles,,"I started learning the basics of probabillity theory by myself and did some practicing and I was doing the following exercise which i found on the internet. Two dices are rolled n-times, determine the probabillity of getting each double (1,1),(2,2),.....,(6,6) atleast one time. I used the binominal distribution, since all four conditions i) finte number of trials ii)trials are independent iii)each trial has two outcomes and at each trial probability doesn't change. Consider getting a double is a sucess P(getting a double on a roll)=$\frac { 1 }{ 6 } $ P( not getting a double)=$\frac { 5 }{ 6 } $ since we are looking for 6-succes we get from the binominal distribution formula that (n,6) $P(x=6)=(n,6){ p }^{ 6 }{ (1-p) }^{ n-6 }$ $P(x=6)=(n,6){ \frac { 1 }{ 6 }  }^{ 6 }{ (1-\frac { 5 }{ 6 } ) }^{ n-6 }$ ((n,6) denotes the binominal coeff.) I'm a little concerned if this is right,since i did not consider the atleast one time thing furhter my modell does not consider that if a pair comes twice it still counts as success even tho its none. Could you help me to finish this correctly","I started learning the basics of probabillity theory by myself and did some practicing and I was doing the following exercise which i found on the internet. Two dices are rolled n-times, determine the probabillity of getting each double (1,1),(2,2),.....,(6,6) atleast one time. I used the binominal distribution, since all four conditions i) finte number of trials ii)trials are independent iii)each trial has two outcomes and at each trial probability doesn't change. Consider getting a double is a sucess P(getting a double on a roll)=$\frac { 1 }{ 6 } $ P( not getting a double)=$\frac { 5 }{ 6 } $ since we are looking for 6-succes we get from the binominal distribution formula that (n,6) $P(x=6)=(n,6){ p }^{ 6 }{ (1-p) }^{ n-6 }$ $P(x=6)=(n,6){ \frac { 1 }{ 6 }  }^{ 6 }{ (1-\frac { 5 }{ 6 } ) }^{ n-6 }$ ((n,6) denotes the binominal coeff.) I'm a little concerned if this is right,since i did not consider the atleast one time thing furhter my modell does not consider that if a pair comes twice it still counts as success even tho its none. Could you help me to finish this correctly",,['probability']
41,double barrier stopping time density function,double barrier stopping time density function,,"We define a Brownian motion $W$, and two stopping times as follow : $$\tau_a=\inf(t \ge 0 | W_t>a)$$ $$\tau_b=\inf(t \ge 0 | W_t<-b)$$ where $a,b >0$ We can define another stopping time as follow  $$\tau=\min(\tau_a,\tau_b)$$ While the density functions of $\tau_a$ and $\tau_b$ are known (by using the Brownian motion reflection principal), how about $\tau$ ?","We define a Brownian motion $W$, and two stopping times as follow : $$\tau_a=\inf(t \ge 0 | W_t>a)$$ $$\tau_b=\inf(t \ge 0 | W_t<-b)$$ where $a,b >0$ We can define another stopping time as follow  $$\tau=\min(\tau_a,\tau_b)$$ While the density functions of $\tau_a$ and $\tau_b$ are known (by using the Brownian motion reflection principal), how about $\tau$ ?",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
42,"What does Pr(dx, dy) mean?","What does Pr(dx, dy) mean?",,"The book The Elements of Statistical Learning by Hastie and others (page 18) defines the expected value of prediction error as \begin{align}  \operatorname{EPE}(f) &= \operatorname E(Y - f(X))^2\\  & = \int [y - f(x)]^2 \Pr(dx, dy) \end{align} Why is it like above? Why not as below to be consistent with any expected value definition? $$ \operatorname{EPE}(f) = E(Y - f(x))^2 = \iint  [y - f(x)]^2  \Pr(x,y) d(x) d(y)$$ What does $\Pr(dx, dy)$ even mean?",The book The Elements of Statistical Learning by Hastie and others (page 18) defines the expected value of prediction error as Why is it like above? Why not as below to be consistent with any expected value definition? What does even mean?,"\begin{align}
 \operatorname{EPE}(f) &= \operatorname E(Y - f(X))^2\\
 & = \int [y - f(x)]^2 \Pr(dx, dy)
\end{align}  \operatorname{EPE}(f) = E(Y - f(x))^2 = \iint  [y - f(x)]^2  \Pr(x,y) d(x) d(y) \Pr(dx, dy)","['probability', 'integration', 'statistics', 'measure-theory', 'machine-learning']"
43,Geometric Without Replacement?,Geometric Without Replacement?,,"Is there a probability distribution corresponding to a geometric distribution without replacement? By this I mean the idea of the time until the first success, but with dependent rather than independent events? For example, the time it takes until you draw a spade from a standard deck of $52$ cards? Or if you have $5$ red and $5$ blue marbles in an urn, the time it takes until you draw a blue marble? Is this just the hypergeometric distribution? I am inclined to say no because the hypergeometric distribution specifies the number of samples.","Is there a probability distribution corresponding to a geometric distribution without replacement? By this I mean the idea of the time until the first success, but with dependent rather than independent events? For example, the time it takes until you draw a spade from a standard deck of cards? Or if you have red and blue marbles in an urn, the time it takes until you draw a blue marble? Is this just the hypergeometric distribution? I am inclined to say no because the hypergeometric distribution specifies the number of samples.",52 5 5,"['probability', 'probability-distributions']"
44,Estimating entropy from a set of measurements,Estimating entropy from a set of measurements,,"Given a set of measurements, such as $528, 412, 281, 66, 338, 249$, is it possible to compute an estimate on how much entropy each measurement provides? Just to clarify: I seek an estimate for the amount of unpredictability to expect from a measurement, measured in bits (shannons). I am experimenting with ways to harvest entropy (for seeding a cryptographically secure pseudorandom number generator), and one of my entropy sources provides imprecise measurements of the time a process takes to complete. The process is the same each time, the measurement should be approximately the same each time, so variation should (by design) mainly be due to measurement error. The smallest theoretically possible measurement is $0$, the largest is unknown. My math background is limited, so I would appreciate clear and comprehendible explanations.","Given a set of measurements, such as $528, 412, 281, 66, 338, 249$, is it possible to compute an estimate on how much entropy each measurement provides? Just to clarify: I seek an estimate for the amount of unpredictability to expect from a measurement, measured in bits (shannons). I am experimenting with ways to harvest entropy (for seeding a cryptographically secure pseudorandom number generator), and one of my entropy sources provides imprecise measurements of the time a process takes to complete. The process is the same each time, the measurement should be approximately the same each time, so variation should (by design) mainly be due to measurement error. The smallest theoretically possible measurement is $0$, the largest is unknown. My math background is limited, so I would appreciate clear and comprehendible explanations.",,"['probability', 'statistics', 'information-theory', 'entropy']"
45,"Probability that for two random points in unit ball, one is closer to the center than to the other point","Probability that for two random points in unit ball, one is closer to the center than to the other point",,"If I have two points $p_1, p_2$ uniformly randomly selected in the unit ball, how can I calculate the probability that one of them is closer to the center of the ball than the distance between the two points? I know how to calculate the distribution of the distance between two random points in the ball, same for one point from the center, but I'm not sure how to use the two distributions to get what I'm after.","If I have two points $p_1, p_2$ uniformly randomly selected in the unit ball, how can I calculate the probability that one of them is closer to the center of the ball than the distance between the two points? I know how to calculate the distribution of the distance between two random points in the ball, same for one point from the center, but I'm not sure how to use the two distributions to get what I'm after.",,"['probability', 'geometry', 'geometric-probability']"
46,"""Standard error"" of a sample's 90th percentile for a normally distributed population","""Standard error"" of a sample's 90th percentile for a normally distributed population",,"When sampling from a normally distributed population, I understand that the expected deviation between the sample mean and the population mean can be calculated using the standard error $$ \text{standard error} = \frac{\sigma_{\text{population}}}{\sqrt{n}}$$ Is there a way to calculate the expected deviation between a sample's 90th percentile and the population's true 90th percentile? Edit: Here's my attempt to formalize this idea: $\sigma= \frac{\sum_i^n{((\pi_{90}^*-\pi_{90})^2})}{n}$ where $ \pi_{90} $ is the truly such that/$\pi_{90}^*$ is the sample value such that $ P(f(X) < \pi_{90}) = 0.9 $ My question is: ""Can $\sigma$ be expressed in terms of $\sigma = g(f(X))$,"" where g is some mapping from f's formulation to a description of how $\sigma$ scales with X? I realize that there may be different answers for different types of PDFs - I'm curious if this can be solved for any specific PDF (uniform, Gaussian, or whatever else lends itself well to the mathematics).","When sampling from a normally distributed population, I understand that the expected deviation between the sample mean and the population mean can be calculated using the standard error $$ \text{standard error} = \frac{\sigma_{\text{population}}}{\sqrt{n}}$$ Is there a way to calculate the expected deviation between a sample's 90th percentile and the population's true 90th percentile? Edit: Here's my attempt to formalize this idea: $\sigma= \frac{\sum_i^n{((\pi_{90}^*-\pi_{90})^2})}{n}$ where $ \pi_{90} $ is the truly such that/$\pi_{90}^*$ is the sample value such that $ P(f(X) < \pi_{90}) = 0.9 $ My question is: ""Can $\sigma$ be expressed in terms of $\sigma = g(f(X))$,"" where g is some mapping from f's formulation to a description of how $\sigma$ scales with X? I realize that there may be different answers for different types of PDFs - I'm curious if this can be solved for any specific PDF (uniform, Gaussian, or whatever else lends itself well to the mathematics).",,['probability']
47,A pill bottle with large and small pills,A pill bottle with large and small pills,,"Alright here's the exact question: A bottle initially contains $48$ large pills and $76$ small pills. Each day a patient randomly chooses one of the pills. If a small pill is chosen, it is eaten. If a large pill is chosen, the pill is broken in two; one part is eaten and the other part is returned to the bottle, and is now considered to be a small pill. Let $X$ be the number of small pills in the bottle after the last large pill has been chosen and its smaller half is returned. Find $\operatorname{E}(X)$. Now here is my thought process so far: $X_i$ = the time at which the $i$th large pill is chosen and then broken. Then $X = \sum_{i = 1}^{48}X_i$, so $\operatorname{E}(X) = \sum_{i = 1}^{48}\operatorname{E}(X_i)$. From this I gather that $X\sim \operatorname{Geo}(\frac{48-i+1}{76+i-1})$, but I have no idea how I would actually go about computing such a ridiculous amount of geometric random variables.","Alright here's the exact question: A bottle initially contains $48$ large pills and $76$ small pills. Each day a patient randomly chooses one of the pills. If a small pill is chosen, it is eaten. If a large pill is chosen, the pill is broken in two; one part is eaten and the other part is returned to the bottle, and is now considered to be a small pill. Let $X$ be the number of small pills in the bottle after the last large pill has been chosen and its smaller half is returned. Find $\operatorname{E}(X)$. Now here is my thought process so far: $X_i$ = the time at which the $i$th large pill is chosen and then broken. Then $X = \sum_{i = 1}^{48}X_i$, so $\operatorname{E}(X) = \sum_{i = 1}^{48}\operatorname{E}(X_i)$. From this I gather that $X\sim \operatorname{Geo}(\frac{48-i+1}{76+i-1})$, but I have no idea how I would actually go about computing such a ridiculous amount of geometric random variables.",,"['probability', 'random-variables']"
48,Memoryless property for Poisson process,Memoryless property for Poisson process,,"Suppose that arrivals of a certain Poisson process occur once every $4$ seconds on average. Given that there are no arrivals during the first $10$ seconds, what is the probability that there will be 6 arrivals during the subsequent $10$ seconds? My solution Suppose $N(t) =$ number of arrivals at time $t$. Then we need to find $$P(N(20) = 6 \mid N(10) = 0) = P(N(20) = 6) = e^{-\lambda t}\sum_{x=0}^6\frac{(\lambda t)^x}{x!} = e^{-80}\sum_{x=0}^6\frac{80^x}{x!}.$$ Since the fact that nothing occurs during the first $10$ seconds gives us no additional information.","Suppose that arrivals of a certain Poisson process occur once every $4$ seconds on average. Given that there are no arrivals during the first $10$ seconds, what is the probability that there will be 6 arrivals during the subsequent $10$ seconds? My solution Suppose $N(t) =$ number of arrivals at time $t$. Then we need to find $$P(N(20) = 6 \mid N(10) = 0) = P(N(20) = 6) = e^{-\lambda t}\sum_{x=0}^6\frac{(\lambda t)^x}{x!} = e^{-80}\sum_{x=0}^6\frac{80^x}{x!}.$$ Since the fact that nothing occurs during the first $10$ seconds gives us no additional information.",,"['probability', 'probability-distributions', 'poisson-distribution', 'poisson-process', 'exponential-distribution']"
49,higher moments of entropy... does the variance of $ \log x $ have any operational meaning?,higher moments of entropy... does the variance of  have any operational meaning?, \log x ,"The Shannon entropy is the average of the negative log of a list of probabilities $ \{ x_1 , \dots , x_d\} $ , i.e. $$ H(x)= -\sum\limits_{i=1}^d x_i \log x_i $$ there are of course lots of nice interpretations of the Shannon entropy. What about the variance of $ -\log x_i $ ? $$ \sigma^2 (-\log x)=\sum\limits_i x_i (\log x_i )^2-\left( \sum\limits_i x_i \log x_i \right)^2 $$ does this have any meaning / has it been used in the literature?","The Shannon entropy is the average of the negative log of a list of probabilities , i.e. there are of course lots of nice interpretations of the Shannon entropy. What about the variance of ? does this have any meaning / has it been used in the literature?"," \{ x_1 , \dots , x_d\}   H(x)= -\sum\limits_{i=1}^d x_i \log x_i   -\log x_i   \sigma^2 (-\log x)=\sum\limits_i x_i (\log x_i )^2-\left( \sum\limits_i x_i \log x_i \right)^2 ","['probability', 'information-theory', 'coding-theory', 'entropy']"
50,How does the pigeonhole principle intuitively suggest incorrect computations of probability?,How does the pigeonhole principle intuitively suggest incorrect computations of probability?,,"Here is an interesting false computation using the pigeonhole principle. Suppose I am asked to compute the probability that three successive tosses of a fair coin will have the same result. It can be readily seen that there are eight possible outcomes, with two of them having the same result three times.  Therefore, the probability is 1/4. However, suppose that I claim that the probability should be 1/2, and here is my reasoning: First, I point out that there are three coin tosses and only two possible outcomes for each toss.  Therefore, at least two out of the three tosses are guaranteed to have the same result.  I need only point out that the probability of the third toss having the same result is 1/2 to arrive at my conclusion. Why does this reasoning lead to a wrong result?","Here is an interesting false computation using the pigeonhole principle. Suppose I am asked to compute the probability that three successive tosses of a fair coin will have the same result. It can be readily seen that there are eight possible outcomes, with two of them having the same result three times.  Therefore, the probability is 1/4. However, suppose that I claim that the probability should be 1/2, and here is my reasoning: First, I point out that there are three coin tosses and only two possible outcomes for each toss.  Therefore, at least two out of the three tosses are guaranteed to have the same result.  I need only point out that the probability of the third toss having the same result is 1/2 to arrive at my conclusion. Why does this reasoning lead to a wrong result?",,"['probability', 'pigeonhole-principle']"
51,Proof of Hoeffding's Covariance Identity,Proof of Hoeffding's Covariance Identity,,"Let $X,Y$ be random variables such that $\operatorname{Cov}(X,Y)$ is well defined, let $F(x,y)$ be the joint-CDF of $X,Y$ and let $F_X(x),F_Y(y)$ be the CDF of $X,Y$ respecitvely. Hoeffding's covariance identity states $$\operatorname{Cov}(X,Y)=\int\limits_{-\infty}^\infty \int\limits_{-\infty}^\infty \left[F(x,y)-F(x)F(y)\right] \, dx \, dy$$ It can easily be seen that $$[F(x,y)-F(x)F(y)] = \mathbb{P}(X\leq x,Y\leq y)-\mathbb{P}(X\leq x) \mathbb{P}(Y\leq y) =\mathbb{E}[1_{\{ X\leq x\} }\cdot1_{\left\{ Y\leq y\right\} }] - \mathbb{E}[1_{\{ X\leq x\} }] \mathbb{E}\left[1_{\{ Y\leq y\} } \right] = \operatorname{Cov}\left(1_{\{ X\leq x\} }, 1_{\{ Y\leq y\} }\right)$$ So it would suffice to prove that $$\text{Cov}\left(X,Y\right)=\int\limits _{-\infty}^{\infty}\int\limits _{-\infty}^{\infty}\text{Cov}\left(1_{\left\{ X\leq x\right\} },1_{\left\{ Y\leq y\right\} }\right) \, dx \, dy$$ I haven't manged to prove this but I did manage to prove that $$\operatorname{Cov}(X,Y) = \int\limits_{-\infty}^\infty \int\limits _{-\infty}^\infty \operatorname{Cov}\left(1_{\{ X\geq x\} },1_{\{ Y\geq y\} }\right) \, dx \, dy$$ I would really appreciate some help getting from the result I did manage to prove to either the original Hoeffding identity or to the equivalent identity in terms of $\operatorname{Cov}(1_{\{ X\leq x\} }, 1_{\{ Y\leq y\} })$ .","Let be random variables such that is well defined, let be the joint-CDF of and let be the CDF of respecitvely. Hoeffding's covariance identity states It can easily be seen that So it would suffice to prove that I haven't manged to prove this but I did manage to prove that I would really appreciate some help getting from the result I did manage to prove to either the original Hoeffding identity or to the equivalent identity in terms of .","X,Y \operatorname{Cov}(X,Y) F(x,y) X,Y F_X(x),F_Y(y) X,Y \operatorname{Cov}(X,Y)=\int\limits_{-\infty}^\infty \int\limits_{-\infty}^\infty \left[F(x,y)-F(x)F(y)\right] \, dx \, dy [F(x,y)-F(x)F(y)] = \mathbb{P}(X\leq x,Y\leq y)-\mathbb{P}(X\leq x) \mathbb{P}(Y\leq y)
=\mathbb{E}[1_{\{ X\leq x\} }\cdot1_{\left\{ Y\leq y\right\} }] - \mathbb{E}[1_{\{ X\leq x\} }] \mathbb{E}\left[1_{\{ Y\leq y\} } \right] = \operatorname{Cov}\left(1_{\{ X\leq x\} }, 1_{\{ Y\leq y\} }\right) \text{Cov}\left(X,Y\right)=\int\limits _{-\infty}^{\infty}\int\limits _{-\infty}^{\infty}\text{Cov}\left(1_{\left\{ X\leq x\right\} },1_{\left\{ Y\leq y\right\} }\right) \, dx \, dy \operatorname{Cov}(X,Y) = \int\limits_{-\infty}^\infty \int\limits _{-\infty}^\infty \operatorname{Cov}\left(1_{\{ X\geq x\} },1_{\{ Y\geq y\} }\right) \, dx \, dy \operatorname{Cov}(1_{\{ X\leq x\} }, 1_{\{ Y\leq y\} })","['probability', 'probability-theory', 'random-variables', 'covariance']"
52,How many tosses for 95% centainty that coin is not fair,How many tosses for 95% centainty that coin is not fair,,"Given a bag of 10 coins, 9 are ordinary coins and one is a double headed coin. You select one coin at random and toss it three times. It comes up heads each time what is the probability its the double header? This can be solved using bayes rule the answer is $\frac{8}{17}$. However the follow up question asks how many tosses would you need to be 95% sure that the coin is double headed? Based on Mark Galek's answer here If I flip a coin 1000 times in a row and it lands on heads all 1000 times, what is the probability that it's an unfair coin? The probability of getting a head n times is: $(\frac{1}{2})^n$ and I need to find the value of n that gives us 95% confidence that the coin is not fair. $(\frac{1}{2})^n=0.05$ $n=ln(0.05)/ln(\frac{1}{2})$ n=5 Is this correct my gut instinct is that it is a little low? Here I have used the CI for the fair coin to try and find how many heads would be required for us to be 95% sure that it isn't fair. Given that the only other choice here is for the coin to be double headed I believe this is correct. Is there any other way this calculation could be done without using the CI for the fair coin?","Given a bag of 10 coins, 9 are ordinary coins and one is a double headed coin. You select one coin at random and toss it three times. It comes up heads each time what is the probability its the double header? This can be solved using bayes rule the answer is $\frac{8}{17}$. However the follow up question asks how many tosses would you need to be 95% sure that the coin is double headed? Based on Mark Galek's answer here If I flip a coin 1000 times in a row and it lands on heads all 1000 times, what is the probability that it's an unfair coin? The probability of getting a head n times is: $(\frac{1}{2})^n$ and I need to find the value of n that gives us 95% confidence that the coin is not fair. $(\frac{1}{2})^n=0.05$ $n=ln(0.05)/ln(\frac{1}{2})$ n=5 Is this correct my gut instinct is that it is a little low? Here I have used the CI for the fair coin to try and find how many heads would be required for us to be 95% sure that it isn't fair. Given that the only other choice here is for the coin to be double headed I believe this is correct. Is there any other way this calculation could be done without using the CI for the fair coin?",,['probability']
53,Why should we care about sufficient statistics?,Why should we care about sufficient statistics?,,So I just learned the concept of sufficient statistics and I don't entirely understand why it's important. I can think of two reasons but I'd like to get a confirmation for them: Is it because it reduces the dimension of the data (from let's say $R^n$ to $R$ in the case where $\overline{X}$ is a sufficient statistic) which could be computationally significant? It's a sought out property of statistic like unbiasedness and consistency (although I'm not sure why we'd care about sufficiency while I understand why we care about the former two).,So I just learned the concept of sufficient statistics and I don't entirely understand why it's important. I can think of two reasons but I'd like to get a confirmation for them: Is it because it reduces the dimension of the data (from let's say $R^n$ to $R$ in the case where $\overline{X}$ is a sufficient statistic) which could be computationally significant? It's a sought out property of statistic like unbiasedness and consistency (although I'm not sure why we'd care about sufficiency while I understand why we care about the former two).,,"['probability', 'statistics']"
54,distance distribution in Poisson point process,distance distribution in Poisson point process,,"Consider a homogeneous Poisson point process in 2D space with density $\lambda$ per unit area. Let $\mathcal{B}(o,R)$ denote a disk centered at origin with radius $R$. Let $n$ be the number of points inside the disk $\mathcal{B}$. Given $n \geq 1$, let $\{d_1, d_2, \ldots, d_n\}$ be the set of radial distances of points inside the disk respect to the origin. (1) What is the distribution of $n$? Is it a Poisson random variable with density $\lambda \pi R^2$? (2) What is the distribution of $d_i$, given $n$. Given $n$, are $d_i$s i.i.d random variables with uniform distribution in $[0,R]$?","Consider a homogeneous Poisson point process in 2D space with density $\lambda$ per unit area. Let $\mathcal{B}(o,R)$ denote a disk centered at origin with radius $R$. Let $n$ be the number of points inside the disk $\mathcal{B}$. Given $n \geq 1$, let $\{d_1, d_2, \ldots, d_n\}$ be the set of radial distances of points inside the disk respect to the origin. (1) What is the distribution of $n$? Is it a Poisson random variable with density $\lambda \pi R^2$? (2) What is the distribution of $d_i$, given $n$. Given $n$, are $d_i$s i.i.d random variables with uniform distribution in $[0,R]$?",,"['probability', 'probability-theory', 'probability-distributions', 'poisson-distribution', 'geometric-probability']"
55,simulating a fair six with a four equal sector spinner,simulating a fair six with a four equal sector spinner,,"Whist teaching basic probability I needed a group to use a fair four sector spinner but I'd none left. I gave them a die asking them to disregard 5,6 should they arise.  The problem got me thinking about what I could do if I needed a die and only had a spinner. I have tried to formulate some rules for the puzzle: You can relabel the spinner after a spin.  For example $1234$ means the four equally likely sectors were labelled $1,2,3$ and $4$. Similarly $1123$ means $2$ of the sectors were labelled $1$. It is ok to label $5$ and $6$ e.g. $3456$ You cannot choose a sector to ignore essentially reducing the spinner to three equally likely sectors. You can spin and re-label as many times as you like. Is it possible under these rules to simulate a fair six sided die with such a spinner? I have adopted a notation of writing the state of the spinner for each spin underneath each other. $$\begin{array}{c} 1122 \\ 3344 \\1123 \\1223 \\1233 \end{array}$$ The above example an attempt of mine. Let the outcomes of successive spinners be called a branch (thinking like a probability tree) The branch$ (1,4,2,2,3)$ represents the outcome of $1$ on the first spin $4$ on the second etc. I chose this labelling because there would be $2\times2\times3\times3\times3=108$ different branches and $108$ is divisible by $6$ I know the branches are not equally likely but I was hoping to assign sets of branches to the six outcomes of the die e.g. $\{(1,4,2,2,3),(1,3,2,2,1)...\} \mapsto 1$ So far Ive got lost because the tree diagram gets out of hand. I'm not sure this problem can be solved as no power of $4$ is divisible by $6$ This is the first problem I've invented by myself so I apologize if there is something I have overlooked that makes the problem trivial. Thanks in advance and I hope you find it an interesting puzzle if it turns out easier than I've thought.","Whist teaching basic probability I needed a group to use a fair four sector spinner but I'd none left. I gave them a die asking them to disregard 5,6 should they arise.  The problem got me thinking about what I could do if I needed a die and only had a spinner. I have tried to formulate some rules for the puzzle: You can relabel the spinner after a spin.  For example $1234$ means the four equally likely sectors were labelled $1,2,3$ and $4$. Similarly $1123$ means $2$ of the sectors were labelled $1$. It is ok to label $5$ and $6$ e.g. $3456$ You cannot choose a sector to ignore essentially reducing the spinner to three equally likely sectors. You can spin and re-label as many times as you like. Is it possible under these rules to simulate a fair six sided die with such a spinner? I have adopted a notation of writing the state of the spinner for each spin underneath each other. $$\begin{array}{c} 1122 \\ 3344 \\1123 \\1223 \\1233 \end{array}$$ The above example an attempt of mine. Let the outcomes of successive spinners be called a branch (thinking like a probability tree) The branch$ (1,4,2,2,3)$ represents the outcome of $1$ on the first spin $4$ on the second etc. I chose this labelling because there would be $2\times2\times3\times3\times3=108$ different branches and $108$ is divisible by $6$ I know the branches are not equally likely but I was hoping to assign sets of branches to the six outcomes of the die e.g. $\{(1,4,2,2,3),(1,3,2,2,1)...\} \mapsto 1$ So far Ive got lost because the tree diagram gets out of hand. I'm not sure this problem can be solved as no power of $4$ is divisible by $6$ This is the first problem I've invented by myself so I apologize if there is something I have overlooked that makes the problem trivial. Thanks in advance and I hope you find it an interesting puzzle if it turns out easier than I've thought.",,['probability']
56,$\lim_{n \to \infty} {\mathbb E}X_n$ for a coin flipping payoff problem,for a coin flipping payoff problem,\lim_{n \to \infty} {\mathbb E}X_n,"Suppose we have a fair coin and we start with a base amount of money $X_0 = C \in {\mathbb N}$, and each time we flip the coin we have $X_{n+1} = X_n + 1$ if the flip is heads, otherwise $X_{n+1} = 1/X_n$ if tails. Can we compute $\lim_{n \to \infty} {\mathbb E}X_n$? It seems like the limit should exist and be finite. However coming up with a formula or recurrence relation for ${\mathbb E}X_n$ seems pretty daunting after some thought. However maybe the limit can be found and proved without that explicit formula? If the limit cannot be computed explicitly, can it be related to some other limit, and/or bounded with some good bounds, and/or proved for example to be irrational?","Suppose we have a fair coin and we start with a base amount of money $X_0 = C \in {\mathbb N}$, and each time we flip the coin we have $X_{n+1} = X_n + 1$ if the flip is heads, otherwise $X_{n+1} = 1/X_n$ if tails. Can we compute $\lim_{n \to \infty} {\mathbb E}X_n$? It seems like the limit should exist and be finite. However coming up with a formula or recurrence relation for ${\mathbb E}X_n$ seems pretty daunting after some thought. However maybe the limit can be found and proved without that explicit formula? If the limit cannot be computed explicitly, can it be related to some other limit, and/or bounded with some good bounds, and/or proved for example to be irrational?",,['probability']
57,Probability that a word contains at least 3 same consecutive letters?,Probability that a word contains at least 3 same consecutive letters?,,"Assume we have a word of length $n$ and an alphabet of length $26$ (the small letters a through z, if you want so. How likely is it that this word contains at least $k := 3$ consecutive letters of any type? Examples that match: aaabababab  aoeuuuuuuu aaaaaaaaaa Examples that do not match: ababababab banananana abcdefghij","Assume we have a word of length $n$ and an alphabet of length $26$ (the small letters a through z, if you want so. How likely is it that this word contains at least $k := 3$ consecutive letters of any type? Examples that match: aaabababab  aoeuuuuuuu aaaaaaaaaa Examples that do not match: ababababab banananana abcdefghij",,"['probability', 'combinatorics', 'probability-theory']"
58,Upper Bound on Mutual Information,Upper Bound on Mutual Information,,"I am interested in an upper bound on mutual information that I have been encountering frequently in the statistics and probability literature. I have yet to see the ""purest"" form of the inequality, so I will attempt to state it first, and then I will provide some literature that use leverage it. Ideally someone will be able to help me understand where this bound comes from and how it is derived. Here is the idea: Let $M = \left\{\theta_1,\theta_2,\ldots,\theta_m\right\}$ be a set of ""models"". Additionally, let $\phi : \mathbb{R}^{n\times m} \to \left\{1,2,\ldots,m\right\}$. Indeed, $\phi\left(X^n\right)\in \left\{1,2,\ldots,m\right\}$ where $X^n$ may be thought of as a data (or design) matrix of $n$ observations. In other words, we are trying to recover, through the estimator $\phi$ one of the $m$ models which best describes our data. I am interested in the following quantity: $I\left(\phi; X^n\right)$, where $I$ represents the mutual information. Then the following bounds $I$ from above: $$ I\left(\phi,X^n\right) \leq \frac{n}{m^2} \sum_{i=1}^m \sum_{j = 1}^m S\left(\mathbb{P}_{\theta_i} \left|\right| \mathbb{P}_{\theta_j}\right)  $$ Here, $S\left(\cdot\left|\right|\cdot\right)$ denotes the symmetric KL-divergence. Further, $\mathbb{P}_{\theta_i}$ represents the underlying probability distribution for the model $\theta_i$. This bound appears in Exploiting the Limits of Structure Learning via Inherent Symmetry and Information-theoretic bounds on model selection for Gaussian Markov random ﬁelds . In the former, see equation (2). In the latter, see equation (18). For the latter paper though, I believe there is a typo as there seems to be a factor of $2n$ missing. (Please correct me if I am wrong.) Therefore, it may be best to consult the first paper.","I am interested in an upper bound on mutual information that I have been encountering frequently in the statistics and probability literature. I have yet to see the ""purest"" form of the inequality, so I will attempt to state it first, and then I will provide some literature that use leverage it. Ideally someone will be able to help me understand where this bound comes from and how it is derived. Here is the idea: Let $M = \left\{\theta_1,\theta_2,\ldots,\theta_m\right\}$ be a set of ""models"". Additionally, let $\phi : \mathbb{R}^{n\times m} \to \left\{1,2,\ldots,m\right\}$. Indeed, $\phi\left(X^n\right)\in \left\{1,2,\ldots,m\right\}$ where $X^n$ may be thought of as a data (or design) matrix of $n$ observations. In other words, we are trying to recover, through the estimator $\phi$ one of the $m$ models which best describes our data. I am interested in the following quantity: $I\left(\phi; X^n\right)$, where $I$ represents the mutual information. Then the following bounds $I$ from above: $$ I\left(\phi,X^n\right) \leq \frac{n}{m^2} \sum_{i=1}^m \sum_{j = 1}^m S\left(\mathbb{P}_{\theta_i} \left|\right| \mathbb{P}_{\theta_j}\right)  $$ Here, $S\left(\cdot\left|\right|\cdot\right)$ denotes the symmetric KL-divergence. Further, $\mathbb{P}_{\theta_i}$ represents the underlying probability distribution for the model $\theta_i$. This bound appears in Exploiting the Limits of Structure Learning via Inherent Symmetry and Information-theoretic bounds on model selection for Gaussian Markov random ﬁelds . In the former, see equation (2). In the latter, see equation (18). For the latter paper though, I believe there is a typo as there seems to be a factor of $2n$ missing. (Please correct me if I am wrong.) Therefore, it may be best to consult the first paper.",,"['probability', 'statistics', 'probability-theory', 'information-theory']"
59,Understanding conditional expectation and indicator function,Understanding conditional expectation and indicator function,,"$X$ is a random variable which has exponential distribution. We define the event $A=\{a<X<b\}$. Then how is the conditional expectation $E(X\mid A)$ and conditional density $f_{X\mid A}(x)$ defined? Is $f_{X\mid A}=\frac{f_X(x)}{\Pr(A)}$ for $a<X<b$ and $0$ else? Is $E(X\mid A)$ same as $E(1_AX)$ where $1_A$ is the indicator function. The latter I suppose is $E(1_AX)=\int_a^bf_X(t)tdt$, where $f_X(x)$ is the density of $X$. Or is $E(X\mid A)=\int_0^\infty f_{X\mid A}(t)tdt$ which, assuming the above definition of conditional density is correct, is equal to $\frac{E(1_AX)}{\Pr(A)}$","$X$ is a random variable which has exponential distribution. We define the event $A=\{a<X<b\}$. Then how is the conditional expectation $E(X\mid A)$ and conditional density $f_{X\mid A}(x)$ defined? Is $f_{X\mid A}=\frac{f_X(x)}{\Pr(A)}$ for $a<X<b$ and $0$ else? Is $E(X\mid A)$ same as $E(1_AX)$ where $1_A$ is the indicator function. The latter I suppose is $E(1_AX)=\int_a^bf_X(t)tdt$, where $f_X(x)$ is the density of $X$. Or is $E(X\mid A)=\int_0^\infty f_{X\mid A}(t)tdt$ which, assuming the above definition of conditional density is correct, is equal to $\frac{E(1_AX)}{\Pr(A)}$",,['probability']
60,Variance of the sum of Bernoulli Random variables?,Variance of the sum of Bernoulli Random variables?,,"$\newcommand{\var}{\operatorname{var}}$ Let $X_{i}$ be a Bernoulli random variable with paramater $p_{i}$ where $p_i$ itself is a random variable that ranges from $0$ to $1$. The expectation of $p_{i}$ is $\rho$, and $X_{i}$ is independent of $X_{j}$ where $i\neq j$ Let $Y=\sum_{i=1}^{n} X_{i}$ Show that $\var(Y)>n\rho(1-\rho)$ This is what I have done so far: $$\var(Y)=\var\left(\sum_{i=1}^n X_{i}\right) = \sum_{i=1}^n \var(X_{i})$$ $$\var(X_{i})=E[\var(X_{i}\mid p_{i})]+\var(E[X_i \mid p_i])$$ $$=E[p_i-p_i^2]+\var(p_i)$$ $$=\rho-E[p_i^2]+E[p_i^2]-E[p_i]^2$$ $$=\rho-\rho^2$$ So, $$\var(Y)=\sum_{i=1}^n (\rho-\rho^{2})=n\rho(1-\rho)$$ What am I doing wrong? This is the variance if $p_i$ were a constant. When $p_i$ varies, surely that should increase the variance of $Y$. Any insight would be appreciated!","$\newcommand{\var}{\operatorname{var}}$ Let $X_{i}$ be a Bernoulli random variable with paramater $p_{i}$ where $p_i$ itself is a random variable that ranges from $0$ to $1$. The expectation of $p_{i}$ is $\rho$, and $X_{i}$ is independent of $X_{j}$ where $i\neq j$ Let $Y=\sum_{i=1}^{n} X_{i}$ Show that $\var(Y)>n\rho(1-\rho)$ This is what I have done so far: $$\var(Y)=\var\left(\sum_{i=1}^n X_{i}\right) = \sum_{i=1}^n \var(X_{i})$$ $$\var(X_{i})=E[\var(X_{i}\mid p_{i})]+\var(E[X_i \mid p_i])$$ $$=E[p_i-p_i^2]+\var(p_i)$$ $$=\rho-E[p_i^2]+E[p_i^2]-E[p_i]^2$$ $$=\rho-\rho^2$$ So, $$\var(Y)=\sum_{i=1}^n (\rho-\rho^{2})=n\rho(1-\rho)$$ What am I doing wrong? This is the variance if $p_i$ were a constant. When $p_i$ varies, surely that should increase the variance of $Y$. Any insight would be appreciated!",,"['probability', 'random-variables']"
61,Prokhorov theorem in locally compact Hausdorff space?,Prokhorov theorem in locally compact Hausdorff space?,,"Prokhorov theorem gives a compactness condition in the space of probability measures on a Polish space. I am wondering whether we have similar conditions for probability measures on more general spaces, say, locally compact Hausdorff spaces, which seems to me to be a more natural setting of measure theory. However, since the proofs that I have seen for Prokhorov theorem depend heavily on the completeness and separability of the underlying space, they do not help much when one tries to extend the result to more general spaces. And to my best guess such an extension would rely on techniques from functional analysis. So, do we actually have such a condition for more general spaces? Thanks!","Prokhorov theorem gives a compactness condition in the space of probability measures on a Polish space. I am wondering whether we have similar conditions for probability measures on more general spaces, say, locally compact Hausdorff spaces, which seems to me to be a more natural setting of measure theory. However, since the proofs that I have seen for Prokhorov theorem depend heavily on the completeness and separability of the underlying space, they do not help much when one tries to extend the result to more general spaces. And to my best guess such an extension would rely on techniques from functional analysis. So, do we actually have such a condition for more general spaces? Thanks!",,"['probability', 'general-topology', 'functional-analysis', 'measure-theory', 'compactness']"
62,unbiased estimator for geometric distribution,unbiased estimator for geometric distribution,,"Let $X_1,\ldots,X_n$ to be sample distributed geometric with parameter $p$. Find MLE. Is it unbiased? The distribution for each is $p(1-p)^{x_i-1}$ so the function is $$L(p)=\displaystyle\prod_{i=1}^np(1-p)^{X_i-1}.$$ After taking lns on both sides I got $$l(p)=\ln(L(p))=n\log(p)+\sum_{i=1}^n(X_i-1)\cdot \log(1-p).$$ I derivatied and found maximum in $p_m=\dfrac{n}{n+\sum_{i=1}^n(X_i-1)}$. Now I need to calculate $E[p_m]$: $$E[p_m]=nE\left[\frac{1}{\sum X_i}\right]$$ How can proceed?","Let $X_1,\ldots,X_n$ to be sample distributed geometric with parameter $p$. Find MLE. Is it unbiased? The distribution for each is $p(1-p)^{x_i-1}$ so the function is $$L(p)=\displaystyle\prod_{i=1}^np(1-p)^{X_i-1}.$$ After taking lns on both sides I got $$l(p)=\ln(L(p))=n\log(p)+\sum_{i=1}^n(X_i-1)\cdot \log(1-p).$$ I derivatied and found maximum in $p_m=\dfrac{n}{n+\sum_{i=1}^n(X_i-1)}$. Now I need to calculate $E[p_m]$: $$E[p_m]=nE\left[\frac{1}{\sum X_i}\right]$$ How can proceed?",,[]
63,Calculating expectations in terms of quantile functions?,Calculating expectations in terms of quantile functions?,,"I have a well behaved random variable, $X$, where I can solve for the quantile in closed form, but in general cannot invert it to get the pdf/cdf.  Assume whatever you need on the properties of $X$ and that the quantile function is $F^{-1}(p)$. Then through standard results, we know that the expectation can be calculated as: $$ E(X) = \int_{-\infty}^{\infty}x F'(x)dx = \int_{0}^{1} F^{-1}(p)dp $$ My question is whether this generalizes for expectations of functions of $X$.  i.e. for  strictly increasing $h(X)$ assuming whatever measureability necessary, can $E(h(X))$ be written in terms of quantiles? $$ E(h(X)) = \int_{0}^{1}h(F^{-1}(p))dp ??? $$","I have a well behaved random variable, $X$, where I can solve for the quantile in closed form, but in general cannot invert it to get the pdf/cdf.  Assume whatever you need on the properties of $X$ and that the quantile function is $F^{-1}(p)$. Then through standard results, we know that the expectation can be calculated as: $$ E(X) = \int_{-\infty}^{\infty}x F'(x)dx = \int_{0}^{1} F^{-1}(p)dp $$ My question is whether this generalizes for expectations of functions of $X$.  i.e. for  strictly increasing $h(X)$ assuming whatever measureability necessary, can $E(h(X))$ be written in terms of quantiles? $$ E(h(X)) = \int_{0}^{1}h(F^{-1}(p))dp ??? $$",,"['probability', 'probability-distributions']"
64,"In a random graph of $n$ vertices, what is the expected value of the number of simple paths?","In a random graph of  vertices, what is the expected value of the number of simple paths?",n,"I am very new to discrete probabilty and was asked this question: In a random graph $G$ on $n$ vertices (any edge can be in the graph with probabilty of $\frac{1}{2}$,) what is the expected value of the number of paths between a vertex $v$ and a vertex $u$? (The answer might be a summation). How do we exactly begin this? I know we have to define $f(u,v) = \text{number of simple paths between v and u}$, and we need to calculate $E[f(u,v)] = \sum_{u,v \in \omega} {f(u,v) \cdot Pr(u,v)}$. But what exactly is $f(u,v)$ here and what is our $\omega$?","I am very new to discrete probabilty and was asked this question: In a random graph $G$ on $n$ vertices (any edge can be in the graph with probabilty of $\frac{1}{2}$,) what is the expected value of the number of paths between a vertex $v$ and a vertex $u$? (The answer might be a summation). How do we exactly begin this? I know we have to define $f(u,v) = \text{number of simple paths between v and u}$, and we need to calculate $E[f(u,v)] = \sum_{u,v \in \omega} {f(u,v) \cdot Pr(u,v)}$. But what exactly is $f(u,v)$ here and what is our $\omega$?",,['probability']
65,$m$ balls into $n$ urns,balls into  urns,m n,"Assume that there are $m$ balls and $n$ urns with $m\gt n$. Each ball is thrown randomly and uniformly into urns. That is, each ball goes into each urn with probability $\dfrac1n$. What is the probability that there are exactly $r$ urns with at least one ball in it? In other words, what is the probability that there are $n-r$ empty urns? ( I am Not sure whether it makes any difference whether balls and urns being distinguishable or not. If there is a difference assume that both balls and urns are distinguishable)","Assume that there are $m$ balls and $n$ urns with $m\gt n$. Each ball is thrown randomly and uniformly into urns. That is, each ball goes into each urn with probability $\dfrac1n$. What is the probability that there are exactly $r$ urns with at least one ball in it? In other words, what is the probability that there are $n-r$ empty urns? ( I am Not sure whether it makes any difference whether balls and urns being distinguishable or not. If there is a difference assume that both balls and urns are distinguishable)",,"['probability', 'combinatorics', 'balls-in-bins']"
66,Probabilistic Interpretation of Burnside's Lemma,Probabilistic Interpretation of Burnside's Lemma,,"Burnside's Lemma states that $N$, the number of orbits when a group $G$ acts on a set $X$ is given by  $$N = \frac{1}{|G|} \sum_{g \in G} |\text{Fix } g|$$ The standard proof involves applying the orbit-stabilizer theorem to representatives $x_1, \cdots, x_N$ from each orbit: $$\sum_{g \in G} |\text{Fix } g| = \sum_{i = 1}^N \sum_{x \in \text{Orb }x_i} |\text{Stab }x|= \sum_{i = 1}^N |\text{Orb }x_i||\text{Stab }x_i| = N \cdot G$$ An alternate way of stating this is to say that the number of orbits is equal to the average number of fixed points. Is there some probabilistic way of interpreting this? I have seen the MathOverflow thread https://mathoverflow.net/questions/50033/intuitive-explanation-of-burnsides-lemma .","Burnside's Lemma states that $N$, the number of orbits when a group $G$ acts on a set $X$ is given by  $$N = \frac{1}{|G|} \sum_{g \in G} |\text{Fix } g|$$ The standard proof involves applying the orbit-stabilizer theorem to representatives $x_1, \cdots, x_N$ from each orbit: $$\sum_{g \in G} |\text{Fix } g| = \sum_{i = 1}^N \sum_{x \in \text{Orb }x_i} |\text{Stab }x|= \sum_{i = 1}^N |\text{Orb }x_i||\text{Stab }x_i| = N \cdot G$$ An alternate way of stating this is to say that the number of orbits is equal to the average number of fixed points. Is there some probabilistic way of interpreting this? I have seen the MathOverflow thread https://mathoverflow.net/questions/50033/intuitive-explanation-of-burnsides-lemma .",,"['probability', 'combinatorics', 'group-theory', 'finite-groups']"
67,Coupon Collector Problem - expected number of draws for some coupon to be drawn twice,Coupon Collector Problem - expected number of draws for some coupon to be drawn twice,,"Suppose that there are $n$ different coupons, equally likely, from which coupons are being randomly drawn with replacement. Find the expected number of draws for some coupon to be drawn twice. I've attempted to solve this from the basic definition of expectation. If $N$ is a randomly variable for the number of draws for some coupon to be drawn twice, then $1\lt N\le n+1$ and $$ E[N]=\sum_{i=2}^{n+1} n*Pr(N=n)\\ =2*\left(\frac{1}{n}\right)+3*\left(\frac{n-1}{n}\right)\left(\frac{2}{n}\right)+4*\left(\frac{n-1}{n}\right)\left(\frac{n-2}{n}\right)\left(\frac{3}{n}\right)+... $$ (Sorry for not finishing the equation, hopefully you get the idea, it goes up to $n+1$, my latex maths is pretty crap.) Is this correct? How do I evaluate this sum or is there a closed-form solution to this sum? Is there a better way to solve this?","Suppose that there are $n$ different coupons, equally likely, from which coupons are being randomly drawn with replacement. Find the expected number of draws for some coupon to be drawn twice. I've attempted to solve this from the basic definition of expectation. If $N$ is a randomly variable for the number of draws for some coupon to be drawn twice, then $1\lt N\le n+1$ and $$ E[N]=\sum_{i=2}^{n+1} n*Pr(N=n)\\ =2*\left(\frac{1}{n}\right)+3*\left(\frac{n-1}{n}\right)\left(\frac{2}{n}\right)+4*\left(\frac{n-1}{n}\right)\left(\frac{n-2}{n}\right)\left(\frac{3}{n}\right)+... $$ (Sorry for not finishing the equation, hopefully you get the idea, it goes up to $n+1$, my latex maths is pretty crap.) Is this correct? How do I evaluate this sum or is there a closed-form solution to this sum? Is there a better way to solve this?",,"['probability', 'combinatorics', 'coupon-collector']"
68,$K$ consecutive heads with a biased coin?,consecutive heads with a biased coin?,K,"You toss a coin repeatedly and independently. The probability to get a head is $p$, tail is $1-p$. Let $A_k$ be the following event: $k$ or more consecutive heads occur amongst the tosses numbered $2^k,...,2^{k+1}-1$. Prove that $\mathbb P\left(A_k\hspace{1mm} \text i.\text o.\right)=1$ if $\displaystyle p\geq \frac{1}{2}$, $0$ otherwise. I'd appreciate any help with this one! edit : Assuming this has to do with Borel-Cantelli, specifically a ""$0/1$ law"". We know that if $\{A_n:n\geq 1\}$ is a sequence of independent events in a probability space, then either $\mathbb P\left(A\left(\text i.\text o.\right)\right)=0$, which is the $\mathbb E\left(N\right)<\infty$ case, or $\mathbb P\left(A\left(\text i.\text o.\right)\right)=1$, which is the $\mathbb E\left(N\right)=\infty$ case, where $N$ denotes the total number of $A_n$ to occur; $\displaystyle N=\sum_{n=1}^{\infty}I_n$, where $I_n=I\{A_n\}$ denote the indicator rv for the event $A_n$. $\displaystyle \mathbb{E}(N) = \sum_{k=1}^\infty \mathbb{P}(A_k)$, so we have to show that this sum converges for $\displaystyle p< \frac{1}{2}$, and diverges otherwise. (how?)","You toss a coin repeatedly and independently. The probability to get a head is $p$, tail is $1-p$. Let $A_k$ be the following event: $k$ or more consecutive heads occur amongst the tosses numbered $2^k,...,2^{k+1}-1$. Prove that $\mathbb P\left(A_k\hspace{1mm} \text i.\text o.\right)=1$ if $\displaystyle p\geq \frac{1}{2}$, $0$ otherwise. I'd appreciate any help with this one! edit : Assuming this has to do with Borel-Cantelli, specifically a ""$0/1$ law"". We know that if $\{A_n:n\geq 1\}$ is a sequence of independent events in a probability space, then either $\mathbb P\left(A\left(\text i.\text o.\right)\right)=0$, which is the $\mathbb E\left(N\right)<\infty$ case, or $\mathbb P\left(A\left(\text i.\text o.\right)\right)=1$, which is the $\mathbb E\left(N\right)=\infty$ case, where $N$ denotes the total number of $A_n$ to occur; $\displaystyle N=\sum_{n=1}^{\infty}I_n$, where $I_n=I\{A_n\}$ denote the indicator rv for the event $A_n$. $\displaystyle \mathbb{E}(N) = \sum_{k=1}^\infty \mathbb{P}(A_k)$, so we have to show that this sum converges for $\displaystyle p< \frac{1}{2}$, and diverges otherwise. (how?)",,"['probability', 'probability-theory']"
69,Is the probability of at least $k$ consecutive heads higher for a coin with higher probability of heads?,Is the probability of at least  consecutive heads higher for a coin with higher probability of heads?,k,"Suppose a coin has probability $p$ for heads and $(1-p)$ for tail. Let $P_{k,p}$ be the probability that in $N$ flips there is a sequence of consecutive heads of length greater than or equal to $k$. $N$ is some fixed number greater than $k$. Does it follow that $P_{k,p}< P_{k,q}$ if  $p$ < $q$? I would greatly appreciate any hint/suggestion/solution! Thank you very much!","Suppose a coin has probability $p$ for heads and $(1-p)$ for tail. Let $P_{k,p}$ be the probability that in $N$ flips there is a sequence of consecutive heads of length greater than or equal to $k$. $N$ is some fixed number greater than $k$. Does it follow that $P_{k,p}< P_{k,q}$ if  $p$ < $q$? I would greatly appreciate any hint/suggestion/solution! Thank you very much!",,['probability']
70,Joint Bernoulli Distribution,Joint Bernoulli Distribution,,"If $X$ and $Y$ are two (not necessarily independent) Bernoulli's with success probabilities $a$ and $b$ resp., how do we construct the joint dist. in terms of $a$,$b$, and $\rho$---the correlation? I can get $\mathbb{P}(X=1,Y=1)$ by manipulating the expression for $\rho$, but lost for the other three...","If $X$ and $Y$ are two (not necessarily independent) Bernoulli's with success probabilities $a$ and $b$ resp., how do we construct the joint dist. in terms of $a$,$b$, and $\rho$---the correlation? I can get $\mathbb{P}(X=1,Y=1)$ by manipulating the expression for $\rho$, but lost for the other three...",,['probability']
71,How do I calculate the probability distribution of the percentage of a binary random variable?,How do I calculate the probability distribution of the percentage of a binary random variable?,,"I have an urn containing balls that are all either black or red. I'm interested in discovering the percentage of balls that are red. But I can only sample from the urn (without replacement), so the best I can do is calculate a probability distribution over possible percentages. Obviously, if I've drawn no balls, I have no information, so the probability distribution is uniform from 0 to 1. But what is it once I start drawing balls?","I have an urn containing balls that are all either black or red. I'm interested in discovering the percentage of balls that are red. But I can only sample from the urn (without replacement), so the best I can do is calculate a probability distribution over possible percentages. Obviously, if I've drawn no balls, I have no information, so the probability distribution is uniform from 0 to 1. But what is it once I start drawing balls?",,"['probability', 'statistics', 'random']"
72,Probability greatest roll of z dice exceeding greatest roll of h dice?,Probability greatest roll of z dice exceeding greatest roll of h dice?,,"Let's assume there are two players in a dice game; zombie and hero. The Zombie rolls z fair 6-sided dice. The Hero rolles h fair 6-sided dice. If the heroes greatest dice roll is larger than the zombie's greatest dice roll, the hero wins.  Otherwise, the zombie wins. How can I calculate the probability of the hero winning as a function of z and h (without just enumerating the answers). Example 1: z = 1, h = 2 Zombie rolls (4), hero rolls (1,5).  Hero has a higher dice roll and wins. Example 2: z = 2, h = 2 Zombie rolls (4,4), hero rolls (1,4).  Hero does not have a higher dice roll and loses. Related Question: Given a die, what is the probability that the second roll of a die will be less than the first roll?","Let's assume there are two players in a dice game; zombie and hero. The Zombie rolls z fair 6-sided dice. The Hero rolles h fair 6-sided dice. If the heroes greatest dice roll is larger than the zombie's greatest dice roll, the hero wins.  Otherwise, the zombie wins. How can I calculate the probability of the hero winning as a function of z and h (without just enumerating the answers). Example 1: z = 1, h = 2 Zombie rolls (4), hero rolls (1,5).  Hero has a higher dice roll and wins. Example 2: z = 2, h = 2 Zombie rolls (4,4), hero rolls (1,4).  Hero does not have a higher dice roll and loses. Related Question: Given a die, what is the probability that the second roll of a die will be less than the first roll?",,"['probability', 'dice']"
73,Expected number of draws until the first good element is chosen,Expected number of draws until the first good element is chosen,,"A population has $G$ good and $B$ bad elements, $G+B=N$. Elements are drawn one by one at random without replacement. Suppose the first good element appears on draw number $X$. Find a simple formula, not involving any summation from $1$ to $N$, for $E(X)$. Hint: Write $X-1$ as sum of $B$ indicators. Ok, so we know in the first $X-1$ draws we only get bad elements. Let $I_j$ be $1$ if $j$th draw gives bad ball and $0$ otherwise. $X-1=I_1+I_2+ \cdots +I_{x-1}$, all of which have value $1$.  $E(I_1)= \cdots=E(I_n)=B/N=(N-G)/N$. Now we can write $E(X)=E((X-1)+1)$ $=E(X-1)+E(1)=E(X-1)+1.$ I'm not exactly sure on the formula for $E(X-1)$. Hopefully, I'm on the right track. Thanks!","A population has $G$ good and $B$ bad elements, $G+B=N$. Elements are drawn one by one at random without replacement. Suppose the first good element appears on draw number $X$. Find a simple formula, not involving any summation from $1$ to $N$, for $E(X)$. Hint: Write $X-1$ as sum of $B$ indicators. Ok, so we know in the first $X-1$ draws we only get bad elements. Let $I_j$ be $1$ if $j$th draw gives bad ball and $0$ otherwise. $X-1=I_1+I_2+ \cdots +I_{x-1}$, all of which have value $1$.  $E(I_1)= \cdots=E(I_n)=B/N=(N-G)/N$. Now we can write $E(X)=E((X-1)+1)$ $=E(X-1)+E(1)=E(X-1)+1.$ I'm not exactly sure on the formula for $E(X-1)$. Hopefully, I'm on the right track. Thanks!",,['probability']
74,Relative entropy is non-negative,Relative entropy is non-negative,,"Let $p=(p_1,\dotsc,p_r), q=(q_1,\dotsc,q_r)$ be two different probability distributions. Define the relative entropy $$h(p||q) = \sum_{i=1}^r p_i (\ln p_i - \ln q_i)$$ Show $h(p||q)\geq 0$. I'm given the hint that I should show $-x\ln x$ is concave and then show for any concave function $f(y)-f(x)\leq (y-x)f'(x)$ holds. I rewritten the relative entropy as $$h(p||q)=\sum_{i=1}^r p_i \ln \left(\frac{p_i}{q_i}\right)= -\sum_{i=1}^r p_i \ln \left(\frac{q_i}{p_i}\right)$$ which sort of looks like $-x\ln x$, and I did show that $-x\ln x$ is concave, but I don't really understand what I'm supposed to do, or even if this hint is helpful.","Let $p=(p_1,\dotsc,p_r), q=(q_1,\dotsc,q_r)$ be two different probability distributions. Define the relative entropy $$h(p||q) = \sum_{i=1}^r p_i (\ln p_i - \ln q_i)$$ Show $h(p||q)\geq 0$. I'm given the hint that I should show $-x\ln x$ is concave and then show for any concave function $f(y)-f(x)\leq (y-x)f'(x)$ holds. I rewritten the relative entropy as $$h(p||q)=\sum_{i=1}^r p_i \ln \left(\frac{p_i}{q_i}\right)= -\sum_{i=1}^r p_i \ln \left(\frac{q_i}{p_i}\right)$$ which sort of looks like $-x\ln x$, and I did show that $-x\ln x$ is concave, but I don't really understand what I'm supposed to do, or even if this hint is helpful.",,['probability']
75,Asymptotic behavior for the return to zero of a simple random walk,Asymptotic behavior for the return to zero of a simple random walk,,"I got stuck today trying to understand an argument of the Frank den Hollander Book's. The problem is described below. Let $S_n=\sum_{i=1}^n X_i$ be the simple random walk in $\mathbb{Z}^d$, that is  $$ \mathbb{P}(X_i=x)= \left\{ \begin{array}{ll}  \frac{1}{2d}&\text{if}\ \|x\|=1;\\ &&\\  0&\text{otherwise.}  \end{array}\right. $$ I would like to know how to prove that  $$ \mathbb{P}(S_{2n}=0)\sim 2\left(\frac{d}{4\pi n}\right)^{\frac{d}{2}},  \qquad n\to\infty. $$ I learn from the Gregory Lawler book's that this is a consequence of the Local Central Limit Theorem. But I would like to know if one can prove this fact without use this result. I tried to Taylor Expand  $$ \hat{p}(k)=\frac{1}{d}\sum_{j=1}^d \cos k_j $$ $k=(k_1,\dots,k_d)\in [-\pi,\pi)^d$ and use that  $$ \mathbb{P}(S_{2n}=0)=\left(\frac{1}{2\pi}\right)^d\int_{[-\pi,\pi)^d} [\hat{p}(k)]^{2n} dk. $$  But It is not working. Any help or reference is welcome. Thanks.","I got stuck today trying to understand an argument of the Frank den Hollander Book's. The problem is described below. Let $S_n=\sum_{i=1}^n X_i$ be the simple random walk in $\mathbb{Z}^d$, that is  $$ \mathbb{P}(X_i=x)= \left\{ \begin{array}{ll}  \frac{1}{2d}&\text{if}\ \|x\|=1;\\ &&\\  0&\text{otherwise.}  \end{array}\right. $$ I would like to know how to prove that  $$ \mathbb{P}(S_{2n}=0)\sim 2\left(\frac{d}{4\pi n}\right)^{\frac{d}{2}},  \qquad n\to\infty. $$ I learn from the Gregory Lawler book's that this is a consequence of the Local Central Limit Theorem. But I would like to know if one can prove this fact without use this result. I tried to Taylor Expand  $$ \hat{p}(k)=\frac{1}{d}\sum_{j=1}^d \cos k_j $$ $k=(k_1,\dots,k_d)\in [-\pi,\pi)^d$ and use that  $$ \mathbb{P}(S_{2n}=0)=\left(\frac{1}{2\pi}\right)^d\int_{[-\pi,\pi)^d} [\hat{p}(k)]^{2n} dk. $$  But It is not working. Any help or reference is welcome. Thanks.",,"['probability', 'random-walk']"
76,How can I prove this random process to be Standard Brownian Motion?,How can I prove this random process to be Standard Brownian Motion?,,"$B_t,t\ge 0$ is a standard Brownian Motion. Then define $X(t)=e^{t/2}B_{1-e^{-t}}$ and $Y_t=X_t-\frac{1}{2}\int_0^t X_u du$. The question is to show that $Y_t, t\ge 0$ is a standard Brownian Motion. I tried to calculate the variance of $Y_t$ for given $t$, but failed to get $t$..","$B_t,t\ge 0$ is a standard Brownian Motion. Then define $X(t)=e^{t/2}B_{1-e^{-t}}$ and $Y_t=X_t-\frac{1}{2}\int_0^t X_u du$. The question is to show that $Y_t, t\ge 0$ is a standard Brownian Motion. I tried to calculate the variance of $Y_t$ for given $t$, but failed to get $t$..",,"['probability', 'stochastic-processes']"
77,Holomorphic Characteristic Function of a Random Variable,Holomorphic Characteristic Function of a Random Variable,,"Let $X$ be a random variable with distribution $\mu _X$.  Then, we define the characteristic function of $X$, $\phi _X$, by $$ \phi _X(t)\equiv \mathrm{E}\left[ e^{itX}\right] =\int _\mathbb{R} e^{itx}d\mu _X(x) $$ This integral always exists for $t\in \mathbb{R}$.  I am trying to determine a ""good"" set of assumptions to place on $X$ so as to guarantee that this integral makes sense for all $t\in \mathbb{C}$ and so that the resulting function is entire. I have tried several things, but to no avail.  I fear as if I have not even come up anything worthy of mentioning.  Any thoughts/hints/suggestions/solutions would be most welcome. Thanks much!","Let $X$ be a random variable with distribution $\mu _X$.  Then, we define the characteristic function of $X$, $\phi _X$, by $$ \phi _X(t)\equiv \mathrm{E}\left[ e^{itX}\right] =\int _\mathbb{R} e^{itx}d\mu _X(x) $$ This integral always exists for $t\in \mathbb{R}$.  I am trying to determine a ""good"" set of assumptions to place on $X$ so as to guarantee that this integral makes sense for all $t\in \mathbb{C}$ and so that the resulting function is entire. I have tried several things, but to no avail.  I fear as if I have not even come up anything worthy of mentioning.  Any thoughts/hints/suggestions/solutions would be most welcome. Thanks much!",,"['probability', 'complex-analysis', 'probability-theory', 'probability-distributions']"
78,"Conditional expectation $E[X_0|X_0X_1,\ldots, X_0X_n]$.",Conditional expectation .,"E[X_0|X_0X_1,\ldots, X_0X_n]","Consider iid random variables $(X_j)_{j\in\mathbb{N}_0}$ uniformly distributed on $[0,1]$ . For $j\in\mathbb{N}$ define $V_j:=X_0X_j$ and the recursively defined estimator $W_j:=\max (W_{j-1},V_j)$ with $W_0:=0$ . I want to compute 1. $E[X_0|\mathcal{F}_j^V]$ , the MMSE-estimator, 2. the mean square error $E[(X_0-W_j)^2]$ , 3. the convergence rate of $E[(X_0-W_j)^2]$ . My attempt: 1. With this part, I struggle most. I have done the following: From product distribution of two uniform distribution, what about 3 or more , it holds $f_{V_1}(x)=-\log(x)$ . Then for $[a,b]\subset(0,1)$ , I find $$ \begin{aligned} E[X_01_{X_0\in[a,b]}] =\int_a^bxdx \end{aligned} $$ and $$ \begin{aligned} E[-\frac{V_1}{\log(V_1)}1_{V_1\in[a,b]}]=\int_a^b-\frac{x}{\log(x)}(-\log(x))dx=\int_a^bxdx \end{aligned} $$ I am not sure, if this is even useful or how to connect the integrals, such that $1_A$ shows up on both sides for $A\in\sigma(V_1,\ldots, V_j)$ . Does the MMSE-estimator even coincide with the conditional expectation? 2. With this part I am quite confident. By observation, I find $$W_j=X_0\max (X_1,\ldots, X_j),$$ and by independence of $g(X_0)=X_0^2$ from $f(X_1,\ldots,X_j)=(1-\max(X_1,\ldots, X_n))^2$ , I find $$E[(X_0-W_j)^2]=E[X_0^2(1-\max (X_1,\ldots, X_j))^2]=E[X_0^2]E[(1-\max (X_1,\ldots, X_j))^2].$$ Using Expected value of $\max\{X_1,\ldots,X_n\}$ where $X_i$ are iid uniform. , I end up with $$E[(X_0-W_j)^2]=C\frac{1}{(j+1)(j+2)}.$$ 3. the rate of convergence is therefore $j^2$ . It would be great, if someone can check over it. I can add further details, if necessary! Any hint or help is appreciated! Thank you in advance!","Consider iid random variables uniformly distributed on . For define and the recursively defined estimator with . I want to compute 1. , the MMSE-estimator, 2. the mean square error , 3. the convergence rate of . My attempt: 1. With this part, I struggle most. I have done the following: From product distribution of two uniform distribution, what about 3 or more , it holds . Then for , I find and I am not sure, if this is even useful or how to connect the integrals, such that shows up on both sides for . Does the MMSE-estimator even coincide with the conditional expectation? 2. With this part I am quite confident. By observation, I find and by independence of from , I find Using Expected value of $\max\{X_1,\ldots,X_n\}$ where $X_i$ are iid uniform. , I end up with 3. the rate of convergence is therefore . It would be great, if someone can check over it. I can add further details, if necessary! Any hint or help is appreciated! Thank you in advance!","(X_j)_{j\in\mathbb{N}_0} [0,1] j\in\mathbb{N} V_j:=X_0X_j W_j:=\max (W_{j-1},V_j) W_0:=0 E[X_0|\mathcal{F}_j^V] E[(X_0-W_j)^2] E[(X_0-W_j)^2] f_{V_1}(x)=-\log(x) [a,b]\subset(0,1) 
\begin{aligned}
E[X_01_{X_0\in[a,b]}]
=\int_a^bxdx
\end{aligned}
 
\begin{aligned}
E[-\frac{V_1}{\log(V_1)}1_{V_1\in[a,b]}]=\int_a^b-\frac{x}{\log(x)}(-\log(x))dx=\int_a^bxdx
\end{aligned}
 1_A A\in\sigma(V_1,\ldots, V_j) W_j=X_0\max (X_1,\ldots, X_j), g(X_0)=X_0^2 f(X_1,\ldots,X_j)=(1-\max(X_1,\ldots, X_n))^2 E[(X_0-W_j)^2]=E[X_0^2(1-\max (X_1,\ldots, X_j))^2]=E[X_0^2]E[(1-\max (X_1,\ldots, X_j))^2]. E[(X_0-W_j)^2]=C\frac{1}{(j+1)(j+2)}. j^2","['probability', 'probability-theory', 'conditional-expectation']"
79,Proving a combinatorial quantity is uniformly distributed,Proving a combinatorial quantity is uniformly distributed,,"Shorter Version. Pick a list $\mathbf{a}$ of length $n$ , taking in values in $\{1,2,\ldots,n+1\}$ at random. Then sort $\mathbf{a}$ in increasing order to obtain $\mathbf{a}' = (a_{(1)}, \ldots, a_{(n)})$ , and count the number of times $a_{(k)} \leq k$ holds. Conjecture: The resulting count takes in values $0, 1, \ldots, n$ equally likely. How do we prove or disprove this conjecture? Longer Version. The setting is as follows: $\mathcal{A}_n = \{1, 2, \ldots, n+1\}^n$ is the collection of all lists of length $n$ taking integer values between $1$ and $n+1$ . For each list $\mathbf{a} \in \mathcal{A}_n $ , we sort $a$ in increasing order to obtain $\mathtt{sort}(\mathbf{a}) = (a_{(k)})_{k=1}^{n}$ . Equivalently, $a_{(k)}$ denotes the $k$ th smallest element in $\mathbf{a}$ . For example, $$ \mathtt{sort}(5, 1, 2, 7, 5, 2) = (1, 2, 2, 5, 5, 7). $$ Then, define the function $\mathtt{below}(\mathbf{a})$ as the number of $k$ 's for which $a_{(k)} \leq k$ holds, that is, $\mathtt{below}(\mathbf{a}) = \sum_{k=1}^{n} \mathbf{1}[a_{(k)} \leq k]$ . For example, $$ \mathtt{below}(5, 1, 2, 7, 5, 2) = \mathtt{below}(\underline{1}, \underline{2}, \underline{2}, 5, \underline{5}, 7) = 4. $$ While playing with this setting with computer software, I noticed some patterns that eventually led me to formulate the following conjecture: Conjecture. Sample $A$ from $\mathcal{A}_n$ uniformly at random. Then $\mathtt{below}(A)$ is uniformly distributed over the set $\{0, 1, \ldots, n\}$ . How do we prove or disprove this? Discussion. For example, if $n = 2$ , then $$ \begin{array}{c} \mathbf{a} \\  (1, 1) \\ (1, 2) \\ (1, 3) \\ (2, 1) \\ (2, 2) \\ (2, 3) \\ (3, 1) \\ (3, 2) \\ (3, 3) \end{array} \quad \longrightarrow \quad \begin{array}{c} \mathtt{sort}(\mathbf{a}) \\  (1, 1) \\ (1, 2) \\ (1, 3) \\ (1, 2) \\ (2, 2) \\ (2, 3) \\ (1, 3) \\ (2, 3) \\ (3, 3) \end{array} \quad \longrightarrow \quad \begin{array}{c} \mathtt{below}(\mathbf{a}) \\  2\vphantom{,)} \\ 2\vphantom{,)} \\ 1\vphantom{,)} \\ 2\vphantom{,)} \\ 1\vphantom{,)} \\ 0\vphantom{,)} \\ 1\vphantom{,)} \\ 0\vphantom{,)}\\ 0\vphantom{,)} \end{array} $$ and hence $\mathtt{below}(A)$ takes values $0, 1, 2$ with equal probabilities. Also, using computer software, I tested this conjecture for $n \leq 7$ . However, brute-force search goes quickly out of hand as $n$ gets larger. And I was unable to come up with a nice explanation of this observation, letting alone a proof. Context. This can be thought of as a discrete analog of the fact that, for the Brownian bridge $(B_t)_{t\in[0,1]}$ joining $(0, 0)$ to $(1, 0)$ , the occupation time $\int_{0}^{1} \mathbf{1}[B_t \geq 0] \, \mathrm{d}t$ is uniformly distributed over $[0, 1]$ . Indeed, a version of invariance principle tells that $$t \mapsto n^{-1/2}(\lfloor nt\rfloor - a_{(\lfloor nt\rfloor)})$$ tends to the Brownian bridge as $n \to \infty$ in an appropriate sense. So, it is reasonable to expect that $\mathtt{below}(A)$ is approximately uniformly distributed. What is quite surprising is that $\mathtt{below}(A)$ seems exactly uniformly distributed.","Shorter Version. Pick a list of length , taking in values in at random. Then sort in increasing order to obtain , and count the number of times holds. Conjecture: The resulting count takes in values equally likely. How do we prove or disprove this conjecture? Longer Version. The setting is as follows: is the collection of all lists of length taking integer values between and . For each list , we sort in increasing order to obtain . Equivalently, denotes the th smallest element in . For example, Then, define the function as the number of 's for which holds, that is, . For example, While playing with this setting with computer software, I noticed some patterns that eventually led me to formulate the following conjecture: Conjecture. Sample from uniformly at random. Then is uniformly distributed over the set . How do we prove or disprove this? Discussion. For example, if , then and hence takes values with equal probabilities. Also, using computer software, I tested this conjecture for . However, brute-force search goes quickly out of hand as gets larger. And I was unable to come up with a nice explanation of this observation, letting alone a proof. Context. This can be thought of as a discrete analog of the fact that, for the Brownian bridge joining to , the occupation time is uniformly distributed over . Indeed, a version of invariance principle tells that tends to the Brownian bridge as in an appropriate sense. So, it is reasonable to expect that is approximately uniformly distributed. What is quite surprising is that seems exactly uniformly distributed.","\mathbf{a} n \{1,2,\ldots,n+1\} \mathbf{a} \mathbf{a}' = (a_{(1)}, \ldots, a_{(n)}) a_{(k)} \leq k 0, 1, \ldots, n \mathcal{A}_n = \{1, 2, \ldots, n+1\}^n n 1 n+1 \mathbf{a} \in \mathcal{A}_n  a \mathtt{sort}(\mathbf{a}) = (a_{(k)})_{k=1}^{n} a_{(k)} k \mathbf{a}  \mathtt{sort}(5, 1, 2, 7, 5, 2) = (1, 2, 2, 5, 5, 7).  \mathtt{below}(\mathbf{a}) k a_{(k)} \leq k \mathtt{below}(\mathbf{a}) = \sum_{k=1}^{n} \mathbf{1}[a_{(k)} \leq k]  \mathtt{below}(5, 1, 2, 7, 5, 2) = \mathtt{below}(\underline{1}, \underline{2}, \underline{2}, 5, \underline{5}, 7) = 4.  A \mathcal{A}_n \mathtt{below}(A) \{0, 1, \ldots, n\} n = 2  \begin{array}{c}
\mathbf{a} \\ 
(1, 1) \\ (1, 2) \\ (1, 3) \\ (2, 1) \\ (2, 2) \\ (2, 3) \\ (3, 1) \\ (3, 2) \\ (3, 3)
\end{array}
\quad
\longrightarrow
\quad
\begin{array}{c}
\mathtt{sort}(\mathbf{a}) \\ 
(1, 1) \\ (1, 2) \\ (1, 3) \\ (1, 2) \\ (2, 2) \\ (2, 3) \\ (1, 3) \\ (2, 3) \\ (3, 3)
\end{array}
\quad
\longrightarrow
\quad
\begin{array}{c}
\mathtt{below}(\mathbf{a}) \\ 
2\vphantom{,)} \\ 2\vphantom{,)} \\ 1\vphantom{,)} \\ 2\vphantom{,)} \\ 1\vphantom{,)} \\ 0\vphantom{,)} \\ 1\vphantom{,)} \\ 0\vphantom{,)}\\ 0\vphantom{,)}
\end{array}
 \mathtt{below}(A) 0, 1, 2 n \leq 7 n (B_t)_{t\in[0,1]} (0, 0) (1, 0) \int_{0}^{1} \mathbf{1}[B_t \geq 0] \, \mathrm{d}t [0, 1] t \mapsto n^{-1/2}(\lfloor nt\rfloor - a_{(\lfloor nt\rfloor)}) n \to \infty \mathtt{below}(A) \mathtt{below}(A)","['probability', 'combinatorics', 'uniform-distribution']"
80,Probability of Twisting a Phone Cord During a Call,Probability of Twisting a Phone Cord During a Call,,"I invented this problem and am unable to solve it. It is not a homework problem. I make a phone call on a standard handset (with a coiled cord). I start with the phone on my right ear. With probability p I talk long enough that I transfer the phone to my left ear, putting a twist in the cord. If I hang up at that point the cord remains twisted. But at probability p^2 I talk even longer and transfer the phone back to my right ear, removing the twist. At p^3 I put the twist back, and at p^4 I remove the twist again, and so on. If the call can be unbounded, how do I compute the probability P(p) that a call will put a twist in the cord? Here is a diagram of the call, where the (possibly infinite) call is on the horizontal and the possible hang-ups on the vertical. 1 means a twist, and 0 means no twist. p^1       p^2       p^3       p^4    0---------1---------0---------1---------0...  Phone call -->    |         |         |         |    | 1-p^1   | 1-p^2   | 1-p^3   | 1-p^4         Hangups |    |         |         |         |                       |    0         1         0         1                       v  There are scenarios that result in a 1:  Q1 = p^1 * (1 - p^2)             Twist and no untwist Q3 = p^1 * p^2 * p^3 * (1 - p^4) Twist, untwist, twist again and no untwist Q5 = p^1 * p^2 * p^3 * p^4 * p^5 * (1 - p^6) Two aborted twists and a twist ... For any given call, there can be at most one Q. But that seems to mean the exclusive-or of an infinite number of Qs! How can that be done? Or is that the wrong approach? I'm looking for: How to calculate P(p)? What is the limit of P(p) as p approaches 1.0? (if it exists) (Graphs of P(p) and (P(p) - p) might be interesting) Update: When p is 1.0 my Q scenarios all go to 0 because of the last term. It is impossible to avoid untwisting.","I invented this problem and am unable to solve it. It is not a homework problem. I make a phone call on a standard handset (with a coiled cord). I start with the phone on my right ear. With probability p I talk long enough that I transfer the phone to my left ear, putting a twist in the cord. If I hang up at that point the cord remains twisted. But at probability p^2 I talk even longer and transfer the phone back to my right ear, removing the twist. At p^3 I put the twist back, and at p^4 I remove the twist again, and so on. If the call can be unbounded, how do I compute the probability P(p) that a call will put a twist in the cord? Here is a diagram of the call, where the (possibly infinite) call is on the horizontal and the possible hang-ups on the vertical. 1 means a twist, and 0 means no twist. p^1       p^2       p^3       p^4    0---------1---------0---------1---------0...  Phone call -->    |         |         |         |    | 1-p^1   | 1-p^2   | 1-p^3   | 1-p^4         Hangups |    |         |         |         |                       |    0         1         0         1                       v  There are scenarios that result in a 1:  Q1 = p^1 * (1 - p^2)             Twist and no untwist Q3 = p^1 * p^2 * p^3 * (1 - p^4) Twist, untwist, twist again and no untwist Q5 = p^1 * p^2 * p^3 * p^4 * p^5 * (1 - p^6) Two aborted twists and a twist ... For any given call, there can be at most one Q. But that seems to mean the exclusive-or of an infinite number of Qs! How can that be done? Or is that the wrong approach? I'm looking for: How to calculate P(p)? What is the limit of P(p) as p approaches 1.0? (if it exists) (Graphs of P(p) and (P(p) - p) might be interesting) Update: When p is 1.0 my Q scenarios all go to 0 because of the last term. It is impossible to avoid untwisting.",,['probability']
81,Random walk of a drunk man trying to find his way home,Random walk of a drunk man trying to find his way home,,"The problem is stated as the following: Suppose we have a man walking along a pavement, whose width is 5. For each step forward, the drunk man can either move to the left, or to the right. Both outcomes are equally as likely. However, when the drunk man encounters the 5th position, he must return to the 4th, and when the drunk man encounters the 1st position, he can either go left or right. If he chooses to go right, the drunk man falls off, and the game ends. The question is now: How far on average will the walker walk? What is the probability of the walker returning home after moving K positions. I'll try to solve the latter question, since I believe it's easier for me. First of all, we have to form our transition matrix T. $$ T = \begin{pmatrix} 1 & 0 & 0 & 0 & 0 & 0 \\ 1/2 & 0 & 1/2 &  0& 0 & 0 \\ 0 & 1/2 & 0 & 1/2 & 0 & 0 \\ 0 & 0 & 1/2 & 0 & 1/2 & 0 \\ 0 & 0 & 0 & 1/2 & 0 & 1/2 \\ 0 & 0 & 0 & 0 & 1 & 0 \\ \end{pmatrix} $$ Where the rows are indexed as E,1,2,...,5 where E stands for ""end"", and thus the random walk terminates if the drunk man falls into this position. To answer what the probability for the walker to arrive at home after K positions, we can note one obivous fact If the K moves are odd, the probability of returning home is $0$ . We might need to use this later to check whether our answer is reasonable. More generally, we can write the probability of returning home after $K$ positions, which we can denote as the event $H_K$ , as: $$ P(H_K) = \begin{pmatrix}  0& 0 & 0 & 1 & 0 & 0 \end{pmatrix} T^k \cdot \begin{pmatrix}  0& 0 & 0 & 1 & 0 & 0 \end{pmatrix}  $$ However, I don't really know if there's any way to create a closed form expression for this probability given this. It's not really that easy to calculate $T^k$ for some general $k$ too. I tried to plot the probabilities of the positions after 30 steps in Python, and got this graph: Notice, position $1$ is what I previously labeled as position $E$ . Position $2$ in the graph represents position $1$ in my previous definition, and so forth. I also tried to plot the probabilities after 100 steps, and it really looks some exponential decay regarding the probabilites for positions. So I assume there might be some easy expression to derive from this. For the question regarding how far the walker will get on average, I've really no idea how to start. I'm thinking that I want to find the expected value of arriving at position $E$ given that our starting position is $3$ . However, I don't really know how to express this in terms of our transition matrix $T$ . I'd be glad if anyone could share their ideas for this problem. Thanks in advance.","The problem is stated as the following: Suppose we have a man walking along a pavement, whose width is 5. For each step forward, the drunk man can either move to the left, or to the right. Both outcomes are equally as likely. However, when the drunk man encounters the 5th position, he must return to the 4th, and when the drunk man encounters the 1st position, he can either go left or right. If he chooses to go right, the drunk man falls off, and the game ends. The question is now: How far on average will the walker walk? What is the probability of the walker returning home after moving K positions. I'll try to solve the latter question, since I believe it's easier for me. First of all, we have to form our transition matrix T. Where the rows are indexed as E,1,2,...,5 where E stands for ""end"", and thus the random walk terminates if the drunk man falls into this position. To answer what the probability for the walker to arrive at home after K positions, we can note one obivous fact If the K moves are odd, the probability of returning home is . We might need to use this later to check whether our answer is reasonable. More generally, we can write the probability of returning home after positions, which we can denote as the event , as: However, I don't really know if there's any way to create a closed form expression for this probability given this. It's not really that easy to calculate for some general too. I tried to plot the probabilities of the positions after 30 steps in Python, and got this graph: Notice, position is what I previously labeled as position . Position in the graph represents position in my previous definition, and so forth. I also tried to plot the probabilities after 100 steps, and it really looks some exponential decay regarding the probabilites for positions. So I assume there might be some easy expression to derive from this. For the question regarding how far the walker will get on average, I've really no idea how to start. I'm thinking that I want to find the expected value of arriving at position given that our starting position is . However, I don't really know how to express this in terms of our transition matrix . I'd be glad if anyone could share their ideas for this problem. Thanks in advance."," T = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 \\
1/2 & 0 & 1/2 &  0& 0 & 0 \\
0 & 1/2 & 0 & 1/2 & 0 & 0 \\
0 & 0 & 1/2 & 0 & 1/2 & 0 \\
0 & 0 & 0 & 1/2 & 0 & 1/2 \\
0 & 0 & 0 & 0 & 1 & 0 \\
\end{pmatrix}  0 K H_K  P(H_K) = \begin{pmatrix}
 0& 0 & 0 & 1 & 0 & 0
\end{pmatrix} T^k \cdot \begin{pmatrix}
 0& 0 & 0 & 1 & 0 & 0
\end{pmatrix}
  T^k k 1 E 2 1 E 3 T","['probability', 'expected-value', 'markov-chains', 'markov-process', 'random-walk']"
82,Find the quantity: $P \left(\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \} \right)$,Find the quantity:,P \left(\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \} \right),"Let $U_1,...,U_n$ be i.i.d. $U(0,1)$ and $U_{(1)},...,U_{(n)}$ be their order statistics. For $n=1,2,...$ ,  find the quantity: $$ P \left(\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \} \right) $$ where $0 \le \alpha \le 1$ . My approach: We can write $$ \begin{align*} P \left(\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \} \right) & = E \left[ I_{\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \}} \right] \\ & = E \left[ \prod_{j=1}^{n} I_{\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \}} \right] \\ & = E \left[ E \left [ \prod_{j=1}^{n} I_{\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \}} | U_{(n)} \right ] \right ] \\ & = E \left[ E \left [ \prod_{j=1}^{n} I_{\bigcap_{j=1}^{n} \left \{\frac{U_{(j)}}{U_{(n)}} > \frac{\alpha j}{nt} \right \}} | U_{(n)}=t \right ] \right ] \\ & = E \left[  \prod_{j=1}^{n} P  \left \{ \frac{U_{(j)}}{U_{(n)}} > \frac{\alpha j}{nt} \right \} \right ] \ \text{using Basu's Theorem} \\ \end{align*} $$ I am not sure if I am doing this the right way. I used the fact that $\left \{ \frac{U_{(1)}}{U_{(n)}},...,\frac{U_{(n-1)}}{U_{(n)}} \right \}$ and $U_{(n)}$ are independent. Even if this is correct, how should I compute the probability in the last step? Is there an easier way out? Thanks.","Let be i.i.d. and be their order statistics. For ,  find the quantity: where . My approach: We can write I am not sure if I am doing this the right way. I used the fact that and are independent. Even if this is correct, how should I compute the probability in the last step? Is there an easier way out? Thanks.","U_1,...,U_n U(0,1) U_{(1)},...,U_{(n)} n=1,2,...  P \left(\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \} \right)  0 \le \alpha \le 1  \begin{align*}
P \left(\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \} \right) & = E \left[ I_{\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \}} \right] \\
& = E \left[ \prod_{j=1}^{n} I_{\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \}} \right] \\
& = E \left[ E \left [ \prod_{j=1}^{n} I_{\bigcap_{j=1}^{n} \left \{U_{(j)} > \frac{\alpha j}{n} \right \}} | U_{(n)} \right ] \right ] \\
& = E \left[ E \left [ \prod_{j=1}^{n} I_{\bigcap_{j=1}^{n} \left \{\frac{U_{(j)}}{U_{(n)}} > \frac{\alpha j}{nt} \right \}} | U_{(n)}=t \right ] \right ] \\
& = E \left[  \prod_{j=1}^{n} P  \left \{ \frac{U_{(j)}}{U_{(n)}} > \frac{\alpha j}{nt} \right \} \right ] \ \text{using Basu's Theorem} \\
\end{align*}
 \left \{ \frac{U_{(1)}}{U_{(n)}},...,\frac{U_{(n-1)}}{U_{(n)}} \right \} U_{(n)}","['probability', 'statistics', 'independence', 'uniform-distribution', 'order-statistics']"
83,"Deceptively simple problem to find expected number of seconds it takes a particle to exit $(-1, 1)$",Deceptively simple problem to find expected number of seconds it takes a particle to exit,"(-1, 1)","I've been working through past MIT Primes problems, and got stuck on 2021 Problem M4: A particle is initially on the number line at a position of $0$ .  Every second, if it is at position $x$ , it chooses a real number $t \in [−1, 1]$ uniformly and at random, and moves from $x$ to $x+t$ . Find the expected value of the number of seconds it takes for the particle to exit the interval $(−1, 1)$ . I've been trying to solve it differently from the solution they provided. Let me outline my approach. Let $X$ denote the number of seconds it takes the particle to exit $[-1, 1]$ . Then, we are looking for $$ \text{E}[X] = \sum_x x \Pr(X=x) $$ The PMF of $X$ is $$ \Pr(X = x) = \Big( 1 - \Pr(-1 < X_x < 1) \Big) \prod_{i=1}^{x-1} \Pr(-1 < X_i < 1) $$ where $X_t$ is $X$ at time $t$ . We have now punted the problem to finding $\Pr(-1 < X_i < 1)$ for all $i$ . Remember, each $X_i$ is dependent on $X_{i-1}$ . We can make a step towards finding $\Pr(-1 < X_i < 1)$ using the law of total probability: $$ \Pr(X_i \leq x) = \int_{-\infty}^\infty \Pr(X_i \leq x \mid X_{i-1}=y) f_{X_{i-1}}(y) \ \text{d}y $$ $\Pr(X_i \leq x \mid X_{i-1}=y)$ can be defined as a piecewise function (I derived this by fixing $y$ , and then considering $x$ ): $$ \Pr(X_i \leq x \mid X_{i-1}=y) = \begin{cases} \frac{x+1}{2+y} & -1 \leq y < 0 \; \land \; x \leq y + 1 \\ 1 & -1 \leq y < 0 \; \land \; x > y + 1 \\ \frac{x-y+1}{2-y} & 0 \leq y < 1 \; \land \; x \geq y - 1 \\ 0 & 0 \leq y < 1 \; \land \; x < y - 1 \end{cases} $$ We also know that $f_{X_{i-1}}(y)$ is the derivative of $\Pr(X_{i-1} \leq y)$ . Because $\Pr(X_1 \leq x) = (x + 1)/2$ , we can now find $\Pr(X_2 \leq x)$ . Now here is the problem. I evaluated $\Pr(X_2 \leq x)$ using the following Mathematica script: (* the piecewise function *) XiCDFconditional[x_, y_] = Piecewise[{     {(x + 1) / (2 + y), -1 <= y < 0 && x <= y + 1},     {1, -1 <= y < 0 && x > y + 1},     {(x - y + 1) / (2 - y), 0 <= y < 1 && x >= y - 1},     {0, 0 <= y < 1 && x < y - 1} }]; X1CDF[x_] = (x + 1) / 2; (* Pr(X2 <= x) *) X2CDF[x_] = Integrate[XiCDFconditional[x, y] * X1CDF'[y], {y, -Infinity, Infinity}] when I execute X2CDF[1] - X2CDF[-1] (i.e. $\Pr(-1 \leq X_2 \leq 1)$ ), I get $1$ , which is obviously incorrect. Where did I screw up? I feel like I might have subtly screwed up $\Pr(X_i \leq x \mid X_{i-1}=y)$ . Or maybe I didn't screw up, and I'm almost surely (pun intended) getting confused in the continuous world.","I've been working through past MIT Primes problems, and got stuck on 2021 Problem M4: A particle is initially on the number line at a position of .  Every second, if it is at position , it chooses a real number uniformly and at random, and moves from to . Find the expected value of the number of seconds it takes for the particle to exit the interval . I've been trying to solve it differently from the solution they provided. Let me outline my approach. Let denote the number of seconds it takes the particle to exit . Then, we are looking for The PMF of is where is at time . We have now punted the problem to finding for all . Remember, each is dependent on . We can make a step towards finding using the law of total probability: can be defined as a piecewise function (I derived this by fixing , and then considering ): We also know that is the derivative of . Because , we can now find . Now here is the problem. I evaluated using the following Mathematica script: (* the piecewise function *) XiCDFconditional[x_, y_] = Piecewise[{     {(x + 1) / (2 + y), -1 <= y < 0 && x <= y + 1},     {1, -1 <= y < 0 && x > y + 1},     {(x - y + 1) / (2 - y), 0 <= y < 1 && x >= y - 1},     {0, 0 <= y < 1 && x < y - 1} }]; X1CDF[x_] = (x + 1) / 2; (* Pr(X2 <= x) *) X2CDF[x_] = Integrate[XiCDFconditional[x, y] * X1CDF'[y], {y, -Infinity, Infinity}] when I execute X2CDF[1] - X2CDF[-1] (i.e. ), I get , which is obviously incorrect. Where did I screw up? I feel like I might have subtly screwed up . Or maybe I didn't screw up, and I'm almost surely (pun intended) getting confused in the continuous world.","0 x t \in [−1, 1] x x+t (−1, 1) X [-1, 1] 
\text{E}[X] = \sum_x x \Pr(X=x)
 X 
\Pr(X = x) = \Big( 1 - \Pr(-1 < X_x < 1) \Big) \prod_{i=1}^{x-1} \Pr(-1 < X_i < 1)
 X_t X t \Pr(-1 < X_i < 1) i X_i X_{i-1} \Pr(-1 < X_i < 1) 
\Pr(X_i \leq x) = \int_{-\infty}^\infty \Pr(X_i \leq x \mid X_{i-1}=y) f_{X_{i-1}}(y) \ \text{d}y
 \Pr(X_i \leq x \mid X_{i-1}=y) y x 
\Pr(X_i \leq x \mid X_{i-1}=y) =
\begin{cases}
\frac{x+1}{2+y} & -1 \leq y < 0 \; \land \; x \leq y + 1 \\
1 & -1 \leq y < 0 \; \land \; x > y + 1 \\
\frac{x-y+1}{2-y} & 0 \leq y < 1 \; \land \; x \geq y - 1 \\
0 & 0 \leq y < 1 \; \land \; x < y - 1
\end{cases}
 f_{X_{i-1}}(y) \Pr(X_{i-1} \leq y) \Pr(X_1 \leq x) = (x + 1)/2 \Pr(X_2 \leq x) \Pr(X_2 \leq x) \Pr(-1 \leq X_2 \leq 1) 1 \Pr(X_i \leq x \mid X_{i-1}=y)","['probability', 'stochastic-processes', 'expected-value', 'problem-solving', 'cumulative-distribution-functions']"
84,A very confusing statistics problem from a high school math student,A very confusing statistics problem from a high school math student,,"I have just made an account to ask this question, since nobody has been able to clear up my confusion as of yet. I am a high school student so if I am using incorrect terminology or notation I do apologize for any confusion that may occur. Say that one were to roll two fair, 6 sided dice, such that each number 1-6 has an equal chance of appearing. After the first roll, the sum of the presenting faces is recorded on a table  as 'N', the 1st term in a sequence. To continue the sequence, the dice are rolled N amount of times. There are two possibilities during this 'rolling period:' If during this rolling period a sum of N appears before the final roll, the remaining rolls are discarded and the number N is recorded as the next term in the sequence. If during this rolling period a sum of N does not appear at any time, the sum of the faces on the Nth roll are recorded as the next term in the sequence. I have two questions here about the resulting sequence from this procedure. 1: If the sequence is continued to the 10th term, what is the probability that the sequence consists of all 7s? 2: Now assume that N was determined to be 7, and is not included in the resulting sequence. The rest of the procedure is unchanged. If the sequence is continued infinitely, and each term is placed into a bar graph recording the prevalence of each possible sum, would the graph present a standard bellcurve? I came up with this situation and both questions while sitting in a Adv. Algebra 2/Trig class. I have solved the first question (I think), however I am both unable to answer the second question and very curious about the answer. If anybody wants to take a crack I'd be interested in seeing how this situation is approached. If anything is unclear or confusing let me know so that I can clarify.","I have just made an account to ask this question, since nobody has been able to clear up my confusion as of yet. I am a high school student so if I am using incorrect terminology or notation I do apologize for any confusion that may occur. Say that one were to roll two fair, 6 sided dice, such that each number 1-6 has an equal chance of appearing. After the first roll, the sum of the presenting faces is recorded on a table  as 'N', the 1st term in a sequence. To continue the sequence, the dice are rolled N amount of times. There are two possibilities during this 'rolling period:' If during this rolling period a sum of N appears before the final roll, the remaining rolls are discarded and the number N is recorded as the next term in the sequence. If during this rolling period a sum of N does not appear at any time, the sum of the faces on the Nth roll are recorded as the next term in the sequence. I have two questions here about the resulting sequence from this procedure. 1: If the sequence is continued to the 10th term, what is the probability that the sequence consists of all 7s? 2: Now assume that N was determined to be 7, and is not included in the resulting sequence. The rest of the procedure is unchanged. If the sequence is continued infinitely, and each term is placed into a bar graph recording the prevalence of each possible sum, would the graph present a standard bellcurve? I came up with this situation and both questions while sitting in a Adv. Algebra 2/Trig class. I have solved the first question (I think), however I am both unable to answer the second question and very curious about the answer. If anybody wants to take a crack I'd be interested in seeing how this situation is approached. If anything is unclear or confusing let me know so that I can clarify.",,"['probability', 'statistics', 'dice']"
85,Boundedness in probability of Stochastic Process,Boundedness in probability of Stochastic Process,,"This question is related to some other similar ones I did in the recent past. Let $X_t$ be a Stochastic Process defined through the equation $$\text{d}X_t=f(X_t,t)\text{d}t+\text{d}W_t,$$ where $f$ is a twice differentiable function such that $f(x)<a<0$ for all $x>k$ , and $X_0<k$ . What I am wishing to show is: For all $\epsilon>0$ there is $M>0$ (which we can WLOG assume to be bigger than $k$ ) such that for all $t\ge0$ it holds that $$\mathbb{P}[X_t>M]\le\epsilon.$$ What I tried to do is define $\tau_t$ as $\sup\{0<s<t: X_s=k\}$ , i.e. the last hitting time of the level $k$ before time $t$ , where the sup is set equal to $0$ if the set $\{0<s<t: X_s=k\}$ is empty. This should be a stopping time, even if last hitting times in general are not. Then, we can manipulate the given probability in this way: \begin{align*}\mathbb{P}[X_t>M]&=\underbrace{\mathbb{P}[X_t>M,\tau_t=0]}_{=0}+\underbrace{\mathbb{P}[X_t>M,\tau_t\ne0, X_t<k]}_{=0}+\mathbb{P}[X_t>M,\tau_t\ne0, X_t>k]\\ &\le\mathbb{P}[X_t-X_{\tau_t}>M-k,\tau_t\ne0]\\ &\le \mathbb{P}[a(t-\tau_t)+W_t-W_{\tau_t}>M-k, \tau_t\ne0]\\ &\le \mathbb{P}[a(t-\tau_t)+W_t-W_{\tau_t}>M-k].\end{align*} Since $a<0$ we can bound this probability uniformly over $t$ , and the claim should be proven. However, I think I've been too slick with some steps, and I want to make sure they are correct (in particular, the $\tau_t$ seems to be not a stopping time). Can someone help me find any potential errors? Also, is there a more straightforward way to prove this? Maybe I just didn't see an easier solution. EDIT: the $f$ in my specific problem satisfies the hypothesis $|f(x,t)-k_0|<\theta\cdot |x|+ \mu,$ for some constants $k_0, \theta$ and $\mu$ : is there some kind of comparison principle with the absolute value bound? I can't find it online, but if it exists, then I would be done, as the Ornstein-Uhlenbeck process is bounded in the sense I am looking for.","This question is related to some other similar ones I did in the recent past. Let be a Stochastic Process defined through the equation where is a twice differentiable function such that for all , and . What I am wishing to show is: For all there is (which we can WLOG assume to be bigger than ) such that for all it holds that What I tried to do is define as , i.e. the last hitting time of the level before time , where the sup is set equal to if the set is empty. This should be a stopping time, even if last hitting times in general are not. Then, we can manipulate the given probability in this way: Since we can bound this probability uniformly over , and the claim should be proven. However, I think I've been too slick with some steps, and I want to make sure they are correct (in particular, the seems to be not a stopping time). Can someone help me find any potential errors? Also, is there a more straightforward way to prove this? Maybe I just didn't see an easier solution. EDIT: the in my specific problem satisfies the hypothesis for some constants and : is there some kind of comparison principle with the absolute value bound? I can't find it online, but if it exists, then I would be done, as the Ornstein-Uhlenbeck process is bounded in the sense I am looking for.","X_t \text{d}X_t=f(X_t,t)\text{d}t+\text{d}W_t, f f(x)<a<0 x>k X_0<k \epsilon>0 M>0 k t\ge0 \mathbb{P}[X_t>M]\le\epsilon. \tau_t \sup\{0<s<t: X_s=k\} k t 0 \{0<s<t: X_s=k\} \begin{align*}\mathbb{P}[X_t>M]&=\underbrace{\mathbb{P}[X_t>M,\tau_t=0]}_{=0}+\underbrace{\mathbb{P}[X_t>M,\tau_t\ne0, X_t<k]}_{=0}+\mathbb{P}[X_t>M,\tau_t\ne0, X_t>k]\\
&\le\mathbb{P}[X_t-X_{\tau_t}>M-k,\tau_t\ne0]\\
&\le \mathbb{P}[a(t-\tau_t)+W_t-W_{\tau_t}>M-k, \tau_t\ne0]\\
&\le \mathbb{P}[a(t-\tau_t)+W_t-W_{\tau_t}>M-k].\end{align*} a<0 t \tau_t f |f(x,t)-k_0|<\theta\cdot |x|+ \mu, k_0, \theta \mu","['probability', 'solution-verification', 'brownian-motion', 'upper-lower-bounds']"
86,Bug moving on number line in random directions,Bug moving on number line in random directions,,"A bug at the origin moves on the number line either left or right $u$ units every second, where $u$ is am arbitrary real between -1 and 1. For example, the bug could go from 0 to -0.4 in one second, then -0.4 to 0.3 in the next second, etc.. How long (in seconds) do you expect the bug to take before it is more than or at least a distance 1 from the origin (i.e. its position is less than or equal -1 or greater than equal to 1)? EDIT #1 : I tried representing the expected value as a function of the position it is currently at, but couldn't get any further EDIT #2 : I ran a computer simulation for about 100 million trials and got an answer of around $5.36457$ , similar to @DreiCleaner . @Mike Earnest had a promising approach expanding on my [EDIT #1] . His appraoch: Let $f(x)$ be the expected value of remaining steps if you are currently at position $x$ . Then it can be shown that $f(x)=1+\frac12\int_{\max(x-1,-1)}^{\min(x+1,1)} f(t)\,dt$ . I do not see why this is true yet.","A bug at the origin moves on the number line either left or right units every second, where is am arbitrary real between -1 and 1. For example, the bug could go from 0 to -0.4 in one second, then -0.4 to 0.3 in the next second, etc.. How long (in seconds) do you expect the bug to take before it is more than or at least a distance 1 from the origin (i.e. its position is less than or equal -1 or greater than equal to 1)? EDIT #1 : I tried representing the expected value as a function of the position it is currently at, but couldn't get any further EDIT #2 : I ran a computer simulation for about 100 million trials and got an answer of around , similar to @DreiCleaner . @Mike Earnest had a promising approach expanding on my [EDIT #1] . His appraoch: Let be the expected value of remaining steps if you are currently at position . Then it can be shown that . I do not see why this is true yet.","u u 5.36457 f(x) x f(x)=1+\frac12\int_{\max(x-1,-1)}^{\min(x+1,1)} f(t)\,dt","['probability', 'combinatorics', 'ordinary-differential-equations', 'probability-theory', 'expected-value']"
87,From disintegration to conditioning,From disintegration to conditioning,,"There is a paper ""Conditioning as disintegration"" by J. T. Chang and D. Pollard , which seems to construct the regular conditional probability from the disintegration . In particular, from Definition 1, Theorem 1 and Theorem 2.(iii) in that paper, we can summarize a theorem as follows: Theorem. Let $\Omega$ be a Polish space, $\mathcal F = \mathcal B(\Omega)$ be the Borel $\sigma$ -field for $\Omega$ , and $\mathbf P$ be a probability measure on $(\Omega,\mathcal F)$ . Let $(E,\mathcal E)$ be a measurable space, with $\mathcal E$ countably generated and containing all the singleton sets. Let $X:(\Omega,\mathcal F) \to (E,\mathcal E)$ be a random element. Denote by $P_X := X_*\mathbf P = \mathbf P\circ X^{-1}$ the pushforward measure of $X$ on $(E,\mathcal E)$ . Then there is a family $\{\mathbf P^x\}_{x\in E}$ of probability measures on $(\Omega,\mathcal F)$ , such that: For every $x\in E$ , the probability measure $\mathbf P^x$ concentrates on the event $\{X = x\}$ . For all $A\in\mathcal F$ , the mapping $\mathbf P^\cdot(A): (E,\mathcal E)\to [0,1]$ is measurable. For all $A\in\mathcal F$ and $B\in\mathcal E$ , \begin{equation}   \mathbf P\left(A\cap X^{-1}(B)\right) = \int_B \mathbf P^x(A) P_X (dx). \end{equation} Moreover, the family $\{\mathbf P^x\}_{x\in E}$ is uniquely determined up to an almost sure equivalence: if $\{\mathbf Q^x\}_{x\in E}$ is another family of probability measure on $(\Omega,\mathcal F)$ that satisfies above conditions, then \begin{equation*}   P_X\{x\in E: \mathbf P^x \ne \mathbf Q^x\} = 0. \end{equation*} Here is the problem . Consider the special case that $E=\Omega$ and $\mathcal E$ is a sub- $\sigma$ -field of $\mathcal F$ that contains all singletons. Since $\Omega$ is second countable, its Borel $\sigma$ -field $\mathcal F$ must be countably generated and contain all singletons . As a sub- $\sigma$ -field of $\mathcal F$ , $\mathcal E$ is also countably generated. Let $X = \mathrm{Id}$ . Then $P_\mathrm{Id} = \mathbf P$ and $\sigma(\mathrm{Id}) = \mathcal E$ . Now all assumptions in the theorem are fulfilled. Hence, we get a $\mathbf P$ -a.s. unique family of probability measures $\{\mathbf P^\omega\}_{\omega\in\Omega}$ on $(\Omega,\mathcal F)$ satisfying: For every $\omega\in\Omega$ , the probability measure $\mathbf P^\omega$ concentrates on the singleton $\{\omega\}$ . For all $A\in\mathcal F$ , the mapping $\mathbf P^\cdot(A): (\Omega,\mathcal E)\to [0,1]$ is measurable. For all $A\in\mathcal F$ and $B\in\mathcal E$ , \begin{equation}   \mathbf P\left(A\cap B\right) = \int_B \mathbf P^\omega(A) \mathbf P (dx). \end{equation} The statements 2 and 3 are completely the same as the formulation of conditional probability , that is, $\mathbf P^\omega(A) = \mathbf P(A\mid \mathcal E)(\omega)$ . However, if we combine them with the statement 1, then there are something quite strange. Indeed, since $\mathbf P^\omega$ concentrates on $\{\omega\}$ , we have $\mathbf P^\omega(A) = \mathrm{1}_A(\omega)$ for all $A\in\mathcal F$ , while this should hold only for $A\in\mathcal E$ since $\mathbf P^\omega$ is the conditional probability by statement 3. Besides, the mapping $\mathbf P^\cdot(A) = \mathrm{1}_A: (\Omega,\mathcal E)\to [0,1]$ is measurable only for $A\in\mathcal E$ , but not for all $A\in\mathcal F$ claimed in statement 2. So where does it go wrong? Any comments or hints will be appreciated. TIA... EDIT: Here are some further remarks: I just claimed that ""as a sub- $\sigma$ -field of $\mathcal F$ , $\mathcal E$ is also countably generated"". This is wrong. See e.g., here for a counterexample. Thanks to the comment by @aduh, the problem reduce to whether it must be $\mathcal E = \mathcal F$ ? Or does there exist a proper sub- $\sigma$ -field of $\mathcal F$ that is countably generated and contains all singletons? I post this as another question in Math.SE . Conclusion: Under my assumptions, $\mathcal E$ must coincide with $\mathcal F$ . So the problem is trivial. See the accepted answer given by @GEdgar in the ""another question"" I mentioned for details.","There is a paper ""Conditioning as disintegration"" by J. T. Chang and D. Pollard , which seems to construct the regular conditional probability from the disintegration . In particular, from Definition 1, Theorem 1 and Theorem 2.(iii) in that paper, we can summarize a theorem as follows: Theorem. Let be a Polish space, be the Borel -field for , and be a probability measure on . Let be a measurable space, with countably generated and containing all the singleton sets. Let be a random element. Denote by the pushforward measure of on . Then there is a family of probability measures on , such that: For every , the probability measure concentrates on the event . For all , the mapping is measurable. For all and , Moreover, the family is uniquely determined up to an almost sure equivalence: if is another family of probability measure on that satisfies above conditions, then Here is the problem . Consider the special case that and is a sub- -field of that contains all singletons. Since is second countable, its Borel -field must be countably generated and contain all singletons . As a sub- -field of , is also countably generated. Let . Then and . Now all assumptions in the theorem are fulfilled. Hence, we get a -a.s. unique family of probability measures on satisfying: For every , the probability measure concentrates on the singleton . For all , the mapping is measurable. For all and , The statements 2 and 3 are completely the same as the formulation of conditional probability , that is, . However, if we combine them with the statement 1, then there are something quite strange. Indeed, since concentrates on , we have for all , while this should hold only for since is the conditional probability by statement 3. Besides, the mapping is measurable only for , but not for all claimed in statement 2. So where does it go wrong? Any comments or hints will be appreciated. TIA... EDIT: Here are some further remarks: I just claimed that ""as a sub- -field of , is also countably generated"". This is wrong. See e.g., here for a counterexample. Thanks to the comment by @aduh, the problem reduce to whether it must be ? Or does there exist a proper sub- -field of that is countably generated and contains all singletons? I post this as another question in Math.SE . Conclusion: Under my assumptions, must coincide with . So the problem is trivial. See the accepted answer given by @GEdgar in the ""another question"" I mentioned for details.","\Omega \mathcal F = \mathcal B(\Omega) \sigma \Omega \mathbf P (\Omega,\mathcal F) (E,\mathcal E) \mathcal E X:(\Omega,\mathcal F) \to (E,\mathcal E) P_X := X_*\mathbf P = \mathbf P\circ X^{-1} X (E,\mathcal E) \{\mathbf P^x\}_{x\in E} (\Omega,\mathcal F) x\in E \mathbf P^x \{X = x\} A\in\mathcal F \mathbf P^\cdot(A): (E,\mathcal E)\to [0,1] A\in\mathcal F B\in\mathcal E \begin{equation}
  \mathbf P\left(A\cap X^{-1}(B)\right) = \int_B \mathbf P^x(A) P_X (dx).
\end{equation} \{\mathbf P^x\}_{x\in E} \{\mathbf Q^x\}_{x\in E} (\Omega,\mathcal F) \begin{equation*}
  P_X\{x\in E: \mathbf P^x \ne \mathbf Q^x\} = 0.
\end{equation*} E=\Omega \mathcal E \sigma \mathcal F \Omega \sigma \mathcal F \sigma \mathcal F \mathcal E X = \mathrm{Id} P_\mathrm{Id} = \mathbf P \sigma(\mathrm{Id}) = \mathcal E \mathbf P \{\mathbf P^\omega\}_{\omega\in\Omega} (\Omega,\mathcal F) \omega\in\Omega \mathbf P^\omega \{\omega\} A\in\mathcal F \mathbf P^\cdot(A): (\Omega,\mathcal E)\to [0,1] A\in\mathcal F B\in\mathcal E \begin{equation}
  \mathbf P\left(A\cap B\right) = \int_B \mathbf P^\omega(A) \mathbf P (dx).
\end{equation} \mathbf P^\omega(A) = \mathbf P(A\mid \mathcal E)(\omega) \mathbf P^\omega \{\omega\} \mathbf P^\omega(A) = \mathrm{1}_A(\omega) A\in\mathcal F A\in\mathcal E \mathbf P^\omega \mathbf P^\cdot(A) = \mathrm{1}_A: (\Omega,\mathcal E)\to [0,1] A\in\mathcal E A\in\mathcal F \sigma \mathcal F \mathcal E \mathcal E = \mathcal F \sigma \mathcal F \mathcal E \mathcal F","['probability', 'probability-theory', 'measure-theory', 'conditional-probability', 'conditional-expectation']"
88,Probability that the mean of a sequence of random variables never exceeds a critical value,Probability that the mean of a sequence of random variables never exceeds a critical value,,"Let $p,\mu_c \in [0,1]$ . Let $(X_i)_{i \in \mathbb{N}}$ be a sequence of i.i.d random variables, each following a Bernoulli distribution $\mathcal{B}(p)$ . For $n \in \mathbb{N}$ , let $ \mu_n = \frac{1}{n+1} \sum_{i=0}^n X_i $ and $A_n$ the event: "" $\mu_n \leq \mu_c$ "". I am looking for a way to compute $$ \mathbb{P} \left(\bigcap_{n \in \mathbb{N}} A_n \right), $$ that is, the probability that the mean of the sequence never exceeds the critical value $\mu_c$ . You can assume $\mu_c > p$ , since this probability is $0$ when $\mu_c \leq p$ . I first wanted to compute it using a martingale, but the optional stopping theorem does not seem to help. I don't know if computing it ""by hand"" (combinatorially) is possible, but it would be quite unsatisfying anyway. Eventually, it may be somehow linked to this post , but I don't understand Brownian motion well enough to use it correctly. Thank you for any advice! Edit: When $p = \frac{1}{2}$ and $\mu_c = \frac{3}{4}$ , simulations give $$\mathbb{P} \left(\bigcap_{n \leq 1000} A_n \right) \approx 0.456.$$ I think that this is a very good approximation of $\mathbb{P} \left(\bigcap_{n \in \mathbb{N}} A_n \right)$ (going up to 2000 does not affect the result). This fact may be used to check any suggested answer. I find it surprisingly high, since $\mathbb{P}(A_0)$ alone is equal to $\frac{1}{2}$ .","Let . Let be a sequence of i.i.d random variables, each following a Bernoulli distribution . For , let and the event: "" "". I am looking for a way to compute that is, the probability that the mean of the sequence never exceeds the critical value . You can assume , since this probability is when . I first wanted to compute it using a martingale, but the optional stopping theorem does not seem to help. I don't know if computing it ""by hand"" (combinatorially) is possible, but it would be quite unsatisfying anyway. Eventually, it may be somehow linked to this post , but I don't understand Brownian motion well enough to use it correctly. Thank you for any advice! Edit: When and , simulations give I think that this is a very good approximation of (going up to 2000 does not affect the result). This fact may be used to check any suggested answer. I find it surprisingly high, since alone is equal to .","p,\mu_c \in [0,1] (X_i)_{i \in \mathbb{N}} \mathcal{B}(p) n \in \mathbb{N}  \mu_n = \frac{1}{n+1} \sum_{i=0}^n X_i  A_n \mu_n \leq \mu_c  \mathbb{P} \left(\bigcap_{n \in \mathbb{N}} A_n \right),  \mu_c \mu_c > p 0 \mu_c \leq p p = \frac{1}{2} \mu_c = \frac{3}{4} \mathbb{P} \left(\bigcap_{n \leq 1000} A_n \right) \approx 0.456. \mathbb{P} \left(\bigcap_{n \in \mathbb{N}} A_n \right) \mathbb{P}(A_0) \frac{1}{2}","['probability', 'means']"
89,A confusing question on probability,A confusing question on probability,,"In a race, the probabilities of A and B winning the race are $\frac{1}{3}$ and $\frac{1}{6}$ respectively. Find the probability   of neither of them winning the race. I solved the question in the following manner- Since A and B are running in a race, probability of neither of them winning is $$1-\left(\frac{1}{3}+\frac{1}{6}\right)=\frac{1}{2}$$ However, all the solution books that I refer to are solving it in the following manner $$\left(1-\frac{1}{3}\right)\left(1-\frac{1}{6}\right)=\frac{5}{9}$$ Now this does not make any sense to me since the events of A winning and B winning are not independent. I was pretty confident of my answer but even the official answer key of the test has given $\frac{5}{9}$ as the answer. Where exactly am I wrong? How can the winning of A and B be independent of each other since given that one does not win, the winning chances of the other increases?","In a race, the probabilities of A and B winning the race are and respectively. Find the probability   of neither of them winning the race. I solved the question in the following manner- Since A and B are running in a race, probability of neither of them winning is However, all the solution books that I refer to are solving it in the following manner Now this does not make any sense to me since the events of A winning and B winning are not independent. I was pretty confident of my answer but even the official answer key of the test has given as the answer. Where exactly am I wrong? How can the winning of A and B be independent of each other since given that one does not win, the winning chances of the other increases?",\frac{1}{3} \frac{1}{6} 1-\left(\frac{1}{3}+\frac{1}{6}\right)=\frac{1}{2} \left(1-\frac{1}{3}\right)\left(1-\frac{1}{6}\right)=\frac{5}{9} \frac{5}{9},['probability']
90,How to approximate the expected minimum Hamming distance with $N \gg n$ strings,How to approximate the expected minimum Hamming distance with  strings,N \gg n,"If we sample $N \gg n$ binary strings of length $n$ , uniformly and   independently, what is the expected minimum Hamming distance between the closest pair? It seems likely this is hard to compute exactly so a good approximation would be very welcome. This related question asks specifically about the case where $N = 3$ . In a very nice answer @joriki sets out that the mean minimum Hamming distance in this case is approximately: $$ \boxed{\frac n2-\frac34\sqrt\frac n\pi}\;. $$ In order to have a concrete value to aim at: If $N=2^{12}$ and $n=50$ then the mean minimum Hamming distance is approximately $7.3$ . If $N=2^{12}$ and $n=64$ then the mean minimum Hamming distance is approximately $11.7$ . If $N=2^{14}$ and $n=50$ then the mean minimum Hamming distance is approximately $5.9$ . If $N=2^{14}$ and $n=150$ then the mean minimum Hamming distance is approximately $40.2$ .","If we sample binary strings of length , uniformly and   independently, what is the expected minimum Hamming distance between the closest pair? It seems likely this is hard to compute exactly so a good approximation would be very welcome. This related question asks specifically about the case where . In a very nice answer @joriki sets out that the mean minimum Hamming distance in this case is approximately: In order to have a concrete value to aim at: If and then the mean minimum Hamming distance is approximately . If and then the mean minimum Hamming distance is approximately . If and then the mean minimum Hamming distance is approximately . If and then the mean minimum Hamming distance is approximately .","N \gg n n N = 3 
\boxed{\frac n2-\frac34\sqrt\frac n\pi}\;.
 N=2^{12} n=50 7.3 N=2^{12} n=64 11.7 N=2^{14} n=50 5.9 N=2^{14} n=150 40.2",['probability']
91,"Random points on interval, expected lengths of pieces","Random points on interval, expected lengths of pieces",,"Many years ago I came across the following task. If we have the interval $[0; 1]$ and we throw $N$ uniformly distributed and mutually independent points on it, then we'll get $N+1$ segments. What is the expected length of the longest segment? The 2nd longest? Etc. For $N=1$ , the solution is trivial: $3/4$ and $1/4$ (since the longest segment is uniformly distributed in [1/2; 1] and the shorter one is uniformly distributed in $[0; 1/2]$ ). For $N=2$ , the solution is not trivial, but possible. One just has to draw a quadrat 1 x 1. A point in it would mean that the longest segment has the x coordinate, and the 2nd longest segment has the y coordinate (and the shortest one is 1 - 1st - 2nd). One then has to carefully draw the possible area (this will be a triangle), and find its middle point. But for $N>2$ I have no clue how to solve it. I remember, the book I saw the task in, had a general solution for arbitrary $N$ , but I don't know anymore what book it was. Note that the task is somewhat similar to Average Distance Between Random Points on a Line Segment , but just somewhat.","Many years ago I came across the following task. If we have the interval and we throw uniformly distributed and mutually independent points on it, then we'll get segments. What is the expected length of the longest segment? The 2nd longest? Etc. For , the solution is trivial: and (since the longest segment is uniformly distributed in [1/2; 1] and the shorter one is uniformly distributed in ). For , the solution is not trivial, but possible. One just has to draw a quadrat 1 x 1. A point in it would mean that the longest segment has the x coordinate, and the 2nd longest segment has the y coordinate (and the shortest one is 1 - 1st - 2nd). One then has to carefully draw the possible area (this will be a triangle), and find its middle point. But for I have no clue how to solve it. I remember, the book I saw the task in, had a general solution for arbitrary , but I don't know anymore what book it was. Note that the task is somewhat similar to Average Distance Between Random Points on a Line Segment , but just somewhat.",[0; 1] N N+1 N=1 3/4 1/4 [0; 1/2] N=2 N>2 N,"['probability', 'geometry']"
92,Probability of the Champions League quarter final draw featuring at least one all-English clash.,Probability of the Champions League quarter final draw featuring at least one all-English clash.,,"Four English teams have progressed to the Champion's League quarter finals this year (for the first time since 2008). What is the probability that at least one quarter final will be an all-English tie? My attempt Obviously this is the complement of there being no all-English ties. Suppose the order of the teams (and the fixtures) matters (i.e. $AB,\;CD,\;EF,\;GH$ is a different draw from $DC,\;AB,\;HG,\;EF$ ). Then there are $8!$ total possible draws. If we try to count the number of possible draws with no all-English ties, we have $8$ choices for the first team and $4$ for the second; $6$ choices for the third team and $3$ for the fourth; $4$ choices for the fifth team and $2$ for the sixth; $2$ choices for the seventh team and $1$ for the eighth. This makes $8\times4\times6\times3\times4\times2\times2\times1=9216$ draws with no all-English ties, so the probability of at least one all-English tie is \begin{equation} 1-\frac{9216}{8!}=\frac{27}{35}. \end{equation} Two questions: Have I got the right answer? What would be a more elegant way of going about this? Even if it is correct, I think my argument is 'lucky' in the sense that it wouldn't work for any other number of English teams.","Four English teams have progressed to the Champion's League quarter finals this year (for the first time since 2008). What is the probability that at least one quarter final will be an all-English tie? My attempt Obviously this is the complement of there being no all-English ties. Suppose the order of the teams (and the fixtures) matters (i.e. is a different draw from ). Then there are total possible draws. If we try to count the number of possible draws with no all-English ties, we have choices for the first team and for the second; choices for the third team and for the fourth; choices for the fifth team and for the sixth; choices for the seventh team and for the eighth. This makes draws with no all-English ties, so the probability of at least one all-English tie is Two questions: Have I got the right answer? What would be a more elegant way of going about this? Even if it is correct, I think my argument is 'lucky' in the sense that it wouldn't work for any other number of English teams.","AB,\;CD,\;EF,\;GH DC,\;AB,\;HG,\;EF 8! 8 4 6 3 4 2 2 1 8\times4\times6\times3\times4\times2\times2\times1=9216 \begin{equation}
1-\frac{9216}{8!}=\frac{27}{35}.
\end{equation}",['probability']
93,Convergence of a random created series,Convergence of a random created series,,"We know that: $\sum \limits _{n=1}^{\infty}\frac{1}{n} = \infty$ $\sum \limits _{n=1}^{\infty}\frac{(-1)^n}{n} < \infty$ Both are easy to show. In the first case we can use the criterion based on integrating the function $f(x) = \frac{1}{x}$ and the convergence of the second series can be settle with the Dirichlet's criterion. Let's imagine a random series: $$\sum \limits _{n=1}^{\infty}\frac{\lambda_n}{n},$$ where $\lambda = 1$ or $\lambda = -1$. $P(\lambda = 1) = P(\lambda = -1) = \frac{1}{2}$. When the series will converge?","We know that: $\sum \limits _{n=1}^{\infty}\frac{1}{n} = \infty$ $\sum \limits _{n=1}^{\infty}\frac{(-1)^n}{n} < \infty$ Both are easy to show. In the first case we can use the criterion based on integrating the function $f(x) = \frac{1}{x}$ and the convergence of the second series can be settle with the Dirichlet's criterion. Let's imagine a random series: $$\sum \limits _{n=1}^{\infty}\frac{\lambda_n}{n},$$ where $\lambda = 1$ or $\lambda = -1$. $P(\lambda = 1) = P(\lambda = -1) = \frac{1}{2}$. When the series will converge?",,"['probability', 'sequences-and-series', 'probability-theory', 'random']"
94,Are all probability density functions described by their mean and variance?,Are all probability density functions described by their mean and variance?,,"The question might be trivial, but I would like someone to correct me or confirm it. I know that the Normal (Gaussian) distribution is completely determined by its mean and variance, but does that hold for any other distribution? I assume that the answer is no. I could notice this is true for many distributions, but there are some exceptions. For example, mean and variance are undefined for the Cauchy distribution.","The question might be trivial, but I would like someone to correct me or confirm it. I know that the Normal (Gaussian) distribution is completely determined by its mean and variance, but does that hold for any other distribution? I assume that the answer is no. I could notice this is true for many distributions, but there are some exceptions. For example, mean and variance are undefined for the Cauchy distribution.",,"['probability', 'probability-theory', 'probability-distributions', 'density-function']"
95,Expanding Nebula: Problem in Cellular Automata or Coding Theory,Expanding Nebula: Problem in Cellular Automata or Coding Theory,,"First post to Math Stackexchange. Recently I was posed with a mathematically intensive computer programming challenge that I am completely at a loss for solving. To give you some info on my math background, I'm a senior physics major and computer science minor at university and have recently completed a course in linear algebra in addition to having taken calc 1, 2, multivariate calc, and diff eq. I have some small experience with discrete mathematics and number theory from an intro computer science course. I have applied linear algebra, discrete mathematics, and algebraic coding courses scheduled in the next 6 months but am not sure if I will cover the material to answer my problem. I would wait until after taking the courses to see if I can apply anything new to it but this problem has been driving me nuts. I'm not necessarily looking for a solution but rather some areas to look into that may help me to solve it. If more info or explanation is needed, please let me know. The problem is as follows: From the scans of the nebula, you have found that it is very flat and distributed in distinct patches, so you can model it as a 2D grid. You find that the current existence of gas in a cell of the grid is determined exactly by its 4 nearby cells, specifically, (1) that cell, (2) the cell below it, (3) the cell to the right of it, and (4) the cell below and to the right of it. If, in the current state, exactly 1 of those 4 cells in the 2x2 block has gas, then it will also have gas in the next state. Otherwise, the cell will be empty in the next state. For example, let's say the previous state of the grid (p) was: .O.. ..O. ...O O... To see how this grid will change to become the current grid (c) over the next time step, consider the 2x2 blocks of cells around each cell.  Of the 2x2 block of [p[0][0], p[0][1], p[1][0], p[1][1]], only p[0][1] has gas in it, which means this 2x2 block would become cell c[0][0] with gas in the next time step: .O -> O .. Likewise, in the next 2x2 block to the right consisting of [p[0][1], p[0][2], p[1][1], p[1][2]], two of the containing cells have gas, so in the next state of the grid, c[0][1] will NOT have gas: O. -> . .O Following this pattern to its conclusion, from the previous state p, the current state of the grid c will be: O.O .O. O.O Note that the resulting output will have 1 fewer row and column, since the bottom and rightmost cells do not have a cell below and to the right of them, respectively. Write a function answer(g) where g is an array of array of bools saying whether there is gas in each cell (the current scan of the nebula), and return an int with the number of possible previous states that could have resulted in that grid after 1 time step.  For instance, if the function were given the current state c above, it would deduce that the possible previous states were p (given above) as well as its horizontal and vertical reflections, and would return 4. The width of the grid will be between 3 and 50 inclusive, and the height of the grid will be between 3 and 9 inclusive.  The answer will always be less than one billion (10^9). Inputs: (boolean) g = [                 [true, false, true],                 [false, true, false],                 [true, false, true]               ] Output: (int) 4  Inputs: (boolean) g = [                 [true, false, true, false, false, true, true, true],                 [true, false, true, false, false, false, true, false],                 [true, true, true, false, false, false, true, false],                 [true, false, true, false, false, false, true, false],                 [true, false, true, false, false, true, true, true]               ] Output: (int) 254  Inputs: (boolean) g = [                 [true, true, false, true, false, true, false, true, true, false],                 [true, true, false, false, false, false, true, true, true, false],                 [true, true, false, false, false, false, false, false, false, true],                 [false, true, false, false, false, false, true, true, false, false]               ] Output: (int) 11567 I have looked into coding theory but don't think this falls into any of those categories. I have explored options in bit masking image processing, and cellular automata. The closest I have come to a solution is in researching Margolus neighborhood 2D cellular automata. As this isn't reversible by definition, I haven't found a solution or even general method to find a solution. I'm just curious where I should look. I know this has to have an answer stemming from a field in mathematics but it doesn't resemble anything I currently know.","First post to Math Stackexchange. Recently I was posed with a mathematically intensive computer programming challenge that I am completely at a loss for solving. To give you some info on my math background, I'm a senior physics major and computer science minor at university and have recently completed a course in linear algebra in addition to having taken calc 1, 2, multivariate calc, and diff eq. I have some small experience with discrete mathematics and number theory from an intro computer science course. I have applied linear algebra, discrete mathematics, and algebraic coding courses scheduled in the next 6 months but am not sure if I will cover the material to answer my problem. I would wait until after taking the courses to see if I can apply anything new to it but this problem has been driving me nuts. I'm not necessarily looking for a solution but rather some areas to look into that may help me to solve it. If more info or explanation is needed, please let me know. The problem is as follows: From the scans of the nebula, you have found that it is very flat and distributed in distinct patches, so you can model it as a 2D grid. You find that the current existence of gas in a cell of the grid is determined exactly by its 4 nearby cells, specifically, (1) that cell, (2) the cell below it, (3) the cell to the right of it, and (4) the cell below and to the right of it. If, in the current state, exactly 1 of those 4 cells in the 2x2 block has gas, then it will also have gas in the next state. Otherwise, the cell will be empty in the next state. For example, let's say the previous state of the grid (p) was: .O.. ..O. ...O O... To see how this grid will change to become the current grid (c) over the next time step, consider the 2x2 blocks of cells around each cell.  Of the 2x2 block of [p[0][0], p[0][1], p[1][0], p[1][1]], only p[0][1] has gas in it, which means this 2x2 block would become cell c[0][0] with gas in the next time step: .O -> O .. Likewise, in the next 2x2 block to the right consisting of [p[0][1], p[0][2], p[1][1], p[1][2]], two of the containing cells have gas, so in the next state of the grid, c[0][1] will NOT have gas: O. -> . .O Following this pattern to its conclusion, from the previous state p, the current state of the grid c will be: O.O .O. O.O Note that the resulting output will have 1 fewer row and column, since the bottom and rightmost cells do not have a cell below and to the right of them, respectively. Write a function answer(g) where g is an array of array of bools saying whether there is gas in each cell (the current scan of the nebula), and return an int with the number of possible previous states that could have resulted in that grid after 1 time step.  For instance, if the function were given the current state c above, it would deduce that the possible previous states were p (given above) as well as its horizontal and vertical reflections, and would return 4. The width of the grid will be between 3 and 50 inclusive, and the height of the grid will be between 3 and 9 inclusive.  The answer will always be less than one billion (10^9). Inputs: (boolean) g = [                 [true, false, true],                 [false, true, false],                 [true, false, true]               ] Output: (int) 4  Inputs: (boolean) g = [                 [true, false, true, false, false, true, true, true],                 [true, false, true, false, false, false, true, false],                 [true, true, true, false, false, false, true, false],                 [true, false, true, false, false, false, true, false],                 [true, false, true, false, false, true, true, true]               ] Output: (int) 254  Inputs: (boolean) g = [                 [true, true, false, true, false, true, false, true, true, false],                 [true, true, false, false, false, false, true, true, true, false],                 [true, true, false, false, false, false, false, false, false, true],                 [false, true, false, false, false, false, true, true, false, false]               ] Output: (int) 11567 I have looked into coding theory but don't think this falls into any of those categories. I have explored options in bit masking image processing, and cellular automata. The closest I have come to a solution is in researching Margolus neighborhood 2D cellular automata. As this isn't reversible by definition, I haven't found a solution or even general method to find a solution. I'm just curious where I should look. I know this has to have an answer stemming from a field in mathematics but it doesn't resemble anything I currently know.",,"['probability', 'combinatorics', 'discrete-mathematics', 'cellular-automata']"
96,Spanning graph of regular graph,Spanning graph of regular graph,,"Show that there exists $d'$ such that for every $d > d'$, every $d$-regular graph contains a spanning subgraph with minimum degree $\ge 10$ and girth $\ge 10$. Any idea how to approach this question?","Show that there exists $d'$ such that for every $d > d'$, every $d$-regular graph contains a spanning subgraph with minimum degree $\ge 10$ and girth $\ge 10$. Any idea how to approach this question?",,"['probability', 'combinatorics', 'graph-theory']"
97,Prove that integration and summation can be swapped,Prove that integration and summation can be swapped,,"$\def\d{\mathrm{d}}$Prove that integration and summation can be swapped in the following expression: $$\int_{0}^{\infty} \sum_{n=0}^{\infty} \frac{(itx)^n}{n!}f(x)\,\d x,$$ where $|t|<\lambda$ and $f(x)$ is the density function of the $\mathrm{Gamma}(\lambda, \alpha)$ distribution for any real $\alpha >0$. I know that I need to use Fubini's theorem and show: $$\int_{0}^{\infty} \sum_{n=0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x< \infty,$$ or $$\sum_{n=0}^{\infty} \int_{0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x< \infty.$$ I have tried the following: \begin{align*} &\mathrel{\phantom{=}} \sum_{n=0}^{\infty} \int_{0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x\\ &< \sum_{n=0}^{\infty} \int_{0}^{\infty} \frac{\lambda^nx^n}{n!}|f(x)|\,\d x\ \text{(Used $|t|<\lambda$)}\\ &=\sum_{n=0}^{\infty} \int_{x=0}^{\infty} \frac{\lambda^nx^n}{n!}\left|\frac{x^{\alpha-1}\lambda^{\alpha}e^{-{\lambda}x}}{\Gamma(\alpha)}\right|\,\d x\ \text{(Substituted in $f(x)$)}\\ &=\sum_{n=0}^{\infty} \int_{x=0}^{\infty} \frac{1}{n!}\frac{x^{n+\alpha-1}\lambda^{n+\alpha}e^{-{\lambda}x}}{\Gamma(\alpha)}\,\d x\\ &\mathrel{\phantom{=}}\text{(Combined exponents and removed absolute value)}\\ &=\sum_{n=0}^{\infty} \frac{\Gamma(n+\alpha)}{n!\Gamma(\alpha)} \int_{x=0}^{\infty}\frac{x^{n+\alpha-1}\lambda^{n+\alpha}e^{-{\lambda}x}}{\Gamma(n+\alpha)}\,\d x\\ &=\sum_{n=0}^{\infty} \frac{\Gamma(n+\alpha)}{n!\Gamma(\alpha)}\\ &\mathrel{\phantom{=}}\text{(As the integral of the density of Gamma($\lambda$, $n+\alpha$) is $1$)} \end{align*} The problem now is I don't believe this sum converges. Any help would be appreciated!","$\def\d{\mathrm{d}}$Prove that integration and summation can be swapped in the following expression: $$\int_{0}^{\infty} \sum_{n=0}^{\infty} \frac{(itx)^n}{n!}f(x)\,\d x,$$ where $|t|<\lambda$ and $f(x)$ is the density function of the $\mathrm{Gamma}(\lambda, \alpha)$ distribution for any real $\alpha >0$. I know that I need to use Fubini's theorem and show: $$\int_{0}^{\infty} \sum_{n=0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x< \infty,$$ or $$\sum_{n=0}^{\infty} \int_{0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x< \infty.$$ I have tried the following: \begin{align*} &\mathrel{\phantom{=}} \sum_{n=0}^{\infty} \int_{0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x\\ &< \sum_{n=0}^{\infty} \int_{0}^{\infty} \frac{\lambda^nx^n}{n!}|f(x)|\,\d x\ \text{(Used $|t|<\lambda$)}\\ &=\sum_{n=0}^{\infty} \int_{x=0}^{\infty} \frac{\lambda^nx^n}{n!}\left|\frac{x^{\alpha-1}\lambda^{\alpha}e^{-{\lambda}x}}{\Gamma(\alpha)}\right|\,\d x\ \text{(Substituted in $f(x)$)}\\ &=\sum_{n=0}^{\infty} \int_{x=0}^{\infty} \frac{1}{n!}\frac{x^{n+\alpha-1}\lambda^{n+\alpha}e^{-{\lambda}x}}{\Gamma(\alpha)}\,\d x\\ &\mathrel{\phantom{=}}\text{(Combined exponents and removed absolute value)}\\ &=\sum_{n=0}^{\infty} \frac{\Gamma(n+\alpha)}{n!\Gamma(\alpha)} \int_{x=0}^{\infty}\frac{x^{n+\alpha-1}\lambda^{n+\alpha}e^{-{\lambda}x}}{\Gamma(n+\alpha)}\,\d x\\ &=\sum_{n=0}^{\infty} \frac{\Gamma(n+\alpha)}{n!\Gamma(\alpha)}\\ &\mathrel{\phantom{=}}\text{(As the integral of the density of Gamma($\lambda$, $n+\alpha$) is $1$)} \end{align*} The problem now is I don't believe this sum converges. Any help would be appreciated!",,"['probability', 'integration']"
98,Roll an N sided die K times. Let S be the side that appeared most often. What is the expected number of times S appeared?,Roll an N sided die K times. Let S be the side that appeared most often. What is the expected number of times S appeared?,,"For example, consider a 6 sided die rolled 10 times. Based on the following monte-carlo simulation, I get that the side that appears most will appear 3.44 times on average. n = 6 k = 10 samples = 10000 results = []  for _ in range(samples):     counts = {s:0 for s in range(n)}     for _ in range(k):         s = randint(0, n-1)         counts[s] += 1      results.append(max(counts.values()))  print sum(results)/float(len(results)) But I can't figure out how to get this in a closed form for any particular N and K.","For example, consider a 6 sided die rolled 10 times. Based on the following monte-carlo simulation, I get that the side that appears most will appear 3.44 times on average. n = 6 k = 10 samples = 10000 results = []  for _ in range(samples):     counts = {s:0 for s in range(n)}     for _ in range(k):         s = randint(0, n-1)         counts[s] += 1      results.append(max(counts.values()))  print sum(results)/float(len(results)) But I can't figure out how to get this in a closed form for any particular N and K.",,"['probability', 'statistics', 'expectation', 'monte-carlo']"
99,Discrete uniform probability on a sample space of prime cardinality,Discrete uniform probability on a sample space of prime cardinality,,"My question is to show that if I have a fair die with $p$ faces, where $p$ is prime, and the experiment consists of rolling it once, no two proper events can be independent. Here is my approach: Suppose $A$ and $B$ are independent events. Then $$P(A \cap B) = P(A) * P(B) = \frac{|A|}{p} * \frac{|B|}{p} = \frac{|A||B|}{p^{2}} < 1$$ Not sure where a contradiction would happen to know how to proceed. Any help?","My question is to show that if I have a fair die with $p$ faces, where $p$ is prime, and the experiment consists of rolling it once, no two proper events can be independent. Here is my approach: Suppose $A$ and $B$ are independent events. Then $$P(A \cap B) = P(A) * P(B) = \frac{|A|}{p} * \frac{|B|}{p} = \frac{|A||B|}{p^{2}} < 1$$ Not sure where a contradiction would happen to know how to proceed. Any help?",,"['probability', 'probability-theory']"
