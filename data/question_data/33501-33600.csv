,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Some basic questions about Stochastic Calculus,Some basic questions about Stochastic Calculus,,"I have a transition function for a Markov process $X_t$.  I want to find a density function for the stochastic process $Y_t := \int_0^t X_s \,ds$.  Some questions about this: Is this the same as the transition function for the stochastic process $Y'_t := \int_0^t 1 \,dX_s$?  If not, what is the difference in real-world meaning between $Y_t$ and $Y'_t$? In normal calculus, one typically integrates by invoking the Fundamental Theorem and taking antiderivatives.  Is there a Fundamental Theorem analog in stochastic calculus that might be useful here? My best lead so far is to use the Feynman-Kac formula on $X_t$ to find the characteristic function of the density function of $Y_t$, then invert it.  The transition function for $X_t$ is very long and ugly, so this would be hugely complicated to execute.  I've got Mathematica as my integration calculator, so I can handle some amount of ugliness, but this strategy was too complicated for Mathematica to stomach, and it froze up.  Is there a known simpler method? Thanks - advice on any of these three questions is appreciated.","I have a transition function for a Markov process $X_t$.  I want to find a density function for the stochastic process $Y_t := \int_0^t X_s \,ds$.  Some questions about this: Is this the same as the transition function for the stochastic process $Y'_t := \int_0^t 1 \,dX_s$?  If not, what is the difference in real-world meaning between $Y_t$ and $Y'_t$? In normal calculus, one typically integrates by invoking the Fundamental Theorem and taking antiderivatives.  Is there a Fundamental Theorem analog in stochastic calculus that might be useful here? My best lead so far is to use the Feynman-Kac formula on $X_t$ to find the characteristic function of the density function of $Y_t$, then invert it.  The transition function for $X_t$ is very long and ugly, so this would be hugely complicated to execute.  I've got Mathematica as my integration calculator, so I can handle some amount of ugliness, but this strategy was too complicated for Mathematica to stomach, and it froze up.  Is there a known simpler method? Thanks - advice on any of these three questions is appreciated.",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals']"
1,"$X,Y\sim Poiss(\lambda)$ are IID R.V, How to calculate $P(Y\geq 2X)$?","are IID R.V, How to calculate ?","X,Y\sim Poiss(\lambda) P(Y\geq 2X)","I am given the following question: Suppose that the times it takes for two students to solve a certain   homework problem are independently and identically distributed   according to the distribution $Poiss(\lambda)$. Find the probability that one of the students will take at least twice   as long as the other one to solve the problem. What I did: Since $X,Y$ are independent $$P_{Y|X}(y|x)=P(Y=y|X=x)=P(Y=y)$$ Given some value, $k$, of $X$: The probability that it takes the second student at least twice as long to do the homework is $P(Y\geq2k)$. Hence the probability that it takes the second student at least twice as long to do the homework is, according to Law of total probability, $$\sum_{k=1}^{\infty}P(X=k)P_{Y|X}(Y\geq2k|X=k)$$ $$=\sum_{k=1}^{\infty}P(X=k)\cdot P(Y\geq2k)$$ $$=\sum_{k=1}^{\infty}P(X=k)\cdot(1-P(Y<2k))$$ $$=\sum_{k=1}^{\infty}P(X=k)\cdot(1-\sum_{j=1}^{2k-1}P(Y=j))$$ $$=\sum_{k=1}^{\infty}e^{-\lambda}\frac{\lambda^{k}}{k!}\cdot(1-\sum_{j=1}^{2k-1}e^{-\lambda}\frac{\lambda^{j}}{j!}))$$ and this is where I am stuck. Can someone please help me continue on calculating this sum, or maybe suggest a different approach ?","I am given the following question: Suppose that the times it takes for two students to solve a certain   homework problem are independently and identically distributed   according to the distribution $Poiss(\lambda)$. Find the probability that one of the students will take at least twice   as long as the other one to solve the problem. What I did: Since $X,Y$ are independent $$P_{Y|X}(y|x)=P(Y=y|X=x)=P(Y=y)$$ Given some value, $k$, of $X$: The probability that it takes the second student at least twice as long to do the homework is $P(Y\geq2k)$. Hence the probability that it takes the second student at least twice as long to do the homework is, according to Law of total probability, $$\sum_{k=1}^{\infty}P(X=k)P_{Y|X}(Y\geq2k|X=k)$$ $$=\sum_{k=1}^{\infty}P(X=k)\cdot P(Y\geq2k)$$ $$=\sum_{k=1}^{\infty}P(X=k)\cdot(1-P(Y<2k))$$ $$=\sum_{k=1}^{\infty}P(X=k)\cdot(1-\sum_{j=1}^{2k-1}P(Y=j))$$ $$=\sum_{k=1}^{\infty}e^{-\lambda}\frac{\lambda^{k}}{k!}\cdot(1-\sum_{j=1}^{2k-1}e^{-\lambda}\frac{\lambda^{j}}{j!}))$$ and this is where I am stuck. Can someone please help me continue on calculating this sum, or maybe suggest a different approach ?",,"['probability', 'summation']"
2,Random walk in the plane,Random walk in the plane,,"A particles moves in $\mathbb{R^2}$ started at the origin. At each stage $i (i = 1, 2, ...)$, the particles would move, independently of all the stages before, one of the four directions North, East, South and West 1 unit, with probability $1 \over 4 $ each.Let $T_n$ be the distance from the origin just after $n$ steps. What is $E(T_n)$. I tried define 4 $1\times 2$matrice with only $1,0,-1$ in all entries. The use technique similar to simple random walk in 1 dimension and we know that for a $1\times 2$ matrice $(x,y)$, the distance from origin =$\sqrt {x^2+y^2}$ but i am not sure how to like the 1 D to 2 D. As in 2 D there are 4 possible direction.","A particles moves in $\mathbb{R^2}$ started at the origin. At each stage $i (i = 1, 2, ...)$, the particles would move, independently of all the stages before, one of the four directions North, East, South and West 1 unit, with probability $1 \over 4 $ each.Let $T_n$ be the distance from the origin just after $n$ steps. What is $E(T_n)$. I tried define 4 $1\times 2$matrice with only $1,0,-1$ in all entries. The use technique similar to simple random walk in 1 dimension and we know that for a $1\times 2$ matrice $(x,y)$, the distance from origin =$\sqrt {x^2+y^2}$ but i am not sure how to like the 1 D to 2 D. As in 2 D there are 4 possible direction.",,"['probability', 'probability-theory']"
3,Does fractional part converge in distribution to a uniform random variable?,Does fractional part converge in distribution to a uniform random variable?,,"Let $X$ be a continuous random variable with a density function $f(x).$ Let $\{x\}$ denote the fractional part of a real number. I am tryng to prove that  $$ \mathbb{P}[\{nX\}\leq z] \rightarrow z, \ \ \forall z \in [0,1] $$ Can anyone help me in this ? My attempt: If $g_n(z)$ is the density of $\{nX\}$, I got $g_n(z)=\sum_{m \in \mathbb{Z}}\frac{1}{n}f(\frac{m}{n}+\frac{z}{n})$. Can I justify from here ? One can assume nice properties on $f$ if needed but I want to keep those assumptions as minimal as possible.","Let $X$ be a continuous random variable with a density function $f(x).$ Let $\{x\}$ denote the fractional part of a real number. I am tryng to prove that  $$ \mathbb{P}[\{nX\}\leq z] \rightarrow z, \ \ \forall z \in [0,1] $$ Can anyone help me in this ? My attempt: If $g_n(z)$ is the density of $\{nX\}$, I got $g_n(z)=\sum_{m \in \mathbb{Z}}\frac{1}{n}f(\frac{m}{n}+\frac{z}{n})$. Can I justify from here ? One can assume nice properties on $f$ if needed but I want to keep those assumptions as minimal as possible.",,"['probability', 'probability-theory', 'probability-limit-theorems']"
4,What is the expectation of a random variable raised to the $n$th power?,What is the expectation of a random variable raised to the th power?,n,"If $Y=X^n$, with $n$ and the expectation and variance of $X$ known, what is the expectation and variance of $Y$?","If $Y=X^n$, with $n$ and the expectation and variance of $X$ known, what is the expectation and variance of $Y$?",,"['probability', 'expectation']"
5,Probability that randomly picking $4$ out of $90$ numbers yields an ascending sequence?,Probability that randomly picking  out of  numbers yields an ascending sequence?,4 90,"Probability: In a box there are $90$ slips, numbered from $1$ to $90$ .  Alex picks up four slips at random, one after the other, without replacement.  Find the probability that the numbers on the slips, in the order he picks up, are in ascending order. My attempt: Sample space = picking up 4 slips one-by-one without replacement should be as good as picking 4 slips at a time which can be done in ${90 \choose 4}$ ways Now each of these equally likely ${90 \choose 4}$ outcomes will provide us 1 favourable outcome as well in which all four slips would be in ascending order, but then this would be simply $\frac{{90 \choose 4}*1 }{90 \choose 4}$ , however this isn't correct .  Please help me by stating the flaw in my argument and helping me with the correct thought process. Any approach without the involvement of combinatorics would also be appreciated.","Probability: In a box there are slips, numbered from to .  Alex picks up four slips at random, one after the other, without replacement.  Find the probability that the numbers on the slips, in the order he picks up, are in ascending order. My attempt: Sample space = picking up 4 slips one-by-one without replacement should be as good as picking 4 slips at a time which can be done in ways Now each of these equally likely outcomes will provide us 1 favourable outcome as well in which all four slips would be in ascending order, but then this would be simply , however this isn't correct .  Please help me by stating the flaw in my argument and helping me with the correct thought process. Any approach without the involvement of combinatorics would also be appreciated.",90 1 90 {90 \choose 4} {90 \choose 4} \frac{{90 \choose 4}*1 }{90 \choose 4},"['probability', 'combinatorics']"
6,"Set A = {1,2,3,4,5} Pick randomly one digit and remove it. What is the prob. that we pick an odd digit the 2nd time.","Set A = {1,2,3,4,5} Pick randomly one digit and remove it. What is the prob. that we pick an odd digit the 2nd time.",,"The probability that we pick any number for the first time is $\dfrac{1}{5}$ the sample space of sample spaces after the first event is then {2,3,4,5} {1,3,4,5} {1,2,4,5} {1,2,3,5} {1,2,3,4} prob. to pick an odd from the 1st sample space is $\dfrac{1}{2}$ prob. to pick an odd from the 2nd sample  space is $\dfrac{3}{4}$ prob. to pick an odd from the 3rd sample  space is $\dfrac{1}{2}$ prob. to pick an odd from the 4th sample  space is $\dfrac{3}{4}$ prob. to pick an odd from the 5th sample  space is $\dfrac{1}{2}$ The final result is: $\dfrac{1}{5}$ * $\dfrac{1}{2}$ + $\dfrac{1}{5}$ * $\dfrac{3}{4}$ + $\dfrac{1}{5}$ * $\dfrac{1}{2}$ + $\dfrac{1}{5}$ * $\dfrac{3}{4}$ + $\dfrac{1}{5}$ * $\dfrac{1}{2}$ = $\dfrac{3}{5}$ Is this reasoning correct? Are there any simpler ways to solve this problem?","The probability that we pick any number for the first time is $\dfrac{1}{5}$ the sample space of sample spaces after the first event is then {2,3,4,5} {1,3,4,5} {1,2,4,5} {1,2,3,5} {1,2,3,4} prob. to pick an odd from the 1st sample space is $\dfrac{1}{2}$ prob. to pick an odd from the 2nd sample  space is $\dfrac{3}{4}$ prob. to pick an odd from the 3rd sample  space is $\dfrac{1}{2}$ prob. to pick an odd from the 4th sample  space is $\dfrac{3}{4}$ prob. to pick an odd from the 5th sample  space is $\dfrac{1}{2}$ The final result is: $\dfrac{1}{5}$ * $\dfrac{1}{2}$ + $\dfrac{1}{5}$ * $\dfrac{3}{4}$ + $\dfrac{1}{5}$ * $\dfrac{1}{2}$ + $\dfrac{1}{5}$ * $\dfrac{3}{4}$ + $\dfrac{1}{5}$ * $\dfrac{1}{2}$ = $\dfrac{3}{5}$ Is this reasoning correct? Are there any simpler ways to solve this problem?",,['probability']
7,How many ways can 4 men and 4 women stand in a line so that the men are together and the women are together,How many ways can 4 men and 4 women stand in a line so that the men are together and the women are together,,"Question: How many ways can $\mathbf{4}$ men and $\mathbf{4}$ women line up with all the women together and all the men together? My thoughts: I begin my solution to the problem by adding the total amount of men and women together: $\mathbf{8}$. With that in mind, I find how many ways the men can be lined up. The men can be lined up in $\mathbf{4!}$ ways, likewise the women can be lined up in $\mathbf{4!}$ ways. Thus, the product of these two groups lining up is $\mathbf{576}$. This is where I can't really understand how the solution $\mathbf{1152}$ is met. Multiplying $\mathbf{576}$ $\cdot$ $\mathbf{2}$ gives me this value, but I don't understand why. What are your thoughts?","Question: How many ways can $\mathbf{4}$ men and $\mathbf{4}$ women line up with all the women together and all the men together? My thoughts: I begin my solution to the problem by adding the total amount of men and women together: $\mathbf{8}$. With that in mind, I find how many ways the men can be lined up. The men can be lined up in $\mathbf{4!}$ ways, likewise the women can be lined up in $\mathbf{4!}$ ways. Thus, the product of these two groups lining up is $\mathbf{576}$. This is where I can't really understand how the solution $\mathbf{1152}$ is met. Multiplying $\mathbf{576}$ $\cdot$ $\mathbf{2}$ gives me this value, but I don't understand why. What are your thoughts?",,"['probability', 'combinatorics', 'discrete-mathematics', 'permutations', 'combinations']"
8,A probability interview questions on pen type,A probability interview questions on pen type,,"In an interview, the following question was asked: A (single) box contains $20$ pens. $8$ pens are of type $A$ , and the others are of type ‌ $B$ . We then randomly choose a pen, and discard it from the box (regardless of type). If we then choose another pen from the box, what is the probability that this pen is of type $A$ ? I'm having trouble coming up with a solution to this, how would you compute this?","In an interview, the following question was asked: A (single) box contains pens. pens are of type , and the others are of type ‌ . We then randomly choose a pen, and discard it from the box (regardless of type). If we then choose another pen from the box, what is the probability that this pen is of type ? I'm having trouble coming up with a solution to this, how would you compute this?",20 8 A B A,['probability']
9,"For $\int_{x}^{x+dx} p(x) \,dx = P(x)$ which one is the correct interval, $(x,x+dx)$ or $[x,x+dx]$?","For  which one is the correct interval,  or ?","\int_{x}^{x+dx} p(x) \,dx = P(x) (x,x+dx) [x,x+dx]","In Physics (both in Statistical & Quantum Mechanics) when we describe the probability function of finding a particle between $x$ and $x+dx$ , we write $\int_{x}^{x+dx} p(x) \,dx = P(x)$ . Here in some books the interval is chosen as $(x,x+dx)$ and in some other books it's chosen as $[x,x+dx]$ . Depending on the chosen interval, the writing will either say: “between $x$ and $x+dx$ “ or “from $x$ to $x+dx$ “, respectively. Though the probability in finding a particle at the endpoints $x$ , $x+dx$ is zero, so it's not necessary to include or exclude the boundary points, as the integral will give the same result, but for the Physics and Physical arguments, which one is correct and why? Edit: My understanding (I may be wrong): if we consider a spherical shell at a distance $x$ from the origin with width $dx$ , then the particle would be in a small shell of $dx$ from the distance $x$ . My question is if we define the open interval and closed interval in the probability definition, then we are respectively excluding and including the fact that the particle may not or may access the position $x$ and $x+dx$ respectively. Both can't be correct according to my understanding. So, which one should be correct and why?","In Physics (both in Statistical & Quantum Mechanics) when we describe the probability function of finding a particle between and , we write . Here in some books the interval is chosen as and in some other books it's chosen as . Depending on the chosen interval, the writing will either say: “between and “ or “from to “, respectively. Though the probability in finding a particle at the endpoints , is zero, so it's not necessary to include or exclude the boundary points, as the integral will give the same result, but for the Physics and Physical arguments, which one is correct and why? Edit: My understanding (I may be wrong): if we consider a spherical shell at a distance from the origin with width , then the particle would be in a small shell of from the distance . My question is if we define the open interval and closed interval in the probability definition, then we are respectively excluding and including the fact that the particle may not or may access the position and respectively. Both can't be correct according to my understanding. So, which one should be correct and why?","x x+dx \int_{x}^{x+dx} p(x) \,dx = P(x) (x,x+dx) [x,x+dx] x x+dx x x+dx x x+dx x dx dx x x x+dx","['quantum-mechanics', 'probability']"
10,Probability that a 5 occurs first,Probability that a 5 occurs first,,Suppose we roll pair of dice until a sum of either 5 or 7 appears. What is the probability that a sum of 5 occurs first? Try: Let $A$ be the event that a sum of $5$ occurs on the ith roll and $B$ that the sum of 7 occurs on the ith roll. We are interested on the event $A | A^c \cup B^c $ . We have $$ P(A | A^c \cup B^c) = \dfrac{ P(A \cap (A^c \cup B^c))}{P(A^c \cup B^c)} = \frac{P(A \cap B^c)}{1 - P(A \cap B)} = \frac{P(A \cap B^c)}{1-0} = P(A \cap B^c)$$ Is this approach correct so far?,Suppose we roll pair of dice until a sum of either 5 or 7 appears. What is the probability that a sum of 5 occurs first? Try: Let be the event that a sum of occurs on the ith roll and that the sum of 7 occurs on the ith roll. We are interested on the event . We have Is this approach correct so far?,A 5 B A | A^c \cup B^c   P(A | A^c \cup B^c) = \dfrac{ P(A \cap (A^c \cup B^c))}{P(A^c \cup B^c)} = \frac{P(A \cap B^c)}{1 - P(A \cap B)} = \frac{P(A \cap B^c)}{1-0} = P(A \cap B^c),['probability']
11,There is an $80\%$ chance of rain on each of the next $6$ days. What is the probability that it will rain on exactly $2$ of those days? [closed],There is an  chance of rain on each of the next  days. What is the probability that it will rain on exactly  of those days? [closed],80\% 6 2,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question There is an $80\%$ chance of rain on each of the next six days. What is the probability that it will rain on exactly two of those days? Could you show the workings as well as showing in the equation format. I don't quite understand the equation formatting yet... :(","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question There is an $80\%$ chance of rain on each of the next six days. What is the probability that it will rain on exactly two of those days? Could you show the workings as well as showing in the equation format. I don't quite understand the equation formatting yet... :(",,['probability']
12,Find the expected value of $\frac{1}{X+1}$ where $X$ is binomial,Find the expected value of  where  is binomial,\frac{1}{X+1} X,"The problem: X is a binomial random variable, find $E[\frac{1}{X+1}]$ n and p are not given PDF for a binomial distribution is $\binom{n}{k}p^k(1-p)^{n-k}$ Expected value is $\sum{x_ip(x_i)}$ But this is where I get stuck, I'm really rusty on my statistics and I'm not sure exactly how to structure it in the next step? I think I want to get the form of the following out of the summation $\sum _{k=0}^{n} \binom{n}{k}p^k(1-p)^{n-k} = (p + 1 - p)^n = 1$ But I'm not sure if it should look like $\sum \frac{1}{xp(x)+1} $ and if it should where to go from here?","The problem: X is a binomial random variable, find $E[\frac{1}{X+1}]$ n and p are not given PDF for a binomial distribution is $\binom{n}{k}p^k(1-p)^{n-k}$ Expected value is $\sum{x_ip(x_i)}$ But this is where I get stuck, I'm really rusty on my statistics and I'm not sure exactly how to structure it in the next step? I think I want to get the form of the following out of the summation $\sum _{k=0}^{n} \binom{n}{k}p^k(1-p)^{n-k} = (p + 1 - p)^n = 1$ But I'm not sure if it should look like $\sum \frac{1}{xp(x)+1} $ and if it should where to go from here?",,"['probability', 'probability-distributions', 'expected-value', 'binomial-distribution']"
13,"how to explain that Prob[heads, tails] = 2 * Prob[heads, heads] to a student?","how to explain that Prob[heads, tails] = 2 * Prob[heads, heads] to a student?",,"I throw two coins (simultaneously). A student (very much a beginner in both math and probability theory) thought that the following 3 outcomes are equally likely: ""two heads"", ""two tails"", ""a head and a tail"". However much I tried, I couldn't find a clear and obvious explanation of why it's not the case. Of course, I could say the coins are distinct, so we need to look at how each individual coin falls (leading to 4 equally likely outcomes: HH, HT, TH, TT). But I couldn't clearly explain the concept of ""distinct"" and why it's important for the probability calculation. Anyone can help with a simple, precise and very intuitive explanation?","I throw two coins (simultaneously). A student (very much a beginner in both math and probability theory) thought that the following 3 outcomes are equally likely: ""two heads"", ""two tails"", ""a head and a tail"". However much I tried, I couldn't find a clear and obvious explanation of why it's not the case. Of course, I could say the coins are distinct, so we need to look at how each individual coin falls (leading to 4 equally likely outcomes: HH, HT, TH, TT). But I couldn't clearly explain the concept of ""distinct"" and why it's important for the probability calculation. Anyone can help with a simple, precise and very intuitive explanation?",,"['probability', 'intuition', 'education']"
14,"7 white balls and 5 black balls. Find the probability that the 6th ball drawn is white, while...","7 white balls and 5 black balls. Find the probability that the 6th ball drawn is white, while...",,"A box contains 7 identical white balls and 5 identical black balls. They are to be drawn randomly, one at a time without replacement, until the box is empty. Find the probability that the 6th ball drawn is white, while before that exactly 3 black balls are drawn. I thought the problem this way: There are $\dfrac{12!}{7!5!}=792$ ways to order the balls in general. Then, if we fix black,black,black,white we have eight other balls to place in the other bins, which is $\dfrac{8!}{6!2!}=28$. Therefore the probability is $\dfrac{28}{792}=\dfrac{7}{198}$. But the book says the answer is $\dfrac{25}{132}$, why tho!?","A box contains 7 identical white balls and 5 identical black balls. They are to be drawn randomly, one at a time without replacement, until the box is empty. Find the probability that the 6th ball drawn is white, while before that exactly 3 black balls are drawn. I thought the problem this way: There are $\dfrac{12!}{7!5!}=792$ ways to order the balls in general. Then, if we fix black,black,black,white we have eight other balls to place in the other bins, which is $\dfrac{8!}{6!2!}=28$. Therefore the probability is $\dfrac{28}{792}=\dfrac{7}{198}$. But the book says the answer is $\dfrac{25}{132}$, why tho!?",,"['probability', 'combinatorics']"
15,Probability of 1x six from seven dice?,Probability of 1x six from seven dice?,,Could someone help me with how the following is calculated: What is the probability of rolling a die seven times and getting at least one six? My instinct told me it would be $1/6+\cdots + 1/6$ but this ends up being $7/6$.,Could someone help me with how the following is calculated: What is the probability of rolling a die seven times and getting at least one six? My instinct told me it would be $1/6+\cdots + 1/6$ but this ends up being $7/6$.,,"['probability', 'dice']"
16,Four tetrahedron dice probability,Four tetrahedron dice probability,,"We have four dice in the shape of a tetrahedron. Each dice has faces numbered 2, 0, 1, and 7. If we roll all four dice simultaneously, what is the probability that we can compose the number 2017 using one of the three visible numbers from each dice? Here is what I tried: $\frac{3}{4}$x$\frac{3}{4}$x$\frac{3}{4}$x$\frac{3}{4}$=$\frac{81}{256}$ The real answer is $\frac{63}{64}$. Please help me with this answer!","We have four dice in the shape of a tetrahedron. Each dice has faces numbered 2, 0, 1, and 7. If we roll all four dice simultaneously, what is the probability that we can compose the number 2017 using one of the three visible numbers from each dice? Here is what I tried: $\frac{3}{4}$x$\frac{3}{4}$x$\frac{3}{4}$x$\frac{3}{4}$=$\frac{81}{256}$ The real answer is $\frac{63}{64}$. Please help me with this answer!",,"['probability', 'dice']"
17,Probability with my Facebook friends,Probability with my Facebook friends,,"If I have 5000 Facebook friends, what is the probability that a day with no one having that birthday exists? I assume there are 365 days in a year, and a uniform distribution of the dates of birth. I guess that it's easier to calculate the opposite, and to subtract it from one.","If I have 5000 Facebook friends, what is the probability that a day with no one having that birthday exists? I assume there are 365 days in a year, and a uniform distribution of the dates of birth. I guess that it's easier to calculate the opposite, and to subtract it from one.",,"['probability', 'combinatorics']"
18,Help with a specific limit $\left( \dfrac{n-1}{n} \right)^n$ as $n \rightarrow \infty$,Help with a specific limit  as,\left( \dfrac{n-1}{n} \right)^n n \rightarrow \infty,"Allow me to preface this by saying this is not a homework problem. If I had had this thought four years ago when I was taking calculus, I probably could do it... I'm trying to calculate the limit as  $n \to \infty$ of $1-\left(\frac{n-1}{n}\right)^n$ - - it's a constant I'm inclined to call ""natural chance of success"". I have estimated this value to be ~0.632121 but would very much like to see how it could be calculated aside from the brute-force method i employed earlier. The background of this would be... consider n = 2 (a coin). You are given two flips of the coin to get what you pick - what is the chance you'll get your chosen outcome, assuming of course it's a fair coin. The best way to go about this would be to say there's a 1/2 chance of failing, and you have 2 flips. This means you have $(1/2)^2$ chance of failure, being 1/4. 1-1/4 is 3/4, so your chance of success here is 3/4. Now consider n = 6 (standard die). You get six rolls to get the number of your choice (assuming a fair die again). Again, you have a 5/6 chance to not get your choice, and 6 rolls at 5/6 chance would be $(5/6)^6$, or ~.334, giving you a ~.665 chance of success. And I'm curious as n increases to infinity, what is your chance of success? Now again, I've estimated this with a double precision float (in Java) to be 0.63212 (actually, this was the point at which it could simply gain no more precision on the value, n = 296536) but this doesn't really give insight to the derivation of the number, merely its value. So I'm hoping someone a little fresher on their integrals than I can help me out here. Thanks!","Allow me to preface this by saying this is not a homework problem. If I had had this thought four years ago when I was taking calculus, I probably could do it... I'm trying to calculate the limit as  $n \to \infty$ of $1-\left(\frac{n-1}{n}\right)^n$ - - it's a constant I'm inclined to call ""natural chance of success"". I have estimated this value to be ~0.632121 but would very much like to see how it could be calculated aside from the brute-force method i employed earlier. The background of this would be... consider n = 2 (a coin). You are given two flips of the coin to get what you pick - what is the chance you'll get your chosen outcome, assuming of course it's a fair coin. The best way to go about this would be to say there's a 1/2 chance of failing, and you have 2 flips. This means you have $(1/2)^2$ chance of failure, being 1/4. 1-1/4 is 3/4, so your chance of success here is 3/4. Now consider n = 6 (standard die). You get six rolls to get the number of your choice (assuming a fair die again). Again, you have a 5/6 chance to not get your choice, and 6 rolls at 5/6 chance would be $(5/6)^6$, or ~.334, giving you a ~.665 chance of success. And I'm curious as n increases to infinity, what is your chance of success? Now again, I've estimated this with a double precision float (in Java) to be 0.63212 (actually, this was the point at which it could simply gain no more precision on the value, n = 296536) but this doesn't really give insight to the derivation of the number, merely its value. So I'm hoping someone a little fresher on their integrals than I can help me out here. Thanks!",,"['probability', 'integration']"
19,Full House in Poker -- Why do we treat all possible hands to be equally likely?,Full House in Poker -- Why do we treat all possible hands to be equally likely?,,"The problem asks us to find the probability of a full house in a well-shuffled deck of $52$ cards. The solution in the textbook states in the first line ""All of the $52\choose 5$ possible hands are equally likely by symmetry, so the naive definition [of Probability] is applicable."" Everything after this involves counting, which I understand. However, I do not see why all outcomes are equally likely. Here is why. Say we chose a card with rank $7$ . The number of $7$ 's left are now less than that of other ranks. This must mean the probability of choosing a different rank must be more than that of choosing another $7$ . This means that the probability of an outcome (a hand) with ranks $(2, 3, 4, 5, 6)$ must be more than that of a hand with ranks $(2, 2, 2, 3, 3)$ . Kindly explain why the naive definition works here and why we treat every hand (all $52\choose 5$ hands) to be an equally likely outcome.","The problem asks us to find the probability of a full house in a well-shuffled deck of cards. The solution in the textbook states in the first line ""All of the possible hands are equally likely by symmetry, so the naive definition [of Probability] is applicable."" Everything after this involves counting, which I understand. However, I do not see why all outcomes are equally likely. Here is why. Say we chose a card with rank . The number of 's left are now less than that of other ranks. This must mean the probability of choosing a different rank must be more than that of choosing another . This means that the probability of an outcome (a hand) with ranks must be more than that of a hand with ranks . Kindly explain why the naive definition works here and why we treat every hand (all hands) to be an equally likely outcome.","52 52\choose 5 7 7 7 (2, 3, 4, 5, 6) (2, 2, 2, 3, 3) 52\choose 5","['probability', 'poker']"
20,Another Monty Hall Question,Another Monty Hall Question,,"I still do not believe the ""correct"" solution to the Monty Hall Problem. Here is my reasoning: The player can pick from $1$ of $3$ doors. The prize can be behind $1$ of $3$ doors. Monty will open $1$ of $3$ doors. $3 \times 3 \times 3 = 27$ possible sequences of events. In $15$ of those possible events, Monty either opens the door the player picked or the door with the prize.  Since Monty will not do either of those, these $15$ events are removed from the possibilities. Of the remaining $12$ possibilities, $6$ times the player wins if he stays with his original pick and $6$ times he wins if he switches.  It looks to me like the player has the same chance of winning whether he stays or switches. Could someone please explain the flaw in my reasoning.","I still do not believe the ""correct"" solution to the Monty Hall Problem. Here is my reasoning: The player can pick from $1$ of $3$ doors. The prize can be behind $1$ of $3$ doors. Monty will open $1$ of $3$ doors. $3 \times 3 \times 3 = 27$ possible sequences of events. In $15$ of those possible events, Monty either opens the door the player picked or the door with the prize.  Since Monty will not do either of those, these $15$ events are removed from the possibilities. Of the remaining $12$ possibilities, $6$ times the player wins if he stays with his original pick and $6$ times he wins if he switches.  It looks to me like the player has the same chance of winning whether he stays or switches. Could someone please explain the flaw in my reasoning.",,"['probability', 'monty-hall']"
21,How To Calculate Binomial Distribution Of Really Small %?,How To Calculate Binomial Distribution Of Really Small %?,,"I asked this question on the Bitcoin Forum , but I think it's more appropriate for a mathematics forum. I'm making an informative video and I need a binomial distribution calculation. I want to find out how many trials are needed to get 1%, 50% and 90% likelihood 1 or more successes. The problem is that the likelihood of success is 1 out of 2^160 (number of distinct bitcoin/ethereum addresses). Normally for something like this, I would use a binomial distribution calculation in Excel using this formula: =1-BINOM.DIST(0,????,2^-160,TRUE) I would then tinker with the ???? until the entire cell result returned 1%, 50% and 90%. However, Excel can't handle numbers anywhere near this large. Does anyone know of a way I can calculate the number of trials required for these 3 percentages given the infinitesimally small chance of success? It would be great if there was an online tool I could use to support my results. Just to illustrate what I'm looking for. If this analysis was for something much simpler, such as a probability of success being 1% , then I could calculate the results to be: 229 trials needed for 90%, | 89.99% =1-BINOM.DIST(0,229,0.01,TRUE) 69 trials needed for 50%,  | 50.01% =1-BINOM.DIST(0,69,0.01,TRUE) 1 trial needed for 1%,  | 1.00% =1-BINOM.DIST(0,1,0.01,TRUE)","I asked this question on the Bitcoin Forum , but I think it's more appropriate for a mathematics forum. I'm making an informative video and I need a binomial distribution calculation. I want to find out how many trials are needed to get 1%, 50% and 90% likelihood 1 or more successes. The problem is that the likelihood of success is 1 out of 2^160 (number of distinct bitcoin/ethereum addresses). Normally for something like this, I would use a binomial distribution calculation in Excel using this formula: =1-BINOM.DIST(0,????,2^-160,TRUE) I would then tinker with the ???? until the entire cell result returned 1%, 50% and 90%. However, Excel can't handle numbers anywhere near this large. Does anyone know of a way I can calculate the number of trials required for these 3 percentages given the infinitesimally small chance of success? It would be great if there was an online tool I could use to support my results. Just to illustrate what I'm looking for. If this analysis was for something much simpler, such as a probability of success being 1% , then I could calculate the results to be: 229 trials needed for 90%, | 89.99% =1-BINOM.DIST(0,229,0.01,TRUE) 69 trials needed for 50%,  | 50.01% =1-BINOM.DIST(0,69,0.01,TRUE) 1 trial needed for 1%,  | 1.00% =1-BINOM.DIST(0,1,0.01,TRUE)",,"['probability', 'statistics', 'binomial-distribution']"
22,Proof of equation with binomial coefficients: $\sum\limits_{k=1}^{n} (k+1) \binom{n}{k} = 2^{n-1} \cdot (n+2)-1$ [duplicate],Proof of equation with binomial coefficients:  [duplicate],\sum\limits_{k=1}^{n} (k+1) \binom{n}{k} = 2^{n-1} \cdot (n+2)-1,This question already has answers here : How to prove this binomial identity $\sum_{r=0}^n {r {n \choose r}} = n2^{n-1}$? (10 answers) Closed 7 years ago . $$\sum\limits_{k=1}^{n} (k+1) \binom{n}{k} = 2^{n-1} \cdot (n+2)-1$$ Maybe it's simple to prove this equation but I'm not sure how to get along with the induction. Any hints for this? Or may I use another method? Thanks a lot!,This question already has answers here : How to prove this binomial identity $\sum_{r=0}^n {r {n \choose r}} = n2^{n-1}$? (10 answers) Closed 7 years ago . $$\sum\limits_{k=1}^{n} (k+1) \binom{n}{k} = 2^{n-1} \cdot (n+2)-1$$ Maybe it's simple to prove this equation but I'm not sure how to get along with the induction. Any hints for this? Or may I use another method? Thanks a lot!,,"['calculus', 'probability', 'summation', 'binomial-coefficients']"
23,Does the likelihood of an event increase with the number of times it does not occur?,Does the likelihood of an event increase with the number of times it does not occur?,,"I would seem logical that the more times an event does not happen, the more likely it is to happen, for example: If a coin is flipped and it lands on tails 10 times in a row it would seam more likely that the next flip will result in heads. The Infinite Monkey Theorem is one such idea that suggests this is true, http://en.wikipedia.org/wiki/Infinite_monkey_theorem It states that if some number of monkeys are left in a room with typewriters for an infinite amount of time then they will eventually compose all written texts ever produced.  This seems to suggest that since the chance of the monkeys writing a work, say Shakespeare's Romeo and Juliet , is very low. The more times they do not write it, the more likely they are to write it, until the chance becomes significant and it, the writing of the play, happens. However another idea, Gambler's Fallacy states quite the opposite. http://en.wikipedia.org/wiki/Gambler%27s_fallacy It states that the chance of an event does not increase with the number of times it does not occur. So what is the answer? Does the likelihood of an event go up the more times it does not happen, or does it stay the same? And if it does stay the same then how does one explain the Infinite Monkey Theorem?","I would seem logical that the more times an event does not happen, the more likely it is to happen, for example: If a coin is flipped and it lands on tails 10 times in a row it would seam more likely that the next flip will result in heads. The Infinite Monkey Theorem is one such idea that suggests this is true, http://en.wikipedia.org/wiki/Infinite_monkey_theorem It states that if some number of monkeys are left in a room with typewriters for an infinite amount of time then they will eventually compose all written texts ever produced.  This seems to suggest that since the chance of the monkeys writing a work, say Shakespeare's Romeo and Juliet , is very low. The more times they do not write it, the more likely they are to write it, until the chance becomes significant and it, the writing of the play, happens. However another idea, Gambler's Fallacy states quite the opposite. http://en.wikipedia.org/wiki/Gambler%27s_fallacy It states that the chance of an event does not increase with the number of times it does not occur. So what is the answer? Does the likelihood of an event go up the more times it does not happen, or does it stay the same? And if it does stay the same then how does one explain the Infinite Monkey Theorem?",,['probability']
24,Probability that a divisor of $10^{99}$ is a multiple of $10^{96}$,Probability that a divisor of  is a multiple of,10^{99} 10^{96},What is the probability that a divisor of $10^{99}$ is a multiple of $10^{96}$? How to solve this type of question. I know probability but  I'm weak in number theory.,What is the probability that a divisor of $10^{99}$ is a multiple of $10^{96}$? How to solve this type of question. I know probability but  I'm weak in number theory.,,"['probability', 'elementary-number-theory']"
25,"Law of Large Numbers, a confusion","Law of Large Numbers, a confusion",,"According to Law of Large Numbers, if I throw a coin 1000 times approximately 500 will be head and 500 tail. Suppose that I throw the coin 700 times and I got 700 heads. Can I say that in the next 300 throws the probability of getting tails will be higher than probability of getting heads? Edit: To make an analogy, imagine that you have a box that contains 500 black and 500 white balls. If 700 times (700 exaggerated) you choose black, than it is more probable that for 701 you get white. However if you say me that instead of one box you have 1000 similar box and every time you choose from one box that means the probability of choosing black or white will never change. With independent events you mean this? Edit2: Imagine that there are billions of people that throwing coins 1000 times. For each person there is an empty box. When he throw the coin, if it is tail he puts a black ball in his box, when the coin is head he puts white ball. So at the end of the experiment there are billions of boxes that each box contains approximately 500 black 500 white ball. So they give me the opportunity to choose one box. The box that I choose represents the one possible coin throwing that I would make. I am asking what is the difference between throwing coins and choosing one box in billions of boxes? If there is no difference, than the first statement holds. For example I pick 400 black balls from my box than it is more probably to choose white ball from remaining 600 hundreds.","According to Law of Large Numbers, if I throw a coin 1000 times approximately 500 will be head and 500 tail. Suppose that I throw the coin 700 times and I got 700 heads. Can I say that in the next 300 throws the probability of getting tails will be higher than probability of getting heads? Edit: To make an analogy, imagine that you have a box that contains 500 black and 500 white balls. If 700 times (700 exaggerated) you choose black, than it is more probable that for 701 you get white. However if you say me that instead of one box you have 1000 similar box and every time you choose from one box that means the probability of choosing black or white will never change. With independent events you mean this? Edit2: Imagine that there are billions of people that throwing coins 1000 times. For each person there is an empty box. When he throw the coin, if it is tail he puts a black ball in his box, when the coin is head he puts white ball. So at the end of the experiment there are billions of boxes that each box contains approximately 500 black 500 white ball. So they give me the opportunity to choose one box. The box that I choose represents the one possible coin throwing that I would make. I am asking what is the difference between throwing coins and choosing one box in billions of boxes? If there is no difference, than the first statement holds. For example I pick 400 black balls from my box than it is more probably to choose white ball from remaining 600 hundreds.",,"['probability', 'law-of-large-numbers']"
26,There are 10 marbles in a bag. $6$ are red and $4$ are blue. You must chose at least 1 red marble. In how many ways can you chose three total marbles.,There are 10 marbles in a bag.  are red and  are blue. You must chose at least 1 red marble. In how many ways can you chose three total marbles.,6 4,I thought the answer is $^9C_2$ since the first (red) marble didn't count. You have to pick a red marble which reduces the total count from 10 to 9. The answer is 116 possible ways.,I thought the answer is $^9C_2$ since the first (red) marble didn't count. You have to pick a red marble which reduces the total count from 10 to 9. The answer is 116 possible ways.,,"['probability', 'permutations', 'combinations']"
27,"Seven coins are flipped. Find the probability that three land on one side, four on the other.","Seven coins are flipped. Find the probability that three land on one side, four on the other.",,"I'm a little confused as to which answer is correct or if either are correct. Answer #1: $\frac{\binom{7}{3}}{2^{7}}$ 7 choose 3= number of ways three land on one side, $2^{7}$= outcomes of coin toss Answer #2: $\frac{\binom{7}{3}+\binom{4}{4}}{2^{7}}$ 7 choose 3= number of ways three coins land on one side,4 choose 4= number of ways four coins land on the other, and  $2^{7}$= outcomes of coin toss Can someone please double check my results? Thank you!","I'm a little confused as to which answer is correct or if either are correct. Answer #1: $\frac{\binom{7}{3}}{2^{7}}$ 7 choose 3= number of ways three land on one side, $2^{7}$= outcomes of coin toss Answer #2: $\frac{\binom{7}{3}+\binom{4}{4}}{2^{7}}$ 7 choose 3= number of ways three coins land on one side,4 choose 4= number of ways four coins land on the other, and  $2^{7}$= outcomes of coin toss Can someone please double check my results? Thank you!",,"['probability', 'combinatorics', 'discrete-mathematics', 'combinations']"
28,Each of the two persons makes a single throw with a pair of unbiased dice.What is the probability that the throws are equal?,Each of the two persons makes a single throw with a pair of unbiased dice.What is the probability that the throws are equal?,,Each of the two persons makes a single throw with a pair of unbiased dice.What is the probability that the throws are equal? Since the same throws can result if either both of them get 1 or both of them get 2 or both of them get 3 or both of them get 4 or both of them 5 or both of them get 6. So I calculated probability as $\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}=\frac{1}{6}$ But my answer is wrong and the correct answer is $\frac{73}{648}$.Please help me with the correct approach to solve it.Thanks.,Each of the two persons makes a single throw with a pair of unbiased dice.What is the probability that the throws are equal? Since the same throws can result if either both of them get 1 or both of them get 2 or both of them get 3 or both of them get 4 or both of them 5 or both of them get 6. So I calculated probability as $\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}+\frac{1}{6}\times\frac{1}{6}=\frac{1}{6}$ But my answer is wrong and the correct answer is $\frac{73}{648}$.Please help me with the correct approach to solve it.Thanks.,,"['probability', 'combinatorics']"
29,Probability to draw specific ball from the bag as last one,Probability to draw specific ball from the bag as last one,,"Let's say I have a bag with 8 numbered balls inside, and I'm drawing them 1 by 1 until I get ball #1. What's the chance of me drawing ball #1 as last one? I was under the impression that the chances for me to draw it last is $$\frac18* \frac17*\frac16*  \frac15* \frac14* \frac13*\frac12=\frac1{40320}$$ since I'm drawing them 1 by 1, so 1st time I draw, I have 1/8 chance to pull #1, next draw I have 1/7, and so on? Is that wrong? A friend of mine says it's just 1/8, am I misunderstanding this?","Let's say I have a bag with 8 numbered balls inside, and I'm drawing them 1 by 1 until I get ball #1. What's the chance of me drawing ball #1 as last one? I was under the impression that the chances for me to draw it last is since I'm drawing them 1 by 1, so 1st time I draw, I have 1/8 chance to pull #1, next draw I have 1/7, and so on? Is that wrong? A friend of mine says it's just 1/8, am I misunderstanding this?",\frac18* \frac17*\frac16*  \frac15* \frac14* \frac13*\frac12=\frac1{40320},['probability']
30,Outcome of rolling a fair die 6 times,Outcome of rolling a fair die 6 times,,"I'm failing to understand how to come to the answer to this question. If you roll a fair die six times, what is the probability that the numbers recorded are $1$, $2$, $3$, $4$, $5$, and $6$ in any order? The answer given is $6!(1/6)^6 = 3/324$ Can anyone explain to me how to get to that answer? I would really appreciate the help! :)","I'm failing to understand how to come to the answer to this question. If you roll a fair die six times, what is the probability that the numbers recorded are $1$, $2$, $3$, $4$, $5$, and $6$ in any order? The answer given is $6!(1/6)^6 = 3/324$ Can anyone explain to me how to get to that answer? I would really appreciate the help! :)",,"['probability', 'combinatorics']"
31,Probability of drawing an Ace: before and after,Probability of drawing an Ace: before and after,,"this is my first question on the website. When I took probability, one of the first questions in my textbook was this: What is the probability of drawing an ace in a standard 52-card deck? That one was pretty easy, thankfully. The next one threw me for a loop... Take the top card away from the deck. What is the probability of drawing an ace? And the answer was the same as the first one! I can't remember how my professor explained it, but I feel the intuition at least. All one card removals are equally likely: it's almost like still having the original 52 cards. But I'm still bothered. ""The question is how to understand this."" Hope someone can help.","this is my first question on the website. When I took probability, one of the first questions in my textbook was this: What is the probability of drawing an ace in a standard 52-card deck? That one was pretty easy, thankfully. The next one threw me for a loop... Take the top card away from the deck. What is the probability of drawing an ace? And the answer was the same as the first one! I can't remember how my professor explained it, but I feel the intuition at least. All one card removals are equally likely: it's almost like still having the original 52 cards. But I'm still bothered. ""The question is how to understand this."" Hope someone can help.",,['probability']
32,Proof of: If $P(A) = P(B) = 1$ then $P(A \cap B) = 1$.,Proof of: If  then .,P(A) = P(B) = 1 P(A \cap B) = 1,Ok so I know this is obviously true but not sure if my method is right to proving it. Here's my go. $P(A\cap B)= P(A) \cdot P(B)$ by definition. $P(A)=P(B)=1$ Therefore $1\cdot 1=1$ so $P(A\cap B)=1$ I realise this is a really simply question but this answer seems too easy. Thanks,Ok so I know this is obviously true but not sure if my method is right to proving it. Here's my go. by definition. Therefore so I realise this is a really simply question but this answer seems too easy. Thanks,P(A\cap B)= P(A) \cdot P(B) P(A)=P(B)=1 1\cdot 1=1 P(A\cap B)=1,"['probability', 'proof-verification']"
33,"If a fair die is rolled 3 times, what are the odds of getting an even number on each of the first 2 rolls, and an odd number on the third roll?","If a fair die is rolled 3 times, what are the odds of getting an even number on each of the first 2 rolls, and an odd number on the third roll?",,"If a fair die is rolled 3 times, what are the odds of getting an even number on each of the first 2 rolls, and an odd number on the third roll? I think the permutations formula is needed i.e. $n!/(n-r)!$ because order matters but I'm not sure if n is 3 or 6 and what would r be? Any help would be much appreciated!","If a fair die is rolled 3 times, what are the odds of getting an even number on each of the first 2 rolls, and an odd number on the third roll? I think the permutations formula is needed i.e. because order matters but I'm not sure if n is 3 or 6 and what would r be? Any help would be much appreciated!",n!/(n-r)!,"['probability', 'permutations']"
34,Looking for counter-intuitive example for independence of random variables,Looking for counter-intuitive example for independence of random variables,,I am looking for a simple example of two independent discrete random variables that one would not expect to be independent because one knows that these two quantities have a causal relationship in real life.,I am looking for a simple example of two independent discrete random variables that one would not expect to be independent because one knows that these two quantities have a causal relationship in real life.,,"['probability', 'examples-counterexamples', 'independence']"
35,Evidence of Absence = Absence of Evidence?,Evidence of Absence = Absence of Evidence?,,Any clever-cloggs out there who can explain the formula below in more simple English please? - Do you agree with the formula?,Any clever-cloggs out there who can explain the formula below in more simple English please? - Do you agree with the formula?,,"['probability', 'probability-theory', 'philosophy']"
36,The probability that 25 people do not have the same birthday,The probability that 25 people do not have the same birthday,,"I figure that it would be something like this $$\frac{365}{365} \times \frac{364}{365} \times \cdots \times \frac{340}{365}$$ But that is a lot of fractions to enter into a calculator, even so I think this is the right answer but I was wondering if there is a shortcut or something? I have a casio CFX-9850GB.","I figure that it would be something like this $$\frac{365}{365} \times \frac{364}{365} \times \cdots \times \frac{340}{365}$$ But that is a lot of fractions to enter into a calculator, even so I think this is the right answer but I was wondering if there is a shortcut or something? I have a casio CFX-9850GB.",,['probability']
37,Why is the lim inf the union of intersections [duplicate],Why is the lim inf the union of intersections [duplicate],,This question already has answers here : Intuitive interpretation of limsup and liminf of sequences of sets? (5 answers) Closed 6 years ago . For my statistics class we had elementary set theory. It was stated that: $$\inf_{k\geq n } A_k = \bigcap\limits_{k=n}^{\infty} A_k$$ and $$\sup_{k\geq n } A_k = \bigcup\limits_{k=n}^{\infty} A_k$$ From this was deduced that: $$\lim\limits_{n\to\infty} \inf A_k = \bigcup\limits_{n=1}^{\infty} \bigcap\limits_{k=n}^{\infty} A_k$$ and $$\lim\limits_{n\to\infty} \sup A_k = \bigcap\limits_{n=1}^{\infty} \bigcup\limits_{k=n}^{\infty} A_k$$ I absolutely have no idea why. Could someone explain it to me in the least technical way possible? I neither get why the intersection of Ak from n onwards should be the infimum nor why the union of all intersections should be the limit of that infimum.,This question already has answers here : Intuitive interpretation of limsup and liminf of sequences of sets? (5 answers) Closed 6 years ago . For my statistics class we had elementary set theory. It was stated that: $$\inf_{k\geq n } A_k = \bigcap\limits_{k=n}^{\infty} A_k$$ and $$\sup_{k\geq n } A_k = \bigcup\limits_{k=n}^{\infty} A_k$$ From this was deduced that: $$\lim\limits_{n\to\infty} \inf A_k = \bigcup\limits_{n=1}^{\infty} \bigcap\limits_{k=n}^{\infty} A_k$$ and $$\lim\limits_{n\to\infty} \sup A_k = \bigcap\limits_{n=1}^{\infty} \bigcup\limits_{k=n}^{\infty} A_k$$ I absolutely have no idea why. Could someone explain it to me in the least technical way possible? I neither get why the intersection of Ak from n onwards should be the infimum nor why the union of all intersections should be the limit of that infimum.,,"['probability', 'probability-theory', 'elementary-set-theory', 'self-learning']"
38,A pair of fair dice is rolled. What is the condition probability that one of the dice is a four given the sum is a seven,A pair of fair dice is rolled. What is the condition probability that one of the dice is a four given the sum is a seven,,"I believe that the probability of the sum is seven is (1/18), unless i'm wrong of course. I'm getting stuck getting the top value. Any help? Is the probability of one of the dice being four = 1/3? Then it would be (1/3)(1/18)/ (1/18)?","I believe that the probability of the sum is seven is (1/18), unless i'm wrong of course. I'm getting stuck getting the top value. Any help? Is the probability of one of the dice being four = 1/3? Then it would be (1/3)(1/18)/ (1/18)?",,['probability']
39,Can all laws be derived from axioms?,Can all laws be derived from axioms?,,"I don't really understand the purpose of an axiom if some laws cannot be derived from them. For example, how is one supposed to prove De Morgan's laws with only the axioms of probability?","I don't really understand the purpose of an axiom if some laws cannot be derived from them. For example, how is one supposed to prove De Morgan's laws with only the axioms of probability?",,"['probability', 'axioms']"
40,"Train wait problem, probability","Train wait problem, probability",,"If one commuter train comes every $15$ minutes and another comes every $40$ minutes, what is the average amount of time one would have to wait before getting on a train? Suppose that they are not synchronized. The answer by the way is $6.5$ minutes. I don't see how the trains are not synchronized. Because they will arrive at the same time in $15*40$ minutes. Not sure if I understood the problem. I think it relates to the uniform distribution and the expected value of the uniform distribution. Please show steps in how you solve it.","If one commuter train comes every $15$ minutes and another comes every $40$ minutes, what is the average amount of time one would have to wait before getting on a train? Suppose that they are not synchronized. The answer by the way is $6.5$ minutes. I don't see how the trains are not synchronized. Because they will arrive at the same time in $15*40$ minutes. Not sure if I understood the problem. I think it relates to the uniform distribution and the expected value of the uniform distribution. Please show steps in how you solve it.",,"['probability', 'probability-distributions']"
41,Difficult probability of choosing ball from bag with $7$ balls labelled from $1-7$,Difficult probability of choosing ball from bag with  balls labelled from,7 1-7,"This is a very interesting word problem that I came across in an old textbook of mine. So I know its got something to do with probability, which perhaps yields the shortest, simplest proofs, but other than that, the textbook gave no hints really and I'm really not sure about how to approach it. Any guidance hints or help would be truly greatly appreciated. Thanks in advance :) So anyway, here the problem goes: A bag contains seven balls numbered from $1$ to $7$. A ball is chosen at random   and its number is noted. The ball is then returned to the bag. This is done a total of seven times. $(a)$ What is the probability that each ball is selected exactly once? $(b)$ What is the probability that at least one ball is not selected? $(c)$ What is the probability that exactly one of the balls is not selected? My thoughts: $(a)\, \left(\frac 17\right)^7=\frac{1}{823543}$ $(b) \, 1 - \frac{1}{823543}?$ $(c)$ No idea on this one. My head aches after just thinking about it.","This is a very interesting word problem that I came across in an old textbook of mine. So I know its got something to do with probability, which perhaps yields the shortest, simplest proofs, but other than that, the textbook gave no hints really and I'm really not sure about how to approach it. Any guidance hints or help would be truly greatly appreciated. Thanks in advance :) So anyway, here the problem goes: A bag contains seven balls numbered from $1$ to $7$. A ball is chosen at random   and its number is noted. The ball is then returned to the bag. This is done a total of seven times. $(a)$ What is the probability that each ball is selected exactly once? $(b)$ What is the probability that at least one ball is not selected? $(c)$ What is the probability that exactly one of the balls is not selected? My thoughts: $(a)\, \left(\frac 17\right)^7=\frac{1}{823543}$ $(b) \, 1 - \frac{1}{823543}?$ $(c)$ No idea on this one. My head aches after just thinking about it.",,['probability']
42,Recursive random draw [closed],Recursive random draw [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $R(n)$ be a random draw of integers between $0$ and $n − 1$ (inclusive). I repeatedly apply $R$, starting at $10^{100}$. What’s the expected number of repeated applications until I get zero?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $R(n)$ be a random draw of integers between $0$ and $n − 1$ (inclusive). I repeatedly apply $R$, starting at $10^{100}$. What’s the expected number of repeated applications until I get zero?",,"['probability', 'combinatorics', 'number-theory', 'recurrence-relations', 'expectation']"
43,What is the probability that the sum of two random numbers is less than a given number?,What is the probability that the sum of two random numbers is less than a given number?,,"Let us assume a pure random number generator generates a random number between the given range $[0,m]$ with equal probability. Given $m_1$, let it generate a random number($r_1$) in the range $[0,m_1]$. Given $m_2$, let it generate a random number($r_2$) in the range $[0,m_2]$. Now what is the probability that $r_1 + r_2 < K$ ( another number)? How can I calculate this probability?","Let us assume a pure random number generator generates a random number between the given range $[0,m]$ with equal probability. Given $m_1$, let it generate a random number($r_1$) in the range $[0,m_1]$. Given $m_2$, let it generate a random number($r_2$) in the range $[0,m_2]$. Now what is the probability that $r_1 + r_2 < K$ ( another number)? How can I calculate this probability?",,['probability']
44,Past coin tosses affect the latest one if you know about them? [duplicate],Past coin tosses affect the latest one if you know about them? [duplicate],,"This question already has answers here : If a coin toss is observed to come up as heads many times, does that affect the probability of the next toss? (12 answers) Closed 7 years ago . Suppose Mark and Paul are sitting on a table, and Mark starts tossing an unbiased and fair coin. He tosses it for 99 times, and he gets 99 consecutive tails. At this point Mark asks Paul: ""let's bet $100 on the next toss, do you want to pick tail or head?"" Question: In order to maximize his expected return, should Paul pick tail, head, or it doesn't matter?","This question already has answers here : If a coin toss is observed to come up as heads many times, does that affect the probability of the next toss? (12 answers) Closed 7 years ago . Suppose Mark and Paul are sitting on a table, and Mark starts tossing an unbiased and fair coin. He tosses it for 99 times, and he gets 99 consecutive tails. At this point Mark asks Paul: ""let's bet $100 on the next toss, do you want to pick tail or head?"" Question: In order to maximize his expected return, should Paul pick tail, head, or it doesn't matter?",,['probability']
45,Probability of getting a piece longer than $1/2$ on cutting a rope of length $1$ at two randomly chosen points,Probability of getting a piece longer than  on cutting a rope of length  at two randomly chosen points,1/2 1,"Here's a bootstrap approach I used to find the answer (python 3). def num_pieces(num,lenght):     ot = list(range(1,lenght+1))[::-1]     nig = []     for i in range(lenght-1):         n = random.randint(1, num-ot[i])         nig.append(n)         num -= n     nig.append(num)     r = []     for i in nig:          r.append(i/10)     return r  res = [] n1 = 1000 n2 = int(n1/10)  for i in range(n1):     a = []     for i in range(n2):         r = num_pieces(10,3)         if r[0] > 0.5 or r[1] > 0.5 or r[2] > 0.5:             a.append(1)         else:             a.append(0)     res.append(sum(a)/n2)  pd.DataFrame(res).hist(); And here's the result If my code is correct (I believe it is), the probability is about 50% Question - I do not know how to solve this task using plain math. In other words - what is the math base under the bootstrap result? UPDATE After receiving those awesome answers below, I checked the code and fixed the num_pieces generator. It worked incorrectly. All other code works just fine. So, here's the final solution def get_random():     a = [random.random(), random.random()]     c = 1 - (max(a))     b = max(a) - min(a)     a = min(a)     return [a,b,c] res = [] n1 = 1000 n2 = int(n1/10) for i in range(n1):     a = []     for i in range(n2):         r = get_random()         if r[0] > 0.5 or r[1] > 0.5 or r[2] > 0.5:             a.append(1)         else:             a.append(0)     res.append(sum(a)/n2) pd.DataFrame(res).hist(); The probability is 75% indeed. Thank you all for answering!","Here's a bootstrap approach I used to find the answer (python 3). def num_pieces(num,lenght):     ot = list(range(1,lenght+1))[::-1]     nig = []     for i in range(lenght-1):         n = random.randint(1, num-ot[i])         nig.append(n)         num -= n     nig.append(num)     r = []     for i in nig:          r.append(i/10)     return r  res = [] n1 = 1000 n2 = int(n1/10)  for i in range(n1):     a = []     for i in range(n2):         r = num_pieces(10,3)         if r[0] > 0.5 or r[1] > 0.5 or r[2] > 0.5:             a.append(1)         else:             a.append(0)     res.append(sum(a)/n2)  pd.DataFrame(res).hist(); And here's the result If my code is correct (I believe it is), the probability is about 50% Question - I do not know how to solve this task using plain math. In other words - what is the math base under the bootstrap result? UPDATE After receiving those awesome answers below, I checked the code and fixed the num_pieces generator. It worked incorrectly. All other code works just fine. So, here's the final solution def get_random():     a = [random.random(), random.random()]     c = 1 - (max(a))     b = max(a) - min(a)     a = min(a)     return [a,b,c] res = [] n1 = 1000 n2 = int(n1/10) for i in range(n1):     a = []     for i in range(n2):         r = get_random()         if r[0] > 0.5 or r[1] > 0.5 or r[2] > 0.5:             a.append(1)         else:             a.append(0)     res.append(sum(a)/n2) pd.DataFrame(res).hist(); The probability is 75% indeed. Thank you all for answering!",,['probability']
46,Expected consultant bill given distribution of time taken,Expected consultant bill given distribution of time taken,,"The cdf of the number of hours it takes a consultant to complete a project is given by $F(x)= \dfrac{x^2}{16}$ for o to 4. The consultant bills $300 per hour, rounded up to the nearest half hour, for the project. What is the expected amount of the total bill? (a)900 (b)800 (c)872 (d)950 (e)1100 My work: $f(x)= \dfrac{dF(x)}{dx}$ $f(x)=\dfrac{x}{8}$ so integral of $x^2/8$ from 0 to 4 = $x^3/24$ from 0 to 4 = 64/24 = 2.6667 round 2.6667 to nearest half hour is 2.5 so 2.5*300 = 800 But that's wrong; the answer to the question is 872. Can I please have help understanding why my method is incorrect, so I can try another method while understanding why my last attempt was incorrect.","The cdf of the number of hours it takes a consultant to complete a project is given by for o to 4. The consultant bills $300 per hour, rounded up to the nearest half hour, for the project. What is the expected amount of the total bill? (a)900 (b)800 (c)872 (d)950 (e)1100 My work: so integral of from 0 to 4 = from 0 to 4 = 64/24 = 2.6667 round 2.6667 to nearest half hour is 2.5 so 2.5*300 = 800 But that's wrong; the answer to the question is 872. Can I please have help understanding why my method is incorrect, so I can try another method while understanding why my last attempt was incorrect.",F(x)= \dfrac{x^2}{16} f(x)= \dfrac{dF(x)}{dx} f(x)=\dfrac{x}{8} x^2/8 x^3/24,"['probability', 'probability-distributions']"
47,Does the sum of Poisson random variables have a Poisson distribution?,Does the sum of Poisson random variables have a Poisson distribution?,,"So I have been taught that the sum of Poisson random variables has a Poisson distribution. However, I have a problem with this. Suppose you have a Poisson random variable $X$ with $E(X) = a$. Then a sum of $n$ Poisson random variables gives a mean of $E(nX) = n(a).$ However the variance will be $\text{Var}(nX) = n^2(a)$ Here lies the problem. If $nX$ has a Poisson distribution then the mean and the variance has to be the same; this is a property of Poisson distribution. But since they are different, the distribution can't be Poisson. So how do I resolve this discrepancy?","So I have been taught that the sum of Poisson random variables has a Poisson distribution. However, I have a problem with this. Suppose you have a Poisson random variable $X$ with $E(X) = a$. Then a sum of $n$ Poisson random variables gives a mean of $E(nX) = n(a).$ However the variance will be $\text{Var}(nX) = n^2(a)$ Here lies the problem. If $nX$ has a Poisson distribution then the mean and the variance has to be the same; this is a property of Poisson distribution. But since they are different, the distribution can't be Poisson. So how do I resolve this discrepancy?",,"['probability', 'statistics', 'poisson-distribution']"
48,If $S_2$ reaches the semi-final then the probability that $S_1$ wins the tournament is $\frac{1}{20}$,If  reaches the semi-final then the probability that  wins the tournament is,S_2 S_1 \frac{1}{20},"In  a knockout tournament $2^n$ equally skilled players;$S_1,S_2,...,S_{2^n}$ are participating.In each round players are divided in pair at random and winner from each pair moves in the next round.If $S_2$ reaches the semi-final then the probability that $S_1$ wins the tournament is $\frac{1}{20}$.Find the value of $n.$ There will be $n$ rounds of the tournament because $2^n$ players are there.But i dont know how to solve further.Some help/hints are needed.Thanks.","In  a knockout tournament $2^n$ equally skilled players;$S_1,S_2,...,S_{2^n}$ are participating.In each round players are divided in pair at random and winner from each pair moves in the next round.If $S_2$ reaches the semi-final then the probability that $S_1$ wins the tournament is $\frac{1}{20}$.Find the value of $n.$ There will be $n$ rounds of the tournament because $2^n$ players are there.But i dont know how to solve further.Some help/hints are needed.Thanks.",,['probability']
49,"What is the probability that Raj and Rana have atleast 3 persons between them,given raj and rana are standing in a row and there are 9 peoples.","What is the probability that Raj and Rana have atleast 3 persons between them,given raj and rana are standing in a row and there are 9 peoples.",,"Question: Raj and Rana are standing in a row. There are 9 persons including Raj and Rana. What is the probability that at least 3 people will stand between Raj and Rana? My solution: $9$ people can be arranged in $9!$ ways. Excluding Raj and Rana, out of $7$ people. Case 1: I select 3 people $^7C_3$ who can be arranged in $3!$ ways. Remaining $(9-(3+2))=4$ people can be arranged in $4!$ ways Therefore required arrangement=$^7C_3*3!*4!*2!$   ----$(i)$ Case 2: I select 4 people $^7C_4$ who can be arranged in $4!$ ways Remaining $(9-(4+2))=3$ people can be arranged in $3!$ ways Therefore required arrangement=$^7C_4*4!*3!*2!$   ----$(ii)$ Case 3: I select 5 people $^7C_5$ who can be arranged in $5!$ ways Remaining $(9-(5+2))=2$ people can be arranged in $2!$ ways Therefore required arrangement=$^7C_3*5!*2!*2!$   ----$(iii)$ Case 4: I select 6 people $^7C_6$ who can be arranged in $6!$ ways Remaining $(9-(6+2))=1$ people can -be arranged in $1!$ way. Therefore required arrangement=$^7C_6*6!*1!*2!$   ----$(iv)$ Case 5: I select 7 people $^7C_7$  which can be arranged in $7!$ ways Remaining $(9-(7+2))=0$ people can be arranged in $1!$ ways Therefore required arrangement=$^7C_7*7!*1!*2!$   ----$(v)$ Adding equations $\frac{(i)+(ii)+(iii)+(iv)+(v)}{9!}$ we get the  required probability. Is it a correct approach and if there exists any shorter method, could you please tell me? Correct answer is $\frac5{12}$.","Question: Raj and Rana are standing in a row. There are 9 persons including Raj and Rana. What is the probability that at least 3 people will stand between Raj and Rana? My solution: $9$ people can be arranged in $9!$ ways. Excluding Raj and Rana, out of $7$ people. Case 1: I select 3 people $^7C_3$ who can be arranged in $3!$ ways. Remaining $(9-(3+2))=4$ people can be arranged in $4!$ ways Therefore required arrangement=$^7C_3*3!*4!*2!$   ----$(i)$ Case 2: I select 4 people $^7C_4$ who can be arranged in $4!$ ways Remaining $(9-(4+2))=3$ people can be arranged in $3!$ ways Therefore required arrangement=$^7C_4*4!*3!*2!$   ----$(ii)$ Case 3: I select 5 people $^7C_5$ who can be arranged in $5!$ ways Remaining $(9-(5+2))=2$ people can be arranged in $2!$ ways Therefore required arrangement=$^7C_3*5!*2!*2!$   ----$(iii)$ Case 4: I select 6 people $^7C_6$ who can be arranged in $6!$ ways Remaining $(9-(6+2))=1$ people can -be arranged in $1!$ way. Therefore required arrangement=$^7C_6*6!*1!*2!$   ----$(iv)$ Case 5: I select 7 people $^7C_7$  which can be arranged in $7!$ ways Remaining $(9-(7+2))=0$ people can be arranged in $1!$ ways Therefore required arrangement=$^7C_7*7!*1!*2!$   ----$(v)$ Adding equations $\frac{(i)+(ii)+(iii)+(iv)+(v)}{9!}$ we get the  required probability. Is it a correct approach and if there exists any shorter method, could you please tell me? Correct answer is $\frac5{12}$.",,['probability']
50,Probablity of drawing all the red balls while blue and green are still left,Probablity of drawing all the red balls while blue and green are still left,,"Suppose that a box contains 10 red balls, 20 green balls, and 30 blue balls. Suppose also that balls are drawn from the box one at a time at random. What is the probability that all the red balls are drawn before the blue or green balls are themselves exhausted. What is the probability that as the last red ball is drawn, there remains at least one blue and one green left in the box. The answer I was given is $\dfrac{7}{12}$ and a general equation is: $$ \dfrac{b g}{1-b}+\dfrac{b g}{1-g} $$ where $$ g=\dfrac{20}{60},b=\dfrac{30}{60} $$ but why?","Suppose that a box contains 10 red balls, 20 green balls, and 30 blue balls. Suppose also that balls are drawn from the box one at a time at random. What is the probability that all the red balls are drawn before the blue or green balls are themselves exhausted. What is the probability that as the last red ball is drawn, there remains at least one blue and one green left in the box. The answer I was given is $\dfrac{7}{12}$ and a general equation is: $$ \dfrac{b g}{1-b}+\dfrac{b g}{1-g} $$ where $$ g=\dfrac{20}{60},b=\dfrac{30}{60} $$ but why?",,"['probability', 'probability-theory']"
51,Exponential distribution moment generating function to find the mean,Exponential distribution moment generating function to find the mean,,With mean = 2 with exponential distribution Calculate $ E(200 + 5Y^2 + 4Y^3) = 432 $ $E(200) = 200 $ $E(5Y^2) = 5E(Y^2) = 5(8) = 40 $ $E(4Y^3) = 4E(Y^3) = 4(48) = 192 $ $E(Y^2) = V(Y) + [E(Y)]^2 = 2^2+2^2$ $E(Y^3) = m_Y^3(0) = 48(1-2(0))^{-4} = 48$ is this right?,With mean = 2 with exponential distribution Calculate $ E(200 + 5Y^2 + 4Y^3) = 432 $ $E(200) = 200 $ $E(5Y^2) = 5E(Y^2) = 5(8) = 40 $ $E(4Y^3) = 4E(Y^3) = 4(48) = 192 $ $E(Y^2) = V(Y) + [E(Y)]^2 = 2^2+2^2$ $E(Y^3) = m_Y^3(0) = 48(1-2(0))^{-4} = 48$ is this right?,,"['probability', 'probability-distributions']"
52,"Expected value of $\ln X$ if $X$ is $\Gamma(a,b)$ distributed.",Expected value of  if  is  distributed.,"\ln X X \Gamma(a,b)","I'm new here and hope you can help. It's really late here in South Africa, maybe my mind just doesn't want to function now!  But I need to figure out how to get a closed form expression hopefully for $E(\ln X)$  and even $E(\ln (X^2))$  if $X$ is $\Gamma(a,b)$ distributed. Any help would be greatly appreciated!! Scrofungulus","I'm new here and hope you can help. It's really late here in South Africa, maybe my mind just doesn't want to function now!  But I need to figure out how to get a closed form expression hopefully for $E(\ln X)$  and even $E(\ln (X^2))$  if $X$ is $\Gamma(a,b)$ distributed. Any help would be greatly appreciated!! Scrofungulus",,"['probability', 'statistics', 'special-functions']"
53,"How to prove a random variable taking values in $[0,1]$ range has variance no larger than $\frac{1}{4}$?",How to prove a random variable taking values in  range has variance no larger than ?,"[0,1] \frac{1}{4}","How can I prove that a random variable taking values in $[0,1]$ has variance no larger than $\frac{1}{4}$? If it matters, discrete and continuous proofs are both welcome.","How can I prove that a random variable taking values in $[0,1]$ has variance no larger than $\frac{1}{4}$? If it matters, discrete and continuous proofs are both welcome.",,"['probability', 'statistics']"
54,A question regarding the hitting time formula in brownian motion,A question regarding the hitting time formula in brownian motion,,"Let $\tau_a=\inf\{t: B_t=a\}$, the hitting time of the standard Brownian motion to reach the boundary $a$. This is easily derived $$E(e^{-\lambda \tau_a})=e^{-|a|\sqrt{2\lambda}}$$ But I am having a problem of using this formula to get the moments of $\tau_a$ by matching the coefficients of terms for each power of $\lambda$, specifically, the LHS, if expanded, has all integer powers of $\lambda$; however, the RHS has the various terms of $\sqrt{\lambda}$. How to reconcile the difference here? Could somebody please help? Thanks.","Let $\tau_a=\inf\{t: B_t=a\}$, the hitting time of the standard Brownian motion to reach the boundary $a$. This is easily derived $$E(e^{-\lambda \tau_a})=e^{-|a|\sqrt{2\lambda}}$$ But I am having a problem of using this formula to get the moments of $\tau_a$ by matching the coefficients of terms for each power of $\lambda$, specifically, the LHS, if expanded, has all integer powers of $\lambda$; however, the RHS has the various terms of $\sqrt{\lambda}$. How to reconcile the difference here? Could somebody please help? Thanks.",,"['probability', 'stochastic-processes']"
55,very simple conditional probability question,very simple conditional probability question,,"You know that a couple has two children. You go to the couple's house and one of their children, a young boy, opens the door. What is the probability that the couple's other child is a girl? If you list all possibilities for the sexes of two children, $BB, BG, GB, GG$, you see that $2$ of the $3$ pairs that have B (for boy) in them also have a girl, so the answer one could argue is $2/3$. On the other hand, one could argue that the answer is $1/2$, since the probability that any one child is a girl is $1/2$, and intuitively (?) should be independent of the gender of its siblings. Some background to possibly justify posting it here: the question was asked at an interview for an actuarial/insurance type position, and the interviewer said the answer was $2/3$, whereas my friend who was being interviewed (and has a masters in math) thought the answer was $1/2$, even after the interviewer explained his logic. My friend felt that the interviewer wasn't taking into account the fact that it is not equally likely that a boy will open the door in the $BB$ versus the $BG$ combination, and one has to take into account that fact. I have no idea which is the correct answer, both sound somewhat convincing to me (I have a Ph.D. in math, but I won't mention from where in an effort to avoid embarrassing my degree granting institution!). Anyways, any help would be appreciated and I apologize if this is too simple a question for this forum.","You know that a couple has two children. You go to the couple's house and one of their children, a young boy, opens the door. What is the probability that the couple's other child is a girl? If you list all possibilities for the sexes of two children, $BB, BG, GB, GG$, you see that $2$ of the $3$ pairs that have B (for boy) in them also have a girl, so the answer one could argue is $2/3$. On the other hand, one could argue that the answer is $1/2$, since the probability that any one child is a girl is $1/2$, and intuitively (?) should be independent of the gender of its siblings. Some background to possibly justify posting it here: the question was asked at an interview for an actuarial/insurance type position, and the interviewer said the answer was $2/3$, whereas my friend who was being interviewed (and has a masters in math) thought the answer was $1/2$, even after the interviewer explained his logic. My friend felt that the interviewer wasn't taking into account the fact that it is not equally likely that a boy will open the door in the $BB$ versus the $BG$ combination, and one has to take into account that fact. I have no idea which is the correct answer, both sound somewhat convincing to me (I have a Ph.D. in math, but I won't mention from where in an effort to avoid embarrassing my degree granting institution!). Anyways, any help would be appreciated and I apologize if this is too simple a question for this forum.",,[]
56,"Expectation and variance of $Y=\max(X_1,\ldots,X_n)$, where $X$ is uniformly distributed.","Expectation and variance of , where  is uniformly distributed.","Y=\max(X_1,\ldots,X_n) X","I've got a problem, with a solution, in my introduction to mathematical statistics book and I just don't get how they got there. There are follow up questions so I'd like to get insight at how they got to the answer. The problem: Let $X_1,\ldots,X_n$ be independent random variables with the uniform distribution on the interval $[0,1]$. Determine the expectation and variance of $Y=\max(X_1,\ldots,X_n)$. Hint: Deduce the density of Y from the distriution function $P(Y \leq y)$ of $Y$, which can be determined using the distribution functions of $X_1, \ldots, X_n$. The solution: $\operatorname E[Y]=\frac{n}{n+1}$, $\operatorname{var}[Y]=\frac{n}{n+2}+\left(\frac{n}{n+1}\right)^2$. Now I know that a uniformly distributed random variable on $[0,1]$ has the following probability distribution, expectation and variance; $F(x)=x$ for $x \in [0,1]$,  $\operatorname E[X]=\frac{1}{2}$ and $\operatorname{var}[X]=\frac{1}{12}$.","I've got a problem, with a solution, in my introduction to mathematical statistics book and I just don't get how they got there. There are follow up questions so I'd like to get insight at how they got to the answer. The problem: Let $X_1,\ldots,X_n$ be independent random variables with the uniform distribution on the interval $[0,1]$. Determine the expectation and variance of $Y=\max(X_1,\ldots,X_n)$. Hint: Deduce the density of Y from the distriution function $P(Y \leq y)$ of $Y$, which can be determined using the distribution functions of $X_1, \ldots, X_n$. The solution: $\operatorname E[Y]=\frac{n}{n+1}$, $\operatorname{var}[Y]=\frac{n}{n+2}+\left(\frac{n}{n+1}\right)^2$. Now I know that a uniformly distributed random variable on $[0,1]$ has the following probability distribution, expectation and variance; $F(x)=x$ for $x \in [0,1]$,  $\operatorname E[X]=\frac{1}{2}$ and $\operatorname{var}[X]=\frac{1}{12}$.",,"['probability', 'probability-distributions', 'uniform-distribution', 'expected-value']"
57,Deriving the variance of the Bernoulli distribution,Deriving the variance of the Bernoulli distribution,,"For a Bernoulli distribution, $\mu_X = p$. I can easily derive this from the general equation for mean of a discrete random variable: $$ \mu_X=\sum_{i=1}^kx_iPr(X=x) $$ $$ \mu_X=1(p)+0(1-p)=p $$ I know that the variance of the Bernoulli distribution is supposed to be $\sigma_x^2=p(1-p)$. But I can not seem to derive that properly from the general equation for variance of a discrete random variable: $$ \sigma_x^2=\sum_{i=1}^k(x_i-\mu_X)Pr(X=x_i) $$ $$ \sigma_x^2=(x_0-p)(1-p)+(x_1-p)(p) $$ $$ \sigma_x^2=(0-p)(1-p)+(1-p)(p) $$ $$ \sigma_x^2=-p(1-p)+(1-p)(p) $$ $$ \sigma_x^2=-p+p^2+p-p^2 $$ $$ \sigma_x^2=0 $$ This is obviously incorrect; what am I doing incorrectly in my derivation?","For a Bernoulli distribution, $\mu_X = p$. I can easily derive this from the general equation for mean of a discrete random variable: $$ \mu_X=\sum_{i=1}^kx_iPr(X=x) $$ $$ \mu_X=1(p)+0(1-p)=p $$ I know that the variance of the Bernoulli distribution is supposed to be $\sigma_x^2=p(1-p)$. But I can not seem to derive that properly from the general equation for variance of a discrete random variable: $$ \sigma_x^2=\sum_{i=1}^k(x_i-\mu_X)Pr(X=x_i) $$ $$ \sigma_x^2=(x_0-p)(1-p)+(x_1-p)(p) $$ $$ \sigma_x^2=(0-p)(1-p)+(1-p)(p) $$ $$ \sigma_x^2=-p(1-p)+(1-p)(p) $$ $$ \sigma_x^2=-p+p^2+p-p^2 $$ $$ \sigma_x^2=0 $$ This is obviously incorrect; what am I doing incorrectly in my derivation?",,"['probability', 'probability-distributions']"
58,"An experiment is repeated, and the first success occurs on the 8th attempt. What is the success probability for which this is most likely to happen?","An experiment is repeated, and the first success occurs on the 8th attempt. What is the success probability for which this is most likely to happen?",,"An experiment is repeated, and the first success occurs on the 8th attempt. What is the success probability for which this is most likely to happen? So we want to find $p$ between $0$ and $1$ which maximizes $(1-p)^{7}p$. To do this we could take the derivative and find all the critical points: $$(1-p)^7 - 7(1-p)^6p = 0$$ But I don't know how to get the roots of this equation by hand. What can I do instead to solve this problem?","An experiment is repeated, and the first success occurs on the 8th attempt. What is the success probability for which this is most likely to happen? So we want to find $p$ between $0$ and $1$ which maximizes $(1-p)^{7}p$. To do this we could take the derivative and find all the critical points: $$(1-p)^7 - 7(1-p)^6p = 0$$ But I don't know how to get the roots of this equation by hand. What can I do instead to solve this problem?",,['probability']
59,"100 pieces of paper in a box, one of which has a black dot on it. Probability Question. [closed]","100 pieces of paper in a box, one of which has a black dot on it. Probability Question. [closed]",,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question There are $100$ pieces of paper in a box, one of which has a black dot on it. If $100$ people go up one by one and pick a paper from the box, which one has the lowest probability of getting the black dot, and which one has the highest probability of getting the black dot?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question There are $100$ pieces of paper in a box, one of which has a black dot on it. If $100$ people go up one by one and pick a paper from the box, which one has the lowest probability of getting the black dot, and which one has the highest probability of getting the black dot?",,['probability']
60,How many ways in which distinct people can get off a train,How many ways in which distinct people can get off a train,,"I've been learning probability recently but I'm having trouble solving this question: Suppose you have 50 people on a train and you have 4 stations you can get off at (call them Stations 1,2,3,4). If no one boards the train at any of these stations, in how many ways can the 50 people get off the train, assuming the people are distinguishable (I care who gets off where)? If I didn't care who gets off where, then using stars and bars it would simply be 54 choose 3. But the problem for me arises in thinking when they're distinguishable. Right now my logic was for each of the 54 choose 3 ways, you can permute the groups among themselves in 4! ways. I'm pretty sure that's not right, but I don't know where to go.","I've been learning probability recently but I'm having trouble solving this question: Suppose you have 50 people on a train and you have 4 stations you can get off at (call them Stations 1,2,3,4). If no one boards the train at any of these stations, in how many ways can the 50 people get off the train, assuming the people are distinguishable (I care who gets off where)? If I didn't care who gets off where, then using stars and bars it would simply be 54 choose 3. But the problem for me arises in thinking when they're distinguishable. Right now my logic was for each of the 54 choose 3 ways, you can permute the groups among themselves in 4! ways. I'm pretty sure that's not right, but I don't know where to go.",,"['probability', 'combinatorics', 'combinations']"
61,How to generate equiprobable numbers with a random generator?,How to generate equiprobable numbers with a random generator?,,"Is it possible to emulate a 2 sided coin flip (50/50) with a random number generator which outputs equiprobably the numbers 1, 2 and 3 ? If yes, how ? If not why ? Is there a theorem? Can it be expanded to any numbers x (""sides"" of the coin) and y (random generator output) ?","Is it possible to emulate a 2 sided coin flip (50/50) with a random number generator which outputs equiprobably the numbers 1, 2 and 3 ? If yes, how ? If not why ? Is there a theorem? Can it be expanded to any numbers x (""sides"" of the coin) and y (random generator output) ?",,"['probability', 'combinatorics', 'elementary-number-theory', 'random']"
62,Probability that 4th Question on Test is First Question Graded Right if Grading Order is Random Too,Probability that 4th Question on Test is First Question Graded Right if Grading Order is Random Too,,"I came across this one question in my textbook: For each question on a multiple-choice test with 5 questions, there are five possible answers, of which exactly one is correct. If a student selects answers at random, give the probability that the first question answered correctly is question 4. And I was wondering what would happen if the teacher also graded the test in a random order. The way I approached the problem was by looking at a permutation of the sequence {1,2,3,4,5}. There's then a function that maps 1,2,3,4,5 to their position in the permutation we can call f. The probability that the teacher grades in the order of that permutation and that question #4 is the first question right is then: 0.8^(f(4)-1)*0.2/(5!) since we need every question that were graded before #4 to be wrong and then for #4 to be right. The 1/5! is the probability that that specific grading order was chosen. We can group the permutation functions by how they map 4. So the set of functions that map 4 to 1 would be one group and the set of functions that map 4 to 5 would be another group. There are 4! elements in each set (4! arrangements of 5 objects with one object being fixed) so the total probability is then the sum from n=1 to 5 of 0.8^(n-1)*1/25 which I got to be roughly 0.134. I think my answer is right but when I tried to check it experimentally in Python (simulating these probability problems makes for some good coding problems which is nice), I got 0.0711. Here's the code: import random  def experi():     li = [];          index = random.sample(range(1, 6), 5);          for i in range(1,6):         li.append(random.randint(1,6));          #check if 4th question is right if not, return 0     if li[3] != 1:         return 0;              #li is a list of random integers from 1-5     #for simplicity we assume that all questions have same answer, 1     #generate random integer, that is question number we need to get right first     #then we shuffle range(1:5) to get a random indexing     #we then iterate through the shuffle and check if first index to be right is 4          # goes through index if it hits 4 then nothing before was correct     #if it hits a right answer before 4, then we return false     for i in index:         if i == 3:             return 1;         if li[i-1] == 1:             return 0;          return 0;  count = 0; N = 100000; for i in range(N):     count += experi();  print(count/N); I would really appreciate it if you guys could tell me whether it's my code or my math that's wrong (or both).","I came across this one question in my textbook: For each question on a multiple-choice test with 5 questions, there are five possible answers, of which exactly one is correct. If a student selects answers at random, give the probability that the first question answered correctly is question 4. And I was wondering what would happen if the teacher also graded the test in a random order. The way I approached the problem was by looking at a permutation of the sequence {1,2,3,4,5}. There's then a function that maps 1,2,3,4,5 to their position in the permutation we can call f. The probability that the teacher grades in the order of that permutation and that question #4 is the first question right is then: 0.8^(f(4)-1)*0.2/(5!) since we need every question that were graded before #4 to be wrong and then for #4 to be right. The 1/5! is the probability that that specific grading order was chosen. We can group the permutation functions by how they map 4. So the set of functions that map 4 to 1 would be one group and the set of functions that map 4 to 5 would be another group. There are 4! elements in each set (4! arrangements of 5 objects with one object being fixed) so the total probability is then the sum from n=1 to 5 of 0.8^(n-1)*1/25 which I got to be roughly 0.134. I think my answer is right but when I tried to check it experimentally in Python (simulating these probability problems makes for some good coding problems which is nice), I got 0.0711. Here's the code: import random  def experi():     li = [];          index = random.sample(range(1, 6), 5);          for i in range(1,6):         li.append(random.randint(1,6));          #check if 4th question is right if not, return 0     if li[3] != 1:         return 0;              #li is a list of random integers from 1-5     #for simplicity we assume that all questions have same answer, 1     #generate random integer, that is question number we need to get right first     #then we shuffle range(1:5) to get a random indexing     #we then iterate through the shuffle and check if first index to be right is 4          # goes through index if it hits 4 then nothing before was correct     #if it hits a right answer before 4, then we return false     for i in index:         if i == 3:             return 1;         if li[i-1] == 1:             return 0;          return 0;  count = 0; N = 100000; for i in range(N):     count += experi();  print(count/N); I would really appreciate it if you guys could tell me whether it's my code or my math that's wrong (or both).",,"['probability', 'combinatorics', 'probability-theory', 'discrete-mathematics', 'python']"
63,Is $E[X^2] = E[|X|^2]$?,Is ?,E[X^2] = E[|X|^2],"Let $X$ be a random variable with mean 0 and variance $\sigma^2$ . Then $E[X^2] = E[|X|^2]$ but when we write them as $$ E[X^2] = \text{Var}[X] + E[X]^2 = \sigma, $$ and $$ E[|X|^2] = \text{Var}[|X|] + E[|X|]^2, $$ they are not equal. What is going on here, am I mistaken in thinking $E[X^2] = E[|X|^2]$ ?","Let be a random variable with mean 0 and variance . Then but when we write them as and they are not equal. What is going on here, am I mistaken in thinking ?","X \sigma^2 E[X^2] = E[|X|^2] 
E[X^2] = \text{Var}[X] + E[X]^2 = \sigma,
 
E[|X|^2] = \text{Var}[|X|] + E[|X|]^2,
 E[X^2] = E[|X|^2]","['probability', 'probability-theory', 'statistics', 'expected-value', 'variance']"
64,Simple problem on conditional geometric probability,Simple problem on conditional geometric probability,,"The occurrence of the event $A$ is equally likely in every moment of the interval $[0, T]$. The probability of event $A$ occurring at all in this interval is $p$. Given that $A$ hasn't occurred in the interval $[0,t]$ what's the probability that $A$ will occur in $[t, T]$? I am getting a different answer than the one given in the book. I wonder which one is correct. My answer is $\dfrac{Tp-tp}{T-pt}$ The book's answer is my answer divided by $p$.","The occurrence of the event $A$ is equally likely in every moment of the interval $[0, T]$. The probability of event $A$ occurring at all in this interval is $p$. Given that $A$ hasn't occurred in the interval $[0,t]$ what's the probability that $A$ will occur in $[t, T]$? I am getting a different answer than the one given in the book. I wonder which one is correct. My answer is $\dfrac{Tp-tp}{T-pt}$ The book's answer is my answer divided by $p$.",,['probability']
65,Finding probability for general cases,Finding probability for general cases,,"For a student to qualify, he must pass at least two out of three exams. The probability that he will pass the 1st exam is $p$. If he fails in one of the exams then the probability of passing in the next exam is $p/2$ otherwise it remains the same. Find the probability that he will qualify. My textbook answer reads  $2p^2 – p^3$. This is possible if only the below cases are considered: He passes first and second exam. He passes first, fails in second but passes third exam. He fails in first, passes second and third exam. But I think this is wrong since at least two out of three exams means,passing in first, second  and third exam is inclusive.  Someone please solve this paradox.","For a student to qualify, he must pass at least two out of three exams. The probability that he will pass the 1st exam is $p$. If he fails in one of the exams then the probability of passing in the next exam is $p/2$ otherwise it remains the same. Find the probability that he will qualify. My textbook answer reads  $2p^2 – p^3$. This is possible if only the below cases are considered: He passes first and second exam. He passes first, fails in second but passes third exam. He fails in first, passes second and third exam. But I think this is wrong since at least two out of three exams means,passing in first, second  and third exam is inclusive.  Someone please solve this paradox.",,['probability']
66,Consequences of being both independent and conditionally independent?,Consequences of being both independent and conditionally independent?,,"Suppose $A$, $B$, and $C$ are random variables. If $A$ and $B$ are independent, and they are also conditionally independent given $C$, can we conclude that either $A$ and $C$ are independent or $B$ and $C$ are independent? Or is there a case where given the constraints, $C$ can still be dependent to both $A$ and $B$? This question was inspired from Bayesian network configurations. I was trying to prove the former with no luck, and I wasn't able to find anything online that helped, so I figured that it might not even be true. Could someone please provide either a proof or a counterexample (or some other reasoning to why it's false)?","Suppose $A$, $B$, and $C$ are random variables. If $A$ and $B$ are independent, and they are also conditionally independent given $C$, can we conclude that either $A$ and $C$ are independent or $B$ and $C$ are independent? Or is there a case where given the constraints, $C$ can still be dependent to both $A$ and $B$? This question was inspired from Bayesian network configurations. I was trying to prove the former with no luck, and I wasn't able to find anything online that helped, so I figured that it might not even be true. Could someone please provide either a proof or a counterexample (or some other reasoning to why it's false)?",,['probability']
67,Which is the probability that a group of 10 people exceed the maximum load?,Which is the probability that a group of 10 people exceed the maximum load?,,An elevator with capacity for 10 people is designed to support a maximum load of 750kg.If the weights  of people that use the elevator are distribuited with mean 70kg and standard deviation 8kg. Which is the probability that a group of 10 people exceed the maximum load ? Attempt: I know that I should have something like this $P(X>750)=1-P(X\le 750)=..$ but I don't know how to define the random variable $X$. I also don't know what is the distribution. I was thinking on 'Let $X$ be the random variable that represent the weights of 10 people'. Am I correct? Could someone guide me please?,An elevator with capacity for 10 people is designed to support a maximum load of 750kg.If the weights  of people that use the elevator are distribuited with mean 70kg and standard deviation 8kg. Which is the probability that a group of 10 people exceed the maximum load ? Attempt: I know that I should have something like this $P(X>750)=1-P(X\le 750)=..$ but I don't know how to define the random variable $X$. I also don't know what is the distribution. I was thinking on 'Let $X$ be the random variable that represent the weights of 10 people'. Am I correct? Could someone guide me please?,,"['probability', 'statistics', 'probability-distributions']"
68,Picking first or picking last,Picking first or picking last,,"We've had quite a debate in our family regarding this one. Five guys want to share a house with five bedrooms.  Room 5 is smaller than the rest and no one wants to pick it.  To decide which room they get, they put five pieces of paper in a bag, labelled rooms 1 to 5. One at a time, each guy puts a hand in the bag and pulls one piece of paper. They reveal which room they got after each pull from the bag. The last guy to pull gets the last sheet of paper. The debate in our family is around the odds of picking room 5.  We all agree, at the beginning of the selection process, that it is 20% (1 in 5).  But after the first sheet is pulled and it is not room 5, the remaining odds for picking room 5 rise to 1 in 4.  Then if room 5 is not selected again, the odds rise to 1 in 3 then the 4th person has odds of 1 in 2 = 50%. One member of our family insisted that the strategy should be to pick first (or earliest possible) to keep the odds lowest that room 5 would be picked.  We contrasted this with a scenario where each guy pulled their sheet but no one revealed until all sheets were picked.  Clearly the odds would be 20% for each person. Meanwhile, another argument presented in our family is that if you pick first there is a 20% chance of picking room 5 and an 80% chance of picking any of the other rooms. However if you get the last slip of paper there is also an 80% chance that it will have already been picked, thereby giving the last person a 20% chance of getting room 5 as well.  So the question to this community is: when the picks are revealed as they occur, is there any benefit or advantage to picking first or last?  And, does revealing affect the overall outcome.","We've had quite a debate in our family regarding this one. Five guys want to share a house with five bedrooms.  Room 5 is smaller than the rest and no one wants to pick it.  To decide which room they get, they put five pieces of paper in a bag, labelled rooms 1 to 5. One at a time, each guy puts a hand in the bag and pulls one piece of paper. They reveal which room they got after each pull from the bag. The last guy to pull gets the last sheet of paper. The debate in our family is around the odds of picking room 5.  We all agree, at the beginning of the selection process, that it is 20% (1 in 5).  But after the first sheet is pulled and it is not room 5, the remaining odds for picking room 5 rise to 1 in 4.  Then if room 5 is not selected again, the odds rise to 1 in 3 then the 4th person has odds of 1 in 2 = 50%. One member of our family insisted that the strategy should be to pick first (or earliest possible) to keep the odds lowest that room 5 would be picked.  We contrasted this with a scenario where each guy pulled their sheet but no one revealed until all sheets were picked.  Clearly the odds would be 20% for each person. Meanwhile, another argument presented in our family is that if you pick first there is a 20% chance of picking room 5 and an 80% chance of picking any of the other rooms. However if you get the last slip of paper there is also an 80% chance that it will have already been picked, thereby giving the last person a 20% chance of getting room 5 as well.  So the question to this community is: when the picks are revealed as they occur, is there any benefit or advantage to picking first or last?  And, does revealing affect the overall outcome.",,['probability']
69,Linearity in Expected Value,Linearity in Expected Value,,"I have 4 cards, number 1, 2, 3, and 4. I draw 2 cards at random and without replacement. What is the expected value of the sum? Solution: $E[X_1+X_2]=E[X_1]+E[X_2],$  where $E[X_i]= 1/4(1+2+3+4)=2.5$. Thus $E[X_1+X_2]=2*2.5 =5.$ I totally understand that regardless $X_1,X_2$ are dependent or independent, linearity in expectation holds. My question is, how come after taking the expectation, you can treat $E[X_1]=E[X_2]=E[X_i]?$ This has sharp contrast with the Coupon Collection problems, in which the problem asks the expected number of attempts in order to collect at least 1 coupon of each N type. Linearity of expectation still holds.  The solution is: $E[Coupon_1 + Coupon_2 + .. + Coupon_N] = E[Coupon_1] + ... + E[Coupon_N]$ however, $E[Coupon_1] \neq E[Coupon_2]\neq E[Coupon_3].....$. Whereas in the former problem, you can treat $E[X_i]$ to be the same, while in both cases, they are all dependent on the other random variables. But in the later case, the $E[X_i]$ are no longer the same.  I am confused!","I have 4 cards, number 1, 2, 3, and 4. I draw 2 cards at random and without replacement. What is the expected value of the sum? Solution: $E[X_1+X_2]=E[X_1]+E[X_2],$  where $E[X_i]= 1/4(1+2+3+4)=2.5$. Thus $E[X_1+X_2]=2*2.5 =5.$ I totally understand that regardless $X_1,X_2$ are dependent or independent, linearity in expectation holds. My question is, how come after taking the expectation, you can treat $E[X_1]=E[X_2]=E[X_i]?$ This has sharp contrast with the Coupon Collection problems, in which the problem asks the expected number of attempts in order to collect at least 1 coupon of each N type. Linearity of expectation still holds.  The solution is: $E[Coupon_1 + Coupon_2 + .. + Coupon_N] = E[Coupon_1] + ... + E[Coupon_N]$ however, $E[Coupon_1] \neq E[Coupon_2]\neq E[Coupon_3].....$. Whereas in the former problem, you can treat $E[X_i]$ to be the same, while in both cases, they are all dependent on the other random variables. But in the later case, the $E[X_i]$ are no longer the same.  I am confused!",,"['probability', 'probability-theory', 'probability-distributions']"
70,The probability of scoring a 2 just once when a die is thrown three times?,The probability of scoring a 2 just once when a die is thrown three times?,,"A die is thrown three times. Show the probability of scoring a $2$ on just one occasion in the probability tree diagram and find the probability. My Approach: When a die is thrown once, the sample space is $6$. When it is thrown twice, the sample space is $36$ and when the die is thrown thrice, the sample space is $216$. But, how could I adjust the tree diagram with $216$ sample space in one piece of paper. Moreover, I asked this question to my teacher at school, he, too could not draw the tree diagram. However, he got the answer as $\frac {25}{72}$, but the answer given in my book is $\frac {1}{8}$. Please, help me to solve this.","A die is thrown three times. Show the probability of scoring a $2$ on just one occasion in the probability tree diagram and find the probability. My Approach: When a die is thrown once, the sample space is $6$. When it is thrown twice, the sample space is $36$ and when the die is thrown thrice, the sample space is $216$. But, how could I adjust the tree diagram with $216$ sample space in one piece of paper. Moreover, I asked this question to my teacher at school, he, too could not draw the tree diagram. However, he got the answer as $\frac {25}{72}$, but the answer given in my book is $\frac {1}{8}$. Please, help me to solve this.",,['probability']
71,"sixteen players $s_1, s_2, s_3, \ldots, s_{16}$ playing a tournament are divided into eight pairs at random",sixteen players  playing a tournament are divided into eight pairs at random,"s_1, s_2, s_3, \ldots, s_{16}","Sixteen players $s_1, s_2, s_3, \ldots, s_{16}$ playing a tournament are divided into eight pairs at random.  From each pair, a winner is decided on the basis of a game played between the two players of the pair.  Assume all players are of equal strength. Find the probability that $s_1$ is among the eight winners. Find the probability that exactly one of the players $s_1$ and $s_2$ are present in the $8$ winners.","Sixteen players $s_1, s_2, s_3, \ldots, s_{16}$ playing a tournament are divided into eight pairs at random.  From each pair, a winner is decided on the basis of a game played between the two players of the pair.  Assume all players are of equal strength. Find the probability that $s_1$ is among the eight winners. Find the probability that exactly one of the players $s_1$ and $s_2$ are present in the $8$ winners.",,"['probability', 'permutations', 'combinations']"
72,How many times should I roll a die to get 4 different results?,How many times should I roll a die to get 4 different results?,,"What is the expected value of the number $X$ of rolling a die until we obtain 4 different results (for example, $X=6$ in case of the event $(1,4,4,1,5,2)$)? I'm not only interested in technical details of a solution---I can solve it to some extent, see below---but even more in the following: Is it a known problem, does it have a name? Does there exist a closed-form expression? (See below for a series expansion) Does there exist a feasible algorithm/formula to compute it if the die is not ""fair"" and each face has possibly a different probability? My attempt: $EX=\sum_{j=4}^\infty j\, P(X=j)$. Clearly, $P(X=j)$ is $1/6^j$ multiplied by the number of ways to obtain $X=j$. The number of ways is $6\choose 3$ (the choice of 3 elements that occur within the first $j-1$ rolls) multiplied by $3$ (the last roll) multiplied by the number of surjective functions from $j-1$ to 3 (the number of ways what can happen in the first $j-1$ rolls, if the three outputs are given). Further, the number of surjective functions can be expressed via Stirling numbers of the second kind : so in this way, I can get a series expression, although not a very nice one.","What is the expected value of the number $X$ of rolling a die until we obtain 4 different results (for example, $X=6$ in case of the event $(1,4,4,1,5,2)$)? I'm not only interested in technical details of a solution---I can solve it to some extent, see below---but even more in the following: Is it a known problem, does it have a name? Does there exist a closed-form expression? (See below for a series expansion) Does there exist a feasible algorithm/formula to compute it if the die is not ""fair"" and each face has possibly a different probability? My attempt: $EX=\sum_{j=4}^\infty j\, P(X=j)$. Clearly, $P(X=j)$ is $1/6^j$ multiplied by the number of ways to obtain $X=j$. The number of ways is $6\choose 3$ (the choice of 3 elements that occur within the first $j-1$ rolls) multiplied by $3$ (the last roll) multiplied by the number of surjective functions from $j-1$ to 3 (the number of ways what can happen in the first $j-1$ rolls, if the three outputs are given). Further, the number of surjective functions can be expressed via Stirling numbers of the second kind : so in this way, I can get a series expression, although not a very nice one.",,"['probability', 'combinatorics', 'reference-request']"
73,5-Card Poker Two-Pair Probability Calculation,5-Card Poker Two-Pair Probability Calculation,,Question: What is the probability that 5 cards dealt from a deck of 52 (without replacement) contain exactly two distinct pairs (meaning no full house)? Solution: $$\frac{\binom{13}{2}\binom{4}{2}\binom{4}{2}\binom{11}{1}\binom{4}{1}}{\binom{52}{5}} = 0.047539$$ Why doesn't ${13\choose 1}{4\choose 2}{12\choose 1}{4\choose 2}{11\choose 1}{4\choose 1}\over{52\choose 5}$ OR ${13\choose 3}{4\choose 2}{4\choose 2}{4\choose 1}\over{52\choose 5}$ work?,Question: What is the probability that 5 cards dealt from a deck of 52 (without replacement) contain exactly two distinct pairs (meaning no full house)? Solution: $$\frac{\binom{13}{2}\binom{4}{2}\binom{4}{2}\binom{11}{1}\binom{4}{1}}{\binom{52}{5}} = 0.047539$$ Why doesn't ${13\choose 1}{4\choose 2}{12\choose 1}{4\choose 2}{11\choose 1}{4\choose 1}\over{52\choose 5}$ OR ${13\choose 3}{4\choose 2}{4\choose 2}{4\choose 1}\over{52\choose 5}$ work?,,"['probability', 'discrete-mathematics', 'poker']"
74,"How can one handle very large numbers such as ${1,000,000 \choose 500,000}$ using binomial formula and very tiny numbers such as $0.5^{1,000,000}$?",How can one handle very large numbers such as  using binomial formula and very tiny numbers such as ?,"{1,000,000 \choose 500,000} 0.5^{1,000,000}","For a problem such as what is the probability of getting exactly $500,000$ heads out of $1,000,000$ (1 million) fair coin flips, we get one huge valued number and one tiny valued number as intermediate results, both of which are not able to be computed with many online tools such as combination calculators and other online calculators. I think the correct answer to this is ${1,000,000 \choose 500,000}$ * $0.5^{1,000,000}$. So my question is, if someone wanted to know this approximate probability in decimal form, how would they compute it?  Is there any ""shortcut""?  For example, we know that ${1,000,000 \choose 500,000}$ is $1,000,000 * 999,999 * ... 500,001$ / $500,000$! so we know we can keep the intermediate or accumulated result from becoming super large or super small and thus ""blowing up"".  We also know that there are $500,000$ terms that make up the numerator and ditto for the denominator, however there are $1,000,000$ powers of $0.5$ we need to multiply by so we can further ""simplify"" (or manipulate) that to be $500,000$ powers of $0.5^2$ which is $0.25 ^ {500,000}$.  So to me it would make sense for a combination calculator to know these ""tricks"" and use them to it's advantage so the result can actually be computed.  I see so many online combination calculators that cannot compute this expression.  Instead it tells me $infinity$ or Nan (not a number).  What it really means is their utility just blew a chunk and they are putting the ""blame"" on me that I did something wrong. So for example, if I made a combination calculator for this problem, The first subterm, (out of $500,000$ of them), I would get would be ($1,000,000$ / $500,000$) * $0.25$ = $0.5$.  The 2nd subterm would be $999,999$ / $499,999$ * $0.25$ = $0.500000500001000002000004000008$ and so on. The last ($500,000$th) subterm would be $500,001$ / $1$ * $0.25$ = $125,000.25$. At that point I would have the final answer since I'd be accumulating the intermediate results. I also get a similar problem when trying to compute $0.5 ^ {1,000,000}$ so it seems like someone needs to write a better combination calculator to handle problems like this.","For a problem such as what is the probability of getting exactly $500,000$ heads out of $1,000,000$ (1 million) fair coin flips, we get one huge valued number and one tiny valued number as intermediate results, both of which are not able to be computed with many online tools such as combination calculators and other online calculators. I think the correct answer to this is ${1,000,000 \choose 500,000}$ * $0.5^{1,000,000}$. So my question is, if someone wanted to know this approximate probability in decimal form, how would they compute it?  Is there any ""shortcut""?  For example, we know that ${1,000,000 \choose 500,000}$ is $1,000,000 * 999,999 * ... 500,001$ / $500,000$! so we know we can keep the intermediate or accumulated result from becoming super large or super small and thus ""blowing up"".  We also know that there are $500,000$ terms that make up the numerator and ditto for the denominator, however there are $1,000,000$ powers of $0.5$ we need to multiply by so we can further ""simplify"" (or manipulate) that to be $500,000$ powers of $0.5^2$ which is $0.25 ^ {500,000}$.  So to me it would make sense for a combination calculator to know these ""tricks"" and use them to it's advantage so the result can actually be computed.  I see so many online combination calculators that cannot compute this expression.  Instead it tells me $infinity$ or Nan (not a number).  What it really means is their utility just blew a chunk and they are putting the ""blame"" on me that I did something wrong. So for example, if I made a combination calculator for this problem, The first subterm, (out of $500,000$ of them), I would get would be ($1,000,000$ / $500,000$) * $0.25$ = $0.5$.  The 2nd subterm would be $999,999$ / $499,999$ * $0.25$ = $0.500000500001000002000004000008$ and so on. The last ($500,000$th) subterm would be $500,001$ / $1$ * $0.25$ = $125,000.25$. At that point I would have the final answer since I'd be accumulating the intermediate results. I also get a similar problem when trying to compute $0.5 ^ {1,000,000}$ so it seems like someone needs to write a better combination calculator to handle problems like this.",,"['probability', 'probability-theory']"
75,How many arrangements of the word marmalade can be made with the vowels in the original order,How many arrangements of the word marmalade can be made with the vowels in the original order,,How many arrangements of the word MARMALADE can be made with the vowels in the original order? What is the procedure for doing this problem? Is there more than one way of approaching it?,How many arrangements of the word MARMALADE can be made with the vowels in the original order? What is the procedure for doing this problem? Is there more than one way of approaching it?,,"['probability', 'combinatorics']"
76,Why is this the answer?,Why is this the answer?,,"A fair coin is tossed $n$ times by Adam and $n$ times by Andrew. What is the probability that they get the same number of heads? Now since there are a total of $2n$ flips, $n$ from each person, we would need to choose $k$ flips that they both have heads correct? So since this is a binomial$\sim (2n,\frac12)$ I came to find that we have $${2n \choose k }\left(\frac12\right)^{2n}$$ However my textbook says it differently. I'm wondering why the book says it is:  $${2n \choose n }\left(\frac12\right)^{2n}$$ Is it the same thing? I'm just confused as to why it would say choose $n$. Should I be assuming assume that half of the total flips are are going to be the same?","A fair coin is tossed $n$ times by Adam and $n$ times by Andrew. What is the probability that they get the same number of heads? Now since there are a total of $2n$ flips, $n$ from each person, we would need to choose $k$ flips that they both have heads correct? So since this is a binomial$\sim (2n,\frac12)$ I came to find that we have $${2n \choose k }\left(\frac12\right)^{2n}$$ However my textbook says it differently. I'm wondering why the book says it is:  $${2n \choose n }\left(\frac12\right)^{2n}$$ Is it the same thing? I'm just confused as to why it would say choose $n$. Should I be assuming assume that half of the total flips are are going to be the same?",,"['probability', 'probability-theory']"
77,Masters in Actuarial Science,Masters in Actuarial Science,,"I am applying to a grad school for the Masters in Actuarial Science. Now i am getting cold feet. I do love math, i was always good in math  (not excellent or a genius). Did all adv. calculus classes in College, financial, economics. I have degrees in Computer programming (AAS) and Information System Management (BS) in 2002. Worked in the financial world for a quite a while.  I was always interested in getting a degree in that field, even if  i don't become an actuary. My problem: I think i forgot everything about maths, it has been over 10 yrs.I don't even think i might get admitted in the first place with this background. do you really have to be super excellent in maths or statistic to even think about embarking in that journey?","I am applying to a grad school for the Masters in Actuarial Science. Now i am getting cold feet. I do love math, i was always good in math  (not excellent or a genius). Did all adv. calculus classes in College, financial, economics. I have degrees in Computer programming (AAS) and Information System Management (BS) in 2002. Worked in the financial world for a quite a while.  I was always interested in getting a degree in that field, even if  i don't become an actuary. My problem: I think i forgot everything about maths, it has been over 10 yrs.I don't even think i might get admitted in the first place with this background. do you really have to be super excellent in maths or statistic to even think about embarking in that journey?",,"['probability', 'statistics', 'education', 'actuarial-science']"
78,Probability of a Union,Probability of a Union,,"I know that $$P\left(\bigcup_{i=1}^{n} A_i \right)$$ is the sum of of the probabilities of all the sample points that are contained in at least one of the $A_{i}$'s. This is the probability of sample points belonging to exactly 1 event, exactly 2 events, ...,exactly $n$ events. WLOG this can be written as $$P\left(\bigcup_{i=1}^{n} A_i \right) = P(A_1) + P(A_1 \cap A_2) + \cdots + P(A_1 \cap A_2 \cap \cdots \cap A_n)$$ But the $A_i$'s are arbitrary and we have to account for that. So there are $n$ possibilities for the first probability, $\binom{n}{2}$ possibilities for the second probability, ..., and $1$ possibility for the final probability. So we add and subtract these to prevent overcounting?","I know that $$P\left(\bigcup_{i=1}^{n} A_i \right)$$ is the sum of of the probabilities of all the sample points that are contained in at least one of the $A_{i}$'s. This is the probability of sample points belonging to exactly 1 event, exactly 2 events, ...,exactly $n$ events. WLOG this can be written as $$P\left(\bigcup_{i=1}^{n} A_i \right) = P(A_1) + P(A_1 \cap A_2) + \cdots + P(A_1 \cap A_2 \cap \cdots \cap A_n)$$ But the $A_i$'s are arbitrary and we have to account for that. So there are $n$ possibilities for the first probability, $\binom{n}{2}$ possibilities for the second probability, ..., and $1$ possibility for the final probability. So we add and subtract these to prevent overcounting?",,['probability']
79,"Expressing ""Probability that #successes is an even number"" mathematically","Expressing ""Probability that #successes is an even number"" mathematically",,"Needing a little help with my probability concept. Here's the question: An urn contains $10$ red balls, $20$ green balls and $30$ blue balls. Each trial consists of drawing a ball from the urn with replacement. If either red or blue ball is drawn, the trial is called a success . Suppose that $n$ independent trials are performed and let $P_n$ be the probability that the total number of successes that result is an even number. Find $P_n$ and $\lim \limits_{n \to \infty} P_n$. My Solution: $$ P (\text{success}) = \frac{\binom{40}{1}}{\binom{60}{1}} = \frac {2}{3} .$$ Then it is a binomial r.v with parameters $(n, \frac 2 3)$. How do I express the idea ""total number of successes that result is an even number"" mathematically? Thanks for looking at my question.","Needing a little help with my probability concept. Here's the question: An urn contains $10$ red balls, $20$ green balls and $30$ blue balls. Each trial consists of drawing a ball from the urn with replacement. If either red or blue ball is drawn, the trial is called a success . Suppose that $n$ independent trials are performed and let $P_n$ be the probability that the total number of successes that result is an even number. Find $P_n$ and $\lim \limits_{n \to \infty} P_n$. My Solution: $$ P (\text{success}) = \frac{\binom{40}{1}}{\binom{60}{1}} = \frac {2}{3} .$$ Then it is a binomial r.v with parameters $(n, \frac 2 3)$. How do I express the idea ""total number of successes that result is an even number"" mathematically? Thanks for looking at my question.",,"['probability', 'statistics']"
80,Quick ways for approximating $\sum_{k=a_1}^{k=a_2}C_{100}^k(\frac{1}{2})^k(\frac{1}{2})^{100-k}$?,Quick ways for approximating ?,\sum_{k=a_1}^{k=a_2}C_{100}^k(\frac{1}{2})^k(\frac{1}{2})^{100-k},"Consider the following problem: A fair coin is to be tossed 100 times, with each toss resulting in a head or a tail. Let   $$H:=\textrm{the total number of heads}$$   and    $$T:=\textrm{the total number of tails},$$   which of the following events has the greatest probability? A. $H=50$ B. $T\geq 60$ C. $51\leq H\leq 55$ D. $H\geq 48$ and $T\geq 48$ E. $H\leq 5$ or $H\geq 95$ What I can think is the direct calculation: $$P(a_1\leq H\leq a_2)=\sum_{k=a_1}^{k=a_2}C_{100}^k(\frac{1}{2})^k(\frac{1}{2})^{100-k}$$ Here is my question: Is there any quick way to solve this problem except the direct calculation?","Consider the following problem: A fair coin is to be tossed 100 times, with each toss resulting in a head or a tail. Let   $$H:=\textrm{the total number of heads}$$   and    $$T:=\textrm{the total number of tails},$$   which of the following events has the greatest probability? A. $H=50$ B. $T\geq 60$ C. $51\leq H\leq 55$ D. $H\geq 48$ and $T\geq 48$ E. $H\leq 5$ or $H\geq 95$ What I can think is the direct calculation: $$P(a_1\leq H\leq a_2)=\sum_{k=a_1}^{k=a_2}C_{100}^k(\frac{1}{2})^k(\frac{1}{2})^{100-k}$$ Here is my question: Is there any quick way to solve this problem except the direct calculation?",,[]
81,Optimizing the expectancy,Optimizing the expectancy,,"The following problem is about optimization. It is not a homework, but rather a natural question to ask to oneself afterwards. Here it is. Consider a road of length $L$ between two cities $A$ and $B$. Whenever a car runs out of fuel on this road, the distance between the car and the city $A$ is uniformely distributed on the interval $[0,L]$. There are three gas stations on the road. Now the question of the exercise is to compare two different distributions of the set of gas stations along the road. The first distribution is to put a station in A, another at distance $L/2$ from $A$ and the third in $B$. The second distribution is to put the stations at distance $L/4$, $L/2$ and $3L/4$. Clearly the second distribution is better. However, the reference (from which I took the exercise) admits that the second distribution is not optimal! Question : Given $n$ gas stations, where to place them on the road is such a way that the expectancy of the distance from one station to the place of breakdown is minimal?","The following problem is about optimization. It is not a homework, but rather a natural question to ask to oneself afterwards. Here it is. Consider a road of length $L$ between two cities $A$ and $B$. Whenever a car runs out of fuel on this road, the distance between the car and the city $A$ is uniformely distributed on the interval $[0,L]$. There are three gas stations on the road. Now the question of the exercise is to compare two different distributions of the set of gas stations along the road. The first distribution is to put a station in A, another at distance $L/2$ from $A$ and the third in $B$. The second distribution is to put the stations at distance $L/4$, $L/2$ and $3L/4$. Clearly the second distribution is better. However, the reference (from which I took the exercise) admits that the second distribution is not optimal! Question : Given $n$ gas stations, where to place them on the road is such a way that the expectancy of the distance from one station to the place of breakdown is minimal?",,"['optimization', 'probability']"
82,Does probability of $1$% means that it is guaranteed to get a success event if I do $100$ tries?,Does probability of % means that it is guaranteed to get a success event if I do  tries?,1 100,"Let us suppose I have $100$ balls in a container, each one has a different number ( from $1$ to $100$ ). I want to pick a ball, and we'll suppose this is a random process ( i.e. choosing the ball is random). Question $1$ Given that the whole universe of balls ( a.k.a the set Ω ) is made up of only those $100$ balls in the container, I can say that probability of picking up the ball i is 1% ( i is any number from $1$ to $100$ )? Question $2$ If the answer to question $1$ is ""yes"", and if I repeat the picking of a ball $100$ times (each time I put it back in the container, and I will suppose that the next pickup is unrelated to the previous one, hence randomness), Is it guaranteed that the ball i will appear at least one time during the $100$ pickups? Note: I am not a total beginner in maths, but I am confused about something: does a n% chance means that it is guaranteed to get n successes out of $100$ tries, or it is not guaranteed unless I repeat the tries till infinity?","Let us suppose I have balls in a container, each one has a different number ( from to ). I want to pick a ball, and we'll suppose this is a random process ( i.e. choosing the ball is random). Question Given that the whole universe of balls ( a.k.a the set Ω ) is made up of only those balls in the container, I can say that probability of picking up the ball i is 1% ( i is any number from to )? Question If the answer to question is ""yes"", and if I repeat the picking of a ball times (each time I put it back in the container, and I will suppose that the next pickup is unrelated to the previous one, hence randomness), Is it guaranteed that the ball i will appear at least one time during the pickups? Note: I am not a total beginner in maths, but I am confused about something: does a n% chance means that it is guaranteed to get n successes out of tries, or it is not guaranteed unless I repeat the tries till infinity?",100 1 100 1 100 1 100 2 1 100 100 100,"['probability', 'probability-theory']"
83,Probability concepts - how can balls of same colour be distinguishable?,Probability concepts - how can balls of same colour be distinguishable?,,"An urn contains $6$ white and $4$ black balls. A fair die is rolled   and that number of balls are chosen from the urn. Find the probability   that the balls selected are white. I know the basic way to go about solving the problem. Let $W$ be the event of finally drawing all white balls. Let $P(n)$ denote the probability of appearance of $n$ on the die. We want: $$P(W) = P(1)P(W\mid 1)+ P(2)P(W\mid 2)+\dots \implies P(W) = \dfrac{1}{6}\left(\sum_{i=1}^6P(W\mid i)\right)$$ Now, I am actually facing trouble in computing $P(W/i)$ . I saw author's method and in it he has used $P(W\mid i) = \dfrac{^6C_i}{^{10}C_i}$ but I fail to understand how that can be true when all white balls are identical and all black balls are identical. Here, $^6C_i$ denotes the combination of $i$ different things from 6 different objects , doesn't it? How can that be used here?","An urn contains white and black balls. A fair die is rolled   and that number of balls are chosen from the urn. Find the probability   that the balls selected are white. I know the basic way to go about solving the problem. Let be the event of finally drawing all white balls. Let denote the probability of appearance of on the die. We want: Now, I am actually facing trouble in computing . I saw author's method and in it he has used but I fail to understand how that can be true when all white balls are identical and all black balls are identical. Here, denotes the combination of different things from 6 different objects , doesn't it? How can that be used here?",6 4 W P(n) n P(W) = P(1)P(W\mid 1)+ P(2)P(W\mid 2)+\dots \implies P(W) = \dfrac{1}{6}\left(\sum_{i=1}^6P(W\mid i)\right) P(W/i) P(W\mid i) = \dfrac{^6C_i}{^{10}C_i} ^6C_i i,"['probability', 'combinatorics']"
84,Expected number of games in the Baseball World Series,Expected number of games in the Baseball World Series,,"Consider the following problem, from Understanding Probability by Henk Tijms. In the World Series Baseball, the final two teams play a series   consisting of a possible seven games until such time that one of the   two teams has won four games. In one such final, two unevenly matched   teams are pitted against each other and the probability that the   weaker team will win any given game is equal to $p=0.45$. Assuming that   the results of the various games are independent from each other,   calculate the probability of the weaker team winning the final. What   are the expected value and the standard deviation of the number of   games the final will take? The probability of the weaker team winning is: $$ \sum_{k=0}^3 \binom{7}{k} (1-p)^kp^{7-k}\simeq 0.3917. $$ For the expected value of the number of games, I consider the following table, where I list the number of possible wins for each of the two teams: $$ \begin{array}{cc} \text{strong team} & 4 & 4 & 4 & 4 & 0 & 1 & 2 & 3 \\ \text{weak team} & 0 & 1 & 2 & 3 & 4 & 4 & 4 & 4 \\ \end{array} $$ which leads me to the expression: $$ \sum_{k=0}^3 (4+k)\binom{4+k}{k}p^k(1-p)^4 + \sum_{k=0}^3 (4+k)\binom{4+k}{k}p^4(1-p)^k \simeq 8.622 $$ the result, however, is wrong. The only thing that I can think of is that I am counting in a wrong way the number of games with a given number of wins for the two teams. I have found the solution of this problem here , but why is my approach wrong?","Consider the following problem, from Understanding Probability by Henk Tijms. In the World Series Baseball, the final two teams play a series   consisting of a possible seven games until such time that one of the   two teams has won four games. In one such final, two unevenly matched   teams are pitted against each other and the probability that the   weaker team will win any given game is equal to $p=0.45$. Assuming that   the results of the various games are independent from each other,   calculate the probability of the weaker team winning the final. What   are the expected value and the standard deviation of the number of   games the final will take? The probability of the weaker team winning is: $$ \sum_{k=0}^3 \binom{7}{k} (1-p)^kp^{7-k}\simeq 0.3917. $$ For the expected value of the number of games, I consider the following table, where I list the number of possible wins for each of the two teams: $$ \begin{array}{cc} \text{strong team} & 4 & 4 & 4 & 4 & 0 & 1 & 2 & 3 \\ \text{weak team} & 0 & 1 & 2 & 3 & 4 & 4 & 4 & 4 \\ \end{array} $$ which leads me to the expression: $$ \sum_{k=0}^3 (4+k)\binom{4+k}{k}p^k(1-p)^4 + \sum_{k=0}^3 (4+k)\binom{4+k}{k}p^4(1-p)^k \simeq 8.622 $$ the result, however, is wrong. The only thing that I can think of is that I am counting in a wrong way the number of games with a given number of wins for the two teams. I have found the solution of this problem here , but why is my approach wrong?",,"['probability', 'random-variables']"
85,Alternating dice roll game,Alternating dice roll game,,"Imagine we played a game using a dice. I start, then you get a turn, then me again and so on. The first person to get a 6 wins. What is my probability of winning if I start? Now consider we did the same but with a coin. Without calculation, would this probability increase or decrease? Here's what I was thinking: On average, you get 6 every $6$ rolls. So on average, the $6$th person to roll will win. So you going first doesn't change the probability (three rolls each), which must therefore be $\frac 12$. Using this logic for a two-sided die, we'd get the same probability: $\frac 12$. These results are extremely unintuitive to me and and almost certainly incorrect. I'd like to know (1) the flaw in the reasoning, and (2) how to get the correct solution.","Imagine we played a game using a dice. I start, then you get a turn, then me again and so on. The first person to get a 6 wins. What is my probability of winning if I start? Now consider we did the same but with a coin. Without calculation, would this probability increase or decrease? Here's what I was thinking: On average, you get 6 every $6$ rolls. So on average, the $6$th person to roll will win. So you going first doesn't change the probability (three rolls each), which must therefore be $\frac 12$. Using this logic for a two-sided die, we'd get the same probability: $\frac 12$. These results are extremely unintuitive to me and and almost certainly incorrect. I'd like to know (1) the flaw in the reasoning, and (2) how to get the correct solution.",,"['probability', 'problem-solving', 'dice']"
86,Why is $\mathbb{E}[X] = 1 + \sum^\infty_{k=1}\mathbb{P}(X > k)$ true?,Why is  true?,\mathbb{E}[X] = 1 + \sum^\infty_{k=1}\mathbb{P}(X > k),"I'm working through a problem regarding expected values in Markov chains, and at some point it says: Recall from probability that if $X$ is a positive integer valued random variable, then $\mathbb{E}[X] = 1 + \sum^\infty_{k=1}\mathbb{P}(X > k)$. I know that by definition $\mathbb{E}[X] = \sum_a a\mathbb{P}(X = a)$, but I can't see how the above equality follows from this, nor am I sure if this is how to approach the problem.","I'm working through a problem regarding expected values in Markov chains, and at some point it says: Recall from probability that if $X$ is a positive integer valued random variable, then $\mathbb{E}[X] = 1 + \sum^\infty_{k=1}\mathbb{P}(X > k)$. I know that by definition $\mathbb{E}[X] = \sum_a a\mathbb{P}(X = a)$, but I can't see how the above equality follows from this, nor am I sure if this is how to approach the problem.",,"['probability', 'random-variables', 'expectation']"
87,$7$ people in a line,people in a line,7,"$7$ people including $A$ and $B$ are to be lined. What is the probability if there will be $1$ person between $A$ and $B$? The answer is written as $$\frac{5!\cdot3!}{7!}$$ but I am not sure whether it is true. There is also a similar question here , but there is no clear explanation for that question too.","$7$ people including $A$ and $B$ are to be lined. What is the probability if there will be $1$ person between $A$ and $B$? The answer is written as $$\frac{5!\cdot3!}{7!}$$ but I am not sure whether it is true. There is also a similar question here , but there is no clear explanation for that question too.",,"['probability', 'combinatorics']"
88,What is the probability that a Poisson random variable is prime?,What is the probability that a Poisson random variable is prime?,,"Let $X \sim Poisson(\lambda)$, and let $k \in \mathbb{N}$. Consider the quantity $Q(\lambda,k) = P\left( X+k \in Primes\right)$. Obviously $0 < Q(\lambda,k) < 1$. How does $Q(\lambda,k)$ behave with respect to $\lambda$ and $k$? For example, is there any asymptotic behavior as $\lambda \rightarrow \infty$? Is $Q(\lambda,k)$ sensitive to the value of $k$ when $\lambda$ is large enough?","Let $X \sim Poisson(\lambda)$, and let $k \in \mathbb{N}$. Consider the quantity $Q(\lambda,k) = P\left( X+k \in Primes\right)$. Obviously $0 < Q(\lambda,k) < 1$. How does $Q(\lambda,k)$ behave with respect to $\lambda$ and $k$? For example, is there any asymptotic behavior as $\lambda \rightarrow \infty$? Is $Q(\lambda,k)$ sensitive to the value of $k$ when $\lambda$ is large enough?",,"['probability', 'probability-distributions', 'prime-numbers']"
89,probability: when to multiply when to add?,probability: when to multiply when to add?,,"The ""classic"" high school probability exercises most of the time ends up in a tree of possibilities that deals with all the scenarios (combinations?) that are possible for a given scenario: be it coin tosses, balls in a jar, anagrams, etc. But there is something that I always have a had time deciding: when to add and when to multiply quantities under a certain scenario? I see that for each branch of the tree, I can just multiply, but when does addition enters the picture?","The ""classic"" high school probability exercises most of the time ends up in a tree of possibilities that deals with all the scenarios (combinations?) that are possible for a given scenario: be it coin tosses, balls in a jar, anagrams, etc. But there is something that I always have a had time deciding: when to add and when to multiply quantities under a certain scenario? I see that for each branch of the tree, I can just multiply, but when does addition enters the picture?",,['probability']
90,Probability of 5 cards drawn from shuffled deck,Probability of 5 cards drawn from shuffled deck,,Five cards are drawn from a shuffled deck with $52$ cards. Find the probability that a) four cards are aces b) four cards are aces and the other is a king c) three cards are tens and two are jacks d) at least one card is an ace My attempt: a) $\left(13*12*\binom{4}{4}*\binom{4}{1}\right)/\binom{52}{5}$ b) same as (a)? c) $\left(13 * 12 * \binom{4}{3} * \binom{4}{2}\right)/\binom{52}{5}$ d) $\left(13 * \binom{4}{1}\right)/\binom{52}{5}$,Five cards are drawn from a shuffled deck with cards. Find the probability that a) four cards are aces b) four cards are aces and the other is a king c) three cards are tens and two are jacks d) at least one card is an ace My attempt: a) b) same as (a)? c) d),52 \left(13*12*\binom{4}{4}*\binom{4}{1}\right)/\binom{52}{5} \left(13 * 12 * \binom{4}{3} * \binom{4}{2}\right)/\binom{52}{5} \left(13 * \binom{4}{1}\right)/\binom{52}{5},"['probability', 'combinatorics', 'binomial-coefficients', 'card-games']"
91,What is the probability that the first card is an ace given that the 15th card is an ace,What is the probability that the first card is an ace given that the 15th card is an ace,,"Cards are drawn one at a time, without replacement, from a deck of 52   playing cards. What is the probability that the first card drawn is an   ace, given that the 15th card is an ace? I have trouble calculating the probability of seeing aces on the first and the 15th draws and the probability of seeing $i$ aces in the first 14th draws, $i=0,1,2,3$. Any hint is much appreciated, thanks a lot!","Cards are drawn one at a time, without replacement, from a deck of 52   playing cards. What is the probability that the first card drawn is an   ace, given that the 15th card is an ace? I have trouble calculating the probability of seeing aces on the first and the 15th draws and the probability of seeing $i$ aces in the first 14th draws, $i=0,1,2,3$. Any hint is much appreciated, thanks a lot!",,"['probability', 'discrete-mathematics', 'combinations', 'card-games']"
92,If $P(A)=0$ then $A=\emptyset $?,If  then ?,P(A)=0 A=\emptyset ,Let $P$ be a probability function. It satisfied probability axioms . Can we deduce from it that if $P(A)=0$ then $A=\emptyset $ ?,Let $P$ be a probability function. It satisfied probability axioms . Can we deduce from it that if $P(A)=0$ then $A=\emptyset $ ?,,"['probability', 'probability-theory']"
93,Inequality involving expectation,Inequality involving expectation,,"$X,Y$ are two RV taking values in $[1,+\infty)$. Do we have following inequality? $$ E\left[\frac{Y}{X}\right]\geq\frac{E[Y]}{E[X]} $$","$X,Y$ are two RV taking values in $[1,+\infty)$. Do we have following inequality? $$ E\left[\frac{Y}{X}\right]\geq\frac{E[Y]}{E[X]} $$",,"['probability', 'probability-theory']"
94,"$x,y,z$ independent and uniform random on $[0,1]$, $P(x \geq  yz)$?","independent and uniform random on , ?","x,y,z [0,1] P(x \geq  yz)","$x,y,z$ are independent and uniform random on $[0,1]$. I know that $P(x \geq yz) = 3/4$ by triple integrating the triple density function. However, is there a easier way to get this solution? Without triple integration.","$x,y,z$ are independent and uniform random on $[0,1]$. I know that $P(x \geq yz) = 3/4$ by triple integrating the triple density function. However, is there a easier way to get this solution? Without triple integration.",,['probability']
95,Interpretation of a probability problem: expected value.,Interpretation of a probability problem: expected value.,,"I am having a few doubt on the interpretation of this problem that I have read on book about interviews questions. Here the text: A mythical city contains N=100,000 married couples but no children. Each family wishes to continue the male lane but they do not wish to overpopulate. So, each family has one baby per annum until the arrival of the first boy. Assume that all the children are equally like to be born male and female (and independent). Let $p(n)$ be the percentage of children that are male at the end of the year n. How is this percentage expected to evolve through time? This is the problem and the solution says that the percentage is expected to remain constant at a level $\frac{1}{2}$. Thanks in advance; if something is not clear, just ask.","I am having a few doubt on the interpretation of this problem that I have read on book about interviews questions. Here the text: A mythical city contains N=100,000 married couples but no children. Each family wishes to continue the male lane but they do not wish to overpopulate. So, each family has one baby per annum until the arrival of the first boy. Assume that all the children are equally like to be born male and female (and independent). Let $p(n)$ be the percentage of children that are male at the end of the year n. How is this percentage expected to evolve through time? This is the problem and the solution says that the percentage is expected to remain constant at a level $\frac{1}{2}$. Thanks in advance; if something is not clear, just ask.",,['probability']
96,Getting a negative variance for the sum of dice rolling,Getting a negative variance for the sum of dice rolling,,"I'm trying to find what I did wrong. If $X$ signifies the sum of what you get from rolling a regular die (1-6), 100 times and $X_i$ for a single roll. Then: $$E\left[X\right]=\sum_{i=1}^{100}\frac{7}{2}=100\frac{7}{2}=350$$ and: $$E\left[X^{2}\right]=E\left[\sum_{i=1}^{100}X_{i}^{2}\right]=\sum_{i=1}^{100}E\left[X_{i}^{2}\right]=100\cdot\frac{91}{6}=\frac{4550}{3}$$ Then the variance is negative: $$Var\left(X\right)=E\left[X^{2}\right]-E\left[X\right]^{2}=\frac{-362950}{3}$$ In this way, however, I recieve a positive number: $$100Var\left(X_{i}\right)=100\left(E\left[X_{i}^{2}\right]-E\left[X_{i}\right]^{2}\right)=100\left(\frac{91}{6}-\left(\frac{7}{2}\right)^{2}\right)$$ I suppose the latter is correct, but why is the first way false?","I'm trying to find what I did wrong. If signifies the sum of what you get from rolling a regular die (1-6), 100 times and for a single roll. Then: and: Then the variance is negative: In this way, however, I recieve a positive number: I suppose the latter is correct, but why is the first way false?",X X_i E\left[X\right]=\sum_{i=1}^{100}\frac{7}{2}=100\frac{7}{2}=350 E\left[X^{2}\right]=E\left[\sum_{i=1}^{100}X_{i}^{2}\right]=\sum_{i=1}^{100}E\left[X_{i}^{2}\right]=100\cdot\frac{91}{6}=\frac{4550}{3} Var\left(X\right)=E\left[X^{2}\right]-E\left[X\right]^{2}=\frac{-362950}{3} 100Var\left(X_{i}\right)=100\left(E\left[X_{i}^{2}\right]-E\left[X_{i}\right]^{2}\right)=100\left(\frac{91}{6}-\left(\frac{7}{2}\right)^{2}\right),"['probability', 'variance', 'dice']"
97,Probability of lines in a pentagon intersecting internally or at vertices.,Probability of lines in a pentagon intersecting internally or at vertices.,,"I'm studying maths as a hobby. The points A,B,C,D & E are the vertices of a regular pentagon. All possible lines joining the pairs of these points are drawn. If two of these lines are chosen at random, what is the probability that their point of intersection is (a) inside the pentagon, (b) one of the points A,B,C,D,E? I start out by saying the number of ways of choosing 2 lines from 10 is $\binom{10}{2} = 45$ Then I started getting confused. I can see there are 5 internal points of intersection, which I mark in red, so that would give me $\frac{5}{45} = \frac{1}{9}$ probability of choosing lines which meet internally. And this is indeed the answer my text book gives. But I'm not sure if this is just coincidence. As for (b), I'm not sure how to proceed. The book gives the answer as $\frac{2}{3}$","I'm studying maths as a hobby. The points A,B,C,D & E are the vertices of a regular pentagon. All possible lines joining the pairs of these points are drawn. If two of these lines are chosen at random, what is the probability that their point of intersection is (a) inside the pentagon, (b) one of the points A,B,C,D,E? I start out by saying the number of ways of choosing 2 lines from 10 is Then I started getting confused. I can see there are 5 internal points of intersection, which I mark in red, so that would give me probability of choosing lines which meet internally. And this is indeed the answer my text book gives. But I'm not sure if this is just coincidence. As for (b), I'm not sure how to proceed. The book gives the answer as",\binom{10}{2} = 45 \frac{5}{45} = \frac{1}{9} \frac{2}{3},"['probability', 'combinatorics']"
98,Probability of exactly $2$ sixes in $3$ dice rolls where $2$ dice have $6$ on $2$ faces?,Probability of exactly  sixes in  dice rolls where  dice have  on  faces?,2 3 2 6 2,Three dice are rolled. One is fair and the other two have 6 on two faces. Find the probability of rolling exactly 2 sixes. My textbook gives an answer of $\frac{20}{147}$ but I get an answer of: $$\frac{1}{6}\frac{2}{6}\frac{4}{6}+\frac{1}{6}\frac{4}{6}\frac{2}{6}+\frac{5}{6}\frac{2}{6}\frac{2}{6}=\frac{8}{216}+\frac{8}{216}+\frac{20}{216}=\frac{36}{216}=\frac{1}{6}$$ I just want to know where I am going wrong or could the textbook be mistaken ?,Three dice are rolled. One is fair and the other two have 6 on two faces. Find the probability of rolling exactly 2 sixes. My textbook gives an answer of but I get an answer of: I just want to know where I am going wrong or could the textbook be mistaken ?,\frac{20}{147} \frac{1}{6}\frac{2}{6}\frac{4}{6}+\frac{1}{6}\frac{4}{6}\frac{2}{6}+\frac{5}{6}\frac{2}{6}\frac{2}{6}=\frac{8}{216}+\frac{8}{216}+\frac{20}{216}=\frac{36}{216}=\frac{1}{6},"['probability', 'dice']"
99,Clarification of algebra in moment generating functions,Clarification of algebra in moment generating functions,,"Suppose $X$ has a range $\{1,2,\dots n \}$ and $p_X(j)=1/n$ for $1\leq j \leq n$ (uniform distribution). Then \begin{align*}  g(t)&=\sum_{j=1}^{n}\frac{1}{n}e^{tj}\\ &=\frac{1}{n}(e^t+e^{2t}+\cdots+e^{nt})\\ &=\frac{e^t(e^{nt}-1)}{n(e^t-1)} \end{align*} I don't understand how the algebra goes from step 2 to step 3 here. I understand factoring out an $e^t$ , but how does the denominator come about. Is this polynomial division?","Suppose has a range and for (uniform distribution). Then I don't understand how the algebra goes from step 2 to step 3 here. I understand factoring out an , but how does the denominator come about. Is this polynomial division?","X \{1,2,\dots n \} p_X(j)=1/n 1\leq j \leq n \begin{align*} 
g(t)&=\sum_{j=1}^{n}\frac{1}{n}e^{tj}\\
&=\frac{1}{n}(e^t+e^{2t}+\cdots+e^{nt})\\
&=\frac{e^t(e^{nt}-1)}{n(e^t-1)} \end{align*} e^t","['probability', 'algebra-precalculus']"
