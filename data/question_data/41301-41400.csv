,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Efficient Algorithm for finding left (or right) Transversal in a Group,Efficient Algorithm for finding left (or right) Transversal in a Group,,"I'm wondering if anyone knows an algorithm to find a left or right transversal in a group efficiently. The definition is you are given a subgroup $H$ of a group $G$, and you want to find a representative of each coset of $H$ in $G$. Recall the coset test : $x, y \in G$ are in the same coset iff $x^{-1}y \in H$. This yields a trivial $O(|G|)$ algorithm. Simply test each element of $G$ until you find $|H : G|$ unique representatives. I'm wondering if there is a more efficient way to do this, preferably deterministically. Also, if finding a base or strongly generating set is necessary beforehand, the cost of such should be included in the efficiency of the algorithm. I am interested in such an algorithm for any arbitrary group, but if a special algorithm exists when $G = S_n$ and $H$ is a permutation group, possibly $S_k$ for some $k < n$, I'd be happy to learn of this as well. I would also appreciate any references to textbooks or papers that might help solve this problem. Thanks!","I'm wondering if anyone knows an algorithm to find a left or right transversal in a group efficiently. The definition is you are given a subgroup $H$ of a group $G$, and you want to find a representative of each coset of $H$ in $G$. Recall the coset test : $x, y \in G$ are in the same coset iff $x^{-1}y \in H$. This yields a trivial $O(|G|)$ algorithm. Simply test each element of $G$ until you find $|H : G|$ unique representatives. I'm wondering if there is a more efficient way to do this, preferably deterministically. Also, if finding a base or strongly generating set is necessary beforehand, the cost of such should be included in the efficiency of the algorithm. I am interested in such an algorithm for any arbitrary group, but if a special algorithm exists when $G = S_n$ and $H$ is a permutation group, possibly $S_k$ for some $k < n$, I'd be happy to learn of this as well. I would also appreciate any references to textbooks or papers that might help solve this problem. Thanks!",,"['abstract-algebra', 'group-theory', 'algorithms']"
1,A group whose automorphism group is cyclic,A group whose automorphism group is cyclic,,Is there an Abelian group $A$ which is not locally cyclic whose automorphism group is cyclic ?,Is there an Abelian group $A$ which is not locally cyclic whose automorphism group is cyclic ?,,"['abstract-algebra', 'group-theory', 'abelian-groups']"
2,Product of nilpotent ideal and simple module is zero,Product of nilpotent ideal and simple module is zero,,"I am stuck with trying to show that if an ideal $I$ of a ring $R$ is nilpotent and $M$ is a simple $R$-module, then $IM = 0$. I have attempted showing this by using the fact that the annihilator of a simple module is the primitive ideal, and I'm guessing trying to show that a nilpotent ideal and a primitive ideal are some how related but i think i am missing some crucial information. I have tried using properties of maximal ideals but to no conclusion, I'm sure I'm just missing an initial step any help on this will be greatly appreciated thanks in advance","I am stuck with trying to show that if an ideal $I$ of a ring $R$ is nilpotent and $M$ is a simple $R$-module, then $IM = 0$. I have attempted showing this by using the fact that the annihilator of a simple module is the primitive ideal, and I'm guessing trying to show that a nilpotent ideal and a primitive ideal are some how related but i think i am missing some crucial information. I have tried using properties of maximal ideals but to no conclusion, I'm sure I'm just missing an initial step any help on this will be greatly appreciated thanks in advance",,"['abstract-algebra', 'ring-theory', 'modules', 'ideals']"
3,Does there exist a UFD having only finitely many irreducibles?,Does there exist a UFD having only finitely many irreducibles?,,"Does there exist a UFD (which is not a field) having only finitely many irreducible elements? Definition of a UFD is: $R$ is an integral domain ($R$ is a commutative ring having unity and no zero-divisors) such that each $a\in R \setminus (R^* \cup {0})$ factors into a product of irreducible elements. I've tried to look for one, but without luck so far.","Does there exist a UFD (which is not a field) having only finitely many irreducible elements? Definition of a UFD is: $R$ is an integral domain ($R$ is a commutative ring having unity and no zero-divisors) such that each $a\in R \setminus (R^* \cup {0})$ factors into a product of irreducible elements. I've tried to look for one, but without luck so far.",,"['abstract-algebra', 'commutative-algebra', 'unique-factorization-domains']"
4,Open Source Abstract Algebra Textbooks,Open Source Abstract Algebra Textbooks,,"Does anyone know of any open source abstract algebra textbooks other than Judson's ? I am about to write a small program for a friend that will generate a random algebra problem (for preparing for quals) and my idea is to go through judson (and hopefully some other open source algebra textbooks) and get the exercises, put them in a database and pick them randomly and then show it to them using MathJax or something. But I'm having trouble finding a list of open source abstract algebra textbooks that have the .tex files. I would be content with finding online lists of abstract algebra problems with latex code that is easily parseable? Thanks!","Does anyone know of any open source abstract algebra textbooks other than Judson's ? I am about to write a small program for a friend that will generate a random algebra problem (for preparing for quals) and my idea is to go through judson (and hopefully some other open source algebra textbooks) and get the exercises, put them in a database and pick them randomly and then show it to them using MathJax or something. But I'm having trouble finding a list of open source abstract algebra textbooks that have the .tex files. I would be content with finding online lists of abstract algebra problems with latex code that is easily parseable? Thanks!",,"['abstract-algebra', 'reference-request', 'book-recommendation']"
5,Equivalence of weak forms of Hilbert's Nullstellensatz,Equivalence of weak forms of Hilbert's Nullstellensatz,,"The version of the Nullstellensatz with which I am familiar states that if $K$ is an algebraically closed field, and $f_1,\dots,f_n\in K[X_1,\dots,X_m]$, then the family $\{f_i\}$ has a common zero iff $\langle f_1,\dots,f_n\rangle\neq K[X_1,\dots,X_m]$. However, another form I have heard of states that if $K$ is algebraically closed, then the maximal ideals of $K[X_1,\dots,X_m]$ are precisely those of form $(X_1-a_1,\dots,X_m-a_m)$ for some $a_i\in K$. Can anybody explain how the first form implies the second?","The version of the Nullstellensatz with which I am familiar states that if $K$ is an algebraically closed field, and $f_1,\dots,f_n\in K[X_1,\dots,X_m]$, then the family $\{f_i\}$ has a common zero iff $\langle f_1,\dots,f_n\rangle\neq K[X_1,\dots,X_m]$. However, another form I have heard of states that if $K$ is algebraically closed, then the maximal ideals of $K[X_1,\dots,X_m]$ are precisely those of form $(X_1-a_1,\dots,X_m-a_m)$ for some $a_i\in K$. Can anybody explain how the first form implies the second?",,"['abstract-algebra', 'algebraic-geometry']"
6,How to determine the matrix of adjoint representation of Lie algebra?,How to determine the matrix of adjoint representation of Lie algebra?,,"My questions will concern two pages: http://mathworld.wolfram.com/AdjointRepresentation.html and http://mathworld.wolfram.com/KillingForm.html In the first page, we know the basis of four matrix $\{e_1,e_2,e_3,e_4\}$, and my try to find their adjoint representations is (taking example of $e_2$): $$\hbox{ad}_{e_2}e_1=-e_2,\\\hbox{ad}_{e_2}e_2=0,\\\hbox{ad}_{e_2}e_3=e_1-e_4,\\\hbox{ad}_{e_2}e_4=-e_3.$$ Then in the basis $\{e_1,e_2,e_3,e_4\}$, we can write the matrix of adjoint representation of $e_2$ as: $$\hbox{ad}(e_2)=\left[\begin{array}{cccc}0 & 0 & 1 & 0\\-1 & 0 & 0 & 1\\0 & 0 & 0 & 0\\0 & 0 & -1 & 0\end{array}\right]$$ just like the result in the page. Now my questions: Q1. If my try is right, now we read the second page (""killing form"") and let's do the same calculations with the basis $[X,Y,H]$. I find the matrix of $\hbox{ad}(Y)$ as $$\hbox{ad}(Y)=\left[\begin{array}{ccc}0 & 0 & 2\\0 &0 & 0\\-2 & 0 & 0\end{array}\right]$$ but not the result in the page (just its transposition). If this page is right, my precedent result should be $$\hbox{ad}(e_2)=\left[\begin{array}{cccc}0 & -1 & 0 & 0\\0 & 0 & 0 & 0\\1 & 0 & 0 & -1\\0 & 1 & 0 & 0\end{array}\right].$$ What should it be? Q2. We have the fomula of Lie algebra: $\hbox{ad}_XY=[X,Y]$. What are the relationships between $\hbox{ad}(X)$ and $\hbox{ad}_X(Y)$? Q3. In the page of ""killing form"", how does he get $B=\left[\begin{array}{ccc}8 & 0 & 0\\0 & -8 & 0\\0 & 0 & 8\end{array}\right]$? Thanks!","My questions will concern two pages: http://mathworld.wolfram.com/AdjointRepresentation.html and http://mathworld.wolfram.com/KillingForm.html In the first page, we know the basis of four matrix $\{e_1,e_2,e_3,e_4\}$, and my try to find their adjoint representations is (taking example of $e_2$): $$\hbox{ad}_{e_2}e_1=-e_2,\\\hbox{ad}_{e_2}e_2=0,\\\hbox{ad}_{e_2}e_3=e_1-e_4,\\\hbox{ad}_{e_2}e_4=-e_3.$$ Then in the basis $\{e_1,e_2,e_3,e_4\}$, we can write the matrix of adjoint representation of $e_2$ as: $$\hbox{ad}(e_2)=\left[\begin{array}{cccc}0 & 0 & 1 & 0\\-1 & 0 & 0 & 1\\0 & 0 & 0 & 0\\0 & 0 & -1 & 0\end{array}\right]$$ just like the result in the page. Now my questions: Q1. If my try is right, now we read the second page (""killing form"") and let's do the same calculations with the basis $[X,Y,H]$. I find the matrix of $\hbox{ad}(Y)$ as $$\hbox{ad}(Y)=\left[\begin{array}{ccc}0 & 0 & 2\\0 &0 & 0\\-2 & 0 & 0\end{array}\right]$$ but not the result in the page (just its transposition). If this page is right, my precedent result should be $$\hbox{ad}(e_2)=\left[\begin{array}{cccc}0 & -1 & 0 & 0\\0 & 0 & 0 & 0\\1 & 0 & 0 & -1\\0 & 1 & 0 & 0\end{array}\right].$$ What should it be? Q2. We have the fomula of Lie algebra: $\hbox{ad}_XY=[X,Y]$. What are the relationships between $\hbox{ad}(X)$ and $\hbox{ad}_X(Y)$? Q3. In the page of ""killing form"", how does he get $B=\left[\begin{array}{ccc}8 & 0 & 0\\0 & -8 & 0\\0 & 0 & 8\end{array}\right]$? Thanks!",,"['abstract-algebra', 'matrices', 'lie-algebras']"
7,Number of distinct conjugates of a subgroup is finite,Number of distinct conjugates of a subgroup is finite,,"Let $H$ be a subgroup of $G$.  I would like to prove that if $H$ has finite index in $G$, then there is only a finite number of distinct subgroups in $G$ of the form $aHa^{-1}$.  (This is an exercise in [Herstein, Topics in Algebra], in the section on subgroups and Lagrange's theorem.) The assertion clearly holds if $|H|$ (or $|G|$) is finite.  Also, the number of distinct conjugates $aHa^{-1}$ is 1 if $H \trianglelefteq G$.  So we need to consider only the case $|H|=\infty, H \ntrianglelefteq G$. I am also wondering what would be some specific examples of such infinite groups $H \le G$ with $|G:H| < \infty$ and $H \ntrianglelefteq G$.","Let $H$ be a subgroup of $G$.  I would like to prove that if $H$ has finite index in $G$, then there is only a finite number of distinct subgroups in $G$ of the form $aHa^{-1}$.  (This is an exercise in [Herstein, Topics in Algebra], in the section on subgroups and Lagrange's theorem.) The assertion clearly holds if $|H|$ (or $|G|$) is finite.  Also, the number of distinct conjugates $aHa^{-1}$ is 1 if $H \trianglelefteq G$.  So we need to consider only the case $|H|=\infty, H \ntrianglelefteq G$. I am also wondering what would be some specific examples of such infinite groups $H \le G$ with $|G:H| < \infty$ and $H \ntrianglelefteq G$.",,"['abstract-algebra', 'group-theory']"
8,"Ring without $1$ where $\forall r\in R$, $\exists$ $n_r > 1$ such that $r^{n_r} = r$, and not all primes are maximal","Ring without  where ,   such that , and not all primes are maximal",1 \forall r\in R \exists n_r > 1 r^{n_r} = r,"On my algebra final exam, there was a problem that essentially asked the following: Let $R$ be a commutative ring such that for all $r\in R$, there exists $n_r\in\Bbb{Z}^{>1}$ with $r^{n_r} = r$. Prove that all prime ideals are maximal. The solution which I believe was desired goes like this: Let $\mathfrak{p}\subseteq R$ be prime. Take $a\in R\setminus\mathfrak{p}$, and consider $a + \mathfrak{p} = a^{n_a} + \mathfrak{p}\in R/\mathfrak{p}$. As a ring mod a prime ideal is an integral domain has no zero divisors, we can cancel. Assuming that $R$ has unity , we find $1 + \mathfrak{p} = a^{n_a - 1} + \mathfrak{p}$, and since $n_a > 1$, we can write   $$ a\cdot a^{n_a - 2} + \mathfrak{p} = \left(a + \mathfrak{p}\right)\left(a^{n_a - 2} + \mathfrak{p}\right) = 1 + \mathfrak{p}, $$   so we have found an inverse for any nonzero element in $R/\mathfrak{p}$. Since $R/\mathfrak{p}$ is commutative, $R/\mathfrak{p}$ is a field, and hence $\mathfrak{p}$ is maximal. I had a problem with the cancellation step. It seems to require $R$ that have unity, whereas the problem statement does not require $R$ to have unity. I think this was a misstatement on my professor's part, but I cannot seem to find a counterexample. It isn't too much trouble to find an $R$ (without unity) with the property that for all $ r\in R$, there exists $ n_r\in\Bbb{Z}^{> 1}$ such that $r^{n_r} = r$: take for example, the subring of $\left(\Bbb{Z}/p\Bbb{Z}\right)^{\Bbb{N}}$ (countably infinite product of $\Bbb{Z}/p\Bbb{Z}$'s) where all but finitely many entries in a ""vector"" are nonzero. It's easy to see that this ring does not have unity; however, it still satisfies the property that every prime ideal is maximal. I tried to come up with a genuine counterexample, but I couldn't find one. My idea was to modify the example above by considering an infinite product of some integral domain $\mathcal{O}$ ( not a field) where $a^{n_a} = a$ for some $n_a > 1$ for each $a\in\mathcal{O}$, but I couldn't find such an $\mathcal{O}$. So long story short, my question is: Is there a counterexample to the original claim when $R$ does not have $1$?","On my algebra final exam, there was a problem that essentially asked the following: Let $R$ be a commutative ring such that for all $r\in R$, there exists $n_r\in\Bbb{Z}^{>1}$ with $r^{n_r} = r$. Prove that all prime ideals are maximal. The solution which I believe was desired goes like this: Let $\mathfrak{p}\subseteq R$ be prime. Take $a\in R\setminus\mathfrak{p}$, and consider $a + \mathfrak{p} = a^{n_a} + \mathfrak{p}\in R/\mathfrak{p}$. As a ring mod a prime ideal is an integral domain has no zero divisors, we can cancel. Assuming that $R$ has unity , we find $1 + \mathfrak{p} = a^{n_a - 1} + \mathfrak{p}$, and since $n_a > 1$, we can write   $$ a\cdot a^{n_a - 2} + \mathfrak{p} = \left(a + \mathfrak{p}\right)\left(a^{n_a - 2} + \mathfrak{p}\right) = 1 + \mathfrak{p}, $$   so we have found an inverse for any nonzero element in $R/\mathfrak{p}$. Since $R/\mathfrak{p}$ is commutative, $R/\mathfrak{p}$ is a field, and hence $\mathfrak{p}$ is maximal. I had a problem with the cancellation step. It seems to require $R$ that have unity, whereas the problem statement does not require $R$ to have unity. I think this was a misstatement on my professor's part, but I cannot seem to find a counterexample. It isn't too much trouble to find an $R$ (without unity) with the property that for all $ r\in R$, there exists $ n_r\in\Bbb{Z}^{> 1}$ such that $r^{n_r} = r$: take for example, the subring of $\left(\Bbb{Z}/p\Bbb{Z}\right)^{\Bbb{N}}$ (countably infinite product of $\Bbb{Z}/p\Bbb{Z}$'s) where all but finitely many entries in a ""vector"" are nonzero. It's easy to see that this ring does not have unity; however, it still satisfies the property that every prime ideal is maximal. I tried to come up with a genuine counterexample, but I couldn't find one. My idea was to modify the example above by considering an infinite product of some integral domain $\mathcal{O}$ ( not a field) where $a^{n_a} = a$ for some $n_a > 1$ for each $a\in\mathcal{O}$, but I couldn't find such an $\mathcal{O}$. So long story short, my question is: Is there a counterexample to the original claim when $R$ does not have $1$?",,"['abstract-algebra', 'ring-theory']"
9,Finding the Galois group over $\Bbb{Q}$.,Finding the Galois group over .,\Bbb{Q},"If K is the splitting field of $X^8-2$ over $\Bbb{Q}$, I want to find the galois group. We know that $K=\Bbb{Q}(2^{1/8}, \zeta_8)$. So first I want to look at $Gal(\Bbb{Q}(\zeta_8)/\Bbb{Q})$ and then look at $Gal(\Bbb{Q}(2^{1/8})/\Bbb{Q})$, since there is a homomorphism $\rho: Gal(\Bbb{Q}(2^{1/8},\zeta_8)/\Bbb{Q}) \rightarrow Gal(\Bbb{Q}(\zeta_8)/\Bbb{Q})$. Since $Gal(\Bbb{Q}(\zeta_8)/\Bbb{Q}) \cong Aut(<\zeta_8>) \cong Z^{\times}_8 = \{1, 3, 5, 7\}$, we know that we have four subgroups in $Gal(Q(\zeta_8)/\Bbb{Q})$ (Let $\zeta_8 = \zeta$): $\sigma_1(\zeta) = \zeta$ $\sigma_3(\zeta) = \zeta^3$ $\sigma_5(\zeta) = \zeta^5$ $\sigma_7(\zeta) = \zeta^7$ And now I have to relate this to the homomorphism $\rho$ in order to find the rest of the permutations, right? But I'm a bit confused. I've spent hours trying to do it and I'm seriously stuck...could anybody help me with this? Thanks in advance","If K is the splitting field of $X^8-2$ over $\Bbb{Q}$, I want to find the galois group. We know that $K=\Bbb{Q}(2^{1/8}, \zeta_8)$. So first I want to look at $Gal(\Bbb{Q}(\zeta_8)/\Bbb{Q})$ and then look at $Gal(\Bbb{Q}(2^{1/8})/\Bbb{Q})$, since there is a homomorphism $\rho: Gal(\Bbb{Q}(2^{1/8},\zeta_8)/\Bbb{Q}) \rightarrow Gal(\Bbb{Q}(\zeta_8)/\Bbb{Q})$. Since $Gal(\Bbb{Q}(\zeta_8)/\Bbb{Q}) \cong Aut(<\zeta_8>) \cong Z^{\times}_8 = \{1, 3, 5, 7\}$, we know that we have four subgroups in $Gal(Q(\zeta_8)/\Bbb{Q})$ (Let $\zeta_8 = \zeta$): $\sigma_1(\zeta) = \zeta$ $\sigma_3(\zeta) = \zeta^3$ $\sigma_5(\zeta) = \zeta^5$ $\sigma_7(\zeta) = \zeta^7$ And now I have to relate this to the homomorphism $\rho$ in order to find the rest of the permutations, right? But I'm a bit confused. I've spent hours trying to do it and I'm seriously stuck...could anybody help me with this? Thanks in advance",,['abstract-algebra']
10,Quasicommutative semigroups.,Quasicommutative semigroups.,,"A Semigroup is called quasicommutative if for all elements $a,b$ there is some $r≥1$ such that $$ab=b^ra$$ We know that every commutative semigroup is also quasicommutative, so we can make lots of examples for quasicommutative semigroups by regarding a commutative one. But I am looking for a non-commutative , finite quasicommutative semigroup. In fact, I am searching for a sample of such to see this structure work. Any help would be appreciated.","A Semigroup is called quasicommutative if for all elements $a,b$ there is some $r≥1$ such that $$ab=b^ra$$ We know that every commutative semigroup is also quasicommutative, so we can make lots of examples for quasicommutative semigroups by regarding a commutative one. But I am looking for a non-commutative , finite quasicommutative semigroup. In fact, I am searching for a sample of such to see this structure work. Any help would be appreciated.",,"['abstract-algebra', 'semigroups']"
11,Seeking an example in module theory -- (In)decomposable modules,Seeking an example in module theory -- (In)decomposable modules,,"Can anyone give me a module $M$ over a ring $R$, such that $M$ is indecomposable, but $M$ has a submodule $N$ such that $N$ is decomposable? In general, what further assumptions can we put on the ring $R$ or $M$ to guarantee that $M$ has no such decomposable submodule $N$?","Can anyone give me a module $M$ over a ring $R$, such that $M$ is indecomposable, but $M$ has a submodule $N$ such that $N$ is decomposable? In general, what further assumptions can we put on the ring $R$ or $M$ to guarantee that $M$ has no such decomposable submodule $N$?",,"['abstract-algebra', 'modules']"
12,"Group of sphere transformations, impressing friends","Group of sphere transformations, impressing friends",,"Ok, so here's the story: I am reading a book on algebra and, via some exercises, discovered that in any group $G$, the order of $x \cdot y$, written $o(x \cdot y)$, equals $o(y \cdot x)$. Now, this is trivial in an abelian group, but I was looking for examples of a non-abelian group (simply because the result was interesting) to see this happen. Of course, I knew $GL(2, \mathbb{R})$ and the permutation groups. However, literally by chance (I had a ball in my hand), I realized that $m(90)$ degree rotations of a sphere - $m \in \mathbb{N}$ - are also a non-abelian group. (That is, let $G$ be the set of transformations of some particular distinguished point on a sphere through right angles, like the transformation forward , or clockwise , or right . The group operation is composition, and the identity is the ""don't do anything"" transformation.) This discovery lends itself to a trick I find neat: take a sequence of operations, and find their order. (Like $o(\text{fwd cwise left left})$, which is $3$.) Then, take any cyclic permutation of that sequence, and you have a sequence of the same order. If you actually have a sphere on you (I took a ball and drew a little arrow on it) and you ask someone for an eight-term sequence, and then instantly give them back a (well-mixed, unrecognizable) sequence of the same order, and show them that you're right, on the spot -  this is impressive. Well, okay... actually, that's the thing. I find it impressive; my friends don't. This bums me out. So, my question: how can I amp this trick up? I thought about memorizing a ""basis"" for all sequences of a certain length, i.e., knowing enough sequences that any of them are commutation-equivalent with the ones I know; but, unfortunately, this is impractical. Does anybody know how to make this cooler?","Ok, so here's the story: I am reading a book on algebra and, via some exercises, discovered that in any group $G$, the order of $x \cdot y$, written $o(x \cdot y)$, equals $o(y \cdot x)$. Now, this is trivial in an abelian group, but I was looking for examples of a non-abelian group (simply because the result was interesting) to see this happen. Of course, I knew $GL(2, \mathbb{R})$ and the permutation groups. However, literally by chance (I had a ball in my hand), I realized that $m(90)$ degree rotations of a sphere - $m \in \mathbb{N}$ - are also a non-abelian group. (That is, let $G$ be the set of transformations of some particular distinguished point on a sphere through right angles, like the transformation forward , or clockwise , or right . The group operation is composition, and the identity is the ""don't do anything"" transformation.) This discovery lends itself to a trick I find neat: take a sequence of operations, and find their order. (Like $o(\text{fwd cwise left left})$, which is $3$.) Then, take any cyclic permutation of that sequence, and you have a sequence of the same order. If you actually have a sphere on you (I took a ball and drew a little arrow on it) and you ask someone for an eight-term sequence, and then instantly give them back a (well-mixed, unrecognizable) sequence of the same order, and show them that you're right, on the spot -  this is impressive. Well, okay... actually, that's the thing. I find it impressive; my friends don't. This bums me out. So, my question: how can I amp this trick up? I thought about memorizing a ""basis"" for all sequences of a certain length, i.e., knowing enough sequences that any of them are commutation-equivalent with the ones I know; but, unfortunately, this is impractical. Does anybody know how to make this cooler?",,"['abstract-algebra', 'group-theory', 'puzzle', 'recreational-mathematics']"
13,Proof of first isomorphism theorem of group,Proof of first isomorphism theorem of group,,"(Proof of (first) Isomorphism Theorem) Let $f : G \rightarrow H$ be a surjective group homomorphism.   Let $K = \operatorname{ker} f$. Then the map $f' : G/K \rightarrow H$ by $f'(gK) = f(g)$   is well-defined and is an isomorphism. Proof: If $g'K = gK$, then $g' = gk$ with $k ∈ K$, and $f(g') = f(gk) = f(g) f(k) = f(g) e = f(g)$ so the map $f'$ is well-defined. It is surjective because $f$ is. For injectivity, if $f'(gK) = f'(g'K)$, then   $f(g) = f(g')$, and $e_{H} = f(g)^{-1} · f(g') = f(g^{−1}) · f(g) = f(g^{−1}g')$   Thus, $g^{−1}g' ∈ K$, so $g' ∈ gK$, and $g'K = gK$.   In summary, the normal subgroups of a group are exactly the kernels of surjective homomorphisms. First of all, I am not getting how $f(g)^{-1} \cdot f(g')$ leads to $f(g^{-1}) \cdot f(g)$. Secondly, I am unsure how the later part of the proof establishes injectivity. And lastly, at http://en.wikipedia.org/wiki/Isomorphism_theorem#Discussion , there is a diagram that shows the relationship, and can anyone explain this diagram with some insights from the above proof?","(Proof of (first) Isomorphism Theorem) Let $f : G \rightarrow H$ be a surjective group homomorphism.   Let $K = \operatorname{ker} f$. Then the map $f' : G/K \rightarrow H$ by $f'(gK) = f(g)$   is well-defined and is an isomorphism. Proof: If $g'K = gK$, then $g' = gk$ with $k ∈ K$, and $f(g') = f(gk) = f(g) f(k) = f(g) e = f(g)$ so the map $f'$ is well-defined. It is surjective because $f$ is. For injectivity, if $f'(gK) = f'(g'K)$, then   $f(g) = f(g')$, and $e_{H} = f(g)^{-1} · f(g') = f(g^{−1}) · f(g) = f(g^{−1}g')$   Thus, $g^{−1}g' ∈ K$, so $g' ∈ gK$, and $g'K = gK$.   In summary, the normal subgroups of a group are exactly the kernels of surjective homomorphisms. First of all, I am not getting how $f(g)^{-1} \cdot f(g')$ leads to $f(g^{-1}) \cdot f(g)$. Secondly, I am unsure how the later part of the proof establishes injectivity. And lastly, at http://en.wikipedia.org/wiki/Isomorphism_theorem#Discussion , there is a diagram that shows the relationship, and can anyone explain this diagram with some insights from the above proof?",,['abstract-algebra']
14,Let $f_{i}$ be different automorphisms of field $\mathbb{K}$. Does there exist an $x \in \mathbb{K}$ such that $f_{i}(x)$ are pairwise distinct?,Let  be different automorphisms of field . Does there exist an  such that  are pairwise distinct?,f_{i} \mathbb{K} x \in \mathbb{K} f_{i}(x),"Let $f_{1},f_{2},\ldots,f_{n}$ be different automorphisms of field $\mathbb{K}$ . What I want to ask is: Does there exist an element $x \in \mathbb{K}$ such that $f_{1}(x),f_{2}(x),\ldots,f_{n}(x)$ are pairwise distinct?","Let $f_{1},f_{2},\ldots,f_{n}$ be different automorphisms of field $\mathbb{K}$ . What I want to ask is: Does there exist an element $x \in \mathbb{K}$ such that $f_{1}(x),f_{2}(x),\ldots,f_{n}(x)$ are pairwise distinct?",,['abstract-algebra']
15,Module M/IM of finite length $\implies$ Ring A/I of finite length,Module M/IM of finite length  Ring A/I of finite length,\implies,"This question is due to a proof in an algebra book (on the topic of dimension theory) which I don't fully understand (specifically, the proof of Thm 6.9b) in Kommutative Algebra by Ischebeck). It may have a very simple answer which I currently don't see. Let A be a semilocal, noetherian ring, $M$ a finite A-module with $\mathrm{Ann}_A(M)=0$ and $a_1,\ldots,a_s\in \mathrm{Jac}(A)$ with $l_A(M/(a_1,\ldots,a_s)M)\lt\infty.$   Why is $l_A(A/(a_1,\ldots,a_s))\lt\infty$ ? (where $\mathrm{Ann}_A(M)=\{x\in A\mid xM=0\}$, $\mathrm{Jac}(A)=\bigcap\limits_{\text{m is maximal ideal in } A} m$, $l_X(Y)=$ length of $Y$ as an $X$-module) My ideas: I know that from $l_A(M/(a_1,\ldots,a_s)M)\lt \infty$ it follows that the ring $A/\mathrm{Ann}_A(M/(a_1,\ldots,a_s)M)$ is of finite length, because it can be embedded (as an $A$-module) in $M/(a_1,\ldots,a_s)M.$ But I don't know if/why $\mathrm{Ann}_A(M/(a_1,\ldots,a_s)M)=(a_1,\ldots,a_s)$. Also I don't know if $A$ being semilocal or $a_1,\ldots,a_s\in \mathrm{Jac}(A)$ instead of $a_1,\ldots,a_s\in A$ is of any relevance to the question. As further information, the final goal is to show that the degree of the polynomial p(n), which for large n gives the length $l_{A/Jac(A)}(M/Jac(A)^nM)$, is lesser or equal the minimum number s for which $l(M/(a_1,..,a_s)M)<∞$ as above.","This question is due to a proof in an algebra book (on the topic of dimension theory) which I don't fully understand (specifically, the proof of Thm 6.9b) in Kommutative Algebra by Ischebeck). It may have a very simple answer which I currently don't see. Let A be a semilocal, noetherian ring, $M$ a finite A-module with $\mathrm{Ann}_A(M)=0$ and $a_1,\ldots,a_s\in \mathrm{Jac}(A)$ with $l_A(M/(a_1,\ldots,a_s)M)\lt\infty.$   Why is $l_A(A/(a_1,\ldots,a_s))\lt\infty$ ? (where $\mathrm{Ann}_A(M)=\{x\in A\mid xM=0\}$, $\mathrm{Jac}(A)=\bigcap\limits_{\text{m is maximal ideal in } A} m$, $l_X(Y)=$ length of $Y$ as an $X$-module) My ideas: I know that from $l_A(M/(a_1,\ldots,a_s)M)\lt \infty$ it follows that the ring $A/\mathrm{Ann}_A(M/(a_1,\ldots,a_s)M)$ is of finite length, because it can be embedded (as an $A$-module) in $M/(a_1,\ldots,a_s)M.$ But I don't know if/why $\mathrm{Ann}_A(M/(a_1,\ldots,a_s)M)=(a_1,\ldots,a_s)$. Also I don't know if $A$ being semilocal or $a_1,\ldots,a_s\in \mathrm{Jac}(A)$ instead of $a_1,\ldots,a_s\in A$ is of any relevance to the question. As further information, the final goal is to show that the degree of the polynomial p(n), which for large n gives the length $l_{A/Jac(A)}(M/Jac(A)^nM)$, is lesser or equal the minimum number s for which $l(M/(a_1,..,a_s)M)<∞$ as above.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'modules']"
16,$A$ an absolutely flat ring $\Rightarrow$ $S^{-1}A$ is absolutely flat,an absolutely flat ring   is absolutely flat,A \Rightarrow S^{-1}A,"I was doing some exercises in the book of Atiyah / MacDonald on Commutative Algebra, and I'm a little ""stuck"" with number 3.10 (i): If $A$ is an absolutely flat ring and $S\subseteq A$ a multiplicatively closed subset, then the localization $S^{-1}A$ is absolutely flat. I wanted to use a criterion shown earlier: $A$ absolutely flat $\Leftrightarrow$ every principal ideal of $A$ is idempotent. So if $\frac{a}{s}\in S^{-1}A$, my plan was to show that there exists a $\frac{b}{t}\in S^{-1}A$ with $\frac{b}{t}\cdot(\frac{a}{s})^2=\frac{a}{s}$. From the absolute flatness of $A$, we know that there are $x,y\in A$ with $xa^2=a$ and $ys^2=s$. So choosing $b:=x$, $t:=y$ one would be done, but I don't see why $y$ should be in $S$? I guess this has to be ""obvious"" in some way, and I'm just being stupid!? Then I tried to google it, but all I found was a different solution ( here ), and I'd like to ask one question regarding this solution, too, but I don't know if this is the appropriate place to do so? Since it's the same topic, I hope so, but if not, please correct me and I'll edit this post. Let $P$ be an arbitrary $S^{-1}A$-module. The author says there is an obvious isomorphism $S^{-1}P\cong S^{-1}A\otimes_A P\to P$ of $S^{-1}A$-modules. The first isomorphy is clear to me (and proven in the book), but I don't get the second one. I believe the maps should look like this: $\varphi:S^{-1}A\otimes_A P\to P, \varphi(\frac{1}{s}\otimes p)=\frac{1}{s}p$, and $\psi:P\to S^{-1}A\otimes_A P, \psi(p)=1\otimes p$. Then $\varphi\circ\psi=1$. As for $\psi\circ\varphi$, let $\frac{1}{s}\otimes p\in S^{-1}A\otimes_A P$, then $\psi(\varphi(\frac{1}{s}\otimes p))=\psi(\frac{1}{s}p)=1\otimes\frac{1}{s}p$, and then I don't know why I can switch over the $\frac{1}{s}$. I know that there is an $S^{-1}A$-module structure on the tensor product, but I thought it was of the form $\frac{a}{s}\cdot(\frac{1}{t}\otimes p)=\frac{a}{st}\otimes p$. It has to have something to do with the $S^{-1}A$-module structure on $P$. I guess it should be easier to show $S^{-1}M\cong M$ directly, I just had the idea to do it this way, but didn't try it out yet. I am going to do this now, but the question above still remains. It has to be a simple thing I overlook again, something I did not fully understand yet, and I hope you can help me understand it! Thanks for your help in advance!","I was doing some exercises in the book of Atiyah / MacDonald on Commutative Algebra, and I'm a little ""stuck"" with number 3.10 (i): If $A$ is an absolutely flat ring and $S\subseteq A$ a multiplicatively closed subset, then the localization $S^{-1}A$ is absolutely flat. I wanted to use a criterion shown earlier: $A$ absolutely flat $\Leftrightarrow$ every principal ideal of $A$ is idempotent. So if $\frac{a}{s}\in S^{-1}A$, my plan was to show that there exists a $\frac{b}{t}\in S^{-1}A$ with $\frac{b}{t}\cdot(\frac{a}{s})^2=\frac{a}{s}$. From the absolute flatness of $A$, we know that there are $x,y\in A$ with $xa^2=a$ and $ys^2=s$. So choosing $b:=x$, $t:=y$ one would be done, but I don't see why $y$ should be in $S$? I guess this has to be ""obvious"" in some way, and I'm just being stupid!? Then I tried to google it, but all I found was a different solution ( here ), and I'd like to ask one question regarding this solution, too, but I don't know if this is the appropriate place to do so? Since it's the same topic, I hope so, but if not, please correct me and I'll edit this post. Let $P$ be an arbitrary $S^{-1}A$-module. The author says there is an obvious isomorphism $S^{-1}P\cong S^{-1}A\otimes_A P\to P$ of $S^{-1}A$-modules. The first isomorphy is clear to me (and proven in the book), but I don't get the second one. I believe the maps should look like this: $\varphi:S^{-1}A\otimes_A P\to P, \varphi(\frac{1}{s}\otimes p)=\frac{1}{s}p$, and $\psi:P\to S^{-1}A\otimes_A P, \psi(p)=1\otimes p$. Then $\varphi\circ\psi=1$. As for $\psi\circ\varphi$, let $\frac{1}{s}\otimes p\in S^{-1}A\otimes_A P$, then $\psi(\varphi(\frac{1}{s}\otimes p))=\psi(\frac{1}{s}p)=1\otimes\frac{1}{s}p$, and then I don't know why I can switch over the $\frac{1}{s}$. I know that there is an $S^{-1}A$-module structure on the tensor product, but I thought it was of the form $\frac{a}{s}\cdot(\frac{1}{t}\otimes p)=\frac{a}{st}\otimes p$. It has to have something to do with the $S^{-1}A$-module structure on $P$. I guess it should be easier to show $S^{-1}M\cong M$ directly, I just had the idea to do it this way, but didn't try it out yet. I am going to do this now, but the question above still remains. It has to be a simple thing I overlook again, something I did not fully understand yet, and I hope you can help me understand it! Thanks for your help in advance!",,"['abstract-algebra', 'commutative-algebra']"
17,Intermediate field between $F$ and $F(x)$,Intermediate field between  and,F F(x),"Suppose that $F$ is a field and that $u \in F(x):= \{PQ^{-1}:P,Q \in F[x], Q\neq 0 \}$, so that $F \subseteq F(u) \subseteq F(x)$. Is there a general method for determining $[F(x):F(u)]$? For my homework problem I have been given the specific case of $u := \frac{x^3}{x+1} = x^2-x+1-\frac{1}{x+1}$ and we haven't even gone over anything remotely similar to a problem like this in class. The hint was to choose $v \in F(x)$ so that $F(u,v) = F(x)$. If we had such a $v$ then $[F(x):F(u)] = [(F(u))(v):F(u)]$ which is equal to the minimum degree of a polynomial with coefficients in $F(u)$ which has $v$ as a root. But I don't know how to find such a polynomial, nor is it obvious that one exists. If we take $v:=x$ then certainly $F(u,x)=F(x)$ but I didn't make any progress from this. I was thinking of writing a Mathematica script to try random polynomials but I don't think this is the intended method of solution. I was also thinking that it might be significant that the roots of the numerator and denominator of $u$ are 0 and 1, namely they are elements of $F$. Any help would be appreciated.","Suppose that $F$ is a field and that $u \in F(x):= \{PQ^{-1}:P,Q \in F[x], Q\neq 0 \}$, so that $F \subseteq F(u) \subseteq F(x)$. Is there a general method for determining $[F(x):F(u)]$? For my homework problem I have been given the specific case of $u := \frac{x^3}{x+1} = x^2-x+1-\frac{1}{x+1}$ and we haven't even gone over anything remotely similar to a problem like this in class. The hint was to choose $v \in F(x)$ so that $F(u,v) = F(x)$. If we had such a $v$ then $[F(x):F(u)] = [(F(u))(v):F(u)]$ which is equal to the minimum degree of a polynomial with coefficients in $F(u)$ which has $v$ as a root. But I don't know how to find such a polynomial, nor is it obvious that one exists. If we take $v:=x$ then certainly $F(u,x)=F(x)$ but I didn't make any progress from this. I was thinking of writing a Mathematica script to try random polynomials but I don't think this is the intended method of solution. I was also thinking that it might be significant that the roots of the numerator and denominator of $u$ are 0 and 1, namely they are elements of $F$. Any help would be appreciated.",,"['abstract-algebra', 'field-theory']"
18,Understanding of exterior algebra,Understanding of exterior algebra,,"Consider the following definition from Loring W. Tu's An Introduction to Manifolds : For a finite-dimensional vector space $V$, say of dimension $n$, define   $$A_*(V)=\oplus_{k=0}^{\infty}A_k(V)=\oplus_{k=0}^{n}A_k(V)$$   where $A_0(V)={\mathbb R}$, and $A_k(k>0)$ denotes the set of all alternating $k$-linear functions $f$ on $V$, i.e.,   $$f:V^k\to{\mathbb R},\qquad f(v_{\sigma(1),\cdots,v_{\sigma(k)}})=(\text{sgn}\sigma)f(v_1,\cdots,v_k) \quad\text{for all} \quad\sigma\in S_k.$$   With the wedge product of multicovectors as multiplication, $A_*(V)$ becomes an anticommutative graded algebra, called the exterior algebra or the Grassmann algebra of multicovectors on the vector space $V$. By definition of graded algebra, $A_*(V)$ has the structure of a vector space. But I don't understand what does the element of $A_*(V)$ look like. For example, if $f\in A_2(V)$ and $g\in A_3(V)$, then what is $f+g$? Since domains of $f$ and $g$ are of different dimensions, how can one ""add"" them? So here are my questions : What does the element of $A_*(V)$ look like? And what's the addition of the vector space? According to the comments, the question above is actually a matter of understanding of the ""direct sum"". In stead of putting another post, I would like to ask a closed related question here: How many different definitions are there of exterior algebra and how are they equivalent to each other? I totally don't understand the one I learn from wikipedia . Any recommendation of a complete treatment of the subject?","Consider the following definition from Loring W. Tu's An Introduction to Manifolds : For a finite-dimensional vector space $V$, say of dimension $n$, define   $$A_*(V)=\oplus_{k=0}^{\infty}A_k(V)=\oplus_{k=0}^{n}A_k(V)$$   where $A_0(V)={\mathbb R}$, and $A_k(k>0)$ denotes the set of all alternating $k$-linear functions $f$ on $V$, i.e.,   $$f:V^k\to{\mathbb R},\qquad f(v_{\sigma(1),\cdots,v_{\sigma(k)}})=(\text{sgn}\sigma)f(v_1,\cdots,v_k) \quad\text{for all} \quad\sigma\in S_k.$$   With the wedge product of multicovectors as multiplication, $A_*(V)$ becomes an anticommutative graded algebra, called the exterior algebra or the Grassmann algebra of multicovectors on the vector space $V$. By definition of graded algebra, $A_*(V)$ has the structure of a vector space. But I don't understand what does the element of $A_*(V)$ look like. For example, if $f\in A_2(V)$ and $g\in A_3(V)$, then what is $f+g$? Since domains of $f$ and $g$ are of different dimensions, how can one ""add"" them? So here are my questions : What does the element of $A_*(V)$ look like? And what's the addition of the vector space? According to the comments, the question above is actually a matter of understanding of the ""direct sum"". In stead of putting another post, I would like to ask a closed related question here: How many different definitions are there of exterior algebra and how are they equivalent to each other? I totally don't understand the one I learn from wikipedia . Any recommendation of a complete treatment of the subject?",,['abstract-algebra']
19,I-adic completion of a ring,I-adic completion of a ring,,"Let $R$ be a ring, $I$ an ideal. According to Atiyah-Macdonald, if $R$ is Noetherian, then, we have $\hat{I}=\hat{R}I$ where hat denotes $I$-adic completion of $R$ and (I presume) $\hat{I}$ denotes the induced completion on $I$. I don't understand how to arrive at this equality and why the Noetherian hypothesis is necessary. Essentially $\hat{I}$ consists of equivalence classes of Cauchy sequences with elements in $I$. Any element of $\hat{R}I$ is an equivalence class of Cauchy sequences consisting of elements of $I$. I don't see how every Cauchy sequence with elements in $I$ is equivalent to one which can be written as a sum of products of a Cauchy sequence and a constant sequence of an element of $I$.","Let $R$ be a ring, $I$ an ideal. According to Atiyah-Macdonald, if $R$ is Noetherian, then, we have $\hat{I}=\hat{R}I$ where hat denotes $I$-adic completion of $R$ and (I presume) $\hat{I}$ denotes the induced completion on $I$. I don't understand how to arrive at this equality and why the Noetherian hypothesis is necessary. Essentially $\hat{I}$ consists of equivalence classes of Cauchy sequences with elements in $I$. Any element of $\hat{R}I$ is an equivalence class of Cauchy sequences consisting of elements of $I$. I don't see how every Cauchy sequence with elements in $I$ is equivalent to one which can be written as a sum of products of a Cauchy sequence and a constant sequence of an element of $I$.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
20,What is the kernel of the summation map from the direct sum to the sum?,What is the kernel of the summation map from the direct sum to the sum?,,"Let $R$ be a ring, and let $I_1,\ldots,I_n$ be ideals in $R$ (or submodules of some $R$-module). Consider the sequence $$ \bigoplus_{1\leq j < k\leq n} I_j\cap I_k\quad\xrightarrow{f}\quad\bigoplus_{l=1}^n I_l\quad\xrightarrow{g}\quad\sum_{k=1}^n I_k, $$ where $g$ is given by addition, and $f$ maps $x\in I_j\cap I_k$ to $x\in I_j$ and to $-x\in I_k$ (and to zero in all other components). Clearly, $g$ is surjective and the composition $g\circ f$ vanishes. Question: Is the above sequence exact in the middle? (This seems to be easy for $n=2$.) (Concerning the title: I am aware of the fact that $f$ won't be injective in general.)","Let $R$ be a ring, and let $I_1,\ldots,I_n$ be ideals in $R$ (or submodules of some $R$-module). Consider the sequence $$ \bigoplus_{1\leq j < k\leq n} I_j\cap I_k\quad\xrightarrow{f}\quad\bigoplus_{l=1}^n I_l\quad\xrightarrow{g}\quad\sum_{k=1}^n I_k, $$ where $g$ is given by addition, and $f$ maps $x\in I_j\cap I_k$ to $x\in I_j$ and to $-x\in I_k$ (and to zero in all other components). Clearly, $g$ is surjective and the composition $g\circ f$ vanishes. Question: Is the above sequence exact in the middle? (This seems to be easy for $n=2$.) (Concerning the title: I am aware of the fact that $f$ won't be injective in general.)",,"['abstract-algebra', 'homological-algebra']"
21,Notation for a polynomial ring and formal polynomials,Notation for a polynomial ring and formal polynomials,,"Given that we shouldn't say that ""$f(z)$ is a function"", shouldn't we also not write ""$p \in k[X_1, \ldots, X_n]$ is a polynomial""? Along those lines, I usually write $p(X_1, \ldots, X_n) \in k[X_1, \ldots, X_n]$ in order to balance the ""free variables"" on both sides of the relation, but that gets unwieldy when you start dealing with iterated polynomial rings. My question is: Is there a notation for polynomial rings which allow us to talk about polynomials without explicitly naming the indeterminates? Consider, for an analogy, vector spaces $\mathbb{R}^n$. These have a canonical basis, but the notation $\mathbb{R}^n$ does not commit me to naming the canonical basis, unlike, say, the notation $\operatorname{span} \{ e_1, \ldots, e_n \}$. I suppose I should fix a definition for polynomial rings. For simplicity let's work in the category $\mathbf{CRing}$ of commutative rings with 1. Let $U: \mathbf{CRing} \to \mathbf{Set}$ be the forgetful functor taking rings to their underlying sets. A polynomial ring in a set of indeterminates $\mathcal{S}$ over a ring $A$ is a ring $R$ together with an inclusion map $\iota: A \hookrightarrow R$ and a set-map $x: \mathcal{S} \hookrightarrow UR$, and has the universal property that for every ring $B$, homomorphism $\phi: A \to B$, and set-map $b: \mathcal{S} \to B$, there is a homomorphism $\epsilon: R \to B$ such that $\epsilon \circ \iota = \phi$ and $U\epsilon \circ x = b$. If we write $A[\mathcal{S}]$ for such a ring $R$, then we could write, for instance, $A[5]$ for the ring of polynomials in 5 variables over $A$, but that would, I imagine, be extremely confusing. Yet, on the other hand, if we have a bijection $\mathcal{S} \to \mathcal{S}'$, then this lifts to an isomorphism of $A[\mathcal{S}] \to A[\mathcal{S}']$, so it is all the more tempting to write $A[\kappa]$, $\kappa = |\mathcal{S}|$, for the canonical representative of this isomorphism class. If $\mathcal{S} = \{ 1, \ldots, n \} \subset \mathbb{N}$ and $\phi: A \to B$ is given, I write $\phi p(b_1, \ldots, b_n)$ for the image of $p \in A[\mathcal{S}]$ under $\epsilon$ for $b(m) = b_m, m \in \mathcal{S}$. When the choice of homomorphism $\phi$ is clear I'll omit it in writing. This justifies my notation $p(X_1, \ldots, X_n) \in A[X_1, \ldots, X_n]$, since I would like to regard $A[X]$ as being analogous to $\mathbb{Z}[\pi]$, i.e. it's a ring with a transcendental element adjoined so is isomorphic to a polynomial ring, but doesn't come with evaluation maps attached. But following this line of thought, how should I denote the object that $p$ itself belongs to? I recently started attending an algebraic geometry course and at one point the lecturer wrote $k[\mathbb{A}^n]$ for the ring of polynomials in $n$ indeterminates over $k$. This seems like a reasonable solution, but there are some problems: It feels suspiciously like a function ring, but in general the map taking formal polynomials to polynomial functions is neither injective nor surjective. The notation makes it look like a ring with $\mathbb{A}^n$ adjoined, but that doesn't seem to make sense. (Is there a way to make sense of it, e.g. by defining ring operations on $\mathbb{A}^n$?) Is it standard notation? I have seen $k[V]$ in some algebraic geometry textbooks for the coordinate ring of the (affine) variety $V$, but never for $V = \mathbb{A}^n$. (I have similar reservations about the notation $k[V]$, but not as strongly.) Would it make sense to write, say, $\mathbb{Z}[\mathbb{A}^n]$? A related problem arises from the following: let $p(X)$ and $q(X)$ be formal polynomials in $k[X]$, with $p(X) = q(X^2)$. It's clear that $\operatorname{deg} p = 2 \operatorname{deg} q$... but this shows that, in a certain sense, the degree depends on the ambient polynomial ring: if $p(X)$ were considered as a formal polynomial in $k[X^2]$, its degree would be the same as $q$, since, after all, $p(X) = q(X^2)$. It is clear that we should have $k[X^2] \subset k[X]$, but if we obviate the indeterminates and reduce polynomials to their bare skeletons, then the ""inclusion"" map $k[X^2] \hookrightarrow k[X]$ is no longer a set-theoretic inclusion map. Is there a coherent way of thinking about polynomials and polynomial rings which resolves this ambiguity, and what is the notation that goes with it?","Given that we shouldn't say that ""$f(z)$ is a function"", shouldn't we also not write ""$p \in k[X_1, \ldots, X_n]$ is a polynomial""? Along those lines, I usually write $p(X_1, \ldots, X_n) \in k[X_1, \ldots, X_n]$ in order to balance the ""free variables"" on both sides of the relation, but that gets unwieldy when you start dealing with iterated polynomial rings. My question is: Is there a notation for polynomial rings which allow us to talk about polynomials without explicitly naming the indeterminates? Consider, for an analogy, vector spaces $\mathbb{R}^n$. These have a canonical basis, but the notation $\mathbb{R}^n$ does not commit me to naming the canonical basis, unlike, say, the notation $\operatorname{span} \{ e_1, \ldots, e_n \}$. I suppose I should fix a definition for polynomial rings. For simplicity let's work in the category $\mathbf{CRing}$ of commutative rings with 1. Let $U: \mathbf{CRing} \to \mathbf{Set}$ be the forgetful functor taking rings to their underlying sets. A polynomial ring in a set of indeterminates $\mathcal{S}$ over a ring $A$ is a ring $R$ together with an inclusion map $\iota: A \hookrightarrow R$ and a set-map $x: \mathcal{S} \hookrightarrow UR$, and has the universal property that for every ring $B$, homomorphism $\phi: A \to B$, and set-map $b: \mathcal{S} \to B$, there is a homomorphism $\epsilon: R \to B$ such that $\epsilon \circ \iota = \phi$ and $U\epsilon \circ x = b$. If we write $A[\mathcal{S}]$ for such a ring $R$, then we could write, for instance, $A[5]$ for the ring of polynomials in 5 variables over $A$, but that would, I imagine, be extremely confusing. Yet, on the other hand, if we have a bijection $\mathcal{S} \to \mathcal{S}'$, then this lifts to an isomorphism of $A[\mathcal{S}] \to A[\mathcal{S}']$, so it is all the more tempting to write $A[\kappa]$, $\kappa = |\mathcal{S}|$, for the canonical representative of this isomorphism class. If $\mathcal{S} = \{ 1, \ldots, n \} \subset \mathbb{N}$ and $\phi: A \to B$ is given, I write $\phi p(b_1, \ldots, b_n)$ for the image of $p \in A[\mathcal{S}]$ under $\epsilon$ for $b(m) = b_m, m \in \mathcal{S}$. When the choice of homomorphism $\phi$ is clear I'll omit it in writing. This justifies my notation $p(X_1, \ldots, X_n) \in A[X_1, \ldots, X_n]$, since I would like to regard $A[X]$ as being analogous to $\mathbb{Z}[\pi]$, i.e. it's a ring with a transcendental element adjoined so is isomorphic to a polynomial ring, but doesn't come with evaluation maps attached. But following this line of thought, how should I denote the object that $p$ itself belongs to? I recently started attending an algebraic geometry course and at one point the lecturer wrote $k[\mathbb{A}^n]$ for the ring of polynomials in $n$ indeterminates over $k$. This seems like a reasonable solution, but there are some problems: It feels suspiciously like a function ring, but in general the map taking formal polynomials to polynomial functions is neither injective nor surjective. The notation makes it look like a ring with $\mathbb{A}^n$ adjoined, but that doesn't seem to make sense. (Is there a way to make sense of it, e.g. by defining ring operations on $\mathbb{A}^n$?) Is it standard notation? I have seen $k[V]$ in some algebraic geometry textbooks for the coordinate ring of the (affine) variety $V$, but never for $V = \mathbb{A}^n$. (I have similar reservations about the notation $k[V]$, but not as strongly.) Would it make sense to write, say, $\mathbb{Z}[\mathbb{A}^n]$? A related problem arises from the following: let $p(X)$ and $q(X)$ be formal polynomials in $k[X]$, with $p(X) = q(X^2)$. It's clear that $\operatorname{deg} p = 2 \operatorname{deg} q$... but this shows that, in a certain sense, the degree depends on the ambient polynomial ring: if $p(X)$ were considered as a formal polynomial in $k[X^2]$, its degree would be the same as $q$, since, after all, $p(X) = q(X^2)$. It is clear that we should have $k[X^2] \subset k[X]$, but if we obviate the indeterminates and reduce polynomials to their bare skeletons, then the ""inclusion"" map $k[X^2] \hookrightarrow k[X]$ is no longer a set-theoretic inclusion map. Is there a coherent way of thinking about polynomials and polynomial rings which resolves this ambiguity, and what is the notation that goes with it?",,"['abstract-algebra', 'commutative-algebra', 'notation']"
22,Left-adjoint to Yoneda embedding,Left-adjoint to Yoneda embedding,,"Let $C$ be locally small. Consider the Yoneda embedding $Y:C\rightarrow [C^{op},Set]$ . Since limits in functor categories are computed pointwise and since the hom-functor preserves limits, the Yoneda embedding is limit-preserving. A natural question to ask then is, whether or when the Yoneda embedding has a left adjoint. Categories whose Yoneda embedding has a left adjoint are called total . Apparently the category of sets and the category of groups are both total. What are the left adjoints of the Yoneda embedding (of these or other interesting examples) explicitely?","Let be locally small. Consider the Yoneda embedding . Since limits in functor categories are computed pointwise and since the hom-functor preserves limits, the Yoneda embedding is limit-preserving. A natural question to ask then is, whether or when the Yoneda embedding has a left adjoint. Categories whose Yoneda embedding has a left adjoint are called total . Apparently the category of sets and the category of groups are both total. What are the left adjoints of the Yoneda embedding (of these or other interesting examples) explicitely?","C Y:C\rightarrow [C^{op},Set]","['abstract-algebra', 'category-theory', 'examples-counterexamples', 'adjoint-functors', 'yoneda-lemma']"
23,Does every sequence of group epimorphisms (between finitely generated groups) contain a stable subsequence?,Does every sequence of group epimorphisms (between finitely generated groups) contain a stable subsequence?,,"I have a question that is related to the topic of limit groups: Let $G$ and $H$ be finitely generated groups and let $(\varphi_n: G \to H)_{n \in \mathbb{N}}$ be a sequence of group epimorphisms. Does there exist a stable subsequence of $(\varphi_n)_{n \in \mathbb{N}}$ ? This is the definition of ""stable sequence"": Let G be a group and $(\varphi_n) _{n \in \mathbb{N}}⊂ Hom(G, H)$ . The sequence $(\varphi_n) _{n \in \mathbb{N}}$ is stable if for any $g ∈ G$ either $\varphi_n(g) = 1$ for almost all $n$ or $\varphi_n(g)\neq 1$ for almost all $n$ . I conjecture that the answer to the question is positive, because the statement of the question is used on page 27 of the following article (in the article we have a sequence of epimorphisms $g_n: F_l \to L$ to which the statement of my question is applied to): https://arxiv.org/pdf/2002.10278.pdf Edit: In the above article we have the situation that G is a free group of rank at least two and H is a non-abelian limit group. So it would be sufficient if somebody can answer my question for this situation. Of course you can still say something to the general situation. Edit: ""Almost all"" means that the statement ist true for all natural numbers with possibly a finite number of exceptions.","I have a question that is related to the topic of limit groups: Let and be finitely generated groups and let be a sequence of group epimorphisms. Does there exist a stable subsequence of ? This is the definition of ""stable sequence"": Let G be a group and . The sequence is stable if for any either for almost all or for almost all . I conjecture that the answer to the question is positive, because the statement of the question is used on page 27 of the following article (in the article we have a sequence of epimorphisms to which the statement of my question is applied to): https://arxiv.org/pdf/2002.10278.pdf Edit: In the above article we have the situation that G is a free group of rank at least two and H is a non-abelian limit group. So it would be sufficient if somebody can answer my question for this situation. Of course you can still say something to the general situation. Edit: ""Almost all"" means that the statement ist true for all natural numbers with possibly a finite number of exceptions.","G H (\varphi_n: G \to H)_{n \in \mathbb{N}} (\varphi_n)_{n \in \mathbb{N}} (\varphi_n) _{n \in \mathbb{N}}⊂ Hom(G, H) (\varphi_n) _{n \in \mathbb{N}} g ∈ G \varphi_n(g) = 1 n \varphi_n(g)\neq 1 n g_n: F_l \to L","['abstract-algebra', 'geometry', 'group-theory', 'geometric-group-theory']"
24,Is exercise 2.22 (iii) in Rotman's Homological Algebra book wrong?,Is exercise 2.22 (iii) in Rotman's Homological Algebra book wrong?,,"I believe that the statement of exercise 2.22 in Rotman's Introduction to Homological Algebra is wrong. It states that if $R$ is an integral domain, $M$ is an $R$ -module, and $\textrm{Hom}_{R}(M,R/I) = 0$ for all non-zero ideals $I$ of $R$ , then $\textrm{Hom}_R(M,R) = 0$ . If $R$ is a field, then the only non-zero ideal is $(1)$ and $\textrm{Hom}_{R}(M,R/(1))$ is trivially zero, but $\textrm{Hom}_R(M,R)$ need not be. Am I right that the exercise is mistaken? I did not find a correction in the errata. Edit: Thank you metalspringpro for your answer. The exercise is correct when we exclude the possibility that $R$ is a field. To see this one can use the following statement: If the intersection of all non-zero ideals of an integral domain R is non-zero, show that R is a field.","I believe that the statement of exercise 2.22 in Rotman's Introduction to Homological Algebra is wrong. It states that if is an integral domain, is an -module, and for all non-zero ideals of , then . If is a field, then the only non-zero ideal is and is trivially zero, but need not be. Am I right that the exercise is mistaken? I did not find a correction in the errata. Edit: Thank you metalspringpro for your answer. The exercise is correct when we exclude the possibility that is a field. To see this one can use the following statement: If the intersection of all non-zero ideals of an integral domain R is non-zero, show that R is a field.","R M R \textrm{Hom}_{R}(M,R/I) = 0 I R \textrm{Hom}_R(M,R) = 0 R (1) \textrm{Hom}_{R}(M,R/(1)) \textrm{Hom}_R(M,R) R","['abstract-algebra', 'commutative-algebra', 'homological-algebra']"
25,Algebraic closure of $\mathbb F_p$ [duplicate],Algebraic closure of  [duplicate],\mathbb F_p,"This question already has an answer here : What is the algebraic closure of $\mathbb F_q$? (1 answer) Closed 3 years ago . I'm proving that $\overline{\mathbb{F}}_p = \bigcup\limits_{i=1}^{\infty} \mathbb{F}_{p^i}$ is an algebraic closure of $\mathbb{F}_p$ where $p$ is a prime. I think I've gotten down how to prove that $\overline{\mathbb{F}}_p$ is a field and that it is algebraic over $\mathbb{F}_p$ . I have some difficulties with proving that $\overline{\mathbb{F}}_p$ is algebraically closed. My attempt is as following: Suppose $f$ is a non-constant polynomial in $\overline{\mathbb{F}}_p [X]$ . If $\overline{\mathbb{F}}_p$ contains a root of $f$ , then it is algebraiclly closed. Per definition there must exist a $\mathbb{F}_{p^k}$ for a certain positive integer $k$ that contains all the coefficients of $f$ . Take a root $\alpha$ of $f$ and consider the extension $\mathbb{F}_{p^k}(\alpha)$ . How is this now a field of the form $\mathbb{F}_{p^l}$ for a certain positive integer $l$ ?","This question already has an answer here : What is the algebraic closure of $\mathbb F_q$? (1 answer) Closed 3 years ago . I'm proving that is an algebraic closure of where is a prime. I think I've gotten down how to prove that is a field and that it is algebraic over . I have some difficulties with proving that is algebraically closed. My attempt is as following: Suppose is a non-constant polynomial in . If contains a root of , then it is algebraiclly closed. Per definition there must exist a for a certain positive integer that contains all the coefficients of . Take a root of and consider the extension . How is this now a field of the form for a certain positive integer ?",\overline{\mathbb{F}}_p = \bigcup\limits_{i=1}^{\infty} \mathbb{F}_{p^i} \mathbb{F}_p p \overline{\mathbb{F}}_p \mathbb{F}_p \overline{\mathbb{F}}_p f \overline{\mathbb{F}}_p [X] \overline{\mathbb{F}}_p f \mathbb{F}_{p^k} k f \alpha f \mathbb{F}_{p^k}(\alpha) \mathbb{F}_{p^l} l,"['abstract-algebra', 'finite-fields']"
26,"Understanding the proof and meaning of the Butterfly lemma (Zassenhaus) (Lang's Algebra, pp. 20--21)","Understanding the proof and meaning of the Butterfly lemma (Zassenhaus) (Lang's Algebra, pp. 20--21)",,"I would like to type out my understanding of the Butterfly (Zassenhaus) Lemma, using the notation from pp. 20--21 of Lang's Algebra . I have trouble understanding Lang's proof so this is a hybrid of my own work and other sources. Butterfly lemma: Proof: First off, it is immediate that $U \cap V, U \cap v$ , and $u \cap V$ are subgroups of the unnamed group within which we are working. It is also clear that the latter two are subgroups of the former, since they are subsets of $U \cap V$ and groups themselves. We want to show that the latter two are in fact normal subgroups of $U \cap V$ . To see that $u \cap V$ is normal in $U \cap V$ , consider $x \in u \cap V$ and $z \in U \cap V$ . Because $x \in u$ and $z \in U$ , by normality we see that $zx z^{-1} \in u$ . Because $x \in V$ and $z \in V$ , by closure we see that $zxz^{-1} \in V$ . This shows that $zxz^{-1} \in u \cap V$ which proves normality of $u \cap V$ in $U \cap V$ . An entirely symmetrical argument works to show that $U \cap v$ is normal in $U \cap V$ . Since the product of normal subgroups is still normal, we are able to form the quotient group $\frac{U \cap V}{(u \cap V)(U \cap v)}$ , which we will return to later. Next we want to show that $u(U \cap v), u(U \cap V), (u \cap V)v$ , and $(U \cap V)v$ are groups. Because $U \cap v$ is a subgroup of the normalizer of $u$ , i.e. $U$ itself, it follows that $u(U \cap v)$ is a group. The same argument works to show that $u(U \cap V)$ is a group, and a symmetrical argument works to show that the latter two are groups. (I think these product groups could be written in either order, in terms of the set multiplication, but I haven't checked this. I'm just following Lang's notation here.) Now we want to show that $u(U \cap v)$ is normal in $u(U \cap V)$ and $(u \cap V)v$ is normal in $(U \cap V)v$ . (It is clear that the first and third are subgroups of the second and fourth respectively, since they are clearly subsets and are groups themselves.) Consider the function $f \colon u(U \cap V) \to \frac{U \cap V}{(u \cap V)(U \cap v)}$ given by $ab \mapsto b(U \cap v)(u \cap V)$ , where $a \in u$ and $b \in U \cap v$ . This is a well-defined function because if we take $a' \in u$ and $b' \in U \cap V$ such that $a'b' = ab$ , then $a^{-1}a' = bb'^{-1}$ so by the left-hand side, $a^{-1}a' \in u$ , and by the right-hand side, $bb'^{-1} \in U \cap V$ , so $a^{-1}a' = bb'^{-1}$ must be in $u \cap (U \cap V) = u \cap V \subseteq (u \cap V)( U \cap v)$ . This means that the inverse of $f(a'b')$ is the inverse of $f(ab)$ , which implies that $f(a'b') = f(ab)$ . Furthermore $f$ is a homomorphism, which can be seen as follows. Consider $a, \alpha \in u$ and $b, \beta \in U \cap V$ . We want to show that $f(ab \alpha \beta) = f(ab) f(\alpha \beta)$ . By normality $b \alpha b^{-1} = \alpha' \in u$ , so $\alpha = b^{-1} \alpha' b$ , which means that $ab \alpha \beta = ab b^{-1} \alpha' b \beta = a \alpha' b \beta$ . Therefore $f(ab \alpha \beta) = f(a \alpha' b \beta) = b \beta (u \cap V)(U \cap v) = f(ab) f(\alpha \beta)$ . The homomorphism $f$ is surjective, because for any $x \in U \cap V$ , $f(ex) = x(u \cap V)(U \cap v)$ . As for the kernel of $f$ , we are looking for $ab \in u(U \cap V)$ such that $f(ab) = (u \cap V)(U \cap v)$ . Clearly any $a \in u$ will suffice, and we need $b \in U \cap V$ by definition, but also $b \in (u \cap V)(U \cap v)$ , and the intersection of those two is just $(u \cap V)(U \cap v)$ . We can therefore write $b = xy$ , where $x$ is an element of $u$ and $y$ is an element of $U \cap v$ , which gives us $ab = axy = (ax)y \in u(U \cap v)$ . This shows that $\ker(f) \subseteq u(U \cap v)$ . On the other hand, if $cd \in u(U \cap v)$ , then because $U \cap v \subset (u \cap V)(U \cap v)$ , we see that $f(cd) = (u \cap V)(U \cap v)$ which shows that $u(U \cap v) \subseteq \ker(f)$ . Thus $\ker(f) = u(U \cap v)$ , so $u(U \cap v)$ is normal in $u(U \cap V)$ . By one of the isomorphism theorems, this establishes an isomorphism $\frac{u(U \cap V)}{u(U \cap v)} \cong \frac{U \cap V}{(u \cap V)(U \cap v)}$ . By a symmetrical argument we conclude that $\frac{u(U \cap V)}{u(U \cap v)} \cong \frac{(U \cap V)v}{(u \cap V)v}$ , as desired. Comments: Corrections or comments regarding my proof are appreciated. If anyone can explain Lang's proof in a way that I understand, I'd appreciate that too, because I don't get it. Lastly, if anyone can give me a decent intuition or main takeaway of this lemma, that would be great, because I'm not going to remember the details of this proof. Lang's proof:","I would like to type out my understanding of the Butterfly (Zassenhaus) Lemma, using the notation from pp. 20--21 of Lang's Algebra . I have trouble understanding Lang's proof so this is a hybrid of my own work and other sources. Butterfly lemma: Proof: First off, it is immediate that , and are subgroups of the unnamed group within which we are working. It is also clear that the latter two are subgroups of the former, since they are subsets of and groups themselves. We want to show that the latter two are in fact normal subgroups of . To see that is normal in , consider and . Because and , by normality we see that . Because and , by closure we see that . This shows that which proves normality of in . An entirely symmetrical argument works to show that is normal in . Since the product of normal subgroups is still normal, we are able to form the quotient group , which we will return to later. Next we want to show that , and are groups. Because is a subgroup of the normalizer of , i.e. itself, it follows that is a group. The same argument works to show that is a group, and a symmetrical argument works to show that the latter two are groups. (I think these product groups could be written in either order, in terms of the set multiplication, but I haven't checked this. I'm just following Lang's notation here.) Now we want to show that is normal in and is normal in . (It is clear that the first and third are subgroups of the second and fourth respectively, since they are clearly subsets and are groups themselves.) Consider the function given by , where and . This is a well-defined function because if we take and such that , then so by the left-hand side, , and by the right-hand side, , so must be in . This means that the inverse of is the inverse of , which implies that . Furthermore is a homomorphism, which can be seen as follows. Consider and . We want to show that . By normality , so , which means that . Therefore . The homomorphism is surjective, because for any , . As for the kernel of , we are looking for such that . Clearly any will suffice, and we need by definition, but also , and the intersection of those two is just . We can therefore write , where is an element of and is an element of , which gives us . This shows that . On the other hand, if , then because , we see that which shows that . Thus , so is normal in . By one of the isomorphism theorems, this establishes an isomorphism . By a symmetrical argument we conclude that , as desired. Comments: Corrections or comments regarding my proof are appreciated. If anyone can explain Lang's proof in a way that I understand, I'd appreciate that too, because I don't get it. Lastly, if anyone can give me a decent intuition or main takeaway of this lemma, that would be great, because I'm not going to remember the details of this proof. Lang's proof:","U \cap V, U \cap v u \cap V U \cap V U \cap V u \cap V U \cap V x \in u \cap V z \in U \cap V x \in u z \in U zx z^{-1} \in u x \in V z \in V zxz^{-1} \in V zxz^{-1} \in u \cap V u \cap V U \cap V U \cap v U \cap V \frac{U \cap V}{(u \cap V)(U \cap v)} u(U \cap v), u(U \cap V), (u \cap V)v (U \cap V)v U \cap v u U u(U \cap v) u(U \cap V) u(U \cap v) u(U \cap V) (u \cap V)v (U \cap V)v f \colon u(U \cap V) \to \frac{U \cap V}{(u \cap V)(U \cap v)} ab \mapsto b(U \cap v)(u \cap V) a \in u b \in U \cap v a' \in u b' \in U \cap V a'b' = ab a^{-1}a' = bb'^{-1} a^{-1}a' \in u bb'^{-1} \in U \cap V a^{-1}a' = bb'^{-1} u \cap (U \cap V) = u \cap V \subseteq (u \cap V)( U \cap v) f(a'b') f(ab) f(a'b') = f(ab) f a, \alpha \in u b, \beta \in U \cap V f(ab \alpha \beta) = f(ab) f(\alpha \beta) b \alpha b^{-1} = \alpha' \in u \alpha = b^{-1} \alpha' b ab \alpha \beta = ab b^{-1} \alpha' b \beta = a \alpha' b \beta f(ab \alpha \beta) = f(a \alpha' b \beta) = b \beta (u \cap V)(U \cap v) = f(ab) f(\alpha \beta) f x \in U \cap V f(ex) = x(u \cap V)(U \cap v) f ab \in u(U \cap V) f(ab) = (u \cap V)(U \cap v) a \in u b \in U \cap V b \in (u \cap V)(U \cap v) (u \cap V)(U \cap v) b = xy x u y U \cap v ab = axy = (ax)y \in u(U \cap v) \ker(f) \subseteq u(U \cap v) cd \in u(U \cap v) U \cap v \subset (u \cap V)(U \cap v) f(cd) = (u \cap V)(U \cap v) u(U \cap v) \subseteq \ker(f) \ker(f) = u(U \cap v) u(U \cap v) u(U \cap V) \frac{u(U \cap V)}{u(U \cap v)} \cong \frac{U \cap V}{(u \cap V)(U \cap v)} \frac{u(U \cap V)}{u(U \cap v)} \cong \frac{(U \cap V)v}{(u \cap V)v}","['abstract-algebra', 'group-theory', 'solution-verification', 'intuition']"
27,What is the point of Hecke $L$-series?,What is the point of Hecke -series?,L,"Let $K$ be a number field and $\mathcal{O}_K$ its ring of integers. For an integral ideal $\mathfrak{m} \subset \mathcal{O}_K$ we let $J^{\mathfrak{m}}$ be the group of fractional ideals coprime to $\mathfrak{m}$ . A Hecke character $(\textrm{mod}\ \mathfrak{m})$ is a group character $\chi: J^{\mathfrak{m}} \to S^1$ , satisfying some conditions. A generalised Dirichlet character $\chi: J^{\mathfrak{m}}/P^{\mathfrak{m}} \to S^1$ is any group character of the ray class group $J^{\mathfrak{m}}/P^{\mathfrak{m}}$ ; $P^{\mathfrak{m}}$ being the subgroup of principal ideals congruent to $1\ (\textrm{mod}\ \mathfrak{m})$ . In his Class Field Theory , J. Neukirch introduces only generalised Dirichlet $L$ -series, defined in terms of generalised Dirichlet characters. He uses these to prove: 1) The generalised Dirichlet density theorem. 2) That Artin $L$ -series of Abelian extensions are in fact generalised Dirichlet $L$ -series. Then in his Algebraic Number Theory , he chooses instead to work with Hecke $L$ -series, as opposed to generalised Dirichlet $L$ -series. But he does not seem to derive any new results using this more general definition. So my question is: What is the point of considering the more general Hecke $L$ -series, as opposed to just restricting one's attention to generalised Dirichlet $L$ -series?","Let be a number field and its ring of integers. For an integral ideal we let be the group of fractional ideals coprime to . A Hecke character is a group character , satisfying some conditions. A generalised Dirichlet character is any group character of the ray class group ; being the subgroup of principal ideals congruent to . In his Class Field Theory , J. Neukirch introduces only generalised Dirichlet -series, defined in terms of generalised Dirichlet characters. He uses these to prove: 1) The generalised Dirichlet density theorem. 2) That Artin -series of Abelian extensions are in fact generalised Dirichlet -series. Then in his Algebraic Number Theory , he chooses instead to work with Hecke -series, as opposed to generalised Dirichlet -series. But he does not seem to derive any new results using this more general definition. So my question is: What is the point of considering the more general Hecke -series, as opposed to just restricting one's attention to generalised Dirichlet -series?",K \mathcal{O}_K \mathfrak{m} \subset \mathcal{O}_K J^{\mathfrak{m}} \mathfrak{m} (\textrm{mod}\ \mathfrak{m}) \chi: J^{\mathfrak{m}} \to S^1 \chi: J^{\mathfrak{m}}/P^{\mathfrak{m}} \to S^1 J^{\mathfrak{m}}/P^{\mathfrak{m}} P^{\mathfrak{m}} 1\ (\textrm{mod}\ \mathfrak{m}) L L L L L L L,"['abstract-algebra', 'group-theory', 'number-theory', 'ring-theory', 'algebraic-number-theory']"
28,Definitions of a constant sheaf,Definitions of a constant sheaf,,"I am trying to understand local systems and the first step is to understand constant sheaves. I am confused, because I see different definitions used. For symplicity, I will ask about sheaves over $X$ with values in $\mathbb C$ . The constant presheaf is the sheaf $U \mapsto \mathbb C$ with restriction maps the identity. Its sheafification is called the constant sheaf. A sheaf is called a constant sheaf, if it is isomorphic to the constant sheaf (See on stacksproject) The sheaf of locally constant functions is called a constant sheaf The constant sheaf is a sheaf on X whose stalks are all equal to $\mathbb C$ . (Wikipedia) Here are my questions: First of all, 4. does not seem right to me, as it would imply that all line bundles are constant sheafs. Did I understand this correctly? Is the constant presheaf already a sheaf on reasonable spaces, for example on the interval? Are $2$ and $3$ equivalent? And most importantly, how can I show that a sheaf is a constant sheaf? My approach so far was to construct an isomorphism of sheaves to the sheaf whose restriction maps are all the identity. But as I know now, this was not an isomorphism of sheaves, only of pre-sheaves. I am rather new here, would it be better to ask the questions separately?","I am trying to understand local systems and the first step is to understand constant sheaves. I am confused, because I see different definitions used. For symplicity, I will ask about sheaves over with values in . The constant presheaf is the sheaf with restriction maps the identity. Its sheafification is called the constant sheaf. A sheaf is called a constant sheaf, if it is isomorphic to the constant sheaf (See on stacksproject) The sheaf of locally constant functions is called a constant sheaf The constant sheaf is a sheaf on X whose stalks are all equal to . (Wikipedia) Here are my questions: First of all, 4. does not seem right to me, as it would imply that all line bundles are constant sheafs. Did I understand this correctly? Is the constant presheaf already a sheaf on reasonable spaces, for example on the interval? Are and equivalent? And most importantly, how can I show that a sheaf is a constant sheaf? My approach so far was to construct an isomorphism of sheaves to the sheaf whose restriction maps are all the identity. But as I know now, this was not an isomorphism of sheaves, only of pre-sheaves. I am rather new here, would it be better to ask the questions separately?",X \mathbb C U \mapsto \mathbb C \mathbb C 2 3,"['abstract-algebra', 'algebraic-geometry', 'complex-geometry', 'sheaf-theory']"
29,Normalizer of group action,Normalizer of group action,,"Take a group $G$ acting faithfully on a set $X$ , and let $H \leq G$ . It can be easily shown that the elements of $N_{G}(H)$ stabilize the collection of orbits of $H$ (as a set, ie orbits are mapped to orbits). Is the converse true? That is, if we take $\mathcal{O}$ to be the collection of orbits of $H$ , do we always have that $\mathrm{Stab}_{G}(\mathcal{O}) = N_{G}(H)$ ? (I'm happy if everything is assumed to be finite, but more general answers are also welcome.) Edit: Since, as mentioned in the answer of runway44, this can be considered by looking at what happens with each of the $G$ -orbits on $X$ , I would like to know if this is true for $G$ acting transitively and faithfully on $X$ .","Take a group acting faithfully on a set , and let . It can be easily shown that the elements of stabilize the collection of orbits of (as a set, ie orbits are mapped to orbits). Is the converse true? That is, if we take to be the collection of orbits of , do we always have that ? (I'm happy if everything is assumed to be finite, but more general answers are also welcome.) Edit: Since, as mentioned in the answer of runway44, this can be considered by looking at what happens with each of the -orbits on , I would like to know if this is true for acting transitively and faithfully on .",G X H \leq G N_{G}(H) H \mathcal{O} H \mathrm{Stab}_{G}(\mathcal{O}) = N_{G}(H) G X G X,"['abstract-algebra', 'finite-groups', 'group-actions']"
30,What is the difference between an inner product space and an Algebra over a field?,What is the difference between an inner product space and an Algebra over a field?,,"From what I’ve gathered an algebra over a field is a vector space equipped with a bilinear form, and an inner product space is the same but that bilinear form satisfies certain extra axioms (symmetric, nondegenerate, etc.) . Is every inner product space an algebra? Are most typical algebras inner product spaces?","From what I’ve gathered an algebra over a field is a vector space equipped with a bilinear form, and an inner product space is the same but that bilinear form satisfies certain extra axioms (symmetric, nondegenerate, etc.) . Is every inner product space an algebra? Are most typical algebras inner product spaces?",,['abstract-algebra']
31,"The prime number theorem over a finite field - Lang's *Algebra*, Chapter V, Exercise 23(b)","The prime number theorem over a finite field - Lang's *Algebra*, Chapter V, Exercise 23(b)",,"This is Exercise 23(b) of Chapter V (Algebraic Extensions) from Lang's Algebra . Let $k$ be finite field with $q$ elements, and let $\pi_q(n)$ be the number of monic irreducible polynomials $p \in k[X]$ of degree $\leq n$ . Prove that $$ \pi_q(m) \sim \frac{q}{q-1} \frac{q^m}{m} \quad \text{for} \quad m \to \infty. $$ I have tried a few things but I'm not making any progress at all. The hint given in class was to take the logarithmic derivative of the zeta function that was defined in part (a) of the same problem. We defined the zeta function to be $$ Z(t) = (1-t)^{-1} \prod_p (1-t^{\deg p})^{-1}. $$ I computed this to be equal to the rational function $$ (1-t)^{-1}(1-qt)^{-1} $$ on the region $|t| < q^{-1}$ . Taking the logarithmic derivative of $Z(t)$ , I get $$ \frac{Z'(t)}{Z(t)} = \frac{1}{1-t} + \frac{q}{1-qt} = \frac{1+q-2qt}{(1-t)(1-qt)} = (1+q-2qt)Z(t). $$ I am not getting any further ideas at this point in how to use this to describe $\pi_q(n)$ . From Exercise 22 I know that if $\psi(d)$ denotes the number of monic irreducible polynomials of degree $d$ , then the total number of polynomials of degree $n$ , which is $q^n$ , can be expressed as $$ q^n = \sum_{d \mid n} d \psi(d). $$ Using the Möbius inversion formula, I can deduce that $$ n\psi(n) = \sum_{d \mid n} \mu(d) q^{n/d}, $$ where $\mu$ is the Möbius function. Since $\pi_q(m) = \sum_{k=1}^m \psi(k)$ , I can use the above equation to write $$ \pi_q(m) = \sum_{k=1}^m \frac{1}{k} \sum_{d \mid k} \mu(d) q^{k/d}. $$ My intuition is that the highest power of $q$ will dominate the sum, so the RHS is approximately $$ \frac{q^m}{m}, $$ so I get roughly what I'm asked to show in the problem. I'm having trouble refining my ideas any further. I have also looked at this question , which asks the same problem, but no answers or comments have been posted there. Lang remarks after stating the problem, ""This is the analogue of the prime number theorem in number theory, but it is essentially trivial in the present case, because the Riemann hypothesis is trivially verified."" I have tried looking at the proof of the prime number theorem on the internet, but I haven't really understood it; and I certainly can't see how to deduce it from the Riemann hypothesis even in this case. Any help in solving this problem would be appreciated.","This is Exercise 23(b) of Chapter V (Algebraic Extensions) from Lang's Algebra . Let be finite field with elements, and let be the number of monic irreducible polynomials of degree . Prove that I have tried a few things but I'm not making any progress at all. The hint given in class was to take the logarithmic derivative of the zeta function that was defined in part (a) of the same problem. We defined the zeta function to be I computed this to be equal to the rational function on the region . Taking the logarithmic derivative of , I get I am not getting any further ideas at this point in how to use this to describe . From Exercise 22 I know that if denotes the number of monic irreducible polynomials of degree , then the total number of polynomials of degree , which is , can be expressed as Using the Möbius inversion formula, I can deduce that where is the Möbius function. Since , I can use the above equation to write My intuition is that the highest power of will dominate the sum, so the RHS is approximately so I get roughly what I'm asked to show in the problem. I'm having trouble refining my ideas any further. I have also looked at this question , which asks the same problem, but no answers or comments have been posted there. Lang remarks after stating the problem, ""This is the analogue of the prime number theorem in number theory, but it is essentially trivial in the present case, because the Riemann hypothesis is trivially verified."" I have tried looking at the proof of the prime number theorem on the internet, but I haven't really understood it; and I certainly can't see how to deduce it from the Riemann hypothesis even in this case. Any help in solving this problem would be appreciated.","k q \pi_q(n) p \in k[X] \leq n 
\pi_q(m) \sim \frac{q}{q-1} \frac{q^m}{m} \quad \text{for} \quad m \to \infty.
 
Z(t) = (1-t)^{-1} \prod_p (1-t^{\deg p})^{-1}.
 
(1-t)^{-1}(1-qt)^{-1}
 |t| < q^{-1} Z(t) 
\frac{Z'(t)}{Z(t)} = \frac{1}{1-t} + \frac{q}{1-qt} = \frac{1+q-2qt}{(1-t)(1-qt)} = (1+q-2qt)Z(t).
 \pi_q(n) \psi(d) d n q^n 
q^n = \sum_{d \mid n} d \psi(d).
 
n\psi(n) = \sum_{d \mid n} \mu(d) q^{n/d},
 \mu \pi_q(m) = \sum_{k=1}^m \psi(k) 
\pi_q(m) = \sum_{k=1}^m \frac{1}{k} \sum_{d \mid k} \mu(d) q^{k/d}.
 q 
\frac{q^m}{m},
","['abstract-algebra', 'number-theory']"
32,$H$ is normal subgroup of $G$ iff $gHg^{-1}=H$ for every $g$ of $G$,is normal subgroup of  iff  for every  of,H G gHg^{-1}=H g G,"Given the following definition of normal subgroup A subgroup $H$ of a group $G$ is said to be normal if, for every $g\in G$: $$gH=Hg$$ I've tried to show that $H\mathrel{\unlhd} G$ if and only if we have $gHg^{-1}=H$ for every $g\in G$: (if) Let $H\mathrel{\unlhd} G$, $g\in G$; if $l\in gHg^{-1}$, there exists $h\in H$ such that $l=ghg^{-1}$ and since $gh$ = $h'g$ for some $h'\in H$, then $l=ghg^{-1}=h'(gg^{-1}) = h'\in H$. Let $h\in H$; we can write $h$ as $hgg^{-1}$, and since $hg = gh'$ for some $h'\in H$, we obtain $h = hgg^{-1} = gh'g^{-1}\in ghg^{-1}$. So $gHg^{-1}=H$. (only if) Let $gHg^{-1}=H$, $g\in G$; if we take an $l\in Hg$, $l = hg$ for some $h\in H$, we note immediately that $l=hg=(gh'g^{-1})g=gh'\in gH$. What should I do to show that $gH\subset Hg$ ? I'm also wondering if this mess is correct, and if it is possible a more elegant proof of this fact.","Given the following definition of normal subgroup A subgroup $H$ of a group $G$ is said to be normal if, for every $g\in G$: $$gH=Hg$$ I've tried to show that $H\mathrel{\unlhd} G$ if and only if we have $gHg^{-1}=H$ for every $g\in G$: (if) Let $H\mathrel{\unlhd} G$, $g\in G$; if $l\in gHg^{-1}$, there exists $h\in H$ such that $l=ghg^{-1}$ and since $gh$ = $h'g$ for some $h'\in H$, then $l=ghg^{-1}=h'(gg^{-1}) = h'\in H$. Let $h\in H$; we can write $h$ as $hgg^{-1}$, and since $hg = gh'$ for some $h'\in H$, we obtain $h = hgg^{-1} = gh'g^{-1}\in ghg^{-1}$. So $gHg^{-1}=H$. (only if) Let $gHg^{-1}=H$, $g\in G$; if we take an $l\in Hg$, $l = hg$ for some $h\in H$, we note immediately that $l=hg=(gh'g^{-1})g=gh'\in gH$. What should I do to show that $gH\subset Hg$ ? I'm also wondering if this mess is correct, and if it is possible a more elegant proof of this fact.",,['abstract-algebra']
33,The condition between $\chi(1)$ and $[G:H]$ which gives us a normal subgroup.,The condition between  and  which gives us a normal subgroup.,\chi(1) [G:H],"$\textbf{The question is as follows:}$ Let $H \le G$ with $|G : H| = n$ and suppose that $\chi \in Char(G)$. $\rm (a)$ Show that $[\chi ; \chi] \ge \frac{[\chi_H; \chi_H]}{n}$. $\rm (b)$ Show that, if $H$ is Abelian and $\chi \in Irr(G)$ then $\chi(1) \le n$. $\rm (c)$ Show that, if the equality holds in part (b), then $H \vartriangleleft G$. I can show the first part as follows: $\rm (a)$  We have $$|H| [\chi_H; \chi_H] = \sum_{h \in H}^{} |\chi(h)|^2 \le \sum_{g \in G}^{}|\chi(g)|^2 = |G|[\chi, \chi] $$ $\rm (b)$ For second part I can write $$\chi(1)=\chi|_H(1)\le [\chi|_H,\chi|_G]\le [G:H][\chi,\chi]=[G:H]$$ But I am not sure if it is correct? Can someone correct me please? $\rm (c)$  For the third part I still have no idea so far! Can someone help me to show this, please? Thanks!","$\textbf{The question is as follows:}$ Let $H \le G$ with $|G : H| = n$ and suppose that $\chi \in Char(G)$. $\rm (a)$ Show that $[\chi ; \chi] \ge \frac{[\chi_H; \chi_H]}{n}$. $\rm (b)$ Show that, if $H$ is Abelian and $\chi \in Irr(G)$ then $\chi(1) \le n$. $\rm (c)$ Show that, if the equality holds in part (b), then $H \vartriangleleft G$. I can show the first part as follows: $\rm (a)$  We have $$|H| [\chi_H; \chi_H] = \sum_{h \in H}^{} |\chi(h)|^2 \le \sum_{g \in G}^{}|\chi(g)|^2 = |G|[\chi, \chi] $$ $\rm (b)$ For second part I can write $$\chi(1)=\chi|_H(1)\le [\chi|_H,\chi|_G]\le [G:H][\chi,\chi]=[G:H]$$ But I am not sure if it is correct? Can someone correct me please? $\rm (c)$  For the third part I still have no idea so far! Can someone help me to show this, please? Thanks!",,"['abstract-algebra', 'group-theory', 'finite-groups', 'characters']"
34,Understanding the Proof that Algebraic Integers are a Subring of $\Bbb{C}$,Understanding the Proof that Algebraic Integers are a Subring of,\Bbb{C},"The set $\Bbb{A}$ of all the algebraic integers is a subring of $\Bbb{C}$ Here is an excerpt from my book: Suppose $\alpha$ an $\beta$ are algebraic integers; let $\alpha$ be the root of a monic $f(x) \in \Bbb{Z}[x]$ of degree $n$, and let $\beta$ be a root of a monic $g(x) \in \Bbb{Z}[x]$ of degree $m$. Now $\Bbb{Z}[\alpha \beta]$ is an additive subgroup of $G= \langle \alpha^i \beta^j ~|~ 0 \le i < n$, ~ $0 \le j < m \rangle$. Since $G$ a finitely generated, so is its subgroup $\Bbb{Z}[\alpha \beta]$, and so $\alpha \beta$ is an algebraic integer. Similarly, $\Bbb{Z}[\alpha + \beta]$ is an additive subgroup of $\langle \alpha^i \beta^j ~|~ i+j \le n+m-1 \rangle$, and so $\alpha + \beta$ is also algebraic. I am having trouble seeing the two set inclusions, particularly because $\Bbb{Z}[\alpha] := \{g(\alpha) ~|~ g(x) \in \Bbb{Z}[x] \}$ and the degree of the polynomials in $\Bbb{Z}[x]$ is unbounded, while $G$ and the other set are built from (multivariable) polynomials of finite degree. Perhaps someone could make this more explicit. Also, what's the motivation for choosing $n+m-1$ as the upper bound for $i+j$, other than the fact that it works?","The set $\Bbb{A}$ of all the algebraic integers is a subring of $\Bbb{C}$ Here is an excerpt from my book: Suppose $\alpha$ an $\beta$ are algebraic integers; let $\alpha$ be the root of a monic $f(x) \in \Bbb{Z}[x]$ of degree $n$, and let $\beta$ be a root of a monic $g(x) \in \Bbb{Z}[x]$ of degree $m$. Now $\Bbb{Z}[\alpha \beta]$ is an additive subgroup of $G= \langle \alpha^i \beta^j ~|~ 0 \le i < n$, ~ $0 \le j < m \rangle$. Since $G$ a finitely generated, so is its subgroup $\Bbb{Z}[\alpha \beta]$, and so $\alpha \beta$ is an algebraic integer. Similarly, $\Bbb{Z}[\alpha + \beta]$ is an additive subgroup of $\langle \alpha^i \beta^j ~|~ i+j \le n+m-1 \rangle$, and so $\alpha + \beta$ is also algebraic. I am having trouble seeing the two set inclusions, particularly because $\Bbb{Z}[\alpha] := \{g(\alpha) ~|~ g(x) \in \Bbb{Z}[x] \}$ and the degree of the polynomials in $\Bbb{Z}[x]$ is unbounded, while $G$ and the other set are built from (multivariable) polynomials of finite degree. Perhaps someone could make this more explicit. Also, what's the motivation for choosing $n+m-1$ as the upper bound for $i+j$, other than the fact that it works?",,"['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
35,Linear independence of Galois conjugates,Linear independence of Galois conjugates,,"Suppose we have an irreducible degree $n$ polynomial in $\mathbb{F}_{q}[x]$ whose roots $$ \alpha, \alpha^q, \alpha^{q^2}, \dots, \alpha^{q^{n-1}} $$ over the extension field $\mathbb{F}_{q^n}$ do not form a normal basis. If we consider the roots as elements of the vector space over $\mathbb{F}_q$ with basis $\{1,\alpha,\alpha^2,\dots,\alpha^{n-1}\}$, is there a minimum number of these roots which must be linearly independent? For example, take $f(x)=x^3+2x+1$. Over $\mathbb{F}_{3^3}$ viewed as a vector space with basis $\{1,\alpha,\alpha^2\}$, the set of roots $\{\alpha,\alpha^3\}$ is linearly independent but once we add the third root, we find that $\alpha^{3^2} = 2\alpha+2\alpha^3$.","Suppose we have an irreducible degree $n$ polynomial in $\mathbb{F}_{q}[x]$ whose roots $$ \alpha, \alpha^q, \alpha^{q^2}, \dots, \alpha^{q^{n-1}} $$ over the extension field $\mathbb{F}_{q^n}$ do not form a normal basis. If we consider the roots as elements of the vector space over $\mathbb{F}_q$ with basis $\{1,\alpha,\alpha^2,\dots,\alpha^{n-1}\}$, is there a minimum number of these roots which must be linearly independent? For example, take $f(x)=x^3+2x+1$. Over $\mathbb{F}_{3^3}$ viewed as a vector space with basis $\{1,\alpha,\alpha^2\}$, the set of roots $\{\alpha,\alpha^3\}$ is linearly independent but once we add the third root, we find that $\alpha^{3^2} = 2\alpha+2\alpha^3$.",,"['abstract-algebra', 'field-theory', 'finite-fields', 'extension-field']"
36,How to solve for a variable in an equation that involves XOR?,How to solve for a variable in an equation that involves XOR?,,"I was recently introduced to XOR and other bitwise operators while reading up some articles on C++. The concept seems rather simple but can be confusing because it involves visualizing numbers in binary. I ran into an equation that involves XOR sometime while I was looking up some real-world examples people use for encryption. I was baffled at the equation, and wanted to learn how to solve it. Here is the equation: $y = (x * (i+A)+B) \oplus (x*i+C)$ I am trying to solve for x in the equation, with all other variables being known at the time of the solve. Variables A, B, and C remain constant at all times, with y, x, and i changing. This can simplify the equation to: $y = (x * (i+32757935)-29408451) \oplus (x*i-5512095)$ I would like to learn how to solve this equation for x, and many others similar to this in the future as well. As such, I want to have some pointers on how to solve it. I remember reading up that splitting the equation into a system of linear equations in modulo 2 is the way to go, but I do not know how to do that. I've read up about the rules about XOR and such, but I'm not sure how I should go about creating a system, and solving it. Note: All variables are unsigned 32-bit integers $\oplus$ is the XOR operation","I was recently introduced to XOR and other bitwise operators while reading up some articles on C++. The concept seems rather simple but can be confusing because it involves visualizing numbers in binary. I ran into an equation that involves XOR sometime while I was looking up some real-world examples people use for encryption. I was baffled at the equation, and wanted to learn how to solve it. Here is the equation: $y = (x * (i+A)+B) \oplus (x*i+C)$ I am trying to solve for x in the equation, with all other variables being known at the time of the solve. Variables A, B, and C remain constant at all times, with y, x, and i changing. This can simplify the equation to: $y = (x * (i+32757935)-29408451) \oplus (x*i-5512095)$ I would like to learn how to solve this equation for x, and many others similar to this in the future as well. As such, I want to have some pointers on how to solve it. I remember reading up that splitting the equation into a system of linear equations in modulo 2 is the way to go, but I do not know how to do that. I've read up about the rules about XOR and such, but I'm not sure how I should go about creating a system, and solving it. Note: All variables are unsigned 32-bit integers $\oplus$ is the XOR operation",,"['abstract-algebra', 'computer-science', 'binary', 'computational-mathematics']"
37,What are the group homomorphisms from $ \prod_ {n \in \mathbb {N}} \mathbb {Z} / \bigoplus_ {n \in \mathbb {N}} \mathbb {Z} $ to $ \mathbb {Z} $?,What are the group homomorphisms from  to ?, \prod_ {n \in \mathbb {N}} \mathbb {Z} / \bigoplus_ {n \in \mathbb {N}} \mathbb {Z}   \mathbb {Z} ,"By a theorem of Specker, there’s only the zero map since any map out of $ \prod_{n \in \mathbb{N}} \mathbb{Z} $ is determined by the values of the unit vectors, which all lie in $ \bigoplus_{n \in \mathbb{N}} \mathbb{Z} $, but the original proof is more general, uses a bunch of machinery, and in German. Isn’t there an easier way?","By a theorem of Specker, there’s only the zero map since any map out of $ \prod_{n \in \mathbb{N}} \mathbb{Z} $ is determined by the values of the unit vectors, which all lie in $ \bigoplus_{n \in \mathbb{N}} \mathbb{Z} $, but the original proof is more general, uses a bunch of machinery, and in German. Isn’t there an easier way?",,"['abstract-algebra', 'group-theory']"
38,Lang-Nishimura theorem still carries through or fails when assumptions are dropped?,Lang-Nishimura theorem still carries through or fails when assumptions are dropped?,,"Theorem (Lang-Nishimura). Let $X \,-\!\!\rightarrow Y$ be a rational map between $k$-varieties, where $Y$ is proper. If $X$ has a smooth $k$-point, then $Y$ has a $k$-point. Does the theorem of Lang-Nishimura still hold if any of the following changes are made? The assumption that $Y$ is proper is dropped. The given $k$-point on $X$ is not assumed to be smooth. Thanks in advance!","Theorem (Lang-Nishimura). Let $X \,-\!\!\rightarrow Y$ be a rational map between $k$-varieties, where $Y$ is proper. If $X$ has a smooth $k$-point, then $Y$ has a $k$-point. Does the theorem of Lang-Nishimura still hold if any of the following changes are made? The assumption that $Y$ is proper is dropped. The given $k$-point on $X$ is not assumed to be smooth. Thanks in advance!",,"['abstract-algebra', 'number-theory']"
39,Galois group of $x^5-5x+10$,Galois group of,x^5-5x+10,"I was illustrating the theorem on solvability by radicals through some examples of degree $5$ polynomials. One I chose was $x^5-5x+10$. I was (perhaps wrongly) going to prove that the Galos group is $S_5$, with expectation that it has exactly three real roots . However, it has exactly one real root (which I saw by looking graph of this polynomial in $\mathbb{R}^2$ using some online software). Then I get stucked, and couldn't completely find the Galois group of this polynomial. How do we proceed to determine the Galois group of this polynomial over $\mathbb{Q}$?","I was illustrating the theorem on solvability by radicals through some examples of degree $5$ polynomials. One I chose was $x^5-5x+10$. I was (perhaps wrongly) going to prove that the Galos group is $S_5$, with expectation that it has exactly three real roots . However, it has exactly one real root (which I saw by looking graph of this polynomial in $\mathbb{R}^2$ using some online software). Then I get stucked, and couldn't completely find the Galois group of this polynomial. How do we proceed to determine the Galois group of this polynomial over $\mathbb{Q}$?",,"['abstract-algebra', 'field-theory', 'galois-theory']"
40,Are all quintic polynomials of this type not solvable by radicals?,Are all quintic polynomials of this type not solvable by radicals?,,The author of my textbook argues that the quintic polynomial $3x^5-15x+5$ is not solvable by radicals over $\mathbb{Q}$ by showing that the Galois group of $3x^5-15x+5$ over $\mathbb{Q}$ is isomorphic to $S_{5}$ (which is not solvable). But the argument given would seemingly apply to any quintic polynomial with integer coefficients that is irreducible over $\mathbb{Q}$ and has 3 distinct real roots and 2 non-real complex roots. Are all quintic polynomials of this type not solvable by radicals?,The author of my textbook argues that the quintic polynomial $3x^5-15x+5$ is not solvable by radicals over $\mathbb{Q}$ by showing that the Galois group of $3x^5-15x+5$ over $\mathbb{Q}$ is isomorphic to $S_{5}$ (which is not solvable). But the argument given would seemingly apply to any quintic polynomial with integer coefficients that is irreducible over $\mathbb{Q}$ and has 3 distinct real roots and 2 non-real complex roots. Are all quintic polynomials of this type not solvable by radicals?,,"['abstract-algebra', 'polynomials', 'field-theory', 'galois-theory']"
41,"If groups $G$ and $H$ act on $X$, does $G\times H$ act on $X$?","If groups  and  act on , does  act on ?",G H X G\times H X,"Suppose two groups $G$ and $H$ act on a set $X$ . What is the group action of $G\times H$ on $X$ ? From the actions there a homomorphisms $\varphi\colon G\to S_X$ and $\psi\colon H\to S_X$ . So this induces a homomorphism from the coproduct $\Phi\colon G\times H\to S_X$ , so there should be an action. Identifying $G$ and $H$ with the subgroups $\{(g,e):g\in G\}$ and $\{(e,h):h\in H\}$ by the inclusions into the coproduct, it seems $(g,e)$ should act as $g$ , and $(e,h)$ should act as $h$ , as $\Phi(g,e)=\varphi(g)$ and $\Phi(e,h)=\psi(h)$ . Since $(g,h)=(g,e)(e,h)$ , it seems like $(g,h)$ should act as $g\cdot (h\cdot x)$ . My concern was that $$ ((g_1,h_1)(g_2,h_2))\cdot x=(g_1g_2,h_1h_2)\cdot x=g_1g_2\cdot(h_1h_2\cdot x) $$ but $$ (g_1,h_2)\cdot((g_2,h_2)\cdot x)=g_1\cdot(h_1\cdot(g_2\cdot (h_2\cdot x)) $$ If the actions of $G$ and $H$ ""commute,"" this seems like it would be okay, since $$ \psi(h)\varphi(g)=\Phi(e,h)\Phi(g,e)=\Phi((e,h)(g,e))=\Phi(g,h)=\Phi((g,e)(e,h))=\varphi(g)\psi(h) $$ but this makes it seem like any two group actions on $X$ commute, which doesn't sound like it should be true. Have I made an error somewhere? Edit: I made a mistake and used the incorrect coproduct. But it seems like there is at least an action if the actions of $G$ and $H$ commute. Motivation: I have $G$ and $H$ acting on a ring $X$ , and I'm looking at the fixed points $X^{G\times H}$ , but I'm not sure what the action of $G\times H$ should be.","Suppose two groups and act on a set . What is the group action of on ? From the actions there a homomorphisms and . So this induces a homomorphism from the coproduct , so there should be an action. Identifying and with the subgroups and by the inclusions into the coproduct, it seems should act as , and should act as , as and . Since , it seems like should act as . My concern was that but If the actions of and ""commute,"" this seems like it would be okay, since but this makes it seem like any two group actions on commute, which doesn't sound like it should be true. Have I made an error somewhere? Edit: I made a mistake and used the incorrect coproduct. But it seems like there is at least an action if the actions of and commute. Motivation: I have and acting on a ring , and I'm looking at the fixed points , but I'm not sure what the action of should be.","G H X G\times H X \varphi\colon G\to S_X \psi\colon H\to S_X \Phi\colon G\times H\to S_X G H \{(g,e):g\in G\} \{(e,h):h\in H\} (g,e) g (e,h) h \Phi(g,e)=\varphi(g) \Phi(e,h)=\psi(h) (g,h)=(g,e)(e,h) (g,h) g\cdot (h\cdot x) 
((g_1,h_1)(g_2,h_2))\cdot x=(g_1g_2,h_1h_2)\cdot x=g_1g_2\cdot(h_1h_2\cdot x)
 
(g_1,h_2)\cdot((g_2,h_2)\cdot x)=g_1\cdot(h_1\cdot(g_2\cdot (h_2\cdot x))
 G H 
\psi(h)\varphi(g)=\Phi(e,h)\Phi(g,e)=\Phi((e,h)(g,e))=\Phi(g,h)=\Phi((g,e)(e,h))=\varphi(g)\psi(h)
 X G H G H X X^{G\times H} G\times H","['abstract-algebra', 'group-theory', 'group-actions', 'symmetric-groups', 'direct-product']"
42,Why do roots span dual space of maximal toral subalgebra?,Why do roots span dual space of maximal toral subalgebra?,,"Suppose $\Phi$ is the root system of a semi simple Lie algebra with maximal toral subalgebra $H$. I read that $\Phi$ spans $H^\ast$. The Killing form on $H$ is nondegenerate, so $H\cong H^\ast$ by identifying $\phi\in H^\ast$ with the unique $t_\phi$ such that $\phi(t)=\kappa(t_\phi,t)$. Every proof is by contradiction, beginning by saying if $\Phi$ does not span $H^\ast$, then there exists nonzero $h\in H$ such that $\alpha(h)=0$ for all $\alpha\in\Phi$. I understand the proof except for this line. Can anybody clarify why such $h$ must exist?","Suppose $\Phi$ is the root system of a semi simple Lie algebra with maximal toral subalgebra $H$. I read that $\Phi$ spans $H^\ast$. The Killing form on $H$ is nondegenerate, so $H\cong H^\ast$ by identifying $\phi\in H^\ast$ with the unique $t_\phi$ such that $\phi(t)=\kappa(t_\phi,t)$. Every proof is by contradiction, beginning by saying if $\Phi$ does not span $H^\ast$, then there exists nonzero $h\in H$ such that $\alpha(h)=0$ for all $\alpha\in\Phi$. I understand the proof except for this line. Can anybody clarify why such $h$ must exist?",,"['abstract-algebra', 'representation-theory', 'lie-algebras']"
43,Proving a ring is Noetherian when all maximal ideals are principal generated by idempotents,Proving a ring is Noetherian when all maximal ideals are principal generated by idempotents,,"Let $R$ be a commutative ring with unity such that all maximal ideals are of the form $(r)$ where $r\in R$ and $r^2=r$. I wish to show that $R$ is Noetherian. I know that if all prime (or primary) ideals in $R$ are finitely generated, then $R$ is Noetherian, so my plan was to show that all prime or primary ideals in $R$ are maximal and therefore of the above form (finitely generated), but I seem to be missing what exactly I should do to show that. Any help is appreciated!","Let $R$ be a commutative ring with unity such that all maximal ideals are of the form $(r)$ where $r\in R$ and $r^2=r$. I wish to show that $R$ is Noetherian. I know that if all prime (or primary) ideals in $R$ are finitely generated, then $R$ is Noetherian, so my plan was to show that all prime or primary ideals in $R$ are maximal and therefore of the above form (finitely generated), but I seem to be missing what exactly I should do to show that. Any help is appreciated!",,"['abstract-algebra', 'commutative-algebra', 'noetherian']"
44,Tensor product of (general?) groups,Tensor product of (general?) groups,,I am starting to learn about tensor products of abelian groups. Why is the tensor product defined for abelian groups? In which part of the construction the commutativity of the groups is needed?,I am starting to learn about tensor products of abelian groups. Why is the tensor product defined for abelian groups? In which part of the construction the commutativity of the groups is needed?,,"['abstract-algebra', 'group-theory']"
45,Is the number of associative $n$-ary algebraic operations on a finite set with 2 cardinality always 8?,Is the number of associative -ary algebraic operations on a finite set with 2 cardinality always 8?,n,"We know that if $n = 2$ then the operation is called a binary operation. $ \circ $ on set $X$ is a function $\circ : X \times X \rightarrow X$. And the number of all associative binary operation on a finite set $X=\{1, 2\}$ with $|X|=2$ cardinality, is 8. They are: $$1)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  1&  \\        &  1&  1& \end{array}  2)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  1&  \\        &  1&  2& \end{array}  3)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  1&  \\        &  2&  2& \end{array}  4)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  2&  \\        &  1&  2& \end{array}$$  $$5)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  2&  1&  \\        &  1&  2& \end{array}  6)                          \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  2&  \\        &  2&  1& \end{array}  7)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  2&  \\        &  2&  2& \end{array} 8)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  2&  2&  \\        &  2&  2& \end{array} $$ $$1,2 \in \mathbb X$$ Also I made a program which counts associative operations when $n=3$, I mean it counts ternary associative operations based on this condition:  $a \circ b \circ (c \circ d \circ e) = a \circ (b \circ c \circ d) \circ e = (a \circ b \circ c) \circ d \circ e$ Where $ \circ $ on set $X$ is a function $\circ : X \times X \times X \rightarrow X$. Also $a,b,c,d,e \in \mathbb X$ and when cardinality equals $|X|=2$ .I mean when $X=\{1, 2\}$ it showed me only 8 associative operations. They are: $$1)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  1&   &   1& \\        &  1&   &   1&     \\       &   &  1&   &   1& \\        &  1&   &   1& \end{array}  2)  \begin{array}{c|ccccc} \circ &  &  &  &          \\ \hline       &   &  1&   &   1&  \\        &  1&   &   1&      \\       &   &  1&   &   2&  \\        &  1&   &   1& \end{array}  3)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   2& \\        &  1&   &   1&     \\       &   &  2&   &   2& \\        &  1&   &   1& \end{array}  4)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  1&   &   2& \\        &  1&   &   2&     \\       &   &  1&   &   2& \\        &  1&   &   2& \end{array} $$ $$5)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   1& \\        &  1&   &   2&     \\       &   &  1&   &   2& \\        &  2&   &   1& \end{array}  6)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   2& \\        &  1&   &   2&     \\       &   &  2&   &   2& \\        &  2&   &   2& \end{array}  7)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  1&   &   2& \\        &  2&   &   1&     \\       &   &  2&   &   1& \\        &  1&   &   2& \end{array}  8)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   2& \\        &  2&   &   2&     \\       &   &  2&   &   2& \\        &  2&   &   2& \end{array} $$ So in this case I wrote result from arguments of a ternary operations in a cubic matrices as called in a tensors. Things will get even more difficult when $n = 4$. I wrote such a program also based on this condition: $$a \circ b \circ c \circ (d \circ e \circ f \circ g) = a \circ b \circ (c \circ d \circ e \circ f) \circ g = a \circ (b \circ c \circ d \circ e) \circ f \circ g = (a \circ b \circ c \circ d) \circ e \circ f \circ g$$ Where $ \circ $ on set $X$ is a function $\circ : X \times X \times X \times X \rightarrow X$. Also $a,b,c,d,e,f,g \in \mathbb X$ and when cardinality equals $|X|=2$ .I mean when $X=\{1, 2\}$ it showed me only 8 associative operations. They are: $$1)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                            \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\       &   &   &   &   &   &   1&   &   1&               \\        &   &   &   &   &   1&   &   1&                   \\          &   &   &   &   &   &   1&   &   1&               \\        &   &   &   &   &   1&   &   1&                   \\       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\ \end{array}  2)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                             \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  1&  \\        &  1&   &   &   &   &   &   &   &   &   &   1&     \\       &   &   &   &   &   &   1&   &   1&                \\        &   &   &   &   &   1&   &   1&                    \\          &   &   &   &   &   &   1&   &   2&                \\        &   &   &   &   &   1&   &   1&                    \\       &   &  1&   &   &   &   &   &   &   &   &   &  1&  \\        &  1&   &   &   &   &   &   &   &   &   &   1&     \\ \end{array} $$ ............................................................................................................................................................. $$3)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                            \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\       &   &   &   &   &   &   2&   &   2&               \\        &   &   &   &   &   2&   &   2&                   \\          &   &   &   &   &   &   2&   &   2&               \\        &   &   &   &   &   2&   &   2&                   \\       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\ \end{array}  4)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                            \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  2& \\        &  1&   &   &   &   &   &   &   &   &   &   2&    \\       &   &   &   &   &   &   1&   &   2&               \\        &   &   &   &   &   1&   &   2&                   \\          &   &   &   &   &   &   1&   &   2&               \\        &   &   &   &   &   1&   &   2&                   \\       &   &  1&   &   &   &   &   &   &   &   &   &  2& \\        &  1&   &   &   &   &   &   &   &   &   &   2&    \\ \end{array}$$ ............................................................................................................................................................. $$5)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                               \\ \hline       &   &  2&   &   &   &   &   &   &   &   &   &  1&    \\        &  1&   &   &   &   &   &   &   &   &   &   2&       \\       &   &   &   &   &   &   1&   &   2&                  \\        &   &   &   &   &   2&   &   1&                      \\          &   &   &   &   &   &   2&   &   1&                  \\        &   &   &   &   &   1&   &   2&                      \\       &   &  1&   &   &   &   &   &   &   &   &   &  2&    \\        &  2&   &   &   &   &   &   &   &   &   &   1&       \\ \end{array}  6)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                              \\ \hline       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  1&   &   &   &   &   &   &   &   &   &   2&      \\       &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\          &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  2&   &   &   &   &   &   &   &   &   &   2&      \\ \end{array} $$ ............................................................................................................................................................. $$7)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                                \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  2&     \\        &  2&   &   &   &   &   &   &   &   &   &   1&        \\       &   &   &   &   &   &   2&   &   1&                   \\        &   &   &   &   &   1&   &   2&                       \\          &   &   &   &   &   &   1&   &   2&                   \\        &   &   &   &   &   2&   &   1&                       \\       &   &  2&   &   &   &   &   &   &   &   &   &  1&     \\        &  1&   &   &   &   &   &   &   &   &   &   2&        \\ \end{array}  8)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                              \\ \hline       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  2&   &   &   &   &   &   &   &   &   &   2&      \\       &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\          &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  2&   &   &   &   &   &   &   &   &   &   2&      \\ \end{array} $$ So in this case I wrote result from arguments of operations in a Hypercube as called in a ""Tesseract"" in order to see it more easily. I did not tried it when $n = 5$ because we will have $2^{(2^5)} = 4294967296 $ algebraic operations and to check it`s associative property it takes a long time! Will it be again 8 if $n = 5$? So my question is: If this my program tells me true, then how to prove it using only math, I mean without programming, that the number of all associative $n$-ary algebraic operations on a finite set with 2 cardinality will be always 8?","We know that if $n = 2$ then the operation is called a binary operation. $ \circ $ on set $X$ is a function $\circ : X \times X \rightarrow X$. And the number of all associative binary operation on a finite set $X=\{1, 2\}$ with $|X|=2$ cardinality, is 8. They are: $$1)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  1&  \\        &  1&  1& \end{array}  2)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  1&  \\        &  1&  2& \end{array}  3)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  1&  \\        &  2&  2& \end{array}  4)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  2&  \\        &  1&  2& \end{array}$$  $$5)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  2&  1&  \\        &  1&  2& \end{array}  6)                          \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  2&  \\        &  2&  1& \end{array}  7)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  1&  2&  \\        &  2&  2& \end{array} 8)  \begin{array}{c|ccccc} \circ &  &       \\ \hline       &  2&  2&  \\        &  2&  2& \end{array} $$ $$1,2 \in \mathbb X$$ Also I made a program which counts associative operations when $n=3$, I mean it counts ternary associative operations based on this condition:  $a \circ b \circ (c \circ d \circ e) = a \circ (b \circ c \circ d) \circ e = (a \circ b \circ c) \circ d \circ e$ Where $ \circ $ on set $X$ is a function $\circ : X \times X \times X \rightarrow X$. Also $a,b,c,d,e \in \mathbb X$ and when cardinality equals $|X|=2$ .I mean when $X=\{1, 2\}$ it showed me only 8 associative operations. They are: $$1)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  1&   &   1& \\        &  1&   &   1&     \\       &   &  1&   &   1& \\        &  1&   &   1& \end{array}  2)  \begin{array}{c|ccccc} \circ &  &  &  &          \\ \hline       &   &  1&   &   1&  \\        &  1&   &   1&      \\       &   &  1&   &   2&  \\        &  1&   &   1& \end{array}  3)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   2& \\        &  1&   &   1&     \\       &   &  2&   &   2& \\        &  1&   &   1& \end{array}  4)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  1&   &   2& \\        &  1&   &   2&     \\       &   &  1&   &   2& \\        &  1&   &   2& \end{array} $$ $$5)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   1& \\        &  1&   &   2&     \\       &   &  1&   &   2& \\        &  2&   &   1& \end{array}  6)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   2& \\        &  1&   &   2&     \\       &   &  2&   &   2& \\        &  2&   &   2& \end{array}  7)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  1&   &   2& \\        &  2&   &   1&     \\       &   &  2&   &   1& \\        &  1&   &   2& \end{array}  8)  \begin{array}{c|ccccc} \circ &  &  &  &         \\ \hline       &   &  2&   &   2& \\        &  2&   &   2&     \\       &   &  2&   &   2& \\        &  2&   &   2& \end{array} $$ So in this case I wrote result from arguments of a ternary operations in a cubic matrices as called in a tensors. Things will get even more difficult when $n = 4$. I wrote such a program also based on this condition: $$a \circ b \circ c \circ (d \circ e \circ f \circ g) = a \circ b \circ (c \circ d \circ e \circ f) \circ g = a \circ (b \circ c \circ d \circ e) \circ f \circ g = (a \circ b \circ c \circ d) \circ e \circ f \circ g$$ Where $ \circ $ on set $X$ is a function $\circ : X \times X \times X \times X \rightarrow X$. Also $a,b,c,d,e,f,g \in \mathbb X$ and when cardinality equals $|X|=2$ .I mean when $X=\{1, 2\}$ it showed me only 8 associative operations. They are: $$1)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                            \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\       &   &   &   &   &   &   1&   &   1&               \\        &   &   &   &   &   1&   &   1&                   \\          &   &   &   &   &   &   1&   &   1&               \\        &   &   &   &   &   1&   &   1&                   \\       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\ \end{array}  2)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                             \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  1&  \\        &  1&   &   &   &   &   &   &   &   &   &   1&     \\       &   &   &   &   &   &   1&   &   1&                \\        &   &   &   &   &   1&   &   1&                    \\          &   &   &   &   &   &   1&   &   2&                \\        &   &   &   &   &   1&   &   1&                    \\       &   &  1&   &   &   &   &   &   &   &   &   &  1&  \\        &  1&   &   &   &   &   &   &   &   &   &   1&     \\ \end{array} $$ ............................................................................................................................................................. $$3)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                            \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\       &   &   &   &   &   &   2&   &   2&               \\        &   &   &   &   &   2&   &   2&                   \\          &   &   &   &   &   &   2&   &   2&               \\        &   &   &   &   &   2&   &   2&                   \\       &   &  1&   &   &   &   &   &   &   &   &   &  1& \\        &  1&   &   &   &   &   &   &   &   &   &   1&    \\ \end{array}  4)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                            \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  2& \\        &  1&   &   &   &   &   &   &   &   &   &   2&    \\       &   &   &   &   &   &   1&   &   2&               \\        &   &   &   &   &   1&   &   2&                   \\          &   &   &   &   &   &   1&   &   2&               \\        &   &   &   &   &   1&   &   2&                   \\       &   &  1&   &   &   &   &   &   &   &   &   &  2& \\        &  1&   &   &   &   &   &   &   &   &   &   2&    \\ \end{array}$$ ............................................................................................................................................................. $$5)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                               \\ \hline       &   &  2&   &   &   &   &   &   &   &   &   &  1&    \\        &  1&   &   &   &   &   &   &   &   &   &   2&       \\       &   &   &   &   &   &   1&   &   2&                  \\        &   &   &   &   &   2&   &   1&                      \\          &   &   &   &   &   &   2&   &   1&                  \\        &   &   &   &   &   1&   &   2&                      \\       &   &  1&   &   &   &   &   &   &   &   &   &  2&    \\        &  2&   &   &   &   &   &   &   &   &   &   1&       \\ \end{array}  6)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                              \\ \hline       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  1&   &   &   &   &   &   &   &   &   &   2&      \\       &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\          &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  2&   &   &   &   &   &   &   &   &   &   2&      \\ \end{array} $$ ............................................................................................................................................................. $$7)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                                \\ \hline       &   &  1&   &   &   &   &   &   &   &   &   &  2&     \\        &  2&   &   &   &   &   &   &   &   &   &   1&        \\       &   &   &   &   &   &   2&   &   1&                   \\        &   &   &   &   &   1&   &   2&                       \\          &   &   &   &   &   &   1&   &   2&                   \\        &   &   &   &   &   2&   &   1&                       \\       &   &  2&   &   &   &   &   &   &   &   &   &  1&     \\        &  1&   &   &   &   &   &   &   &   &   &   2&        \\ \end{array}  8)  \begin{array}{c|ccccc} \circ &  &  &  &  &  &  &  &                              \\ \hline       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  2&   &   &   &   &   &   &   &   &   &   2&      \\       &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\          &   &   &   &   &   &   2&   &   2&                 \\        &   &   &   &   &   2&   &   2&                     \\       &   &  2&   &   &   &   &   &   &   &   &   &  2&   \\        &  2&   &   &   &   &   &   &   &   &   &   2&      \\ \end{array} $$ So in this case I wrote result from arguments of operations in a Hypercube as called in a ""Tesseract"" in order to see it more easily. I did not tried it when $n = 5$ because we will have $2^{(2^5)} = 4294967296 $ algebraic operations and to check it`s associative property it takes a long time! Will it be again 8 if $n = 5$? So my question is: If this my program tells me true, then how to prove it using only math, I mean without programming, that the number of all associative $n$-ary algebraic operations on a finite set with 2 cardinality will be always 8?",,"['abstract-algebra', 'combinatorics', 'group-theory', 'binary-operations', 'associativity']"
46,"If $\{M_i\}_{i \in I}$ is a family of $R$-modules free, then the product $\prod_{i \in I}M_i$ is free?","If  is a family of -modules free, then the product  is free?",\{M_i\}_{i \in I} R \prod_{i \in I}M_i,"If $\{M_i\}_{i \in I}$ is a family of free $R$-modules, then $\bigoplus_{i \in I}M_i$ is free. Is this  true for the product $\prod_{i \in I}M_i$ too?","If $\{M_i\}_{i \in I}$ is a family of free $R$-modules, then $\bigoplus_{i \in I}M_i$ is free. Is this  true for the product $\prod_{i \in I}M_i$ too?",,"['abstract-algebra', 'commutative-algebra', 'modules']"
47,Showing that $x^n -2$ is irreducible in $\mathbb{Q}[X]$,Showing that  is irreducible in,x^n -2 \mathbb{Q}[X],"I'm trying to show that the polynomial $X^n -2$ ($n \in \mathbb{N}$) is irreducible in $\mathbb{Q}[X]$ but am a bit stuck. Methods I know to show irreducibility: Gauss' lemma - which says that if I can show it is irreducible in $\mathbb{Z}[X]$ then it will be irreducible in $\mathbb{Q}[X]$. This would allow me to check reduction modulo a prime. However this doesn't work in this case, because if I reduce mod 2, then the polynomial is just $X^n$ which is reducible. I'm also aware of Eisensteins criterion where I can check that if a prime divides all the coefficients but its square doesn't divide the constant coefficient, then it is irreducible. None of these methods are working for this polynomial so help would be much appreciated! Also are there any general methods to look out for when trying to show polynomials are irreducible? Thanks","I'm trying to show that the polynomial $X^n -2$ ($n \in \mathbb{N}$) is irreducible in $\mathbb{Q}[X]$ but am a bit stuck. Methods I know to show irreducibility: Gauss' lemma - which says that if I can show it is irreducible in $\mathbb{Z}[X]$ then it will be irreducible in $\mathbb{Q}[X]$. This would allow me to check reduction modulo a prime. However this doesn't work in this case, because if I reduce mod 2, then the polynomial is just $X^n$ which is reducible. I'm also aware of Eisensteins criterion where I can check that if a prime divides all the coefficients but its square doesn't divide the constant coefficient, then it is irreducible. None of these methods are working for this polynomial so help would be much appreciated! Also are there any general methods to look out for when trying to show polynomials are irreducible? Thanks",,"['abstract-algebra', 'ring-theory', 'irreducible-polynomials']"
48,Is the extension Galois if $\mathrm{Aut}(K)$ acts transitively on the non-ramified prime ideals?,Is the extension Galois if  acts transitively on the non-ramified prime ideals?,\mathrm{Aut}(K),"Let $K/\mathbb Q$ be a finite extension such that $\mathrm{Aut}(K)$ acts transitively on the prime ideals that are not ramified above the same prime $p\in\mathbb N$, for every $p$. Is $K$ Galois? Thanks in advance.","Let $K/\mathbb Q$ be a finite extension such that $\mathrm{Aut}(K)$ acts transitively on the prime ideals that are not ramified above the same prime $p\in\mathbb N$, for every $p$. Is $K$ Galois? Thanks in advance.",,"['abstract-algebra', 'number-theory', 'field-theory', 'algebraic-number-theory', 'galois-theory']"
49,"The cardinality of the group $\mathrm{SL}(k,\mathbb{Z}/n\mathbb{Z})$",The cardinality of the group,"\mathrm{SL}(k,\mathbb{Z}/n\mathbb{Z})","I want to calculate the cardinality of the group $\mathrm{SL}(k,\mathbb{Z}/n\mathbb{Z})$, $k,n \in \mathbb{N}$. When $n$ is prime, it is easy to calculate, so I want to know the general case.","I want to calculate the cardinality of the group $\mathrm{SL}(k,\mathbb{Z}/n\mathbb{Z})$, $k,n \in \mathbb{N}$. When $n$ is prime, it is easy to calculate, so I want to know the general case.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'modules', 'linear-groups']"
50,Why is factorization in the localization of a UFD actually unique?,Why is factorization in the localization of a UFD actually unique?,,"I was reading Arturo Magidin's answer here , which states that the localization of a UFD over a multiplicative subset not containing $0$ is still a UFD. It makes sense that a factorization into units and irreducibles exists, but I don't see uniqueness. He says it follows by cross multiplying and using the claims. Ok, I let $a/s\in S^{-1}D$. I can factor it into irreducibles $$ \frac{a}{s}=\frac{p_1}{s_1}\cdots\frac{p_n}{s_n}=\frac{q_1}{t_1}\cdots\frac{q_m}{t_m}. $$ If I crossmultiply I get different types of terms all over the place and don't know what to compare?","I was reading Arturo Magidin's answer here , which states that the localization of a UFD over a multiplicative subset not containing $0$ is still a UFD. It makes sense that a factorization into units and irreducibles exists, but I don't see uniqueness. He says it follows by cross multiplying and using the claims. Ok, I let $a/s\in S^{-1}D$. I can factor it into irreducibles $$ \frac{a}{s}=\frac{p_1}{s_1}\cdots\frac{p_n}{s_n}=\frac{q_1}{t_1}\cdots\frac{q_m}{t_m}. $$ If I crossmultiply I get different types of terms all over the place and don't know what to compare?",,['abstract-algebra']
51,"What is the order of $(\mathbb{Z} \oplus \mathbb{Z})/ \langle (2,2) \rangle$ and is it cyclic?",What is the order of  and is it cyclic?,"(\mathbb{Z} \oplus \mathbb{Z})/ \langle (2,2) \rangle","Evidently, $(\mathbb{Z} \oplus \mathbb{Z})/ \langle (2,2) \rangle$ has order $4$, but I think it's infinite. The four cosets are listed as $(0,0) +  \langle (2,2) \rangle$, $(0,1) +  \langle (2,2) \rangle$, $(1,0)+  \langle (2,2) \rangle$ and $(1,1) +  \langle (2,2) \rangle$. However, $(2,0)$ doesn't appear to be in any of these cosets. Maybe the answer I'm being told is wrong.","Evidently, $(\mathbb{Z} \oplus \mathbb{Z})/ \langle (2,2) \rangle$ has order $4$, but I think it's infinite. The four cosets are listed as $(0,0) +  \langle (2,2) \rangle$, $(0,1) +  \langle (2,2) \rangle$, $(1,0)+  \langle (2,2) \rangle$ and $(1,1) +  \langle (2,2) \rangle$. However, $(2,0)$ doesn't appear to be in any of these cosets. Maybe the answer I'm being told is wrong.",,"['abstract-algebra', 'group-theory']"
52,"$R$ is a ring with unity, and for each $a \in R$, there exists $x \in R$ such that $a^2x=a$. Show that $ax=xa$.","is a ring with unity, and for each , there exists  such that . Show that .",R a \in R x \in R a^2x=a ax=xa,"Let $R$ be a ring with unity. For each $a \in R$, there exists $x \in R$ such that $a^2x=a$. Show that $ax=xa$. I know that $R$ has no nonzero nilpotent elements and $axa=a$. Thus I tried to show that $$(ax-xa)^2=0$$ but I failed to show that. Thanks in advance.","Let $R$ be a ring with unity. For each $a \in R$, there exists $x \in R$ such that $a^2x=a$. Show that $ax=xa$. I know that $R$ has no nonzero nilpotent elements and $axa=a$. Thus I tried to show that $$(ax-xa)^2=0$$ but I failed to show that. Thanks in advance.",,"['abstract-algebra', 'ring-theory']"
53,characterization of projective/injective/flat modules via $\operatorname{Hom}$ and $\otimes$,characterization of projective/injective/flat modules via  and,\operatorname{Hom} \otimes,"Let $R$ be a commutative unital ring and $M$ an $R$-module. Then $M$ is projective iff $\operatorname{Hom}(M,-)$ is exact, injective iff $\operatorname{Hom}(-,M)$ is exact, and flat iff $M\otimes-$ is exact. Furthermore, $M$ is faithfully flat when every chain complex is exact iff the induced $M\otimes-$ chain complex is exact. Question 1: What are the modules with the property: every chain complex is exact iff the induced $\operatorname{Hom}(-,M)$ chain complex is exact; every chain complex is exact iff the induced $\operatorname{Hom}(M,-)$ chain complex is exact. Is there a notion faithfully projective/injective, and does it coincide with projective/injective? Question 2: Why is $M$ faithfully flat precisely when $(\ast)$ every map $A\to B$ is injective iff $A\!\otimes\!M\to B\!\otimes\!M$ is injective? I know that $-\!\otimes\!M$ is right exact, so it preserves epimorphisms, but if we assume $(\ast)$, how does $A\!\otimes\!M\to B\!\otimes\!M$ surjective imply $A\to B$ surjective?","Let $R$ be a commutative unital ring and $M$ an $R$-module. Then $M$ is projective iff $\operatorname{Hom}(M,-)$ is exact, injective iff $\operatorname{Hom}(-,M)$ is exact, and flat iff $M\otimes-$ is exact. Furthermore, $M$ is faithfully flat when every chain complex is exact iff the induced $M\otimes-$ chain complex is exact. Question 1: What are the modules with the property: every chain complex is exact iff the induced $\operatorname{Hom}(-,M)$ chain complex is exact; every chain complex is exact iff the induced $\operatorname{Hom}(M,-)$ chain complex is exact. Is there a notion faithfully projective/injective, and does it coincide with projective/injective? Question 2: Why is $M$ faithfully flat precisely when $(\ast)$ every map $A\to B$ is injective iff $A\!\otimes\!M\to B\!\otimes\!M$ is injective? I know that $-\!\otimes\!M$ is right exact, so it preserves epimorphisms, but if we assume $(\ast)$, how does $A\!\otimes\!M\to B\!\otimes\!M$ surjective imply $A\to B$ surjective?",,"['abstract-algebra', 'commutative-algebra', 'modules', 'homological-algebra']"
54,Question about a proof showing that the center of $S_n$ is trivial,Question about a proof showing that the center of  is trivial,S_n,"How do I need to modify this in order for it to be correct? The center of $S_n$ (for $n\geq$ 3) is the trivial identity. Proof: Assume the center of $S_n$ is $C = \{ id , \tau \}$ where $ \tau \in S_n$ and $\tau \neq \ id$. Then for some $n$ the factor group $S_n\backslash C$ is abelian and solvable, a contradiction.","How do I need to modify this in order for it to be correct? The center of $S_n$ (for $n\geq$ 3) is the trivial identity. Proof: Assume the center of $S_n$ is $C = \{ id , \tau \}$ where $ \tau \in S_n$ and $\tau \neq \ id$. Then for some $n$ the factor group $S_n\backslash C$ is abelian and solvable, a contradiction.",,"['abstract-algebra', 'group-theory', 'symmetric-groups', 'permutations']"
55,Rings in which every irreducible ideal is primary,Rings in which every irreducible ideal is primary,,"Suppose $R$ is a commutative ring with $1$. It is well-known that if $R$ is Noetherian, then every irreducible ideal is primary (Lemma 7.12 in Atiyah & Macdonald). Is the converse true? That is: If every irreducible ideal of $R$ is primary, then is it necessarily   true that $R$ is Noetherian? This is just to satisfy my own curiosity. :) Note the following related problem. There, the question is about different converse (which is false). Added. In order to make the post self-contained, I will add the relevant definitions. An ideal $\mathfrak{a}$ is called irreducible if $\mathfrak{a}=\mathfrak{b}\cap\mathfrak{c}$ implies $\mathfrak{a}=\mathfrak{b}$ or $\mathfrak{a}=\mathfrak{c}$. An ideal $\mathfrak{a}$ is called primary if $\mathfrak{a}\neq R$, and for all $x,y\in R$, $xy\in \mathfrak{a}$ implies $x\in\mathfrak{a}$ or $y^{n}\in\mathfrak{a}$ for some $n\in\mathbb{N}$.","Suppose $R$ is a commutative ring with $1$. It is well-known that if $R$ is Noetherian, then every irreducible ideal is primary (Lemma 7.12 in Atiyah & Macdonald). Is the converse true? That is: If every irreducible ideal of $R$ is primary, then is it necessarily   true that $R$ is Noetherian? This is just to satisfy my own curiosity. :) Note the following related problem. There, the question is about different converse (which is false). Added. In order to make the post self-contained, I will add the relevant definitions. An ideal $\mathfrak{a}$ is called irreducible if $\mathfrak{a}=\mathfrak{b}\cap\mathfrak{c}$ implies $\mathfrak{a}=\mathfrak{b}$ or $\mathfrak{a}=\mathfrak{c}$. An ideal $\mathfrak{a}$ is called primary if $\mathfrak{a}\neq R$, and for all $x,y\in R$, $xy\in \mathfrak{a}$ implies $x\in\mathfrak{a}$ or $y^{n}\in\mathfrak{a}$ for some $n\in\mathbb{N}$.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
56,If every nonzero element of $R$ is either a unit or a zero divisor then $R$ contains only finitely many ideals?,If every nonzero element of  is either a unit or a zero divisor then  contains only finitely many ideals?,R R,"Let $R$ be a commutative ring with $1$, if $R$ contains only finitely many ideals, then every nonzero element of $R$ is either a unit or a zero divisor. I know it's true. How about the converse? i.e. If every nonzero element of $R$ is either a unit or a zero divisor, then $R$ contains only finitely many ideals. Is it true? Can you give me an example about a commutative ring with $1$ that has infinitely many zero divisors? Thanks.","Let $R$ be a commutative ring with $1$, if $R$ contains only finitely many ideals, then every nonzero element of $R$ is either a unit or a zero divisor. I know it's true. How about the converse? i.e. If every nonzero element of $R$ is either a unit or a zero divisor, then $R$ contains only finitely many ideals. Is it true? Can you give me an example about a commutative ring with $1$ that has infinitely many zero divisors? Thanks.",,"['abstract-algebra', 'ring-theory']"
57,Group of order $p^2$ is abelian. [duplicate],Group of order  is abelian. [duplicate],p^2,"This question already has answers here : Showing group with $p^2$ elements is Abelian (12 answers) Closed 10 years ago . The community reviewed whether to reopen this question 9 months ago and left it closed: Original close reason(s) were not resolved Yes, I know that there are tons of solutions of this up here, but I, essentially, wanted to try it a different way and ah, well. Let $|G| = p^2$ for some prime $p$. Consider $x \in G$. So, $|x| = p, $ or $ p^2$. If it is the latter, then, we are done. So, if $|x|= p$, then, let, $H = [h|  h=x^i, i \in Z] \Rightarrow |H|= p$. As $p$ is the smallest prime dividing $|G|$, $H$ is a normal subgroup. Now, consider some $y \in G$, but not in $H \Rightarrow y^p= e$. Then, its easy to show that $G = \langle x,y \rangle$. Now, consider a homomorphism $f:G \rightarrow \operatorname{Aut}(H), g \to c_g $, wherein $c_g$ represents conjugacy by $g$. So, for example, $c_g(x) = gx g^{-1}$. Then, it is clear that, $H \subset \operatorname{Ker}(f) $, as it is cyclic and therefore abelian. So, we need only look at $G/H$. Basically, I am asking for a hint as to why $c_y(x) = yxy^{-1} = x = c_e(x)$, where $x$ and $y$ are the generators of $H$ and $G/H$, respectively? Because, if I establish it for the generators, then it follows that it applies for for all elements, i.e, that $\operatorname{Im}(f)$ is trivial and therefore that $G$ is abelian. Thank You!","This question already has answers here : Showing group with $p^2$ elements is Abelian (12 answers) Closed 10 years ago . The community reviewed whether to reopen this question 9 months ago and left it closed: Original close reason(s) were not resolved Yes, I know that there are tons of solutions of this up here, but I, essentially, wanted to try it a different way and ah, well. Let $|G| = p^2$ for some prime $p$. Consider $x \in G$. So, $|x| = p, $ or $ p^2$. If it is the latter, then, we are done. So, if $|x|= p$, then, let, $H = [h|  h=x^i, i \in Z] \Rightarrow |H|= p$. As $p$ is the smallest prime dividing $|G|$, $H$ is a normal subgroup. Now, consider some $y \in G$, but not in $H \Rightarrow y^p= e$. Then, its easy to show that $G = \langle x,y \rangle$. Now, consider a homomorphism $f:G \rightarrow \operatorname{Aut}(H), g \to c_g $, wherein $c_g$ represents conjugacy by $g$. So, for example, $c_g(x) = gx g^{-1}$. Then, it is clear that, $H \subset \operatorname{Ker}(f) $, as it is cyclic and therefore abelian. So, we need only look at $G/H$. Basically, I am asking for a hint as to why $c_y(x) = yxy^{-1} = x = c_e(x)$, where $x$ and $y$ are the generators of $H$ and $G/H$, respectively? Because, if I establish it for the generators, then it follows that it applies for for all elements, i.e, that $\operatorname{Im}(f)$ is trivial and therefore that $G$ is abelian. Thank You!",,"['abstract-algebra', 'group-theory', 'finite-groups']"
58,A Question on the Young Lattice and Young Tableaux,A Question on the Young Lattice and Young Tableaux,,"Let: $\lambda \vdash n$ be a partition of $n$ $f^\lambda$ - number of standard Young Tableaux of shape $\lambda$ $\succ$ - be the covering in the Young Lattice (that is, $\mu \succ \lambda$ iff $\mu$ is obtained by adding a single box to $\lambda$) Then I want to show: $$\frac{\sum_{\mu \succ \lambda}f^\mu}{f^\lambda}=n+1$$ This is the last step in a proof I've come up with showing the well-known relation $$\sum_{\lambda \vdash n}(f^\lambda)^2=n!$$ Can someone help verify that the former formula is true, and, if so, perhaps have ideas on how may I show it?","Let: $\lambda \vdash n$ be a partition of $n$ $f^\lambda$ - number of standard Young Tableaux of shape $\lambda$ $\succ$ - be the covering in the Young Lattice (that is, $\mu \succ \lambda$ iff $\mu$ is obtained by adding a single box to $\lambda$) Then I want to show: $$\frac{\sum_{\mu \succ \lambda}f^\mu}{f^\lambda}=n+1$$ This is the last step in a proof I've come up with showing the well-known relation $$\sum_{\lambda \vdash n}(f^\lambda)^2=n!$$ Can someone help verify that the former formula is true, and, if so, perhaps have ideas on how may I show it?",,"['abstract-algebra', 'combinatorics', 'symmetric-groups', 'lattice-orders', 'young-tableaux']"
59,$\operatorname{Aut}(\mathbb Z_8)$ is isomorphic to $\mathbb Z_2 \oplus\mathbb Z_2$,is isomorphic to,\operatorname{Aut}(\mathbb Z_8) \mathbb Z_2 \oplus\mathbb Z_2,"I'm trying to prove that $\operatorname{Aut}(\mathbb Z_8)$ is isomorphic to $\mathbb Z_2 \oplus\mathbb Z_2$ , but I have no idea how to prove it. First of all, I'm trying to prove that $\operatorname{Aut}(\mathbb Z_8)$ has four elements. Can I argue that because $\mathbb Z_8$ has four possibilities of generators, say $\bar 1$ , $\bar 3$ $\bar 5$ , $\bar 7$ , since each isomorphism is compleated determined by the image of its generators, then $\mathbb Z_8$ has four elements? I need help Thanks","I'm trying to prove that is isomorphic to , but I have no idea how to prove it. First of all, I'm trying to prove that has four elements. Can I argue that because has four possibilities of generators, say , , , since each isomorphism is compleated determined by the image of its generators, then has four elements? I need help Thanks",\operatorname{Aut}(\mathbb Z_8) \mathbb Z_2 \oplus\mathbb Z_2 \operatorname{Aut}(\mathbb Z_8) \mathbb Z_8 \bar 1 \bar 3 \bar 5 \bar 7 \mathbb Z_8,"['abstract-algebra', 'group-theory']"
60,Noncommutative Hilbert basis theorem is false?,Noncommutative Hilbert basis theorem is false?,,"How can I show that for a field $K$, in the free algebra on $2$ generators $K\langle x,y\rangle$, the two-sided ideal $$\big\langle\!\big\langle xy^ix\;\big|\;i\in\mathbb{N}\big\rangle\!\big\rangle =\bigg\{\sum_{i}g_ixy^ixh_i \;\bigg|\; i\in\mathbb{N},\, g_i,h_i\in K\langle x,y\rangle\bigg\}$$ is not generated by any finitely many $f_1,\ldots,f_k\!\in\!K\langle x,y\rangle$, if this is even true? If not, what other generators of the ideal must I take? Is there a simpler set of generators of an ideal that is not finitely generated?","How can I show that for a field $K$, in the free algebra on $2$ generators $K\langle x,y\rangle$, the two-sided ideal $$\big\langle\!\big\langle xy^ix\;\big|\;i\in\mathbb{N}\big\rangle\!\big\rangle =\bigg\{\sum_{i}g_ixy^ixh_i \;\bigg|\; i\in\mathbb{N},\, g_i,h_i\in K\langle x,y\rangle\bigg\}$$ is not generated by any finitely many $f_1,\ldots,f_k\!\in\!K\langle x,y\rangle$, if this is even true? If not, what other generators of the ideal must I take? Is there a simpler set of generators of an ideal that is not finitely generated?",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
61,The order of a conjugacy class is bounded by the index of the center,The order of a conjugacy class is bounded by the index of the center,,"If the center of a group $G$ is of index $n$ , prove that every conjugacy class has at most $n$ elements. (This question is from Dummit and Foote, page 130, 3rd edition.) Here is my attempt: we have $$   |G| = |C_G (g_i)| |G : C_G (g_i)| \,,   \quad   |C_G (g_i)| = |Z(G)| \cdot  |C_G (g_i):Z(G)| \,. $$ Then $$   |G| = |Z(G)| \cdot |C_G (g_i):Z(G)| \cdot |G : C_G (g_i)| \,. $$ Then $$   n = |C_G (g_i):Z(G)| \cdot |G : C_G (g_i)| \,. $$ But $|C_G (g_i):Z(G)|$ is a positive integer as $Z(G)$ is subgroup of $C_G (g_i)$ . If $|G : C_G (g_i)|$ bigger than $n$ , then $|C_G (g_i):Z(G)| \cdot |G : C_G (g_i)|$ is bigger than $n$ . But $|C_G (g_i):Z(G)| \cdot |G : C_G (g_i)| = n$ , contradiction. Then $|G : C_G (g_i)| \leq n$ and this completes the proof. Is this proof right or not?","If the center of a group is of index , prove that every conjugacy class has at most elements. (This question is from Dummit and Foote, page 130, 3rd edition.) Here is my attempt: we have Then Then But is a positive integer as is subgroup of . If bigger than , then is bigger than . But , contradiction. Then and this completes the proof. Is this proof right or not?","G n n 
  |G| = |C_G (g_i)| |G : C_G (g_i)| \,,
  \quad
  |C_G (g_i)| = |Z(G)| \cdot  |C_G (g_i):Z(G)| \,.
 
  |G| = |Z(G)| \cdot |C_G (g_i):Z(G)| \cdot |G : C_G (g_i)| \,.
 
  n = |C_G (g_i):Z(G)| \cdot |G : C_G (g_i)| \,.
 |C_G (g_i):Z(G)| Z(G) C_G (g_i) |G : C_G (g_i)| n |C_G (g_i):Z(G)| \cdot |G : C_G (g_i)| n |C_G (g_i):Z(G)| \cdot |G : C_G (g_i)| = n |G : C_G (g_i)| \leq n","['abstract-algebra', 'group-theory', 'group-actions']"
62,Nonabelian $p$-groups all of whose proper subgroups are abelian.,Nonabelian -groups all of whose proper subgroups are abelian.,p,"Theorem. Let $G$ be a finite, non-abelian $p$-group all of whose proper subgroups are abelian. Then $|G'|=p$. Take a counterexample of minimal order. Assume that exist a $H$  such that $1<H<G'$. Then (by $G'\leq \Phi (G) \leq Z(G)$) $H\vartriangleleft G$. From this we deduce we can assume $|G'|\leq p^2$. Then? How am I supposed to continue? Edit Additional infos $G'$ is elementary abelian since $G$ is Frattini-in-center.","Theorem. Let $G$ be a finite, non-abelian $p$-group all of whose proper subgroups are abelian. Then $|G'|=p$. Take a counterexample of minimal order. Assume that exist a $H$  such that $1<H<G'$. Then (by $G'\leq \Phi (G) \leq Z(G)$) $H\vartriangleleft G$. From this we deduce we can assume $|G'|\leq p^2$. Then? How am I supposed to continue? Edit Additional infos $G'$ is elementary abelian since $G$ is Frattini-in-center.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'p-groups']"
63,Maximal ideals of some localization of a commutative ring,Maximal ideals of some localization of a commutative ring,,"If $R$ is commutative ring, $P_1, P_2, \dots, P_n$ prime ideals of $R$ with the property $P_i \not\subseteq \bigcup _{j \not = i} P_j$, $\forall 1\le i\le n$, and $S:=R\setminus(P_1 \cup \cdots \cup P_n)$, then show: $$S^{-1}R \text{ has exactly } n \text{ maximal ideals}.$$ Definition. $S^{-1}R=${${r \over s} : r \in R , s \in S $}.","If $R$ is commutative ring, $P_1, P_2, \dots, P_n$ prime ideals of $R$ with the property $P_i \not\subseteq \bigcup _{j \not = i} P_j$, $\forall 1\le i\le n$, and $S:=R\setminus(P_1 \cup \cdots \cup P_n)$, then show: $$S^{-1}R \text{ has exactly } n \text{ maximal ideals}.$$ Definition. $S^{-1}R=${${r \over s} : r \in R , s \in S $}.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
64,"if $S$ is a ring (possibly without identity) with no proper left ideals, then either $S^2=0$ or $S$ is a division ring.","if  is a ring (possibly without identity) with no proper left ideals, then either  or  is a division ring.",S S^2=0 S,"I'm having trouble with this homework problem (from Algebra by Hungerford). If $S$ is a ring (possibly without identity) with no proper left ideals, then either $S^2=0$ or $S$ is a division ring. We've just proven in the previous part that if $S$ is a ring with identity and with no proper left ideals, then $S$ is a division ring. So the strategy is to suppose $S^2 \neq 0$ and prove that $S$ has an identity. The problem also has a hint: Hint: Show that $\{a \in S \mid Sa = 0\}$ is an ideal. If $cd \neq 0$, show that $\{r \in S \mid rd = 0\} = 0$. Find $e \in S$ such that $ed = d$ and show that $e$ is a two-sided identity. Here's what I have so far, with some boring details removed: Note that $S_0 = \{a \in S \mid Sa = 0\}$ is an ideal, because [proof it's an ideal]. Since $S$ has no proper left ideals, we must have $S_0 = 0$ or $S_0 = S$. This means that either $S^2 = 0$ (if $S_0 = S$) or for every non-zero $a \in S$, there is some $b \in S$ with $ba \neq 0$ (if $S_0 = 0$). From now on suppose $S_0 = 0$, and we will show that $S$ is a division ring. Note also that $A(d) = \{r \in S \mid rd = 0\}$ is a left ideal, because [proof it's a left ideal]. Now if $cd \neq 0$ for some $c, d \in S$, then $A(d) \neq S$ because $c \notin A(d)$; but $S$ has no proper left ideals, so $A(d) = 0$. Then $rd = sd$ if and only if $r = s$, for otherwise $(r-s)d = 0$ contradicts $A(d) = 0$. Consider the left ideal $I_a = \{ra \mid r \in S\}$. [proof that it's a left ideal]. Since $S$ has no proper left ideals, we must have $I_a = 0$ or $I_a = S$ for all $a \in S$. If $cd \neq 0$ then $I_d = S$ (so $I_d = S$ for all non-zero $d \in S$, since we showed that for all $d$ there is a $c$ with $cd \neq 0$), and therefore $d \in I_d$ so there is some $e \in S$ with $ed = d$. As we observed before, $rd = sd$ iff $r = s$, and $(re)d = r(ed) = rd$, so $re = r$ for each $r \in S$. In summary, for every $a \in S$ we have some $e \in S$ (specific to this $a$) such that $e a = a$ and $r e = r$ for all $r \in S$. I feel like it should be very easy to show that there is a two-sided identity (e.g. by showing that all of these $e$ are in fact the same), but I can't seem to get there. Thanks for any help!","I'm having trouble with this homework problem (from Algebra by Hungerford). If $S$ is a ring (possibly without identity) with no proper left ideals, then either $S^2=0$ or $S$ is a division ring. We've just proven in the previous part that if $S$ is a ring with identity and with no proper left ideals, then $S$ is a division ring. So the strategy is to suppose $S^2 \neq 0$ and prove that $S$ has an identity. The problem also has a hint: Hint: Show that $\{a \in S \mid Sa = 0\}$ is an ideal. If $cd \neq 0$, show that $\{r \in S \mid rd = 0\} = 0$. Find $e \in S$ such that $ed = d$ and show that $e$ is a two-sided identity. Here's what I have so far, with some boring details removed: Note that $S_0 = \{a \in S \mid Sa = 0\}$ is an ideal, because [proof it's an ideal]. Since $S$ has no proper left ideals, we must have $S_0 = 0$ or $S_0 = S$. This means that either $S^2 = 0$ (if $S_0 = S$) or for every non-zero $a \in S$, there is some $b \in S$ with $ba \neq 0$ (if $S_0 = 0$). From now on suppose $S_0 = 0$, and we will show that $S$ is a division ring. Note also that $A(d) = \{r \in S \mid rd = 0\}$ is a left ideal, because [proof it's a left ideal]. Now if $cd \neq 0$ for some $c, d \in S$, then $A(d) \neq S$ because $c \notin A(d)$; but $S$ has no proper left ideals, so $A(d) = 0$. Then $rd = sd$ if and only if $r = s$, for otherwise $(r-s)d = 0$ contradicts $A(d) = 0$. Consider the left ideal $I_a = \{ra \mid r \in S\}$. [proof that it's a left ideal]. Since $S$ has no proper left ideals, we must have $I_a = 0$ or $I_a = S$ for all $a \in S$. If $cd \neq 0$ then $I_d = S$ (so $I_d = S$ for all non-zero $d \in S$, since we showed that for all $d$ there is a $c$ with $cd \neq 0$), and therefore $d \in I_d$ so there is some $e \in S$ with $ed = d$. As we observed before, $rd = sd$ iff $r = s$, and $(re)d = r(ed) = rd$, so $re = r$ for each $r \in S$. In summary, for every $a \in S$ we have some $e \in S$ (specific to this $a$) such that $e a = a$ and $r e = r$ for all $r \in S$. I feel like it should be very easy to show that there is a two-sided identity (e.g. by showing that all of these $e$ are in fact the same), but I can't seem to get there. Thanks for any help!",,"['abstract-algebra', 'ideals', 'rngs']"
65,"When $\operatorname{Hom}_{R}(M,N)$ is finitely generated as $\mathbb Z$-module or $R$-module?",When  is finitely generated as -module or -module?,"\operatorname{Hom}_{R}(M,N) \mathbb Z R","Assume that $M$ and $N$ are two finitely generated $R$-modules. Then $\operatorname{Hom}_{R}(M,N)$ is a finitely generated $\mathbb Z$-module and/or $R$-module (in this case, assume that $R$ is commutative)? Note that $R$ is not Noetherian ring. Is there any counterexample (for any cases)?","Assume that $M$ and $N$ are two finitely generated $R$-modules. Then $\operatorname{Hom}_{R}(M,N)$ is a finitely generated $\mathbb Z$-module and/or $R$-module (in this case, assume that $R$ is commutative)? Note that $R$ is not Noetherian ring. Is there any counterexample (for any cases)?",,['abstract-algebra']
66,how to get the injective envelope and projective cover of a given module,how to get the injective envelope and projective cover of a given module,,"Given a bound quiver $(Q, I)$ and a representation $M$ of $Q$, how to get the injective envelope and projective cover of $M$?  how to give the corresponding essential monomorphism and superfluous epimorphism?  Is there a general or specific method?","Given a bound quiver $(Q, I)$ and a representation $M$ of $Q$, how to get the injective envelope and projective cover of $M$?  how to give the corresponding essential monomorphism and superfluous epimorphism?  Is there a general or specific method?",,"['abstract-algebra', 'representation-theory', 'quiver']"
67,Finding a Galois extension of $\Bbb{Q}(i)$ isomorphic to $D_4$,Finding a Galois extension of  isomorphic to,\Bbb{Q}(i) D_4,"This problem has been bothering me for a few days, now. This is not homework, just something I do for my own entertainment. I want to find a Galois extension of $\Bbb{Q}(i)$ which has Galois group isomorphic to $D_4$, the symmetry group of the square (with 8 elements), if one exists. If one does not exist, I would like to know why. I'd also like to find explicitly an irreducible polynomial in $\Bbb{Q}(i)[x]$ corresponding to this extension. My instincts tell me I might be looking for a ""bi-quadratic"" polynomial (that is: one of the form $x^4 + ax^2 + b$). I can do this if the base field is $\Bbb{Q}$,  but the presence of $i$ throws me off a bit. Hints are fine with me, I'll gladly do the leg-work, if someone points me in the right direction.","This problem has been bothering me for a few days, now. This is not homework, just something I do for my own entertainment. I want to find a Galois extension of $\Bbb{Q}(i)$ which has Galois group isomorphic to $D_4$, the symmetry group of the square (with 8 elements), if one exists. If one does not exist, I would like to know why. I'd also like to find explicitly an irreducible polynomial in $\Bbb{Q}(i)[x]$ corresponding to this extension. My instincts tell me I might be looking for a ""bi-quadratic"" polynomial (that is: one of the form $x^4 + ax^2 + b$). I can do this if the base field is $\Bbb{Q}$,  but the presence of $i$ throws me off a bit. Hints are fine with me, I'll gladly do the leg-work, if someone points me in the right direction.",,"['abstract-algebra', 'galois-theory']"
68,invertible polynomials over non-commutative rings,invertible polynomials over non-commutative rings,,"Let $f = a_0 + a_1 t + \dotsc + a_n t^n$ be a polynomial over some nontrivial, possibly noncommutative ring $R$. When is $f$ invertible in $R[t]$? When $R$ is commutative, the answer is well-known: $a_0$ is a unit and $a_1,\dotsc,a_n$ are nilpotent. There are direct element proofs for this, but there is also very nice proof which reduces the claim to integral domains $R$ by using that the radical of $R$ is the intersection of all prime ideals of $R$. What is known about the noncommutative case? Clearly $a_0$ has to be a unit (apply the homomorphism $t \mapsto 0$). Since $a_0^{-1} f$ is invertible iff $f$ is invertible, we may therefore assume that $a_0 = 1$. If $f = 1 + a_i t^i$ for some $i$, it is still true that $f$ is a unit iff $a_i$ is nilpotent.","Let $f = a_0 + a_1 t + \dotsc + a_n t^n$ be a polynomial over some nontrivial, possibly noncommutative ring $R$. When is $f$ invertible in $R[t]$? When $R$ is commutative, the answer is well-known: $a_0$ is a unit and $a_1,\dotsc,a_n$ are nilpotent. There are direct element proofs for this, but there is also very nice proof which reduces the claim to integral domains $R$ by using that the radical of $R$ is the intersection of all prime ideals of $R$. What is known about the noncommutative case? Clearly $a_0$ has to be a unit (apply the homomorphism $t \mapsto 0$). Since $a_0^{-1} f$ is invertible iff $f$ is invertible, we may therefore assume that $a_0 = 1$. If $f = 1 + a_i t^i$ for some $i$, it is still true that $f$ is a unit iff $a_i$ is nilpotent.",,"['abstract-algebra', 'polynomials', 'ring-theory', 'noncommutative-algebra']"
69,The polynomial $x^p-x-1/p$ over $\mathbb Q_p$,The polynomial  over,x^p-x-1/p \mathbb Q_p,"I know that the polynomial $f(x)=x^p-x-\frac1p\in\mathbb Q_p[x]$ is irreducible. So, let $\alpha$ be a root of $f(x)$, and $K=\mathbb Q_p(\alpha)$. Let $O_K$ be the valuation ring of $K$ with respect to the unique extension of the p-adic valuation to $K$. Let $\mathfrak p_K$ be the unique maximal ideal of $O_K$. We know that $O_K$ is also the integral closure of $\mathbb Z_p$ in $K$. I am trying to show that there exists $\beta_i \in O_K$ for $i =0,...,p-1$ such that $\alpha + \beta_i$ is a root of $f(x)$ and $\beta_i \equiv i$ (mod $\mathfrak p_k$). My guess is the following: I know from Hensel's lemma that the polynomial $x^p - x$ splits in $\mathbb Z_p$ with roots $\beta_i \in \mathbb Z_p$ for $i =0,...,p-1$ such that $\beta_i \equiv i$ (mod $p\mathbb Z_p$). So clearly, $\beta_i \equiv i$ (mod $\mathfrak p_k$). What remains to show is that $\alpha + \beta_i$ are the roots that I seek. I think I am on the right track, but I don't know how to show that $\alpha + \beta_i$ are roots of $f(x)$. Any help or hint would be appreciated. Of course, my guess could be totally wrong. In that case I have no idea how to come up with the desired $\beta_i 's$.","I know that the polynomial $f(x)=x^p-x-\frac1p\in\mathbb Q_p[x]$ is irreducible. So, let $\alpha$ be a root of $f(x)$, and $K=\mathbb Q_p(\alpha)$. Let $O_K$ be the valuation ring of $K$ with respect to the unique extension of the p-adic valuation to $K$. Let $\mathfrak p_K$ be the unique maximal ideal of $O_K$. We know that $O_K$ is also the integral closure of $\mathbb Z_p$ in $K$. I am trying to show that there exists $\beta_i \in O_K$ for $i =0,...,p-1$ such that $\alpha + \beta_i$ is a root of $f(x)$ and $\beta_i \equiv i$ (mod $\mathfrak p_k$). My guess is the following: I know from Hensel's lemma that the polynomial $x^p - x$ splits in $\mathbb Z_p$ with roots $\beta_i \in \mathbb Z_p$ for $i =0,...,p-1$ such that $\beta_i \equiv i$ (mod $p\mathbb Z_p$). So clearly, $\beta_i \equiv i$ (mod $\mathfrak p_k$). What remains to show is that $\alpha + \beta_i$ are the roots that I seek. I think I am on the right track, but I don't know how to show that $\alpha + \beta_i$ are roots of $f(x)$. Any help or hint would be appreciated. Of course, my guess could be totally wrong. In that case I have no idea how to come up with the desired $\beta_i 's$.",,"['abstract-algebra', 'algebraic-number-theory', 'p-adic-number-theory']"
70,Subgroups of a vector space,Subgroups of a vector space,,"I would like to have an overview of how a subgroup of a vector space over $\mathbb R$ of dimension $n$ can look like. Is there a complete classification available? I know that there are for examples the linear subspaces, subgroups which are ismorphic to $\mathbb Z^k$ or $\mathbb  Q^k$ (with $k\leq n$) and probably many more. What if I impose some extra condition? For example, I know that the only discrete subgroups are those isomorphic to $\mathbb Z^k$. So what happens if I ask for local compactness? (I know this rules out the subgroups isomorphic to $\mathbb  Q^k$).  Or for the Lie subgroups? Are in this case the linear subspaces and the discrete subgroups the only candidates?","I would like to have an overview of how a subgroup of a vector space over $\mathbb R$ of dimension $n$ can look like. Is there a complete classification available? I know that there are for examples the linear subspaces, subgroups which are ismorphic to $\mathbb Z^k$ or $\mathbb  Q^k$ (with $k\leq n$) and probably many more. What if I impose some extra condition? For example, I know that the only discrete subgroups are those isomorphic to $\mathbb Z^k$. So what happens if I ask for local compactness? (I know this rules out the subgroups isomorphic to $\mathbb  Q^k$).  Or for the Lie subgroups? Are in this case the linear subspaces and the discrete subgroups the only candidates?",,"['abstract-algebra', 'group-theory', 'lie-groups', 'abelian-groups', 'locally-compact-groups']"
71,A condition for a subgroup of a finitely generated free abelian group to have finite index,A condition for a subgroup of a finitely generated free abelian group to have finite index,,"Let $A$ be a free abelian group of finite rank and $B$ be a subgroup of $A$ such that $A=B+pA$ for some prime number $p$. Then how to prove $B$ is a subgroup of finite index in $A$? And if $A=B+pA$ holds for any prime number number $p$, then $A=B$? I tried to use The Second Isomorphism Theorem for groups, since any subgroup of an abelian group is normal, so we can get $pA/(pA\cap B) \cong\ (B+pA)/B=A/B$, since $A=B+pA$, so the next step will be show $pA/(pA\cap B)$ is finite, then I got stuck. I also tried to use $A/pA=(B+pA)/pA \cong\ B/(pA\cap B)$, and stuck again. I guess we might need to connect $A/B$  with $A/pA$, since the later the finite, and I don't know how to use the condition that A is with finite rank, any suggestions?","Let $A$ be a free abelian group of finite rank and $B$ be a subgroup of $A$ such that $A=B+pA$ for some prime number $p$. Then how to prove $B$ is a subgroup of finite index in $A$? And if $A=B+pA$ holds for any prime number number $p$, then $A=B$? I tried to use The Second Isomorphism Theorem for groups, since any subgroup of an abelian group is normal, so we can get $pA/(pA\cap B) \cong\ (B+pA)/B=A/B$, since $A=B+pA$, so the next step will be show $pA/(pA\cap B)$ is finite, then I got stuck. I also tried to use $A/pA=(B+pA)/pA \cong\ B/(pA\cap B)$, and stuck again. I guess we might need to connect $A/B$  with $A/pA$, since the later the finite, and I don't know how to use the condition that A is with finite rank, any suggestions?",,"['abstract-algebra', 'group-theory', 'abelian-groups']"
72,When $G'$/$G''$ and $G''$ both are cyclic groups,When / and  both are cyclic groups,G' G'' G'',"There is a claim saying that if both $G'/G''$ and $G''$ are cyclic groups, then $G''=1$, where $G'$ is the derived subgroup of the group $G$. I have been thinking of this by focusing the N/C Lemma to clear the problem for myself. I need a useful igniting hint(s). Furthermore, may I ask: are these kinds of groups well known? Of course, any group satisfying the above conditions will be metabelian and obviously is soluble.","There is a claim saying that if both $G'/G''$ and $G''$ are cyclic groups, then $G''=1$, where $G'$ is the derived subgroup of the group $G$. I have been thinking of this by focusing the N/C Lemma to clear the problem for myself. I need a useful igniting hint(s). Furthermore, may I ask: are these kinds of groups well known? Of course, any group satisfying the above conditions will be metabelian and obviously is soluble.",,"['abstract-algebra', 'group-theory']"
73,Contravariant Grothendieck Spectral Sequence,Contravariant Grothendieck Spectral Sequence,,"I'm currently getting confused about indices in some spectral sequences. Assume we work in the category of modules for simplicity. Let $A^\cdot$ be a (bounded on the right) complex and let $B^\cdot$ (I don't think we have to assume anything about the boundedness of $B$). I want to compute $Ext^n(A^\cdot,B^\cdot)$, which is classically called hyperext (and sometimes denoted by $\mathbb{E}xt$. Now, (perhaps assuming $B^\cdot$ to be bounded on the right), there exists a spectral sequence $$E^{p,q}_2 = Ext^p(A^\cdot,H^q(B^\cdot)) \Rightarrow Ext^{p+q}(A^\cdot,B^\cdot).$$ There should be an analogous by switching A and B, but I'm unsure of the indices, so my question is is $$ E^{p,q}_2 = Ext^q(A^\cdot,H^{-p}(B^\cdot)) \Rightarrow Ext^{q-p}(A^\cdot,B^\cdot) $$   the right thing? Thanks.","I'm currently getting confused about indices in some spectral sequences. Assume we work in the category of modules for simplicity. Let $A^\cdot$ be a (bounded on the right) complex and let $B^\cdot$ (I don't think we have to assume anything about the boundedness of $B$). I want to compute $Ext^n(A^\cdot,B^\cdot)$, which is classically called hyperext (and sometimes denoted by $\mathbb{E}xt$. Now, (perhaps assuming $B^\cdot$ to be bounded on the right), there exists a spectral sequence $$E^{p,q}_2 = Ext^p(A^\cdot,H^q(B^\cdot)) \Rightarrow Ext^{p+q}(A^\cdot,B^\cdot).$$ There should be an analogous by switching A and B, but I'm unsure of the indices, so my question is is $$ E^{p,q}_2 = Ext^q(A^\cdot,H^{-p}(B^\cdot)) \Rightarrow Ext^{q-p}(A^\cdot,B^\cdot) $$   the right thing? Thanks.",,"['abstract-algebra', 'homological-algebra', 'spectral-sequences']"
74,Assistance with an exercise on field endomorphisms,Assistance with an exercise on field endomorphisms,,"Working through the problems in a book on field theory (Field Extensions and Galois Theory by Bastida). I came across one which I thought looked like a ""routine"" exercise, but has been particularly stubborn. Suppose $K$ is a field with $char(K) \neq 2$ and $u:K \rightarrow K$ a map so that $u(x+y) = u(x)+u(y)$ for all $x,y \in K$ , $u(1) = 1$ and $u(x)u(1/x) = 1$ for all $x \in K^*$ . Show that $u$ is an endomorphism. Seems straightforward, I just need to show $u(xy) = u(x)u(y)$ . I figured out that I can reduce the problem to just verifying it for ""squares."" That is, if I can just show $u(x^2) = u(x)^2$ for all $x$ . In that case, we can say: $u((x+y)^2) = u(x^2+ xy + xy + y^2) = u(x^2) + 2u(xy) + u(y^2)$ . But also $u((x+y)^2) = u(x+y)u(x+y) = u(x)^2 + 2u(x)u(y) + u(y)^2$ . Then we have $2u(xy) = 2u(x)u(y)$ and since $K$ is a field not of characteristic 2, we can cancel the 2's and get the result. Alas, proving the special case $u(x^2) = u(x)^2$ has resisted my efforts. Of course $x = 0$ is not a problem. Otherwise, I was trying to play around with $u(x)u(1/x) = 1$ and $u(1) = 1$ to get it. The closest I've managed to get by tinkering with these is $u(x^2\cdot 1/x) = u(x)^2u(1/x)$ . A hint in the right direction would be appreciated, or, if this approach won't work, a nudge in another direction.","Working through the problems in a book on field theory (Field Extensions and Galois Theory by Bastida). I came across one which I thought looked like a ""routine"" exercise, but has been particularly stubborn. Suppose is a field with and a map so that for all , and for all . Show that is an endomorphism. Seems straightforward, I just need to show . I figured out that I can reduce the problem to just verifying it for ""squares."" That is, if I can just show for all . In that case, we can say: . But also . Then we have and since is a field not of characteristic 2, we can cancel the 2's and get the result. Alas, proving the special case has resisted my efforts. Of course is not a problem. Otherwise, I was trying to play around with and to get it. The closest I've managed to get by tinkering with these is . A hint in the right direction would be appreciated, or, if this approach won't work, a nudge in another direction.","K char(K) \neq 2 u:K \rightarrow K u(x+y) = u(x)+u(y) x,y \in K u(1) = 1 u(x)u(1/x) = 1 x \in K^* u u(xy) = u(x)u(y) u(x^2) = u(x)^2 x u((x+y)^2) = u(x^2+ xy + xy + y^2) = u(x^2) + 2u(xy) + u(y^2) u((x+y)^2) = u(x+y)u(x+y) = u(x)^2 + 2u(x)u(y) + u(y)^2 2u(xy) = 2u(x)u(y) K u(x^2) = u(x)^2 x = 0 u(x)u(1/x) = 1 u(1) = 1 u(x^2\cdot 1/x) = u(x)^2u(1/x)","['abstract-algebra', 'field-theory', 'galois-theory']"
75,"In the group $G=\langle r,s,t\mid r^2=s^3=t^3=rst\rangle,$ the element $rst$ has order $2$",In the group  the element  has order,"G=\langle r,s,t\mid r^2=s^3=t^3=rst\rangle, rst 2","Formally, if $F$ is the free group with basis $X = \{r, s, t\}$ and $N$ is the normal subgroup generated by $R = \{r^2 s^{-3}, s^3 t^{-3}, t^{3} (rst)^{-1}\}$ , and $G = F/N$ , I want to show that the coset of $rst$ has order $2$ in $G$ . There are two parts to this: showing $rstrst = 1$ and showing $rst \neq 1$ . There must be some way to play with and combine the relations in just the right way to get $rstrst = 1$ , but it seems difficult to get inverses to even appear in the right places and amounts to cancel all the $r, s, t$ of positive exponent. So far I know $r^2 = s^3 = t^3 = rst = str = trs$ , $r = st$ , $s^2 = tr$ , $t^2 = rs$ , and so I try at random some manipulations like $rstrst = t^2 s^2 r = (s^{-1}r)^2 (rt^{-1})^2 (t^2 s^{-1}) = \cdots$ or similar, which has just resulted in wandering about aimlessly. On the other hand, to show $rst \neq 1$ , I have previously shown that $G/\langle rst \rangle \cong A_4$ , so I could exhibit a property that is different between $G$ and $A_4$ to say that $rst \neq 1$ , but such a property might already rely on $rst$ being not $1$ to demonstrate, as the groups share all other defining relations. Proving $rst \neq 1$ directly by showing $rst \notin N$ in $F$ seems way too messy, since the elements of $N$ are words on the conjugates of $R$ .","Formally, if is the free group with basis and is the normal subgroup generated by , and , I want to show that the coset of has order in . There are two parts to this: showing and showing . There must be some way to play with and combine the relations in just the right way to get , but it seems difficult to get inverses to even appear in the right places and amounts to cancel all the of positive exponent. So far I know , , , , and so I try at random some manipulations like or similar, which has just resulted in wandering about aimlessly. On the other hand, to show , I have previously shown that , so I could exhibit a property that is different between and to say that , but such a property might already rely on being not to demonstrate, as the groups share all other defining relations. Proving directly by showing in seems way too messy, since the elements of are words on the conjugates of .","F X = \{r, s, t\} N R = \{r^2 s^{-3}, s^3 t^{-3}, t^{3} (rst)^{-1}\} G = F/N rst 2 G rstrst = 1 rst \neq 1 rstrst = 1 r, s, t r^2 = s^3 = t^3 = rst = str = trs r = st s^2 = tr t^2 = rs rstrst = t^2 s^2 r = (s^{-1}r)^2 (rt^{-1})^2 (t^2 s^{-1}) = \cdots rst \neq 1 G/\langle rst \rangle \cong A_4 G A_4 rst \neq 1 rst 1 rst \neq 1 rst \notin N F N R","['abstract-algebra', 'group-theory', 'free-groups', 'group-presentation', 'combinatorial-group-theory']"
76,"Find all power series $f$ such that $\mathbb{C}[[x, y]]/(f(x, y))\cong \mathbb{C}[[x, y]]/(xy)$",Find all power series  such that,"f \mathbb{C}[[x, y]]/(f(x, y))\cong \mathbb{C}[[x, y]]/(xy)","Find all power series $f$ such that $\mathbb{C}[[x, y]]/(f(x, y)) \cong  \mathbb{C}[[x, y]]/(xy)$ . The isomorphism $\phi$ should be identical on $\mathbb{C}$ , i.e., $\forall c \in \mathbb{C} \subseteq \mathbb{C}[[x, y]]/(f(x, y))$ , $\phi(c) = c$ . This problem is the third problem of the 2018 Alibaba math contest (final) —— Algebra track. It is not an ongoing contest. My only attempt is to show the power series of the Right Hand Side (RHS) are in the form $\sum\limits_{i = 0}a_ix^i + \sum\limits_{j = 0}b_iy^j (xy = 0)$ but I do not know how to proceed. Does this problem require some advanced theories or theorems? Is the complex field $\mathbb{C}$ anything special?","Find all power series such that . The isomorphism should be identical on , i.e., , . This problem is the third problem of the 2018 Alibaba math contest (final) —— Algebra track. It is not an ongoing contest. My only attempt is to show the power series of the Right Hand Side (RHS) are in the form but I do not know how to proceed. Does this problem require some advanced theories or theorems? Is the complex field anything special?","f \mathbb{C}[[x, y]]/(f(x, y)) \cong  \mathbb{C}[[x, y]]/(xy) \phi \mathbb{C} \forall c \in \mathbb{C} \subseteq \mathbb{C}[[x, y]]/(f(x, y)) \phi(c) = c \sum\limits_{i = 0}a_ix^i + \sum\limits_{j = 0}b_iy^j (xy = 0) \mathbb{C}","['abstract-algebra', 'ring-theory', 'contest-math']"
77,The determinant of a Cartan matrix is positive,The determinant of a Cartan matrix is positive,,"Let $R\subset V$ be an abstract root system in a finite-dimensional vector space $V$ . Let $\Pi \subset R$ be a base of $R$ . Define the Cartan matrix of $R$ as $C(R)=(\langle \alpha,\beta \check{}\rangle)_{\alpha,\beta \in \Pi}$ . My lecture notes claim: Since we may assume $V$ to be a Euclidean vector space, $\det(C(R)) > 0$ . Why is that? Why do we have to assume that $V$ is a Euclidean vector space? Since $\langle\alpha,\beta \check{}\rangle=2 \frac{(\alpha,\beta)}{(\beta,\beta)}$ (for an inner product $(-,-)$ on $V$ that is invariant under the Weyl group of $R$ ) the definition of the Cartan matrix is reminiscent to the Gram matrix of an inner product? Are the two related?","Let be an abstract root system in a finite-dimensional vector space . Let be a base of . Define the Cartan matrix of as . My lecture notes claim: Since we may assume to be a Euclidean vector space, . Why is that? Why do we have to assume that is a Euclidean vector space? Since (for an inner product on that is invariant under the Weyl group of ) the definition of the Cartan matrix is reminiscent to the Gram matrix of an inner product? Are the two related?","R\subset V V \Pi \subset R R R C(R)=(\langle \alpha,\beta \check{}\rangle)_{\alpha,\beta \in \Pi} V \det(C(R)) > 0 V \langle\alpha,\beta \check{}\rangle=2 \frac{(\alpha,\beta)}{(\beta,\beta)} (-,-) V R","['abstract-algebra', 'matrices', 'definition', 'determinant', 'lie-algebras']"
78,Sign in definition of Cap product,Sign in definition of Cap product,,"We define the cap product in the following way : $$a \frown z := \epsilon \otimes 1(a \otimes Ez \circ \Delta_\star(z))$$ Where : $1. \hspace{0.3cm} \Delta_\star$ is the induced map on chain complex by the diagonal map $\Delta : X \longrightarrow X \times X$ $2. \hspace{0.3cm}Ez$ is a choince of an Eilenberg-Zielber map $Ez : C_\bullet(X \times X) \longrightarrow C_\bullet(X) \otimes C_\bullet(X)$ $3.\hspace{0.3cm} \epsilon$ is the map defined only in degree $0$ , more accurately $\epsilon_n = 0$ if $n \ne 0$ and $\epsilon_0 : (C^\bullet(X)\otimes C_\bullet(X))_0 \longrightarrow \mathbb{Z}$ where $\langle f,x \rangle = f(x), f \in C^i(X),x \in C_i(X)$ . With those convention it should be clear that we call cap product the following map : $$C^q(X) \otimes C_{p+q}(X) \overset{\frown}{\longrightarrow} C_p(X)$$ Now, since the Eilenberg-Zielber theorem due to acyclic models theorem we have that any choice (dependant on chain level) that extends the diagonal will be as good as the defined since they will induce the same map in homology. Given the premise I'd like to substitute the $Ez \circ \Delta_\star(z)$ with $AW(z) = \sum\limits_{p+q = n} \sigma_p^1 \otimes \sigma_q^2$ the Alexander Whitney map, see the definition in a previous question here . What I don't understand is the following : If I compute $\varphi \frown \sigma$ with $\varphi \in C^p$ and $\sigma : \Delta^{p+q} \longrightarrow X$ I end up having the formula $\varphi(\sigma_{|[e_q,\cdots,e_{p+q}]})\cdot \sigma_{|[e_0,\cdots e_q]}$ which is indeed the formula of the cap product here . What I should get according to my professor is $(-1)^{pq}\varphi(\sigma_{|[e_q,\cdots,e_{p+q}]})\cdot \sigma_{|[e_0,\cdots e_q]}$ . Where the sign on $(-1)$ comes from ? Reading ""Tammo Tom Dieck, Algebraic Topology"" at page $290$ , I found the following Is this somehow related to my problem? I thought $f = \epsilon$ and $g = \text{id}$ could work. I'm not sure since if the degree of a map is defined as the integer $p$ such that $f : C_q(X) \longrightarrow C_{q+p}(X)$ the identity should have degree $0$ , which doesn't solve the problem. Addendum : Is the sign of the $(1)^{|g||a|}$ there for particular reasons ? I thought this could be since if we define the differential of two chain complex with a factor $(-1)^{\bullet}$ then that is the right sign to achieve $d(f \otimes g) = (f\otimes g)d$ , but computing the two of them, that doesn't seem relevant. Any help in understanding this would de be appreciated since the construction of cap product and cup product is strictly related to understanding duality.","We define the cap product in the following way : Where : is the induced map on chain complex by the diagonal map is a choince of an Eilenberg-Zielber map is the map defined only in degree , more accurately if and where . With those convention it should be clear that we call cap product the following map : Now, since the Eilenberg-Zielber theorem due to acyclic models theorem we have that any choice (dependant on chain level) that extends the diagonal will be as good as the defined since they will induce the same map in homology. Given the premise I'd like to substitute the with the Alexander Whitney map, see the definition in a previous question here . What I don't understand is the following : If I compute with and I end up having the formula which is indeed the formula of the cap product here . What I should get according to my professor is . Where the sign on comes from ? Reading ""Tammo Tom Dieck, Algebraic Topology"" at page , I found the following Is this somehow related to my problem? I thought and could work. I'm not sure since if the degree of a map is defined as the integer such that the identity should have degree , which doesn't solve the problem. Addendum : Is the sign of the there for particular reasons ? I thought this could be since if we define the differential of two chain complex with a factor then that is the right sign to achieve , but computing the two of them, that doesn't seem relevant. Any help in understanding this would de be appreciated since the construction of cap product and cup product is strictly related to understanding duality.","a \frown z := \epsilon \otimes 1(a \otimes Ez \circ \Delta_\star(z)) 1. \hspace{0.3cm} \Delta_\star \Delta : X \longrightarrow X \times X 2. \hspace{0.3cm}Ez Ez : C_\bullet(X \times X) \longrightarrow C_\bullet(X) \otimes C_\bullet(X) 3.\hspace{0.3cm} \epsilon 0 \epsilon_n = 0 n \ne 0 \epsilon_0 : (C^\bullet(X)\otimes C_\bullet(X))_0 \longrightarrow \mathbb{Z} \langle f,x \rangle = f(x), f \in C^i(X),x \in C_i(X) C^q(X) \otimes C_{p+q}(X) \overset{\frown}{\longrightarrow} C_p(X) Ez \circ \Delta_\star(z) AW(z) = \sum\limits_{p+q = n} \sigma_p^1 \otimes \sigma_q^2 \varphi \frown \sigma \varphi \in C^p \sigma : \Delta^{p+q} \longrightarrow X \varphi(\sigma_{|[e_q,\cdots,e_{p+q}]})\cdot \sigma_{|[e_0,\cdots e_q]} (-1)^{pq}\varphi(\sigma_{|[e_q,\cdots,e_{p+q}]})\cdot \sigma_{|[e_0,\cdots e_q]} (-1) 290 f = \epsilon g = \text{id} p f : C_q(X) \longrightarrow C_{q+p}(X) 0 (1)^{|g||a|} (-1)^{\bullet} d(f \otimes g) = (f\otimes g)d","['abstract-algebra', 'algebraic-topology', 'homology-cohomology', 'tensor-products', 'group-cohomology']"
79,Ideal Class Group of $ \mathbb{Q}(\sqrt[3]{3}) $,Ideal Class Group of, \mathbb{Q}(\sqrt[3]{3}) ,"I'm trying to compute the ideal class group of $\mathbb Q(\sqrt[3]{3})$ , and I would like to know if my calculations are right and if I could improve my arguments. Let $K=\mathbb Q (\sqrt[3]{3}),$ its ring of integers $\mathcal O_K$ is $ \mathbb Z[\sqrt[3]{3}]$ , since Disc $(1,\sqrt[3]{3},\sqrt[3]{3^2})=-3^5 \quad $ and $f(x)=x^3-3 \ $ is Eisenstein for $3$ . The Minkowski bound is $\frac{4}{\pi}\cdot\frac{6}{27}\cdot \sqrt{3^5}<5$ . Thus we need to check ideals of norm less than $5$ . Set $a=\sqrt[3]{3}$ to facilitate notation. The only ideal of norm 1 is $\mathcal{O}_K$ Every ideal contains its norm, thus ideals of norm $2$ are prime factors of $(2). \quad $ $ (2)=(a-1)(a^2+a+1) \ $ , since $2=3-1=a^3-1=(a-1)(a^2+a+1). N(a-1)=2, N(a^2+a+1)=4 $ . $(3)=(a)^3$ and $(a)$ is principal. Since $(2)=(a-1)(a^2+a+1),$ ideals of norm 4 are: $(a-1)^2, \ (a^2+a+1).$ All of the ideals above are principal, thus the ideal class group is trivial and $\mathcal O_K$ is a PID.","I'm trying to compute the ideal class group of , and I would like to know if my calculations are right and if I could improve my arguments. Let its ring of integers is , since Disc and is Eisenstein for . The Minkowski bound is . Thus we need to check ideals of norm less than . Set to facilitate notation. The only ideal of norm 1 is Every ideal contains its norm, thus ideals of norm are prime factors of , since . and is principal. Since ideals of norm 4 are: All of the ideals above are principal, thus the ideal class group is trivial and is a PID.","\mathbb Q(\sqrt[3]{3}) K=\mathbb Q (\sqrt[3]{3}), \mathcal O_K  \mathbb Z[\sqrt[3]{3}] (1,\sqrt[3]{3},\sqrt[3]{3^2})=-3^5 \quad  f(x)=x^3-3 \  3 \frac{4}{\pi}\cdot\frac{6}{27}\cdot \sqrt{3^5}<5 5 a=\sqrt[3]{3} \mathcal{O}_K 2 (2). \quad   (2)=(a-1)(a^2+a+1) \  2=3-1=a^3-1=(a-1)(a^2+a+1). N(a-1)=2, N(a^2+a+1)=4  (3)=(a)^3 (a) (2)=(a-1)(a^2+a+1), (a-1)^2, \ (a^2+a+1). \mathcal O_K","['abstract-algebra', 'number-theory', 'ring-theory', 'algebraic-number-theory']"
80,Kernel of Quadratic Field Norm,Kernel of Quadratic Field Norm,,"Let $D > 0$ be squarefree and consider the field $\mathbb{Q}(\sqrt{D})$ . Then the field norm $N : \mathbb{Q}(\sqrt{D}) \to \mathbb{Q}^\times$ is given by $N(a + b\sqrt{D}) = a^2 - D b^2$ . Let $K$ be the kernel of this map, consisting of elements of norm $+1$ . I'm looking for an example where $K$ is not isomorphic to $\mathbb{Z}/2\mathbb{Z} \times \bigoplus_{i = 0}^\infty \mathbb{Z}$ as abelian groups. The motivation is the Pell conic group $C$ defined on the curve $x^2 - Dy^2 = 1$ . If $D$ is a square of a rational number, then $x \mapsto (\frac{x+x^{-1}}{2},\frac{x-x^{-1}}{2\sqrt{D}})$ gives an isomorphism $\mathbb{Q}^{\times} \cong C$ , but otherwise we have the isomorphism $K \cong C$ where $K$ is the kernel of the norm map. I am wondering whether the group structure of $C$ alone can detect the irrationality of a square root of a natural number. Below I've included my current thoughts on this question. Let's consider $D = 2$ . Then the group of units of $\mathbb{Z}[\sqrt{2}]$ is generated by powers of $\pm(1 + \sqrt{2})$ , so it is isomorphic $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}$ . Since $\mathbb{Z}[\sqrt{2}]$ is a UFD, we have that any element of $\mathbb{Q}(\sqrt{2})^\times$ can be written as a unique product of primes and units of $\mathbb{Z}[\sqrt{2}]$ , so $\mathbb{Q}(\sqrt{2})^\times \cong (\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}) \times \bigoplus_{p \text{ prime}} \mathbb{Z}$ . Now consider the map $h : \mathbb{Q}(\sqrt{2})^\times \to K$ given by $h(a) = \frac{a^*}{a}$ where $a^*$ denotes the conjugate. My understanding is that Hilbert's Theorem 90 implies this map is surjective. Its kernel is $\mathbb{Q}^\times$ , so $K$ should be something like $K \cong (\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}) \times \bigoplus_{p \text{ prime, } \notin \mathbb{Q}} \mathbb{Z}$ . This paper uses a similar map to obtain the analogous result for $\mathbb{Q}(i)$ . It seems like similar reasoning should apply to any UFD. Now consider a non-UFD, say $D = 10$ . Here we have $2 \cdot 5 = \sqrt{10} \cdot \sqrt{10}$ which at first seems like it might change the structure of $\mathbb{Q}(\sqrt{10})^\times$ compared to $\mathbb{Q}(\sqrt{2})^\times$ . However, I think you can throw out $5$ as a generator because you can get it from the other irreducibles as as $(\sqrt{10})^2/2$ . It seems like $\mathbb{Q}(\sqrt{10})^\times$ has a chance of being isomorphic to $\mathbb{Z}/2\mathbb{Z} \times \bigoplus_{i = 0}^\infty \mathbb{Z}$ despite not being a UFD. Then applying $h$ should then just kill the factors corresponding to primes in $\mathbb{Q}$ , so you might get the same thing for $K$ as with $D = 2$ .","Let be squarefree and consider the field . Then the field norm is given by . Let be the kernel of this map, consisting of elements of norm . I'm looking for an example where is not isomorphic to as abelian groups. The motivation is the Pell conic group defined on the curve . If is a square of a rational number, then gives an isomorphism , but otherwise we have the isomorphism where is the kernel of the norm map. I am wondering whether the group structure of alone can detect the irrationality of a square root of a natural number. Below I've included my current thoughts on this question. Let's consider . Then the group of units of is generated by powers of , so it is isomorphic . Since is a UFD, we have that any element of can be written as a unique product of primes and units of , so . Now consider the map given by where denotes the conjugate. My understanding is that Hilbert's Theorem 90 implies this map is surjective. Its kernel is , so should be something like . This paper uses a similar map to obtain the analogous result for . It seems like similar reasoning should apply to any UFD. Now consider a non-UFD, say . Here we have which at first seems like it might change the structure of compared to . However, I think you can throw out as a generator because you can get it from the other irreducibles as as . It seems like has a chance of being isomorphic to despite not being a UFD. Then applying should then just kill the factors corresponding to primes in , so you might get the same thing for as with .","D > 0 \mathbb{Q}(\sqrt{D}) N : \mathbb{Q}(\sqrt{D}) \to \mathbb{Q}^\times N(a + b\sqrt{D}) = a^2 - D b^2 K +1 K \mathbb{Z}/2\mathbb{Z} \times \bigoplus_{i = 0}^\infty \mathbb{Z} C x^2 - Dy^2 = 1 D x \mapsto (\frac{x+x^{-1}}{2},\frac{x-x^{-1}}{2\sqrt{D}}) \mathbb{Q}^{\times} \cong C K \cong C K C D = 2 \mathbb{Z}[\sqrt{2}] \pm(1 + \sqrt{2}) \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z} \mathbb{Z}[\sqrt{2}] \mathbb{Q}(\sqrt{2})^\times \mathbb{Z}[\sqrt{2}] \mathbb{Q}(\sqrt{2})^\times \cong (\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}) \times \bigoplus_{p \text{ prime}} \mathbb{Z} h : \mathbb{Q}(\sqrt{2})^\times \to K h(a) = \frac{a^*}{a} a^* \mathbb{Q}^\times K K \cong (\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}) \times \bigoplus_{p \text{ prime, } \notin \mathbb{Q}} \mathbb{Z} \mathbb{Q}(i) D = 10 2 \cdot 5 = \sqrt{10} \cdot \sqrt{10} \mathbb{Q}(\sqrt{10})^\times \mathbb{Q}(\sqrt{2})^\times 5 (\sqrt{10})^2/2 \mathbb{Q}(\sqrt{10})^\times \mathbb{Z}/2\mathbb{Z} \times \bigoplus_{i = 0}^\infty \mathbb{Z} h \mathbb{Q} K D = 2","['abstract-algebra', 'group-theory', 'number-theory', 'field-theory', 'algebraic-number-theory']"
81,Bound for order of a group depending on number of elements of maximal order,Bound for order of a group depending on number of elements of maximal order,,"In a paper On the Number of Elements of maximal order in a Group it is proven that an arbitrary group $G$ with a finite number of elements of maximal order has bounded size. Namely: $$|G|\leq\frac{mk^2}{\varphi(m)},$$ where $m$ is the maximal order and $k$ the number of elements that have order $m$ . I wanted to characterize all groups $G$ , where the limit is sharp, i.e. $|G|=\frac{mk^2}{\varphi(m)}$ . Using GAP I found all groups with this property up to order 1023 and was able to state a conjecture. It is easy to see in the paper, that a group has this property only if all elements of maximal order are conjugated. So we need this as as a requirement. I wanted to prove the following conjecture, but missing some tiny part. Maybe someone knows a way, I would be really happy. Conjecture. Let $G$ be a group with $k<\infty$ elements of maximal order $m$ , in which all elements of maximal order are conjugated. Then the following are equivalent. $i)$ $|G|=\frac{mk^2}{\varphi(m)}$ $ii)$ $k=\varphi(m)$ $iii)$ $G$ has a unique subgroup of order $m$ $iv)$ $C_m \cong C_G(x)=C_G(y)\trianglelefteq G$ for all $x,y\in G$ with maximal order Proof. $i) \implies ii)$ This is the part, I could not prove : I only could prove, that all elements of order $m$ commute: Let $C_G(x)$ be the stabilizer of an element of maximal order. Orbit-Stabilizer-Theorem tells us, that $|C_G(x)|=\frac{mk}{\varphi(m)}$ . Assume there exists an element of order $m$ , not contained in $C_G(x)$ . $\langle x \rangle$ operates via left-multiplication on $C_G(x)$ . $C_G(x)$ is partitioned into $\frac{|C_G(x)|}{m}$ orbits. According to Lemma 3 of  the paper linked above, in each orbit exist at least $\varphi(m)$ elements of order $m$ , i.e. in $C_G(x)$ exist at least $\varphi(m)\frac{|C_G(x)|}{m}$ elements of order $m$ . Our assumption tells us $\varphi(m)\frac{|C_G(x)|}{m} < k$ , which leads to the contradiction $|C_G(x)| < \frac{mk}{\varphi(m)}$ . It follows that all elements of order $m$ commute. This is where I can't proceed further. Maybe someone has an idea? $ii) \iff iii)$ If $k=\varphi(m)$ , an element of order $m$ generates a cyclic subgroup which contains $\varphi(m)$ elements of order $m$ , that all generate this subgroup. So there can't be other elements of order $m$ in different subgroups. Otherwise, if there is only one cyclic subgroup of order $m$ , then it contains $\varphi(m)$ elements of order $m$ , no additional elements of order $m$ can exist, as they would generate a second cyclic subgroup of order $m$ . $iii) \implies iv)$ Let $Z$ be the unique subgroup of order $m$ and $X=\{x_1,\dots,x_k\}$ the set of elements of order $m$ . As all $x\in X$ generate $Z$ , $Z$ must be contained in all centralizers of elements in $X$ . Note that $G$ operates on itself via conjugation. Orbit-Stabilizer-Theorem tells us for $x \in X$ : $$|G|=|^Gx||G_x|=k|G_x|=\frac{mk^2}{\varphi(m)}=mk$$ This follows as all elements of order $m$ are conjugated and $k=\varphi(m)$ holds. It follows, that $|G_x|=m$ , which leads to $G_x=Z\cong C_m$ for all $x \in X$ . For the normal subgroup part, note that $\phi(x_i)=x_j$ for an inner automorphism $\phi$ and $i,j\in \{1,\dots k\}$ . Let $y \in Z$ arbitrary, then $y=x_1^\alpha$ for $\alpha \in \mathbb{N}$ . Let $\phi$ be an arbitrary inner automorphism. It follows that there is a $i \in \{1,\dots k\}$ with $$\phi(y)=\phi(x_1^\alpha)=\phi(x_1)^\alpha=x_i^\alpha \in Z$$ It follows that $Z$ is invariant under inner automorphisms, i.e. normal. $iv) \implies i)$ Orbit-Stabilizer-Theorem tells us that $|G|=|^Gx||G_x|=mk$ . As all stabilizers of elements of order $m$ are equal to the same cyclic group of order $m$ , it follows, that there exist only one cyclic group of order $m$ , it follows $k=\varphi(m)$ and $|G|=mk=\frac{mk^2}{\varphi(m)}$ . Thanks to anyone, who read till here ;) Another property, which my GAP-study suggests to be equivalent is : $v)$ $G'$ is cyclic This proof has low priority, as I first want to have my circle-implications. I guess I can show, that $G'$ is contained in the unique cyclic group $Z$ of order $m$ , by proving, that $G/Z$ is abelian. I did not succeed yet, though.","In a paper On the Number of Elements of maximal order in a Group it is proven that an arbitrary group with a finite number of elements of maximal order has bounded size. Namely: where is the maximal order and the number of elements that have order . I wanted to characterize all groups , where the limit is sharp, i.e. . Using GAP I found all groups with this property up to order 1023 and was able to state a conjecture. It is easy to see in the paper, that a group has this property only if all elements of maximal order are conjugated. So we need this as as a requirement. I wanted to prove the following conjecture, but missing some tiny part. Maybe someone knows a way, I would be really happy. Conjecture. Let be a group with elements of maximal order , in which all elements of maximal order are conjugated. Then the following are equivalent. has a unique subgroup of order for all with maximal order Proof. This is the part, I could not prove : I only could prove, that all elements of order commute: Let be the stabilizer of an element of maximal order. Orbit-Stabilizer-Theorem tells us, that . Assume there exists an element of order , not contained in . operates via left-multiplication on . is partitioned into orbits. According to Lemma 3 of  the paper linked above, in each orbit exist at least elements of order , i.e. in exist at least elements of order . Our assumption tells us , which leads to the contradiction . It follows that all elements of order commute. This is where I can't proceed further. Maybe someone has an idea? If , an element of order generates a cyclic subgroup which contains elements of order , that all generate this subgroup. So there can't be other elements of order in different subgroups. Otherwise, if there is only one cyclic subgroup of order , then it contains elements of order , no additional elements of order can exist, as they would generate a second cyclic subgroup of order . Let be the unique subgroup of order and the set of elements of order . As all generate , must be contained in all centralizers of elements in . Note that operates on itself via conjugation. Orbit-Stabilizer-Theorem tells us for : This follows as all elements of order are conjugated and holds. It follows, that , which leads to for all . For the normal subgroup part, note that for an inner automorphism and . Let arbitrary, then for . Let be an arbitrary inner automorphism. It follows that there is a with It follows that is invariant under inner automorphisms, i.e. normal. Orbit-Stabilizer-Theorem tells us that . As all stabilizers of elements of order are equal to the same cyclic group of order , it follows, that there exist only one cyclic group of order , it follows and . Thanks to anyone, who read till here ;) Another property, which my GAP-study suggests to be equivalent is : is cyclic This proof has low priority, as I first want to have my circle-implications. I guess I can show, that is contained in the unique cyclic group of order , by proving, that is abelian. I did not succeed yet, though.","G |G|\leq\frac{mk^2}{\varphi(m)}, m k m G |G|=\frac{mk^2}{\varphi(m)} G k<\infty m i) |G|=\frac{mk^2}{\varphi(m)} ii) k=\varphi(m) iii) G m iv) C_m \cong C_G(x)=C_G(y)\trianglelefteq G x,y\in G i) \implies ii) m C_G(x) |C_G(x)|=\frac{mk}{\varphi(m)} m C_G(x) \langle x \rangle C_G(x) C_G(x) \frac{|C_G(x)|}{m} \varphi(m) m C_G(x) \varphi(m)\frac{|C_G(x)|}{m} m \varphi(m)\frac{|C_G(x)|}{m} < k |C_G(x)| < \frac{mk}{\varphi(m)} m ii) \iff iii) k=\varphi(m) m \varphi(m) m m m \varphi(m) m m m iii) \implies iv) Z m X=\{x_1,\dots,x_k\} m x\in X Z Z X G x \in X |G|=|^Gx||G_x|=k|G_x|=\frac{mk^2}{\varphi(m)}=mk m k=\varphi(m) |G_x|=m G_x=Z\cong C_m x \in X \phi(x_i)=x_j \phi i,j\in \{1,\dots k\} y \in Z y=x_1^\alpha \alpha \in \mathbb{N} \phi i \in \{1,\dots k\} \phi(y)=\phi(x_1^\alpha)=\phi(x_1)^\alpha=x_i^\alpha \in Z Z iv) \implies i) |G|=|^Gx||G_x|=mk m m m k=\varphi(m) |G|=mk=\frac{mk^2}{\varphi(m)} v) G' G' Z m G/Z","['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
82,Limit of $\mathbb{Z}/n\mathbb{Z}$,Limit of,\mathbb{Z}/n\mathbb{Z},"This is a super weird question coming from someone who is just starting out in mathematics. If $n$ is a positive integer, one can notice that as $n$ grows, $\mathbb{Z}/n\mathbb{Z}$ starts to look more and more like $\mathbb{N}$ . If I were a small integer $k$ , the entire group would begin to look more and more indistinguishable from $\mathbb{N}$ as $n$ grows - my additive inverse is getting further and further away. Is this idea something that is studied or formalized anywhere?","This is a super weird question coming from someone who is just starting out in mathematics. If is a positive integer, one can notice that as grows, starts to look more and more like . If I were a small integer , the entire group would begin to look more and more indistinguishable from as grows - my additive inverse is getting further and further away. Is this idea something that is studied or formalized anywhere?",n n \mathbb{Z}/n\mathbb{Z} \mathbb{N} k \mathbb{N} n,"['abstract-algebra', 'group-theory', 'ring-theory']"
83,Isomorphism between the actions of $G$ on $G/H$ and $G/gHg^{-1}$?,Isomorphism between the actions of  on  and ?,G G/H G/gHg^{-1},"I'm doing Aluffi's Chapter 0, and Exercise 9.13 asks: Prove that for all subgroups $H$ of a group $G$ and for all $g\in G$ , $G/H$ and $G/(gHg^{-1})$ (endowed with the action of G by left-multiplication) are isomorphic in G-Set. My plan is to first find a bijection between $G/H$ and $G/(gHg^{-1})$ , then prove that the map commutes with the action. The first map I thought of was just $\varphi:G/H \longrightarrow G/(gHg^{-1})$ defined by $aH \mapsto a(gHg^{-1})$ , but the problem is that this is not well defined, since we can have $aH = a'H$ but $a(gHg^{-1}) \neq a'(gHg^{-1})$ . What would be well-defined is $aH \mapsto g(aH)g^{-1}$ . This works as a bijection between $G/H$ and $G/(gHg^{-1})$ , but the problem is that is does not commute with the action of $G$ . If the action wasn't strictly left-multiplication, then I could make the map work (by making it conjugate instead), but Aluffi is specifying that the action must be left multiplication. So now I don't really know what to do. On one hand, my gut feeling tells me that left-multiplication is just not ""compatible"" with conjugation, and maybe there's no way to make $\varphi$ commute with the action of $G$ . On the other hand, Aluffi's exercises are pretty well done, and I might be just missing something?","I'm doing Aluffi's Chapter 0, and Exercise 9.13 asks: Prove that for all subgroups of a group and for all , and (endowed with the action of G by left-multiplication) are isomorphic in G-Set. My plan is to first find a bijection between and , then prove that the map commutes with the action. The first map I thought of was just defined by , but the problem is that this is not well defined, since we can have but . What would be well-defined is . This works as a bijection between and , but the problem is that is does not commute with the action of . If the action wasn't strictly left-multiplication, then I could make the map work (by making it conjugate instead), but Aluffi is specifying that the action must be left multiplication. So now I don't really know what to do. On one hand, my gut feeling tells me that left-multiplication is just not ""compatible"" with conjugation, and maybe there's no way to make commute with the action of . On the other hand, Aluffi's exercises are pretty well done, and I might be just missing something?",H G g\in G G/H G/(gHg^{-1}) G/H G/(gHg^{-1}) \varphi:G/H \longrightarrow G/(gHg^{-1}) aH \mapsto a(gHg^{-1}) aH = a'H a(gHg^{-1}) \neq a'(gHg^{-1}) aH \mapsto g(aH)g^{-1} G/H G/(gHg^{-1}) G \varphi G,"['abstract-algebra', 'group-theory', 'group-actions']"
84,Group $G$ such that $[G : Z(G)] = 4$,Group  such that,G [G : Z(G)] = 4,"Let $G$ be a group, let $Z(G)$ be the center of $G$ , and suppose that $[G : Z(G)] = 4$ . (a) Prove that $x^2 \in Z(G)$ for every $x \in G$ . (b) Prove that $Z(G)$ contains an element of order two. Here are my thoughts so far: Recall that $Z(G)$ is a normal subgroup of $G$ . Thus, $G/Z(G)$ has a group structure. By the fact that $[G : Z(G)] = 4$ , we have that $|G/Z(G)| = 4$ . This gives that $G/Z(G)$ is either isomorphic to $\mathbb{Z}/4\mathbb{Z}$ or $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ . But, $G/Z(G)$ cannot be isomorphic to $\mathbb{Z}/4\mathbb{Z}$ ; this would mean that $G/Z(G)$ is cyclic $\Rightarrow$ $G$ abelian $\Rightarrow$ $G = Z(G)$ , which contradicts the index of $Z(G)$ in $G$ being equal to $4$ . Thus, so far I know that $G/Z(G)$ is isomorphic to $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ . I also know that $G/Z(G) \cong Inn(G)$ , the inner automorphism group of $G$ . How can I use these facts to  prove the desired facts ? Here's one attempt to use that $G/Z(G) \cong Inn(G)$ for part (b). If this is the case, we have that $Inn(G) \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ $\Rightarrow$ $Inn(G)$ necessarily contains an element of order $2$ . Thus, the map $\phi: G \longrightarrow G : h \longmapsto ghg^{-1}$ for some $g \in G$ , where $\phi$ is not the identity map, has order $2$ $\Rightarrow$ $g^2hg^{-2} = h$ $\Rightarrow$ $g^2h = hg^{2}$ . It looks like I have a commutativity relation here -- how can I relate this to $Z(G)$ having an element of order $2$ ? For part (a), is the right idea to look at the order of the cosets $G/Z(G)$ ? I suppose all cosets that aren't the identity are of order $2$ , since $G/Z(G) \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ . Is this the right route to take? Thanks for all of your help. (=","Let be a group, let be the center of , and suppose that . (a) Prove that for every . (b) Prove that contains an element of order two. Here are my thoughts so far: Recall that is a normal subgroup of . Thus, has a group structure. By the fact that , we have that . This gives that is either isomorphic to or . But, cannot be isomorphic to ; this would mean that is cyclic abelian , which contradicts the index of in being equal to . Thus, so far I know that is isomorphic to . I also know that , the inner automorphism group of . How can I use these facts to  prove the desired facts ? Here's one attempt to use that for part (b). If this is the case, we have that necessarily contains an element of order . Thus, the map for some , where is not the identity map, has order . It looks like I have a commutativity relation here -- how can I relate this to having an element of order ? For part (a), is the right idea to look at the order of the cosets ? I suppose all cosets that aren't the identity are of order , since . Is this the right route to take? Thanks for all of your help. (=",G Z(G) G [G : Z(G)] = 4 x^2 \in Z(G) x \in G Z(G) Z(G) G G/Z(G) [G : Z(G)] = 4 |G/Z(G)| = 4 G/Z(G) \mathbb{Z}/4\mathbb{Z} \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z} G/Z(G) \mathbb{Z}/4\mathbb{Z} G/Z(G) \Rightarrow G \Rightarrow G = Z(G) Z(G) G 4 G/Z(G) \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z} G/Z(G) \cong Inn(G) G G/Z(G) \cong Inn(G) Inn(G) \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z} \Rightarrow Inn(G) 2 \phi: G \longrightarrow G : h \longmapsto ghg^{-1} g \in G \phi 2 \Rightarrow g^2hg^{-2} = h \Rightarrow g^2h = hg^{2} Z(G) 2 G/Z(G) 2 G/Z(G) \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z},"['abstract-algebra', 'group-theory', 'normal-subgroups']"
85,Construct a nonabelian group of order 44,Construct a nonabelian group of order 44,,"Let $G$ be a group s.t. $|G|=44=2^211$ . Using Sylow's Theorems, I have deduced that there is a unique Sylow $11$ -subgroup of $G$ ; we shall call it $R$ . Let $P$ be a Sylow $2$ -subgroup of $G$ . Then we have $G=P\rtimes R$ and a homomorphism $$\gamma: P \rightarrow Aut(R)=Aut(\mathbb{Z_{11}})\cong(\mathbb{Z_{10}},+) .$$ Is this all correct so far? So what about $\gamma(p)=\phi_p$ where $\phi_p(r)=r^5$ . I thought this because $\tilde{5}\in\mathbb{Z_{10}}$ has order $4$ so the order of any element of $P$ could divide it... or something... So I was thinking the group would be something like $$G= \langle p,r | p^4=r^{11} prp^{-1}=r^5 \rangle .$$ Any insight is greatly appreciated! Thanks! I would like to know both where I went wrong and how to do it correctly. Did I do the above right? Identifying $\mathbb{Z_{11}}$ with the additive group of $\mathbb{Z_{10}}$ ? Or should I look at it multiplicatively, because I don't understand how that isomorphism works so it doesn't make sense to define the conjugation that makes the semi-direct product well defined based on elements of the additive group $\mathbb{Z_{10}}$ , but instead realize that $10 \in U(\mathbb{Z_{11}})$ has order $2$ so we can have a group presentation something like: $G = \langle p, r | p^2=r^{11}=1 , prp^{-1}=r^{10} \rangle$ Insight appreciated! I understand the dihedral group of the $22$ -gon works now, thank you. Can somebody help me with my approach in constructing a non-abelian group of order $44$ via the methods I've been using? Thanks!","Let be a group s.t. . Using Sylow's Theorems, I have deduced that there is a unique Sylow -subgroup of ; we shall call it . Let be a Sylow -subgroup of . Then we have and a homomorphism Is this all correct so far? So what about where . I thought this because has order so the order of any element of could divide it... or something... So I was thinking the group would be something like Any insight is greatly appreciated! Thanks! I would like to know both where I went wrong and how to do it correctly. Did I do the above right? Identifying with the additive group of ? Or should I look at it multiplicatively, because I don't understand how that isomorphism works so it doesn't make sense to define the conjugation that makes the semi-direct product well defined based on elements of the additive group , but instead realize that has order so we can have a group presentation something like: Insight appreciated! I understand the dihedral group of the -gon works now, thank you. Can somebody help me with my approach in constructing a non-abelian group of order via the methods I've been using? Thanks!","G |G|=44=2^211 11 G R P 2 G G=P\rtimes R \gamma: P \rightarrow Aut(R)=Aut(\mathbb{Z_{11}})\cong(\mathbb{Z_{10}},+) . \gamma(p)=\phi_p \phi_p(r)=r^5 \tilde{5}\in\mathbb{Z_{10}} 4 P G= \langle p,r | p^4=r^{11} prp^{-1}=r^5 \rangle . \mathbb{Z_{11}} \mathbb{Z_{10}} \mathbb{Z_{10}} 10 \in U(\mathbb{Z_{11}}) 2 G = \langle p, r | p^2=r^{11}=1 , prp^{-1}=r^{10} \rangle 22 44","['abstract-algebra', 'group-theory']"
86,Example of factorization in a polynomial ring which is not an UFD,Example of factorization in a polynomial ring which is not an UFD,,"I'm looking for a particular example of a polynomial ring $A[x]$ , with $A$ integral domain, which is not an UFD. An easy example is $\mathbb{Z}[\sqrt{-5}][x]$ , here $6 x^2 = (2x)(3x) = ((1+\sqrt{-5})x)((1-\sqrt{-5})x)$ . I would like to find a ring and a polynomial where the problem is not only in the coefficients. In other words a ring $A[x]$ where there exist a polynomial $f \in A[x]$ with two factorizations that are not of the form $f = (a_1g)(b_1h) = (a_2 g)(b_2h)$ , with $g,h \in A[x]$ , $a = a_1b_1 = a_2b_2 \in A$ (with $a_1b_1, a_2b_2$ two factorization of $a$ ). Or not of a similar form with more factors.","I'm looking for a particular example of a polynomial ring , with integral domain, which is not an UFD. An easy example is , here . I would like to find a ring and a polynomial where the problem is not only in the coefficients. In other words a ring where there exist a polynomial with two factorizations that are not of the form , with , (with two factorization of ). Or not of a similar form with more factors.","A[x] A \mathbb{Z}[\sqrt{-5}][x] 6 x^2 = (2x)(3x) = ((1+\sqrt{-5})x)((1-\sqrt{-5})x) A[x] f \in A[x] f = (a_1g)(b_1h) = (a_2 g)(b_2h) g,h \in A[x] a = a_1b_1 = a_2b_2 \in A a_1b_1, a_2b_2 a",['abstract-algebra']
87,Abstract algebra subgroup proof verification,Abstract algebra subgroup proof verification,,"This is my first attempt at a formally written proof so I would appreciate any pointers as far as proof-writing technique or the validity of the actual proof itself. Note: I have not formally taken abstract algebra or a proof-writing course so I am sure that I am lacking in many proof-writing aspects, so I would really love a lot of constructive criticism both on the actual proof itself, and the way I wrote the proof. I also go into greater detail than might be appropriate for this type of proof because I am shaky on a lot of the math foundations so I figure that any imperfections in my knowledge will be more easily seen with a more explicit construction of this proof. Thank you all in advance. Let $G$ be a finite group, and let $S$ be a nonempty subset of $G$ . Suppose $S$ is closed with respect to multiplication. Prove that $S$ is a subgroup of $G$ . (HINT: It remains to prove that $S$ contains $e$ and is closed with respect to inverses. Let $S$ = { $a_1$ ... $a_n$ }. If $a_i$ $∈$ $S$ , consider the distinct elements $a_ia_1$ , $a_ia_2$ , $...$ $a_ia_n$ Proof: First we will define a function $A_1 : S \rightarrow S$ that maps $s \mapsto a_1s$ . This function is injective because $$a_1y = a_1x$$ $$a^{-1}_1a_1y = a^{-1}_1a_1x$$ $$y = x$$ The function is then surjective because $A_1(S) \subseteq S$ and since $A_1$ is injective, it contains $|S|$ elements. Therefore $A_1$ maps onto every element in $S$ and is therefore surjective as well. This means that $a_1$ is in the image of $A_1$ . Therefore $$A_1(a_1) = a_1$$ $$a_1s = a_1$$ $$s = e$$ Since $S$ is closed under multiplication, $e \in S$ . Next, we will define a function $A_2 : S \rightarrow S$ that maps $s \mapsto a^2_1s$ . This function is also injective $$a^2_1x = a^2_1y$$ $$x = y$$ It follows that this function is also surjective since it too is injective and contains |S| elements. This means that $a_1$ is in the image of $A_2$ as well. Therefore $$A_2(z) = a_1$$ $$a^2_1z = a_1$$ $$z = a^{-1}_1$$ Since $S$ is closed under multiplication $a^{-1}_1 \in S$ . Therefore $e, a^{-1}_1 \in S$ so $S$ is a subgroup of $G$ . Please tear this apart! Thanks in advance.","This is my first attempt at a formally written proof so I would appreciate any pointers as far as proof-writing technique or the validity of the actual proof itself. Note: I have not formally taken abstract algebra or a proof-writing course so I am sure that I am lacking in many proof-writing aspects, so I would really love a lot of constructive criticism both on the actual proof itself, and the way I wrote the proof. I also go into greater detail than might be appropriate for this type of proof because I am shaky on a lot of the math foundations so I figure that any imperfections in my knowledge will be more easily seen with a more explicit construction of this proof. Thank you all in advance. Let be a finite group, and let be a nonempty subset of . Suppose is closed with respect to multiplication. Prove that is a subgroup of . (HINT: It remains to prove that contains and is closed with respect to inverses. Let = { ... }. If , consider the distinct elements , , Proof: First we will define a function that maps . This function is injective because The function is then surjective because and since is injective, it contains elements. Therefore maps onto every element in and is therefore surjective as well. This means that is in the image of . Therefore Since is closed under multiplication, . Next, we will define a function that maps . This function is also injective It follows that this function is also surjective since it too is injective and contains |S| elements. This means that is in the image of as well. Therefore Since is closed under multiplication . Therefore so is a subgroup of . Please tear this apart! Thanks in advance.","G S G S S G S e S a_1 a_n a_i ∈ S a_ia_1 a_ia_2 ... a_ia_n A_1 : S \rightarrow S s \mapsto a_1s a_1y = a_1x a^{-1}_1a_1y = a^{-1}_1a_1x y = x A_1(S) \subseteq S A_1 |S| A_1 S a_1 A_1 A_1(a_1) = a_1 a_1s = a_1 s = e S e \in S A_2 : S \rightarrow S s \mapsto a^2_1s a^2_1x = a^2_1y x = y a_1 A_2 A_2(z) = a_1 a^2_1z = a_1 z = a^{-1}_1 S a^{-1}_1 \in S e, a^{-1}_1 \in S S G","['abstract-algebra', 'group-theory', 'proof-verification', 'proof-writing', 'finite-groups']"
88,When is $p^2+1$ twice of a prime?,When is  twice of a prime?,p^2+1,"When trying to solve a bigger problem, I came across the problem of characterising all primes $p,q$ such that $p^2+1=2q$ . That is, are there necessary and sufficient conditions for primes $p,q$ to satisfy the equation? Even better, is there a paramatrisation of solutions (though, this is probably unlikely)? I know the solutions $(p,q)=(3,5),(5,13),(11,61),(19,181),(29,421)$ but I don't know that these are the only ones (indeed, it seems likely there are many more). Some incomplete thoughts: I immediately made the factorisation $(p+1)(p-1)=2(q-1)$ , and because $p$ is obviously odd, let $p=2p_1+1$ . This leads us to the equation $2p_1(p_1+1)=q-1$ . If we substituted $q=2q_1+1$ we have $p_1(p_1+1)=q_1$ , so $q$ is twice of the product of two consecutive integers, plus one. It follows that $q$ is $1$ mod $4$ , and $p^2$ is $1$ mod $8$ . The same conclusion can be obtained simply by noting that $-1$ must be a quadratic residue mod $2q$ , hence $1$ is a $4$ th power residue mod $2q$ . By Lagrange's Theorem we have $4\mid\phi(2q)=q-1$ , so $q \equiv1$ mod $4$ . Any further thoughts are appreciated!","When trying to solve a bigger problem, I came across the problem of characterising all primes such that . That is, are there necessary and sufficient conditions for primes to satisfy the equation? Even better, is there a paramatrisation of solutions (though, this is probably unlikely)? I know the solutions but I don't know that these are the only ones (indeed, it seems likely there are many more). Some incomplete thoughts: I immediately made the factorisation , and because is obviously odd, let . This leads us to the equation . If we substituted we have , so is twice of the product of two consecutive integers, plus one. It follows that is mod , and is mod . The same conclusion can be obtained simply by noting that must be a quadratic residue mod , hence is a th power residue mod . By Lagrange's Theorem we have , so mod . Any further thoughts are appreciated!","p,q p^2+1=2q p,q (p,q)=(3,5),(5,13),(11,61),(19,181),(29,421) (p+1)(p-1)=2(q-1) p p=2p_1+1 2p_1(p_1+1)=q-1 q=2q_1+1 p_1(p_1+1)=q_1 q q 1 4 p^2 1 8 -1 2q 1 4 2q 4\mid\phi(2q)=q-1 q \equiv1 4","['abstract-algebra', 'number-theory', 'prime-numbers', 'diophantine-equations']"
89,Why is $x^4 - 4x + 2$ irreducible over $\mathbb Q(i)$?,Why is  irreducible over ?,x^4 - 4x + 2 \mathbb Q(i),"This is an exercise from Garling's A Course in Galois Theory Ch. 5 on irreducible polynomials. The other part of the question was to show that $x^5 - 4x + 2$ was irreducible over $\mathbb Q(i)$ .  I got that one.  Clearly the polynomial is irreducible over $\mathbb Q$ by Eisenstein and Gauss' lemma, and, since $5$ and $2$ are relatively prime, it follows from a previous exercise that a root of the polynomial must have degree $5$ over $\mathbb Q(i)$ . So the given polynomial must be the root's minimal polynomial over $\mathbb Q(i)$ (and not just over $\mathbb Q$ ).  So in particular the polynomial must be irreducible over $\mathbb Q(i)$ . But that trick doesn't work for $x^5 - 4x + 2$ anymore, and I'm stumped.  I convinced myself that it can't have a linear factor over $\mathbb Z[i]$ because that would mean a root that was a factor of $2$ , and none of the factors of $2$ (namely, $\pm 2, \pm 1, \pm 2i, \pm i, \pm (1 - i), \pm (1 + i)$ ) solve the polynomial, but I don't see why it can't have a quadratic factor.  Help!","This is an exercise from Garling's A Course in Galois Theory Ch. 5 on irreducible polynomials. The other part of the question was to show that was irreducible over .  I got that one.  Clearly the polynomial is irreducible over by Eisenstein and Gauss' lemma, and, since and are relatively prime, it follows from a previous exercise that a root of the polynomial must have degree over . So the given polynomial must be the root's minimal polynomial over (and not just over ).  So in particular the polynomial must be irreducible over . But that trick doesn't work for anymore, and I'm stumped.  I convinced myself that it can't have a linear factor over because that would mean a root that was a factor of , and none of the factors of (namely, ) solve the polynomial, but I don't see why it can't have a quadratic factor.  Help!","x^5 - 4x + 2 \mathbb Q(i) \mathbb Q 5 2 5 \mathbb Q(i) \mathbb Q(i) \mathbb Q \mathbb Q(i) x^5 - 4x + 2 \mathbb Z[i] 2 2 \pm 2, \pm 1, \pm 2i, \pm i, \pm (1 - i), \pm (1 + i)","['abstract-algebra', 'irreducible-polynomials']"
90,Why noetherian ring satisfies the maximal condition?,Why noetherian ring satisfies the maximal condition?,,"""maximal condition"" means if any non-empty collection of ideals in R has a maximal element (under set inclusion). And we define noetherian ring to be a ring such that any ascending chain of ideals is finite. I don't see why the definition implies the maximal condition. Let's suppose $S=\{\mathfrak{A}_1, \mathfrak{A}_2\}$ such that $\mathfrak{A}_1\bigcap\mathfrak{A}_2=\{0_R\}$ and none of them is  unit ideal. Then there is no such maximal element. There is no need for an ideal properly contains in another ideal if it is not a maximal element. Can anyone point out what's the problem here? Thanks in advance Edit: What I am confusing is what will be the maximal element in my example. My definition for maximal element is: given $(S, R)$ a poset and $T\subset S$, then $s\in S$ a maximal element of $T$ if $sRy$ with $y\in S$ implies $s=y$. And I proved ""noetherian ring satisfies the maximal condition"" in this way: Since any non-empty collection of ideals is a poset, let $S$ be one and $T$ be a chain of $S$. As R is noetherian, there must be an ""end"" for the chain, namely $\mathfrak{A}\in T$. Then it is an upper bound of $T$ and hence $S$ is inductive and the result follow from Zorn's Lemma. But then I found I can't tell what is the maximal element in my example. So either my proof is false or something else goes wrong","""maximal condition"" means if any non-empty collection of ideals in R has a maximal element (under set inclusion). And we define noetherian ring to be a ring such that any ascending chain of ideals is finite. I don't see why the definition implies the maximal condition. Let's suppose $S=\{\mathfrak{A}_1, \mathfrak{A}_2\}$ such that $\mathfrak{A}_1\bigcap\mathfrak{A}_2=\{0_R\}$ and none of them is  unit ideal. Then there is no such maximal element. There is no need for an ideal properly contains in another ideal if it is not a maximal element. Can anyone point out what's the problem here? Thanks in advance Edit: What I am confusing is what will be the maximal element in my example. My definition for maximal element is: given $(S, R)$ a poset and $T\subset S$, then $s\in S$ a maximal element of $T$ if $sRy$ with $y\in S$ implies $s=y$. And I proved ""noetherian ring satisfies the maximal condition"" in this way: Since any non-empty collection of ideals is a poset, let $S$ be one and $T$ be a chain of $S$. As R is noetherian, there must be an ""end"" for the chain, namely $\mathfrak{A}\in T$. Then it is an upper bound of $T$ and hence $S$ is inductive and the result follow from Zorn's Lemma. But then I found I can't tell what is the maximal element in my example. So either my proof is false or something else goes wrong",,"['abstract-algebra', 'ring-theory', 'noetherian']"
91,Proof of isomorphism between $\text{PGL}_2(\mathbb{F}_5)$ and $S_5$,Proof of isomorphism between  and,\text{PGL}_2(\mathbb{F}_5) S_5,"This question has been asked here before but I don't think any of the previous answers are clear to someone like me who only has an elementary background in abstract algebra. So can I take the time to ask once again: Why do we have $PGL_2(\mathbb{F}_5) \cong S_5$? So far I have tried to find an action of $GL_2(\mathbb{F}_5)$ on a set with 5 elements but have had no luck. However if you let $GL_2(\mathbb{F}_5)$ act on the projective line $P^1(\mathbb{F}_5)$ then we get a homomorphism to $S_6$ whose kernel is the set of scalar matrices which is exactly $Z(GL_2(\mathbb{F}_5))$. So we get an isomorphism from $PGL_2(\mathbb{F}_5)$ to a subgroup of $S_6$ . I then tried to consider the action of $S_6$ on $S_6:PGL_2(\mathbb{F}_5)$ and tried to use that to show the isomorphism but it didn't help. Does anyone know how it might be possible to proceed from here or am I going down completely the wrong track? Any hints are much appreciated! EDIT: Here is the full question as requested: Show that the groups $SL_2(\mathbb{F}_4)$ and $PSL_2(\mathbb{F}_5)$ both have order 60. Use this and some results from previous questions to show that they are both isomorphic to the alternating group $A_5$. Show that $SL_2(\mathbb{F}_5)$ and $PGL_2(\mathbb{F}_5)$ both have order 120, that $SL_2(\mathbb{F}_5)$ is not isomorphic to $S_5$, but $PGL_2(\mathbb{F}_5)$ is. The previous questions which the question refers to (and I was able to do) were: Let $G$ be a group of order 60 which has more than one Sylow 5-subgroup. Show that $G$ is simple. Let $G$ be a simple group of order 60. Deduce that $G \cong A_5$, as follows. Show that $G$ has six Sylow 5-subgroups. By considering the conjugation action of the set of Sylow 5-subgroups, show that $G$ is isomorphic to a subgroup $G \leq A_6$ of index 6. By considering the action of $A_6$ on $A_6:G$, show that that there is an automorphism of $A_6$ taking $G$ to $A_5$.","This question has been asked here before but I don't think any of the previous answers are clear to someone like me who only has an elementary background in abstract algebra. So can I take the time to ask once again: Why do we have $PGL_2(\mathbb{F}_5) \cong S_5$? So far I have tried to find an action of $GL_2(\mathbb{F}_5)$ on a set with 5 elements but have had no luck. However if you let $GL_2(\mathbb{F}_5)$ act on the projective line $P^1(\mathbb{F}_5)$ then we get a homomorphism to $S_6$ whose kernel is the set of scalar matrices which is exactly $Z(GL_2(\mathbb{F}_5))$. So we get an isomorphism from $PGL_2(\mathbb{F}_5)$ to a subgroup of $S_6$ . I then tried to consider the action of $S_6$ on $S_6:PGL_2(\mathbb{F}_5)$ and tried to use that to show the isomorphism but it didn't help. Does anyone know how it might be possible to proceed from here or am I going down completely the wrong track? Any hints are much appreciated! EDIT: Here is the full question as requested: Show that the groups $SL_2(\mathbb{F}_4)$ and $PSL_2(\mathbb{F}_5)$ both have order 60. Use this and some results from previous questions to show that they are both isomorphic to the alternating group $A_5$. Show that $SL_2(\mathbb{F}_5)$ and $PGL_2(\mathbb{F}_5)$ both have order 120, that $SL_2(\mathbb{F}_5)$ is not isomorphic to $S_5$, but $PGL_2(\mathbb{F}_5)$ is. The previous questions which the question refers to (and I was able to do) were: Let $G$ be a group of order 60 which has more than one Sylow 5-subgroup. Show that $G$ is simple. Let $G$ be a simple group of order 60. Deduce that $G \cong A_5$, as follows. Show that $G$ has six Sylow 5-subgroups. By considering the conjugation action of the set of Sylow 5-subgroups, show that $G$ is isomorphic to a subgroup $G \leq A_6$ of index 6. By considering the action of $A_6$ on $A_6:G$, show that that there is an automorphism of $A_6$ taking $G$ to $A_5$.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'group-isomorphism', 'exceptional-isomorphisms']"
92,"Torsion-free abelian groups $G,H$ such that $k[G] \cong k[H]$ (as rings) for any field $k$",Torsion-free abelian groups  such that  (as rings) for any field,"G,H k[G] \cong k[H] k","Let $G,H$ be torsion-free abelian groups such that $k[G] \cong k[H]$ for any field $k$ . Then is it true that $G \cong H$ ? If this is not true, then what if I change the hypothesis to $R[G]\cong R[H]$ for any non-zero commutative unital ring; is the conclusion true then ?","Let be torsion-free abelian groups such that for any field . Then is it true that ? If this is not true, then what if I change the hypothesis to for any non-zero commutative unital ring; is the conclusion true then ?","G,H k[G] \cong k[H] k G \cong H R[G]\cong R[H]","['abstract-algebra', 'ring-theory', 'field-theory', 'abelian-groups', 'group-rings']"
93,Vertical harpoon (half-arrow) notation,Vertical harpoon (half-arrow) notation,,"I am studying a paper about Subgroups of Infinite Symmetric Groups by Macpherson and Neumann; throughout the paper, the authors use the notation $\upharpoonright$. For example, when they seek to topologize an infinite symmetric group $Sym(\Omega)$, they define the closure of a subset $X$ of $Sym(\Omega)$ as such: $\{f \in Sym(\Omega)  \ |$ for all finite subsets $\Phi$ of $\Omega$ there exists $x \in X$ such that $x\upharpoonright\Phi=f\upharpoonright\Phi\}$ The authors don't define this notation, but they use it in several proofs. What do the authors mean when they use it?","I am studying a paper about Subgroups of Infinite Symmetric Groups by Macpherson and Neumann; throughout the paper, the authors use the notation $\upharpoonright$. For example, when they seek to topologize an infinite symmetric group $Sym(\Omega)$, they define the closure of a subset $X$ of $Sym(\Omega)$ as such: $\{f \in Sym(\Omega)  \ |$ for all finite subsets $\Phi$ of $\Omega$ there exists $x \in X$ such that $x\upharpoonright\Phi=f\upharpoonright\Phi\}$ The authors don't define this notation, but they use it in several proofs. What do the authors mean when they use it?",,"['abstract-algebra', 'notation', 'topological-groups']"
94,Class group of $\mathbb{Q}(\sqrt{7})$,Class group of,\mathbb{Q}(\sqrt{7}),"Find the class group of $\mathbb{Q}(\sqrt{7})$ . $\textit{Hint}$ : notice that $2=(3+\sqrt{7})(3-\sqrt{7})$ and that $-1+\sqrt{7}=(2+\sqrt{7})(3-\sqrt{7})$ Here's what I've done: the Minkowski bound is $\sqrt{7}\approx 2.65$ , so we need to analyse $2\mathcal{O}$ . Since $x^2-7=(x+1)^2(\text{mod }2)$ , then $(2)=\mathfrak{p}^2$ , where $\mathfrak{p}=(2, 1+\sqrt{7})$ . $[\mathfrak{p}]$ has order $\leq 2$ because $[\mathfrak{p}]^2=[(2)]=e$ . If $\mathfrak{p}=(a+b\sqrt{7})$ for some $a+b\sqrt{7}\in\mathcal{O}$ , then $(2)=\mathfrak{p}^2=((a+b\sqrt{7})^2)$ , so $2=u(a+b\sqrt{7})^2$ for some unit $u$ . The only units in $\mathbb{Z}[\sqrt{7}]$ are $(8+3\sqrt{7})^n$ for some $n\in\mathbb{Z}$ . Obviously $n$ cannot be even, because that would mean $2=w^2$ for some $w\in\mathbb{Z}[\sqrt{7}]$ (absurd), so we must have $2(8+3\sqrt{7})=w^2$ for some $w\in\mathbb{Z}[\sqrt{7}]$ , which is also impossible by simple verification. Therefore $[\mathfrak{p}]\neq e$ and $Cl_{\mathbb{Q}(\sqrt{7})}=\mathbb{Z}/2\mathbb{Z}$ . That took a little bit of work, and I suppose the tip could be useful, but I dont see how.","Find the class group of . : notice that and that Here's what I've done: the Minkowski bound is , so we need to analyse . Since , then , where . has order because . If for some , then , so for some unit . The only units in are for some . Obviously cannot be even, because that would mean for some (absurd), so we must have for some , which is also impossible by simple verification. Therefore and . That took a little bit of work, and I suppose the tip could be useful, but I dont see how.","\mathbb{Q}(\sqrt{7}) \textit{Hint} 2=(3+\sqrt{7})(3-\sqrt{7}) -1+\sqrt{7}=(2+\sqrt{7})(3-\sqrt{7}) \sqrt{7}\approx 2.65 2\mathcal{O} x^2-7=(x+1)^2(\text{mod }2) (2)=\mathfrak{p}^2 \mathfrak{p}=(2, 1+\sqrt{7}) [\mathfrak{p}] \leq 2 [\mathfrak{p}]^2=[(2)]=e \mathfrak{p}=(a+b\sqrt{7}) a+b\sqrt{7}\in\mathcal{O} (2)=\mathfrak{p}^2=((a+b\sqrt{7})^2) 2=u(a+b\sqrt{7})^2 u \mathbb{Z}[\sqrt{7}] (8+3\sqrt{7})^n n\in\mathbb{Z} n 2=w^2 w\in\mathbb{Z}[\sqrt{7}] 2(8+3\sqrt{7})=w^2 w\in\mathbb{Z}[\sqrt{7}] [\mathfrak{p}]\neq e Cl_{\mathbb{Q}(\sqrt{7})}=\mathbb{Z}/2\mathbb{Z}","['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
95,Permutation of coefficients of polynomials,Permutation of coefficients of polynomials,,"Are there any known results relating to permutation of coefficients of polynomials? for example given a polynomial, if the coefficients are permuted, then are there any results relating the two? related question, given set of all polynomials that are permutations of coefficients, are there any known results? The only possible example that I can think of is that if roots of a polynomial are not rational, then all polynomials permutations of it's coefficients also have no rational roots. Not sure if this is correct or incorrect.","Are there any known results relating to permutation of coefficients of polynomials? for example given a polynomial, if the coefficients are permuted, then are there any results relating the two? related question, given set of all polynomials that are permutations of coefficients, are there any known results? The only possible example that I can think of is that if roots of a polynomial are not rational, then all polynomials permutations of it's coefficients also have no rational roots. Not sure if this is correct or incorrect.",,['abstract-algebra']
96,Jacobson radical of a group algebra,Jacobson radical of a group algebra,,"I have not too much experience of playing with rings. So the question could be elementary but for me it is not till now. Let $K$ be a field of characteristic $p$ and $G$ a finite group of order divisible by $p$. Can we determine the Jacobson radical of the group algebra $K[G]$? If this is difficult for arbitray finite group (with $p||G|$) then taking simplest example - $G=\langle x|x^p=1\rangle$, can we determine $J(K[G])$? (The thing I know is that if characteristic of a field does not divides $|G|$ or if it is zero, then the group algebra is semi-simple so I can ensure that Jacobson radical of the group algebra is zero. I am considering complementary side of this fact.)","I have not too much experience of playing with rings. So the question could be elementary but for me it is not till now. Let $K$ be a field of characteristic $p$ and $G$ a finite group of order divisible by $p$. Can we determine the Jacobson radical of the group algebra $K[G]$? If this is difficult for arbitray finite group (with $p||G|$) then taking simplest example - $G=\langle x|x^p=1\rangle$, can we determine $J(K[G])$? (The thing I know is that if characteristic of a field does not divides $|G|$ or if it is zero, then the group algebra is semi-simple so I can ensure that Jacobson radical of the group algebra is zero. I am considering complementary side of this fact.)",,"['abstract-algebra', 'ring-theory', 'representation-theory']"
97,Why do we study the number of homomorphisms/isomorphisms between fields?,Why do we study the number of homomorphisms/isomorphisms between fields?,,"From the first abstract algebra class, we encounter many problems that ask us to find the number of homomorphisms/isomorphism a between two algebra structures (e.g. field). My first question is why do we study homomorphisms? To me, it is much weaker than isomorphisms (although stronger than a mere bijection, of course, so I guess it's better than nothing). My second question is, why are we especially interested in the number of homomorphisms/isomorphisms ? Or is it just something that tests students' understanding of the subject? Update: Was out for some gyoza and wrote on my phone. I have this question because I just graduated and am taking an online course on Galois Theory . The quiz has quite some problems on ""counting morphisms"". One example would be, Given an algebraic extension $F/\mathbb{Q}$, how many homomorphisms $F\to \mathbb{C}$ of fields are there? Another example would be, How many homomorphisms are there from $\mathbb{F}_{p^3}$ to $\mathbb{F}_{p^4}$? I guess I am just not fully understanding the motivation/take away here (which really makes me think it's difficult to learn advanced math without being in a university). The first question sort of makes sense since, $\mathbb{C}$ is a ""natural extension"" of $\mathbb{Q}$ even though it is not an algebraic one. But I don't have any thought on the second question.","From the first abstract algebra class, we encounter many problems that ask us to find the number of homomorphisms/isomorphism a between two algebra structures (e.g. field). My first question is why do we study homomorphisms? To me, it is much weaker than isomorphisms (although stronger than a mere bijection, of course, so I guess it's better than nothing). My second question is, why are we especially interested in the number of homomorphisms/isomorphisms ? Or is it just something that tests students' understanding of the subject? Update: Was out for some gyoza and wrote on my phone. I have this question because I just graduated and am taking an online course on Galois Theory . The quiz has quite some problems on ""counting morphisms"". One example would be, Given an algebraic extension $F/\mathbb{Q}$, how many homomorphisms $F\to \mathbb{C}$ of fields are there? Another example would be, How many homomorphisms are there from $\mathbb{F}_{p^3}$ to $\mathbb{F}_{p^4}$? I guess I am just not fully understanding the motivation/take away here (which really makes me think it's difficult to learn advanced math without being in a university). The first question sort of makes sense since, $\mathbb{C}$ is a ""natural extension"" of $\mathbb{Q}$ even though it is not an algebraic one. But I don't have any thought on the second question.",,"['abstract-algebra', 'soft-question', 'morphism']"
98,What is the quotient ring $\Bbb Z[x]/(2x-3)$?,What is the quotient ring ?,\Bbb Z[x]/(2x-3),"Is there a good description for the quotient ring $\Bbb Z[x]/(2x-3)$? That is, does the quotient ring $\Bbb Z[x]/(2x-3)$ isomorphic to some other ring with a simple description? I know that $\Bbb Z[x]/(2x-3)$ is an integral domain since $2x-3$ is irreducible in $\Bbb Z[x]$, so the quotient ring is indeed well defined. But I don't know if we can go further than that.","Is there a good description for the quotient ring $\Bbb Z[x]/(2x-3)$? That is, does the quotient ring $\Bbb Z[x]/(2x-3)$ isomorphic to some other ring with a simple description? I know that $\Bbb Z[x]/(2x-3)$ is an integral domain since $2x-3$ is irreducible in $\Bbb Z[x]$, so the quotient ring is indeed well defined. But I don't know if we can go further than that.",,"['abstract-algebra', 'ring-theory']"
99,1-dim representations of the affine Hecke algebra for $G = \text{SL}_2$,1-dim representations of the affine Hecke algebra for,G = \text{SL}_2,"I want to count the number of (isomoprhism clases) of one-dimensional representations of the affine Hecke algebra for $G = \text{SL}_2$ .  I'm doing it in two ways: (1) by explicitly looking at generators and relations, and (2) by looking at the cohomology of flags fixed by two $q$ -commuting elements. The problem is by (1) I count four, and by (2) I only count two.  I'm not entirely sure where I am going wrong. Method 1: The affine Hecke algebra for $\text{SL}_2$ is an algebra $H$ which is a free module over $k[q, q^{-1}]$ with basis $\{e^n, e^n T\}$ with multiplicative relations $$(T + 1)(T - q) = 0\,,$$ $$Te^{-1} - e^1 T = (1-q)e^1\,,$$ $$e^{-1} e^1 = 1\,.$$ Then, the one-dimensional dimensional irreducibles are as follows.  For one-dimensional representations, one has $$T \mapsto -1\,,$$ $$e^1 \mapsto \pm q^{-1/2}\,,$$ and $$T \mapsto q\,,$$ $$e^1 \mapsto \pm q^{1/2}\,.$$ i.e. there are four $1$ -dim representations. Method 2: We should be able to read off the irreducibles by Kazhdan-Lusztig theory.  Namely, for generic $q$ , for $(g, x) \in G \times \mathcal{N}$ and $g$ semisimple, such that $gxg^{-1} = qx$ , the cohomology of ""Springer"" fiber $\mathcal{B}_{g, x}$ (i.e. fixed by both $g, x$ ) is a big direct sum whose summands are the tensor product of an irreducible $H$ -module with an irreducible representation of the component group of the double centralizer $C(g, x)/C(g, x)^\circ$ .  Further, any given irreducible can only occur once in this list. So, I have for conjugacy classes of $(g, x)$ : (1) $x = 0$ , and $g$ is parameterized by $\mathbb{A}^1 = T//W$ .  When $g$ is regular semisimple, the fiber is two points, and when it is the identity, the fiber is $\mathbb{P}^1$ .  In either case the total cohomology is two dimensional.  Now, the centralizer when $g$ is regular is the torus $T$ , which is connected, so the $H$ -representation is really two dimensional (and not, say, the direct sum of two one-dimensional representations tensored with representations of the component group).  When $g = 1$ , then the centralizer is $G$ , which is still connected. (2) $x = \left(\begin{array}{cc}0&1\\0&0\end{array}\right)$ , and $g = \pm \left(\begin{array}{cc} \sqrt{q}&0\\0&1/\sqrt{q}\end{array}\right)$ .  The fiber here is a point.  So we have a one-dimensional cohomology.  The centralizer is two points, so not connected, but twisting with an irreducible representation of $\mathbb{Z}/2$ won't change our dimension count in any case. So here, we only find two $1$ -dim representations.  Where is the discrepancy?","I want to count the number of (isomoprhism clases) of one-dimensional representations of the affine Hecke algebra for .  I'm doing it in two ways: (1) by explicitly looking at generators and relations, and (2) by looking at the cohomology of flags fixed by two -commuting elements. The problem is by (1) I count four, and by (2) I only count two.  I'm not entirely sure where I am going wrong. Method 1: The affine Hecke algebra for is an algebra which is a free module over with basis with multiplicative relations Then, the one-dimensional dimensional irreducibles are as follows.  For one-dimensional representations, one has and i.e. there are four -dim representations. Method 2: We should be able to read off the irreducibles by Kazhdan-Lusztig theory.  Namely, for generic , for and semisimple, such that , the cohomology of ""Springer"" fiber (i.e. fixed by both ) is a big direct sum whose summands are the tensor product of an irreducible -module with an irreducible representation of the component group of the double centralizer .  Further, any given irreducible can only occur once in this list. So, I have for conjugacy classes of : (1) , and is parameterized by .  When is regular semisimple, the fiber is two points, and when it is the identity, the fiber is .  In either case the total cohomology is two dimensional.  Now, the centralizer when is regular is the torus , which is connected, so the -representation is really two dimensional (and not, say, the direct sum of two one-dimensional representations tensored with representations of the component group).  When , then the centralizer is , which is still connected. (2) , and .  The fiber here is a point.  So we have a one-dimensional cohomology.  The centralizer is two points, so not connected, but twisting with an irreducible representation of won't change our dimension count in any case. So here, we only find two -dim representations.  Where is the discrepancy?","G = \text{SL}_2 q \text{SL}_2 H k[q, q^{-1}] \{e^n, e^n T\} (T + 1)(T - q) = 0\,, Te^{-1} - e^1 T = (1-q)e^1\,, e^{-1} e^1 = 1\,. T \mapsto -1\,, e^1 \mapsto \pm q^{-1/2}\,, T \mapsto q\,, e^1 \mapsto \pm q^{1/2}\,. 1 q (g, x) \in G \times \mathcal{N} g gxg^{-1} = qx \mathcal{B}_{g, x} g, x H C(g, x)/C(g, x)^\circ (g, x) x = 0 g \mathbb{A}^1 = T//W g \mathbb{P}^1 g T H g = 1 G x = \left(\begin{array}{cc}0&1\\0&0\end{array}\right) g = \pm \left(\begin{array}{cc} \sqrt{q}&0\\0&1/\sqrt{q}\end{array}\right) \mathbb{Z}/2 1","['abstract-algebra', 'representation-theory', 'lie-groups', 'noncommutative-algebra', 'hecke-algebras']"
