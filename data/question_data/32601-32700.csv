,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Random Walk of a drunk man,Random Walk of a drunk man,,"Problem Statement: From where he stands, one step toward the cliff would send the drunken man over the edge. He takes random steps, either toward or away from the cliff. At any step his probability of taking a step away is 2/3, of a step toward the cliff 1/3. What is his chance of escaping the cliff? My take: Say the probability that he dies from where he stands right now is p.  Then, he could comfortably make one step left and end his life with probability 1/3 Or he could take one step away and two step towards and boom...take two steps away and three steps toward...so on and so forth Resulting in p= 1/3 + 2/3 * (1/3)^2 + (2/3)^2 * (1/3)^3 +.... Summing this infinite sequence gives me probability of dying as 3/7 (around 43%). I was rather puzzled when i learnt that the correct probability is 1/2. Cant figure out what are the other 7% ways for my drunken man to die which I missed above?","Problem Statement: From where he stands, one step toward the cliff would send the drunken man over the edge. He takes random steps, either toward or away from the cliff. At any step his probability of taking a step away is 2/3, of a step toward the cliff 1/3. What is his chance of escaping the cliff? My take: Say the probability that he dies from where he stands right now is p.  Then, he could comfortably make one step left and end his life with probability 1/3 Or he could take one step away and two step towards and boom...take two steps away and three steps toward...so on and so forth Resulting in p= 1/3 + 2/3 * (1/3)^2 + (2/3)^2 * (1/3)^3 +.... Summing this infinite sequence gives me probability of dying as 3/7 (around 43%). I was rather puzzled when i learnt that the correct probability is 1/2. Cant figure out what are the other 7% ways for my drunken man to die which I missed above?",,"['probability', 'puzzle', 'random-walk']"
1,Bernoulli trial: probability of even times of sum of $7$.,Bernoulli trial: probability of even times of sum of .,7,"We throw a pair of dice unlimited number of times. For any $n\in \Bbb N$,   let $$E_n=\text{""at the first n trials, the number of time we get sum of $7$ is even""}$$   Also let $P_n=P(E_n)$. We need to calculate $P_n$ (in terms of $n$). So I have used a recurrence relation (for $n>1$): $$P_n=\frac56 P_{n-1}+\frac16(1-P_{n-1})$$ and got $P_n=1/2\cdot(2/3)^n+1/2$, for $P_1=30/36=5/6$. Now, I need to to calculate $P_n$ in Bernoulli trial.","We throw a pair of dice unlimited number of times. For any $n\in \Bbb N$,   let $$E_n=\text{""at the first n trials, the number of time we get sum of $7$ is even""}$$   Also let $P_n=P(E_n)$. We need to calculate $P_n$ (in terms of $n$). So I have used a recurrence relation (for $n>1$): $$P_n=\frac56 P_{n-1}+\frac16(1-P_{n-1})$$ and got $P_n=1/2\cdot(2/3)^n+1/2$, for $P_1=30/36=5/6$. Now, I need to to calculate $P_n$ in Bernoulli trial.",,"['probability', 'combinatorics', 'binomial-distribution', 'bernoulli-numbers']"
2,In a random selection of three pairs among $6$ people what is the probability that each girl will be matched with her boyfriend?,In a random selection of three pairs among  people what is the probability that each girl will be matched with her boyfriend?,6,"There are $6$ people, $3$ boys and $3$ girls. Each boy is in a relationship with one girl. Three pairs are randomly drawn. What is the probability that these three pairs will be the actual couples? My reasoning was $$ P =  \frac{3}{\binom{6}{2}} \times \frac{2}{\binom{4}{2}} \times \frac{1}{\binom{2}{2}}$$ But this does not give me the answer a professor has given me. I'd appreciate some hints or new ways of approaching the problem.","There are $6$ people, $3$ boys and $3$ girls. Each boy is in a relationship with one girl. Three pairs are randomly drawn. What is the probability that these three pairs will be the actual couples? My reasoning was $$ P =  \frac{3}{\binom{6}{2}} \times \frac{2}{\binom{4}{2}} \times \frac{1}{\binom{2}{2}}$$ But this does not give me the answer a professor has given me. I'd appreciate some hints or new ways of approaching the problem.",,"['probability', 'combinatorics']"
3,Borel isomorphism between polish spaces,Borel isomorphism between polish spaces,,"In my lecture on stochastics the following result has been used: For any uncountable Polish space $X$ there is a Borel isomorphism between this space and the real line. I was not able to find a proof of this in the internet, other than in a book of Srivastava: ""A course on borel sets"". But the proof uses instruments that are far beyond my possibilities. Is there any ""simple"" proof of this fact?","In my lecture on stochastics the following result has been used: For any uncountable Polish space $X$ there is a Borel isomorphism between this space and the real line. I was not able to find a proof of this in the internet, other than in a book of Srivastava: ""A course on borel sets"". But the proof uses instruments that are far beyond my possibilities. Is there any ""simple"" proof of this fact?",,"['probability', 'measure-theory']"
4,Probability of every ball occurring in multiple independent random samples,Probability of every ball occurring in multiple independent random samples,,"An urn contains 5 distinct numbered balls. You choose 2 without replacement. You then reset the urn and choose another 2 without replacement. Do this one more time. Now you have three random samples of size 2. What is the probability that all of the numbered balls appear at least once in your 3 random samples of size 2? My thinking of a way to approach this is through complements. Finding the probability one of the balls is missing, two, and three. Then subtracting all of these scenarios from one. Is this a solid approach? Here is the work: P(all numbered balls appear at least once) = 1 - P(at least one ball is missing) P(at least one ball is missing) = P(one ball missing) + P(two balls are missing) + P(three balls are missing) I found the probabilities of one ball, two balls, and three balls missing to be the following: P(one ball missing) = $$\left(1*{4 \choose 2}/{5 \choose2}\right)^2$$ P(two balls missing) = $$\left(1*{3 \choose 2}/{5 \choose2}\right)^2$$ P(three ball missing) = $$\left(1*{2 \choose 2}/{5 \choose2}\right)^2$$ This is because the first time you can choose any three balls, in the one ball missing case, you can only choose two balls from four when there are five possible balls. You can choose either the two that are original or any combination with a different arbitrary two but one must be left out. This is true for both random samples following the first. Any thoughts?","An urn contains 5 distinct numbered balls. You choose 2 without replacement. You then reset the urn and choose another 2 without replacement. Do this one more time. Now you have three random samples of size 2. What is the probability that all of the numbered balls appear at least once in your 3 random samples of size 2? My thinking of a way to approach this is through complements. Finding the probability one of the balls is missing, two, and three. Then subtracting all of these scenarios from one. Is this a solid approach? Here is the work: P(all numbered balls appear at least once) = 1 - P(at least one ball is missing) P(at least one ball is missing) = P(one ball missing) + P(two balls are missing) + P(three balls are missing) I found the probabilities of one ball, two balls, and three balls missing to be the following: P(one ball missing) = $$\left(1*{4 \choose 2}/{5 \choose2}\right)^2$$ P(two balls missing) = $$\left(1*{3 \choose 2}/{5 \choose2}\right)^2$$ P(three ball missing) = $$\left(1*{2 \choose 2}/{5 \choose2}\right)^2$$ This is because the first time you can choose any three balls, in the one ball missing case, you can only choose two balls from four when there are five possible balls. You can choose either the two that are original or any combination with a different arbitrary two but one must be left out. This is true for both random samples following the first. Any thoughts?",,"['probability', 'random-variables', 'polya-urn-model']"
5,What is the probability that the upturned faces of three fair dice are all of different numbers?,What is the probability that the upturned faces of three fair dice are all of different numbers?,,"Three fair dice are rolled ($6$ sides). What is the probability that the upturned faces of the three dice are all of different numbers? I got that the number of possible outcomes total is $6^3$ and the number of possible outcomes for which the upturned dice are all different numbers is $6 * 5 * 4$, so the probability is $\frac{5}{9}$. Is this correct?","Three fair dice are rolled ($6$ sides). What is the probability that the upturned faces of the three dice are all of different numbers? I got that the number of possible outcomes total is $6^3$ and the number of possible outcomes for which the upturned dice are all different numbers is $6 * 5 * 4$, so the probability is $\frac{5}{9}$. Is this correct?",,"['probability', 'probability-theory', 'proof-verification', 'problem-solving']"
6,Rigorous Probability/Statistics Book reference? [duplicate],Rigorous Probability/Statistics Book reference? [duplicate],,"This question already has answers here : Good books on ""advanced"" probabilities (12 answers) Closed 3 years ago . Im wondering if anyone could recommend a book (or a few books) about statistics/probability for someone at the advanced undergraduate level who has taken some real analysis (at the level of baby rudin) and some mathematical statistics and probability (only with calculus and intro to proofs as prerequisite). I would like to really start from the beginning and approach statistics from a rigorous (rudin-esque) sort of approach, a lot of the statistics I've encountered so far has been a lot of hand waving and lacking in rigorous proofs. Im hoping for a few books to really build a rigorous foundation and intuition, not just introduce me to the topics as quickly as possible.  Thanks for any help and suggestions. Please let me know if what I'm asking for is ridiculous. Note: I haven't taken measure theory, but I would be happy to learn it.","This question already has answers here : Good books on ""advanced"" probabilities (12 answers) Closed 3 years ago . Im wondering if anyone could recommend a book (or a few books) about statistics/probability for someone at the advanced undergraduate level who has taken some real analysis (at the level of baby rudin) and some mathematical statistics and probability (only with calculus and intro to proofs as prerequisite). I would like to really start from the beginning and approach statistics from a rigorous (rudin-esque) sort of approach, a lot of the statistics I've encountered so far has been a lot of hand waving and lacking in rigorous proofs. Im hoping for a few books to really build a rigorous foundation and intuition, not just introduce me to the topics as quickly as possible.  Thanks for any help and suggestions. Please let me know if what I'm asking for is ridiculous. Note: I haven't taken measure theory, but I would be happy to learn it.",,"['probability', 'probability-theory', 'statistics', 'reference-request', 'soft-question']"
7,Coupon collector's problem using inclusion-exclusion,Coupon collector's problem using inclusion-exclusion,,"Coupon collector's problem asks: Given n coupons, how many coupons do you expect you need to draw with replacement before having drawn each coupon at least once? The well-known solution is $E(T)=n \cdot H_n$, where T is the time to collect all n coupons( proof ). I am trying to approach another way, by calculating possible arrangements of coupons using inclusion-exclusion(Stirling's numbers of the second kind) and that one coupon should only be collected at last and other coupons should be collected at least once: $$P(T=k)=\frac{n!\cdot{k-1\brace n-1}}{n^k}\\ =\frac{\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot i^{k-1}}{n^{k-1}}\\ E(T)=\sum\limits_{k=n}^{\infty}k\cdot P(T=k)\\ =\sum\limits_{k=n}^{\infty}k\cdot\frac{\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot i^{k-1}}{n^{k-1}}\\ =\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot\sum\limits_{k=n}^{\infty}k\cdot (\frac i n)^{k-1}\\ =\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot(\frac i n)^{n-1}\cdot(\frac 1 {1-\frac i n})\cdot(n-1+\frac 1 {1-\frac i n})$$ Calculation of first 170 terms yields same results. Are two formulas same?","Coupon collector's problem asks: Given n coupons, how many coupons do you expect you need to draw with replacement before having drawn each coupon at least once? The well-known solution is $E(T)=n \cdot H_n$, where T is the time to collect all n coupons( proof ). I am trying to approach another way, by calculating possible arrangements of coupons using inclusion-exclusion(Stirling's numbers of the second kind) and that one coupon should only be collected at last and other coupons should be collected at least once: $$P(T=k)=\frac{n!\cdot{k-1\brace n-1}}{n^k}\\ =\frac{\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot i^{k-1}}{n^{k-1}}\\ E(T)=\sum\limits_{k=n}^{\infty}k\cdot P(T=k)\\ =\sum\limits_{k=n}^{\infty}k\cdot\frac{\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot i^{k-1}}{n^{k-1}}\\ =\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot\sum\limits_{k=n}^{\infty}k\cdot (\frac i n)^{k-1}\\ =\sum\limits_{i=1}^{n-1}(-1)^{n-i-1}\cdot{n-1\choose i}\cdot(\frac i n)^{n-1}\cdot(\frac 1 {1-\frac i n})\cdot(n-1+\frac 1 {1-\frac i n})$$ Calculation of first 170 terms yields same results. Are two formulas same?",,"['probability', 'combinatorics']"
8,What is a pure-jump process?,What is a pure-jump process?,,"I have been reading some notes and they keep referring (without definition) to a ""pure jump process"". On wiki I can only find a reference in the Levy-Ito decomposition theorem, but still I can't find the definition Can you guys help?","I have been reading some notes and they keep referring (without definition) to a ""pure jump process"". On wiki I can only find a reference in the Levy-Ito decomposition theorem, but still I can't find the definition Can you guys help?",,"['probability', 'probability-theory', 'stochastic-processes']"
9,Pseudorandom Number Generator Using Uniform Random Variable,Pseudorandom Number Generator Using Uniform Random Variable,,"I am working out of Mathematical Statistics and Data Analysis by John Rice and ran into the following interesting problem I'm having trouble figuring out. Ch 2 (#65) How could random variables with the following density function be generated from a uniform random number generator? $$f(x) = \frac{1 + \alpha x}{2}, \quad -1 \leq x \leq 1,\quad -1 \leq \alpha \leq 1$$ So I believe I'm suppose to use the following fact to solve the problem Proposition D Let U be uniform on [0, 1], and let X = $F^{-1}$ ( U ). Then the cdf of X is F . Proof $$P(X \leq x) = P(F^{-1}(U) \leq x) = P(U \leq F(x)) = F(x)$$ That is, we can use uniform random variables to generate other random variables that will have cdf F So my goal should then be to find a cdf and it's inverse then give as input to the inverse the uniform random variable. I've included my attempt. Given $f(x) = \frac{1 + \alpha x}{2}$ $$F(X) = \int_{-1}^{x} \frac{1 + \alpha t}{2} dt \; = \; \frac{x}{2} + \frac{\alpha x}{4} + \frac{1}{2} - \frac{\alpha}{4}$$ $$4 \cdot F(X) - 2 + \alpha = 2x + \alpha x$$ $$F^{-1}(X) = \frac{4X - 2 + \alpha}{2 + \alpha}$$ So our random variable is, for example, T where $$T = F^{-1}(U) = \frac{4U - 2 + \alpha}{2 + \alpha}$$ The answer in the back of the book is $$X = [-1 + 2 \sqrt{1/4 - \alpha(1/2 - \alpha / 4 - U)}]/ \alpha$$ I'm not really sure where I went wrong. Any help?","I am working out of Mathematical Statistics and Data Analysis by John Rice and ran into the following interesting problem I'm having trouble figuring out. Ch 2 (#65) How could random variables with the following density function be generated from a uniform random number generator? So I believe I'm suppose to use the following fact to solve the problem Proposition D Let U be uniform on [0, 1], and let X = ( U ). Then the cdf of X is F . Proof That is, we can use uniform random variables to generate other random variables that will have cdf F So my goal should then be to find a cdf and it's inverse then give as input to the inverse the uniform random variable. I've included my attempt. Given So our random variable is, for example, T where The answer in the back of the book is I'm not really sure where I went wrong. Any help?","f(x) = \frac{1 + \alpha x}{2}, \quad -1 \leq x \leq 1,\quad -1 \leq \alpha \leq 1 F^{-1} P(X \leq x) = P(F^{-1}(U) \leq x) = P(U \leq F(x)) = F(x) f(x) = \frac{1 + \alpha x}{2} F(X) = \int_{-1}^{x} \frac{1 + \alpha t}{2} dt \; = \; \frac{x}{2} + \frac{\alpha x}{4} + \frac{1}{2} - \frac{\alpha}{4} 4 \cdot F(X) - 2 + \alpha = 2x + \alpha x F^{-1}(X) = \frac{4X - 2 + \alpha}{2 + \alpha} T = F^{-1}(U) = \frac{4U - 2 + \alpha}{2 + \alpha} X = [-1 + 2 \sqrt{1/4 - \alpha(1/2 - \alpha / 4 - U)}]/ \alpha","['probability', 'statistics', 'probability-distributions', 'random', 'uniform-distribution']"
10,How does Variance become an Autocorrelation Function?,How does Variance become an Autocorrelation Function?,,"""For a Gaussian stochastic process $X=\{X(t)|-\infty<t<\infty\}$ with mean function $\mu(t)=0$ for all $t$, its autocorrelation function is  $$ E(X(t)\cdot X(s))=R(h)=\max(0,1-|h|), h=t-s. $$ Compute the characteristic function of  $$ Y=X(t)-X(t-0.5)."" $$ Since I know it is Normal distributed (Gaussian), I only have to find the mean and variance of $Y$ and then find the corresponding characteristic function. I have found the mean by $$ E(Y)=E(X(t)-X(t-0.5))=E(X(t))-E(X(t-0.5))=\mu(t)-\mu(t-0.5)=0-0=0. $$  However I am stuck on computing the variance, and only get that: $$ Var(Y)=Var(X(t)-X(t-0.5))=Var(X(t))+Var(X(t-0.5))-2Cov(X(t),X(t-0.5)). $$ I know that  $$ Var(X(t))=E(X(t)^2)-E(X(t))^2=E[X(t)\cdot X(t)]-\mu(t)^2=E[X(t)\cdot X(t)]-0^2 $$ But the answer states that $$ Var(Y)=R(0)+R(0)-2R(0.5)=1+1-2\cdot 0.5=1 $$ How do I get there and does this imply that I am supposed to see that $t=s$ (so that $E(X(t)^2)=R(h)$)? Any help is much appreciated. Edit: Also, how do I see that $h=t-s=0$ and $h=0.5$ in $R(0)$ and $R(0.5)$ respectively?","""For a Gaussian stochastic process $X=\{X(t)|-\infty<t<\infty\}$ with mean function $\mu(t)=0$ for all $t$, its autocorrelation function is  $$ E(X(t)\cdot X(s))=R(h)=\max(0,1-|h|), h=t-s. $$ Compute the characteristic function of  $$ Y=X(t)-X(t-0.5)."" $$ Since I know it is Normal distributed (Gaussian), I only have to find the mean and variance of $Y$ and then find the corresponding characteristic function. I have found the mean by $$ E(Y)=E(X(t)-X(t-0.5))=E(X(t))-E(X(t-0.5))=\mu(t)-\mu(t-0.5)=0-0=0. $$  However I am stuck on computing the variance, and only get that: $$ Var(Y)=Var(X(t)-X(t-0.5))=Var(X(t))+Var(X(t-0.5))-2Cov(X(t),X(t-0.5)). $$ I know that  $$ Var(X(t))=E(X(t)^2)-E(X(t))^2=E[X(t)\cdot X(t)]-\mu(t)^2=E[X(t)\cdot X(t)]-0^2 $$ But the answer states that $$ Var(Y)=R(0)+R(0)-2R(0.5)=1+1-2\cdot 0.5=1 $$ How do I get there and does this imply that I am supposed to see that $t=s$ (so that $E(X(t)^2)=R(h)$)? Any help is much appreciated. Edit: Also, how do I see that $h=t-s=0$ and $h=0.5$ in $R(0)$ and $R(0.5)$ respectively?",,"['probability', 'stochastic-processes', 'correlation', 'variance']"
11,Recurrence for expected length of Gaussian vector,Recurrence for expected length of Gaussian vector,,"Let $g_k \sim N(0, I_{k \times k})$ be a a standard $k$-dimensional Gaussian vector. Denote by $\|g\|$ the $2$-norm of $g$. By explicit integration, it is not hard to see that $$ \mathbb E \|g_k\| = \frac{\sqrt 2 \Gamma\left(\frac{k+1}{2}\right)}{\Gamma\left(\frac k 2\right)}\,, $$ where $\Gamma$ is the Gamma function. In particular, the above expression implies \begin{equation*} \mathbb E \|g_k\|\mathbb E\|g_{k+1}\| = k\,. \end{equation*} This formula gives a nice recurrence for the expected length of a standard Gaussian. The recurrence is so nice that I'd like to see a slick proof of this fact, if one exists. Question : Is there an elegant proof of the recurrence $\mathbb E \|g_k\|\mathbb E\|g_{k+1}\| = k$, one that involves no explicit integration?","Let $g_k \sim N(0, I_{k \times k})$ be a a standard $k$-dimensional Gaussian vector. Denote by $\|g\|$ the $2$-norm of $g$. By explicit integration, it is not hard to see that $$ \mathbb E \|g_k\| = \frac{\sqrt 2 \Gamma\left(\frac{k+1}{2}\right)}{\Gamma\left(\frac k 2\right)}\,, $$ where $\Gamma$ is the Gamma function. In particular, the above expression implies \begin{equation*} \mathbb E \|g_k\|\mathbb E\|g_{k+1}\| = k\,. \end{equation*} This formula gives a nice recurrence for the expected length of a standard Gaussian. The recurrence is so nice that I'd like to see a slick proof of this fact, if one exists. Question : Is there an elegant proof of the recurrence $\mathbb E \|g_k\|\mathbb E\|g_{k+1}\| = k$, one that involves no explicit integration?",,"['probability', 'recurrence-relations', 'normal-distribution', 'expectation']"
12,how to prove that ${S_N\over E[S_N]}$ converges to an exponential distribution,how to prove that  converges to an exponential distribution,{S_N\over E[S_N]},"Suppose that $\{X_1,X_2,\ldots\}$ is a sequence of iid $L^1$-random variables such that $E[X_1]\neq 0$. Define for every $n$,  $$ S_n=X_1+\cdots+X_n. $$ Let $N$ be a geometric random variable such that  $$ P(N=k) = q^{k-1}p,\quad k=1,2,\ldots, $$ where $q=1-p$ and $p\in(0,1)$. Assume that $N$ and $\{X_1,X_2,\ldots\}$ are all independent. Show that as $p\to0$,  $$ {S_N\over E[S_N]} $$ converges in distribution to an exponential distribution with some rate $\lambda$, and identify $\lambda$.","Suppose that $\{X_1,X_2,\ldots\}$ is a sequence of iid $L^1$-random variables such that $E[X_1]\neq 0$. Define for every $n$,  $$ S_n=X_1+\cdots+X_n. $$ Let $N$ be a geometric random variable such that  $$ P(N=k) = q^{k-1}p,\quad k=1,2,\ldots, $$ where $q=1-p$ and $p\in(0,1)$. Assume that $N$ and $\{X_1,X_2,\ldots\}$ are all independent. Show that as $p\to0$,  $$ {S_N\over E[S_N]} $$ converges in distribution to an exponential distribution with some rate $\lambda$, and identify $\lambda$.",,['probability']
13,How to calculate $\int_0^1\cdots\int_0^1\frac{1}{x_1+x_2+\cdots+x_n+1}dx_1\cdots dx_n$,How to calculate,\int_0^1\cdots\int_0^1\frac{1}{x_1+x_2+\cdots+x_n+1}dx_1\cdots dx_n,"I met an integral  $$\int_0^1\cdots\int_0^1\frac{1}{x_1+x_2+\cdots+x_n+1}dx_1\cdots dx_n$$ I calculated $n=1,2,3$ and made an induction! then i got the result: $$\frac{1}{(n-1)!}\sum_{k=1}^{n}(-1)^{n-k}\binom{n}{k}(1+k)^{n-1}\ln(1+k)$$ but how could i get the result without induction? who can help ,thanks!","I met an integral  $$\int_0^1\cdots\int_0^1\frac{1}{x_1+x_2+\cdots+x_n+1}dx_1\cdots dx_n$$ I calculated $n=1,2,3$ and made an induction! then i got the result: $$\frac{1}{(n-1)!}\sum_{k=1}^{n}(-1)^{n-k}\binom{n}{k}(1+k)^{n-1}\ln(1+k)$$ but how could i get the result without induction? who can help ,thanks!",,"['calculus', 'probability', 'integration', 'induction', 'characteristic-functions']"
14,"About Wald's equation, why can't I simply use total expectation to prove?","About Wald's equation, why can't I simply use total expectation to prove?",,"Wald's equation: for i.i.d r.v $X_i$, if $N$ is a stopping time, then: $$E \sum_{i=1}^N X_i = E[N] E[X_1]$$ I just read this equation, but it seems to me if I do: $$E \sum_{i=1}^N X_i =E_N [\sum_{i=1}^N X_i|N]=E_N[NEX_i]=E[N]E[X_1]$$ I don't know what's wrong with this proof. But in this proof it does not use the fact that $N$ is stopping time.","Wald's equation: for i.i.d r.v $X_i$, if $N$ is a stopping time, then: $$E \sum_{i=1}^N X_i = E[N] E[X_1]$$ I just read this equation, but it seems to me if I do: $$E \sum_{i=1}^N X_i =E_N [\sum_{i=1}^N X_i|N]=E_N[NEX_i]=E[N]E[X_1]$$ I don't know what's wrong with this proof. But in this proof it does not use the fact that $N$ is stopping time.",,"['probability', 'stochastic-processes']"
15,What is the probability that the letter came from LONDON?,What is the probability that the letter came from LONDON?,,"A letter has come from exclusively LONDON or CLIFTON, but on the postmark only $2$ consecutive letters ''ON'' are found to be visible. What is the probability that the letter came  from LONDON? This is a question of conditional probability. Let $A$ be the event that the letter has come from LONDON. Let $B$ be the event that consecutive letters ''ON'' are found to be visible. $A\cap B$ is the event that the letter has come from LONDON and consecutive letters ''ON'' are visible. We have to find $P(A\mid B)     =\frac{P(A\cap B)}{P(B)}$. But then i am stuck. Please help me. Thanks.","A letter has come from exclusively LONDON or CLIFTON, but on the postmark only $2$ consecutive letters ''ON'' are found to be visible. What is the probability that the letter came  from LONDON? This is a question of conditional probability. Let $A$ be the event that the letter has come from LONDON. Let $B$ be the event that consecutive letters ''ON'' are found to be visible. $A\cap B$ is the event that the letter has come from LONDON and consecutive letters ''ON'' are visible. We have to find $P(A\mid B)     =\frac{P(A\cap B)}{P(B)}$. But then i am stuck. Please help me. Thanks.",,['probability']
16,Proof of the monotone convergence theorem for the conditional expectation,Proof of the monotone convergence theorem for the conditional expectation,,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $\mathcal F$ be a $\sigma$-algebra on $\Omega$ with $\mathcal    F\subseteq\mathcal A$ $X_n,X$ be non-negative random variables on $(\Omega,\mathcal A,\operatorname P)$ The monotone convergence theorem for the conditional expectation states, that if $X_n\uparrow X$ almost surely, then $$\operatorname E\left[X_n\mid\mathcal F\right]\stackrel{n\to\infty}\to\operatorname E\left[X\mid\mathcal F\right]\;.$$ Clearly, by the monotonicity of the conditional expectation, $$Z:=\lim_{n\to\infty}\operatorname E\left[X_n\mid\mathcal F\right]$$ exists. Since each $\operatorname E\left[X_n\mid\mathcal F\right]$ is $\mathcal F$-measurable by definition, $Z$ is $\mathcal F$-measurable, too. Why is it not that clear, that $$\operatorname E\left[X_n\mid\mathcal F\right]\uparrow Z\;?\tag{1}$$ All proofs I've read so far only state, that there is a modification (version) of $Z$ with $(1)$. Clearly, the conditional expectation is only almost everywhere uniquely determined. So, the monotonicity only yields $$\operatorname E\left[X_n\mid\mathcal F\right]\le \operatorname E\left[X_{n+1}\mid\mathcal F\right]$$ on $\Omega\setminus N_n$ for some $\operatorname P$-null set $N_n\subseteq\Omega$. However, since $$N:=\bigcup_nN_n$$ is a $\operatorname P$-null set, too, we should be able to immediately conclude, that $(1)$ holds on $\Omega\setminus N$, i.e. almost everywhere. So, what am I missing?","Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $\mathcal F$ be a $\sigma$-algebra on $\Omega$ with $\mathcal    F\subseteq\mathcal A$ $X_n,X$ be non-negative random variables on $(\Omega,\mathcal A,\operatorname P)$ The monotone convergence theorem for the conditional expectation states, that if $X_n\uparrow X$ almost surely, then $$\operatorname E\left[X_n\mid\mathcal F\right]\stackrel{n\to\infty}\to\operatorname E\left[X\mid\mathcal F\right]\;.$$ Clearly, by the monotonicity of the conditional expectation, $$Z:=\lim_{n\to\infty}\operatorname E\left[X_n\mid\mathcal F\right]$$ exists. Since each $\operatorname E\left[X_n\mid\mathcal F\right]$ is $\mathcal F$-measurable by definition, $Z$ is $\mathcal F$-measurable, too. Why is it not that clear, that $$\operatorname E\left[X_n\mid\mathcal F\right]\uparrow Z\;?\tag{1}$$ All proofs I've read so far only state, that there is a modification (version) of $Z$ with $(1)$. Clearly, the conditional expectation is only almost everywhere uniquely determined. So, the monotonicity only yields $$\operatorname E\left[X_n\mid\mathcal F\right]\le \operatorname E\left[X_{n+1}\mid\mathcal F\right]$$ on $\Omega\setminus N_n$ for some $\operatorname P$-null set $N_n\subseteq\Omega$. However, since $$N:=\bigcup_nN_n$$ is a $\operatorname P$-null set, too, we should be able to immediately conclude, that $(1)$ holds on $\Omega\setminus N$, i.e. almost everywhere. So, what am I missing?",,"['probability', 'probability-theory', 'measure-theory', 'stochastic-processes', 'conditional-expectation']"
17,A coin tossing game with random probabilities,A coin tossing game with random probabilities,,"Let $p$ a random variable, uniformed distributed in $[0,1]$. Two player $A$ and $B$ play the following game: Starting from A, a player gets a random value $p(\omega)\in[0,1]$, and he has two choices: i) He can flip a coin, with a probability $p(\omega)$ of an head. If he get an head he wins the game, otherwise the other player will play with the same distribution $p$. ii) He can pass the turn to the other player, but giving him a penalized  distribution, namely $p$ is replaced, for that turn, by an uniform distribution on $[0,1-p(\omega)]$ Suppose that both players play optimally, i.e. they choose between (i) and (ii) the one which gives the highest probability of winning. What is the probability of a winning for the first player? EDIT: let me try to clarify how the game is played. At each turn, the current player gets a random probability $p$ in the following way: if in the previous turn his adversary has flipped the coin (without getting head, in which case the game ended), he takes  $p$ uniformly in $[0,1]$. If his adversary hasn't flipped the coin, he takes $p$ uniformly in $[0,1-\tilde{p}]$, where $\tilde{p}$ is the probability his adversary play with during the previous turn. Now the current player can choose if to flip the coin (with a winning probability $p$), or to pass the turn.","Let $p$ a random variable, uniformed distributed in $[0,1]$. Two player $A$ and $B$ play the following game: Starting from A, a player gets a random value $p(\omega)\in[0,1]$, and he has two choices: i) He can flip a coin, with a probability $p(\omega)$ of an head. If he get an head he wins the game, otherwise the other player will play with the same distribution $p$. ii) He can pass the turn to the other player, but giving him a penalized  distribution, namely $p$ is replaced, for that turn, by an uniform distribution on $[0,1-p(\omega)]$ Suppose that both players play optimally, i.e. they choose between (i) and (ii) the one which gives the highest probability of winning. What is the probability of a winning for the first player? EDIT: let me try to clarify how the game is played. At each turn, the current player gets a random probability $p$ in the following way: if in the previous turn his adversary has flipped the coin (without getting head, in which case the game ended), he takes  $p$ uniformly in $[0,1]$. If his adversary hasn't flipped the coin, he takes $p$ uniformly in $[0,1-\tilde{p}]$, where $\tilde{p}$ is the probability his adversary play with during the previous turn. Now the current player can choose if to flip the coin (with a winning probability $p$), or to pass the turn.",,"['probability', 'game-theory']"
18,Showing $\limsup \frac{|S_n|}{n}=\infty$,Showing,\limsup \frac{|S_n|}{n}=\infty,"$X_n$'s are i.i.d symmetric with $E|X_1|=\infty$. Then $\limsup \frac{|S_n|}{n}=\infty$. How do I show $\limsup \frac{S_n}{n}=\infty$ and $\liminf \frac{S_n}{n}=-\infty$? My attempt : Let $c=\limsup \frac{S_n}{n}=\limsup \frac{-S_n}{n}=-\liminf \frac{S_n}{n}$. (Since $X_n\overset{d}{=}-X_n$) As $\limsup \geq \liminf$, we've $c\geq -c \Rightarrow c\geq 0$ Now $\infty=\limsup \frac{|S_n|}{n} \geq \limsup \frac{S_n}{n}=c\hspace{5pt}$ i.e. $0\leq c \leq \infty$ which is trivially true. How do I show $c=\infty$? I appreciate any kind of hint/help. Thank you,","$X_n$'s are i.i.d symmetric with $E|X_1|=\infty$. Then $\limsup \frac{|S_n|}{n}=\infty$. How do I show $\limsup \frac{S_n}{n}=\infty$ and $\liminf \frac{S_n}{n}=-\infty$? My attempt : Let $c=\limsup \frac{S_n}{n}=\limsup \frac{-S_n}{n}=-\liminf \frac{S_n}{n}$. (Since $X_n\overset{d}{=}-X_n$) As $\limsup \geq \liminf$, we've $c\geq -c \Rightarrow c\geq 0$ Now $\infty=\limsup \frac{|S_n|}{n} \geq \limsup \frac{S_n}{n}=c\hspace{5pt}$ i.e. $0\leq c \leq \infty$ which is trivially true. How do I show $c=\infty$? I appreciate any kind of hint/help. Thank you,",,"['probability', 'probability-theory', 'random-variables', 'law-of-large-numbers']"
19,iff $E\Bigl(|X_1|\log ({1+|X_1|)}\Bigr)<\infty$,iff,E\Bigl(|X_1|\log ({1+|X_1|)}\Bigr)<\infty,"Question : $X_n$'s are i.i.d then $$E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n}\Bigr)<\infty \iff E\Bigl(|X_1|\log ({1+|X_1|)}\Bigr)<\infty$$ My attempt : for $\Rightarrow$ part, because $\limsup \frac{|X_n|}{n} \leq \sup_{n\geq 1} \frac{|X_n|}{n}$ a.s. from which I get $\limsup \frac{|X_n|}{n} < \infty$ a.s. implying $X_1 \in L_1$. But the question says something stronger. Motivation : (1) $$0<p<1 \hspace{10pt} \text{then}\hspace{10pt} E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n^{1/p}}\Bigr)<\infty \iff X_1 \in L_1$$ (2) $$1<p<\infty \hspace{10pt} \text{then}\hspace{10pt} E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n^{1/p}}\Bigr)<\infty \iff X_1 \in L_p$$ These two problems I was able to solve but then I saw a comment saying ""what about the case $p=1$? Although it's much complicated to show, it turns out that..."". I tried a lot but could not crack it. Any idea/hint/help? Thank you,","Question : $X_n$'s are i.i.d then $$E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n}\Bigr)<\infty \iff E\Bigl(|X_1|\log ({1+|X_1|)}\Bigr)<\infty$$ My attempt : for $\Rightarrow$ part, because $\limsup \frac{|X_n|}{n} \leq \sup_{n\geq 1} \frac{|X_n|}{n}$ a.s. from which I get $\limsup \frac{|X_n|}{n} < \infty$ a.s. implying $X_1 \in L_1$. But the question says something stronger. Motivation : (1) $$0<p<1 \hspace{10pt} \text{then}\hspace{10pt} E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n^{1/p}}\Bigr)<\infty \iff X_1 \in L_1$$ (2) $$1<p<\infty \hspace{10pt} \text{then}\hspace{10pt} E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n^{1/p}}\Bigr)<\infty \iff X_1 \in L_p$$ These two problems I was able to solve but then I saw a comment saying ""what about the case $p=1$? Although it's much complicated to show, it turns out that..."". I tried a lot but could not crack it. Any idea/hint/help? Thank you,",,"['probability', 'probability-theory', 'statistics', 'random-variables']"
20,"""Empirical"" entropy.","""Empirical"" entropy.",,"Information entropy is usually defined as $$\text{I}_b({\bf p}) = -\sum_{\forall i}p_i\log_b(p_i)$$ i.e. the expected value of the negative logarithm of the probabilities. This is all good when we have a finite set of outcomes i. This can also be estimated using a histogram, treating all values within each bin as the same outcome. Doing this will be possible if we are sampling from a continuous distribution and storing the outcome as floating point numbers. However the estimate we get will be dependent on how we create our histogram bins. It would be nice to get an estimate which is not dependent on how to build histogram bins but still gives a correct estimate for at least some important special cases. Which methods or definitions do you think would be suitable to do this? Update (""own work"") : Consider the random variable $$X = \mathcal{N}(0,0.071) + U(1,n)\,\,\, \text{where the uniform}\,\,\, U(a,b) \in \{a,\cdots,b\}$$, and $\mathcal{N}(\mu,\sigma)$ is the normal distribution with mean $\mu$ and standard deviation $\sigma$. Now we calculate some kind of a ""similarity"" or ""adjacency"" metric between all pair of samples as a monotonically decreasing function of some distance between the samples. In our example we experiment with $${\bf A}_{ij} = \exp\left[{-\frac{|x_i-x_j|^3}{s^3}}\right]$$ for some values of $s$. Then we calculate the 8 largest eigenvalues of $\bf A$. These eigenvalues become very close to the number of samples in each Uniform bin. $$\left[\begin{array}{l|llllllll}\text{eig}({\bf A})& 143.65&140.02&131.85&128.17&123.64&118.61&114.26&111.50\\f& 145&142&133&130&125&120&116&113 \end{array}\right] $$ If we normalize these (so they sum to 1) and calculate entropy, we get: $$\text{I}_2(\text{eig}{\bf A}) = 2.9946 \hspace{1cm} \text{I}_2(p) = 2.9948$$ Which both are very close to the theoretical entropy of 3 bits with 8 equiprobable states. Could this maybe be used somehow? Below is a picture of sorted simulation (1024 samples) and the projection onto the 8 principal components:","Information entropy is usually defined as $$\text{I}_b({\bf p}) = -\sum_{\forall i}p_i\log_b(p_i)$$ i.e. the expected value of the negative logarithm of the probabilities. This is all good when we have a finite set of outcomes i. This can also be estimated using a histogram, treating all values within each bin as the same outcome. Doing this will be possible if we are sampling from a continuous distribution and storing the outcome as floating point numbers. However the estimate we get will be dependent on how we create our histogram bins. It would be nice to get an estimate which is not dependent on how to build histogram bins but still gives a correct estimate for at least some important special cases. Which methods or definitions do you think would be suitable to do this? Update (""own work"") : Consider the random variable $$X = \mathcal{N}(0,0.071) + U(1,n)\,\,\, \text{where the uniform}\,\,\, U(a,b) \in \{a,\cdots,b\}$$, and $\mathcal{N}(\mu,\sigma)$ is the normal distribution with mean $\mu$ and standard deviation $\sigma$. Now we calculate some kind of a ""similarity"" or ""adjacency"" metric between all pair of samples as a monotonically decreasing function of some distance between the samples. In our example we experiment with $${\bf A}_{ij} = \exp\left[{-\frac{|x_i-x_j|^3}{s^3}}\right]$$ for some values of $s$. Then we calculate the 8 largest eigenvalues of $\bf A$. These eigenvalues become very close to the number of samples in each Uniform bin. $$\left[\begin{array}{l|llllllll}\text{eig}({\bf A})& 143.65&140.02&131.85&128.17&123.64&118.61&114.26&111.50\\f& 145&142&133&130&125&120&116&113 \end{array}\right] $$ If we normalize these (so they sum to 1) and calculate entropy, we get: $$\text{I}_2(\text{eig}{\bf A}) = 2.9946 \hspace{1cm} \text{I}_2(p) = 2.9948$$ Which both are very close to the theoretical entropy of 3 bits with 8 equiprobable states. Could this maybe be used somehow? Below is a picture of sorted simulation (1024 samples) and the projection onto the 8 principal components:",,"['probability', 'probability-theory', 'entropy']"
21,Arrangements of Chairs in a Circle,Arrangements of Chairs in a Circle,,"Ten chairs are arranged in a circle. Find the number of subsets of this set of chairs that contain at least three adjacent chairs. Hints only please! This is a confusing worded-problem. We could break it into, $7$ cases but that would take very long? Case 1: 3 chairs adjacent. Ways to do this: $$\binom{10}{3} \cdot \binom{7}{7} = 120$$ But I see that, for the next, $\binom{10}{4}$. So it will be: $$1 + \binom{10}{3} + \binom{10}{4} + \binom{10}{5} + \binom{10}{6} + \cdots + \binom{10}{9}$$ $$= 1 + 120 + 210 + 252+\cdots$$ But this isnt a legit method it looks like. I am not sure how to use PIE/anything else here?","Ten chairs are arranged in a circle. Find the number of subsets of this set of chairs that contain at least three adjacent chairs. Hints only please! This is a confusing worded-problem. We could break it into, $7$ cases but that would take very long? Case 1: 3 chairs adjacent. Ways to do this: $$\binom{10}{3} \cdot \binom{7}{7} = 120$$ But I see that, for the next, $\binom{10}{4}$. So it will be: $$1 + \binom{10}{3} + \binom{10}{4} + \binom{10}{5} + \binom{10}{6} + \cdots + \binom{10}{9}$$ $$= 1 + 120 + 210 + 252+\cdots$$ But this isnt a legit method it looks like. I am not sure how to use PIE/anything else here?",,"['probability', 'combinatorics', 'elementary-number-theory', 'statistics', 'contest-math']"
22,"Determining probability generating function for event ""$SS$""","Determining probability generating function for event """"",SS,"Given a sequence of Bernouilli trials, we have $P(S) = \frac{2}{3}$ with $0<p<1$. The event ""SS"" occurs on the $i$-th trial if we observe an $S$ on the $i$-th trial following a $S$ on the $(i-1)$-th trial. We let $Q$ be the waiting time random variable to see the first event ""SS"". Show that the probability generating function of $Q$ is given by    $$ \frac{4}{27}s^{2}\bigg(\dfrac{2}{1-\frac{2}{3}s} + \dfrac{1}{1+\frac{1}{3}s}\bigg) $$ I cannot determine how to approach this question to get the probability generating function in that form. My first thought is to let $Q_{1}$ be the waiting time for the first ""$S$"", and let $Q_{2}$ be the waiting time for the second ""$S$"" after getting the first ""$S$"". Then $Q_{1} \sim Geo(\frac{2}{3})$, and $Q_{2} \sim Geo(\frac{2}{3})$, and as they are independent I can multiply their respective probability generating functions to get the probability generating function for $Q$. But this gives me  $$ \dfrac{\frac{4}{9}s^{2}}{(1-\frac{1}{3}s)^{2}}$$ which I cannot simplify to be the requested form. This leads me to think that I made an error in my approach, and I should be approaching this question completely differently.","Given a sequence of Bernouilli trials, we have $P(S) = \frac{2}{3}$ with $0<p<1$. The event ""SS"" occurs on the $i$-th trial if we observe an $S$ on the $i$-th trial following a $S$ on the $(i-1)$-th trial. We let $Q$ be the waiting time random variable to see the first event ""SS"". Show that the probability generating function of $Q$ is given by    $$ \frac{4}{27}s^{2}\bigg(\dfrac{2}{1-\frac{2}{3}s} + \dfrac{1}{1+\frac{1}{3}s}\bigg) $$ I cannot determine how to approach this question to get the probability generating function in that form. My first thought is to let $Q_{1}$ be the waiting time for the first ""$S$"", and let $Q_{2}$ be the waiting time for the second ""$S$"" after getting the first ""$S$"". Then $Q_{1} \sim Geo(\frac{2}{3})$, and $Q_{2} \sim Geo(\frac{2}{3})$, and as they are independent I can multiply their respective probability generating functions to get the probability generating function for $Q$. But this gives me  $$ \dfrac{\frac{4}{9}s^{2}}{(1-\frac{1}{3}s)^{2}}$$ which I cannot simplify to be the requested form. This leads me to think that I made an error in my approach, and I should be approaching this question completely differently.",,"['probability', 'statistics', 'generating-functions']"
23,"let x and y be uniformly distributed independent random variables on [0 ,1].the probability that the distance between x and y is less than 1/2 is?","let x and y be uniformly distributed independent random variables on [0 ,1].the probability that the distance between x and y is less than 1/2 is?",,"I have a question about probability: let x and y be uniformly distributed independent random variables on [0 ,1].the probability that the distance between x and y is less than 1/2 is? can someone give some hints to compute it ?","I have a question about probability: let x and y be uniformly distributed independent random variables on [0 ,1].the probability that the distance between x and y is less than 1/2 is? can someone give some hints to compute it ?",,"['probability', 'probability-theory']"
24,Expected value of area of triangle,Expected value of area of triangle,,"Here is the problem: Let $A$ be the point with coordinates $(1, 0)$ in $\mathbb R ^2$. Another point $B$ is chosen randomly over the unit circle. What is then the expected value of the area of the triangle $OAB$ ? What I do is to define a random variable $X$, which is the angle $AOB$ and assume that it is uniformly ditributed between $0$ and $\pi$. Then the random variable $Y = \frac{\sin X}{2}$ is the area of the triangle. Unfortunately I don't know how to calculate it's expected value (or even it's distribution). Can someone help me with this ? Thanks in advance!","Here is the problem: Let $A$ be the point with coordinates $(1, 0)$ in $\mathbb R ^2$. Another point $B$ is chosen randomly over the unit circle. What is then the expected value of the area of the triangle $OAB$ ? What I do is to define a random variable $X$, which is the angle $AOB$ and assume that it is uniformly ditributed between $0$ and $\pi$. Then the random variable $Y = \frac{\sin X}{2}$ is the area of the triangle. Unfortunately I don't know how to calculate it's expected value (or even it's distribution). Can someone help me with this ? Thanks in advance!",,"['probability', 'random-variables', 'triangles', 'expectation', 'area']"
25,Convergence of a sum of random variables,Convergence of a sum of random variables,,Let $(X_n)$ be a sum of i.i.d. positive random variables such that $\mathbb{E}(X_1)=1$ and $\mathbb{P}(X_1\neq 1)>0$. Put $M_n=X_1\ldots X_n$. Show that $\sum _{n\geq 1}\sqrt{M_n}< +\infty $ a.e. It can be show that $M_n$ is a martingale so that $\sqrt{M_n}$ is a supermartingale but this doesn't help. I don't see how to use the condition $\mathbb{P}(X_1\neq 1)>0$ in order to show that this serie converge.,Let $(X_n)$ be a sum of i.i.d. positive random variables such that $\mathbb{E}(X_1)=1$ and $\mathbb{P}(X_1\neq 1)>0$. Put $M_n=X_1\ldots X_n$. Show that $\sum _{n\geq 1}\sqrt{M_n}< +\infty $ a.e. It can be show that $M_n$ is a martingale so that $\sqrt{M_n}$ is a supermartingale but this doesn't help. I don't see how to use the condition $\mathbb{P}(X_1\neq 1)>0$ in order to show that this serie converge.,,['probability']
26,"Why can we consider the Brownian motion as being a mapping into the space of continuous functions, even though its paths are only a.s. continuous?","Why can we consider the Brownian motion as being a mapping into the space of continuous functions, even though its paths are only a.s. continuous?",,"Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal{A},\operatorname{P})$. By definition of $B$, for $\operatorname{P}$-almost every $\omega\in\Omega$ $$[0,\infty)\to\mathbb{R}\;,\;\;\;t\mapsto X_t(\omega)\tag{1}$$ is continuous. Generally, a stochastic process $X=(X_t)_{t\in I}$ on $(\Omega,\mathcal{A})$ with $I\subseteq\mathbb{R}$ can be viewed as a mapping $$X:\Omega\mapsto\mathbb{R}^I\;,\;\;\;\omega\mapsto \left(t\mapsto X_t(\omega)\right)\tag{2}$$ I've frequently read that $B$ is considered to be a mapping $\Omega\to C\left([0,\infty)\right)$, where $C(I)$ is the space of continuous functions $I\to\mathbb{R}$. Why can we do that? Clearly, there exists a $\operatorname{P}$-null set $N\subseteq\mathcal{A}$ such that $(1)$ is continuous for all $\omega\in\Omega\setminus N$. Moreover, I know that we can alter measurable functions on null sets without changing their measure related properties. However, is it guaranteed that we can alter $B$ on all null sets on which $(1)$ is not continuous such that $(1)$ is continuous for all $\omega\in\Omega$? Remark: Maybe we can use the Kolmogorov-Chentsov theorem to prove that $(1)$ can indeed be assumed as continuous for all $\omega\in\Omega$. The theorem can be formulated as follows: Let $X=(X_t,t\ge 0)$ be a real-valued stochastic process such that for all $T>0$, there exists $\alpha,\beta,C>0$ with $$\operatorname{E}\left[\left|X_t-X_s\right|^\alpha\right]\le C|t-s|^{1+\beta}\;\;\;\text{for all }s,t\in [0,T]]$$ Then, there exists a modification of $X$ which is locally Hölder-continuous of order $\gamma\in \left(0,\frac \beta\alpha\right)$. Stochastic processes $X,Y$ are called modifications of each other, if $X_t=Y_t$ almost surely.","Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal{A},\operatorname{P})$. By definition of $B$, for $\operatorname{P}$-almost every $\omega\in\Omega$ $$[0,\infty)\to\mathbb{R}\;,\;\;\;t\mapsto X_t(\omega)\tag{1}$$ is continuous. Generally, a stochastic process $X=(X_t)_{t\in I}$ on $(\Omega,\mathcal{A})$ with $I\subseteq\mathbb{R}$ can be viewed as a mapping $$X:\Omega\mapsto\mathbb{R}^I\;,\;\;\;\omega\mapsto \left(t\mapsto X_t(\omega)\right)\tag{2}$$ I've frequently read that $B$ is considered to be a mapping $\Omega\to C\left([0,\infty)\right)$, where $C(I)$ is the space of continuous functions $I\to\mathbb{R}$. Why can we do that? Clearly, there exists a $\operatorname{P}$-null set $N\subseteq\mathcal{A}$ such that $(1)$ is continuous for all $\omega\in\Omega\setminus N$. Moreover, I know that we can alter measurable functions on null sets without changing their measure related properties. However, is it guaranteed that we can alter $B$ on all null sets on which $(1)$ is not continuous such that $(1)$ is continuous for all $\omega\in\Omega$? Remark: Maybe we can use the Kolmogorov-Chentsov theorem to prove that $(1)$ can indeed be assumed as continuous for all $\omega\in\Omega$. The theorem can be formulated as follows: Let $X=(X_t,t\ge 0)$ be a real-valued stochastic process such that for all $T>0$, there exists $\alpha,\beta,C>0$ with $$\operatorname{E}\left[\left|X_t-X_s\right|^\alpha\right]\le C|t-s|^{1+\beta}\;\;\;\text{for all }s,t\in [0,T]]$$ Then, there exists a modification of $X$ which is locally Hölder-continuous of order $\gamma\in \left(0,\frac \beta\alpha\right)$. Stochastic processes $X,Y$ are called modifications of each other, if $X_t=Y_t$ almost surely.",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
27,Joint distribution function from marginals,Joint distribution function from marginals,,"Is it possible to obtain joint distribution function when only the marginal distribution functions of random variables are given and, the random variables are not independent? If possible, it would be helpful if you could provide how to do it, with an example for a two random variables case. I know how to do it, when the random variables are independent.","Is it possible to obtain joint distribution function when only the marginal distribution functions of random variables are given and, the random variables are not independent? If possible, it would be helpful if you could provide how to do it, with an example for a two random variables case. I know how to do it, when the random variables are independent.",,"['probability', 'probability-distributions']"
28,The finite-dimensional distributions of a centered Gaussian process are uniquely determined by the covariance function,The finite-dimensional distributions of a centered Gaussian process are uniquely determined by the covariance function,,"Let $I\subseteq\mathbb{R}$ and $X=(X_t)_{t\in I}$ be a centered Gaussian process, i.e.  - $E[X_t]=0$ for all $t\ge 0$  - $X$ is real-valued and for all $n\in\mathbb{N}$ and $t_1,\ldots,t_n\ge 0$ we've got $$(X_{t_1},\ldots,X_{t_n})\;\;\;\text{is }n\text{-dimensionally normal distributed}$$ How can we prove, that the finite-dimensional distributions of $X$ are uniquely described by the covariance function $$\Gamma(s,t):=\operatorname{Cov}[X_s,X_t]\;\;\;\text{for }s,t\in I\;?$$","Let $I\subseteq\mathbb{R}$ and $X=(X_t)_{t\in I}$ be a centered Gaussian process, i.e.  - $E[X_t]=0$ for all $t\ge 0$  - $X$ is real-valued and for all $n\in\mathbb{N}$ and $t_1,\ldots,t_n\ge 0$ we've got $$(X_{t_1},\ldots,X_{t_n})\;\;\;\text{is }n\text{-dimensionally normal distributed}$$ How can we prove, that the finite-dimensional distributions of $X$ are uniquely described by the covariance function $$\Gamma(s,t):=\operatorname{Cov}[X_s,X_t]\;\;\;\text{for }s,t\in I\;?$$",,"['probability', 'measure-theory', 'probability-theory', 'stochastic-processes']"
29,Bounds-negative binomial distribution,Bounds-negative binomial distribution,,"Suppose $Y=\sum_{i=1}^{n} X_{i}$  where each $X_{i}$ is an independently and identically distributed geometric random variable with success parameter $p$, so that $Y$ has a negative binomial distribution. Are there any good upper bounds on $\mathbb{P}(Y>l)$ other than the standard Markov inequality for general $l$? I'm not necessarily looking for bounds on the concentration around the mean.","Suppose $Y=\sum_{i=1}^{n} X_{i}$  where each $X_{i}$ is an independently and identically distributed geometric random variable with success parameter $p$, so that $Y$ has a negative binomial distribution. Are there any good upper bounds on $\mathbb{P}(Y>l)$ other than the standard Markov inequality for general $l$? I'm not necessarily looking for bounds on the concentration around the mean.",,"['probability', 'probability-theory', 'probability-distributions']"
30,"Proving the identity $P( X + Y = a)= \int_{-\infty}^{\infty} P( X + y = a)f_Y(y) \, \text{d}y $",Proving the identity,"P( X + Y = a)= \int_{-\infty}^{\infty} P( X + y = a)f_Y(y) \, \text{d}y ","Suppose $\lambda_1, \lambda_2, a \in \mathbb{R}$ and $X,Y$ are random variables. If it is needed, I can assume that $X$ and $Y$ are independent. I want to show, that the identity $$\mathbb{P}(\lambda_1 X + \lambda_2 Y = a)= \int_{-\infty}^{\infty} \mathbb{P}(\lambda_1 X + \lambda_2 y = a)f_Y(y) \, \text{d}y $$ does hold, where $f_Y$ denotes the density function of $Y$. The idea behind this identity is that it is very useful, when the density $f_Y$ is given and we know something about the probability $\mathbb{P}(\lambda_1 X + \lambda_2 y = a)$. Now I want to prove this statement. I tried to use the substitution formula $$\mathbb{E}[g(X)]= \int_{\Omega}g(X(\omega)) \, \text{d} \mathbb{P}(\omega) = \int_{\mathbb{R}} g(x) \, \text{d}P_X(x) = \int_{-\infty}^{\infty} g(x) f_X(x) \, \text{d}x, $$ where $g: \mathbb{R} \rightarrow \mathbb{R}$ is measurable and calculated the following: $$\mathbb{P}(\lambda_1 X + \lambda_2 Y = a)= \mathbb{E}[\mathbb{1}_{\lambda_1 X + \lambda_2 Y = a}]= \int_{\Omega}\mathbb{1}_{\lambda_1 X + \lambda_2 Y = a}(\omega) \, \text{d} \mathbb{P}(\omega)= \int_{-\infty}^{\infty} ..?.. \, \text{d} P_{(X,Y)}(x,y),$$ but I do not know how to continue at this point.","Suppose $\lambda_1, \lambda_2, a \in \mathbb{R}$ and $X,Y$ are random variables. If it is needed, I can assume that $X$ and $Y$ are independent. I want to show, that the identity $$\mathbb{P}(\lambda_1 X + \lambda_2 Y = a)= \int_{-\infty}^{\infty} \mathbb{P}(\lambda_1 X + \lambda_2 y = a)f_Y(y) \, \text{d}y $$ does hold, where $f_Y$ denotes the density function of $Y$. The idea behind this identity is that it is very useful, when the density $f_Y$ is given and we know something about the probability $\mathbb{P}(\lambda_1 X + \lambda_2 y = a)$. Now I want to prove this statement. I tried to use the substitution formula $$\mathbb{E}[g(X)]= \int_{\Omega}g(X(\omega)) \, \text{d} \mathbb{P}(\omega) = \int_{\mathbb{R}} g(x) \, \text{d}P_X(x) = \int_{-\infty}^{\infty} g(x) f_X(x) \, \text{d}x, $$ where $g: \mathbb{R} \rightarrow \mathbb{R}$ is measurable and calculated the following: $$\mathbb{P}(\lambda_1 X + \lambda_2 Y = a)= \mathbb{E}[\mathbb{1}_{\lambda_1 X + \lambda_2 Y = a}]= \int_{\Omega}\mathbb{1}_{\lambda_1 X + \lambda_2 Y = a}(\omega) \, \text{d} \mathbb{P}(\omega)= \int_{-\infty}^{\infty} ..?.. \, \text{d} P_{(X,Y)}(x,y),$$ but I do not know how to continue at this point.",,"['probability', 'probability-theory']"
31,Stochastic Processes Solution manuals.,Stochastic Processes Solution manuals.,,Does anyone have a link or a pdf stash of solution manuals for stochastic processes ebooks?  I am doing a self-study on this course and I can't seem to find any solution manual online to cross-check my solutions with. Any author or volume or version is ok with me. Thanks.,Does anyone have a link or a pdf stash of solution manuals for stochastic processes ebooks?  I am doing a self-study on this course and I can't seem to find any solution manual online to cross-check my solutions with. Any author or volume or version is ok with me. Thanks.,,"['probability', 'soft-question', 'stochastic-processes', 'book-recommendation', 'online-resources']"
32,Solving the Ornstein-Uhlenbeck Stochastic Differential Equation,Solving the Ornstein-Uhlenbeck Stochastic Differential Equation,,"I am asked to solve the following SDE: $$dX_t = (a-bX_t)dt + cdB_t,\ \text{ where }X(0) = x.$$ ($(B_t)_{t\ge0}$ is a brownian motion.) For constants $a$, $b$ and $c$ and $X$ is a random variable independent of brownian motion. Also, find $m$ and $\sigma$ and a condition on $b$ so that if $x$ is normal with mean $m$ and variance $\sigma$ then $X(t)$ is distributed as $x$. Here is what I have done for solving the equation. Let $\alpha_t$ be a (deterministic) process solution of $$d\alpha_t = (a-b\alpha_t)dt,\ \text{ where }\alpha_0 = 1.$$ This is an ODE and solving it yields the answer $\alpha_t = \frac{a-e^{-bt}}{b}$. Let us write $X_t = \alpha_t Y_t$ and search for an equation for $Y_t$. By the integration by parts formula (in differential form)  we have : $$dX_t = d\alpha_t Y_t+\alpha_t dY_t.$$ (The other term is zero since $\alpha$ has bounded variation.) Substituting the expression for $\alpha_t$ we get : $$dX_t = e^{-bt} Y_t + \alpha_t dY_t = (a-b\alpha_t)Y_tdt + \alpha_tdY_t.\quad (I)$$ On the other hand: $$dX_t = (a-bX_t)dt + cdB = (a-b\alpha_t Y_t)dt + cdB\quad(II).$$ Equating $(I)$ and $(II)$ we conclude that $$\alpha_tdY_t = cdB,$$  in other words  $$dY_t = \frac{c}{\alpha_t}dB_t.$$ With Y_0 = X_0/alpha_0 = x_0. This implies that: $$Y_t = x_0 + c \int_0^t \frac{1}{\alpha_s}dB_s = x_0 + c\int_0^t\frac{b}{a-e^{-bt}}dB_s. $$ Therefore the solution $X_t = \alpha_t Y_t$ can be obtained by multiplying $\alpha_t$ by $Y_t$. Is this correct? the final answer obtained looks a bit messy. Also how should approach the second part of the question? I appreciate any help.","I am asked to solve the following SDE: $$dX_t = (a-bX_t)dt + cdB_t,\ \text{ where }X(0) = x.$$ ($(B_t)_{t\ge0}$ is a brownian motion.) For constants $a$, $b$ and $c$ and $X$ is a random variable independent of brownian motion. Also, find $m$ and $\sigma$ and a condition on $b$ so that if $x$ is normal with mean $m$ and variance $\sigma$ then $X(t)$ is distributed as $x$. Here is what I have done for solving the equation. Let $\alpha_t$ be a (deterministic) process solution of $$d\alpha_t = (a-b\alpha_t)dt,\ \text{ where }\alpha_0 = 1.$$ This is an ODE and solving it yields the answer $\alpha_t = \frac{a-e^{-bt}}{b}$. Let us write $X_t = \alpha_t Y_t$ and search for an equation for $Y_t$. By the integration by parts formula (in differential form)  we have : $$dX_t = d\alpha_t Y_t+\alpha_t dY_t.$$ (The other term is zero since $\alpha$ has bounded variation.) Substituting the expression for $\alpha_t$ we get : $$dX_t = e^{-bt} Y_t + \alpha_t dY_t = (a-b\alpha_t)Y_tdt + \alpha_tdY_t.\quad (I)$$ On the other hand: $$dX_t = (a-bX_t)dt + cdB = (a-b\alpha_t Y_t)dt + cdB\quad(II).$$ Equating $(I)$ and $(II)$ we conclude that $$\alpha_tdY_t = cdB,$$  in other words  $$dY_t = \frac{c}{\alpha_t}dB_t.$$ With Y_0 = X_0/alpha_0 = x_0. This implies that: $$Y_t = x_0 + c \int_0^t \frac{1}{\alpha_s}dB_s = x_0 + c\int_0^t\frac{b}{a-e^{-bt}}dB_s. $$ Therefore the solution $X_t = \alpha_t Y_t$ can be obtained by multiplying $\alpha_t$ by $Y_t$. Is this correct? the final answer obtained looks a bit messy. Also how should approach the second part of the question? I appreciate any help.",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus']"
33,Correlation of uniform variables,Correlation of uniform variables,,"Let $X$ and $Y$ be independent random variables, $X,Y \sim unif(0,1)$. Let $U = \min \{X,Y\}$ and $V = \max\{X,Y\}$. Find the correlation coefficient of $U$ and $V$. I think we can assume that $U = X$ and $V = Y$ because they both have the same distribution. Further, $E[U] = E[V] = 1/2$ and $Var(U) = Var(V) = 1/12$. Next is $E[UV]$ and this is where I am stuck, because I can't solve this $E[UV] = \int_{}^{}\int_{\mathbb{R}^2}^{}uvf(u,v)dudv$. I think I can substitute $f(u,v)$ with $1$, but I'm not sure.","Let $X$ and $Y$ be independent random variables, $X,Y \sim unif(0,1)$. Let $U = \min \{X,Y\}$ and $V = \max\{X,Y\}$. Find the correlation coefficient of $U$ and $V$. I think we can assume that $U = X$ and $V = Y$ because they both have the same distribution. Further, $E[U] = E[V] = 1/2$ and $Var(U) = Var(V) = 1/12$. Next is $E[UV]$ and this is where I am stuck, because I can't solve this $E[UV] = \int_{}^{}\int_{\mathbb{R}^2}^{}uvf(u,v)dudv$. I think I can substitute $f(u,v)$ with $1$, but I'm not sure.",,"['probability', 'probability-distributions', 'random-variables', 'correlation']"
34,Expected interarrival time,Expected interarrival time,,"Given that there are 40 arrival times in 3 hours which are uniformly distributed on $(0,3)$, what is the expected time till the tenth arrival? My book says that the answer should be as follows: The expected interarrival time is $\frac{3}{41}$, so the time till the tenth arrival has an expected value of $\frac{30}{41}$. This might be a very basic question, but why is the expected interarrival time $\frac{3}{41}$, and not $\frac{3}{40}$?","Given that there are 40 arrival times in 3 hours which are uniformly distributed on $(0,3)$, what is the expected time till the tenth arrival? My book says that the answer should be as follows: The expected interarrival time is $\frac{3}{41}$, so the time till the tenth arrival has an expected value of $\frac{30}{41}$. This might be a very basic question, but why is the expected interarrival time $\frac{3}{41}$, and not $\frac{3}{40}$?",,"['probability', 'algebra-precalculus']"
35,How can Distinguishable objects behave as if they were Indistinguishable?,How can Distinguishable objects behave as if they were Indistinguishable?,,"I am mentally disabled: I cannot imagine indistinguishable marbles. However, I can imagine that there exist sequences of (random) manipulations on real (distinguishable) marbles causing them to end up in real (distinguishable) boxes according to the Bose-Einstein distribution: For example, in case of $2$ marbles and $3$ boxes the following six arrangements are supposed to be equally likely: $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &.. & & \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & &.. & \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & & &.. \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &. &. & \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &. & &. \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & &. &. \end{gather}$$ (Arrangements of this type can be listed in the case of $n$ marbles and $m$ boxes. So the Bose-Einstein distribution can be defined in general.) Can one describe manipulations that result in the Bose-Einstein distribution? Restriction on the manipulations: one cannot choose a whole arrangement of marbles. Only individual boxes and individual marbles can be picked.","I am mentally disabled: I cannot imagine indistinguishable marbles. However, I can imagine that there exist sequences of (random) manipulations on real (distinguishable) marbles causing them to end up in real (distinguishable) boxes according to the Bose-Einstein distribution: For example, in case of $2$ marbles and $3$ boxes the following six arrangements are supposed to be equally likely: $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &.. & & \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & &.. & \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & & &.. \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &. &. & \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ &. & &. \end{gather}$$ $$\begin{gather} &\_\_\_ &\_\_\_ &\_\_\_\\ & &. &. \end{gather}$$ (Arrangements of this type can be listed in the case of $n$ marbles and $m$ boxes. So the Bose-Einstein distribution can be defined in general.) Can one describe manipulations that result in the Bose-Einstein distribution? Restriction on the manipulations: one cannot choose a whole arrangement of marbles. Only individual boxes and individual marbles can be picked.",,"['probability', 'combinatorics', 'statistics']"
36,"$A$: set of Alice's frieds, $B$: Bob's friends, $C$: all people. Find $P(A \subseteq B)$ and $P(A \cup B = C)$",": set of Alice's frieds, : Bob's friends, : all people. Find  and",A B C P(A \subseteq B) P(A \cup B = C),"(Introduction to Probability, Blitzstein and Nwang, p.80) Alice, Bob, and 100 other people live in a small town. Let C be the set consisting of the 100 other people, let A be the set of people in C who are friends with Alice, and let B be the set of people in C who are friends with Bob. Suppose that for each person in C, Alice is friends with that person with probability 1/2, and likewise for Bob, with all of these friendship statuses independent. (a) Let D $\subseteq$ C. Find P (A = D). (b) Find P (A $\subseteq$ B). (c) Find P (A $\cup$ B = C). My general approach to those problems was conditioning on the set sizes. Part b) must be certainly false. a) $P(A=D) = \sum_{k=0}^{100} P(A=D \mid |A|=k) * P(|A|=k)$ $P(|A|=k) = \binom{100}{k} \left(\frac{1}{2}\right)^{100}$ \begin{align}  P(A=D \mid |A| = k) &= \sum_{j} P(A=D \mid |A| = k, |D|=j) * P(|D|=j)\\ &= P(A=D \mid |A|=|D|=k) * P(|D|=k)\\ &= \binom{100}{k}^{-1} * \frac{1}{101} \end{align} \begin{align} \sum_{k=0}^{100} \binom{100}{k}^{-1} * \frac{1}{101} * \binom{100}{k} * \left(\frac{1}{2}\right)^{100} = \left(\frac{1}{2}\right)^{100} \doteq 0 \end{align} b) \begin{align} P(A \subseteq B) &= \sum_{k\leq j} P(A \subseteq B \mid |A| = k, |B|=j) * P(|A| = k, |B|=j)\\ &= \sum_{k\leq j} \frac{\binom{k}{j}}{\binom{100}{k}\binom{100}{j}} * \binom{100}{j} \left(\frac{1}{2}\right)^{j} * \binom{100}{k} \left(\frac{1}{2}\right)^{k}\\ &= \sum_{k\leq j} \binom{k}{j} \left(\frac{1}{2}\right)^{k+j} = 4 \end{align} c) \begin{align} P(A \cup B = C) &= \sum_{k=0}^{100} P(A \cup B = C \mid |A|=k, |B|=100-k) * P(|A|=k, |B|=100-k)\\ &= \sum_{k=0}^{100} \frac{1}{\binom{100}{k}} * \binom{100}{k} \left(\frac{1}{2}\right)^{100} * \binom{100}{100-k} \left(\frac{1}{2}\right)^{100}\\ &= \sum_{k=0}^{100} \binom{100}{k} \left(\frac{1}{2}\right)^{200} \doteq 0 \end{align} Am I principally doing the right thing? Any help with this?","(Introduction to Probability, Blitzstein and Nwang, p.80) Alice, Bob, and 100 other people live in a small town. Let C be the set consisting of the 100 other people, let A be the set of people in C who are friends with Alice, and let B be the set of people in C who are friends with Bob. Suppose that for each person in C, Alice is friends with that person with probability 1/2, and likewise for Bob, with all of these friendship statuses independent. (a) Let D $\subseteq$ C. Find P (A = D). (b) Find P (A $\subseteq$ B). (c) Find P (A $\cup$ B = C). My general approach to those problems was conditioning on the set sizes. Part b) must be certainly false. a) $P(A=D) = \sum_{k=0}^{100} P(A=D \mid |A|=k) * P(|A|=k)$ $P(|A|=k) = \binom{100}{k} \left(\frac{1}{2}\right)^{100}$ \begin{align}  P(A=D \mid |A| = k) &= \sum_{j} P(A=D \mid |A| = k, |D|=j) * P(|D|=j)\\ &= P(A=D \mid |A|=|D|=k) * P(|D|=k)\\ &= \binom{100}{k}^{-1} * \frac{1}{101} \end{align} \begin{align} \sum_{k=0}^{100} \binom{100}{k}^{-1} * \frac{1}{101} * \binom{100}{k} * \left(\frac{1}{2}\right)^{100} = \left(\frac{1}{2}\right)^{100} \doteq 0 \end{align} b) \begin{align} P(A \subseteq B) &= \sum_{k\leq j} P(A \subseteq B \mid |A| = k, |B|=j) * P(|A| = k, |B|=j)\\ &= \sum_{k\leq j} \frac{\binom{k}{j}}{\binom{100}{k}\binom{100}{j}} * \binom{100}{j} \left(\frac{1}{2}\right)^{j} * \binom{100}{k} \left(\frac{1}{2}\right)^{k}\\ &= \sum_{k\leq j} \binom{k}{j} \left(\frac{1}{2}\right)^{k+j} = 4 \end{align} c) \begin{align} P(A \cup B = C) &= \sum_{k=0}^{100} P(A \cup B = C \mid |A|=k, |B|=100-k) * P(|A|=k, |B|=100-k)\\ &= \sum_{k=0}^{100} \frac{1}{\binom{100}{k}} * \binom{100}{k} \left(\frac{1}{2}\right)^{100} * \binom{100}{100-k} \left(\frac{1}{2}\right)^{100}\\ &= \sum_{k=0}^{100} \binom{100}{k} \left(\frac{1}{2}\right)^{200} \doteq 0 \end{align} Am I principally doing the right thing? Any help with this?",,"['probability', 'combinatorics']"
37,Weak* topology is Hausdorff?,Weak* topology is Hausdorff?,,"Problem: Let $S$ be a complete separable metric space, show that the space of probability measures on $S$, denoted as $PM(S)$ is Hausdorff Attempt: By definition of Hausdorffness, two points $P_1$, $P_2$ in $PM(S)$ can se separated by open disjoint neighborhood: $\exists G_i\in\mathcal{G}(PM(S))$ with $G_1\cap G_2 =\emptyset$ and $P_i\in\mathcal{G_i}$. So I guess I am trying to show this. Also notice that for $\mu_1=\mu_2$ iff $\int fd\mu_1=\int fd\mu_2$ for all continuous function with compact support. in a broader sense, I think this is equivalent to showing that the weak* star topology is Hausdorff..","Problem: Let $S$ be a complete separable metric space, show that the space of probability measures on $S$, denoted as $PM(S)$ is Hausdorff Attempt: By definition of Hausdorffness, two points $P_1$, $P_2$ in $PM(S)$ can se separated by open disjoint neighborhood: $\exists G_i\in\mathcal{G}(PM(S))$ with $G_1\cap G_2 =\emptyset$ and $P_i\in\mathcal{G_i}$. So I guess I am trying to show this. Also notice that for $\mu_1=\mu_2$ iff $\int fd\mu_1=\int fd\mu_2$ for all continuous function with compact support. in a broader sense, I think this is equivalent to showing that the weak* star topology is Hausdorff..",,"['real-analysis', 'probability', 'functional-analysis', 'probability-theory']"
38,Expected number of cluster of cars,Expected number of cluster of cars,,"This question is based on a previously asked question, Probability problem: cars on the road . The question is: A road of infinite length has only one lane, so cars cannot overtake each other. $N$ cars are now put on the road. The cars travel at distinct constant speeds chosen at random and independently from a probability distribution. What is the expected number of cluster of cars formed. This is how I tried to solve it, but I am getting wrong answer. Let the farthest car be $C_1$ , car behind it $C_2$ and so on. Let the speed of car $C_i$ be $a_i$ . Then there are two cases, either $C_1$ is the car with minimum speed or it is not. In first case there will only be $1$ cluster. The probability of first case is $\frac{1}{N}$ . In the second case let a subcase be that $a_i$ is the first speed less than $a_1$ (first in sense, going from $a_2$ to $a_N$ ). Then clearly $a_1, a_2, ... a_{i-1}$ from a cluster and the remaning $N+1-i$ from some clusters among themselves. The probability of this subcase is $\frac{(i-2)!}{i!}=\frac{1}{i(i-1)}$ . Thus expected number of clusters are $$E(n) = \frac{1}{N}.1+\sum_{i=2}^{N}\frac{1}{i(i-1)}(E(n-i+1)+1)$$ with base case $E(1)=1$ . But this is giving me wrong answer for $E(3)$ .","This question is based on a previously asked question, Probability problem: cars on the road . The question is: A road of infinite length has only one lane, so cars cannot overtake each other. cars are now put on the road. The cars travel at distinct constant speeds chosen at random and independently from a probability distribution. What is the expected number of cluster of cars formed. This is how I tried to solve it, but I am getting wrong answer. Let the farthest car be , car behind it and so on. Let the speed of car be . Then there are two cases, either is the car with minimum speed or it is not. In first case there will only be cluster. The probability of first case is . In the second case let a subcase be that is the first speed less than (first in sense, going from to ). Then clearly from a cluster and the remaning from some clusters among themselves. The probability of this subcase is . Thus expected number of clusters are with base case . But this is giving me wrong answer for .","N C_1 C_2 C_i a_i C_1 1 \frac{1}{N} a_i a_1 a_2 a_N a_1, a_2, ... a_{i-1} N+1-i \frac{(i-2)!}{i!}=\frac{1}{i(i-1)} E(n) = \frac{1}{N}.1+\sum_{i=2}^{N}\frac{1}{i(i-1)}(E(n-i+1)+1) E(1)=1 E(3)",['probability']
39,"Uniform distribution, as a sum of biased Bernoulli trials.","Uniform distribution, as a sum of biased Bernoulli trials.",,"Suppose that the probability of $x=0$ is $p$, and the probability of $x=1$ is $1-p=q$. Consider the random sequence $X=\{X_i\}_{i=1}^{\infty}$. We map this sequence by $C$ to a point in the interval $[0,1]$ as below: $1)$ we look at the first random variable. If it is $0$, then we update the interval to $I_1=[0,p)$, else update it to $I_1=[p,1)$. $2)$ Let $I_k=[a,b)$. Look at the $(k+1)^{th}$ random variable. if it is $0$, then we update the interval to $I_{k+1}=[a,a+p(b-a))$, else we update it to $I_{k+1}=[b-q(b-a),b)$. and we continue this process till we reach to a point as the length of the random process goes to infinity. As an example if the first $2$ random variables are $01$, then we have: $I_1=[0,p)$ $I_2=[p-qp,p)$. Find the pdf of $C(X)$.","Suppose that the probability of $x=0$ is $p$, and the probability of $x=1$ is $1-p=q$. Consider the random sequence $X=\{X_i\}_{i=1}^{\infty}$. We map this sequence by $C$ to a point in the interval $[0,1]$ as below: $1)$ we look at the first random variable. If it is $0$, then we update the interval to $I_1=[0,p)$, else update it to $I_1=[p,1)$. $2)$ Let $I_k=[a,b)$. Look at the $(k+1)^{th}$ random variable. if it is $0$, then we update the interval to $I_{k+1}=[a,a+p(b-a))$, else we update it to $I_{k+1}=[b-q(b-a),b)$. and we continue this process till we reach to a point as the length of the random process goes to infinity. As an example if the first $2$ random variables are $01$, then we have: $I_1=[0,p)$ $I_2=[p-qp,p)$. Find the pdf of $C(X)$.",,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'random-variables']"
40,Analogous of Markov's inequality for the lower bound,Analogous of Markov's inequality for the lower bound,,"Consider a positive random variable $X$ and call $E[X]$ its expectation. For any positive $a \in \mathbb{R}$, an upper bound for the probability of $P(X>a)$ is provided by the Markov's Inequality, $$ P(X>a) \leq \frac{E[X]}{a}, $$ Is there an analogous lower bound that is based only on the knowledge of the expectation?","Consider a positive random variable $X$ and call $E[X]$ its expectation. For any positive $a \in \mathbb{R}$, an upper bound for the probability of $P(X>a)$ is provided by the Markov's Inequality, $$ P(X>a) \leq \frac{E[X]}{a}, $$ Is there an analogous lower bound that is based only on the knowledge of the expectation?",,"['probability', 'probability-theory', 'inequality', 'probability-distributions', 'random']"
41,Probability/Decision- infimum over set of expectations (can be interpreted as decision problem),Probability/Decision- infimum over set of expectations (can be interpreted as decision problem),,"Let $X$ be a random variable over $\mathbb{R}$ with finite first moment (mean). Let $H$ be a piecewise function defined such that $H_a=c_1(x-a)$ for $x>a$, and $H_a=c_2(a-x)$ for $x<a$, with $c_1,c_2>0$. Let $a'$ be a number such that $P(X<a')=c_1/(c_1+c2)$, and $\mathbb{P}(X>a')=c_2/(c_1+c_2)$. Why is $\inf_{a\in\mathbb{R}} \mathbb{E}  [H_a] = \mathbb{E}[H_{a'}]$? What I have tried : I am trying to exploit some property of the expected value in order to nicely evaluate the expected value (for fixed $a$) $$\mathbb{P}(X> a)\cdot \mathbb{E}_{X> a}[H_a] + \mathbb{P}(X< a)\cdot \mathbb{E}_{X< a}[H_a].$$ But is there some nice property we can exploit here? What else I tried: Take the case where $c_1=c_2$. Then one can prove that $a'$ is the median and see the equality by a definition of the median, since $\mathbb{E}  [H_a]=\mathbb{E}[|X-a|],$ which is minimized by the median, defined by $P(X<a')=\frac12$. But how to generalize...I wonder if we can do some transformation of $Z$ in the general case to reduce to the case where these constants are the same? Are there similar results for different quartiles (not just the median?)","Let $X$ be a random variable over $\mathbb{R}$ with finite first moment (mean). Let $H$ be a piecewise function defined such that $H_a=c_1(x-a)$ for $x>a$, and $H_a=c_2(a-x)$ for $x<a$, with $c_1,c_2>0$. Let $a'$ be a number such that $P(X<a')=c_1/(c_1+c2)$, and $\mathbb{P}(X>a')=c_2/(c_1+c_2)$. Why is $\inf_{a\in\mathbb{R}} \mathbb{E}  [H_a] = \mathbb{E}[H_{a'}]$? What I have tried : I am trying to exploit some property of the expected value in order to nicely evaluate the expected value (for fixed $a$) $$\mathbb{P}(X> a)\cdot \mathbb{E}_{X> a}[H_a] + \mathbb{P}(X< a)\cdot \mathbb{E}_{X< a}[H_a].$$ But is there some nice property we can exploit here? What else I tried: Take the case where $c_1=c_2$. Then one can prove that $a'$ is the median and see the equality by a definition of the median, since $\mathbb{E}  [H_a]=\mathbb{E}[|X-a|],$ which is minimized by the median, defined by $P(X<a')=\frac12$. But how to generalize...I wonder if we can do some transformation of $Z$ in the general case to reduce to the case where these constants are the same? Are there similar results for different quartiles (not just the median?)",,['probability']
42,What's the distribution of gaussian squared with mean $\mu$ and variance $\sigma^2$?,What's the distribution of gaussian squared with mean  and variance ?,\mu \sigma^2,"Based on my understanding, Chi square distribution and noncentral Chi-squared distribution are used for special Gaussian distribution. However, when the Gaussian is not standard and with no unit variance, how could I calculate the distribution of this Gaussian squared? Mathematically, $X \sim N(\mu,\sigma^2)$. Let $Y=X^2$, what is the distribution of Y?","Based on my understanding, Chi square distribution and noncentral Chi-squared distribution are used for special Gaussian distribution. However, when the Gaussian is not standard and with no unit variance, how could I calculate the distribution of this Gaussian squared? Mathematically, $X \sim N(\mu,\sigma^2)$. Let $Y=X^2$, what is the distribution of Y?",,['probability']
43,"Use the binomial theorem to show that for any positive integer $n$, $\displaystyle\sum_{i=0}^{n} {n \choose i} = 2^n$.","Use the binomial theorem to show that for any positive integer , .",n \displaystyle\sum_{i=0}^{n} {n \choose i} = 2^n,"Can somebody check to see if this is good enough just to show? It's very simple but the question doesn't say prove or anything like that. So the binomial theorem states that $(x+y)^n=\displaystyle\sum_{r=0}^{n} {n \choose r}x^{n-r}y^r$ Let $x=1, y=1$. Then $2^n=\displaystyle\sum_{r=0}^{n} {n \choose r}*1^{n-r}1^r$, which reduces to $2^n=\displaystyle\sum_{r=0}^{n} {n \choose r}$. Tada. Good enough?","Can somebody check to see if this is good enough just to show? It's very simple but the question doesn't say prove or anything like that. So the binomial theorem states that $(x+y)^n=\displaystyle\sum_{r=0}^{n} {n \choose r}x^{n-r}y^r$ Let $x=1, y=1$. Then $2^n=\displaystyle\sum_{r=0}^{n} {n \choose r}*1^{n-r}1^r$, which reduces to $2^n=\displaystyle\sum_{r=0}^{n} {n \choose r}$. Tada. Good enough?",,"['probability', 'summation', 'solution-verification', 'binomial-theorem']"
44,A sequence of nonconstant i.i.d. random variables converges with probability zero,A sequence of nonconstant i.i.d. random variables converges with probability zero,,"Proove:  $X_{n} iid, X_{n}$ not constant a.s. $\iff P(X_{n}$ $converges)=0$ My idea for ""$\Rightarrow$"": $X_{n}$ not constant a.s. $\iff \forall$ c $\in \mathbb{R}$, $\varepsilon$ > 0:  $P(|X_{n}-c|>\varepsilon)>0$ --> $X_{n}$ doesn't converge in Probability, thus $X_{n}$ doesn't converge. --> $P(X_{n}$ $ converges)=0$ $""\Leftarrow""$: $P(X_{n}$ $converges)=0 \iff \forall X \in \mathbb{R}$ exists a $\varepsilon>0: |X_{n}-X|>\varepsilon$ --> $P(X_{n}\not=c)=1, c\in \mathbb{R}$, so $X_{n}$ is not constant a.s. Are there any mistakes or wrong assumptions in this proof? Or can I take this? I got a hint that I can use Borel-Cantelli but I don't where to use it. Thanks for any kind of help.","Proove:  $X_{n} iid, X_{n}$ not constant a.s. $\iff P(X_{n}$ $converges)=0$ My idea for ""$\Rightarrow$"": $X_{n}$ not constant a.s. $\iff \forall$ c $\in \mathbb{R}$, $\varepsilon$ > 0:  $P(|X_{n}-c|>\varepsilon)>0$ --> $X_{n}$ doesn't converge in Probability, thus $X_{n}$ doesn't converge. --> $P(X_{n}$ $ converges)=0$ $""\Leftarrow""$: $P(X_{n}$ $converges)=0 \iff \forall X \in \mathbb{R}$ exists a $\varepsilon>0: |X_{n}-X|>\varepsilon$ --> $P(X_{n}\not=c)=1, c\in \mathbb{R}$, so $X_{n}$ is not constant a.s. Are there any mistakes or wrong assumptions in this proof? Or can I take this? I got a hint that I can use Borel-Cantelli but I don't where to use it. Thanks for any kind of help.",,"['probability', 'probability-theory', 'convergence-divergence']"
45,"Probability of events in an infinite, independent coin-toss space","Probability of events in an infinite, independent coin-toss space",,"I am studying Steven E. Shreve's Stochastic Calculus book. Example 1.1.4 (p.4-6) constructs a probability measure on the space of infinely many coin tosses $\Omega_\infty$. In the example the $\sigma$-algebras for $n$ coin tosses are defined like this $\mathcal{F}_0 = \{\emptyset, \Omega\}$, $\mathcal{F}_1 = \{\emptyset, \Omega , A_{H}, A_{T}\}$, where $A_H$ is the set of all sequences beginning with head. For three coin tosses we get $\mathcal{F}_3 = \{\emptyset, \Omega ,A_H, A_T, A_{HH}, A_{HT}, \ldots\}$ Now the authors state By continuing this process, we can define the probability of every set that can be described in terms of finitely many tosses. And later: We create a $\sigma$-algebra, called $\mathcal{F}_\infty$ by putting in every set that can be described in terms of finitely many coin tosses and then adding all other sets required in order to have a $\sigma$-algebra. It turns out that once we specify the probability of every set that can be described in terms of finitely many coin tosses, the probability of every set in $\mathcal{F}_\infty$ is determined. I find this puzzling! Why do finite descriptions suffice? For example I don't understand how the probability of the event ""infinitely many heads"" is determined. I would guess it has probability 1 but how can I conclude this from the finite cases? How is this done for general elements $A\in\mathcal{F}_\infty$? Edit 2: Can I argue like this: for $A\in (\mathcal{F}_\infty\setminus (\bigcup_{n=1}^\infty F_n))$, the complement $A^C$ is in some $\mathcal{F}_m$ and therefore $\mathbb{P}(A) = 1-\mathbb{P}(A^C)$?","I am studying Steven E. Shreve's Stochastic Calculus book. Example 1.1.4 (p.4-6) constructs a probability measure on the space of infinely many coin tosses $\Omega_\infty$. In the example the $\sigma$-algebras for $n$ coin tosses are defined like this $\mathcal{F}_0 = \{\emptyset, \Omega\}$, $\mathcal{F}_1 = \{\emptyset, \Omega , A_{H}, A_{T}\}$, where $A_H$ is the set of all sequences beginning with head. For three coin tosses we get $\mathcal{F}_3 = \{\emptyset, \Omega ,A_H, A_T, A_{HH}, A_{HT}, \ldots\}$ Now the authors state By continuing this process, we can define the probability of every set that can be described in terms of finitely many tosses. And later: We create a $\sigma$-algebra, called $\mathcal{F}_\infty$ by putting in every set that can be described in terms of finitely many coin tosses and then adding all other sets required in order to have a $\sigma$-algebra. It turns out that once we specify the probability of every set that can be described in terms of finitely many coin tosses, the probability of every set in $\mathcal{F}_\infty$ is determined. I find this puzzling! Why do finite descriptions suffice? For example I don't understand how the probability of the event ""infinitely many heads"" is determined. I would guess it has probability 1 but how can I conclude this from the finite cases? How is this done for general elements $A\in\mathcal{F}_\infty$? Edit 2: Can I argue like this: for $A\in (\mathcal{F}_\infty\setminus (\bigcup_{n=1}^\infty F_n))$, the complement $A^C$ is in some $\mathcal{F}_m$ and therefore $\mathbb{P}(A) = 1-\mathbb{P}(A^C)$?",,"['probability', 'measure-theory']"
46,"Expected number of parallel tosses, where each coin gets heads at least once, of N unfair coins","Expected number of parallel tosses, where each coin gets heads at least once, of N unfair coins",,"A common expectation question is to ask ""What is the expected number of tosses to get heads with an unfair coin?"" This problem can be solved using the recursive equation E = p*1+(1-p)*(E+1), resulting in the solution of E=1/p, where p is the probability of getting heads. If the question is changed to ""What is the expected number of parallel tosses, where each coin gets heads at least once, with N unfair coins assuming each coin has equal probability?,"" does the solution stay as E=1/p, because each coin is independent or is the solution more complicated? If the solution is more complicated, how is it solved?","A common expectation question is to ask ""What is the expected number of tosses to get heads with an unfair coin?"" This problem can be solved using the recursive equation E = p*1+(1-p)*(E+1), resulting in the solution of E=1/p, where p is the probability of getting heads. If the question is changed to ""What is the expected number of parallel tosses, where each coin gets heads at least once, with N unfair coins assuming each coin has equal probability?,"" does the solution stay as E=1/p, because each coin is independent or is the solution more complicated? If the solution is more complicated, how is it solved?",,"['probability', 'expectation']"
47,Jaynes' taxicab problem,Jaynes' taxicab problem,,"I am currently reading Jaynes' Probability Theory, The Logic of Science and am still trying to absorb everything. On page 190, he poses the following intriguing question, paraphrased here. Suppose you fell asleep on the train and upon waking up, you arrive at an unknown station. All you can see is a taxicab with the number 27. What is then your guess at the number N of taxis in the town (assuming they are numbered from 1 consecutively). The ""straightforward"" answer would be 27. I came up with my own solution, see below, and I wonder whether it is a correct way of thinking about the problem.  Also, since I am lacking formal training, I am interested in a more systematic analysis. In particular I'd like to have someone sketch the ""true Bayesian"" solution to this, with  all the quantities explicitly stated and not glossed over. Thank you. My thinking is as follows. Suppose the probability of encountering any taxi is 1/N. Then the probability of seeing a taxicab  with number at most x is x/N. So, seeing taxicab 27, the number N is at least 27 with probability 1. Continuing, 27 is with 90% probability from the 0-0.9 quantile, from which I think I can conclude that N>=30 with 90% probability. Likewise, I'd say that N>=54 with 50% probability, etc.","I am currently reading Jaynes' Probability Theory, The Logic of Science and am still trying to absorb everything. On page 190, he poses the following intriguing question, paraphrased here. Suppose you fell asleep on the train and upon waking up, you arrive at an unknown station. All you can see is a taxicab with the number 27. What is then your guess at the number N of taxis in the town (assuming they are numbered from 1 consecutively). The ""straightforward"" answer would be 27. I came up with my own solution, see below, and I wonder whether it is a correct way of thinking about the problem.  Also, since I am lacking formal training, I am interested in a more systematic analysis. In particular I'd like to have someone sketch the ""true Bayesian"" solution to this, with  all the quantities explicitly stated and not glossed over. Thank you. My thinking is as follows. Suppose the probability of encountering any taxi is 1/N. Then the probability of seeing a taxicab  with number at most x is x/N. So, seeing taxicab 27, the number N is at least 27 with probability 1. Continuing, 27 is with 90% probability from the 0-0.9 quantile, from which I think I can conclude that N>=30 with 90% probability. Likewise, I'd say that N>=54 with 50% probability, etc.",,"['probability', 'bayesian']"
48,Probability of random walk returning to 0,Probability of random walk returning to 0,,"Given a symmetric 1-dimensional random walk starting at 0 -- what is the probability of the walk returning $k$ times to 0 after $2N$ steps? I know that the total number of paths it can take is $2^{2N}$. My problem is finding the total number of paths returning to 0. Also, since you can only return at even $k$'s, the no. of possible hitting points is $ {{N}\choose{k}}.  $","Given a symmetric 1-dimensional random walk starting at 0 -- what is the probability of the walk returning $k$ times to 0 after $2N$ steps? I know that the total number of paths it can take is $2^{2N}$. My problem is finding the total number of paths returning to 0. Also, since you can only return at even $k$'s, the no. of possible hitting points is $ {{N}\choose{k}}.  $",,['probability']
49,Probability roots of quadratic lie in unit disc,Probability roots of quadratic lie in unit disc,,"$A,B\sim\mathscr{U}(0,1)$ and independent. We consider: $$x^2+2Ax+B=0$$ Given that both of the roots of this equation are real, what is the   probability that they lie in the unit disc? Thoughts: if $\lambda, \mu$ are the roots then I have found that ${\mathbb{P}(\lambda,\mu \in\mathbb{R})}=1/3$ so by Bayes' law: $$\mathbb{P}(|\lambda|\leq 1,\; |\mu|\leq 1)=3\cdot\mathbb{P}(\lambda,\mu\in [-1,1])$$ Update: following rogerl's suggestion: $\mathbb{P}(\lambda,\mu \in [-1,1])=\mathbb{P}(2A-1-B\leq 0)$. Set $W=2A-1-B$ and $Z=B$ then the Jacobian is $\frac{1}{2}$ so: $$f_{W,Z}(w,z)=\frac{1}{2}f_{A,B}(a(w,z),b(w,z))=\frac{1}{2}$$ Then: $$\mathbb{P}(W\leq 0)=\frac{1}{2}\int_{?}^?\int_?^? dzdw$$ Is this alright? I am stuck on the limits of integration; my thoughts on these were that the unit square in the $A-B$ plane get mapped to the following figure in the $W-Z$ plane: $\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad$ The region of integration is then the region below the $Z$ axis, which gives $\mathbb{P}(W\leq 0)=3/4.$ This can't be right though, because then the desired probability exceeds $1$. Any help?","$A,B\sim\mathscr{U}(0,1)$ and independent. We consider: $$x^2+2Ax+B=0$$ Given that both of the roots of this equation are real, what is the   probability that they lie in the unit disc? Thoughts: if $\lambda, \mu$ are the roots then I have found that ${\mathbb{P}(\lambda,\mu \in\mathbb{R})}=1/3$ so by Bayes' law: $$\mathbb{P}(|\lambda|\leq 1,\; |\mu|\leq 1)=3\cdot\mathbb{P}(\lambda,\mu\in [-1,1])$$ Update: following rogerl's suggestion: $\mathbb{P}(\lambda,\mu \in [-1,1])=\mathbb{P}(2A-1-B\leq 0)$. Set $W=2A-1-B$ and $Z=B$ then the Jacobian is $\frac{1}{2}$ so: $$f_{W,Z}(w,z)=\frac{1}{2}f_{A,B}(a(w,z),b(w,z))=\frac{1}{2}$$ Then: $$\mathbb{P}(W\leq 0)=\frac{1}{2}\int_{?}^?\int_?^? dzdw$$ Is this alright? I am stuck on the limits of integration; my thoughts on these were that the unit square in the $A-B$ plane get mapped to the following figure in the $W-Z$ plane: $\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad$ The region of integration is then the region below the $Z$ axis, which gives $\mathbb{P}(W\leq 0)=3/4.$ This can't be right though, because then the desired probability exceeds $1$. Any help?",,"['probability', 'multivariable-calculus', 'probability-distributions']"
50,"If I flip a coin $100$ times, why do the results trend towards $50-50$?","If I flip a coin  times, why do the results trend towards ?",100 50-50,"This sounds like a simple question, but here's the gist: Given a coin flip (or some other random process that can result in one of two outcomes) that has a perfect $50-50$ probability of landing on heads or tails (the probability of heads is $50\%$, the probability of tails is $50\%$), if I were to flip the coin 10 times, the results would be close to $5-5$. If I flip it $100$ times, the results would be close to $50-50$. The larger my sample size, the closer the results reflect the probability. But if I flip this coin once, there's a $50-50$ chance of landing on either heads or tails. The next time I flip the coin, the probability is the same. This means that each result of, say, $20$ flips would be equally likely ($8$ heads and $12$ tails and $10$ heads and $10$ tails would be equally likely). If this is true , why do the results of flipping a coin many times trend towards an equal split? If this isn't true, why not?","This sounds like a simple question, but here's the gist: Given a coin flip (or some other random process that can result in one of two outcomes) that has a perfect $50-50$ probability of landing on heads or tails (the probability of heads is $50\%$, the probability of tails is $50\%$), if I were to flip the coin 10 times, the results would be close to $5-5$. If I flip it $100$ times, the results would be close to $50-50$. The larger my sample size, the closer the results reflect the probability. But if I flip this coin once, there's a $50-50$ chance of landing on either heads or tails. The next time I flip the coin, the probability is the same. This means that each result of, say, $20$ flips would be equally likely ($8$ heads and $12$ tails and $10$ heads and $10$ tails would be equally likely). If this is true , why do the results of flipping a coin many times trend towards an equal split? If this isn't true, why not?",,['probability']
51,Is there a mistake in this question?,Is there a mistake in this question?,,"For a random variable $X$ with mean $\mu$ and variance $\sigma^2$   define $V(x)=\mathbb{E}(X-x)^2$. By expressing $V(X)$ in terms of   $\mu,\;\sigma^2,X$ show that $\sigma^2=\frac{1}{2}\mathbb{E}(V(X))$. My question is: isn't $V(X)=0?$ I've rewritten it as $V(X)=\sigma^2-(\mu-X)^2$ but this leads nowhere. I think I am misunderstanding something, or maybe there is a mistake in the question.","For a random variable $X$ with mean $\mu$ and variance $\sigma^2$   define $V(x)=\mathbb{E}(X-x)^2$. By expressing $V(X)$ in terms of   $\mu,\;\sigma^2,X$ show that $\sigma^2=\frac{1}{2}\mathbb{E}(V(X))$. My question is: isn't $V(X)=0?$ I've rewritten it as $V(X)=\sigma^2-(\mu-X)^2$ but this leads nowhere. I think I am misunderstanding something, or maybe there is a mistake in the question.",,['probability']
52,"Convergence almost everywhere implies convergence in measure, the proof thereof","Convergence almost everywhere implies convergence in measure, the proof thereof",,"Let $(E, \mathcal{E}, \mu)$ be a measure space, and $(f_n)_{n\in\mathbb{N}}$ and $f$ be measurable functions $(E, \mathcal{E}, \mu)\longrightarrow (\mathbb{R}, \mathcal{B})$. The first part of Theorem 2.10 on page 20 of Stefan Grosskinsky's lecture notes says ""assume that $\mu(E) < \infty$, then if $f_n \rightarrow f$ almost everywhere then $f_n \rightarrow f$ in measure"". I don't quite understand why we need $\mu(E) < \infty$. The proof given in there does indeed use $\mu(E) < \infty$. However, I seem to be able to find another proof that doesn't need to use it. I will first present (a slightly modified version of) the proof given by Prof. Grosskinsky below. Assume $f_n \rightarrow f$ almost everywhere and let $g_n = f_n - f$ for each $n$, we want to show that $g_n \rightarrow 0$ in measure. We need to show that for every $\epsilon > 0$, we have $\mu(|g_n| \geq \epsilon) \rightarrow 0$, or equivalently in the case $\mu(E) < \infty$, $\mu(|g_n| < \epsilon) \rightarrow \mu(E)$. Indeed, \begin{equation*} \begin{split} \mu(|g_n| < \epsilon) &\geq \mu\big(\bigcap_{m \geq n} \{|g_m| < \epsilon\}\big) \\ &\nearrow \mu\big(\bigcup_{N \in \mathbb{N}} \bigcap_{m > N} \{|g_m| < \epsilon\}\big) \\ &\geq \mu \big(\bigcap_{q \in \mathbb{Q},\, q > 0}\bigcup_{N \in \mathbb{N}} \bigcap_{m > N} \{|g_m| < \epsilon\}\big) \\ &= \mu(g_m \rightarrow 0) \\ &= \mu(E). \end{split} \end{equation*} I understand the proof above, but below I will present what seems to be a proof without resorting to $\mu(E) < \infty$. This proof directly shows, for all $\epsilon > 0$, that $\mu(|g_n| \geq \epsilon) \rightarrow 0$, as opposed to the proof above where we showed $\mu(|g_n| < \epsilon) \rightarrow \mu(E)$. \begin{equation*} \begin{split} \mu(|g_n| \geq \epsilon) & \leq \mu\big(\bigcup_{m \geq n} \{|g_m| \geq \epsilon\}\big)\\ &\searrow \mu \big(\bigcap_{N \in \mathbb{N}} \bigcup_{m>N} \{|g_m| \geq \epsilon\}\big)\\ &\leq \mu\big(\bigcup_{q\in\mathbb{Q},\, q>0} \bigcap_{N \in \mathbb{N}} \bigcup_{m>N} \{|g_m| \geq \epsilon\}\big)\\ &= \mu(g_m \nrightarrow 0)\\ &= 0. \end{split} \end{equation*} This 'proof' doesn't resort to $\mu(E) < \infty$, so it seems to me. Am I doing something wrong? Thank you in anticipation for your help!!!","Let $(E, \mathcal{E}, \mu)$ be a measure space, and $(f_n)_{n\in\mathbb{N}}$ and $f$ be measurable functions $(E, \mathcal{E}, \mu)\longrightarrow (\mathbb{R}, \mathcal{B})$. The first part of Theorem 2.10 on page 20 of Stefan Grosskinsky's lecture notes says ""assume that $\mu(E) < \infty$, then if $f_n \rightarrow f$ almost everywhere then $f_n \rightarrow f$ in measure"". I don't quite understand why we need $\mu(E) < \infty$. The proof given in there does indeed use $\mu(E) < \infty$. However, I seem to be able to find another proof that doesn't need to use it. I will first present (a slightly modified version of) the proof given by Prof. Grosskinsky below. Assume $f_n \rightarrow f$ almost everywhere and let $g_n = f_n - f$ for each $n$, we want to show that $g_n \rightarrow 0$ in measure. We need to show that for every $\epsilon > 0$, we have $\mu(|g_n| \geq \epsilon) \rightarrow 0$, or equivalently in the case $\mu(E) < \infty$, $\mu(|g_n| < \epsilon) \rightarrow \mu(E)$. Indeed, \begin{equation*} \begin{split} \mu(|g_n| < \epsilon) &\geq \mu\big(\bigcap_{m \geq n} \{|g_m| < \epsilon\}\big) \\ &\nearrow \mu\big(\bigcup_{N \in \mathbb{N}} \bigcap_{m > N} \{|g_m| < \epsilon\}\big) \\ &\geq \mu \big(\bigcap_{q \in \mathbb{Q},\, q > 0}\bigcup_{N \in \mathbb{N}} \bigcap_{m > N} \{|g_m| < \epsilon\}\big) \\ &= \mu(g_m \rightarrow 0) \\ &= \mu(E). \end{split} \end{equation*} I understand the proof above, but below I will present what seems to be a proof without resorting to $\mu(E) < \infty$. This proof directly shows, for all $\epsilon > 0$, that $\mu(|g_n| \geq \epsilon) \rightarrow 0$, as opposed to the proof above where we showed $\mu(|g_n| < \epsilon) \rightarrow \mu(E)$. \begin{equation*} \begin{split} \mu(|g_n| \geq \epsilon) & \leq \mu\big(\bigcup_{m \geq n} \{|g_m| \geq \epsilon\}\big)\\ &\searrow \mu \big(\bigcap_{N \in \mathbb{N}} \bigcup_{m>N} \{|g_m| \geq \epsilon\}\big)\\ &\leq \mu\big(\bigcup_{q\in\mathbb{Q},\, q>0} \bigcap_{N \in \mathbb{N}} \bigcup_{m>N} \{|g_m| \geq \epsilon\}\big)\\ &= \mu(g_m \nrightarrow 0)\\ &= 0. \end{split} \end{equation*} This 'proof' doesn't resort to $\mu(E) < \infty$, so it seems to me. Am I doing something wrong? Thank you in anticipation for your help!!!",,"['probability', 'measure-theory', 'convergence-divergence']"
53,"Is Brownian motion on $[0,b]$ bounded?",Is Brownian motion on  bounded?,"[0,b]","Is Brownian motion on $[0,b]$ bounded? Or at least bounded with probability one. Since Brownian motion is continuous with probability $1$, I guess the answer is YES.","Is Brownian motion on $[0,b]$ bounded? Or at least bounded with probability one. Since Brownian motion is continuous with probability $1$, I guess the answer is YES.",,"['probability', 'brownian-motion']"
54,A random variable with neither probability density function nor probability mass function... is this example wrong?,A random variable with neither probability density function nor probability mass function... is this example wrong?,,"This is from Shreve's Stochastic Calculus for Finance II , Appendix A.3. Consider infinitely many independent coin tosses with outcomes $\omega_n$, $n = 1, 2, \dots$ such that $\omega_n$ can be either $H$ = heads or $T$ = tails. Define \begin{equation} Y_n\left(\omega\right) = \begin{cases}1 & \text{ if }\omega_n = H \\ 0& \text{ if } \omega_n = T\text{.} \end{cases} \end{equation} Define $\displaystyle Y = \sum\limits_{n=1}^{\infty}\dfrac{2Y_n}{3^{n}}$. Shreve shows that $Y$ can only take values in the Cantor set, and since that particular set has measure zero, its Lebesgue measure is zero as well, thus it does not have a probability density function (since integrating such a density function would give a value of $0$). This part I understand, as well as my professor. Now Shreve claims that $Y$ does not have a probability mass function. If it did, then for some number $x \in C$ [the Cantor set] we would have $\mathbb{P}\left(Y=x\right) > 0$. But $x$ has a unique base-three expansion    \begin{equation} x = \sum\limits_{n=1}^{\infty}\dfrac{x_n}{3^{n}}\text{,} \end{equation}   where each $x_n$ is either 0, 1, or 2 unless $x$ is of the form $\dfrac{k}{3^{n}}$ for some positive integers $k$ and $n$. In the latter case, $x$ has two base-three expansions... In either case, there at most two choices of $w \in \Omega_{\infty}$ [that is, the infinite coin-toss space] for which $Y(\omega) = x$. In other words, the set $\{\omega \in \Omega; Y(\omega) = x\}$ has either one or two elements. The probability of a set with one element is zero, and the probability of a set with two elements is $0 + 0 = 0$. Hence $\mathbb{P}\left\{Y = x\right\} = 0$. My professor and I were able to follow this until the statement ""The probability of a set with one element is zero."" Is this a true statement? How so? I thought it would be perhaps the fact that the Lebesgue measure of $[a, a] = \{a\}$ is zero, but I don't see any reason why Shreve would only use the Lebesgue measure, since it is not a general probability measure.","This is from Shreve's Stochastic Calculus for Finance II , Appendix A.3. Consider infinitely many independent coin tosses with outcomes $\omega_n$, $n = 1, 2, \dots$ such that $\omega_n$ can be either $H$ = heads or $T$ = tails. Define \begin{equation} Y_n\left(\omega\right) = \begin{cases}1 & \text{ if }\omega_n = H \\ 0& \text{ if } \omega_n = T\text{.} \end{cases} \end{equation} Define $\displaystyle Y = \sum\limits_{n=1}^{\infty}\dfrac{2Y_n}{3^{n}}$. Shreve shows that $Y$ can only take values in the Cantor set, and since that particular set has measure zero, its Lebesgue measure is zero as well, thus it does not have a probability density function (since integrating such a density function would give a value of $0$). This part I understand, as well as my professor. Now Shreve claims that $Y$ does not have a probability mass function. If it did, then for some number $x \in C$ [the Cantor set] we would have $\mathbb{P}\left(Y=x\right) > 0$. But $x$ has a unique base-three expansion    \begin{equation} x = \sum\limits_{n=1}^{\infty}\dfrac{x_n}{3^{n}}\text{,} \end{equation}   where each $x_n$ is either 0, 1, or 2 unless $x$ is of the form $\dfrac{k}{3^{n}}$ for some positive integers $k$ and $n$. In the latter case, $x$ has two base-three expansions... In either case, there at most two choices of $w \in \Omega_{\infty}$ [that is, the infinite coin-toss space] for which $Y(\omega) = x$. In other words, the set $\{\omega \in \Omega; Y(\omega) = x\}$ has either one or two elements. The probability of a set with one element is zero, and the probability of a set with two elements is $0 + 0 = 0$. Hence $\mathbb{P}\left\{Y = x\right\} = 0$. My professor and I were able to follow this until the statement ""The probability of a set with one element is zero."" Is this a true statement? How so? I thought it would be perhaps the fact that the Lebesgue measure of $[a, a] = \{a\}$ is zero, but I don't see any reason why Shreve would only use the Lebesgue measure, since it is not a general probability measure.",,"['probability', 'measure-theory', 'probability-theory']"
55,Probability of a path of a given length between two vertices of a random graph,Probability of a path of a given length between two vertices of a random graph,,"Suppose that in  random graph $G$ on $n$ vertices any $2$ vertices can be connected by an edge with probability $\dfrac{1}{2}$, independently of all other edges.  What is the probability  $P_n(k)$ that two arbitrary vertices are connected by a simple path of length $k$, $0<k \leq n-1$? My attempt. Fix $2$ vertices. To build a path of length $k$ we have to  choose $k-1$ vertices from the remaining $n-2$ vertices. Since order is important we can do it in $(k-1)! {n-2 \choose k-1}$  ways. There are $2^k$ configurations of the edges for a path of length $k$. Thus the probability seems to be  $$ P_n(k)=\frac{(k-1)! {n-2 \choose k-1}}{2^k}. $$ The sum over all path lengths, $\displaystyle \sum_{k=1}^{n-1}P_n(k)$, must equal $1$, but my calculations for small $n$ show that it is not $1$. Where is my mistake?","Suppose that in  random graph $G$ on $n$ vertices any $2$ vertices can be connected by an edge with probability $\dfrac{1}{2}$, independently of all other edges.  What is the probability  $P_n(k)$ that two arbitrary vertices are connected by a simple path of length $k$, $0<k \leq n-1$? My attempt. Fix $2$ vertices. To build a path of length $k$ we have to  choose $k-1$ vertices from the remaining $n-2$ vertices. Since order is important we can do it in $(k-1)! {n-2 \choose k-1}$  ways. There are $2^k$ configurations of the edges for a path of length $k$. Thus the probability seems to be  $$ P_n(k)=\frac{(k-1)! {n-2 \choose k-1}}{2^k}. $$ The sum over all path lengths, $\displaystyle \sum_{k=1}^{n-1}P_n(k)$, must equal $1$, but my calculations for small $n$ show that it is not $1$. Where is my mistake?",,"['probability', 'random-graphs']"
56,Simplifying the expectation of a ratio of exponential random variables.,Simplifying the expectation of a ratio of exponential random variables.,,"Suppose there are i.i.d. exponential random variables $x_1,\dots,x_n, y_1,\dots,y_m$. Can we write the following expectation $$E\left(\cfrac{a_1x_1+\dots+a_nx_n}{b_1y_1+\dots+b_my_m}\right),$$ as the sum of some functions of the coefficients i.e., of the form $$\cfrac{f_1(a_1)+\dots+f_n(a_n)}{g_1(b_1)+\dots+g_m(b_m)},$$ where $f_i$ and $g_j$ are functions and $a_i$ and $b_j$ are constants. I think the numerator can be written as the sum of expectations $a_1Ex_1+\dots+a_nEx_n$ and of course $Ex_i$ are all equal by i.i.d. I am not sure how to simplify the denominator.","Suppose there are i.i.d. exponential random variables $x_1,\dots,x_n, y_1,\dots,y_m$. Can we write the following expectation $$E\left(\cfrac{a_1x_1+\dots+a_nx_n}{b_1y_1+\dots+b_my_m}\right),$$ as the sum of some functions of the coefficients i.e., of the form $$\cfrac{f_1(a_1)+\dots+f_n(a_n)}{g_1(b_1)+\dots+g_m(b_m)},$$ where $f_i$ and $g_j$ are functions and $a_i$ and $b_j$ are constants. I think the numerator can be written as the sum of expectations $a_1Ex_1+\dots+a_nEx_n$ and of course $Ex_i$ are all equal by i.i.d. I am not sure how to simplify the denominator.",,"['probability', 'expectation']"
57,Distribuation Max - Min of Brownian motion,Distribuation Max - Min of Brownian motion,,I'm looking for the distribuation of $M_X(t) - m_X(t)$ of the brownian motion and not the joint distribuation. where $m_X(t) = \min\limits_{0\leq s\leq t}X(s)$ and  $M_X(t) = \max\limits_{0\leq s\leq t}X(s)$. Any help would be greatly appreciated.,I'm looking for the distribuation of $M_X(t) - m_X(t)$ of the brownian motion and not the joint distribuation. where $m_X(t) = \min\limits_{0\leq s\leq t}X(s)$ and  $M_X(t) = \max\limits_{0\leq s\leq t}X(s)$. Any help would be greatly appreciated.,,"['probability', 'stochastic-processes', 'brownian-motion']"
58,Disintegration-like theorem,Disintegration-like theorem,,"$\def\b{\mathcal B}\def\p{\mathcal P}\def\d{\mathrm d}$ Let $X$ be a (standard) Borel space: a topological space isomorphic to a Borel set of a complete separable metric space. Denote by $\b(X)$ the Borel $\sigma$-algebra of $X$, by $\p(X)$ the set of Borel probability measures on $X$ endowed with a topology of weak convergence. Let $Y$ be another Borel space and let $f:X\to Y$ be a Borel map. Consider a measure $\alpha\in \p(X)$ and a stochastic kernel $P:X\to \p(X)$. Let us denote by $Q:X\to\p(Y)$ the pushforward kernel: $$   Q(B|x) := P(f^{-1}(B)|x) \qquad \text{ for all }x\in X,B\in \b(Y). $$ Does there exist a stochastic kernel $R:X\times Y \to \p(X)$ satisfying the following conditions: $R(f^{-1}(y)|x,y) = 1$ for $\alpha\otimes Q$-almost all $(x,y)\in X\times Y$, that is $$   \int_{X\times Y}R\left(\left.X\setminus f^{-1}(y)\right|x,y\right)\;Q(\d y|x)\;\alpha(\d y) = 0 $$ for all $A\in \b(X)$ and $\alpha$-almost all $x\in X$ it holds that $$   P(A|x) = \int_Y R(A|x,y)\; Q(\d y|x). $$ The statement sounds very much related to the Disintegration theorem , however the current version is seemingly more general and I was not able to transform it as a special case of the original formulation. Regarding the assumptions on the measurable spaces involved. In the formulation I have linked the Radon spaces are required (I don't know whether each Borel space is Radon), whereas in ""Conditioning and Disintegration"" of Kallenberg (Ch. 5 in 1st ed., Ch.6 in 2nd ed.) the disintegration theorem only requires the existence of regular conditional distributions. As in my case everything shall only hold almost surely, I guess that the result I am looking for may hold for general measurable spaces just based on the existence of conditional expectation for general measurable spaces. Although I know that there exists a connection between the conditional expectation and the disintegration, I'm not sure whether it can help me here.","$\def\b{\mathcal B}\def\p{\mathcal P}\def\d{\mathrm d}$ Let $X$ be a (standard) Borel space: a topological space isomorphic to a Borel set of a complete separable metric space. Denote by $\b(X)$ the Borel $\sigma$-algebra of $X$, by $\p(X)$ the set of Borel probability measures on $X$ endowed with a topology of weak convergence. Let $Y$ be another Borel space and let $f:X\to Y$ be a Borel map. Consider a measure $\alpha\in \p(X)$ and a stochastic kernel $P:X\to \p(X)$. Let us denote by $Q:X\to\p(Y)$ the pushforward kernel: $$   Q(B|x) := P(f^{-1}(B)|x) \qquad \text{ for all }x\in X,B\in \b(Y). $$ Does there exist a stochastic kernel $R:X\times Y \to \p(X)$ satisfying the following conditions: $R(f^{-1}(y)|x,y) = 1$ for $\alpha\otimes Q$-almost all $(x,y)\in X\times Y$, that is $$   \int_{X\times Y}R\left(\left.X\setminus f^{-1}(y)\right|x,y\right)\;Q(\d y|x)\;\alpha(\d y) = 0 $$ for all $A\in \b(X)$ and $\alpha$-almost all $x\in X$ it holds that $$   P(A|x) = \int_Y R(A|x,y)\; Q(\d y|x). $$ The statement sounds very much related to the Disintegration theorem , however the current version is seemingly more general and I was not able to transform it as a special case of the original formulation. Regarding the assumptions on the measurable spaces involved. In the formulation I have linked the Radon spaces are required (I don't know whether each Borel space is Radon), whereas in ""Conditioning and Disintegration"" of Kallenberg (Ch. 5 in 1st ed., Ch.6 in 2nd ed.) the disintegration theorem only requires the existence of regular conditional distributions. As in my case everything shall only hold almost surely, I guess that the result I am looking for may hold for general measurable spaces just based on the existence of conditional expectation for general measurable spaces. Although I know that there exists a connection between the conditional expectation and the disintegration, I'm not sure whether it can help me here.",,"['probability', 'functional-analysis', 'measure-theory']"
59,I want to prove that these definitions of expected value hold,I want to prove that these definitions of expected value hold,,"Let $(\Omega,\mathcal B,P)$ be a probability space. I have two (related) questions.  Assuming that $g:\mathbb{R}\to\mathbb{R}$ is Borel measurable, and understanding that $$E(g(X)) = \int_{\Omega}g(X(\omega))dP(\omega),$$ how do I prove that these equalities hold for the two following circumstances? First, $X$ is discrete, with range $\{x_{i}:i\in \mathbb N\}$. Then $$E(g(X))=\sum_{i=0}^{\infty}g(x_{i})P(X=x_{i}),\ \  \text{ provided } \sum_{i=0}^{\infty}|g(x_{i})|P(X=x_{i})<\infty.$$ Second, $X $ is absolutely continuous with density $f.$  Then $$E(g(X))=\int g(x)f(x)dx\ \ \text{ provided }\int |g(x)|f(x)dx<\infty.$$ and my try:I think about number one I can write $$E(g(X))=\int_{\mathbb R}g(X)dP$$ As regards $X$ is  discrete I think $$E(g(X))=\sum_{i=1}^{\infty}g(x_{i})\int dP=\sum_{i=1}^{\infty}g(x_{i})P(X=x_{i}) $$ about number two i just now $X$ is absolutely continuous hence$$P_{X}(E)=\int_{E}f(x)dx \qquad \forall E \in \mathcal B_{\mathbb R}$$ thanks for any help.","Let $(\Omega,\mathcal B,P)$ be a probability space. I have two (related) questions.  Assuming that $g:\mathbb{R}\to\mathbb{R}$ is Borel measurable, and understanding that $$E(g(X)) = \int_{\Omega}g(X(\omega))dP(\omega),$$ how do I prove that these equalities hold for the two following circumstances? First, $X$ is discrete, with range $\{x_{i}:i\in \mathbb N\}$. Then $$E(g(X))=\sum_{i=0}^{\infty}g(x_{i})P(X=x_{i}),\ \  \text{ provided } \sum_{i=0}^{\infty}|g(x_{i})|P(X=x_{i})<\infty.$$ Second, $X $ is absolutely continuous with density $f.$  Then $$E(g(X))=\int g(x)f(x)dx\ \ \text{ provided }\int |g(x)|f(x)dx<\infty.$$ and my try:I think about number one I can write $$E(g(X))=\int_{\mathbb R}g(X)dP$$ As regards $X$ is  discrete I think $$E(g(X))=\sum_{i=1}^{\infty}g(x_{i})\int dP=\sum_{i=1}^{\infty}g(x_{i})P(X=x_{i}) $$ about number two i just now $X$ is absolutely continuous hence$$P_{X}(E)=\int_{E}f(x)dx \qquad \forall E \in \mathcal B_{\mathbb R}$$ thanks for any help.",,"['probability', 'probability-theory', 'expectation']"
60,Probability that three randomly chosen points on a circle provides an acute triangle,Probability that three randomly chosen points on a circle provides an acute triangle,,"In trying to solve the classic problem -- ""Find the probability that three randomly chosen points on a circle provides an acute triangle"" I came across this page that seems to have a good explanation. However, I do not understand how they came up with the probability as  $\int_{0}^{\pi }{\frac{1}{\pi }\cdot \frac{\theta }{2\pi }\cdot d\theta }$ I understood that the probability is the length of sector of the circle between the two dotted lines divided by the total circumference, but do not see how/why the integral is needed.","In trying to solve the classic problem -- ""Find the probability that three randomly chosen points on a circle provides an acute triangle"" I came across this page that seems to have a good explanation. However, I do not understand how they came up with the probability as  $\int_{0}^{\pi }{\frac{1}{\pi }\cdot \frac{\theta }{2\pi }\cdot d\theta }$ I understood that the probability is the length of sector of the circle between the two dotted lines divided by the total circumference, but do not see how/why the integral is needed.",,"['calculus', 'probability']"
61,"Combinations: Poker hands, full houses","Combinations: Poker hands, full houses",,"Reading through my Probability book brushing up on some stuff: What is the probability that a poker hand is a full house? (A full house is defined as a hand with three cards of one denomination and two cards of another denomination; ex. three Queens and two 4's.) The solution (this is an example) is stated as: The number of different poker hands is $52\choose5$ . To count the number of full houses, let us call a hand of type (Q,4) if it has three queens and two 4's, with similar representations for other types of full houses. Observe that (Q,4) and (4,Q) are different full houses, and types such as (Q,Q) and (K,K) do not exist. Hence there are $13 \times 12$ different types of full houses. Since every particular type, say (4,Q), there are $4\choose3$ ways to select three 4's and $4\choose2$ ways to select two Q's, the desired probability is $$ \frac{13 \cdot 12 \cdot \binom{4}{3} \cdot \binom{4}{2}}{\binom{52}{5}}$$ I don't understand how the $13 \times 12$ comes about, and that's where I need some clarification. Thank you in advance.","Reading through my Probability book brushing up on some stuff: What is the probability that a poker hand is a full house? (A full house is defined as a hand with three cards of one denomination and two cards of another denomination; ex. three Queens and two 4's.) The solution (this is an example) is stated as: The number of different poker hands is . To count the number of full houses, let us call a hand of type (Q,4) if it has three queens and two 4's, with similar representations for other types of full houses. Observe that (Q,4) and (4,Q) are different full houses, and types such as (Q,Q) and (K,K) do not exist. Hence there are different types of full houses. Since every particular type, say (4,Q), there are ways to select three 4's and ways to select two Q's, the desired probability is I don't understand how the comes about, and that's where I need some clarification. Thank you in advance.",52\choose5 13 \times 12 4\choose3 4\choose2  \frac{13 \cdot 12 \cdot \binom{4}{3} \cdot \binom{4}{2}}{\binom{52}{5}} 13 \times 12,"['probability', 'combinations', 'poker']"
62,Why is the Brownian motion a multivariate normal distribution?,Why is the Brownian motion a multivariate normal distribution?,,"I have seen in class that for some reasons I forgot, the Brownian Motion has a Multivariate normal distribution, but I am unable to prove it easily. Could someone tell me why it's true? From what I understand, I have to take a finite linear combination of values of Brownian motion at different times, and check that it's normally distributed. Could someone help me on this? thanks edit : the definition I start from is the one from wikipedia : http://en.wikipedia.org/wiki/Brownian_motion#Mathematics points 1 to 4 what I'm trying to prove is that  Y = a1*B1 + … + ak*Bk is normally distributed, where Bi are values of the Brownian motion at time Ti","I have seen in class that for some reasons I forgot, the Brownian Motion has a Multivariate normal distribution, but I am unable to prove it easily. Could someone tell me why it's true? From what I understand, I have to take a finite linear combination of values of Brownian motion at different times, and check that it's normally distributed. Could someone help me on this? thanks edit : the definition I start from is the one from wikipedia : http://en.wikipedia.org/wiki/Brownian_motion#Mathematics points 1 to 4 what I'm trying to prove is that  Y = a1*B1 + … + ak*Bk is normally distributed, where Bi are values of the Brownian motion at time Ti",,"['probability', 'brownian-motion']"
63,$X-Y$ equivalent in distribution to $0$?,equivalent in distribution to ?,X-Y 0,"If $X$ is equal to $Y$ in distribution, is it equivalent to $X-Y$ which is equivalent in distribution to $0$?","If $X$ is equal to $Y$ in distribution, is it equivalent to $X-Y$ which is equivalent in distribution to $0$?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
64,Probability of murdering a guinea pig in system of 4 rooms,Probability of murdering a guinea pig in system of 4 rooms,,"A guinea pig is in a system of 4 rooms as described in the following illustration (where the dolphin is the guinea pig and skull the choking poison): The guinea pig can move right in probability $p$ and left in probability $q=1-p$ . In room 1 the guinea pig is chocked, dies and can't move anymore. After breaking out of the system (See 'Outside'),it won't come back. Find probability for its death. My problem is there are infine tracks which all of them include the step $2\to1$ .If I understood correct for each track I need to calculate the probability and sum it (e.g $A=3\to 4\to 3\to2\to1$ has probability $P(A)=(1-p)^3p$ ) but I can't find any common motive except the trivial step toward the trap. How can I sum all the tracks?","A guinea pig is in a system of 4 rooms as described in the following illustration (where the dolphin is the guinea pig and skull the choking poison): The guinea pig can move right in probability and left in probability . In room 1 the guinea pig is chocked, dies and can't move anymore. After breaking out of the system (See 'Outside'),it won't come back. Find probability for its death. My problem is there are infine tracks which all of them include the step .If I understood correct for each track I need to calculate the probability and sum it (e.g has probability ) but I can't find any common motive except the trivial step toward the trap. How can I sum all the tracks?",p q=1-p 2\to1 A=3\to 4\to 3\to2\to1 P(A)=(1-p)^3p,[]
65,"Say I have a bag of 100 unique marbles. With I replacement, I pick 10 marbles at a time, at random.","Say I have a bag of 100 unique marbles. With I replacement, I pick 10 marbles at a time, at random.",,"Say I have a bag of 100 unique marbles. With replacement, I pick 10 marbles at a time, at random. How many times will I have to pick the marbles (10 marbles a pick) in order to have a 95% chance of having seen every unique marble at least once.","Say I have a bag of 100 unique marbles. With replacement, I pick 10 marbles at a time, at random. How many times will I have to pick the marbles (10 marbles a pick) in order to have a 95% chance of having seen every unique marble at least once.",,['probability']
66,Understanding Bayes' Theorem,Understanding Bayes' Theorem,,"I worked through some examples of Bayes' Theorem and now was reading the proof. Bayes' Theorem states the following: Suppose that the sample space S is partitioned into disjoint subsets $B_1, B_2,...,B_n$ .  That is, $S = B_1 \cup B_2 \cup \cdots \cup B_n$ , $\Pr(B_i) > 0$ $\forall i=1,2,...,n$ and $B_i \cap B_j = \varnothing$ $\forall i\ne j$ .  Then for an event A, $\Pr(B_j \mid A)=\cfrac{B_j \cap A}{\Pr(A)}=\cfrac{\Pr(B_j) \cdot \Pr(A \mid B_j)}{\sum\limits_{i=1}^{n}\Pr(B_i) \cdot \Pr(A \mid B_i)}\tag{1}$ The numerator is just from definition of conditional probability in multiplicative form. For the denominator, I read the following: $A= A \cap S= A \cap (B_1 \cup B_2 \cup \cdots \cup B_n)=(A \cap B_1) \cup (A\cap B_2) \cup \cdots \cup(A \cap B_n)\tag{2}$ Now this is what I don't understand: The sets $A \cup B_i$ are disjoint because the sets $B_1, B_2, ..., B_n$ form a partition. $\tag{$\clubsuit$}$ I don't see how that is inferred or why that is the case.  What does B forming a partition have anything to do with  it being disjoint with A.  Can someone please explain this conceptually or via an example? I worked one example where you had 3 coolers and in each cooler you had either root beer or soda.  So the first node would be which cooler you would choose and the second nodes would be whether you choose root beer or soda.  But I don't see why these would be disjoint.  If anything, I would say they weren't disjoint because each cooler contains both types of drinks. Thank you in advance! :)","I worked through some examples of Bayes' Theorem and now was reading the proof. Bayes' Theorem states the following: Suppose that the sample space S is partitioned into disjoint subsets .  That is, , and .  Then for an event A, The numerator is just from definition of conditional probability in multiplicative form. For the denominator, I read the following: Now this is what I don't understand: The sets are disjoint because the sets form a partition. I don't see how that is inferred or why that is the case.  What does B forming a partition have anything to do with  it being disjoint with A.  Can someone please explain this conceptually or via an example? I worked one example where you had 3 coolers and in each cooler you had either root beer or soda.  So the first node would be which cooler you would choose and the second nodes would be whether you choose root beer or soda.  But I don't see why these would be disjoint.  If anything, I would say they weren't disjoint because each cooler contains both types of drinks. Thank you in advance! :)","B_1, B_2,...,B_n S = B_1 \cup B_2 \cup \cdots \cup B_n \Pr(B_i) > 0 \forall i=1,2,...,n B_i \cap B_j = \varnothing \forall i\ne j \Pr(B_j \mid A)=\cfrac{B_j \cap A}{\Pr(A)}=\cfrac{\Pr(B_j) \cdot \Pr(A \mid B_j)}{\sum\limits_{i=1}^{n}\Pr(B_i) \cdot \Pr(A \mid B_i)}\tag{1} A= A \cap S= A \cap (B_1 \cup B_2 \cup \cdots \cup B_n)=(A \cap B_1) \cup (A\cap B_2) \cup \cdots \cup(A \cap B_n)\tag{2} A \cup B_i B_1, B_2, ..., B_n \tag{\clubsuit}",['probability']
67,Roulette strategy,Roulette strategy,,"I came up with a strategy, which imitates the martingale (doubling) strategy , but it seems that there is a good probability to gain profit, which I want to compute. So this is how we start: We do not bet on black/red, but we chose columns, or dozens. Let's say we start with 100 chips. Bet $1$ chip in e.g. a column. The probability to win is $12/37$ . If you win, start over again, while if you lose: Bet again $1$ chip to a column. Why again $1$ ? This is because we will still have profit if we win ( I will have won 3 chips, and lost 2 ). Again, if win go to step $1$ , if lose: Bet $2$ chips in a column. Each time we bet the lowest amount of funds, such that we have profit in case we win. In this case, if we win we will have played $4 $ chips , and won $6$ , which gives the minimum  profit( $2 $ chips). Continuing with this strategy, one has to bet in columns/dozens, the following sequence of chips (each time he loses), in order to have the minimum profit : $$1,1,2,3,4,6,9,14,21,31,47\dots$$ So, here is my question: Using this strategy, and starting with $100$ chips, what is the probability of gaining $+50\%$ , and what is the probability of doubling? You continue until you have doubled, and stop if you have less chips than they are required to put the next bet . *We have to consider that when we gain some profit, e.g. we have reached $140$ chips, we are able to bet more chips of the above sequence. With $100$ chips we can lose up to 9 times, and then bet $31$ chips. But with $140$ chips we can lose one more time , and then bet $46$ . Due to the complexity of the problem, I would also appreciate a numerical solution, but I do not have the knowledge to run a simulation. Anyone can figure out a solution using probability theory?","I came up with a strategy, which imitates the martingale (doubling) strategy , but it seems that there is a good probability to gain profit, which I want to compute. So this is how we start: We do not bet on black/red, but we chose columns, or dozens. Let's say we start with 100 chips. Bet chip in e.g. a column. The probability to win is . If you win, start over again, while if you lose: Bet again chip to a column. Why again ? This is because we will still have profit if we win ( I will have won 3 chips, and lost 2 ). Again, if win go to step , if lose: Bet chips in a column. Each time we bet the lowest amount of funds, such that we have profit in case we win. In this case, if we win we will have played chips , and won , which gives the minimum  profit( chips). Continuing with this strategy, one has to bet in columns/dozens, the following sequence of chips (each time he loses), in order to have the minimum profit : So, here is my question: Using this strategy, and starting with chips, what is the probability of gaining , and what is the probability of doubling? You continue until you have doubled, and stop if you have less chips than they are required to put the next bet . *We have to consider that when we gain some profit, e.g. we have reached chips, we are able to bet more chips of the above sequence. With chips we can lose up to 9 times, and then bet chips. But with chips we can lose one more time , and then bet . Due to the complexity of the problem, I would also appreciate a numerical solution, but I do not have the knowledge to run a simulation. Anyone can figure out a solution using probability theory?","1 12/37 1 1 1 2 4  6 2  1,1,2,3,4,6,9,14,21,31,47\dots 100 +50\% 140 100 31 140 46","['probability', 'gambling']"
68,Is Cesaro convergence still weaker in measure?,Is Cesaro convergence still weaker in measure?,,"I've encountered a question I couldn't answer, and I would appreciate any help: Is it true that $$f_n \xrightarrow{m}0\,\,\implies \,\,\frac{1}{n} \sum_{k=1}^{n}f_k \xrightarrow{m}0$$ where $(X,{\mathcal{B}},m)$ is a probability space, and $\xrightarrow{m}$ means: $\forall \epsilon>0,\,  m\left(|f_n|\geq \epsilon\right) \rightarrow 0.$ This is similar to Cesaro convergence, which is weaker than regular convergence, but it is not the case here. I've tried to prove the proposition, or to give a counter example, but didn't manage to succeed in either. Any insights will be appreciated!","I've encountered a question I couldn't answer, and I would appreciate any help: Is it true that $$f_n \xrightarrow{m}0\,\,\implies \,\,\frac{1}{n} \sum_{k=1}^{n}f_k \xrightarrow{m}0$$ where $(X,{\mathcal{B}},m)$ is a probability space, and $\xrightarrow{m}$ means: $\forall \epsilon>0,\,  m\left(|f_n|\geq \epsilon\right) \rightarrow 0.$ This is similar to Cesaro convergence, which is weaker than regular convergence, but it is not the case here. I've tried to prove the proposition, or to give a counter example, but didn't manage to succeed in either. Any insights will be appreciated!",,"['probability', 'sequences-and-series', 'measure-theory', 'convergence-divergence']"
69,Double Jumps of a Poisson Process,Double Jumps of a Poisson Process,,"If $N_t$ be a Poisson Process with rate $\lambda>0$, surely for any prescribed $t>0$, the probability that $N_t$ ""jumps (at least) twice"" at $t$ is zero, i.e. $\lim_{\epsilon\rightarrow0}P\{N_t-N_{t-\epsilon}\geq 2\}=0$ (is this even a proper way to state what I want to say?) Now my intuition tells me that the probability that $N_t$ ""jumps twice"" at any point in time should still be zero, but clearly you can't claim this by ""integrating"" zero over $t\in\mathbb{R}$ - that would be just like saying a uniform variable $X$ over $[0,1]$ has zero probability of being any point $t\in[0,1]$, and so $X$ has a zero probability of being in $[0,1]$. You would have to say, the probability of $X$ being in a small interval of length $dx$ is $1\cdot dx$, and the integral of that over $[0,1]$ is $1$. Also I notice that the probability that $N_t$ ""jumps at least once"" at some point in time should be one, since that equivalent to the probability $\lim_{t\rightarrow\infty}1-P\{N_t=0\} =1- e^{-\lambda t} = 1$. But again the probability of $N_t$ jumping at any $t>0$ is $0$. The issue, I think, is me trying to claim you can sum probabilities over an uncountable set, when you actually have to do something like put a measure on the $t$'s. Can someone explain what's going on with a little more rigour than I in my best efforts have been able to muster here (shouldn't be hard)?","If $N_t$ be a Poisson Process with rate $\lambda>0$, surely for any prescribed $t>0$, the probability that $N_t$ ""jumps (at least) twice"" at $t$ is zero, i.e. $\lim_{\epsilon\rightarrow0}P\{N_t-N_{t-\epsilon}\geq 2\}=0$ (is this even a proper way to state what I want to say?) Now my intuition tells me that the probability that $N_t$ ""jumps twice"" at any point in time should still be zero, but clearly you can't claim this by ""integrating"" zero over $t\in\mathbb{R}$ - that would be just like saying a uniform variable $X$ over $[0,1]$ has zero probability of being any point $t\in[0,1]$, and so $X$ has a zero probability of being in $[0,1]$. You would have to say, the probability of $X$ being in a small interval of length $dx$ is $1\cdot dx$, and the integral of that over $[0,1]$ is $1$. Also I notice that the probability that $N_t$ ""jumps at least once"" at some point in time should be one, since that equivalent to the probability $\lim_{t\rightarrow\infty}1-P\{N_t=0\} =1- e^{-\lambda t} = 1$. But again the probability of $N_t$ jumping at any $t>0$ is $0$. The issue, I think, is me trying to claim you can sum probabilities over an uncountable set, when you actually have to do something like put a measure on the $t$'s. Can someone explain what's going on with a little more rigour than I in my best efforts have been able to muster here (shouldn't be hard)?",,"['probability', 'measure-theory']"
70,Expected number of different colors,Expected number of different colors,,"I have a box containing $n$ colored balls. There are $c$ different colors. $k_1$ balls have color $1$, $k_2$ balls have color $2$, ... and $k_c$ balls have color $c$. When I draw $m$ balls with replacement, what is the expected number of different colors? Referencess to similar problems are approximations are also appreciated.","I have a box containing $n$ colored balls. There are $c$ different colors. $k_1$ balls have color $1$, $k_2$ balls have color $2$, ... and $k_c$ balls have color $c$. When I draw $m$ balls with replacement, what is the expected number of different colors? Referencess to similar problems are approximations are also appreciated.",,['probability']
71,No two identical ranks together in a standard deck of cards,No two identical ranks together in a standard deck of cards,,"What is the probability that a shuffled standard deck of 52 cards has no two cards of the same rank together ? I am unable to get a handle on this problem, and wonder whether there is an analytical solution ?","What is the probability that a shuffled standard deck of 52 cards has no two cards of the same rank together ? I am unable to get a handle on this problem, and wonder whether there is an analytical solution ?",,"['probability', 'combinatorics']"
72,How long will it take to get 10 heads in a row flipping coins?,How long will it take to get 10 heads in a row flipping coins?,,"I need a way of solving this problem:  It's not math homework, I legitimately want to know and it's bothering me. So the probability of having a coin land on heads is .5 or 1/2, so it'll land on heads half the time in a perfect world. The probability of a coin landing heads ten times in a row is .0009765625. There are 7,000,000 people on the planet. Each person can flip a coin 17280 times a day. If every person on the planet flips coins until one person gets ten heads in a row, how long will it take to get the 10 heads in a row?","I need a way of solving this problem:  It's not math homework, I legitimately want to know and it's bothering me. So the probability of having a coin land on heads is .5 or 1/2, so it'll land on heads half the time in a perfect world. The probability of a coin landing heads ten times in a row is .0009765625. There are 7,000,000 people on the planet. Each person can flip a coin 17280 times a day. If every person on the planet flips coins until one person gets ten heads in a row, how long will it take to get the 10 heads in a row?",,['probability']
73,"Are these numbers $h_{r,s}$ irrational?",Are these numbers  irrational?,"h_{r,s}","I came across these numbers in my work some time ago. This type of expressions do not exist in closed form (not to confuse with Vandermonde convolution), I already know that. To simplify I denote  $$P(r;s;k)=\binom{\frac{n}{2}+r}{k}  \binom{\frac{n}{2}-r}{k+s}$$ Here is why I think these numbers are interesting: anyone can see combinatorial structures in algorithms or elsewhere, but these expressions converge. Experiment  1, $r=0, s=0:$ There are $n$ fair coins, of them half are heads $H$, half are tails $T$. Each coin is flipped w.p. $\frac{1}{n}$, i.e. proportional to size of the sample. The question is, after the experiment is over, what is the probability that the ratio of $H$/$T$ remains the same, i.e. half and half. The tricky thing is, in order to preserve the ratio, we need to flip an $\mathit{even}$ number of coins, or, more specifically, an equal number of $H$ and $T$ (obviously two $H$ or two $T$ won't do): either 0 $H$ and 0 $T$, or 1 $H$ and 1 $T$ and so on till $\frac{n}{2} \ H, \frac{n}{2} \ T$. The probability to preserve the ratio (and the first such number) is therefore  $$ h_{0,0}= \lim _{n \to \infty} \sum_{k=0}^{\frac{n}{2}} P(0;0;k) \frac{1}{n^{2k}} \bigg(1-\frac{1}{n}\bigg)^{n-2k} \approx 0.465267 $$ Experiment 2, $r=0,s=1$: same setup as before, but now I need to obtain $\textit{exactly}$ one more $H$ coin as a result of the experiment (or $T$, it does not matter by symmetry). To do this, I need to flip $exactly$ one more $T$ than $H$, hence we need to flip an $odd$ number of coins: $$ h_{0,1}= \lim _{n \to \infty} \sum_{k=0}^{\frac{n}{2}-1} P(0;1;k) \frac{1}{n^{2k+1}} \bigg(1-\frac{1}{n}\bigg)^{n-2k-1} \approx 0.208912 $$ Experiment 3, $r=1,s=0$. This comes directly after experiment 2: we have $\frac{n}{2}+1 \ H$ and $\frac{n}{2}-1 \ T$. We want the same result as in Experiment 1: maintain the current proportion of $H$ and $T$ (i.e. flip an even number of coins), but clearly this time around the upper bound on the summation is $\frac{n}{2}-1$. $$ h_{1,0}= \lim _{n \to \infty} \sum_{k=0}^{\frac{n}{2}-1} P(1;0;k) \frac{1}{n^{2k}} \bigg(1-\frac{1}{n}\bigg)^{n-2k} \approx 0.465225 $$ and so on for $h_{r,s}, 0 \leq r,s \leq n$. So here is what I'd like to know: 1) Have these numbers arisen in some other context (I never ended up publishing a paper) 2) Is there some rigorous way to prove these numbers are irrational? I've shown the $\lim$ part simply by taking large $n$, so I guess this not rigorous enough. 3) If there is something I've missed, I'd like to know too. Thanks for the suggestions.","I came across these numbers in my work some time ago. This type of expressions do not exist in closed form (not to confuse with Vandermonde convolution), I already know that. To simplify I denote  $$P(r;s;k)=\binom{\frac{n}{2}+r}{k}  \binom{\frac{n}{2}-r}{k+s}$$ Here is why I think these numbers are interesting: anyone can see combinatorial structures in algorithms or elsewhere, but these expressions converge. Experiment  1, $r=0, s=0:$ There are $n$ fair coins, of them half are heads $H$, half are tails $T$. Each coin is flipped w.p. $\frac{1}{n}$, i.e. proportional to size of the sample. The question is, after the experiment is over, what is the probability that the ratio of $H$/$T$ remains the same, i.e. half and half. The tricky thing is, in order to preserve the ratio, we need to flip an $\mathit{even}$ number of coins, or, more specifically, an equal number of $H$ and $T$ (obviously two $H$ or two $T$ won't do): either 0 $H$ and 0 $T$, or 1 $H$ and 1 $T$ and so on till $\frac{n}{2} \ H, \frac{n}{2} \ T$. The probability to preserve the ratio (and the first such number) is therefore  $$ h_{0,0}= \lim _{n \to \infty} \sum_{k=0}^{\frac{n}{2}} P(0;0;k) \frac{1}{n^{2k}} \bigg(1-\frac{1}{n}\bigg)^{n-2k} \approx 0.465267 $$ Experiment 2, $r=0,s=1$: same setup as before, but now I need to obtain $\textit{exactly}$ one more $H$ coin as a result of the experiment (or $T$, it does not matter by symmetry). To do this, I need to flip $exactly$ one more $T$ than $H$, hence we need to flip an $odd$ number of coins: $$ h_{0,1}= \lim _{n \to \infty} \sum_{k=0}^{\frac{n}{2}-1} P(0;1;k) \frac{1}{n^{2k+1}} \bigg(1-\frac{1}{n}\bigg)^{n-2k-1} \approx 0.208912 $$ Experiment 3, $r=1,s=0$. This comes directly after experiment 2: we have $\frac{n}{2}+1 \ H$ and $\frac{n}{2}-1 \ T$. We want the same result as in Experiment 1: maintain the current proportion of $H$ and $T$ (i.e. flip an even number of coins), but clearly this time around the upper bound on the summation is $\frac{n}{2}-1$. $$ h_{1,0}= \lim _{n \to \infty} \sum_{k=0}^{\frac{n}{2}-1} P(1;0;k) \frac{1}{n^{2k}} \bigg(1-\frac{1}{n}\bigg)^{n-2k} \approx 0.465225 $$ and so on for $h_{r,s}, 0 \leq r,s \leq n$. So here is what I'd like to know: 1) Have these numbers arisen in some other context (I never ended up publishing a paper) 2) Is there some rigorous way to prove these numbers are irrational? I've shown the $\lim$ part simply by taking large $n$, so I guess this not rigorous enough. 3) If there is something I've missed, I'd like to know too. Thanks for the suggestions.",,"['probability', 'combinatorics', 'number-theory', 'special-functions', 'irrational-numbers']"
74,Conditioning on an event with probability close to one,Conditioning on an event with probability close to one,,"Let $(\Omega,\mathcal{F},P)$ be a probability space. If $A\in\cal F$ is an event with $P(A)=1$, then $$ P_{\mid A}(B)=P(B\mid A)=\frac{P(B\cap A)}{P(A)}=P(B),\quad B\in\cal F. $$ I wonder if something can be said about how ""close"" $P_{\mid A}$ and $P$ are, when $A\in\cal F$ is an event with probability close to $1$ and also what ""close"" should mean. For example, if $P(A)=p$ and let's say that $p=0.99$, can we give a non-trivial upper bound on the maximal distance $$ \sup_{B\in\cal F}|P_{\mid A}(B)-P(B)| $$ in terms of $p$? And could other types of distances be interesting? This is just me thinking, so anything you can add will be appreciated. Thanks.","Let $(\Omega,\mathcal{F},P)$ be a probability space. If $A\in\cal F$ is an event with $P(A)=1$, then $$ P_{\mid A}(B)=P(B\mid A)=\frac{P(B\cap A)}{P(A)}=P(B),\quad B\in\cal F. $$ I wonder if something can be said about how ""close"" $P_{\mid A}$ and $P$ are, when $A\in\cal F$ is an event with probability close to $1$ and also what ""close"" should mean. For example, if $P(A)=p$ and let's say that $p=0.99$, can we give a non-trivial upper bound on the maximal distance $$ \sup_{B\in\cal F}|P_{\mid A}(B)-P(B)| $$ in terms of $p$? And could other types of distances be interesting? This is just me thinking, so anything you can add will be appreciated. Thanks.",,"['probability', 'statistics']"
75,How to calculate this probability,How to calculate this probability,,"First, if this question is too basic for math.stackexchange, I apologize. I wasn't sure where else to ask, but if you have a suggestion I'll happily take the question elsewhere. I'm totally mathematically unsophisticated, and I was asked a theoretical question I don't know how to answer. The question is: Given: I want to invite as many people as possible to my birthday party. I do not want people who have the same birthday as me to attend. Everyone I invite who does not share my birthday will attend. People who do share my birthday will be jealous and only have a 1 in 3 chance of attending the party if they are invited.  How many invitations should I send if I want there to be no more than a 50% chance of someone with the same birthday as me showing up? Now, I tried to approach this as follows: The chance that a random other person would have the same birthday as you is 1/365. The chance that someone who has the same birthday as you would accept the invitation is 1/3. Therefore the combined probability of someone having the same birthday and choosing to attend is 1/1095. Every time another person attends we are adding one more chance of the above happening, so we can think of this as: 0.5 = n/1095 therefore n = 0.5 / (1/1095) = 547.5 Well, I was told that the above is not correct, but the reason why I was wrong and the correct approach to understanding this problem was not explained to me. Could anyone explain my mistake and how to correctly calculate this probability problem? Thanks!","First, if this question is too basic for math.stackexchange, I apologize. I wasn't sure where else to ask, but if you have a suggestion I'll happily take the question elsewhere. I'm totally mathematically unsophisticated, and I was asked a theoretical question I don't know how to answer. The question is: Given: I want to invite as many people as possible to my birthday party. I do not want people who have the same birthday as me to attend. Everyone I invite who does not share my birthday will attend. People who do share my birthday will be jealous and only have a 1 in 3 chance of attending the party if they are invited.  How many invitations should I send if I want there to be no more than a 50% chance of someone with the same birthday as me showing up? Now, I tried to approach this as follows: The chance that a random other person would have the same birthday as you is 1/365. The chance that someone who has the same birthday as you would accept the invitation is 1/3. Therefore the combined probability of someone having the same birthday and choosing to attend is 1/1095. Every time another person attends we are adding one more chance of the above happening, so we can think of this as: 0.5 = n/1095 therefore n = 0.5 / (1/1095) = 547.5 Well, I was told that the above is not correct, but the reason why I was wrong and the correct approach to understanding this problem was not explained to me. Could anyone explain my mistake and how to correctly calculate this probability problem? Thanks!",,['probability']
76,Question on uniform distribution,Question on uniform distribution,,"Two people agree to meet each other on a particular day, between 5 and 6 PM, They arrive independently on a uniform time between 5 and 6 and wait for 15 mintues. What is the probability that they meet each other ?","Two people agree to meet each other on a particular day, between 5 and 6 PM, They arrive independently on a uniform time between 5 and 6 and wait for 15 mintues. What is the probability that they meet each other ?",,"['probability', 'probability-distributions']"
77,What's the expected value of a lottery ticket? [duplicate],What's the expected value of a lottery ticket? [duplicate],,"This question already has answers here : Which is the correct way to calculate the expected value of a shared lottery jackpot? (4 answers) Closed last year . Suppose there's a lottery. Each ticket sold has probability $p$ of winning, and they are all independent of each other. The size of the jackpot is $j$. If there are $n$ winners, each winner gets a payoff of $j/n$ dollars. The total number of tickets sold is $t$. What is the expected value of a lottery ticket? Also, given that I win, what is the probability that I have to share the jackpot with at least one other person? PS - I think I know the answer, but have failed to convince someone else, so I'm looking for a third-party to give an answer.","This question already has answers here : Which is the correct way to calculate the expected value of a shared lottery jackpot? (4 answers) Closed last year . Suppose there's a lottery. Each ticket sold has probability $p$ of winning, and they are all independent of each other. The size of the jackpot is $j$. If there are $n$ winners, each winner gets a payoff of $j/n$ dollars. The total number of tickets sold is $t$. What is the expected value of a lottery ticket? Also, given that I win, what is the probability that I have to share the jackpot with at least one other person? PS - I think I know the answer, but have failed to convince someone else, so I'm looking for a third-party to give an answer.",,['probability']
78,Order of integration problem in probability,Order of integration problem in probability,,"In a problem in my probability course we change the order of integration, and I am having trouble seeing why we can do it this way. $$\int_0^\infty \int_{\{x : g(x) > t\}} f_X(x)dxdt = \int_{-\infty}^\infty \int_{\{t : 0 \le t < g(x)\}} f_X(x) dt dx.$$ Can anyone enlighten me to why this works. I know how it works with simple examples, but for some reason the $g(x) > t$ is messing with my head.","In a problem in my probability course we change the order of integration, and I am having trouble seeing why we can do it this way. $$\int_0^\infty \int_{\{x : g(x) > t\}} f_X(x)dxdt = \int_{-\infty}^\infty \int_{\{t : 0 \le t < g(x)\}} f_X(x) dt dx.$$ Can anyone enlighten me to why this works. I know how it works with simple examples, but for some reason the $g(x) > t$ is messing with my head.",,"['calculus', 'probability']"
79,Coin Tossing Game Optimal Strategy Part 2,Coin Tossing Game Optimal Strategy Part 2,,"I recently asked a question, that was answered excellently: Coin Tossing Game Optimal Strategy Here I'd like to complicate the question slightly. This part stays the same: You start off with £100 and you toss a coin 100 times. Before each toss you choose a stake S which cannot be more than your current balance x (so your maximum stake for the first toss is £100). If the coin comes up heads, you win 2S and your new balance is x+2S. If it comes up tails, you lose your stake and have x−S. This time, though. Instead of maximizing the expected profit $E[P]$, we want to maxmise  $E[\log(100+P)]$. In both cases the initial balance of £100 is not included in any profit. How should we choose our bets in this case? Now, my first thought and indeed my answer was that whichever strategy maximizes the first case must also maximize the second.. but the very fact that it was asked makes me doubt myself? Any thoughts greatly appreciated! Boris","I recently asked a question, that was answered excellently: Coin Tossing Game Optimal Strategy Here I'd like to complicate the question slightly. This part stays the same: You start off with £100 and you toss a coin 100 times. Before each toss you choose a stake S which cannot be more than your current balance x (so your maximum stake for the first toss is £100). If the coin comes up heads, you win 2S and your new balance is x+2S. If it comes up tails, you lose your stake and have x−S. This time, though. Instead of maximizing the expected profit $E[P]$, we want to maxmise  $E[\log(100+P)]$. In both cases the initial balance of £100 is not included in any profit. How should we choose our bets in this case? Now, my first thought and indeed my answer was that whichever strategy maximizes the first case must also maximize the second.. but the very fact that it was asked makes me doubt myself? Any thoughts greatly appreciated! Boris",,['probability']
80,Double Expectation of a Conditional Expectation,Double Expectation of a Conditional Expectation,,"If there are two sub-sigma algebras $\mathcal{G}$ and $\mathcal{H}$ of $\mathcal{F}$, neither a subset of the other from a probability space $(Y,\mathcal{F},P)$ and a random variable $X$ which is not measurable with respect to either $\mathcal{G}$ or $\mathcal{H}$, can I apply double expectation on the conditional expectation of $X|\mathcal{G}$ like this: $$ E[E[X|\mathcal{G}]|\mathcal{H}] = E[X|\mathcal{G}] $$ Thanks.","If there are two sub-sigma algebras $\mathcal{G}$ and $\mathcal{H}$ of $\mathcal{F}$, neither a subset of the other from a probability space $(Y,\mathcal{F},P)$ and a random variable $X$ which is not measurable with respect to either $\mathcal{G}$ or $\mathcal{H}$, can I apply double expectation on the conditional expectation of $X|\mathcal{G}$ like this: $$ E[E[X|\mathcal{G}]|\mathcal{H}] = E[X|\mathcal{G}] $$ Thanks.",,"['probability', 'measure-theory', 'probability-theory']"
81,Probability that one random number is larger than other random numbers,Probability that one random number is larger than other random numbers,,"Suppose you have several sets of numbers, each with a normal distribution.  For each set, you know the standard deviation and mean.  Now, if you independently choose one random number from each set, what is the probability that the number chosen from a given set will be greater than each of the numbers chosen from the other sets?","Suppose you have several sets of numbers, each with a normal distribution.  For each set, you know the standard deviation and mean.  Now, if you independently choose one random number from each set, what is the probability that the number chosen from a given set will be greater than each of the numbers chosen from the other sets?",,['probability']
82,Gerrymandering urns (redux),Gerrymandering urns (redux),,"This is a rehash of this question (and probably the intent of this , and several other similar questions), but I'd like: a more detailed answer that builds from the simplest cases to potentially higher order applications and more references to explanations, if possible. a proof of the optimality of the so-called gerrymandering solution . So here is a complete statement of the problem: Suppose that you are given 50 each of red and blue balls, and two   urns. You place the red and blue balls in the urns (so that each is   nonempty, and all the balls are allocated to some urn). Then you pick a jar at   random and pick a ball at random. The objective is to distribute the   red and blue balls in each of the urns so that the probability of   picking a red ball is maximized. The so-called gerrymandering solution is given after the break below, and I am wondering if there is a systematic way of arriving at this solution, other than guesswork. Attempt 1 My first thought was to use calculus on this problem, so that if I denote the jars A and B, and denote the tuple $(x, y)$ as the number of red and blue balls in jar A. The the solution $(x^*, y^*)$ is the solution to the first-order conditions. (This is probably a red herring, since only nonnegative integer solutions are valid.) $$ \begin{alignat}{2} &&p(x, y) &= \frac{1}{2}\left(\dfrac{x}{x+y}+ \dfrac{50-x}{100-x-y}\right) \\[1em] &&\left. \dfrac{\partial p(x, y)}{\partial x}\right|_{(x,y)=(x^*, y^*)} &= 0 \\[1em] &\implies\quad&\dfrac{2x^*+y^*}{(x^*+y^*)^2}-\dfrac{150-2x^*-y^*}{(100-x^*-y^*)^2} &=0 \\[1em] &&\left. \dfrac{\partial p(x, y)}{\partial y}\right|_{(x,y)=(x^*, y^*)} &= 0 \\[1em] &\implies\quad&  \dfrac{-x^*}{(x^*+y^*)^2} +\dfrac{50-x^*}{(100-x^*-y^*)^2} &= 0 \end{alignat} $$ This involves finding the solution of cubic equations (which I am sure can be done, with the help of CAS, but it is not obvious that this yields the gerrymandering solution (does it?)). Is this the right way to think about the problem? What is? Attempt 2 Note however that the objective function is closed-form, so can easily be graphed, and then the solution becomes clear. The gerrymandering solution You place one red ball and no blue balls in one urn and all the other balls in the other urn. This leads to the probability of picking a red ball $>\tfrac{1}{2}$.","This is a rehash of this question (and probably the intent of this , and several other similar questions), but I'd like: a more detailed answer that builds from the simplest cases to potentially higher order applications and more references to explanations, if possible. a proof of the optimality of the so-called gerrymandering solution . So here is a complete statement of the problem: Suppose that you are given 50 each of red and blue balls, and two   urns. You place the red and blue balls in the urns (so that each is   nonempty, and all the balls are allocated to some urn). Then you pick a jar at   random and pick a ball at random. The objective is to distribute the   red and blue balls in each of the urns so that the probability of   picking a red ball is maximized. The so-called gerrymandering solution is given after the break below, and I am wondering if there is a systematic way of arriving at this solution, other than guesswork. Attempt 1 My first thought was to use calculus on this problem, so that if I denote the jars A and B, and denote the tuple $(x, y)$ as the number of red and blue balls in jar A. The the solution $(x^*, y^*)$ is the solution to the first-order conditions. (This is probably a red herring, since only nonnegative integer solutions are valid.) $$ \begin{alignat}{2} &&p(x, y) &= \frac{1}{2}\left(\dfrac{x}{x+y}+ \dfrac{50-x}{100-x-y}\right) \\[1em] &&\left. \dfrac{\partial p(x, y)}{\partial x}\right|_{(x,y)=(x^*, y^*)} &= 0 \\[1em] &\implies\quad&\dfrac{2x^*+y^*}{(x^*+y^*)^2}-\dfrac{150-2x^*-y^*}{(100-x^*-y^*)^2} &=0 \\[1em] &&\left. \dfrac{\partial p(x, y)}{\partial y}\right|_{(x,y)=(x^*, y^*)} &= 0 \\[1em] &\implies\quad&  \dfrac{-x^*}{(x^*+y^*)^2} +\dfrac{50-x^*}{(100-x^*-y^*)^2} &= 0 \end{alignat} $$ This involves finding the solution of cubic equations (which I am sure can be done, with the help of CAS, but it is not obvious that this yields the gerrymandering solution (does it?)). Is this the right way to think about the problem? What is? Attempt 2 Note however that the objective function is closed-form, so can easily be graphed, and then the solution becomes clear. The gerrymandering solution You place one red ball and no blue balls in one urn and all the other balls in the other urn. This leads to the probability of picking a red ball $>\tfrac{1}{2}$.",,"['probability', 'discrete-mathematics', 'discrete-optimization']"
83,P[random x is composite | $2^{x-1}$ mod $x = 1$ ]?,P[random x is composite |  mod  ]?,2^{x-1} x = 1,Select a uniformly random integer $n$ between $2^{1024}$ and $2^{1025}$ (Q) What is the probability that n is composite given that $2^{n-1}$ mod $n = 1$ ? How did you calculate this? More info : One way to calculate this would be if you had the following two variables: $$P_Q(n) = 1 - { P_{prime}(n) \over P_{cong}(n) }$$ Where: $P_{prime}(n)$ is the probability n is prime $P_{cong}(n)$ is the probability that $2^{n-1}$ mod $n = 1$ So answering the following two questions would be sufficient to answer the main one: What is $P_{prime}(n)$ equal to? What is $P_{cong}(n)$ equal to ? (This holds because the probability that n is prime if the congruence is false is 0.) Based on the PouletNumber forumale given below: exp((ln(2^1025))^(5/14))-exp((ln(2^1024))^(5/14))  = 123 and (2^1025)*exp(-ln(2^1025)*ln(ln(ln(2^1025))) / (2*ln(ln(2^1025)))) - (2^1024)*exp(-ln(2^1024)*ln(ln(ln(2^1024))) / (2*ln(ln(2^1024))))  = 9.82e263 So its between 123 < x < 9.82e263 ?? And so $P_Q$ is: 3.29e-306 < P_Q < 2.63e-44,Select a uniformly random integer $n$ between $2^{1024}$ and $2^{1025}$ (Q) What is the probability that n is composite given that $2^{n-1}$ mod $n = 1$ ? How did you calculate this? More info : One way to calculate this would be if you had the following two variables: $$P_Q(n) = 1 - { P_{prime}(n) \over P_{cong}(n) }$$ Where: $P_{prime}(n)$ is the probability n is prime $P_{cong}(n)$ is the probability that $2^{n-1}$ mod $n = 1$ So answering the following two questions would be sufficient to answer the main one: What is $P_{prime}(n)$ equal to? What is $P_{cong}(n)$ equal to ? (This holds because the probability that n is prime if the congruence is false is 0.) Based on the PouletNumber forumale given below: exp((ln(2^1025))^(5/14))-exp((ln(2^1024))^(5/14))  = 123 and (2^1025)*exp(-ln(2^1025)*ln(ln(ln(2^1025))) / (2*ln(ln(2^1025)))) - (2^1024)*exp(-ln(2^1024)*ln(ln(ln(2^1024))) / (2*ln(ln(2^1024))))  = 9.82e263 So its between 123 < x < 9.82e263 ?? And so $P_Q$ is: 3.29e-306 < P_Q < 2.63e-44,,"['probability', 'number-theory', 'prime-numbers', 'primality-test']"
84,Maximum-likelihood estimation for continuous random variable with unknown parameter,Maximum-likelihood estimation for continuous random variable with unknown parameter,,"Let $X$ be a random variable with the unknown parameter $\lambda$ and the following pdf   $$f(t)=2\lambda t\cdot\mathrm e^{-\lambda t^2}\cdot\textbf{1}_{[0,\infty)}(t)$$   where $\textbf{1}_A(x)$ is an indicator function with   $$\textbf{1}_A(x)=\begin{cases}1,&\text{if }x\in A,\\0,&\text{else.}\end{cases}$$   Let $\vec x=(x_1,\ldots,x_n)$ be a sample of $X$. Determine the maximum-likelihood estimator $\widehat{\lambda}$ such that the following is true for the likelihood-function $\mathcal L(\vec x;\lambda)$:   $$\forall \lambda\;:\;\mathcal L(\vec x;\lambda)\leq \mathcal L(\vec x;\widehat\lambda)$$ For the sake of simplicity my first thoughts were to get the log-likelihood this way: $$\mathcal L(\vec x;\lambda)=\prod\limits_{i=1}^nf(x_i)\implies \ln(\mathcal L(\vec x;\lambda))=\sum\limits_{i=1}^n\ln(f(x_i))$$ This is the point where I'm stuck: i don't know how to compute the derivative to maximize the function $$\frac{\mathrm d \ln(\mathcal L(\vec x;\lambda))}{\mathrm d\lambda}\overset{!}{=}0.$$ Any hints on how to derive the sum would be appreciated.","Let $X$ be a random variable with the unknown parameter $\lambda$ and the following pdf   $$f(t)=2\lambda t\cdot\mathrm e^{-\lambda t^2}\cdot\textbf{1}_{[0,\infty)}(t)$$   where $\textbf{1}_A(x)$ is an indicator function with   $$\textbf{1}_A(x)=\begin{cases}1,&\text{if }x\in A,\\0,&\text{else.}\end{cases}$$   Let $\vec x=(x_1,\ldots,x_n)$ be a sample of $X$. Determine the maximum-likelihood estimator $\widehat{\lambda}$ such that the following is true for the likelihood-function $\mathcal L(\vec x;\lambda)$:   $$\forall \lambda\;:\;\mathcal L(\vec x;\lambda)\leq \mathcal L(\vec x;\widehat\lambda)$$ For the sake of simplicity my first thoughts were to get the log-likelihood this way: $$\mathcal L(\vec x;\lambda)=\prod\limits_{i=1}^nf(x_i)\implies \ln(\mathcal L(\vec x;\lambda))=\sum\limits_{i=1}^n\ln(f(x_i))$$ This is the point where I'm stuck: i don't know how to compute the derivative to maximize the function $$\frac{\mathrm d \ln(\mathcal L(\vec x;\lambda))}{\mathrm d\lambda}\overset{!}{=}0.$$ Any hints on how to derive the sum would be appreciated.",,"['probability', 'statistics', 'probability-theory']"
85,Bidding Item Problem,Bidding Item Problem,,"You are bidding on an item that has an unknown value uniformly   distributed between 0 and 1. You do not know the true value of the   item, but you know that if you end up winning the bid for the item,   the item will increase its value to 2x its original value. Your bid   can only go through if its at least as large as the original value of   the item. How do you bid to maximize expected payoff. Here's what I have: Let V be the true value of the item Let B be the bid you make Let f(V) represent the profit you make given V as the true original value $$f(V) =       \begin{cases}        2V - B & B \geq V\\        0 & B< V      \end{cases}$$ Where I get confused is when I need to start applying integrals to calculate how to maximize the expected value. Thanks for any help. EDIT: Here is the solution from the book I'm working off of. I do not understand how they are doing the calculus. Let B be your bid. Let S be the true value of the item. The density function of S equals unity for $0 \leq S \leq 1$, and 0 otherwise. Your payoff P is $$P(S) = \begin{cases}   2S - B & B \geq S\\   0 & \text{otherwise} \end{cases}$$ The maximum post bid item value is 2, so you should be no more than 2. You want to maximize $E[P(S)]$ with respect to choice of B in the interval [0, 2]. Your expected payoff is: $$\begin{aligned} E[P(S)] &=  \int_{S=0}^{S=1} P(S)*1*\,\mathrm{d}S \\  &=  \int_{S=0}^{S=\min(B,1)} (2S-B)\,\mathrm{d} \\  &= \left.(S^2-BS)\right|_{S=0}^{S=\min(B,1)} \\  &=       \begin{cases}        0 &  B\leq1\\        1 - B &  B>1      \end{cases} \end{aligned}$$ so you should bid less than or equal to 1 and expect to break even.","You are bidding on an item that has an unknown value uniformly   distributed between 0 and 1. You do not know the true value of the   item, but you know that if you end up winning the bid for the item,   the item will increase its value to 2x its original value. Your bid   can only go through if its at least as large as the original value of   the item. How do you bid to maximize expected payoff. Here's what I have: Let V be the true value of the item Let B be the bid you make Let f(V) represent the profit you make given V as the true original value $$f(V) =       \begin{cases}        2V - B & B \geq V\\        0 & B< V      \end{cases}$$ Where I get confused is when I need to start applying integrals to calculate how to maximize the expected value. Thanks for any help. EDIT: Here is the solution from the book I'm working off of. I do not understand how they are doing the calculus. Let B be your bid. Let S be the true value of the item. The density function of S equals unity for $0 \leq S \leq 1$, and 0 otherwise. Your payoff P is $$P(S) = \begin{cases}   2S - B & B \geq S\\   0 & \text{otherwise} \end{cases}$$ The maximum post bid item value is 2, so you should be no more than 2. You want to maximize $E[P(S)]$ with respect to choice of B in the interval [0, 2]. Your expected payoff is: $$\begin{aligned} E[P(S)] &=  \int_{S=0}^{S=1} P(S)*1*\,\mathrm{d}S \\  &=  \int_{S=0}^{S=\min(B,1)} (2S-B)\,\mathrm{d} \\  &= \left.(S^2-BS)\right|_{S=0}^{S=\min(B,1)} \\  &=       \begin{cases}        0 &  B\leq1\\        1 - B &  B>1      \end{cases} \end{aligned}$$ so you should bid less than or equal to 1 and expect to break even.",,"['probability', 'puzzle']"
86,Probability of Random number selection,Probability of Random number selection,,"Suppose you are asked to pick any random real number. Then you have a choice to pick any number between -∞ and +∞, i.e, infinite numbers. The probability that you select a particular number n = 1/∞ = 0. Which means that you did not select any number. How is it possible?","Suppose you are asked to pick any random real number. Then you have a choice to pick any number between -∞ and +∞, i.e, infinite numbers. The probability that you select a particular number n = 1/∞ = 0. Which means that you did not select any number. How is it possible?",,"['probability', 'experimental-mathematics']"
87,Expected number of collisions,Expected number of collisions,,"$n$ items are distributed into $n$ boxes such that each item is   independently put with probability $p_j$ to be put in box $j$, for   $j=1,2,\ldots,n$, where $\sum_{j=1}^np_j=1$. A collision occurs whenever an item is put into a   non-empty box. Find the expected number of collisions. What's wrong with the following reasoning? Let $C_i$ be the number of collisions in box $i$. Then $C_i+1$ is the number of items in box $i$, so $E[C_i+1]=np_j$ and $E[C_i]=np_j-1$. Therefore the expected number of collisions is $\sum_{j=1}^n(np_j-1)=0$. Obviously the number cannot be zero, because the number is sometimes positive but never negative.","$n$ items are distributed into $n$ boxes such that each item is   independently put with probability $p_j$ to be put in box $j$, for   $j=1,2,\ldots,n$, where $\sum_{j=1}^np_j=1$. A collision occurs whenever an item is put into a   non-empty box. Find the expected number of collisions. What's wrong with the following reasoning? Let $C_i$ be the number of collisions in box $i$. Then $C_i+1$ is the number of items in box $i$, so $E[C_i+1]=np_j$ and $E[C_i]=np_j-1$. Therefore the expected number of collisions is $\sum_{j=1}^n(np_j-1)=0$. Obviously the number cannot be zero, because the number is sometimes positive but never negative.",,['probability']
88,Counting process which is not a Poisson process,Counting process which is not a Poisson process,,"Please construct a counting process N, whose r.v. N(t) are distributed as Poisson(λt) but the process N itself is not a Poisson process. This is an assignment in our Stochastic Process class. So I suppose this counting process N should meet all but one of a Poisson's process conditions. 1) N(0)=0 2) independent increments 3) At any given time t N(t) ~ Poiss( λt). So making the increments dependent should probably be the way to go. However, I've no idea how that could be done.","Please construct a counting process N, whose r.v. N(t) are distributed as Poisson(λt) but the process N itself is not a Poisson process. This is an assignment in our Stochastic Process class. So I suppose this counting process N should meet all but one of a Poisson's process conditions. 1) N(0)=0 2) independent increments 3) At any given time t N(t) ~ Poiss( λt). So making the increments dependent should probably be the way to go. However, I've no idea how that could be done.",,"['probability', 'combinatorics', 'stochastic-processes']"
89,An elementary version of Laplace's Method of Succession,An elementary version of Laplace's Method of Succession,,"I'm currently taking a probability course, and in lecture, my professor went over an example which he called Laplace's method of succession. Basically, there are $n+1$ cards, $k$ of which are successes (the $k$ is uniformly distributed). A $k$ is chosen, and you see $n$ of the cards (after shuffling). The problem is to determine the probability the next trial turns up a success. Here's an account of how he explained the problem: There are two possibilities, either there are $k$ successes in the $n+1$ trials or $k+1$ successes. The probability of each $k$ is uniformly distributed, so we will give $P(k \text{ successes})=P(k+1 \text{ successes})=\frac{1}{2}$. So, we can write the desired probability as $P(1\ |\ k \text{ successes in }n\text{ trials})$ (where $1$ is a success on the next draw and $0$ is failure). We use the definition of conditional probability to get that \begin{equation} P(1 \ | k \text{ successes in }n\text{ trials})=\frac{P(1 \text{ and }k\text{ successes in }n\text{ trials})}{P(k\text{ successes in }n\text{ trials})} \end{equation} Again, using the definition of conditional probabilities and Bayes' rule, that is equal to \begin{equation} \frac{P(1)P(k\text{ successes in }n\text{ trials}\,|\, 1)}{P(1)P(k\text{ successes in }n\text{ trials}\ |\  1)+P(0)P(k\text{ successes in }n\text{ trials}\ | \ 0)} \end{equation} Now, he said that this expression is: \begin{equation} \frac{\frac{1}{2}\frac{k+1}{n+1}}{\frac{1}{2}\frac{k+1}{n+1}+\frac{1}{2}\frac{n+1-k}{n+1}}=\frac{k+1}{n+2} \end{equation} My question is how did he get $\frac{k+1}{n+1}$ and $\frac{n+1-k}{n+1}$ as the answers to the above conditional probabilities? They seem to only denote the chance of drawing success or failure from $n+1$ cards. Furthermore, today in class, he proved that the function which takes the number of black balls (given one black and one white to start) drawn from Polya's urn (sampling with double replacement) is evenly distributed, and said it had a connection to this problem, but did not elaborate. How is that?","I'm currently taking a probability course, and in lecture, my professor went over an example which he called Laplace's method of succession. Basically, there are $n+1$ cards, $k$ of which are successes (the $k$ is uniformly distributed). A $k$ is chosen, and you see $n$ of the cards (after shuffling). The problem is to determine the probability the next trial turns up a success. Here's an account of how he explained the problem: There are two possibilities, either there are $k$ successes in the $n+1$ trials or $k+1$ successes. The probability of each $k$ is uniformly distributed, so we will give $P(k \text{ successes})=P(k+1 \text{ successes})=\frac{1}{2}$. So, we can write the desired probability as $P(1\ |\ k \text{ successes in }n\text{ trials})$ (where $1$ is a success on the next draw and $0$ is failure). We use the definition of conditional probability to get that \begin{equation} P(1 \ | k \text{ successes in }n\text{ trials})=\frac{P(1 \text{ and }k\text{ successes in }n\text{ trials})}{P(k\text{ successes in }n\text{ trials})} \end{equation} Again, using the definition of conditional probabilities and Bayes' rule, that is equal to \begin{equation} \frac{P(1)P(k\text{ successes in }n\text{ trials}\,|\, 1)}{P(1)P(k\text{ successes in }n\text{ trials}\ |\  1)+P(0)P(k\text{ successes in }n\text{ trials}\ | \ 0)} \end{equation} Now, he said that this expression is: \begin{equation} \frac{\frac{1}{2}\frac{k+1}{n+1}}{\frac{1}{2}\frac{k+1}{n+1}+\frac{1}{2}\frac{n+1-k}{n+1}}=\frac{k+1}{n+2} \end{equation} My question is how did he get $\frac{k+1}{n+1}$ and $\frac{n+1-k}{n+1}$ as the answers to the above conditional probabilities? They seem to only denote the chance of drawing success or failure from $n+1$ cards. Furthermore, today in class, he proved that the function which takes the number of black balls (given one black and one white to start) drawn from Polya's urn (sampling with double replacement) is evenly distributed, and said it had a connection to this problem, but did not elaborate. How is that?",,['probability']
90,"Dual of $C[0,1]$, Hilbert space and Riesz representation.","Dual of , Hilbert space and Riesz representation.","C[0,1]","Let $E=C[0,1]$, space of all real-valued continuous functions on $[0,1]$, $\mathcal{E}$  be its Borel $\sigma$-algebra and $\mu$ a Gaussian measure on $E$. I need help proving the following claim: $E^*$ is the space of signed measures on $[0, 1]$ and the duality is given by: $\langle\nu,f\rangle=\nu(f)=\int_0^1f(t)\;\nu(dt),$ where of $E^*$ is a space of all continuous linear functions on $E$. My thoughts: I know that it is an application of Riesz representation theorem. Firstly I need an inner-product on $C[0,1]$, which may as well be $\int_0^1f(t)g(t)\;dt$. Then any functional on $E$ can identified with an integral with respect to Lebesgue measure. However, the author insists on $\nu$. Thank you!","Let $E=C[0,1]$, space of all real-valued continuous functions on $[0,1]$, $\mathcal{E}$  be its Borel $\sigma$-algebra and $\mu$ a Gaussian measure on $E$. I need help proving the following claim: $E^*$ is the space of signed measures on $[0, 1]$ and the duality is given by: $\langle\nu,f\rangle=\nu(f)=\int_0^1f(t)\;\nu(dt),$ where of $E^*$ is a space of all continuous linear functions on $E$. My thoughts: I know that it is an application of Riesz representation theorem. Firstly I need an inner-product on $C[0,1]$, which may as well be $\int_0^1f(t)g(t)\;dt$. Then any functional on $E$ can identified with an integral with respect to Lebesgue measure. However, the author insists on $\nu$. Thank you!",,"['probability', 'functional-analysis', 'stochastic-processes', 'hilbert-spaces', 'duality-theorems']"
91,Absolute value of Brownian motion,Absolute value of Brownian motion,,"I need to show that $$R_t=\frac{1}{|B_t|}$$ is bounded in $\mathcal{L^2}$ for $(t \ge 1)$, where $B_t$ is a 3-dimensional standard Brownian motion. I am trying to find a bound for $\mathbb{E}[\int_{t=1}^{\infty}R^2_t]$. Asymptotically $B_t^i$ is between $\sqrt{t}$ and $t$. I also know that $|B_t| \to \infty$, but the rate is not clear. Hints would be helpful.","I need to show that $$R_t=\frac{1}{|B_t|}$$ is bounded in $\mathcal{L^2}$ for $(t \ge 1)$, where $B_t$ is a 3-dimensional standard Brownian motion. I am trying to find a bound for $\mathbb{E}[\int_{t=1}^{\infty}R^2_t]$. Asymptotically $B_t^i$ is between $\sqrt{t}$ and $t$. I also know that $|B_t| \to \infty$, but the rate is not clear. Hints would be helpful.",,"['probability', 'brownian-motion']"
92,Probability of defeating enemy (info on distributions added),Probability of defeating enemy (info on distributions added),,"I have 27 hit points and my opponent has 50, and the winner is the player that reduces the other player's hit points to 0 first. My expected damage inflicted per round is 5. My expected damage taken per round is 7/3. I have the first attack. What are my chances of winning? edit : As pointed out, the question is unanswerable without further info on distributions, so here it is: A round consists of multiple attacks. If I hit, I can attack again. My damage per hit is 5/6 1, and I have a 5/6 probability of hitting. I figured this makes a geometric series with $a = 5/6, r = 5/6$, so using $a / (1 - r)$ we get an expected damage of 5. Edit: Typo above. Damage is 1 point if I hit, so expected damage is 5/6. (Geometric series is still correct.) When defending, similar rules apply. My damage taken is 7/6, and probability of being hit is 1/2. So a geometric series gives expected damage taken as 7/3. Edit to clarify: Actually I have a 1/6 chance of taking 3 damage, and 2/6 chance of taking 2 damage, which aggregates to 7/6. So as a supplementary question, clearly this is a discrete   distribution, but can we approximate to something linear and solve   analytically? Or am I best off just doing a million trials by   computer?","I have 27 hit points and my opponent has 50, and the winner is the player that reduces the other player's hit points to 0 first. My expected damage inflicted per round is 5. My expected damage taken per round is 7/3. I have the first attack. What are my chances of winning? edit : As pointed out, the question is unanswerable without further info on distributions, so here it is: A round consists of multiple attacks. If I hit, I can attack again. My damage per hit is 5/6 1, and I have a 5/6 probability of hitting. I figured this makes a geometric series with $a = 5/6, r = 5/6$, so using $a / (1 - r)$ we get an expected damage of 5. Edit: Typo above. Damage is 1 point if I hit, so expected damage is 5/6. (Geometric series is still correct.) When defending, similar rules apply. My damage taken is 7/6, and probability of being hit is 1/2. So a geometric series gives expected damage taken as 7/3. Edit to clarify: Actually I have a 1/6 chance of taking 3 damage, and 2/6 chance of taking 2 damage, which aggregates to 7/6. So as a supplementary question, clearly this is a discrete   distribution, but can we approximate to something linear and solve   analytically? Or am I best off just doing a million trials by   computer?",,['probability']
93,Probability of getting $4$ smallest Balls in $2$ Boxes,Probability of getting  smallest Balls in  Boxes,4 2,"I have $2n$ balls labeled $1, 2, \ldots, 2n$, and two boxes, Box $1$ and Box $2$. I take $n$ of the balls at random without replacement and place them in the Box $1$. I take the remaining $n$ balls and place them in the Box $2$. I take the two smallest-numbered balls from each box. What is the probability that I end up with balls $1, 2, 3$ and $4$? I'm trying this for small values of $n$ but am struggling to see the pattern. It is the probability $$ 1-P(\text{any 3 of balls 1,2,3,4 in the same box})-P(\text{all balls 1,2,3,4 in same box}) .$$ I'm having trouble finding the formula form here. Thanks! Ok this part is more complicated. I have 3n balls and 3 boxes. I take n of the balls at random w/out replacement and place them in Box 1. I take n of the remaining 2n balls at random w/out replacement and put them in Box 2. I take the remaining n balls and put them in Box 3. I then take the smallest-numbered ball from each box and then the smallest-numbered ball among the balls remaining. What is the probability that I end up with balls 1,2,3,4? So this time, it is okay to have two of Balls 1,2,3,4 in the one of boxes because he will take the smallest and come back for the next smallest.  So I'm thinking that it is $\binom{4}{3}$ * ($\binom{3}{1}$$\binom{3n-3}{n-1}$)/$\binom{3n}{n}$ *($\binom{2}{1}$$\binom{2n-2}{n-1}$)/$\binom{2n}{n}$ I'm not sure if I need that first factor of $\binom{4}{3}$ though. Thanks!","I have $2n$ balls labeled $1, 2, \ldots, 2n$, and two boxes, Box $1$ and Box $2$. I take $n$ of the balls at random without replacement and place them in the Box $1$. I take the remaining $n$ balls and place them in the Box $2$. I take the two smallest-numbered balls from each box. What is the probability that I end up with balls $1, 2, 3$ and $4$? I'm trying this for small values of $n$ but am struggling to see the pattern. It is the probability $$ 1-P(\text{any 3 of balls 1,2,3,4 in the same box})-P(\text{all balls 1,2,3,4 in same box}) .$$ I'm having trouble finding the formula form here. Thanks! Ok this part is more complicated. I have 3n balls and 3 boxes. I take n of the balls at random w/out replacement and place them in Box 1. I take n of the remaining 2n balls at random w/out replacement and put them in Box 2. I take the remaining n balls and put them in Box 3. I then take the smallest-numbered ball from each box and then the smallest-numbered ball among the balls remaining. What is the probability that I end up with balls 1,2,3,4? So this time, it is okay to have two of Balls 1,2,3,4 in the one of boxes because he will take the smallest and come back for the next smallest.  So I'm thinking that it is $\binom{4}{3}$ * ($\binom{3}{1}$$\binom{3n-3}{n-1}$)/$\binom{3n}{n}$ *($\binom{2}{1}$$\binom{2n-2}{n-1}$)/$\binom{2n}{n}$ I'm not sure if I need that first factor of $\binom{4}{3}$ though. Thanks!",,['probability']
94,a question about an equivalent statement of almost surely convergence,a question about an equivalent statement of almost surely convergence,,"I have seen it from a book that almost surely convergence is equivalent to the following statement: for any $\epsilon>0$, there is an $n>0$, such that $P({|X_{j}-X|\geq\epsilon})=0$, for all $j\geq n.$ I doubt if it is right.","I have seen it from a book that almost surely convergence is equivalent to the following statement: for any $\epsilon>0$, there is an $n>0$, such that $P({|X_{j}-X|\geq\epsilon})=0$, for all $j\geq n.$ I doubt if it is right.",,"['probability', 'convergence-divergence']"
95,Confusions regarding the concept of a stopping time for a martingale,Confusions regarding the concept of a stopping time for a martingale,,"I am studying martingales and I have a few conceptual questions regarding why we need stopping times. My book ( Probability and Computing by Mitzenmacher and Upfal) defines a martingale as follows: A sequence of random variables $Z_0,Z_1,\ldots$  is a martingale with respect to the sequence $X_0,X_1,\ldots$ if $\forall n\geq 0$, the following condition holds: $Z_n$ is a function of $X_0,X_1,\ldots, X_n$ $\mathbb{E}(|Z_n|) < \infty$ $\mathbb{E}(Z_{n+1}\mid X_0,\ldots, X_n) = Z_n$ Here is what I don't get: It seems to me, you could just pick any random variable and symbolically assert the following: $\forall n \geq 0, \mathbb{E}(Z_n)=\mathbb{E}(Z_0) $ using the tower of expectations property recursively, so how do I symbolically verify the need to worry about the stopping time and develop the martingale stopping theorem? PS: Is the following guess as to why we need the stopping theorem correct? We need it because the original theorem might be defined for a countably infinite number of random variables and stopping it at a random time might break the conditions under which it holds?","I am studying martingales and I have a few conceptual questions regarding why we need stopping times. My book ( Probability and Computing by Mitzenmacher and Upfal) defines a martingale as follows: A sequence of random variables $Z_0,Z_1,\ldots$  is a martingale with respect to the sequence $X_0,X_1,\ldots$ if $\forall n\geq 0$, the following condition holds: $Z_n$ is a function of $X_0,X_1,\ldots, X_n$ $\mathbb{E}(|Z_n|) < \infty$ $\mathbb{E}(Z_{n+1}\mid X_0,\ldots, X_n) = Z_n$ Here is what I don't get: It seems to me, you could just pick any random variable and symbolically assert the following: $\forall n \geq 0, \mathbb{E}(Z_n)=\mathbb{E}(Z_0) $ using the tower of expectations property recursively, so how do I symbolically verify the need to worry about the stopping time and develop the martingale stopping theorem? PS: Is the following guess as to why we need the stopping theorem correct? We need it because the original theorem might be defined for a countably infinite number of random variables and stopping it at a random time might break the conditions under which it holds?",,"['probability', 'probability-theory', 'stochastic-processes', 'martingales']"
96,what is the expected maximum number of balls in the same box,what is the expected maximum number of balls in the same box,,"If I have $m$ distinct boxes, and $n$ distinct balls. I put all of these balls into the boxes with one box possibly containing more than one balls. What is the expected maximum number of balls in one box? Appreciate your thoughts on solving this problem.","If I have $m$ distinct boxes, and $n$ distinct balls. I put all of these balls into the boxes with one box possibly containing more than one balls. What is the expected maximum number of balls in one box? Appreciate your thoughts on solving this problem.",,['probability']
97,Mean distance between a fixed point and a gaussian distributed random variable,Mean distance between a fixed point and a gaussian distributed random variable,,"In 2D or 3D I have a fix point y and Gaussian distribution of a random point x. I am now interested in the mean euclidean distance between x and y: $E_x [ d(x,y) ] = \int _{-\infty }^{\infty } d(x,y) N(x; \mu, \Lambda )dx$ Many thanks in advance","In 2D or 3D I have a fix point y and Gaussian distribution of a random point x. I am now interested in the mean euclidean distance between x and y: $E_x [ d(x,y) ] = \int _{-\infty }^{\infty } d(x,y) N(x; \mu, \Lambda )dx$ Many thanks in advance",,['probability']
98,Hitting times of reversible markov chain with known steady state probabilites,Hitting times of reversible markov chain with known steady state probabilites,,"Consider a reversible markov chain Xn whose steady state distribution is known, can we find the expected hitting time to a subset A of the states starting from some state i ? Additionally you can assume the the chain has no self transitions.","Consider a reversible markov chain Xn whose steady state distribution is known, can we find the expected hitting time to a subset A of the states starting from some state i ? Additionally you can assume the the chain has no self transitions.",,['probability']
99,What is the standard method to estimate probabilities of events based on observations?,What is the standard method to estimate probabilities of events based on observations?,,"I start from a simple example. I through a (possibly unfair) coin 20 times. I got ""eagle"" and ""tail"" 15 and 5 times, respectively. Now I need to estimate probabilities for eagle and tail. For eagle I get 15/20 = 0.75 and for the tail I get 0.25. However, I know that the probability that I got are not accurate. It is still possible that I have a fair coin (with probability for eagle equal to 0.5) and I get more eagles in my experiment just by chance. Now I want to estimate probabilities of probabilities. In other words I want to know how likely it is that probability for eagle is 0.5 (or 0.3, or 0.9). I can solve this problem, but I would like to know if there is a name for this problem. I an also interested in the generalization of the problem for the case of more than two events (not just ""eagle"" and ""tail"").","I start from a simple example. I through a (possibly unfair) coin 20 times. I got ""eagle"" and ""tail"" 15 and 5 times, respectively. Now I need to estimate probabilities for eagle and tail. For eagle I get 15/20 = 0.75 and for the tail I get 0.25. However, I know that the probability that I got are not accurate. It is still possible that I have a fair coin (with probability for eagle equal to 0.5) and I get more eagles in my experiment just by chance. Now I want to estimate probabilities of probabilities. In other words I want to know how likely it is that probability for eagle is 0.5 (or 0.3, or 0.9). I can solve this problem, but I would like to know if there is a name for this problem. I an also interested in the generalization of the problem for the case of more than two events (not just ""eagle"" and ""tail"").",,"['probability', 'statistics']"
