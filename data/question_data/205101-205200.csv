,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,MOOCs for college-level discrete math?,MOOCs for college-level discrete math?,,"Specifically I am looking for short lectures (and quizzes) on specific topics. (like Khan Academy offers) Topics I am learning about include; Intro logic-theory + set-theory Notation, negation, simplification, result of set operations) Relations, functions Intro proofs By contradiction, induction, well-ordering Intro graph theory Graph coloring (chromatic numbers), Eulerian paths, Eulerian circuit, Hamiltonian paths, Minimal spanning trees (Prim's and Kruskal's algorithms), shortest path computation Intro combinatorics Permutations, combinations, inclusion-exclusion, binomial theorem","Specifically I am looking for short lectures (and quizzes) on specific topics. (like Khan Academy offers) Topics I am learning about include; Intro logic-theory + set-theory Notation, negation, simplification, result of set operations) Relations, functions Intro proofs By contradiction, induction, well-ordering Intro graph theory Graph coloring (chromatic numbers), Eulerian paths, Eulerian circuit, Hamiltonian paths, Minimal spanning trees (Prim's and Kruskal's algorithms), shortest path computation Intro combinatorics Permutations, combinations, inclusion-exclusion, binomial theorem",,"['discrete-mathematics', 'education', 'self-learning', 'learning', 'online-resources']"
1,"Inverse, Converse and contraposition of statement?","Inverse, Converse and contraposition of statement?",,"I am trying to break the statements: ""Being rich is necessary for Alex to be happy""(1) and ""Stop, or I will shoot!""(2) (1) Statement $\neg Rich \Rightarrow \neg Happy$ Converse $\neg Happy \Rightarrow \neg Rich  $ Inverse $ Rich \Rightarrow  Happy$ Contrapositive $Happy \Rightarrow Rich  $ (2) Statement $\neg Stop  \Rightarrow \neg Shot$ Converse $\neg Shot \Rightarrow  \neg Stop $ Inverse $ Stop  \Rightarrow  Shot$ Contrapositive $Shot \Rightarrow   Stop $ Is this true? I appreciate your answer! UPDATE (2) Statement $\neg Stop  \Rightarrow Shot$ Converse $ Shot \Rightarrow  \neg Stop $ Inverse $ Stop  \Rightarrow  \neg Shot$ Contrapositive $\neg Shot \Rightarrow   Stop $","I am trying to break the statements: ""Being rich is necessary for Alex to be happy""(1) and ""Stop, or I will shoot!""(2) (1) Statement $\neg Rich \Rightarrow \neg Happy$ Converse $\neg Happy \Rightarrow \neg Rich  $ Inverse $ Rich \Rightarrow  Happy$ Contrapositive $Happy \Rightarrow Rich  $ (2) Statement $\neg Stop  \Rightarrow \neg Shot$ Converse $\neg Shot \Rightarrow  \neg Stop $ Inverse $ Stop  \Rightarrow  Shot$ Contrapositive $Shot \Rightarrow   Stop $ Is this true? I appreciate your answer! UPDATE (2) Statement $\neg Stop  \Rightarrow Shot$ Converse $ Shot \Rightarrow  \neg Stop $ Inverse $ Stop  \Rightarrow  \neg Shot$ Contrapositive $\neg Shot \Rightarrow   Stop $",,"['logic', 'discrete-mathematics']"
2,"Solve the recursion, $a_n = 3a_{n-1}-3a_{n-2}+a_{n-3}+8$","Solve the recursion,",a_n = 3a_{n-1}-3a_{n-2}+a_{n-3}+8,"Bring the following recursion relation to an explicit expression: $$a_n = 3a_{n-1}-3a_{n-2}+a_{n-3}+8$$ $a_{0} = 0$, $a_1 = 1$, $a_2 = 2$ All the examples I have seen were with maximum 2 steps back ($a_{n-2}$) and I thought I know how to solve those but I'm having a hard time both with the Generating function and the Characteristic polynomial methods. The Generating function should start from $n = 3$ but what would happen to the defined values? For the Characteristic polynomial , Does it mean I'll have to find the roots of a polynomial from a 3rd degree?","Bring the following recursion relation to an explicit expression: $$a_n = 3a_{n-1}-3a_{n-2}+a_{n-3}+8$$ $a_{0} = 0$, $a_1 = 1$, $a_2 = 2$ All the examples I have seen were with maximum 2 steps back ($a_{n-2}$) and I thought I know how to solve those but I'm having a hard time both with the Generating function and the Characteristic polynomial methods. The Generating function should start from $n = 3$ but what would happen to the defined values? For the Characteristic polynomial , Does it mean I'll have to find the roots of a polynomial from a 3rd degree?",,"['discrete-mathematics', 'recurrence-relations']"
3,Knight tour problem??,Knight tour problem??,,"Consider an n × n chess board. For what values of n is it possible to find a knight’s tour around the board which uses every possible move just once (in one direction or the other). Here on what factors does n depends?? Any Hints. Is every possible move means, we have to visit every possible path on chess board If that's the meaning that the problem can be converted in euler's tour problem for which necessary and sufficient condition is every node must have even number of edges. And this condition is true for chess board.","Consider an n × n chess board. For what values of n is it possible to find a knight’s tour around the board which uses every possible move just once (in one direction or the other). Here on what factors does n depends?? Any Hints. Is every possible move means, we have to visit every possible path on chess board If that's the meaning that the problem can be converted in euler's tour problem for which necessary and sufficient condition is every node must have even number of edges. And this condition is true for chess board.",,"['graph-theory', 'discrete-mathematics']"
4,Ulam's problem - guessing a chosen number in a set,Ulam's problem - guessing a chosen number in a set,,"I tried to solve the following problem, which I found in the book ""Discrete Mathematics and Its Applications"", by Kenneth Rosen (Problem 28 of the section 7.3 of the 6th Edition): Suppose someone picks a number $x$ from a set of $n$   numbers. A second person tries to guess the number   by successively selecting subsets of the $n$ numbers and   asking the first person whether $x$ is in each set. The   first person answers either “yes” or “no.” When the first   person answers each query truthfully, we can find $x$   using $\log n$ queries by successively splitting the sets   used in each query in half. Ulam’s problem, proposed by   Stanislaw Ulam in 1976, asks for the number of queries   required to find $x$, supposing that the first person is allowed   to lie exactly once. a) Show that by asking each question twice, given a number   $x$ and a set with $n$ elements, and asking one more   question when we find the lie, Ulam’s problem can be   solved using $2 \log n + 1$ queries. b) Show that by dividing the initial set of $n$ elements into   four parts, each with $n/4$ elements, $1/4$ of the elements   can be eliminated using two queries. [ Hint : Use two   queries, where each of the queries asks whether the   element is in the union of two of the subsets with $n/4$   elements and where one of the subsets of $n/4$ elements   is used in both queries.] c) Show from part (b) that if $f (n)$ equals the number   of queries used to solve Ulam’s problem using the   method from part (b) and $n$ is divisible by 4, then   $f (n) = f(3n/4) + 2$. d) Solve the recurrence relation in part (c) for $f (n)$. e) Is the naive way to solve Ulam’s problem by asking   each question twice or the divide-and-conquer   method based on part (b) more efficient? ( Note : here, $\log n$ stands for the base-2 logarithm of $n$.) I will post the whole solution as an answer to my own question, because I want to know if the solution is completely correct and consistent . Thank you in advance.","I tried to solve the following problem, which I found in the book ""Discrete Mathematics and Its Applications"", by Kenneth Rosen (Problem 28 of the section 7.3 of the 6th Edition): Suppose someone picks a number $x$ from a set of $n$   numbers. A second person tries to guess the number   by successively selecting subsets of the $n$ numbers and   asking the first person whether $x$ is in each set. The   first person answers either “yes” or “no.” When the first   person answers each query truthfully, we can find $x$   using $\log n$ queries by successively splitting the sets   used in each query in half. Ulam’s problem, proposed by   Stanislaw Ulam in 1976, asks for the number of queries   required to find $x$, supposing that the first person is allowed   to lie exactly once. a) Show that by asking each question twice, given a number   $x$ and a set with $n$ elements, and asking one more   question when we find the lie, Ulam’s problem can be   solved using $2 \log n + 1$ queries. b) Show that by dividing the initial set of $n$ elements into   four parts, each with $n/4$ elements, $1/4$ of the elements   can be eliminated using two queries. [ Hint : Use two   queries, where each of the queries asks whether the   element is in the union of two of the subsets with $n/4$   elements and where one of the subsets of $n/4$ elements   is used in both queries.] c) Show from part (b) that if $f (n)$ equals the number   of queries used to solve Ulam’s problem using the   method from part (b) and $n$ is divisible by 4, then   $f (n) = f(3n/4) + 2$. d) Solve the recurrence relation in part (c) for $f (n)$. e) Is the naive way to solve Ulam’s problem by asking   each question twice or the divide-and-conquer   method based on part (b) more efficient? ( Note : here, $\log n$ stands for the base-2 logarithm of $n$.) I will post the whole solution as an answer to my own question, because I want to know if the solution is completely correct and consistent . Thank you in advance.",,"['algorithms', 'discrete-mathematics', 'recurrence-relations', 'recursive-algorithms']"
5,Determining a recurrence relation (Homework),Determining a recurrence relation (Homework),,"Let ${d_n}$ be the number of DNA strings of length n that contain a pair of consecutive nucleotides of the same type. There are four symbols used in strings of DNA: A, C, G, T . The nucleotides are divided into two types: purines, A and G , and pyrimidines, C and T . The first part of the problem involves determining the first values of ${d_n}$ with n = 1, 2, 3, which I'm pretty sure I have correct: ${d_1}$ = 0 (impossible for a string of length 1 to have a pair of consecutive nucleotides) ${d_2}$ = 8 { AG, CT, GA, TC, AA, GG, CC, TT } ${d_3}$ = ${4^3}$ - 12 = 64 - 16 = 48 (set of all strings of length 3 minus strings with out 2 consecutive nucleotide types): { ACA, ACG, GCA, GCG, ATA, ATG, GTA, GTG, TAT, TAC, CAT, CAC, TGT, TGC, CGT, CGC } The second part of the problem I'm having some more trouble with, which is determining the recurrence relation for ${d_n}$. I know a good first step is to come up with cases, but this is a problem much different from any others I've done in my discrete mathematics class. Any help, even hints would be much appreciated. If you would like me to clarify anything, please let me know.","Let ${d_n}$ be the number of DNA strings of length n that contain a pair of consecutive nucleotides of the same type. There are four symbols used in strings of DNA: A, C, G, T . The nucleotides are divided into two types: purines, A and G , and pyrimidines, C and T . The first part of the problem involves determining the first values of ${d_n}$ with n = 1, 2, 3, which I'm pretty sure I have correct: ${d_1}$ = 0 (impossible for a string of length 1 to have a pair of consecutive nucleotides) ${d_2}$ = 8 { AG, CT, GA, TC, AA, GG, CC, TT } ${d_3}$ = ${4^3}$ - 12 = 64 - 16 = 48 (set of all strings of length 3 minus strings with out 2 consecutive nucleotide types): { ACA, ACG, GCA, GCG, ATA, ATG, GTA, GTG, TAT, TAC, CAT, CAC, TGT, TGC, CGT, CGC } The second part of the problem I'm having some more trouble with, which is determining the recurrence relation for ${d_n}$. I know a good first step is to come up with cases, but this is a problem much different from any others I've done in my discrete mathematics class. Any help, even hints would be much appreciated. If you would like me to clarify anything, please let me know.",,"['discrete-mathematics', 'recurrence-relations', 'recursive-algorithms']"
6,Where can I download Discrete Mathematics lecture videos?,Where can I download Discrete Mathematics lecture videos?,,"Good morning, I'm doing a course in Discrete Mathematics (so far: Four Colour Theorem, Intro Graph Theory, Intro Logic Theory, Intro Set Theory and Intro Proofs) at University, but unfortunately they don't record the lectures. Where can I download Discrete Mathematics lecture videos? - If from multiple places, which would you recommend? Thanks for all suggestions, Alec Taylor PS: Notes and worksheets recommendations would be great too :]","Good morning, I'm doing a course in Discrete Mathematics (so far: Four Colour Theorem, Intro Graph Theory, Intro Logic Theory, Intro Set Theory and Intro Proofs) at University, but unfortunately they don't record the lectures. Where can I download Discrete Mathematics lecture videos? - If from multiple places, which would you recommend? Thanks for all suggestions, Alec Taylor PS: Notes and worksheets recommendations would be great too :]",,"['graph-theory', 'discrete-mathematics', 'self-learning', 'online-resources']"
7,Password combinations help,Password combinations help,,"I've been looking through other posts here about combinations/permutations regarding possible numbers of passwords for a given set of rules, but I can't get my head around it and wondered if someone could help me. I have an example in mind for a password problem. So, how many valid passwords are there if: The password must be exactly 6 characters long. The password can only contain lowercase letters (a to z) and digits    (0 to 9). The password must contain 4 letters and must contain 2 digits. Digits can't be repeated Letters can be repeated So I thought the answer would be: P(6,2) x 10 x 9 x 26^4 P(6,2) I've calculated as: 6! / (6 - 2)! = 30 So final answer: 30 x 10 x 9 x 26^4 Is this right? Or should I be using combinations? Honestly I've been looking on here for ages and reading through different answers and inclusion/exclusion but I can't figure it out so I'd really appreciate someone walking through it. Thanks","I've been looking through other posts here about combinations/permutations regarding possible numbers of passwords for a given set of rules, but I can't get my head around it and wondered if someone could help me. I have an example in mind for a password problem. So, how many valid passwords are there if: The password must be exactly 6 characters long. The password can only contain lowercase letters (a to z) and digits    (0 to 9). The password must contain 4 letters and must contain 2 digits. Digits can't be repeated Letters can be repeated So I thought the answer would be: P(6,2) x 10 x 9 x 26^4 P(6,2) I've calculated as: 6! / (6 - 2)! = 30 So final answer: 30 x 10 x 9 x 26^4 Is this right? Or should I be using combinations? Honestly I've been looking on here for ages and reading through different answers and inclusion/exclusion but I can't figure it out so I'd really appreciate someone walking through it. Thanks",,"['discrete-mathematics', 'permutations', 'combinations']"
8,Two identity element?,Two identity element?,,"On $\Bbb N=\{0,1,2,...\}$ we define the operation $\otimes$ by $m\otimes n= |m-n|$ . Are there any identity element? I came up with two identity elements. $e= 0$ and $e=2m$ for an element $m$ in the set, but how is that possible? I thought on a operation $\otimes$ that it would always be one identity element?","On we define the operation by . Are there any identity element? I came up with two identity elements. and for an element in the set, but how is that possible? I thought on a operation that it would always be one identity element?","\Bbb N=\{0,1,2,...\} \otimes m\otimes n= |m-n| e= 0 e=2m m \otimes",['discrete-mathematics']
9,Prove that the least upper bound of $\mathcal F$ is $\bigcup\mathcal F$ and the greatest lower bound of $\mathcal F$ is $\bigcap\mathcal F$.,Prove that the least upper bound of  is  and the greatest lower bound of  is .,\mathcal F \bigcup\mathcal F \mathcal F \bigcap\mathcal F,"Not a duplicate of this or this . This is exercise $4.4.23$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Prove theorem $4.4.11.$ Theorem $4.4.11.$ Suppose $A$ is a set, $\mathcal F\subseteq \mathscr P(A)$ , and $\mathcal F\neq \emptyset$ . Then the least upper bound of $\mathcal F$ $($ in the subset partial order $)$ is $\bigcup\mathcal F$ and the greatest lower bound of $\mathcal F$ is $\bigcap\mathcal F$ . Here is my proof: Let $F$ be an arbitrary element of $\mathcal F$ . Let $x$ be an arbitrary element of $F$ . Ergo clearly $x\in\bigcup\mathcal F$ . Since $x$ is arbitrary, $F\subseteq\bigcup\mathcal F$ . Therefore if $F\in\mathcal F$ then $F\subseteq\bigcup\mathcal F$ . Since $F$ is arbitrary, $\bigcup\mathcal F$ is an upper bound for $\mathcal F$ . Let $U$ be the set of all upper bounds for $\mathcal F$ and let $X$ be an arbitrary element of $U$ . Let $y$ be an arbitrary element of $\bigcup\mathcal F$ . So we can choose some $G_0\in\mathcal F$ such that $y\in G_0$ . Since $X$ is an upper bound for $\mathcal F$ then $G_0\subseteq X$ . Since $y\in G_0$ , $y\in X$ . Since $y$ is arbitrary, $\bigcup\mathcal F\subseteq X$ . Thus if $X\in U$ then $\bigcup\mathcal F\subseteq X$ . Since $X$ is arbitrary, $\bigcup\mathcal F$ is the smallest element of $U$ and hence the least upper bound for $\mathcal F$ . Let $F$ be an arbitrary element of $\mathcal F$ . Let $x$ be an arbitrary element of $\bigcap\mathcal F$ . Ergo clearly $x\in F$ . Therefore if $F\in\mathcal F$ then $\bigcap\mathcal F\subseteq F$ . Since $F$ is arbitrary, $\bigcap\mathcal F$ is a lower bound for $\mathcal F$ . Let $L$ be the set of all lower bounds for $\mathcal F$ and let $Y$ be an arbitrary element of $L$ . Let $y$ be an arbitrary element of $Y$ . Since $Y$ is a lower bound for $\mathcal F$ , $Y\subseteq F$ . Since $y\in Y$ , $y\in F$ . Since $F$ is arbitrary, $y\in\bigcap\mathcal F$ . Since $y$ is arbitrary, $Y\subseteq \bigcap\mathcal F$ . Thus if $Y\in L$ then $Y\subseteq \bigcap\mathcal F$ . Since $Y$ is arbitrary, $\bigcap\mathcal F$ is the biggest element of $L$ and hence the greatest lower bound for $\mathcal F$ . $Q.E.D.$ Is my proof valid $?$ Thanks for your attention.","Not a duplicate of this or this . This is exercise from the book How to Prove it by Velleman edition : Prove theorem Theorem Suppose is a set, , and . Then the least upper bound of in the subset partial order is and the greatest lower bound of is . Here is my proof: Let be an arbitrary element of . Let be an arbitrary element of . Ergo clearly . Since is arbitrary, . Therefore if then . Since is arbitrary, is an upper bound for . Let be the set of all upper bounds for and let be an arbitrary element of . Let be an arbitrary element of . So we can choose some such that . Since is an upper bound for then . Since , . Since is arbitrary, . Thus if then . Since is arbitrary, is the smallest element of and hence the least upper bound for . Let be an arbitrary element of . Let be an arbitrary element of . Ergo clearly . Therefore if then . Since is arbitrary, is a lower bound for . Let be the set of all lower bounds for and let be an arbitrary element of . Let be an arbitrary element of . Since is a lower bound for , . Since , . Since is arbitrary, . Since is arbitrary, . Thus if then . Since is arbitrary, is the biggest element of and hence the greatest lower bound for . Is my proof valid Thanks for your attention.",4.4.23 (2^{nd} ) 4.4.11. 4.4.11. A \mathcal F\subseteq \mathscr P(A) \mathcal F\neq \emptyset \mathcal F ( ) \bigcup\mathcal F \mathcal F \bigcap\mathcal F F \mathcal F x F x\in\bigcup\mathcal F x F\subseteq\bigcup\mathcal F F\in\mathcal F F\subseteq\bigcup\mathcal F F \bigcup\mathcal F \mathcal F U \mathcal F X U y \bigcup\mathcal F G_0\in\mathcal F y\in G_0 X \mathcal F G_0\subseteq X y\in G_0 y\in X y \bigcup\mathcal F\subseteq X X\in U \bigcup\mathcal F\subseteq X X \bigcup\mathcal F U \mathcal F F \mathcal F x \bigcap\mathcal F x\in F F\in\mathcal F \bigcap\mathcal F\subseteq F F \bigcap\mathcal F \mathcal F L \mathcal F Y L y Y Y \mathcal F Y\subseteq F y\in Y y\in F F y\in\bigcap\mathcal F y Y\subseteq \bigcap\mathcal F Y\in L Y\subseteq \bigcap\mathcal F Y \bigcap\mathcal F L \mathcal F Q.E.D. ?,"['discrete-mathematics', 'proof-writing', 'solution-verification', 'order-theory']"
10,Let $G$ a graph without a $P_4$ as induced subgraph. Prove that either $G$ or $\overline{G}$ is disconnected.,Let  a graph without a  as induced subgraph. Prove that either  or  is disconnected.,G P_4 G \overline{G},"I've got the following problem: Let $G$ a graph not containing a $P_4$ (path with 4 nodes) a an induced subgraph.   Prove, that either $G$ or $\overline{G}$ is disconnected. Initially, I assumed the above condition means that the graph does not contain any paths of length $\geq 3$ . However, this disregards the fact that we're talking about induced subgraphs here. So, if there are ""long"" edges between nodes of a longer path, it would not be considered induced $P_4$ and would thus be admissible. This leaves me stuck. How do I prove the above statement?","I've got the following problem: Let a graph not containing a (path with 4 nodes) a an induced subgraph.   Prove, that either or is disconnected. Initially, I assumed the above condition means that the graph does not contain any paths of length . However, this disregards the fact that we're talking about induced subgraphs here. So, if there are ""long"" edges between nodes of a longer path, it would not be considered induced and would thus be admissible. This leaves me stuck. How do I prove the above statement?",G P_4 G \overline{G} \geq 3 P_4,"['discrete-mathematics', 'graph-theory']"
11,Combinatorial proof that chromatic polynomial of $n$-cycle is $(x-1)^n+(-1)^n(x-1)$.,Combinatorial proof that chromatic polynomial of -cycle is .,n (x-1)^n+(-1)^n(x-1),How we can proof that chromatic polynomial of cycle $C_n$ is $$ w(x) =(x-1)^n+(-1)^n(x-1) $$ I saw algebraic proof but I am really interested in combinatoric proof of this fact We choose random element (without lost of generality) and give him one of $x$ colour. $$ w(x) = x \cdot ... $$ Now we choose color for right neighbour on $(x-1)$ ways. And again for next right neighbour we choose in $(x-1)$ ways next color. We repeat that as long as we don't meet first vertex. So $$ w(x) = x(x-1)^n \neq (x-1)^n+(-1)^n(x-1) $$,How we can proof that chromatic polynomial of cycle is I saw algebraic proof but I am really interested in combinatoric proof of this fact We choose random element (without lost of generality) and give him one of colour. Now we choose color for right neighbour on ways. And again for next right neighbour we choose in ways next color. We repeat that as long as we don't meet first vertex. So,C_n  w(x) =(x-1)^n+(-1)^n(x-1)  x  w(x) = x \cdot ...  (x-1) (x-1)  w(x) = x(x-1)^n \neq (x-1)^n+(-1)^n(x-1) ,"['discrete-mathematics', 'graph-theory', 'coloring', 'combinatorial-proofs']"
12,Find sum $ \sum\limits_{k=2}^{2^{2^n}} \frac{1}{2^{\lfloor \log_2k \rfloor} \cdot 4^{\lfloor \log_2(\log_2k )\rfloor}} $,Find sum, \sum\limits_{k=2}^{2^{2^n}} \frac{1}{2^{\lfloor \log_2k \rfloor} \cdot 4^{\lfloor \log_2(\log_2k )\rfloor}} ,"Calculate sum $$ \sum_{k=2}^{2^{2^n}} \frac{1}{2^{\lfloor \log_2k \rfloor} \cdot 4^{\lfloor \log_2(\log_2k )\rfloor}}  $$ I hope to solve this in use of Iverson notation: my try $$ \sum_{k=2}^{2^{2^n}} \frac{1}{2^{\lfloor \log_2k \rfloor} \cdot 4^{\lfloor \log_2(\log_2k )\rfloor}} = \sum_{k,l,m}2^{-l}4^{-m} [2^l \le k < 2^{l+1}][2^{2^m} \le k < 2^{2^m+1}]  $$ and now: $$ [2^l \le k < 2^{l+1}][2^{2^m} \le k < 2^{2^m+1}] \neq 0 $$ if and only if $$2^l \le k < 2^{l+1} \wedge 2^{2^m} \le k < 2^{2^m+1} $$ I can assume that $l$ is const (we know value of $l$ ) and treat $m$ as variable depence from $l$ . Ok so: $$2^l \le 2^{2^m} \wedge 2^{2^m+1} \le 2^{l+1} $$ but it gives me that $l=2^m$ I think that it is not true (but also I don't see mistake). Even if it is true, how can be it finished?","Calculate sum I hope to solve this in use of Iverson notation: my try and now: if and only if I can assume that is const (we know value of ) and treat as variable depence from . Ok so: but it gives me that I think that it is not true (but also I don't see mistake). Even if it is true, how can be it finished?"," \sum_{k=2}^{2^{2^n}} \frac{1}{2^{\lfloor \log_2k \rfloor} \cdot 4^{\lfloor \log_2(\log_2k )\rfloor}}    \sum_{k=2}^{2^{2^n}} \frac{1}{2^{\lfloor \log_2k \rfloor} \cdot 4^{\lfloor \log_2(\log_2k )\rfloor}} = \sum_{k,l,m}2^{-l}4^{-m} [2^l \le k < 2^{l+1}][2^{2^m} \le k < 2^{2^m+1}]    [2^l \le k < 2^{l+1}][2^{2^m} \le k < 2^{2^m+1}] \neq 0  2^l \le k < 2^{l+1} \wedge 2^{2^m} \le k < 2^{2^m+1}  l l m l 2^l \le 2^{2^m} \wedge 2^{2^m+1} \le 2^{l+1}  l=2^m","['discrete-mathematics', 'summation']"
13,Finding the closed form for $x_n^2 = -x_{n-1}^2+6x_{n-2}^2+n$,Finding the closed form for,x_n^2 = -x_{n-1}^2+6x_{n-2}^2+n,"I'm trying to find a closed form for the recurrence relation $x_n^2 = -x_{n-1}^2+6x_{n-2}^2+n$ , with $x_1 = \frac{1}{4}, x_2=\frac{\sqrt{13}}{4}$ and $x_i \in \mathbb R^+$ .  My attempt was to let $z_n=x_n^2$ and then transform the recurrence relation to a 2nd order non-homogeneous linear recurrence relation. Substitution gives: $$z_n = -z_{n-1}+6z_{n-2}$$ . Now the above recurrence relation has complementary function $$z'_n = L2^n +K(-3)^n$$ for $L,K$ arbitrary constants.  I also found that the new recurrence relation has a particular solution given by $$z''_n = \frac{11-n}{4}$$ . Thus the general solution is $$z_n = L2^n +K(-3)^n + \frac{11-n}{4}$$ By substitution I then found $L=\frac{-7}{8}, K = \frac{11}{48}$ . So the unique solution for our recurrence relation is: $$z_n = \frac{-7}{8}2^n +\frac{11}{48}(-3)^n + \frac{11-n}{4}$$ Now, for $n=3$ I obtain a negative value of $z_n$ indicating that my solution is invalid. I've checked my solution numerous times and I'm pretty sure my numbers are right so I'm wondering if my method here is wrong.","I'm trying to find a closed form for the recurrence relation , with and .  My attempt was to let and then transform the recurrence relation to a 2nd order non-homogeneous linear recurrence relation. Substitution gives: . Now the above recurrence relation has complementary function for arbitrary constants.  I also found that the new recurrence relation has a particular solution given by . Thus the general solution is By substitution I then found . So the unique solution for our recurrence relation is: Now, for I obtain a negative value of indicating that my solution is invalid. I've checked my solution numerous times and I'm pretty sure my numbers are right so I'm wondering if my method here is wrong.","x_n^2 = -x_{n-1}^2+6x_{n-2}^2+n x_1 = \frac{1}{4}, x_2=\frac{\sqrt{13}}{4} x_i \in \mathbb R^+ z_n=x_n^2 z_n = -z_{n-1}+6z_{n-2} z'_n = L2^n +K(-3)^n L,K z''_n = \frac{11-n}{4} z_n = L2^n +K(-3)^n + \frac{11-n}{4} L=\frac{-7}{8}, K = \frac{11}{48} z_n = \frac{-7}{8}2^n +\frac{11}{48}(-3)^n + \frac{11-n}{4} n=3 z_n","['discrete-mathematics', 'recurrence-relations', 'closed-form']"
14,What are the facets of the Birkhoff Polytope when $n=2$?,What are the facets of the Birkhoff Polytope when ?,n=2,"I've read in several sources that the number of facets of the Birkhoff polytope $\mathcal{B}(n)$ is $n^2$. Is this supposed to hold when $n=2$? Since $\mathcal{B}(2)$ has dimension $1$, the facets would be the two $0$-dimensional vertices, which are the two permutation matrices below: $$\begin{pmatrix} 1 & 0 \\ 0 &1  \end{pmatrix} \text{ and } \begin{pmatrix} 0 & 1 \\ 1 &0  \end{pmatrix}$$ However, the claim is that there should be $2^2 = 4$ facets. None of my sources have given any restriction on $n$. What am I missing?","I've read in several sources that the number of facets of the Birkhoff polytope $\mathcal{B}(n)$ is $n^2$. Is this supposed to hold when $n=2$? Since $\mathcal{B}(2)$ has dimension $1$, the facets would be the two $0$-dimensional vertices, which are the two permutation matrices below: $$\begin{pmatrix} 1 & 0 \\ 0 &1  \end{pmatrix} \text{ and } \begin{pmatrix} 0 & 1 \\ 1 &0  \end{pmatrix}$$ However, the claim is that there should be $2^2 = 4$ facets. None of my sources have given any restriction on $n$. What am I missing?",,"['discrete-mathematics', 'polytopes', 'discrete-geometry', 'birkhoff-polytopes']"
15,Use of multi-valued function in proving the equivalence of surjectivity and existence of a right inverse,Use of multi-valued function in proving the equivalence of surjectivity and existence of a right inverse,,"In Dummit and Foote's Abstract Algebra, the first two claims of Proposition 0.1 state that: Let $f: A \rightarrow B$ . If $A \neq \emptyset$ , the map $f$ is injective if and only if $f$ has a left inverse. The map $f$ is surjective if and only if $f$ has a right inverse. For $(1)$ , if $f$ is injective, then we can construct a function $g: B \rightarrow A$ such that $\forall f(a) = b \in B$ , we have the ""reverse"" mapping $$g(b) = a$$ and by appealing to the injectivity of $f$ , it follows that the composition map $g \circ f$ is in fact the identity map, so $f$ has a left inverse. Conversely, if we suppose that $f$ has a left inverse, then we can consider $a_1, a_2 \in A$ such that $a_1 = a_2$ . Since $f$ has a left inverse, we can write $g(f(a_1)) = a_1$ and $g(f(a_2))=a_2 \implies g(f(a_1)) = g(f(a_2)) \implies f(a_1) = f(a_2)$ due to the fact that $g$ is a function. In the case of $(2)$ , we suppose that $f$ is surjective and construct a function $h: B \rightarrow A$ such that $$h(b) \in \{a \in A : f(a) = b \}$$ i.e., considering reserve mapping of sorts where $h(b)$ can be any value $a$ where $f$ maps $a$ back to $b$ . Thus $f$ has a right inverse. In the other direction, it is easy to show that the existence of a right inverse guarantees that $\forall b \in B$ , $\exists a \in A$ such that $f(a) = b$ , namely, $a = h(b)$ , satisfying the definition of surjectivity. My main concern deals with the construction of the relation $h$ . By the set theoretic definition of function, we must have that no two ordered pairs in the relation $h$ have the same first element, but the very notion of having a multi-valued seems to contradict that definition. In other words, I am intuitively thinking of injectivity as an information preserving property, so one can have a reverse mapping without any ambiguities, but surjectivity is a property that results in information loss as multiple elements in $A$ could map to $b \in B$ , and there being no well-defined way to map back to the original $a$ from $b$ . I would like to verify if my reasoning above is correct, and by extension, if the proofs are rigorous enough in their current form.","In Dummit and Foote's Abstract Algebra, the first two claims of Proposition 0.1 state that: Let . If , the map is injective if and only if has a left inverse. The map is surjective if and only if has a right inverse. For , if is injective, then we can construct a function such that , we have the ""reverse"" mapping and by appealing to the injectivity of , it follows that the composition map is in fact the identity map, so has a left inverse. Conversely, if we suppose that has a left inverse, then we can consider such that . Since has a left inverse, we can write and due to the fact that is a function. In the case of , we suppose that is surjective and construct a function such that i.e., considering reserve mapping of sorts where can be any value where maps back to . Thus has a right inverse. In the other direction, it is easy to show that the existence of a right inverse guarantees that , such that , namely, , satisfying the definition of surjectivity. My main concern deals with the construction of the relation . By the set theoretic definition of function, we must have that no two ordered pairs in the relation have the same first element, but the very notion of having a multi-valued seems to contradict that definition. In other words, I am intuitively thinking of injectivity as an information preserving property, so one can have a reverse mapping without any ambiguities, but surjectivity is a property that results in information loss as multiple elements in could map to , and there being no well-defined way to map back to the original from . I would like to verify if my reasoning above is correct, and by extension, if the proofs are rigorous enough in their current form.","f: A \rightarrow B A \neq \emptyset f f f f (1) f g: B \rightarrow A \forall f(a) = b \in B g(b) = a f g \circ f f f a_1, a_2 \in A a_1 = a_2 f g(f(a_1)) = a_1 g(f(a_2))=a_2 \implies g(f(a_1)) = g(f(a_2)) \implies f(a_1) = f(a_2) g (2) f h: B \rightarrow A h(b) \in \{a \in A : f(a) = b \} h(b) a f a b f \forall b \in B \exists a \in A f(a) = b a = h(b) h h A b \in B a b","['discrete-mathematics', 'proof-verification']"
16,Maximum number of edges in a planar graph without $3$- or $4$-cycles,Maximum number of edges in a planar graph without - or -cycles,3 4,"What is the largest possible number of edges in a planar graph without $3$- or $4$-cycles? I've been unsuccessfully trying to solve this problem from my book. I know that every planar graph without $3$-cycles has at most $2n - 4$ edges, though I'm not sure about graphs without $4$-cycles.","What is the largest possible number of edges in a planar graph without $3$- or $4$-cycles? I've been unsuccessfully trying to solve this problem from my book. I know that every planar graph without $3$-cycles has at most $2n - 4$ edges, though I'm not sure about graphs without $4$-cycles.",,"['discrete-mathematics', 'graph-theory', 'planar-graphs']"
17,How many positive integers less than 1000 have distinct digits and are even?,How many positive integers less than 1000 have distinct digits and are even?,,"I am not looking for an answer on this. Just need to clarify why my approach is failing - $N_1 + N_2 + N_3$, i.e. single digit, double digit, 3 digit single $= 2, 4, 6, 8$, i.e 4 double = X non-zero $= 8 \cdot 4 = 32$ X zero $= 9 \cdot 1 = 9$ Now the confusing part three digit, breaking into 4 cases X zero zero $= 9$ X nz nz $= 7 \cdot 8 \cdot 4 = 224$ X z nz $= 8 \cdot 1 \cdot 4 = 32$ X nz z $= 8 \cdot 9 \cdot 1 = 72$ Three digit total comes to $= 9 + 224 + 32 + 72 = 337$. This answer is wrong and it should be $328$. What am I missing in the logic? Please suggest.","I am not looking for an answer on this. Just need to clarify why my approach is failing - $N_1 + N_2 + N_3$, i.e. single digit, double digit, 3 digit single $= 2, 4, 6, 8$, i.e 4 double = X non-zero $= 8 \cdot 4 = 32$ X zero $= 9 \cdot 1 = 9$ Now the confusing part three digit, breaking into 4 cases X zero zero $= 9$ X nz nz $= 7 \cdot 8 \cdot 4 = 224$ X z nz $= 8 \cdot 1 \cdot 4 = 32$ X nz z $= 8 \cdot 9 \cdot 1 = 72$ Three digit total comes to $= 9 + 224 + 32 + 72 = 337$. This answer is wrong and it should be $328$. What am I missing in the logic? Please suggest.",,['discrete-mathematics']
18,"Proving $\frac {2n}{(a+b)^n} \le \frac {1}{a^n} + \frac {1}{b^n}$ for $a,b>0, n\in\mathbb{N}$ by induction",Proving  for  by induction,"\frac {2n}{(a+b)^n} \le \frac {1}{a^n} + \frac {1}{b^n} a,b>0, n\in\mathbb{N}","prove using induction: $$ \frac {2n}{(a+b)^n} \le \frac {1}{a^n} + \frac {1}{b^n} $$ $$a,b \gt 0  ,  n \in N$$ my attempt: base $n=1$ : $$ \frac {2}{(a+b)} \le \frac {1}{a} + \frac {1}{b}$$ $$2ab \le b(a+b) + a(a+b)$$ $$2ab \le ab + b^2 + a^2 + ab$$ $$0 <= a^2 + b^2$$ sum of $2$ not negatives, done. assume it's right for $n=k \in N$ ....... $$ \frac {2k}{(a+b)^k} \le \frac {1}{a^k} + \frac {1}{b^k}$$ prove for $n=k+1$ ...... $$ \frac {2(k+1)}{(a+b)^{k+1}} \le \frac {1}{a^{k+1}} + \frac {1}{b^{k+1}}$$ i've tried various things... and get stuck everytime. this is the attempt mimicking what the lecturer/teaching aid do usually with such problems (problems without parameters tho)... $$ \frac {2(k+1)}{(a+b)^{k+1}} = $$ $$ \frac {1}{(a+b)} \times \left( \frac {2k}{(a+b)^k} + \frac {2}{(a+b)^k} \right) = $$ $$\left(M + \frac {2}{(a+b)^k} \right) \times \frac {1}{(a+b)}$$ go back to the assumption... $$M \le \frac {1}{a^k} + \frac {1}{b^k}$$ $$M + \frac {2}{(a+b)^k} \le \frac {1}{a^k} + \frac {1}{b^k} + \frac {2} {(a+b)^k}$$ $$\left( M + \frac {2}{(a+b)^k} \right) \times \frac {1}{a+b} \le \left( \frac {1}{a^k} + \frac {1}{b^k} + \frac {2} {(a+b)^k} \right) \times \frac {1}{a+b}$$ now we need to prove... $$\left( \frac {1}{a^k} + \frac {1}{b^k} + \frac {2} {(a+b)^k} \right) \times\frac {1}{a+b} \le \frac {1}{a^{k+1}} + \frac {1}{b^{k+1}}$$ no matter how i try messing around with this... i reach a dead end. please help.","prove using induction: my attempt: base : sum of not negatives, done. assume it's right for ....... prove for ...... i've tried various things... and get stuck everytime. this is the attempt mimicking what the lecturer/teaching aid do usually with such problems (problems without parameters tho)... go back to the assumption... now we need to prove... no matter how i try messing around with this... i reach a dead end. please help."," \frac {2n}{(a+b)^n} \le \frac {1}{a^n} + \frac {1}{b^n}  a,b \gt 0  ,  n \in N n=1  \frac {2}{(a+b)} \le \frac {1}{a} + \frac {1}{b} 2ab \le b(a+b) + a(a+b) 2ab \le ab + b^2 + a^2 + ab 0 <= a^2 + b^2 2 n=k \in N  \frac {2k}{(a+b)^k} \le \frac {1}{a^k} + \frac {1}{b^k} n=k+1  \frac {2(k+1)}{(a+b)^{k+1}} \le \frac {1}{a^{k+1}} + \frac {1}{b^{k+1}}  \frac {2(k+1)}{(a+b)^{k+1}} =   \frac {1}{(a+b)} \times \left( \frac {2k}{(a+b)^k} + \frac {2}{(a+b)^k} \right) =  \left(M + \frac {2}{(a+b)^k} \right) \times \frac {1}{(a+b)} M \le \frac {1}{a^k} + \frac {1}{b^k} M + \frac {2}{(a+b)^k} \le \frac {1}{a^k} + \frac {1}{b^k} + \frac {2} {(a+b)^k} \left( M + \frac {2}{(a+b)^k} \right) \times \frac {1}{a+b} \le \left( \frac {1}{a^k} + \frac {1}{b^k} + \frac {2} {(a+b)^k} \right) \times \frac {1}{a+b} \left( \frac {1}{a^k} + \frac {1}{b^k} + \frac {2} {(a+b)^k} \right) \times\frac {1}{a+b} \le \frac {1}{a^{k+1}} + \frac {1}{b^{k+1}}","['discrete-mathematics', 'inequality', 'induction']"
19,"The Ackermann's function ""grows faster"" than any primitive recursive function","The Ackermann's function ""grows faster"" than any primitive recursive function",,"I am looking at the proof that the Ackermann's function is not primitive recursive. At the part: ""We will prove that Ackermann's function is not primitive recursive by showing that it ""grows faster"" than any primitive recursive function. That means that we need a precise way of comparing the ""growth rate"" of the two-variable function $A$ with that of an arbitrary $n-$variable function. What we shall attempt to do is show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $$A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) \tag {*}$$ for all values of $x_1, \dots , x_n$.  The proof is accomplished by induction on the number of compositions and primitive recursions needed to define the function $f$. "" Could you explain to me why we want to show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) $ for all values of $x_1, \dots , x_n$ in order to show that the Ackermann's function ""grows faster"" than any primitive recursive function ?? Also, why do we use induction on the number of compositions and primitive recursions needed to define the function $f$ ?? $$$$ EDIT: The proof that the Ackermann's function is not primitive recursive is the following: To prove this we need the following properties concerning the values of $A$. $A(x,y)>y$. $A(x,y+1)>A(x,y)$. If $y_2>y_1$, then $A(x,y_2)>A(x,y_1)$. $A(x+1, y) \geq A(x,y+1)$. $A(x,y)>x$. If $x_2>x_1$, then $A(x_2, y)>A(x_1, y)$. $A(x+2, y)>A(x,2y)$. We will prove that Ackermann's function is not primitive recursive by showing that it ""grows faster"" than any primitive recursive function. That means that we need a precise way of comparing the ""growth rate"" of the two-variable function $A$ with that of an arbitrary $n-$variable function. What we shall attempt to do is show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $$A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) \tag {*}$$ for all values of $x_1, \dots , x_n$.  The proof is accomplished by induction on the number of compositions and primitive recursions needed to define the function $f$. In order to carry out the induction step of the proof, we need two auxiliary results. The results of these results ensures that if the functions $g_1, \dots , g_m$ and $h$ satisfy $(*)$, so does the function $f$ obtained from $g_1, \dots , g_m$ and $h$ by functional composition. Lemma 1 . Let the $n-$variable function $f=h \circ (g_1, \dots , g_m)$ be obtained from the functions $g_1, \dots , g_m$ and $h$ by composition. Assume the existence of natural numbers $k_1, \dots , k_m$, and $k_0$ such that $$A(k_i, \max (x_1, \dots , x_n)) > g_i (x_1, \dots , x_n) \text{ for } 1 \leq i \leq m\\ \text{ and } \\ A(k_0, \max (y_1, \dots , y_m )) > h(y_1, \dots , y_m)$$ for all $x_1, \dots , x_n$ and $y_1, \dots , y_m$. Define $k$ to be the natural number $\max (k_0, k_1, \dots , k_m)+2$. Then $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n)$ for all $x_1, \dots , x_n$. Lemma 2 . Let the $(n+1)-$variable function $f$ be defined by primitive recursion from the $n-$variable function $g$ and the $(n+2)-$variable function $h$, so that $$f(x_1, \dots , x_n, 0)=g(x_1, \dots , x_n) \\ f(x_1, \dots x_n, y+1)=h(x_1, \dots , x_n , y, f(x_1, \dots , x_n, y))$$ Assume the existence of natural numbers $k_g$ and $k_h$ such that $$A(k_g ,\max (x_1, \dots , x_n)) > g(x_1, \dots , x_n) \\ \text{ and } \\ A(k_h, \max (x_1, \dots , x_n , y , z)) > h(x_1, \dots , x_n , y, z)$$ for all $x_1, \dots ,x_n, y$ and $z$. Define $k$ to be the natural number $\max (k_g, k_h)+3$. Then $A(k, \max (x_1, \dots , x_n , y)) > f(x_1, \dots  ,x_n , y)$ for all $x_1, \dots , x_n, y$. Theorem 1. For each $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n)$, for all $x_1, \dots , x_n$. Proof. By iduction on the number of compositions and primitive recursions needed to define $f$. We use $\hat{x}$ to denote $\max (x_1, \dots , x_n)$. Basis. If the derivation of $f$ requires no compositions or primitive recursions, three cases are possible. If $f$ is the constant function whose value is $c$, choose $k=c$. Property $5$ then guarantees that $A(k, \hat {x})=A(c, \hat{x})>c=f(x_1, \dots , x_n)$. If $f$ is the projection function whose valuee is $x_i$, choose $k=0$. Then $A(k,\hat{x})=A(0,\hat(x))=\hat(x)+1>x_i=f(x_1, \dots , x_n)$. If $f$ is the successor function, choose $k=1$. Then $A(k,x)=A(1,x)>A(0,x)=x+1=f(x)$. Induction step. Assume the statement of the theorem to be true for all functions requiring $w$ or fewer compositions and primitve recursions. Let $f$ be a function requiring a total of $w+1$ compositions and primitive recursions. Two cases are possible. If $f$ is derived from functions $g_1, \dots , g_m$ and $h$ by composition, the induction hypothesis must apply to each of $g_1, \dots , g_m$, and $h$. Lemma $1$ then guarantees the existence of a number $k$ such that $A(k,\hat{x})>f(x_1, \dots , x_n)$. If $f$ is derived from the functions $g$ and $h$ by primitive recursion, the induction hypothesis must apply to $g$ and $h$. Lemma $2$ then guarantees the existence of a number $k$ such that $A(k, \hat{x})>f(x_1, \dots , x_n)$. Theorem $1$ provides a formal expression of the notopn that $A$ ""grows faster"" than any primitive recursive function. It is now a simple matter to establish: Theorem 2. Ackermann's function is not primitive recursive. Proof. Assume hat Ackermann's function is primitive recursive. Then according to Theorem 1, there must exist a natral number $k$ such that $$A(k, \max (x,y)) > A(x,y)$$ for all $x$ and $y$ . Setting $x=y=k$ then yields the contradiction $$A(k,k) > A(k,k)$$ from which we conclude that $A$ cannot be primitive recursive.","I am looking at the proof that the Ackermann's function is not primitive recursive. At the part: ""We will prove that Ackermann's function is not primitive recursive by showing that it ""grows faster"" than any primitive recursive function. That means that we need a precise way of comparing the ""growth rate"" of the two-variable function $A$ with that of an arbitrary $n-$variable function. What we shall attempt to do is show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $$A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) \tag {*}$$ for all values of $x_1, \dots , x_n$.  The proof is accomplished by induction on the number of compositions and primitive recursions needed to define the function $f$. "" Could you explain to me why we want to show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) $ for all values of $x_1, \dots , x_n$ in order to show that the Ackermann's function ""grows faster"" than any primitive recursive function ?? Also, why do we use induction on the number of compositions and primitive recursions needed to define the function $f$ ?? $$$$ EDIT: The proof that the Ackermann's function is not primitive recursive is the following: To prove this we need the following properties concerning the values of $A$. $A(x,y)>y$. $A(x,y+1)>A(x,y)$. If $y_2>y_1$, then $A(x,y_2)>A(x,y_1)$. $A(x+1, y) \geq A(x,y+1)$. $A(x,y)>x$. If $x_2>x_1$, then $A(x_2, y)>A(x_1, y)$. $A(x+2, y)>A(x,2y)$. We will prove that Ackermann's function is not primitive recursive by showing that it ""grows faster"" than any primitive recursive function. That means that we need a precise way of comparing the ""growth rate"" of the two-variable function $A$ with that of an arbitrary $n-$variable function. What we shall attempt to do is show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $$A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) \tag {*}$$ for all values of $x_1, \dots , x_n$.  The proof is accomplished by induction on the number of compositions and primitive recursions needed to define the function $f$. In order to carry out the induction step of the proof, we need two auxiliary results. The results of these results ensures that if the functions $g_1, \dots , g_m$ and $h$ satisfy $(*)$, so does the function $f$ obtained from $g_1, \dots , g_m$ and $h$ by functional composition. Lemma 1 . Let the $n-$variable function $f=h \circ (g_1, \dots , g_m)$ be obtained from the functions $g_1, \dots , g_m$ and $h$ by composition. Assume the existence of natural numbers $k_1, \dots , k_m$, and $k_0$ such that $$A(k_i, \max (x_1, \dots , x_n)) > g_i (x_1, \dots , x_n) \text{ for } 1 \leq i \leq m\\ \text{ and } \\ A(k_0, \max (y_1, \dots , y_m )) > h(y_1, \dots , y_m)$$ for all $x_1, \dots , x_n$ and $y_1, \dots , y_m$. Define $k$ to be the natural number $\max (k_0, k_1, \dots , k_m)+2$. Then $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n)$ for all $x_1, \dots , x_n$. Lemma 2 . Let the $(n+1)-$variable function $f$ be defined by primitive recursion from the $n-$variable function $g$ and the $(n+2)-$variable function $h$, so that $$f(x_1, \dots , x_n, 0)=g(x_1, \dots , x_n) \\ f(x_1, \dots x_n, y+1)=h(x_1, \dots , x_n , y, f(x_1, \dots , x_n, y))$$ Assume the existence of natural numbers $k_g$ and $k_h$ such that $$A(k_g ,\max (x_1, \dots , x_n)) > g(x_1, \dots , x_n) \\ \text{ and } \\ A(k_h, \max (x_1, \dots , x_n , y , z)) > h(x_1, \dots , x_n , y, z)$$ for all $x_1, \dots ,x_n, y$ and $z$. Define $k$ to be the natural number $\max (k_g, k_h)+3$. Then $A(k, \max (x_1, \dots , x_n , y)) > f(x_1, \dots  ,x_n , y)$ for all $x_1, \dots , x_n, y$. Theorem 1. For each $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n)$, for all $x_1, \dots , x_n$. Proof. By iduction on the number of compositions and primitive recursions needed to define $f$. We use $\hat{x}$ to denote $\max (x_1, \dots , x_n)$. Basis. If the derivation of $f$ requires no compositions or primitive recursions, three cases are possible. If $f$ is the constant function whose value is $c$, choose $k=c$. Property $5$ then guarantees that $A(k, \hat {x})=A(c, \hat{x})>c=f(x_1, \dots , x_n)$. If $f$ is the projection function whose valuee is $x_i$, choose $k=0$. Then $A(k,\hat{x})=A(0,\hat(x))=\hat(x)+1>x_i=f(x_1, \dots , x_n)$. If $f$ is the successor function, choose $k=1$. Then $A(k,x)=A(1,x)>A(0,x)=x+1=f(x)$. Induction step. Assume the statement of the theorem to be true for all functions requiring $w$ or fewer compositions and primitve recursions. Let $f$ be a function requiring a total of $w+1$ compositions and primitive recursions. Two cases are possible. If $f$ is derived from functions $g_1, \dots , g_m$ and $h$ by composition, the induction hypothesis must apply to each of $g_1, \dots , g_m$, and $h$. Lemma $1$ then guarantees the existence of a number $k$ such that $A(k,\hat{x})>f(x_1, \dots , x_n)$. If $f$ is derived from the functions $g$ and $h$ by primitive recursion, the induction hypothesis must apply to $g$ and $h$. Lemma $2$ then guarantees the existence of a number $k$ such that $A(k, \hat{x})>f(x_1, \dots , x_n)$. Theorem $1$ provides a formal expression of the notopn that $A$ ""grows faster"" than any primitive recursive function. It is now a simple matter to establish: Theorem 2. Ackermann's function is not primitive recursive. Proof. Assume hat Ackermann's function is primitive recursive. Then according to Theorem 1, there must exist a natral number $k$ such that $$A(k, \max (x,y)) > A(x,y)$$ for all $x$ and $y$ . Setting $x=y=k$ then yields the contradiction $$A(k,k) > A(k,k)$$ from which we conclude that $A$ cannot be primitive recursive.",,"['discrete-mathematics', 'computer-science', 'recursion', 'ackermann-function']"
20,"$\land,\lor$ and $\lnot$ determinate a functionally complete basis",and  determinate a functionally complete basis,"\land,\lor \lnot","I read that a Boolean algebra is defined by the binary operations $\land$ and $\lor$ and the unary operation $\lnot$ on a set such that $$\varphi\land(\psi\land \chi)=(\varphi\land \psi)\land \chi,\quad \varphi\lor(\psi\lor \chi)=(\varphi\lor \psi)\lor \chi$$ $$\varphi\land \psi=\psi\land \varphi,\quad \varphi\lor \psi=\psi\lor \varphi$$ $$\varphi\lor (\psi\land \chi) = (\varphi\lor \psi) \land (\varphi \lor \chi)   ,\quad	\varphi \land (\psi\lor \chi) = (\varphi \land \psi) \lor (\varphi \land \chi) $$ $$\varphi \lor (\varphi \land \psi) = \varphi,\quad \varphi\land (\varphi\lor \psi) = \varphi$$ $$\varphi\land 0 =0,\quad \varphi\lor1=1$$ $$\varphi\lor\lnot \varphi=0,\quad \varphi\land\lnot \varphi=1$$ The text states that $\land,\lor$ and $\lnot$ determinates a functionally complete basis in the sense that any function $\{0,1\}^n\to\{0,1\}$ can be expressed by using such operations, and I would like to understand a proof of that. I have verified that the statement is true for $n=2$. Moreover, I know that the number of all the functions mapping $\{0,1\}^n$ into $\{0,1\}$ are $2^{2^n}$ and I supposed I could verify by induction that we can write all the functions $\{0,1\}^n\to\{0,1\}$ with $\land,\lor$ and $\lnot$, but I am not able to prove it to myself. Could anybody prove it here or give a link to some on line resource? I heartily thank you!","I read that a Boolean algebra is defined by the binary operations $\land$ and $\lor$ and the unary operation $\lnot$ on a set such that $$\varphi\land(\psi\land \chi)=(\varphi\land \psi)\land \chi,\quad \varphi\lor(\psi\lor \chi)=(\varphi\lor \psi)\lor \chi$$ $$\varphi\land \psi=\psi\land \varphi,\quad \varphi\lor \psi=\psi\lor \varphi$$ $$\varphi\lor (\psi\land \chi) = (\varphi\lor \psi) \land (\varphi \lor \chi)   ,\quad	\varphi \land (\psi\lor \chi) = (\varphi \land \psi) \lor (\varphi \land \chi) $$ $$\varphi \lor (\varphi \land \psi) = \varphi,\quad \varphi\land (\varphi\lor \psi) = \varphi$$ $$\varphi\land 0 =0,\quad \varphi\lor1=1$$ $$\varphi\lor\lnot \varphi=0,\quad \varphi\land\lnot \varphi=1$$ The text states that $\land,\lor$ and $\lnot$ determinates a functionally complete basis in the sense that any function $\{0,1\}^n\to\{0,1\}$ can be expressed by using such operations, and I would like to understand a proof of that. I have verified that the statement is true for $n=2$. Moreover, I know that the number of all the functions mapping $\{0,1\}^n$ into $\{0,1\}$ are $2^{2^n}$ and I supposed I could verify by induction that we can write all the functions $\{0,1\}^n\to\{0,1\}$ with $\land,\lor$ and $\lnot$, but I am not able to prove it to myself. Could anybody prove it here or give a link to some on line resource? I heartily thank you!",,"['discrete-mathematics', 'boolean-algebra']"
21,"Binary relation, reflexive, symmetric and transitive","Binary relation, reflexive, symmetric and transitive",,"I have a question regarding an image. I'm currently studying binary relations and the following image confused me: What got me confused is that the page from which I got the link ( http://www.cs.odu.edu/~toida/nerzic/content/relation/property/property.html ) says that the graph in (a) is reflexive, symmetric and transitive. According to what I've learned so far a set is reflexive if for all $x$, $x$ bears a relation to $x$, the graph has this property. Now, for the other two relations, symmetric and transitive, it does not hold. Because for it to be symmetric it would need a path from both points back to each other (because a relation is symmetric iff $x$ has a relation to $y$ and back). The transitive property also does not hold because there are only 2 points and transitivity needs at least three. I would like some proof that explains why the graph is transitive and symmetric.","I have a question regarding an image. I'm currently studying binary relations and the following image confused me: What got me confused is that the page from which I got the link ( http://www.cs.odu.edu/~toida/nerzic/content/relation/property/property.html ) says that the graph in (a) is reflexive, symmetric and transitive. According to what I've learned so far a set is reflexive if for all $x$, $x$ bears a relation to $x$, the graph has this property. Now, for the other two relations, symmetric and transitive, it does not hold. Because for it to be symmetric it would need a path from both points back to each other (because a relation is symmetric iff $x$ has a relation to $y$ and back). The transitive property also does not hold because there are only 2 points and transitivity needs at least three. I would like some proof that explains why the graph is transitive and symmetric.",,"['discrete-mathematics', 'relations', 'equivalence-relations']"
22,Smallest such $n \in \mathbb{N}$ that $2^{n} \equiv 1 \pmod{5\cdot 7\cdot 9\cdot 11\cdot 13}$,Smallest such  that,n \in \mathbb{N} 2^{n} \equiv 1 \pmod{5\cdot 7\cdot 9\cdot 11\cdot 13},"Can anybody give me a hint about how to find smallest such $n \in \mathbb{N}$ that $2^{n} \equiv 1  \pmod{5\cdot 7\cdot 9\cdot 11\cdot 13}$? I thought that I will find it piece by piece with help from my friend Fermat's Little Theorem, so : $2^{n_{1}} \equiv 1 \mod 5$, so $n_{1}=4$. $2^{n_{2}} \equiv 1 \mod 7$, so $n_{2}=6$. $2^{n_{3}} \equiv 1 \mod 3$, so $n_{3}=2$. $2^{n_{4}} \equiv 1 \mod 11$, so $n_{4}=10$. $2^{n_{5}} \equiv 1 \mod 13$, so $n_{5}=12$. So, since I know that $x \equiv y \mod mz \Leftrightarrow x \equiv y \mod m$ when $z \neq 0$, so my lucky was to take the lowest common multiple of $4,6,2,10,12$, which is $60$ and lo and behold it fits the bill. But is it the smallest such $n$? If so, how to explain it?","Can anybody give me a hint about how to find smallest such $n \in \mathbb{N}$ that $2^{n} \equiv 1  \pmod{5\cdot 7\cdot 9\cdot 11\cdot 13}$? I thought that I will find it piece by piece with help from my friend Fermat's Little Theorem, so : $2^{n_{1}} \equiv 1 \mod 5$, so $n_{1}=4$. $2^{n_{2}} \equiv 1 \mod 7$, so $n_{2}=6$. $2^{n_{3}} \equiv 1 \mod 3$, so $n_{3}=2$. $2^{n_{4}} \equiv 1 \mod 11$, so $n_{4}=10$. $2^{n_{5}} \equiv 1 \mod 13$, so $n_{5}=12$. So, since I know that $x \equiv y \mod mz \Leftrightarrow x \equiv y \mod m$ when $z \neq 0$, so my lucky was to take the lowest common multiple of $4,6,2,10,12$, which is $60$ and lo and behold it fits the bill. But is it the smallest such $n$? If so, how to explain it?",,"['discrete-mathematics', 'modular-arithmetic', 'congruences']"
23,Choosing between the 'and' and 'implies' connectives,Choosing between the 'and' and 'implies' connectives,,"$pol(x): x$ is a politician $liar(x): x $ is a liar All politicians are liars : $\forall x(pol(x) → liar(x))$ Some politicians are liars : $\exists x(pol(x) \land liar(x))$ No politicians are liars : $\forall x(pol(x) → ¬liar(x))$ Some politicians are not liars : $\exists x(pol(x) \land ¬liar(x))$ So, do we just use 'and' for $\exists$ statements and 'implies' for $\forall$ statements?","is a politician is a liar All politicians are liars : Some politicians are liars : No politicians are liars : Some politicians are not liars : So, do we just use 'and' for statements and 'implies' for statements?",pol(x): x liar(x): x  \forall x(pol(x) → liar(x)) \exists x(pol(x) \land liar(x)) \forall x(pol(x) → ¬liar(x)) \exists x(pol(x) \land ¬liar(x)) \exists \forall,"['discrete-mathematics', 'logic', 'intuition', 'quantifiers', 'logic-translation']"
24,Strict order and adjacent elements,Strict order and adjacent elements,,"Task: Prove that there is no strict order on 14 elements in which there are exactly 50 pairs of adjacent elements. Some clarifications: Elements x, y of order (X, <) are adjacent if x < y and there is no z such that x < z < y. My thinking: (in this text: pair of adjacent elements = adjacent pair) In fact, the maximum number of adjacent pairs that we can get on 14 elements is 49. Let's build a bipartite graph in which both parts consist of 7 elements. As a result, this will give us 7 * 7 = 49 adjacent pairs. Bipartite graphs where there is not the same number of elements in each part are not suitable for us: 6 * 8 = 48, 5 * 9 = 45, etc., all these cases will give less than 49 pairs of adjacent elements. But I have a problem: I can’t strictly prove that the maximum number of adjacent pairs that we can get will be exactly 49. I need to prove that besides a bipartite graph with 7 elements in each part, there is no other option for implementing strict partial order so that it reaches >= 49 adjacent pairs.","Task: Prove that there is no strict order on 14 elements in which there are exactly 50 pairs of adjacent elements. Some clarifications: Elements x, y of order (X, <) are adjacent if x < y and there is no z such that x < z < y. My thinking: (in this text: pair of adjacent elements = adjacent pair) In fact, the maximum number of adjacent pairs that we can get on 14 elements is 49. Let's build a bipartite graph in which both parts consist of 7 elements. As a result, this will give us 7 * 7 = 49 adjacent pairs. Bipartite graphs where there is not the same number of elements in each part are not suitable for us: 6 * 8 = 48, 5 * 9 = 45, etc., all these cases will give less than 49 pairs of adjacent elements. But I have a problem: I can’t strictly prove that the maximum number of adjacent pairs that we can get will be exactly 49. I need to prove that besides a bipartite graph with 7 elements in each part, there is no other option for implementing strict partial order so that it reaches >= 49 adjacent pairs.",,"['discrete-mathematics', 'order-theory']"
25,"How do I translate ""is not sufficient"" into symbolic logic?","How do I translate ""is not sufficient"" into symbolic logic?",,"Take the proposition ""it is not sufficient for the monkey to dance in order for me to get an A on the test"" m = the monkey dances a = I get an A on the test It makes sense why I can translate the statement ""it IS sufficient for the monkey to dance in order for me to get an A on the test"" to m → a , because if m and a are both true the proposition is true, and if m is false I can understand why the proposition is vacuously true. Where my understanding falls apart is when you negate the statement: m a m → a ¬(m → a) T T T F T F F T F T T F F F T F It makes sense why ¬(m → a) is equivalent to ""it is not sufficient for the monkey to dance in order for me to get an A on the test"", because it is a negation of m → a . But it doesn't make sense that m and a both being true makes ""it is not sufficient for the monkey to dance in order for me to get an A on the test"" false. If the monkey dances, and I get an A on the test, wouldn't that make this proposition vacuously true? This proposition claims that the monkey dancing isn't sufficient, but just because both happen, it doesn't contradict the proposition. Is it just ""vacuously false""?","Take the proposition ""it is not sufficient for the monkey to dance in order for me to get an A on the test"" m = the monkey dances a = I get an A on the test It makes sense why I can translate the statement ""it IS sufficient for the monkey to dance in order for me to get an A on the test"" to m → a , because if m and a are both true the proposition is true, and if m is false I can understand why the proposition is vacuously true. Where my understanding falls apart is when you negate the statement: m a m → a ¬(m → a) T T T F T F F T F T T F F F T F It makes sense why ¬(m → a) is equivalent to ""it is not sufficient for the monkey to dance in order for me to get an A on the test"", because it is a negation of m → a . But it doesn't make sense that m and a both being true makes ""it is not sufficient for the monkey to dance in order for me to get an A on the test"" false. If the monkey dances, and I get an A on the test, wouldn't that make this proposition vacuously true? This proposition claims that the monkey dancing isn't sufficient, but just because both happen, it doesn't contradict the proposition. Is it just ""vacuously false""?",,"['discrete-mathematics', 'logic', 'propositional-calculus', 'logic-translation']"
26,"Prove that if $G$ is a graph of order $101$ and $δ(G) = 51$, then every vertex of $G$ lies on a cycle of length $27$","Prove that if  is a graph of order  and , then every vertex of  lies on a cycle of length",G 101 δ(G) = 51 G 27,"Prove that if $G$ is a graph of order $101$ and $δ(G) = 51$ , then every vertex of $G$ lies on a cycle of length $27$ (Chapter 3 Exercise 16.a  Chromatic Graph Theory,Gary Chartrand, Ping Zhang) Attempt: First I observed that the hypotheses of the dirac theorem are fulfilled. A simple graph with $n$ vertices ( $n\geq 3$ ) is Hamiltonian if every vertex has degree $\frac {n}{2}$ or greater. So the graph $G$ is hamiltonian. And by definition a hamiltonian graph is a graph that contains a hamiltonian cycle (a cycle in G that contains every vertex of G). So now I have a cycle but I don't know how to get what I need.","Prove that if is a graph of order and , then every vertex of lies on a cycle of length (Chapter 3 Exercise 16.a  Chromatic Graph Theory,Gary Chartrand, Ping Zhang) Attempt: First I observed that the hypotheses of the dirac theorem are fulfilled. A simple graph with vertices ( ) is Hamiltonian if every vertex has degree or greater. So the graph is hamiltonian. And by definition a hamiltonian graph is a graph that contains a hamiltonian cycle (a cycle in G that contains every vertex of G). So now I have a cycle but I don't know how to get what I need.",G 101 δ(G) = 51 G 27 n n\geq 3 \frac {n}{2} G,"['discrete-mathematics', 'graph-theory', 'hamiltonian-path']"
27,prove or disprove: every non satisfiable set of WFF has a non satisfiable sub set such every proper subset of it is satisfiable,prove or disprove: every non satisfiable set of WFF has a non satisfiable sub set such every proper subset of it is satisfiable,,"Let $\Gamma$ be a non-satisfiable set of well-formed formulas (wff). prove or disprove: $\Gamma$ has a non-satisfiable subset $\Delta\subseteq\Gamma$ such that for every $\phi\subsetneq\Delta$ is satisfiable. I believe this is wrong, because there are wffs that if I join them I'll get a contradiction, but I wasn't able to find a concrete example.","Let be a non-satisfiable set of well-formed formulas (wff). prove or disprove: has a non-satisfiable subset such that for every is satisfiable. I believe this is wrong, because there are wffs that if I join them I'll get a contradiction, but I wasn't able to find a concrete example.",\Gamma \Gamma \Delta\subseteq\Gamma \phi\subsetneq\Delta,"['discrete-mathematics', 'logic']"
28,Solving a recursive inequality,Solving a recursive inequality,,"I have the following inequality for $\{x_t\}_{t\geq 0}$ and trying to find an upper bound for $x_t$ . Let $c$ be a constant. $$x_{t+1}\leq c^2\left[x_t+\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4}\tag{1}$$ My attempt: If we had an equality instead of inequality in $(1)$ , I would have used generating function of $x_t$ to solve for $x_t$ but for an inequality I don't think I can use generating functions (?). So I tried to think of $x(t)$ as a continuous function of $t$ and $(1)$ being a finite difference approximation. Then: \begin{align*} x_{t+1}-x_t &\leq (c^2-1)x_t+c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\ x_{t+1}-x_t - (c^2-1)x_t &\leq c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\ \frac{dx}{dt}-(c^2-1)x &\leq c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\ \frac{d}{dt}\left( e^{-(c^2-1)t}x\right) &\leq e^{-(c^2-1)t}c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\ \end{align*} and then integrate to find an upper bound on $x=x(t)$ but I'd think this is an approximation for an actual upper bound for $x_t$ and am not sure how to solve $(1)$ with or without using what I did above.","I have the following inequality for and trying to find an upper bound for . Let be a constant. My attempt: If we had an equality instead of inequality in , I would have used generating function of to solve for but for an inequality I don't think I can use generating functions (?). So I tried to think of as a continuous function of and being a finite difference approximation. Then: and then integrate to find an upper bound on but I'd think this is an approximation for an actual upper bound for and am not sure how to solve with or without using what I did above.","\{x_t\}_{t\geq 0} x_t c x_{t+1}\leq c^2\left[x_t+\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4}\tag{1} (1) x_t x_t x(t) t (1) \begin{align*}
x_{t+1}-x_t &\leq (c^2-1)x_t+c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
x_{t+1}-x_t - (c^2-1)x_t &\leq c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
\frac{dx}{dt}-(c^2-1)x &\leq c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
\frac{d}{dt}\left( e^{-(c^2-1)t}x\right) &\leq e^{-(c^2-1)t}c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
\end{align*} x=x(t) x_t (1)",['discrete-mathematics']
29,How many four digits numbers are there not containing zero and multiplication of its digits divisible by 7?,How many four digits numbers are there not containing zero and multiplication of its digits divisible by 7?,,"I saw a question in my math book, it seems very trivial, it says that: How many four digits numbers are there not containing zero and multiplication of its digits divisible by 7? I thought of: (all four digits numbers not containing zero) minus (all four digits numbers not containing 7 and 0) in order to find all four digits number not containing zero and multiplication of its four digits divisible by 7. Then $(9^4)-(8^4)=2465$ . However the answer is $4904$ . What am I missing?","I saw a question in my math book, it seems very trivial, it says that: How many four digits numbers are there not containing zero and multiplication of its digits divisible by 7? I thought of: (all four digits numbers not containing zero) minus (all four digits numbers not containing 7 and 0) in order to find all four digits number not containing zero and multiplication of its four digits divisible by 7. Then . However the answer is . What am I missing?",(9^4)-(8^4)=2465 4904,"['discrete-mathematics', 'permutations']"
30,How can wheel factorization be used to speed up sieving?,How can wheel factorization be used to speed up sieving?,,"I've seen optimizations to the Sieve of Eratosthenes that (claim to) use ""wheel factorization"". If the goal is to generate a list of prime numbers up to a certain value, I'm wondering how exactly is wheel factorization used? The Wikipedia article contains some information but it doesn't make sense to me. For example sieve up to $15$ : $\{1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\}$ Starting with 2 strike off multiples $\{1,2,3,\_,5,\_,7,\_,9,\_,11,\_,13,\_,15\}$ Then strike off multiples of 3: $\{1,2,3,\_,5,\_,7,\_,\_,\_,11,\_,13,\_,\_\}$ For wheel factorization with base primes $2$ and $3$ the idea is composites occur periodically with 3 in a row, then one. So how are these two ideas ""merged"" when creating a list of prime numbers? Is it just wheel factorization is used to create an initial list of candidates before sieving? But that doesn't seem to save any time because SoE has the pitfall where it strikes off all ready stricken off composites (for example 15 is stricken off on 3 and 15 so what good would wheel factorization of circumference 6 do)? Is anyone able to provide an example of wheel factorization used with a sieve? TL;DR how is wheel factorization used with sieving?","I've seen optimizations to the Sieve of Eratosthenes that (claim to) use ""wheel factorization"". If the goal is to generate a list of prime numbers up to a certain value, I'm wondering how exactly is wheel factorization used? The Wikipedia article contains some information but it doesn't make sense to me. For example sieve up to : Starting with 2 strike off multiples Then strike off multiples of 3: For wheel factorization with base primes and the idea is composites occur periodically with 3 in a row, then one. So how are these two ideas ""merged"" when creating a list of prime numbers? Is it just wheel factorization is used to create an initial list of candidates before sieving? But that doesn't seem to save any time because SoE has the pitfall where it strikes off all ready stricken off composites (for example 15 is stricken off on 3 and 15 so what good would wheel factorization of circumference 6 do)? Is anyone able to provide an example of wheel factorization used with a sieve? TL;DR how is wheel factorization used with sieving?","15 \{1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\} \{1,2,3,\_,5,\_,7,\_,9,\_,11,\_,13,\_,15\} \{1,2,3,\_,5,\_,7,\_,\_,\_,11,\_,13,\_,\_\} 2 3","['elementary-number-theory', 'discrete-mathematics', 'algorithms', 'sieve-theory']"
31,"Correct logical equivalent of ""Every real number except zero has multiplicative inverse.""","Correct logical equivalent of ""Every real number except zero has multiplicative inverse.""",,"My Discrete Mathematics textbook translates the statement ""Every real number except zero has multiplicative inverse"" to $$\forall{x}{({(x\neq0)} \rightarrow{\exists{y}{(xy=1)}})}.\tag1$$ I noticed that the above translation is correct if and only if you interpret the original English statement as not specifying whether zero has multiplicative inverse. That is, all numbers have inverses except zero for which zero may or may not have an inverse. (This is evident from the truth table in which if $x$ was equal to zero then whether $x$ has an inverse or not the statement evaluates to true in both cases.) In the same vein, I can say that ""Every real number greater than 7 has a multiplicative inverse"" translates to $$\forall{x}{({(x>7)} \rightarrow{\exists{y}{(xy=1)}})};$$ this statement doesn't mean that only real numbers greater than $7$ have a multiplicative inverse. However, if you interpret the original English statement as ""Every real number except zero has multiplicative inverse while zero does not have a multiplicative inverse"", then this translates to $$\forall{x}{({(x\neq0)} \leftrightarrow{\exists{y}{(xy=1)}})}.\tag2$$ My professor translated the original sentence the same way the book did. So, I asked whether he assumed that zero has multiplicative inverse, and he answered with a yes because we know that zero does not have a multiplicative inverse. I then explained what I wrote above, but I couldn't get my point across, and he insisted that his translation was correct. Is what I wrote above correct, or is the first translation indeed the only correct one? Is ""Every real number except zero has multiplicative inverse"" ambiguous or is $(1)$ or $(2)$ its correct logical equivalent?","My Discrete Mathematics textbook translates the statement ""Every real number except zero has multiplicative inverse"" to I noticed that the above translation is correct if and only if you interpret the original English statement as not specifying whether zero has multiplicative inverse. That is, all numbers have inverses except zero for which zero may or may not have an inverse. (This is evident from the truth table in which if was equal to zero then whether has an inverse or not the statement evaluates to true in both cases.) In the same vein, I can say that ""Every real number greater than 7 has a multiplicative inverse"" translates to this statement doesn't mean that only real numbers greater than have a multiplicative inverse. However, if you interpret the original English statement as ""Every real number except zero has multiplicative inverse while zero does not have a multiplicative inverse"", then this translates to My professor translated the original sentence the same way the book did. So, I asked whether he assumed that zero has multiplicative inverse, and he answered with a yes because we know that zero does not have a multiplicative inverse. I then explained what I wrote above, but I couldn't get my point across, and he insisted that his translation was correct. Is what I wrote above correct, or is the first translation indeed the only correct one? Is ""Every real number except zero has multiplicative inverse"" ambiguous or is or its correct logical equivalent?",\forall{x}{({(x\neq0)} \rightarrow{\exists{y}{(xy=1)}})}.\tag1 x x \forall{x}{({(x>7)} \rightarrow{\exists{y}{(xy=1)}})}; 7 \forall{x}{({(x\neq0)} \leftrightarrow{\exists{y}{(xy=1)}})}.\tag2 (1) (2),"['discrete-mathematics', 'logic', 'first-order-logic', 'predicate-logic', 'logic-translation']"
32,"Finding a chain with no least or greatest elements for $(\mathcal{P}(\mathbb{N}),\subseteq)$",Finding a chain with no least or greatest elements for,"(\mathcal{P}(\mathbb{N}),\subseteq)","I have a poset $(\mathcal{P}(\mathbb{N}),\subseteq)$ , where $\mathcal{P}$ is a power set, and I need to find a non-empty chain, such as that chain would not have the least or greatest element. It is easy for me to imagine a chain in $(\mathcal{P}(\mathbb{N}),\subseteq)$ , but I can't really grasp the idea of how do I make up a chain with no least element. From what I have googled so far, I can suppose it should be somehow related to the poset $(\mathbb{Q},\subseteq)$ , but I don't know how to develop that idea (in case it shall lead me to an answer at all).","I have a poset , where is a power set, and I need to find a non-empty chain, such as that chain would not have the least or greatest element. It is easy for me to imagine a chain in , but I can't really grasp the idea of how do I make up a chain with no least element. From what I have googled so far, I can suppose it should be somehow related to the poset , but I don't know how to develop that idea (in case it shall lead me to an answer at all).","(\mathcal{P}(\mathbb{N}),\subseteq) \mathcal{P} (\mathcal{P}(\mathbb{N}),\subseteq) (\mathbb{Q},\subseteq)","['discrete-mathematics', 'order-theory']"
33,Why are there $2^n-1$ terms in the inclusion-exclusion formula of $n$ sets?,Why are there  terms in the inclusion-exclusion formula of  sets?,2^n-1 n,"Why are there $2^n-1$ terms in the inclusion-exclusion formula of $n$ sets? An example of what I mean by inclusion-exclusion formula is this: There are three sets (i.e. $n$ $=$ $3$ ): $A, B,$ and $C$ . $A \cup B \cup C = |A| +|B|+|C|-|A\cap B| - |A\cap C| - |B \cap C| +|A \cap B \cap C| $ There are $2^3-1 =7$ terms in the right hand side of the equation. This seems to be true in general, but I'm not sure why. It's probably something obvious I'm missing, can anyone give me a hint?","Why are there terms in the inclusion-exclusion formula of sets? An example of what I mean by inclusion-exclusion formula is this: There are three sets (i.e. ): and . There are terms in the right hand side of the equation. This seems to be true in general, but I'm not sure why. It's probably something obvious I'm missing, can anyone give me a hint?","2^n-1 n n = 3 A, B, C A \cup B \cup C = |A| +|B|+|C|-|A\cap B| - |A\cap C| - |B \cap C| +|A \cap B \cap C|  2^3-1 =7","['discrete-mathematics', 'elementary-set-theory', 'inclusion-exclusion']"
34,Distance between a real number and a whole number,Distance between a real number and a whole number,,"Prove that if $a$ is real and $n$ natural. The distance between one of the numbers $a,2a,3a,...,na$ and a whole number is  at most $\frac{1}{n}$. This is a problem from discrete math, but hints from analysis would be appreciated.","Prove that if $a$ is real and $n$ natural. The distance between one of the numbers $a,2a,3a,...,na$ and a whole number is  at most $\frac{1}{n}$. This is a problem from discrete math, but hints from analysis would be appreciated.",,['discrete-mathematics']
35,When does the dual of $s =s$?,When does the dual of ?,s =s,"Why I believe this is not a duplicate: This question might be the same, but the accepted answer is only a partial answer, because it gives no reason as to why those are the only solutions. Since the answer is accepted, that question will likely not receive any further answers. I would like to reopen this question in order to place a bounty and hopefully get a more complete answer. When does $s^*=s$? $s^*$ represents the dual of $s$, where $s$ is a compound proposition involving only $T, F, \wedge, \vee, \neg $, and $s^*$ is obtained by interchanging $T$ for $F$, $F$ for $T$, $\wedge$ for $\vee$, and $\vee$ for $\wedge$. A big obstacle is that question is from the $2^{nd}$ section of chapter $1$ of a $2000^-level discrete math book, so we are not even introduced to induction. I don't even know what sort of tools I'm supposed to use to solve this. What I've tried: First, I drew up some truth tables of compound prepositions and their duals to look for any patterns, and what I noticed  (in the few examples that I tried) was that the number of ""True"" outputs of $s$ was equal to the number of ""False"" outputs from $s^*$. For example, if $s$ was a compound proposition of $p, q, r$ and $s$ was true in $5$ cases and false in $3$, $s^*$ was false in $5$ cases and true in $3$ (they didn't match up though). I think that if $a=b$, then $a^*=b^*$. I'm not sure how to prove this or if it's even necessary to prove it, but I suspect it's true. If it is, then at least $s^*=s$ holds for compound propositions $s$ which can be simplified to a single proposition. For example $s=(p \vee F) \wedge (q \vee T)=p$, therefore $s=p=p^*=s^*$. I know that in the definition of ""dual"" $s$ has to be a compound proposition; but as an exercise, the book asked to find the dual of this $s$ so I guess it's valid. If this is the only time when $s^*=s$, then I was thinking we can prove this by induction (even though we're probably not supposed to use it.) We know that if $s$ reduces to $p \wedge q$ or to $p \vee q$, then $s^* \ne s$, and then maybe we could use induction to show that if it reduces to a simpler proposition of $n+1$ variables, $s^*=s$ also doesn't hold.","Why I believe this is not a duplicate: This question might be the same, but the accepted answer is only a partial answer, because it gives no reason as to why those are the only solutions. Since the answer is accepted, that question will likely not receive any further answers. I would like to reopen this question in order to place a bounty and hopefully get a more complete answer. When does $s^*=s$? $s^*$ represents the dual of $s$, where $s$ is a compound proposition involving only $T, F, \wedge, \vee, \neg $, and $s^*$ is obtained by interchanging $T$ for $F$, $F$ for $T$, $\wedge$ for $\vee$, and $\vee$ for $\wedge$. A big obstacle is that question is from the $2^{nd}$ section of chapter $1$ of a $2000^-level discrete math book, so we are not even introduced to induction. I don't even know what sort of tools I'm supposed to use to solve this. What I've tried: First, I drew up some truth tables of compound prepositions and their duals to look for any patterns, and what I noticed  (in the few examples that I tried) was that the number of ""True"" outputs of $s$ was equal to the number of ""False"" outputs from $s^*$. For example, if $s$ was a compound proposition of $p, q, r$ and $s$ was true in $5$ cases and false in $3$, $s^*$ was false in $5$ cases and true in $3$ (they didn't match up though). I think that if $a=b$, then $a^*=b^*$. I'm not sure how to prove this or if it's even necessary to prove it, but I suspect it's true. If it is, then at least $s^*=s$ holds for compound propositions $s$ which can be simplified to a single proposition. For example $s=(p \vee F) \wedge (q \vee T)=p$, therefore $s=p=p^*=s^*$. I know that in the definition of ""dual"" $s$ has to be a compound proposition; but as an exercise, the book asked to find the dual of this $s$ so I guess it's valid. If this is the only time when $s^*=s$, then I was thinking we can prove this by induction (even though we're probably not supposed to use it.) We know that if $s$ reduces to $p \wedge q$ or to $p \vee q$, then $s^* \ne s$, and then maybe we could use induction to show that if it reduces to a simpler proposition of $n+1$ variables, $s^*=s$ also doesn't hold.",,"['discrete-mathematics', 'logic', 'propositional-calculus']"
36,Find a sum $S = \sum\limits_{t \in E} \sum\limits_{x \in E} (t + x)(t + x^2)...(t+x^{2p})$,Find a sum,S = \sum\limits_{t \in E} \sum\limits_{x \in E} (t + x)(t + x^2)...(t+x^{2p}),"I am solving a problem that has already a plan for the solution. As a subproblem I have to find the value of  $$S = \sum\limits_{t \in E} \sum\limits_{x \in E} (t + x)(t + x^2)...(t+x^{2p})$$ where $E$ is a set of all $p$-th roots of unity and $p$ is a prime number. I also know the right answer (but cannot get the solution yet): $$S = p (\binom{2p}{p} + 4p - 2)$$ Small clarification: you don't have to read the wall of text below. This is just my attempt to get an answer and the real problem has been already told in the begging. So, what I have done: The plan goes like this: First fix $t$ and sum $x$ Split the sum into two sums for $x = 1$ and $x \neq 1$ ($S(t) = S_1(t) + S_2(t)$) The last step is to sum $t$. Lets find out $S_1(t) = \sum\limits_{t \in E} (t + 1)(t + 1^2)...(t+1^{2p})$. Obviously, it is $S_1(t) = \sum\limits_{t \in E} (t + 1)^{2p}$ The first problem is to find out $S_2(t)$. I think, I can prove that: $$S_2(t) = \sum\limits_{w \in E \setminus \{1\} } (t + w)(t + w^2)...(t+w^{2p}) = (p - 1)(t + w_1)(t + w_1^2)...(t+w_1^{2p})$$ where $w_1 = exp(\frac{2\pi i}{p})$ But I am not sure that is actually true. this is can be rewritten as: $$(p - 1)((t + w_1)(t + w_1^2)...(t+w_1^p))^2$$ The next problem is to find the value of $$(t + w_1)(t + w_1^2)...(t+w_1^p)$$ It is easy to find the coefficient of $t^p$ (clearly, it is $1$), $t^{p-1}$ (not so obvious, but it is $0$ for sure) and $t^0$ (easy to show that it is $1$). So, my guess is that the hole polynomial equals to $t^p+1$. If I was correct (but I still want the proof for all this statements), then: $$S = \sum\limits_{t \in E} [(t+1)^{2p} + (p - 1)(t^p+1)^2]$$ Let's split it again: $$S' = \sum\limits_{t \in E} (p - 1)(t^p+1)^2 = 4 p (p - 1)$$ $$S'' = \sum\limits_{t \in E}(t+1)^{2p} = \sum\limits_{t \in E} \sum\limits_{i=0}^{2p} \binom{2p}{i} t^i = \sum\limits_{i=0}^{2p} \binom{2p}{i} \sum\limits_{t \in E} t^i$$ But I think (but have not proven that yet) that $\sum\limits_{t \in E} t^i = 0$ for every $i \neq p$. And then we can rewrite $S''$: $$S'' = p \binom{2p}{p}$$ And the final result is then: $$S = S' + S'' = 4 p (p - 1) + p \binom{2p}{p} = p(\binom{2p}{p} + 4p - 4)$$ And it is not correct, so I have somewhere a mistake =( Well, I am sorry for such a long introduction. You can help me a lot if you find a mistake in my thoughts and/or help with missing proofs. Alternative solutions are welcome as well =)","I am solving a problem that has already a plan for the solution. As a subproblem I have to find the value of  $$S = \sum\limits_{t \in E} \sum\limits_{x \in E} (t + x)(t + x^2)...(t+x^{2p})$$ where $E$ is a set of all $p$-th roots of unity and $p$ is a prime number. I also know the right answer (but cannot get the solution yet): $$S = p (\binom{2p}{p} + 4p - 2)$$ Small clarification: you don't have to read the wall of text below. This is just my attempt to get an answer and the real problem has been already told in the begging. So, what I have done: The plan goes like this: First fix $t$ and sum $x$ Split the sum into two sums for $x = 1$ and $x \neq 1$ ($S(t) = S_1(t) + S_2(t)$) The last step is to sum $t$. Lets find out $S_1(t) = \sum\limits_{t \in E} (t + 1)(t + 1^2)...(t+1^{2p})$. Obviously, it is $S_1(t) = \sum\limits_{t \in E} (t + 1)^{2p}$ The first problem is to find out $S_2(t)$. I think, I can prove that: $$S_2(t) = \sum\limits_{w \in E \setminus \{1\} } (t + w)(t + w^2)...(t+w^{2p}) = (p - 1)(t + w_1)(t + w_1^2)...(t+w_1^{2p})$$ where $w_1 = exp(\frac{2\pi i}{p})$ But I am not sure that is actually true. this is can be rewritten as: $$(p - 1)((t + w_1)(t + w_1^2)...(t+w_1^p))^2$$ The next problem is to find the value of $$(t + w_1)(t + w_1^2)...(t+w_1^p)$$ It is easy to find the coefficient of $t^p$ (clearly, it is $1$), $t^{p-1}$ (not so obvious, but it is $0$ for sure) and $t^0$ (easy to show that it is $1$). So, my guess is that the hole polynomial equals to $t^p+1$. If I was correct (but I still want the proof for all this statements), then: $$S = \sum\limits_{t \in E} [(t+1)^{2p} + (p - 1)(t^p+1)^2]$$ Let's split it again: $$S' = \sum\limits_{t \in E} (p - 1)(t^p+1)^2 = 4 p (p - 1)$$ $$S'' = \sum\limits_{t \in E}(t+1)^{2p} = \sum\limits_{t \in E} \sum\limits_{i=0}^{2p} \binom{2p}{i} t^i = \sum\limits_{i=0}^{2p} \binom{2p}{i} \sum\limits_{t \in E} t^i$$ But I think (but have not proven that yet) that $\sum\limits_{t \in E} t^i = 0$ for every $i \neq p$. And then we can rewrite $S''$: $$S'' = p \binom{2p}{p}$$ And the final result is then: $$S = S' + S'' = 4 p (p - 1) + p \binom{2p}{p} = p(\binom{2p}{p} + 4p - 4)$$ And it is not correct, so I have somewhere a mistake =( Well, I am sorry for such a long introduction. You can help me a lot if you find a mistake in my thoughts and/or help with missing proofs. Alternative solutions are welcome as well =)",,"['discrete-mathematics', 'polynomials', 'complex-numbers', 'summation', 'generating-functions']"
37,How do you find the pair of witnesses in Big-O notation?,How do you find the pair of witnesses in Big-O notation?,,"In this example my textbook provides:  $4n^2+21n+100$   is   $O(n^2)$. What I do not understand is that the book says the witnesses to this relationship is C = 8, K = 9. How did they come up with those number? The book kind of gives an answer to how they came up with C = 8: Suppose $n \ge 0$ $4n^2+21n+100 \le 4n^2+24n+100$ (Yes, the left is $21n$ and the right is $24n$) $\le 4(n^2 + 6n + 25)$ $\le 8n^2$ I have no idea how they got these numbers, could someone explain this to me. I also understand that if there is one pair of witnesses to a relationship, there exists an infinite number of witnesses therefore what is another pair that would be valid for this relationship? Thank you in advance!","In this example my textbook provides:  $4n^2+21n+100$   is   $O(n^2)$. What I do not understand is that the book says the witnesses to this relationship is C = 8, K = 9. How did they come up with those number? The book kind of gives an answer to how they came up with C = 8: Suppose $n \ge 0$ $4n^2+21n+100 \le 4n^2+24n+100$ (Yes, the left is $21n$ and the right is $24n$) $\le 4(n^2 + 6n + 25)$ $\le 8n^2$ I have no idea how they got these numbers, could someone explain this to me. I also understand that if there is one pair of witnesses to a relationship, there exists an infinite number of witnesses therefore what is another pair that would be valid for this relationship? Thank you in advance!",,"['discrete-mathematics', 'asymptotics']"
38,"Calulating the Ramsey number $R(T, K_{1,n})$ of a tree $T$ and bipartite graph $K_{1,n}$",Calulating the Ramsey number  of a tree  and bipartite graph,"R(T, K_{1,n}) T K_{1,n}","Let $m,n \ge 2$ be such that $m-1$ is a divisor of $n-1$. Let $T$ be a tree with $m$ vertices. Calculate the Ramsey number $R(T,K_{1,n})$. Thoughts : I'm having trouble approaching this question. I think the detail about the divisibility is somehow related to the fact that $n-1$ is the number of nodes on one side of the bipartite graph. $m-1$ is the number of nodes in a tree excluding some defined ""root"". I'd love some ideas on what to consider and how to approach such a question. My main problem is that I don't know what to do with the info about divisibility and forms of the two possible subgraphs. I'm wondering if there is some way to connect this to Chvátal's Theorem on $R(T,K_n)$.","Let $m,n \ge 2$ be such that $m-1$ is a divisor of $n-1$. Let $T$ be a tree with $m$ vertices. Calculate the Ramsey number $R(T,K_{1,n})$. Thoughts : I'm having trouble approaching this question. I think the detail about the divisibility is somehow related to the fact that $n-1$ is the number of nodes on one side of the bipartite graph. $m-1$ is the number of nodes in a tree excluding some defined ""root"". I'd love some ideas on what to consider and how to approach such a question. My main problem is that I don't know what to do with the info about divisibility and forms of the two possible subgraphs. I'm wondering if there is some way to connect this to Chvátal's Theorem on $R(T,K_n)$.",,"['discrete-mathematics', 'graph-theory', 'ramsey-theory']"
39,How to represent a Neither/ Nor set operation,How to represent a Neither/ Nor set operation,,Given: A = { Aaron's friends } B = {Bob's friends} X = {all members in network} Set of friends in the network that are friends of neither Aaron nor Bob I got as answer: $X-(A \cup B)$ Is this operation correct?,Given: A = { Aaron's friends } B = {Bob's friends} X = {all members in network} Set of friends in the network that are friends of neither Aaron nor Bob I got as answer: Is this operation correct?,X-(A \cup B),"['discrete-mathematics', 'elementary-set-theory']"
40,Expressing a recursively defined function in terms of factorials or gamma function,Expressing a recursively defined function in terms of factorials or gamma function,,"Given the recursion $$f(n) = nf(n-1) + (n-1)f(n-2) $$ $$f(0) = 1, f(1) = 1$$ How exactly does one express the target function? I know that $$f(n) = nf(n-1)$$ gives rise to $$f(n) = \Gamma(n+1)$$ By repeatedly substituting I can then derive $$f(n) = \Gamma(n+1) + (n-1)f(n-2) + n(n-2)f(n-3) + n(n-1)(n-3)f(n-4) ... $$ Where to go from there?","Given the recursion $$f(n) = nf(n-1) + (n-1)f(n-2) $$ $$f(0) = 1, f(1) = 1$$ How exactly does one express the target function? I know that $$f(n) = nf(n-1)$$ gives rise to $$f(n) = \Gamma(n+1)$$ By repeatedly substituting I can then derive $$f(n) = \Gamma(n+1) + (n-1)f(n-2) + n(n-2)f(n-3) + n(n-1)(n-3)f(n-4) ... $$ Where to go from there?",,"['discrete-mathematics', 'recurrence-relations', 'functional-equations', 'factorial', 'closed-form']"
41,Can someone please clarify combinations vs permutations?,Can someone please clarify combinations vs permutations?,,"I see similar questions asked on here and obviously I did some research and read my book, but it seems like every explanation contradicts another in some way. There are basically infinite scenarios using these and every example problem/scenario I seem to convince myself it could be both! Here are some of my understandings of each: Permutation: Every detail matters and ALL ways of doing something. ""Think of permutations as a list."" Combinations: Used for groups. Order and Position DOES NOT matter. My Confusion: a.) If permutations are ALL ways of doing something.. then why does order/position/type matter? b.) If order does NOT matter with combinations.. why are ""Locks"" said to have a ""combination"" when clearly the order does matter with a lock? If the ""combination"" to unlock something is 1-2-3.. then clearly 1-3-2 would not work. Therefore it seems like order does matter.. c.) If permutations are ALL ways of doing something and if EVERY detail matters.. then why are the number of permutations larger than the number of combinations? Sorry if I included too much. I'm really struggling with this and every time I think I understand a scenario/problem.. I look at another and have no idea how to do it! I'd greatly appreciate any help. Thank you!","I see similar questions asked on here and obviously I did some research and read my book, but it seems like every explanation contradicts another in some way. There are basically infinite scenarios using these and every example problem/scenario I seem to convince myself it could be both! Here are some of my understandings of each: Permutation: Every detail matters and ALL ways of doing something. ""Think of permutations as a list."" Combinations: Used for groups. Order and Position DOES NOT matter. My Confusion: a.) If permutations are ALL ways of doing something.. then why does order/position/type matter? b.) If order does NOT matter with combinations.. why are ""Locks"" said to have a ""combination"" when clearly the order does matter with a lock? If the ""combination"" to unlock something is 1-2-3.. then clearly 1-3-2 would not work. Therefore it seems like order does matter.. c.) If permutations are ALL ways of doing something and if EVERY detail matters.. then why are the number of permutations larger than the number of combinations? Sorry if I included too much. I'm really struggling with this and every time I think I understand a scenario/problem.. I look at another and have no idea how to do it! I'd greatly appreciate any help. Thank you!",,"['discrete-mathematics', 'permutations', 'problem-solving', 'combinations']"
42,Find the sum of the series.,Find the sum of the series.,,"I need to find the following sum: $$\sum_{s=0}^{n+1}{(-1)}^{n-s}4^s\binom{n+s+1}{2s}$$ First I tried to simplify this: $$\begin{split} \sum_{s=0}^{n+1}{(-1)}^{n-s}4^s\binom{n+s+1}{2s}  &= {(-1)}^n\sum_{s=0}^{n+1}{(-1)}^{s}2^{2s}\binom{n+s+1}{2s} \\  &= \left[{(-1)}^{m-1}\sum_{s=0}^m{(-1)}^{s}x^{2s}\binom{m+s}{2s}\right](2) \end{split} $$ Now I reduced the problem to the following: ""Find generating function for the following sequence"" $$\sum_{s=0}^m{(-1)}^{s}x^{2s}\binom{m+s}{2s}$$ Does anyone have any ideas how to solve this problem? Because if you put it to the Wolfram|Alpha result is terryfing and I hope that generating function produced by wolfram is too generalized (for any values of x and m). UPD: I put the wrong sequece to Wolfram|Alpha, here is the correct one . So, Wolphram|Alpha says now, that: $$\sum_{s=0}^m{(-1)}^{s}x^{2s}\binom{m+s}{2s} = \frac{2\cos\left((2m+1)\arcsin\left(\frac2x\right)\right)}{\sqrt{4-x^2}}$$ Unfortunately, it is undefined for $x=2$. While when we set $x=2$ for initial query (Sum[(-1)^s*2^(2s)*Binom(m+s,2s),{s,0,m}]) the answer is following: $$\sum_{s=0}^m{(-1)}^{s}2^{2s}\binom{m+s}{2s} = {(-1)}^m(2m+1)$$ And I still wondering, how to prove that?","I need to find the following sum: $$\sum_{s=0}^{n+1}{(-1)}^{n-s}4^s\binom{n+s+1}{2s}$$ First I tried to simplify this: $$\begin{split} \sum_{s=0}^{n+1}{(-1)}^{n-s}4^s\binom{n+s+1}{2s}  &= {(-1)}^n\sum_{s=0}^{n+1}{(-1)}^{s}2^{2s}\binom{n+s+1}{2s} \\  &= \left[{(-1)}^{m-1}\sum_{s=0}^m{(-1)}^{s}x^{2s}\binom{m+s}{2s}\right](2) \end{split} $$ Now I reduced the problem to the following: ""Find generating function for the following sequence"" $$\sum_{s=0}^m{(-1)}^{s}x^{2s}\binom{m+s}{2s}$$ Does anyone have any ideas how to solve this problem? Because if you put it to the Wolfram|Alpha result is terryfing and I hope that generating function produced by wolfram is too generalized (for any values of x and m). UPD: I put the wrong sequece to Wolfram|Alpha, here is the correct one . So, Wolphram|Alpha says now, that: $$\sum_{s=0}^m{(-1)}^{s}x^{2s}\binom{m+s}{2s} = \frac{2\cos\left((2m+1)\arcsin\left(\frac2x\right)\right)}{\sqrt{4-x^2}}$$ Unfortunately, it is undefined for $x=2$. While when we set $x=2$ for initial query (Sum[(-1)^s*2^(2s)*Binom(m+s,2s),{s,0,m}]) the answer is following: $$\sum_{s=0}^m{(-1)}^{s}2^{2s}\binom{m+s}{2s} = {(-1)}^m(2m+1)$$ And I still wondering, how to prove that?",,"['discrete-mathematics', 'summation', 'binomial-coefficients', 'generating-functions']"
43,Intersection of $\{ [n\sqrt{2}]\mid n \in \mathbb{N}^* \}$ and $\{ [n(2+\sqrt{2})]\mid n \in \mathbb{N}^* \}$,Intersection of  and,\{ [n\sqrt{2}]\mid n \in \mathbb{N}^* \} \{ [n(2+\sqrt{2})]\mid n \in \mathbb{N}^* \},"Find the intersection of sets $A$ and $B$ where $$A = \{ [n\sqrt{2}]\mid n \in \mathbb{N}^* \}$$ $$B = \{ [n(2+\sqrt{2})]\mid n \in \mathbb{N}^* \}.$$ ([$x$] is the integer part of $x$) Using the computer, we found common elements. Does anyone have an idea to solve?","Find the intersection of sets $A$ and $B$ where $$A = \{ [n\sqrt{2}]\mid n \in \mathbb{N}^* \}$$ $$B = \{ [n(2+\sqrt{2})]\mid n \in \mathbb{N}^* \}.$$ ([$x$] is the integer part of $x$) Using the computer, we found common elements. Does anyone have an idea to solve?",,"['elementary-number-theory', 'discrete-mathematics']"
44,Prove that $\sim$ defines an equivalence relation on $\mathbb{Z}$. [duplicate],Prove that  defines an equivalence relation on . [duplicate],\sim \mathbb{Z},"This question already has answers here : Complete set of equivalence class representative (2 answers) Closed 2 years ago . For $a,b \in \mathbb{R}$ define $a \sim b$ if $a - b \in \mathbb{Z}$ I don't understand how I'm suppose to prove this: Prove that $\sim$ defines an equivalence relation on $\mathbb{Z}$ Also can you help me with finding the equivalence class of 5. In other words what I'm trying to describe is the set $[5]$ = {$y : 5 \sim y$}. And $[5]$ is just the name of the set. Edit: Please read my comment below (an attempt to solve this problem) does it make any sense? I'm sorry if I sound really dumb I'm new to this stuff.","This question already has answers here : Complete set of equivalence class representative (2 answers) Closed 2 years ago . For $a,b \in \mathbb{R}$ define $a \sim b$ if $a - b \in \mathbb{Z}$ I don't understand how I'm suppose to prove this: Prove that $\sim$ defines an equivalence relation on $\mathbb{Z}$ Also can you help me with finding the equivalence class of 5. In other words what I'm trying to describe is the set $[5]$ = {$y : 5 \sim y$}. And $[5]$ is just the name of the set. Edit: Please read my comment below (an attempt to solve this problem) does it make any sense? I'm sorry if I sound really dumb I'm new to this stuff.",,"['discrete-mathematics', 'relations', 'equivalence-relations']"
45,Prove that $\lfloor an \rfloor +\lfloor (1-a)n \rfloor = n-1 $,Prove that,\lfloor an \rfloor +\lfloor (1-a)n \rfloor = n-1 ,Given and irrational $a$ and a natural number $n$ prove that $\lfloor an \rfloor +\lfloor (1-a)n \rfloor  = n-1 $. Is this solution correct? $\lfloor an \rfloor +\lfloor (1-a)n  \rfloor = \lfloor an \rfloor +\lfloor n-na \rfloor   =$ (we take out $ n $ because it's an integer) $ \lfloor an \rfloor +n - \lfloor - an \rfloor =$ (because floor of a negative number is a negative of the ceiling of it's positive equivalent) $ \lfloor an \rfloor +n - \lceil an \rceil = n-1$,Given and irrational $a$ and a natural number $n$ prove that $\lfloor an \rfloor +\lfloor (1-a)n \rfloor  = n-1 $. Is this solution correct? $\lfloor an \rfloor +\lfloor (1-a)n  \rfloor = \lfloor an \rfloor +\lfloor n-na \rfloor   =$ (we take out $ n $ because it's an integer) $ \lfloor an \rfloor +n - \lfloor - an \rfloor =$ (because floor of a negative number is a negative of the ceiling of it's positive equivalent) $ \lfloor an \rfloor +n - \lceil an \rceil = n-1$,,['discrete-mathematics']
46,Changing Summation Index Question,Changing Summation Index Question,,"I'm sorry if this seems like a very novice question, but I am still  relatively new to the world of discrete math ( still in 9th grade).  I've been reviewing some of the concepts I learned in a chapter from Concrete Mathematics (Graham,Knuth,Patashnik) about Sums, and I seem to have completely missed something that threw me off. I remember going over this problem, so I decided to re-solve it just to make sure I was 100% percent sure I knew those concepts. But, I've been trying to get it for a while and I still cannot find out the answer to my problem. The problem starts as follows: \begin{equation}    S = \sum_{0 \le k \le n} (a + bk) \end{equation} Using the commutative law, the index $k$ can be re-written as $n-k$ \begin{equation}    S = \sum_{0 \le (n-k) \le n} (a + b(n-k)) \end{equation} And this can then equal \begin{equation}    S = \sum_{0 \le k \le n} (a + bn-bk) \end{equation} My question is not as to how we got $a + bn - bk$, but as to why the index can change from $n-k$ to $k$ from the previous equation? Why and how can this be done?","I'm sorry if this seems like a very novice question, but I am still  relatively new to the world of discrete math ( still in 9th grade).  I've been reviewing some of the concepts I learned in a chapter from Concrete Mathematics (Graham,Knuth,Patashnik) about Sums, and I seem to have completely missed something that threw me off. I remember going over this problem, so I decided to re-solve it just to make sure I was 100% percent sure I knew those concepts. But, I've been trying to get it for a while and I still cannot find out the answer to my problem. The problem starts as follows: \begin{equation}    S = \sum_{0 \le k \le n} (a + bk) \end{equation} Using the commutative law, the index $k$ can be re-written as $n-k$ \begin{equation}    S = \sum_{0 \le (n-k) \le n} (a + b(n-k)) \end{equation} And this can then equal \begin{equation}    S = \sum_{0 \le k \le n} (a + bn-bk) \end{equation} My question is not as to how we got $a + bn - bk$, but as to why the index can change from $n-k$ to $k$ from the previous equation? Why and how can this be done?",,"['discrete-mathematics', 'summation']"
47,Prove $((n+1)!)^n < 2!\cdot4!\cdots(2n)!$,Prove,((n+1)!)^n < 2!\cdot4!\cdots(2n)!,"so I know I need to prove this via induction, but I am somewhat stuck. Here is what I have does so far. Let $p(n) = (n+1)!^n \le 2!\cdot4!\cdot\ldots\cdot(2n)!$ $p(2) = 3!^2\le 2!\cdot4!$ Assume $p(n)$ is true. Prove $p(n+1)$ $p(n+1) = (n+2)!^{n+1}\le 2!\cdot4!\cdot\ldots\cdot(2n+2)!$ $$\begin{align*} &=(n+2)!^n\cdot(n+2)!\le\ldots\\ &=(n+1)!^n\cdot(n+2)^n\cdot(n+2)!\le\ldots \end{align*}$$ Given that $(n+1)!^n\le 2!\cdot4!\cdot\ldots\cdot(2n)!$ (Using Inductive Hypothesis) $$\begin{align*} &=(n+2)^n\cdot(n+2)!\le(2n+2)!\\\\ &=(n+2)^n\le\frac{(2n+2)!}{(n+2)!} \end{align*}$$ And I am stuck here. Any help anyone can give would be helpful.","so I know I need to prove this via induction, but I am somewhat stuck. Here is what I have does so far. Let $p(n) = (n+1)!^n \le 2!\cdot4!\cdot\ldots\cdot(2n)!$ $p(2) = 3!^2\le 2!\cdot4!$ Assume $p(n)$ is true. Prove $p(n+1)$ $p(n+1) = (n+2)!^{n+1}\le 2!\cdot4!\cdot\ldots\cdot(2n+2)!$ $$\begin{align*} &=(n+2)!^n\cdot(n+2)!\le\ldots\\ &=(n+1)!^n\cdot(n+2)^n\cdot(n+2)!\le\ldots \end{align*}$$ Given that $(n+1)!^n\le 2!\cdot4!\cdot\ldots\cdot(2n)!$ (Using Inductive Hypothesis) $$\begin{align*} &=(n+2)^n\cdot(n+2)!\le(2n+2)!\\\\ &=(n+2)^n\le\frac{(2n+2)!}{(n+2)!} \end{align*}$$ And I am stuck here. Any help anyone can give would be helpful.",,"['inequality', 'discrete-mathematics', 'induction', 'factorial']"
48,Convergence of a sequence of partial binomial sums,Convergence of a sequence of partial binomial sums,,"I have a sequence $$a_n = (1-p)^n \sum_{\frac{n}{2}\le k \le n} \binom{n}{k} \left( \frac{p}{1-p} \right)^k.$$ I want to show that $a_n\to 0$ when $n\to\infty$ if $0\le p < \frac{1}{2}$. Here's a plot of the sequence for $p=\frac{1}{3}$: Failed attempt: $$\begin{align} (1-p)^n \sum_{\frac{n}{2}\le k \le n} \binom{n}{k} \left( \frac{p}{1-p} \right)^k <& (1-p)^n \sum_{0 \le k \le n} \binom{n}{k}\left(\frac{p}{1-p}\right)^k \text{ for } n\ge 1\\ =& (1-p)^n \left(1+\frac{p}{1-p}\right)^n = 1. \end{align}$$ My hope here was to end up with something like $0.99^n$ in that last step so I could argue that since $a_n<0.99^n$ and $0.99^n\to 0$ as $n\to\infty$, $a_n\to\infty$. Unfortunately it came out to 1, not $0.99^n$.","I have a sequence $$a_n = (1-p)^n \sum_{\frac{n}{2}\le k \le n} \binom{n}{k} \left( \frac{p}{1-p} \right)^k.$$ I want to show that $a_n\to 0$ when $n\to\infty$ if $0\le p < \frac{1}{2}$. Here's a plot of the sequence for $p=\frac{1}{3}$: Failed attempt: $$\begin{align} (1-p)^n \sum_{\frac{n}{2}\le k \le n} \binom{n}{k} \left( \frac{p}{1-p} \right)^k <& (1-p)^n \sum_{0 \le k \le n} \binom{n}{k}\left(\frac{p}{1-p}\right)^k \text{ for } n\ge 1\\ =& (1-p)^n \left(1+\frac{p}{1-p}\right)^n = 1. \end{align}$$ My hope here was to end up with something like $0.99^n$ in that last step so I could argue that since $a_n<0.99^n$ and $0.99^n\to 0$ as $n\to\infty$, $a_n\to\infty$. Unfortunately it came out to 1, not $0.99^n$.",,"['real-analysis', 'discrete-mathematics', 'binomial-coefficients']"
49,"Consider $f(n) = |\{ k \ |k \in \mathbb{N}, \ \frac{n^k}{k!} \in \mathbb{N} \}|$. Is this function related to the primorial?",Consider . Is this function related to the primorial?,"f(n) = |\{ k \ |k \in \mathbb{N}, \ \frac{n^k}{k!} \in \mathbb{N} \}|","I was playing around with the term $\frac{n^k}{k!}$ . Specifically, given a fixed n, I was wondering for which values of $k$ the term is an integer. Formally Let $f: \mathbb{N} \rightarrow \mathbb{N}, f(n) = |\{ k  \ |k \in \mathbb{N}, \  \frac{n^k}{k!} \in \mathbb{N} \}|$ I wrote a quick python script to compute this: def k_factorial_divisors(n):     k, k_fac, n_k = 1, 1, n     divisors = set()     while k_fac <= n_k:         if n_k % k_fac == 0:             divisors.add(k)         k += 1         k_fac *= k         n_k *= n      return divisors Running this for the first 500 integers yields: print([len(k_factorial_divisors(i+1)) for i in range(500)])  # [1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 10, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 10, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1] I wondered for which n we have $f(n) \gt f(m)$ for all $m \lt n$ . Ie: when this function ""jumps"". A quick search yields: $$f(1) = 1\\ f(2) = 2\\ f(6) = 4\\ f(30) = 6\\ f(210) = 10\\ f(2310) = 12$$ Similarly, there is a repeating pattern up to this new maximum, as can be seen by the first 210 digits 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6,  1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6,  1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 10 These maximums seem to be exactly the primorials. Are they? Why? The numbers seem to cycle, until the new maximum value is reached. Why?","I was playing around with the term . Specifically, given a fixed n, I was wondering for which values of the term is an integer. Formally Let I wrote a quick python script to compute this: def k_factorial_divisors(n):     k, k_fac, n_k = 1, 1, n     divisors = set()     while k_fac <= n_k:         if n_k % k_fac == 0:             divisors.add(k)         k += 1         k_fac *= k         n_k *= n      return divisors Running this for the first 500 integers yields: print([len(k_factorial_divisors(i+1)) for i in range(500)])  # [1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 10, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 10, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1] I wondered for which n we have for all . Ie: when this function ""jumps"". A quick search yields: Similarly, there is a repeating pattern up to this new maximum, as can be seen by the first 210 digits 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6,  1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 6,  1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 4, 1, 2, 1, 2, 1, 10 These maximums seem to be exactly the primorials. Are they? Why? The numbers seem to cycle, until the new maximum value is reached. Why?","\frac{n^k}{k!} k f: \mathbb{N} \rightarrow \mathbb{N}, f(n) = |\{ k  \ |k \in \mathbb{N}, \  \frac{n^k}{k!} \in \mathbb{N} \}| f(n) \gt f(m) m \lt n f(1) = 1\\
f(2) = 2\\
f(6) = 4\\
f(30) = 6\\
f(210) = 10\\
f(2310) = 12","['elementary-number-theory', 'discrete-mathematics', 'prime-numbers']"
50,Find the negative logarithm of $(1+vt^a)^{-1}$,Find the negative logarithm of,(1+vt^a)^{-1},"I’m trying to find the logarithm of this function, but I think I have a mistake with my rules. What I did is: I want to take the $-\log(S(t))$ :- $S(t) = (1+vt^a)^{-1}, v,a>0$ . After applying the rules I got: $\log(1+vt^a)$ Is that correct? Or did I make a mistake? My calculations:","I’m trying to find the logarithm of this function, but I think I have a mistake with my rules. What I did is: I want to take the :- . After applying the rules I got: Is that correct? Or did I make a mistake? My calculations:","-\log(S(t)) S(t) = (1+vt^a)^{-1}, v,a>0 \log(1+vt^a)","['calculus', 'discrete-mathematics', 'logarithms']"
51,Moving Coins (find winning strategy),Moving Coins (find winning strategy),,"I have question about exercise Coin Slide on page 149 I found in ""Thinking Mathematically"" by Mason, Burton and Stacey. Here it is: I was able to solve it successfully for $3-3$ case (original problem) and $4-4$ as well  by try and error ""strategy"". But I'm looking for a conceptional strategy which can be extended to 5-5, 6-6, ...n-n cases. Let denote by $B$ the big circle, by $S$ the small circe, and by $-$ the gap of length of big circle and $.$ the gap of length of small circle. Then the possible solutions for $3-3$ and $4-4$ are: Problem: I solved these two cases more less by try and error and unfortunatelly I ain't recognized a general ""winning strategy"" which can be successfully extended to $n-n$ case. The reason why I think that there exist such general winning strategy to attack every $n-n$ case is author's hint in the exercise: Remember Leapfrogs. The Leapfrog exercise on p 52 is: And the important thing is that elaboration of simpler cases of this exercise reveals a strategy that can easily applied to general cases: That is the straight forward Leapfrog strategy is that after every move the colours in the row should alternate. The point is that since the author gives this Leapfrogs exercise as hint for my original Coin Slide problem, I think that there should be also exist a general winning strategy to attack it independent of $n$ in the $n-n$ case. Does somebody see how this exercise is related to Leapfrogs and what is the successful strategy in this game?","I have question about exercise Coin Slide on page 149 I found in ""Thinking Mathematically"" by Mason, Burton and Stacey. Here it is: I was able to solve it successfully for case (original problem) and as well  by try and error ""strategy"". But I'm looking for a conceptional strategy which can be extended to 5-5, 6-6, ...n-n cases. Let denote by the big circle, by the small circe, and by the gap of length of big circle and the gap of length of small circle. Then the possible solutions for and are: Problem: I solved these two cases more less by try and error and unfortunatelly I ain't recognized a general ""winning strategy"" which can be successfully extended to case. The reason why I think that there exist such general winning strategy to attack every case is author's hint in the exercise: Remember Leapfrogs. The Leapfrog exercise on p 52 is: And the important thing is that elaboration of simpler cases of this exercise reveals a strategy that can easily applied to general cases: That is the straight forward Leapfrog strategy is that after every move the colours in the row should alternate. The point is that since the author gives this Leapfrogs exercise as hint for my original Coin Slide problem, I think that there should be also exist a general winning strategy to attack it independent of in the case. Does somebody see how this exercise is related to Leapfrogs and what is the successful strategy in this game?",3-3 4-4 B S - . 3-3 4-4 n-n n-n n n-n,"['discrete-mathematics', 'logic', 'recreational-mathematics']"
52,How can it be shown that $\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}^{2}a^{n-k}$,How can it be shown that,\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}^{2}a^{n-k},How can it be shown that: $$\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}^{2}a^{n-k}$$ My try: $$\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\sum_{j=0}^{k}\binom{k}{j}a^{j}\left(-1\right)^{k-j}$$ $$=\left(-1\right)^{n}\sum_{k=0}^{n}\binom{n}{k}\binom{-n-1}{n-k}\sum_{j=0}^{k}\binom{k}{j}a^{j}\left(-1\right)^{-j}$$ $$=\left(-1\right)^{n}\sum_{j=0}^{n}\binom{n}{j}a^{j}\left(-1\right)^{-j}\sum_{k=j}^{n}\binom{n-j}{k-j}\binom{-n-1}{n-k}$$ $$=\left(-1\right)^{n}\sum_{j=0}^{n}\binom{n}{j}a^{j}\left(-1\right)^{-j}\binom{-j-1}{n-j}$$ $$=\sum_{j=0}^{n}\binom{n}{j}a^{j}\binom{n}{j}=\sum_{\color{red}{j}=0}^{n}\binom{n}{\color{red}{j}}^2a^{n-\color{red}{j}}$$ The problem is that I have $\color{red}{j}$ instead of $k$ . Source : math.wvu.edu,How can it be shown that: My try: The problem is that I have instead of . Source : math.wvu.edu,\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}^{2}a^{n-k} \sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\sum_{j=0}^{k}\binom{k}{j}a^{j}\left(-1\right)^{k-j} =\left(-1\right)^{n}\sum_{k=0}^{n}\binom{n}{k}\binom{-n-1}{n-k}\sum_{j=0}^{k}\binom{k}{j}a^{j}\left(-1\right)^{-j} =\left(-1\right)^{n}\sum_{j=0}^{n}\binom{n}{j}a^{j}\left(-1\right)^{-j}\sum_{k=j}^{n}\binom{n-j}{k-j}\binom{-n-1}{n-k} =\left(-1\right)^{n}\sum_{j=0}^{n}\binom{n}{j}a^{j}\left(-1\right)^{-j}\binom{-j-1}{n-j} =\sum_{j=0}^{n}\binom{n}{j}a^{j}\binom{n}{j}=\sum_{\color{red}{j}=0}^{n}\binom{n}{\color{red}{j}}^2a^{n-\color{red}{j}} \color{red}{j} k,['discrete-mathematics']
53,Guessing the number of other $1$'s in a binary sequence,Guessing the number of other 's in a binary sequence,1,"Consider the set of all binary sequence of length $n+1$ , $B=\big\{(b_i)_{i=0}^n\,\big| b_i\in\{0,1\}, \forall i\big\}$ . Construct a function $f: \{0,\cdots,n\}\times \{0,1\}\to \{0,\cdots, n\}$ , such that $\forall (b_i)_{i=0}^n\in B,\,\exists i\ni f(i,b_i)=\sum_{j\ne i}b_j$ . What is a systematic way to construct this function? Putting it more colloquially, we assign $n+1$ persons one-to-one to all the digits of an arbitrary binary sequence of length $n+1$ . Each person can see but the digit assigned to him. Devise a strategy so that at least one person guesses correctly the sum of the remaining digits other than his own. Epilogue: It was answered brilliantly on Mathoverflow.net after I posted the question there.","Consider the set of all binary sequence of length , . Construct a function , such that . What is a systematic way to construct this function? Putting it more colloquially, we assign persons one-to-one to all the digits of an arbitrary binary sequence of length . Each person can see but the digit assigned to him. Devise a strategy so that at least one person guesses correctly the sum of the remaining digits other than his own. Epilogue: It was answered brilliantly on Mathoverflow.net after I posted the question there.","n+1 B=\big\{(b_i)_{i=0}^n\,\big| b_i\in\{0,1\}, \forall i\big\} f: \{0,\cdots,n\}\times \{0,1\}\to \{0,\cdots, n\} \forall (b_i)_{i=0}^n\in B,\,\exists i\ni f(i,b_i)=\sum_{j\ne i}b_j n+1 n+1","['discrete-mathematics', 'recreational-mathematics', 'puzzle', 'information-theory', 'coding-theory']"
54,binary search tree with key values $ a_1 < \dots < a_k$. How do I choose $j$ to still get a tree with minimal height?,binary search tree with key values . How do I choose  to still get a tree with minimal height?, a_1 < \dots < a_k j,"So at the beginning I have an empty binary search tree. Moreover I have key values $a_1 < \dots < a_k$ . How can we choose $j$ so that after the first insert of an element with key value $a_j$ a tree of minimal height is still possible by further insertions. My thoughts: My first idea was to choose $j=1$ ( later $j=k$ ), which is obviously false. I know that we somehow have to use the fact that we have $a_1 < \dots < a_k$ . Maybe we could choose $j = \frac{k}{2}$ or something like that. But this is just an idea. I don't know how to argue for that.","So at the beginning I have an empty binary search tree. Moreover I have key values . How can we choose so that after the first insert of an element with key value a tree of minimal height is still possible by further insertions. My thoughts: My first idea was to choose ( later ), which is obviously false. I know that we somehow have to use the fact that we have . Maybe we could choose or something like that. But this is just an idea. I don't know how to argue for that.",a_1 < \dots < a_k j a_j j=1 j=k a_1 < \dots < a_k j = \frac{k}{2},"['discrete-mathematics', 'trees', 'binary']"
55,Consider a triangle-free graph $G:|V(G)|=n$ and show that $\chi{(G)}\leq\lfloor 2\sqrt{n}\rfloor$,Consider a triangle-free graph  and show that,G:|V(G)|=n \chi{(G)}\leq\lfloor 2\sqrt{n}\rfloor,"I've seen this question being asked on here before but I haven't been able to solve this problem with the provided answers. If it is of any use I've been able to prove that $G$ has an independent set $S:|S|= \lfloor \sqrt{n} \rfloor$ but I don't really know what I can do with this. How can I go about proving this? I'm only looking for some ideas, not a full proof. Edit: As you can see in the conversation below a person was kind enough to try to help me but I didn't get anywhere. Are there any further tips that can be given such that I can prove this theorem without actually giving away all of it? Thus far I've been unable to solve this problem and thus far all other students in my class have failed as well.","I've seen this question being asked on here before but I haven't been able to solve this problem with the provided answers. If it is of any use I've been able to prove that has an independent set but I don't really know what I can do with this. How can I go about proving this? I'm only looking for some ideas, not a full proof. Edit: As you can see in the conversation below a person was kind enough to try to help me but I didn't get anywhere. Are there any further tips that can be given such that I can prove this theorem without actually giving away all of it? Thus far I've been unable to solve this problem and thus far all other students in my class have failed as well.",G S:|S|= \lfloor \sqrt{n} \rfloor,"['discrete-mathematics', 'graph-theory']"
56,the difference between $\emptyset$ and $\{\emptyset\}$? [duplicate],the difference between  and ? [duplicate],\emptyset \{\emptyset\},"This question already has answers here : Is ∅ equivalent to {∅}? [duplicate] (4 answers) Closed 5 years ago . What is the difference between $\emptyset$ and $\{\emptyset\}$ ? I am reading from some notes and author denotes the empty set by $\{\emptyset\}$ . I am getting confused as definition says In mathematics, and more specifically set theory, the empty set or   null set is the unique set having no elements I think $\{\emptyset\}$ is wrong notation as that implies that it has one element. More specifically it should be the notation of power set of $\emptyset$","This question already has answers here : Is ∅ equivalent to {∅}? [duplicate] (4 answers) Closed 5 years ago . What is the difference between and ? I am reading from some notes and author denotes the empty set by . I am getting confused as definition says In mathematics, and more specifically set theory, the empty set or   null set is the unique set having no elements I think is wrong notation as that implies that it has one element. More specifically it should be the notation of power set of",\emptyset \{\emptyset\} \{\emptyset\} \{\emptyset\} \emptyset,"['real-analysis', 'discrete-mathematics', 'elementary-set-theory']"
57,What is $15^{15} + 16^{16} + 17^{17} + 18^{18} + 19^{19} + 20^{20} \pmod{7}$?,What is ?,15^{15} + 16^{16} + 17^{17} + 18^{18} + 19^{19} + 20^{20} \pmod{7},"I am trying to evaluate $15^{15} + 16^{16} + 17^{17} + 18^{18} + 19^{19} + 20^{20} \pmod{7}$ . I have found that $15^{15} \equiv 1 \pmod{7}$ and that $16^{16} \equiv 2 \pmod{7}$ . To evaluate $15^{15} \pmod{17}$ , I did the following: $$15 = 2 \times 7 + 1 \equiv 1 \pmod{7}$$ $$15^{15} \equiv 1 \pmod{7}$$ Then, to evaluate $16^{16}$ , I wrote: $$16 = 15 + 1 \equiv 1 + 1 = 2 \pmod{7}$$ $$16^{16} \equiv 2^{16} \pmod{7}$$ $$2^{3} = 8 = 7+1 \equiv 1 \pmod{7}$$ $$2^{16} = 2^{3} \times 2^{13} \equiv 2^{13} = 2^{3} \times 2^{10} \equiv 2^{10} \equiv \dots \equiv 2 \pmod{7}$$ Nevertheless, I have not managed to figure out how to evaluate $17^{17}$ . How should I go about this and is my overall approach for evaluating the sum in question a good one?","I am trying to evaluate . I have found that and that . To evaluate , I did the following: Then, to evaluate , I wrote: Nevertheless, I have not managed to figure out how to evaluate . How should I go about this and is my overall approach for evaluating the sum in question a good one?",15^{15} + 16^{16} + 17^{17} + 18^{18} + 19^{19} + 20^{20} \pmod{7} 15^{15} \equiv 1 \pmod{7} 16^{16} \equiv 2 \pmod{7} 15^{15} \pmod{17} 15 = 2 \times 7 + 1 \equiv 1 \pmod{7} 15^{15} \equiv 1 \pmod{7} 16^{16} 16 = 15 + 1 \equiv 1 + 1 = 2 \pmod{7} 16^{16} \equiv 2^{16} \pmod{7} 2^{3} = 8 = 7+1 \equiv 1 \pmod{7} 2^{16} = 2^{3} \times 2^{13} \equiv 2^{13} = 2^{3} \times 2^{10} \equiv 2^{10} \equiv \dots \equiv 2 \pmod{7} 17^{17},"['discrete-mathematics', 'modular-arithmetic']"
58,History and connecting math to real world,History and connecting math to real world,,"I am software developer with big interest in Mathematics and especially discrete mathematics (which is foundational for computer science). I am currently reading Discrete Mathematics and Its Applications but I feel like I am still lacking connection or history/background between theories and how to apply them. For example, I read about Conjunctive Normal Forms and then I start wondering who created them and what do they solve? what problem they were facing to introduce them? To put it in different terms, most math books seem to miss the narrative or the story or conceptual information on why a certain topic was introduced. They feel more like reference books where they document corollaries, theories or definitions one after the other. Some times the books answer these questions but most of the times they don't Is there any references for resources that might help in this area other than Googling for it all the time? Am I approaching learning these concepts the wrong way? What do you recommend based on your experience? How do you get real intuition for math concepts?","I am software developer with big interest in Mathematics and especially discrete mathematics (which is foundational for computer science). I am currently reading Discrete Mathematics and Its Applications but I feel like I am still lacking connection or history/background between theories and how to apply them. For example, I read about Conjunctive Normal Forms and then I start wondering who created them and what do they solve? what problem they were facing to introduce them? To put it in different terms, most math books seem to miss the narrative or the story or conceptual information on why a certain topic was introduced. They feel more like reference books where they document corollaries, theories or definitions one after the other. Some times the books answer these questions but most of the times they don't Is there any references for resources that might help in this area other than Googling for it all the time? Am I approaching learning these concepts the wrong way? What do you recommend based on your experience? How do you get real intuition for math concepts?",,"['discrete-mathematics', 'computer-science', 'self-learning', 'applications']"
59,"Bipartite graph $G=(A,B)$ with $\delta(A)=3n/2$ and no $C_4$ has a matching which saturate each vertex in $A$.",Bipartite graph  with  and no  has a matching which saturate each vertex in .,"G=(A,B) \delta(A)=3n/2 C_4 A","Say $G$ is a bipartite graph with bipartition $(A,B)$ and $G$ is $C_4$ -free. Prove that if every vertex in $A$ has degree at least $\frac32 n$ and $|A|\leq n^2$ , then $G$ has a matching which uses every vertex in $A$ . My proof: Use the Hall marriage theorem. Take any $X\subseteq A$ and let $|X|=k$ . Also let $Y=N(X)$ and $|Y|=l$ . Let us prove that $l\geq k$ . Assume that $l<k$ . Let $Y^*$ be a set of all unordered pairs $\{y_i,y_j\}$ , $i\ne j$ of elements in $Y$ , and connect a pair $\{y_i,y_j\}$ with $x\in X$ iff both $y_i$ and $y_j$ are adjacent with $x$ in $G$ . Then the degree of each pair in this new bipartite graph $G^*$ (on vertex set $X \cup Y^*$ ) is at most $1$ (since there is no $C_4$ in $G$ ) and the degree of each $x\in X$ is at least $\displaystyle{{3n\over 2}\choose 2}$ . So we have $$k\cdot {{3n\over 2}\choose 2}\leq {l\choose 2} .$$ Since we assume $l<k$ we have $${{3n\over 2}\choose 2}< {k-1\over 2}$$ so $${3n(3n-2)\over 4} < k-1 .$$ Since $k\leq n^2$ we have $$3n(3n-2) \leq  4n^2-8$$ so $$5n^2\leq 6n-8$$ which is obviously not true. Edit: After Darij's confirmation that the proof is correct, I will award any solution with better bound than $\delta (G)=n\sqrt{2}$ (instead of $3n/2$ ).","Say is a bipartite graph with bipartition and is -free. Prove that if every vertex in has degree at least and , then has a matching which uses every vertex in . My proof: Use the Hall marriage theorem. Take any and let . Also let and . Let us prove that . Assume that . Let be a set of all unordered pairs , of elements in , and connect a pair with iff both and are adjacent with in . Then the degree of each pair in this new bipartite graph (on vertex set ) is at most (since there is no in ) and the degree of each is at least . So we have Since we assume we have so Since we have so which is obviously not true. Edit: After Darij's confirmation that the proof is correct, I will award any solution with better bound than (instead of ).","G (A,B) G C_4 A \frac32 n |A|\leq n^2 G A X\subseteq A |X|=k Y=N(X) |Y|=l l\geq k l<k Y^* \{y_i,y_j\} i\ne j Y \{y_i,y_j\} x\in X y_i y_j x G G^* X \cup Y^* 1 C_4 G x\in X \displaystyle{{3n\over 2}\choose 2} k\cdot {{3n\over 2}\choose 2}\leq {l\choose 2} . l<k {{3n\over 2}\choose 2}< {k-1\over 2} {3n(3n-2)\over 4} < k-1 . k\leq n^2 3n(3n-2) \leq  4n^2-8 5n^2\leq 6n-8 \delta (G)=n\sqrt{2} 3n/2","['discrete-mathematics', 'graph-theory', 'solution-verification', 'bipartite-graphs', 'matching-theory']"
60,Asymptotics for partial sum of product of binomial coefficients,Asymptotics for partial sum of product of binomial coefficients,,"For some fixed $0<p<1$, let $np\leq c<n$ and $2np\leq x< 2n$. Are there references or previous results for determining the asymptotics (as $n\to\infty$) of the partial sum $$ \sum_{k=x-c}^c\binom{n}{k}\binom{n}{x-k} $$ or equivalently if $c=n\lambda_1$ and $x=2n\lambda_2$, for constants $p\leq\lambda_2\leq\lambda_1<1$ $$ \sum_{k=2n\lambda_2-n\lambda_1}^{n\lambda_1}\binom{n}{k}\binom{n}{2n\lambda_2-k} $$ I don't think I can just apply Stirling's approximations to the binomial coefficients individual and take the sum and product. EDIT Could someone comment if this is a valid attempt? Using @robjohn's solution in this post , let  $$ a_k=\binom{n}{k}\binom{n}{2n\lambda_2-k} $$ Then letting $k=n\lambda_2+j$, $$ \log\left(\frac{a_{k+1}}{a_k}\right)=-\frac{2j}{n\lambda_2(1-\lambda_2)}+O(n^{-1}) $$ Thus, $$ a_k=a_{n\lambda_2}\exp\left(-\frac{2j^2}{n\lambda_2(1-\lambda_2)}+O(j/n)\right) $$ Estimating  $$ a_{n\lambda_2}\sim C(\lambda_2)=\frac{1}{2\pi n\lambda_2(1-\lambda_2)}(1-\lambda_2)^{-2n}\left(\frac{1-\lambda_2}{\lambda_2}\right)^{2n\lambda_2} $$ by Stirling's formula and using Riemann integral for the exponential, $$ \sum_{j=-n(\lambda_1-\lambda_2)}^{n(\lambda_1-\lambda_2)}\exp\left(-\frac{2j^2}{n\lambda_2(1-\lambda_2)}+O(j/n)\right)=\sqrt{n\lambda_2(1-\lambda_2)}\int_{-\infty}^{\infty}\exp\left(-2t^2\right)dt(1+O(1/n)) $$ we have \begin{eqnarray} \sum_{k=2n\lambda_2-n\lambda_1}^{n\lambda_1}\binom{n}{k}\binom{n}{2n\lambda_2-k}&\sim& C(\lambda_2)\sqrt{n\lambda_2(1-\lambda_2)}\sqrt{\pi/2}\\ &=&\frac{1}{2\sqrt{2\pi n\lambda_2(1-\lambda_2)}}(1-\lambda_2)^{-2n}\left(\frac{1-\lambda_2}{\lambda_2}\right)^{2n\lambda_2} \end{eqnarray} Substituting back $c=n\lambda_1$ and $x=2n\lambda_2$, and noticing Stirling's formula for $\binom{2n}{x}$, we get $$ \sum_{k=x-c}^c\binom{n}{k}\binom{n}{x-k}\sim\frac{1}{\sqrt{2}}\sqrt{\frac{2n}{2\pi x(2n-x)}}\left(\frac{2n}{2n-x}\right)^{2n}\left(\frac{2n-x}{x}\right)^x\sim \frac{1}{\sqrt{2}}\binom{2n}{x} $$ To me this is very interesting that it doesn't involve $c$, which disappeared when estimating with the Riemann integral above. However, after plugging in a couple of values in Mathematica, the approximation on the right hand side doesn't always give an accurate approximation to the partial sum. QUESTION 2 Is there a way to figure out how far this partial sum is from the upper bound of $\binom{2n}{x}$? EDIT 2 It turns out that  $$ \sum_{k=x-c}^c\binom{n}{k}\binom{n}{x-k}=\binom{2n}{x}-2\sum_{k=0}^{x-c-1}\binom{n}{k}\binom{n}{x-k} $$ I guess, then I'm interested in showing if  $$ 2\sum_{k=0}^{x-c-1}\binom{n}{k}\binom{n}{x-k}=o\left(\binom{2n}{x}\right) $$ How would I go about showing this?","For some fixed $0<p<1$, let $np\leq c<n$ and $2np\leq x< 2n$. Are there references or previous results for determining the asymptotics (as $n\to\infty$) of the partial sum $$ \sum_{k=x-c}^c\binom{n}{k}\binom{n}{x-k} $$ or equivalently if $c=n\lambda_1$ and $x=2n\lambda_2$, for constants $p\leq\lambda_2\leq\lambda_1<1$ $$ \sum_{k=2n\lambda_2-n\lambda_1}^{n\lambda_1}\binom{n}{k}\binom{n}{2n\lambda_2-k} $$ I don't think I can just apply Stirling's approximations to the binomial coefficients individual and take the sum and product. EDIT Could someone comment if this is a valid attempt? Using @robjohn's solution in this post , let  $$ a_k=\binom{n}{k}\binom{n}{2n\lambda_2-k} $$ Then letting $k=n\lambda_2+j$, $$ \log\left(\frac{a_{k+1}}{a_k}\right)=-\frac{2j}{n\lambda_2(1-\lambda_2)}+O(n^{-1}) $$ Thus, $$ a_k=a_{n\lambda_2}\exp\left(-\frac{2j^2}{n\lambda_2(1-\lambda_2)}+O(j/n)\right) $$ Estimating  $$ a_{n\lambda_2}\sim C(\lambda_2)=\frac{1}{2\pi n\lambda_2(1-\lambda_2)}(1-\lambda_2)^{-2n}\left(\frac{1-\lambda_2}{\lambda_2}\right)^{2n\lambda_2} $$ by Stirling's formula and using Riemann integral for the exponential, $$ \sum_{j=-n(\lambda_1-\lambda_2)}^{n(\lambda_1-\lambda_2)}\exp\left(-\frac{2j^2}{n\lambda_2(1-\lambda_2)}+O(j/n)\right)=\sqrt{n\lambda_2(1-\lambda_2)}\int_{-\infty}^{\infty}\exp\left(-2t^2\right)dt(1+O(1/n)) $$ we have \begin{eqnarray} \sum_{k=2n\lambda_2-n\lambda_1}^{n\lambda_1}\binom{n}{k}\binom{n}{2n\lambda_2-k}&\sim& C(\lambda_2)\sqrt{n\lambda_2(1-\lambda_2)}\sqrt{\pi/2}\\ &=&\frac{1}{2\sqrt{2\pi n\lambda_2(1-\lambda_2)}}(1-\lambda_2)^{-2n}\left(\frac{1-\lambda_2}{\lambda_2}\right)^{2n\lambda_2} \end{eqnarray} Substituting back $c=n\lambda_1$ and $x=2n\lambda_2$, and noticing Stirling's formula for $\binom{2n}{x}$, we get $$ \sum_{k=x-c}^c\binom{n}{k}\binom{n}{x-k}\sim\frac{1}{\sqrt{2}}\sqrt{\frac{2n}{2\pi x(2n-x)}}\left(\frac{2n}{2n-x}\right)^{2n}\left(\frac{2n-x}{x}\right)^x\sim \frac{1}{\sqrt{2}}\binom{2n}{x} $$ To me this is very interesting that it doesn't involve $c$, which disappeared when estimating with the Riemann integral above. However, after plugging in a couple of values in Mathematica, the approximation on the right hand side doesn't always give an accurate approximation to the partial sum. QUESTION 2 Is there a way to figure out how far this partial sum is from the upper bound of $\binom{2n}{x}$? EDIT 2 It turns out that  $$ \sum_{k=x-c}^c\binom{n}{k}\binom{n}{x-k}=\binom{2n}{x}-2\sum_{k=0}^{x-c-1}\binom{n}{k}\binom{n}{x-k} $$ I guess, then I'm interested in showing if  $$ 2\sum_{k=0}^{x-c-1}\binom{n}{k}\binom{n}{x-k}=o\left(\binom{2n}{x}\right) $$ How would I go about showing this?",,"['discrete-mathematics', 'reference-request', 'asymptotics', 'binomial-coefficients']"
61,Show that exactly half of the integers in the set are quadratic residues,Show that exactly half of the integers in the set are quadratic residues,,"Let p be an odd prime. Show that exactly half of the integers in the set {1,2,...,p− 1} are quadratic residues. Can somebody please dumb down the solution to this? I'm in the process of learning about modulo. Thank you!","Let p be an odd prime. Show that exactly half of the integers in the set {1,2,...,p− 1} are quadratic residues. Can somebody please dumb down the solution to this? I'm in the process of learning about modulo. Thank you!",,"['elementary-number-theory', 'discrete-mathematics']"
62,Determining asymptotic bounds on $T(n) = \sqrt{n}T(\sqrt{n})+n$,Determining asymptotic bounds on,T(n) = \sqrt{n}T(\sqrt{n})+n,"Note: this is from JeffE's Algorithms notes on Recurrences, page 5: http://jeffe.cs.illinois.edu/teaching/algorithms/notes/99-recurrences.pdf (1). So we define the recurrence $T(n) = \sqrt{n}T(\sqrt{n})+n$ without any base case. Now I understand that for most recurrences, since we're looking for asymptotic bounds, the base case wouldn't matter. But in this case, I don't even see where we could define the base case. Is there any number we are guaranteed to hit as we keep taking square roots starting from any integer Do we just define $T(n) = a$ for $n<b$, for some reals $a$, $b$? (2). On page 7, Erickson gets that the number of layers in the recursion tree L will satisfy $n^{{2}^{-L}} = 2$. Where is this coming from? I have no idea. I see that the number of leaves in each level of the tree should sum to $\sqrt(n)\sqrt(n) = n$, but I have no idea where to go from there. (3). From the result mentioned in (2). Erickson derives $T(n) = \theta(n\lg\lg(n))$. But unrolling the recurrence yields       $$T(n) = n^{\sum\limits_{i=1}^k  \frac{1}{2^{i}}}T(n^{\frac{1}{2^k}})+kn \leq (k+1)n $$ For any integer k. Wouldn't this mean $T(n) = O(n)$, contradicting $T(n) = \theta(n\lg \lg(n)$? Where is my reasoning wrong? (Please know that I ask with complete confidence that it is wrong). This is also posted on the computer science stack exchange, because of the overlap in topics. Any help is appreciated!","Note: this is from JeffE's Algorithms notes on Recurrences, page 5: http://jeffe.cs.illinois.edu/teaching/algorithms/notes/99-recurrences.pdf (1). So we define the recurrence $T(n) = \sqrt{n}T(\sqrt{n})+n$ without any base case. Now I understand that for most recurrences, since we're looking for asymptotic bounds, the base case wouldn't matter. But in this case, I don't even see where we could define the base case. Is there any number we are guaranteed to hit as we keep taking square roots starting from any integer Do we just define $T(n) = a$ for $n<b$, for some reals $a$, $b$? (2). On page 7, Erickson gets that the number of layers in the recursion tree L will satisfy $n^{{2}^{-L}} = 2$. Where is this coming from? I have no idea. I see that the number of leaves in each level of the tree should sum to $\sqrt(n)\sqrt(n) = n$, but I have no idea where to go from there. (3). From the result mentioned in (2). Erickson derives $T(n) = \theta(n\lg\lg(n))$. But unrolling the recurrence yields       $$T(n) = n^{\sum\limits_{i=1}^k  \frac{1}{2^{i}}}T(n^{\frac{1}{2^k}})+kn \leq (k+1)n $$ For any integer k. Wouldn't this mean $T(n) = O(n)$, contradicting $T(n) = \theta(n\lg \lg(n)$? Where is my reasoning wrong? (Please know that I ask with complete confidence that it is wrong). This is also posted on the computer science stack exchange, because of the overlap in topics. Any help is appreciated!",,"['discrete-mathematics', 'recurrence-relations']"
63,"How many connected, simple graphs are on n vertices","How many connected, simple graphs are on n vertices",,"I'm trying to find a formula that will give me the number of connected, simple graphs on n vertices, not taking in consideration isomorphism. I though that it can be done by taking the difference between the total number of possible graphs and disconnected graphs. We will have : $2^{\binom{n}{2}}$ , where $\binom{n}{2}$ will determine the number of possible edges(this will give us total number of possible graphs) The disconnected graphs will consist of $n-2, n-3 ...$ edges(since $n-1$ is a tree). The number of disconnected graphs will depend on number of vertices, so I though it would be equal to $\sum_{i=2}^{n-1}(2^{\binom{n}{2} -i})$. Altogether : $2^{\binom{n}{2}}-\sum_{i=2}^{n-1}(2^{\binom{n}{2} -i})$ . And I'm stuck here. What would be a correct approach to this problem?","I'm trying to find a formula that will give me the number of connected, simple graphs on n vertices, not taking in consideration isomorphism. I though that it can be done by taking the difference between the total number of possible graphs and disconnected graphs. We will have : $2^{\binom{n}{2}}$ , where $\binom{n}{2}$ will determine the number of possible edges(this will give us total number of possible graphs) The disconnected graphs will consist of $n-2, n-3 ...$ edges(since $n-1$ is a tree). The number of disconnected graphs will depend on number of vertices, so I though it would be equal to $\sum_{i=2}^{n-1}(2^{\binom{n}{2} -i})$. Altogether : $2^{\binom{n}{2}}-\sum_{i=2}^{n-1}(2^{\binom{n}{2} -i})$ . And I'm stuck here. What would be a correct approach to this problem?",,"['discrete-mathematics', 'graph-theory']"
64,Number of solutions of $x_1+2\cdot x_2+2\cdot x_3 = n$,Number of solutions of,x_1+2\cdot x_2+2\cdot x_3 = n,"I have to find number of solutions of $x_1+2\cdot x_2+2\cdot x_3 = n$. I guess it would be $[x^n](1+x+x^2 \dots)(1 + x^2 + x^4 \dots)^2$, but how to compute it? I know only that $\frac{1}{1-x} = 1+x+x^2 \dots$.","I have to find number of solutions of $x_1+2\cdot x_2+2\cdot x_3 = n$. I guess it would be $[x^n](1+x+x^2 \dots)(1 + x^2 + x^4 \dots)^2$, but how to compute it? I know only that $\frac{1}{1-x} = 1+x+x^2 \dots$.",,"['discrete-mathematics', 'generating-functions']"
65,"Directed graph, partition","Directed graph, partition",,"Let $D=(V,E)$ be a finite directed graph with no isolated nodes(from every node there is at least one edge entering and one exiting, i.e there are no sources or sinks). For $v \in V$ define the following sets: $$v^+= \left\{w \in V|(v,w)\in E \right\}, v^-= \left\{w \in V|(w,v)\in E \right\}$$ For some $S \subseteq V, S^+= \bigcup_{v \in S} v^+, S^-= \bigcup_{v \in S} v^-$ Now define two related graphs, $G_{cp}=(V,E_{cp}),G_{ce}=(V,E_{ce})$ such that for two distinct nodes $v,w \in V$ we have $vw \in E_{cp}$ iff $v^+ \cap w^+ \neq \emptyset$  and $vw \in E_{ce}$ iff  $v^- \cap w^- \neq \emptyset$ Let $B_1,B_2,...,B_p$ be the sets of nodes of the connected components of $G_{cp}$ and $A_1,A_2,...,A_k$ be the set of connected components of $G_{ce}$. Obviously those sets are two partitions of $V$ Prove that $(B^+_1,B^+_2,...,B^+_p)$ and $(A^-_1,A^-_2,...,A^-_k)$ represent partitions of $V$. Also prove that $p=k$ (that is both graphs have the same number of connected components). To prove the first part I thought about taking some arbitrary $v \in V$ and than proving that $v$ is in $(B^+_1,B^+_2,...,B^+_p)$. Then a proof by contradiction may be required to complete the first part, but I can't quite seem to make the connection. I don't even know how to start proving $p=k$ Additional note The notation cp and ce comes from ""common prey"" and ""common enemy"" Update I managed to sketch a proof for the first part along the lines I talked about. Proof by contradiction works. I still need help in proving $p=k$","Let $D=(V,E)$ be a finite directed graph with no isolated nodes(from every node there is at least one edge entering and one exiting, i.e there are no sources or sinks). For $v \in V$ define the following sets: $$v^+= \left\{w \in V|(v,w)\in E \right\}, v^-= \left\{w \in V|(w,v)\in E \right\}$$ For some $S \subseteq V, S^+= \bigcup_{v \in S} v^+, S^-= \bigcup_{v \in S} v^-$ Now define two related graphs, $G_{cp}=(V,E_{cp}),G_{ce}=(V,E_{ce})$ such that for two distinct nodes $v,w \in V$ we have $vw \in E_{cp}$ iff $v^+ \cap w^+ \neq \emptyset$  and $vw \in E_{ce}$ iff  $v^- \cap w^- \neq \emptyset$ Let $B_1,B_2,...,B_p$ be the sets of nodes of the connected components of $G_{cp}$ and $A_1,A_2,...,A_k$ be the set of connected components of $G_{ce}$. Obviously those sets are two partitions of $V$ Prove that $(B^+_1,B^+_2,...,B^+_p)$ and $(A^-_1,A^-_2,...,A^-_k)$ represent partitions of $V$. Also prove that $p=k$ (that is both graphs have the same number of connected components). To prove the first part I thought about taking some arbitrary $v \in V$ and than proving that $v$ is in $(B^+_1,B^+_2,...,B^+_p)$. Then a proof by contradiction may be required to complete the first part, but I can't quite seem to make the connection. I don't even know how to start proving $p=k$ Additional note The notation cp and ce comes from ""common prey"" and ""common enemy"" Update I managed to sketch a proof for the first part along the lines I talked about. Proof by contradiction works. I still need help in proving $p=k$",,"['discrete-mathematics', 'graph-theory']"
66,Solving the recurrence $T(n) = \sqrt n T(\sqrt{n}) + \sqrt{n}$,Solving the recurrence,T(n) = \sqrt n T(\sqrt{n}) + \sqrt{n},"A former student of mine was TA-ing an algorithms class last quarter and asked students to solve this famous recurrence relation: $$T(n) = \sqrt n T(\sqrt{n}) + n$$ There are several ways to solve this recurrence relation and this question has already been asked here. I was talking to my student about this problem and mentioned that it's quite hard to solve and is pretty dependent on the particular choices being made. As an example, I suggested this variant of a recurrence relation that was less simple to solve: $$T(n) = \sqrt n T(\sqrt{n}) + \sqrt{n}$$ The TA and I tried solving this recurrence for about an hour and a half without making any progress. Here are a few things we tried: My approach to solving the initial recurrence relation was to draw out a recursion tree and notice that each level of the tree contributes $n$ to the total and that there are $O(\log \log n)$ layers, so the recurrence solves to $O(n \log \log n)$. When I tried doing this here, I noticed that the work per layer was no longer constant; instead, the top layer sums to $\sqrt{n}$, the second layer to $n^{3/4}$, the third to $n^{7/8}$, etc. We got stuck working with the summation $n^{1/2} + n^{3/4} + n^{7/8} + ...$. We tried using the iteration method to unroll the recurrence. With the original recurrence relation, this works out nicely; here, we got stuck at the same summation given above. I'm completely stuck trying to figure out how to solve this recurrence relation. There's nothing riding on it per se - I don't need to solve it for any particular reason - but the fact that we arrived at it by a straightforward modification of a common algorithms problem set question makes it all the more enticing. Any idea how to solve this recurrence? Thanks!","A former student of mine was TA-ing an algorithms class last quarter and asked students to solve this famous recurrence relation: $$T(n) = \sqrt n T(\sqrt{n}) + n$$ There are several ways to solve this recurrence relation and this question has already been asked here. I was talking to my student about this problem and mentioned that it's quite hard to solve and is pretty dependent on the particular choices being made. As an example, I suggested this variant of a recurrence relation that was less simple to solve: $$T(n) = \sqrt n T(\sqrt{n}) + \sqrt{n}$$ The TA and I tried solving this recurrence for about an hour and a half without making any progress. Here are a few things we tried: My approach to solving the initial recurrence relation was to draw out a recursion tree and notice that each level of the tree contributes $n$ to the total and that there are $O(\log \log n)$ layers, so the recurrence solves to $O(n \log \log n)$. When I tried doing this here, I noticed that the work per layer was no longer constant; instead, the top layer sums to $\sqrt{n}$, the second layer to $n^{3/4}$, the third to $n^{7/8}$, etc. We got stuck working with the summation $n^{1/2} + n^{3/4} + n^{7/8} + ...$. We tried using the iteration method to unroll the recurrence. With the original recurrence relation, this works out nicely; here, we got stuck at the same summation given above. I'm completely stuck trying to figure out how to solve this recurrence relation. There's nothing riding on it per se - I don't need to solve it for any particular reason - but the fact that we arrived at it by a straightforward modification of a common algorithms problem set question makes it all the more enticing. Any idea how to solve this recurrence? Thanks!",,"['discrete-mathematics', 'recurrence-relations']"
67,Discrete math problems,Discrete math problems,,"I am a high school student interested in thinking about math. I don't know a lot of high-powered math (I only know up to calculus), instead I focus on discrete topics related to math Olympiads (combinatorics, number theory, geometry etc). Olympiad problems typically take 2-3 hours to solve. I want to start thinking about interesting problems over extended periods of time. So I am wondering where I can find a bank of problems that satisfy the following criteria: they are simply stated, related to discrete topics (not graduate level math please), and are difficult enough that they cannot be solved in a day, but not as difficult as full fledged research problems. I am not talking about open problems nessecarily; I don't want to think about something like the Collatz conjecture, since that is too difficult as its been open for a long time. I am sorry if I'm not being clear, but I dont know what more specifics I can give. Maybe someone can help me narrow down what I'm actually asking?","I am a high school student interested in thinking about math. I don't know a lot of high-powered math (I only know up to calculus), instead I focus on discrete topics related to math Olympiads (combinatorics, number theory, geometry etc). Olympiad problems typically take 2-3 hours to solve. I want to start thinking about interesting problems over extended periods of time. So I am wondering where I can find a bank of problems that satisfy the following criteria: they are simply stated, related to discrete topics (not graduate level math please), and are difficult enough that they cannot be solved in a day, but not as difficult as full fledged research problems. I am not talking about open problems nessecarily; I don't want to think about something like the Collatz conjecture, since that is too difficult as its been open for a long time. I am sorry if I'm not being clear, but I dont know what more specifics I can give. Maybe someone can help me narrow down what I'm actually asking?",,"['discrete-mathematics', 'soft-question', 'big-list']"
68,Find all integer solution,Find all integer solution,,"Find all integer solutions such that $$a+1|2a^2+9$$ Solution . I could solve this by writing $$\frac{2a^2+9}{a+1}=2a-2+\frac{11}{a+1}.$$ So, the only integer solution for the last equation are $a=10, a=-12.$ But, i want to get a solution using divisibility properties.","Find all integer solutions such that $$a+1|2a^2+9$$ Solution . I could solve this by writing $$\frac{2a^2+9}{a+1}=2a-2+\frac{11}{a+1}.$$ So, the only integer solution for the last equation are $a=10, a=-12.$ But, i want to get a solution using divisibility properties.",,['discrete-mathematics']
69,Uses of integral calculus in discrete mathematics?,Uses of integral calculus in discrete mathematics?,,"I have to do a project in my integral calculus class. But all the topics are too mainstream (parabolic arc calculation,archimedean approzimation of circle are,obtaining $E=mc^2\dots$ However I'm really into discrete maths right now and I would like to use integral calculus for my project in discrete mathematics? Is this viable? What are some topics I could persue?(Things I am really into right now are combinatorial identities, graph theory,abstract algebra and category theory). Thank you very much in advance, forgive me if this question is innapropriate. Best Wishes.","I have to do a project in my integral calculus class. But all the topics are too mainstream (parabolic arc calculation,archimedean approzimation of circle are,obtaining $E=mc^2\dots$ However I'm really into discrete maths right now and I would like to use integral calculus for my project in discrete mathematics? Is this viable? What are some topics I could persue?(Things I am really into right now are combinatorial identities, graph theory,abstract algebra and category theory). Thank you very much in advance, forgive me if this question is innapropriate. Best Wishes.",,"['discrete-mathematics', 'soft-question', 'definite-integrals', 'indefinite-integrals']"
70,How to find recurrence relation of a given solution.,How to find recurrence relation of a given solution.,,Determine values of the constants $A$ and $B$ such that $a_n=An+B$ is a solution of the recurrence relation $a_n=2a_{n-1}+n+5$. I know that the characteristic equation is $r-2 = 0$ which has the root $r = 2$. Usually I find constants $A$ and $B$ by $a_n=Ar^n+Br^n$. It looks like I cannot apply this here because $a_n=An+B$ is given. The solution is $A = -1$ and $B = -7$. I don't know how to get this answer. Can anyone help me please.,Determine values of the constants $A$ and $B$ such that $a_n=An+B$ is a solution of the recurrence relation $a_n=2a_{n-1}+n+5$. I know that the characteristic equation is $r-2 = 0$ which has the root $r = 2$. Usually I find constants $A$ and $B$ by $a_n=Ar^n+Br^n$. It looks like I cannot apply this here because $a_n=An+B$ is given. The solution is $A = -1$ and $B = -7$. I don't know how to get this answer. Can anyone help me please.,,"['discrete-mathematics', 'recurrence-relations']"
71,Help with Cartesian product subsets [duplicate],Help with Cartesian product subsets [duplicate],,"This question already has answers here : If $A \subseteq C$ and $B \subseteq D$ then $A \times B \subseteq C \times D$ (3 answers) Closed 11 years ago . I want to prove that if  $A \subseteq C\,$ and $\,B \subseteq D,\,$ then $\,A \times B \subseteq C \times D.$ I know that $A \subseteq C \iff a \in A \rightarrow a \in C$ and that $B\subseteq D\iff b \in B \rightarrow  b \in D$  I also know that $A \times B = \{(a, b)\mid a\in A, b\in B\}$ and that $C\times D = \{(c, d) \mid c \in C, d \in D\}$. So keep that in mind, how do I connect the dots?","This question already has answers here : If $A \subseteq C$ and $B \subseteq D$ then $A \times B \subseteq C \times D$ (3 answers) Closed 11 years ago . I want to prove that if  $A \subseteq C\,$ and $\,B \subseteq D,\,$ then $\,A \times B \subseteq C \times D.$ I know that $A \subseteq C \iff a \in A \rightarrow a \in C$ and that $B\subseteq D\iff b \in B \rightarrow  b \in D$  I also know that $A \times B = \{(a, b)\mid a\in A, b\in B\}$ and that $C\times D = \{(c, d) \mid c \in C, d \in D\}$. So keep that in mind, how do I connect the dots?",,"['elementary-set-theory', 'discrete-mathematics']"
72,Question about divisibility by $3$,Question about divisibility by,3,"Lets assume that for every $x,y,z$ that belong to an $A$ , $(x+2y)$ and $(y+2z)$ can be divided by $3$.If we want to prove that $(x+2z)$ can also be divided by $3$, is it ok to do the next steps ? $(x+2y),(y+2z)$ can be divided by $3$, so lets take the sum of them:$(x+2y)+(y+2z)$ = $3y+(x+2z)$  And here we come into conclusion that the sum of them is obviously divided by $3$, $  3y$ can be divided by $3$ obviously,  can we say the same about $(x+2z)$ (that can be divided by $3$ according to the above sum) Thanks.","Lets assume that for every $x,y,z$ that belong to an $A$ , $(x+2y)$ and $(y+2z)$ can be divided by $3$.If we want to prove that $(x+2z)$ can also be divided by $3$, is it ok to do the next steps ? $(x+2y),(y+2z)$ can be divided by $3$, so lets take the sum of them:$(x+2y)+(y+2z)$ = $3y+(x+2z)$  And here we come into conclusion that the sum of them is obviously divided by $3$, $  3y$ can be divided by $3$ obviously,  can we say the same about $(x+2z)$ (that can be divided by $3$ according to the above sum) Thanks.",,['discrete-mathematics']
73,Number of relations that are both symmetric and antisymmetric?,Number of relations that are both symmetric and antisymmetric?,,"Because one relation cannot be symmetric and antisymmetric in relation to another, but is always symmetric and reflexive to itself, there are 2^n relations (relations in the diagonal only). Is that right?","Because one relation cannot be symmetric and antisymmetric in relation to another, but is always symmetric and reflexive to itself, there are 2^n relations (relations in the diagonal only). Is that right?",,['discrete-mathematics']
74,How to show that $\sum_{k} (-1)^k{{a+b}\choose{a+k}}{{b+c}\choose{b+k}}{{c+a}\choose{c+k}} = \frac{(a+b+c)!}{a!b!c!}$,How to show that,\sum_{k} (-1)^k{{a+b}\choose{a+k}}{{b+c}\choose{b+k}}{{c+a}\choose{c+k}} = \frac{(a+b+c)!}{a!b!c!},How to show that $$\sum_{k} (-1)^k{{a+b}\choose{a+k}}{{b+c}\choose{b+k}}{{c+a}\choose{c+k}} = \frac{(a+b+c)!}{a!b!c!}$$,How to show that $$\sum_{k} (-1)^k{{a+b}\choose{a+k}}{{b+c}\choose{b+k}}{{c+a}\choose{c+k}} = \frac{(a+b+c)!}{a!b!c!}$$,,"['combinatorics', 'summation', 'binomial-coefficients', 'factorial', 'multinomial-coefficients']"
75,$A \subseteq B \cap C$ if and only if $A \subseteq B$ and $A \subseteq C$.,if and only if  and .,A \subseteq B \cap C A \subseteq B A \subseteq C,"Is this the right way to write the proof for the question? $A \subseteq B \cap C \implies A \subseteq B$ and $A \subseteq C$ . Let $x \in A$ . Since $A \subseteq B \cap C$ , $x \in B \cap C$ So, $x \in B$ and $x \in C$ Hence, proving the statement $A \subseteq B$ and $A \subseteq C \implies A \subseteq B \cap C$ Let $x \in A$ . Since $A \subseteq B$ , $x \in B$ Also since $A \subseteq C$ , $x \in C$ Hence, proving the statement.","Is this the right way to write the proof for the question? and . Let . Since , So, and Hence, proving the statement and Let . Since , Also since , Hence, proving the statement.",A \subseteq B \cap C \implies A \subseteq B A \subseteq C x \in A A \subseteq B \cap C x \in B \cap C x \in B x \in C A \subseteq B A \subseteq C \implies A \subseteq B \cap C x \in A A \subseteq B x \in B A \subseteq C x \in C,"['discrete-mathematics', 'elementary-set-theory', 'solution-verification']"
76,How should one go about learning discrete mathematics? [closed],How should one go about learning discrete mathematics? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question How should one go with learning the proofs? How should one learn to prove things themselves? What kind of thinking skills should one develop and how? How should one practice problems? How to remember the concepts one learnt  better? All in all, what should be the main strategy to do full justice to discrete mathematics and enjoy it.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question How should one go with learning the proofs? How should one learn to prove things themselves? What kind of thinking skills should one develop and how? How should one practice problems? How to remember the concepts one learnt  better? All in all, what should be the main strategy to do full justice to discrete mathematics and enjoy it.",,"['discrete-mathematics', 'soft-question', 'learning']"
77,Open problems in Cellular Automata field,Open problems in Cellular Automata field,,here there is a link on Wolfram about 20 open problems of CA theory . Has anyone of them been solved or tested? I'm searching for literature.,here there is a link on Wolfram about 20 open problems of CA theory . Has anyone of them been solved or tested? I'm searching for literature.,,"['discrete-mathematics', 'computational-complexity', 'automata', 'computational-mathematics', 'cellular-automata']"
78,Let $(F_n)_{n\in \mathbb{N}}$ be the Fibonacci sequence. Prove that $F_{n+1}F_n - F_{n-1}F_{n-2} = F_{2n-1}$. [duplicate],Let  be the Fibonacci sequence. Prove that . [duplicate],(F_n)_{n\in \mathbb{N}} F_{n+1}F_n - F_{n-1}F_{n-2} = F_{2n-1},"This question already has answers here : Fiboncacci theorem: Proof by induction that $F_{n} \cdot F_{n+1} - F_{n-2}\cdot F_{n-1}=F_{2n-1}$ (2 answers) Closed 2 years ago . Let $(F_n)_{n\in \mathbb{N}}$ be the Fibonacci sequence. Prove that $F_{n+1}F_n - F_{n-1}F_{n-2} = F_{2n-1}$ . I'm trying to prove usinge the induction principle, so here is my sketch: $(i)$ $n = 3 \implies F_4F_3-F_2F_1= 6-1 = 5 = F_5$ $(ii)$ Supose true for $n = k$ $F_{k+2}F_{k+1}-F_{k}F_{k-1} = (F_{k+1}+F_k)F_{k+1} - (F_{k-1}+F_{k-2})F_{k-1} = F_{k+1}F_k-F_{k-1}F_{k-2} + F_{k+1}^2 - F_{k-1}^2 = F_{2k-1} + F_{k+1}^2 - F_{k-1}^2 $ . I got stuck here, how can I transform $F_{k+1}^2 - F_{k-1}^2$ in $F_{2k}$ ?","This question already has answers here : Fiboncacci theorem: Proof by induction that $F_{n} \cdot F_{n+1} - F_{n-2}\cdot F_{n-1}=F_{2n-1}$ (2 answers) Closed 2 years ago . Let be the Fibonacci sequence. Prove that . I'm trying to prove usinge the induction principle, so here is my sketch: Supose true for . I got stuck here, how can I transform in ?",(F_n)_{n\in \mathbb{N}} F_{n+1}F_n - F_{n-1}F_{n-2} = F_{2n-1} (i) n = 3 \implies F_4F_3-F_2F_1= 6-1 = 5 = F_5 (ii) n = k F_{k+2}F_{k+1}-F_{k}F_{k-1} = (F_{k+1}+F_k)F_{k+1} - (F_{k-1}+F_{k-2})F_{k-1} = F_{k+1}F_k-F_{k-1}F_{k-2} + F_{k+1}^2 - F_{k-1}^2 = F_{2k-1} + F_{k+1}^2 - F_{k-1}^2  F_{k+1}^2 - F_{k-1}^2 F_{2k},"['discrete-mathematics', 'induction', 'fibonacci-numbers']"
79,Two players placing coins on a table- Extension,Two players placing coins on a table- Extension,,"The origin of my question comes from a common job interview question where two players take turns placing coins on a round table. The coins cannot overlap and can't be moved once they've been placed. The player which first has no available space on the table to place a coin, loses. The intuitive strategy for the first player in this game is to place their first coin in the centre of the table, and then place their ensuing coins collinear to the central coin and his opponent's previously placed coin, as well as equidistant from the centre as his oppponent's coin. I then question what would happen if the table was an equilateral triangle. The strategy as described above falls apart, and unfortunately I have not yet come up with a well defined strategy for the first player to win (if there exists one) without some pretty restricting assumptions. I am looking for some help with this.","The origin of my question comes from a common job interview question where two players take turns placing coins on a round table. The coins cannot overlap and can't be moved once they've been placed. The player which first has no available space on the table to place a coin, loses. The intuitive strategy for the first player in this game is to place their first coin in the centre of the table, and then place their ensuing coins collinear to the central coin and his opponent's previously placed coin, as well as equidistant from the centre as his oppponent's coin. I then question what would happen if the table was an equilateral triangle. The strategy as described above falls apart, and unfortunately I have not yet come up with a well defined strategy for the first player to win (if there exists one) without some pretty restricting assumptions. I am looking for some help with this.",,"['discrete-mathematics', 'recreational-mathematics', 'game-theory', 'algorithmic-game-theory']"
80,"Properties of the ""eeny, meeny, miny, moe function""","Properties of the ""eeny, meeny, miny, moe function""",,"N.B. : there's another question about ""eeny, meeny, miny, moe"" in mathstackexchange but it is different to what it is presented here. Consider the function $f(p,s)$ defined as follows: There are $p>1$ players. We use a rhyme with $s>1$ steps. We start by player 1 and we apply the rhyme. The player where the rhyme ends is eliminated (cycling around if needed). Step 3 is repeated starting with the next non-eliminated player. The last standing player is $f(p,s)$. So, for example, if $p=5$ and $s=3$ we would eliminate players 3, 1, 5 and 2 in that order and we get $f(5,3)=4$. You can implement this function in Python as: def f(p,s):     P=range(p)     while len(P)>1:         r=s%len(P)         if r==0:             r=len(P)         P=P[r:]+P[:r-1]     return P[0]+1 Using this, it is easy to get a table with some values (I include up to 16 here): s  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16   p   --  --  --  --  --  --  --  --  --  --  --  --  --  --  --  --   1|   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   2|   2   1   2   1   2   1   2   1   2   1   2   1   2   1   2   1   3|   3   3   2   2   1   1   3   3   2   2   1   1   3   3   2   2   4|   4   1   1   2   2   3   2   3   3   4   4   1   4   1   1   2   5|   5   3   4   1   2   4   4   1   2   4   5   3   2   5   1   3   6|   6   5   1   5   1   4   5   3   5   2   4   3   3   1   4   1   7|   7   7   4   2   6   3   5   4   7   5   1   1   2   1   5   3   8|   8   1   7   6   3   1   4   4   8   7   4   5   7   7   4   3   9|   9   3   1   1   8   7   2   3   8   8   6   8   2   3   1   1  10|  10   5   4   5   3   3   9   1   7   8   7  10   5   7   6   7  11|  11   7   7   9   8   9   5   9   5   7   7  11   7  10  10   1  12|  12   9  10   1   1   3  12   5   2   5   6  11   8  12   1   5  13|  13  11  13   5   6   9   6  13  11   2   4  10   8  13   3   8  14|  14  13   2   9  11   1  13   7   6  12   1   8   7  13   4  10  15|  15  15   5  13   1   7   5  15  15   7  12   5   5  12   4  11  16|  16   1   8   1   6  13  12   7   8   1   7   1   2  10   3  11 Apart from the obvious properties $f(1,s)=1$, $f(p,1)=p$ and $f(p,p)=f(p-1,p)$, I was only able to see the cyclic pattern that repeats in rows 2 and 3 (so for 2 or 3 players), but not much more than that. My questions are: Is there any general pattern of the sort $f(p,s+k(p))=f(p,s)$? Is there any other relevant property of the function $f$ that I'm missing? More in general, does this function have any particular name and is used somewhere else in Mathematics? Edit: As for the first question it seems now clear to me that $f(p,s+p!)=f(p,s)$.","N.B. : there's another question about ""eeny, meeny, miny, moe"" in mathstackexchange but it is different to what it is presented here. Consider the function $f(p,s)$ defined as follows: There are $p>1$ players. We use a rhyme with $s>1$ steps. We start by player 1 and we apply the rhyme. The player where the rhyme ends is eliminated (cycling around if needed). Step 3 is repeated starting with the next non-eliminated player. The last standing player is $f(p,s)$. So, for example, if $p=5$ and $s=3$ we would eliminate players 3, 1, 5 and 2 in that order and we get $f(5,3)=4$. You can implement this function in Python as: def f(p,s):     P=range(p)     while len(P)>1:         r=s%len(P)         if r==0:             r=len(P)         P=P[r:]+P[:r-1]     return P[0]+1 Using this, it is easy to get a table with some values (I include up to 16 here): s  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16   p   --  --  --  --  --  --  --  --  --  --  --  --  --  --  --  --   1|   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   2|   2   1   2   1   2   1   2   1   2   1   2   1   2   1   2   1   3|   3   3   2   2   1   1   3   3   2   2   1   1   3   3   2   2   4|   4   1   1   2   2   3   2   3   3   4   4   1   4   1   1   2   5|   5   3   4   1   2   4   4   1   2   4   5   3   2   5   1   3   6|   6   5   1   5   1   4   5   3   5   2   4   3   3   1   4   1   7|   7   7   4   2   6   3   5   4   7   5   1   1   2   1   5   3   8|   8   1   7   6   3   1   4   4   8   7   4   5   7   7   4   3   9|   9   3   1   1   8   7   2   3   8   8   6   8   2   3   1   1  10|  10   5   4   5   3   3   9   1   7   8   7  10   5   7   6   7  11|  11   7   7   9   8   9   5   9   5   7   7  11   7  10  10   1  12|  12   9  10   1   1   3  12   5   2   5   6  11   8  12   1   5  13|  13  11  13   5   6   9   6  13  11   2   4  10   8  13   3   8  14|  14  13   2   9  11   1  13   7   6  12   1   8   7  13   4  10  15|  15  15   5  13   1   7   5  15  15   7  12   5   5  12   4  11  16|  16   1   8   1   6  13  12   7   8   1   7   1   2  10   3  11 Apart from the obvious properties $f(1,s)=1$, $f(p,1)=p$ and $f(p,p)=f(p-1,p)$, I was only able to see the cyclic pattern that repeats in rows 2 and 3 (so for 2 or 3 players), but not much more than that. My questions are: Is there any general pattern of the sort $f(p,s+k(p))=f(p,s)$? Is there any other relevant property of the function $f$ that I'm missing? More in general, does this function have any particular name and is used somewhere else in Mathematics? Edit: As for the first question it seems now clear to me that $f(p,s+p!)=f(p,s)$.",,"['discrete-mathematics', 'modular-arithmetic']"
81,"Proof: if $a$ and $b$ are integers, then $a^2-4b-3\neq 0$.","Proof: if  and  are integers, then .",a b a^2-4b-3\neq 0,"I was wondering if someone could take the time to look over this proof and make sure it is correct. I greatly appreciate the help. Proposition: If $a$ and $b$ are integers, then $a^2-4b-3\neq 0$. Proof: Assume $a,b\in\mathbb{Z}$ and, for contradiction's sake, $a^2-4b-3=0$. Solving for $a^2$, we find $a^2=4b+3$. Clearly, $a^2 \equiv 3($mod $4)$. Now, we can factor 2 out of the left-hand side of $a^2=4b+3$ yielding $a^2=2(2b+1)+1$. Thus, by the definition of odd, $a^2$ is odd. Since $a^2$ is odd, $a$ must be odd. By the definition of odd, we can write $a=2c+1$ where $c\in\mathbb{Z}$. Now we can substitute for $a$ in $a^2$ to find $a^2=(2c+1)^2=4c^2+4c+1$. Factoring 4 out from the first two terms, we discover $a^2=4(c^2+c)+1$. Clearly, $a^2\equiv 1($mod $4)$. Earlier, however, we found that $a^2 \equiv 3($mod $4)$. Since $a$ can not be congruent to both 1 and 3 modulo 4, we have a contradiction. Therefore, if $a,b\in\mathbb{Z}$, then $a^2-4b-4\neq0$.","I was wondering if someone could take the time to look over this proof and make sure it is correct. I greatly appreciate the help. Proposition: If $a$ and $b$ are integers, then $a^2-4b-3\neq 0$. Proof: Assume $a,b\in\mathbb{Z}$ and, for contradiction's sake, $a^2-4b-3=0$. Solving for $a^2$, we find $a^2=4b+3$. Clearly, $a^2 \equiv 3($mod $4)$. Now, we can factor 2 out of the left-hand side of $a^2=4b+3$ yielding $a^2=2(2b+1)+1$. Thus, by the definition of odd, $a^2$ is odd. Since $a^2$ is odd, $a$ must be odd. By the definition of odd, we can write $a=2c+1$ where $c\in\mathbb{Z}$. Now we can substitute for $a$ in $a^2$ to find $a^2=(2c+1)^2=4c^2+4c+1$. Factoring 4 out from the first two terms, we discover $a^2=4(c^2+c)+1$. Clearly, $a^2\equiv 1($mod $4)$. Earlier, however, we found that $a^2 \equiv 3($mod $4)$. Since $a$ can not be congruent to both 1 and 3 modulo 4, we have a contradiction. Therefore, if $a,b\in\mathbb{Z}$, then $a^2-4b-4\neq0$.",,"['discrete-mathematics', 'proof-verification', 'modular-arithmetic']"
82,Prove that the ant can survive,Prove that the ant can survive,,"There is a table with infinite cells. An ant starts from cell $(1,1)$ and each time it can move one cell up or right. Before starting to move, an infinite sequence of cell numbers like $<(x_{1},y_{1}) , (x_{2},y_{2}), ... , (x_{n}, y_{n}) , .... >$ is given to it. After step $k$, cell number $(x_{k},y_{k})$ will be poisoned and if ant goes there or already is there, it'll die. Prove with induction that the ant can live forever if it knows sequence elements from the beginning :)","There is a table with infinite cells. An ant starts from cell $(1,1)$ and each time it can move one cell up or right. Before starting to move, an infinite sequence of cell numbers like $<(x_{1},y_{1}) , (x_{2},y_{2}), ... , (x_{n}, y_{n}) , .... >$ is given to it. After step $k$, cell number $(x_{k},y_{k})$ will be poisoned and if ant goes there or already is there, it'll die. Prove with induction that the ant can live forever if it knows sequence elements from the beginning :)",,"['discrete-mathematics', 'induction']"
83,Discrete version of Intermediate Value Theorem,Discrete version of Intermediate Value Theorem,,"In this post the author states a discrete version of the Intermediate Value Theorem as follows: For integers $ a < b $, let $ f $ be a function from the integers in $ [a, b] $ to $ \mathbb{Z} $ that satisfies the property, $ |f(i + 1) - f(i)| \leq 1 $ for all $ i $. If $ f(a) < 0 < f(b) $, then there exists an integer $ c \in (a, b) $ such that $ f(c) = 0 $. And the proof for this theorem was given as follows: Proof . Let $ S = \{x \in \mathbb{Z} \cap [a, b] : f(x) < 0\} $ and let $ c = \max S + 1 $. We claim that $ f(c) = 0 $. Say $ f(c) < 0 $. Then $ c \in S $. This contradicts the fact that $ c - 1 $ is an upper bound on $ S $. Say $ f(c) > 0 $. This implies that $ f(c - 1) \geq 0 $ (by ""continuity""), which contradicts the fact that $ c - 1 \in S $. $ \blacksquare $ However, it seems to me that this proof does not show $ c \in (a, b) $. What makes it obvious that $ c $ belongs to $ (a, b) $?","In this post the author states a discrete version of the Intermediate Value Theorem as follows: For integers $ a < b $, let $ f $ be a function from the integers in $ [a, b] $ to $ \mathbb{Z} $ that satisfies the property, $ |f(i + 1) - f(i)| \leq 1 $ for all $ i $. If $ f(a) < 0 < f(b) $, then there exists an integer $ c \in (a, b) $ such that $ f(c) = 0 $. And the proof for this theorem was given as follows: Proof . Let $ S = \{x \in \mathbb{Z} \cap [a, b] : f(x) < 0\} $ and let $ c = \max S + 1 $. We claim that $ f(c) = 0 $. Say $ f(c) < 0 $. Then $ c \in S $. This contradicts the fact that $ c - 1 $ is an upper bound on $ S $. Say $ f(c) > 0 $. This implies that $ f(c - 1) \geq 0 $ (by ""continuity""), which contradicts the fact that $ c - 1 \in S $. $ \blacksquare $ However, it seems to me that this proof does not show $ c \in (a, b) $. What makes it obvious that $ c $ belongs to $ (a, b) $?",,[]
84,Inconsistency in a Z-transform of an Euler equation?,Inconsistency in a Z-transform of an Euler equation?,,"In this thesis, p. 27, the following Euler equation is given, see (4.9): $$ u_{i+1,j}=\frac{h_t}{2h_x^2}\left[\left(\frac{2h_x^2}{h_t}+2a_1h_x^2-4a_2\right)u_{i,j}+(2a_2-a_3h_x)u_{i,j-1}+(2a_2+a_3h_x)u_{i,j+1}+2b_1h_x^2\right] $$ Here, $i$ represents the time and $j$ represents the (1d-) space. Moreover, $h_t$ and $h_x$ are the step sizes with respect to time and space, respectively. $a_1,a_2$ and $b_1$ are constants. Then, on both sides, the z-tranformation (with respect to time) is applied, where $$ \mathcal{Z}(u_{i+1,j})=:U_j,~\mathcal{Z}(u_{i,j})=z^{-1}U_j,~\mathcal{Z}(u_{i,j-1})=z^{-1}U_{j-1},~\mathcal{Z}(u_{i,j+1})=U_{j+1}. $$ Due to the linked thesis, this gives (4.10) $$ U_j=\frac{h_t}{2h_x^2}\left[\left(\frac{2h_x^2}{h_t}+2a_1h_x^2-4a_2\right)z^{-1}U_j+(2a_2-a_3h_x)z^{-1}U_{j-1}+(2a_2+a_3h_x)z^{-1}U_{j+1}+\color{blue}{2b_1h_x^2}\right] $$ I am really wondering about the blue summand! Why isn't it $$ \mathcal{Z}(2b_1h_x^2)=2b_1h_x^2\mathcal{Z}(1)? $$ Is there some reason for that or is it just a mistake? I would really prefer that there is some reason for it. :-) In particular this seems relevant since the author is interested in poles and zeros $z$ of the z-transform with $\lvert z\rvert <1$ for stability reasons; but for $\lvert z\rvert <1$, we have that $\mathcal{Z}(1)$ diverges. Moreover, the determination of the zeros and poles does not work as done in the thesis in case the summand is $2b_1h_x^2\mathcal{Z}(1)$.","In this thesis, p. 27, the following Euler equation is given, see (4.9): $$ u_{i+1,j}=\frac{h_t}{2h_x^2}\left[\left(\frac{2h_x^2}{h_t}+2a_1h_x^2-4a_2\right)u_{i,j}+(2a_2-a_3h_x)u_{i,j-1}+(2a_2+a_3h_x)u_{i,j+1}+2b_1h_x^2\right] $$ Here, $i$ represents the time and $j$ represents the (1d-) space. Moreover, $h_t$ and $h_x$ are the step sizes with respect to time and space, respectively. $a_1,a_2$ and $b_1$ are constants. Then, on both sides, the z-tranformation (with respect to time) is applied, where $$ \mathcal{Z}(u_{i+1,j})=:U_j,~\mathcal{Z}(u_{i,j})=z^{-1}U_j,~\mathcal{Z}(u_{i,j-1})=z^{-1}U_{j-1},~\mathcal{Z}(u_{i,j+1})=U_{j+1}. $$ Due to the linked thesis, this gives (4.10) $$ U_j=\frac{h_t}{2h_x^2}\left[\left(\frac{2h_x^2}{h_t}+2a_1h_x^2-4a_2\right)z^{-1}U_j+(2a_2-a_3h_x)z^{-1}U_{j-1}+(2a_2+a_3h_x)z^{-1}U_{j+1}+\color{blue}{2b_1h_x^2}\right] $$ I am really wondering about the blue summand! Why isn't it $$ \mathcal{Z}(2b_1h_x^2)=2b_1h_x^2\mathcal{Z}(1)? $$ Is there some reason for that or is it just a mistake? I would really prefer that there is some reason for it. :-) In particular this seems relevant since the author is interested in poles and zeros $z$ of the z-transform with $\lvert z\rvert <1$ for stability reasons; but for $\lvert z\rvert <1$, we have that $\mathcal{Z}(1)$ diverges. Moreover, the determination of the zeros and poles does not work as done in the thesis in case the summand is $2b_1h_x^2\mathcal{Z}(1)$.",,"['discrete-mathematics', 'z-transform']"
85,Generalized way to solve $x_1 + x_2 + x_3 = c$ with the constraint $x_1 > x_2 > x_3$?,Generalized way to solve  with the constraint ?,x_1 + x_2 + x_3 = c x_1 > x_2 > x_3,"On my example final exam, we are given the following problem: How many ways can we pick seven balls of three colors red, blue, yellow given  also that the number of red balls must be strictly greater than blue and  blue strictly greater than yellow? The solution I used (and was given) was a brute force counting. In particular, fix the number of red balls for $0, 1, \dots, 7$ and see how many viable cases we procure each time. However, I wanted to try and find a more clever way to do it, but couldn't. Is there a better/general way to do this problem when the numbers get larger? If possible, it would be even better if we solve the following more generalized form: $$x_1 + \dots + x_n = c, x_1 > \dots > x_n \geq 0$$","On my example final exam, we are given the following problem: How many ways can we pick seven balls of three colors red, blue, yellow given  also that the number of red balls must be strictly greater than blue and  blue strictly greater than yellow? The solution I used (and was given) was a brute force counting. In particular, fix the number of red balls for $0, 1, \dots, 7$ and see how many viable cases we procure each time. However, I wanted to try and find a more clever way to do it, but couldn't. Is there a better/general way to do this problem when the numbers get larger? If possible, it would be even better if we solve the following more generalized form: $$x_1 + \dots + x_n = c, x_1 > \dots > x_n \geq 0$$",,['discrete-mathematics']
86,How to solve a non-homogeneous second-order linear difference equation with both a forward and a backward difference?,How to solve a non-homogeneous second-order linear difference equation with both a forward and a backward difference?,,"Quite a long title for this: I'm looking for the general solution of the following difference equation: $$ax_{t+1} -bx_t + x_{t-1} = c + u_t$$ where $a,b,c$ are real constants and $u_t$ is a bounded stochastic disturbance (e.g. a uniformly distributed random variable between -1 and 1 and the $u_t$ are iid). This is the class of difference equations, that Woodford (2003, Interest and prices, chapter 7) solves as the law of motion of Lagrange multipliers $x$. Unfortunately, he just states ""Well, folks, this is the result"" but does not bother explaining or even stating his approach. Now, I'm pretty sure this problem can be tackled with the usual approach for second-order non-homogeneous difference equations with constant coefficients, i.e. the solution should be looking like this (the condition for two distinct real roots of the CE is fulfilled): $$ x_t = Am_1^t + Bm_2^t + x^*$$ Is this true or am I missing something?","Quite a long title for this: I'm looking for the general solution of the following difference equation: $$ax_{t+1} -bx_t + x_{t-1} = c + u_t$$ where $a,b,c$ are real constants and $u_t$ is a bounded stochastic disturbance (e.g. a uniformly distributed random variable between -1 and 1 and the $u_t$ are iid). This is the class of difference equations, that Woodford (2003, Interest and prices, chapter 7) solves as the law of motion of Lagrange multipliers $x$. Unfortunately, he just states ""Well, folks, this is the result"" but does not bother explaining or even stating his approach. Now, I'm pretty sure this problem can be tackled with the usual approach for second-order non-homogeneous difference equations with constant coefficients, i.e. the solution should be looking like this (the condition for two distinct real roots of the CE is fulfilled): $$ x_t = Am_1^t + Bm_2^t + x^*$$ Is this true or am I missing something?",,"['discrete-mathematics', 'economics', 'recurrence-relations']"
87,Is = (equality) a partial order relation?,Is = (equality) a partial order relation?,,"We know that a partial order relation is a relation which is reflexive , antisymmetric and transitive. Example: (x,y) belongs to R iff x=y. For A={1,2,3}, we get R= {(1,1), (2,2), (3,3)}. Now R is reflexive, transitive and also anti-symmetric (if xRy and yRx then x=y). So equality should be a partial order relation. Is it so? If yes, then why many authors don't mention it as an example of partial order relation. I only find <= , >= , divides, integral multiple and inclusion as an example in most of the books. I am confused.","We know that a partial order relation is a relation which is reflexive , antisymmetric and transitive. Example: (x,y) belongs to R iff x=y. For A={1,2,3}, we get R= {(1,1), (2,2), (3,3)}. Now R is reflexive, transitive and also anti-symmetric (if xRy and yRx then x=y). So equality should be a partial order relation. Is it so? If yes, then why many authors don't mention it as an example of partial order relation. I only find <= , >= , divides, integral multiple and inclusion as an example in most of the books. I am confused.",,"['discrete-mathematics', 'relations', 'order-theory']"
88,Define the relation $\mathscr{R}$ on $\Bbb Z$ by $x \mathscr{R} y$ iff $xy >0$. I wish to examine several properties of this relation.,Define the relation  on  by  iff . I wish to examine several properties of this relation.,\mathscr{R} \Bbb Z x \mathscr{R} y xy >0,"Considering on $\mathbb{Z}$ the following relation: $$\mathscr{R} = \left \{ (x,z) \in \mathbb{Z} \times \mathbb{Z} \quad \mbox{ such that } \quad xz > 0  \right \}$$ i.e. $\forall x,z \in \mathbb{Z}, x \mathscr{R} z \iff \mbox{ the product } \, \, x \cdot z > 0 $ Check if the relation $\mathscr{R}$ is: i) reflexive; ii) symmetrical; iii) transitive; iv) anti-symmetrical; v) of order; vi) of equivalence. What I have done is the following: i) is it a reflexive relation? $\forall x,x \in \mathbb{Z}, \quad x \mathscr{R} x \iff x\cdot x = x^2 > 0 $ since a square is always $> 0$ the relation is reflexive. ii) is it a symmetrical relation? $\forall x,z \in \mathbb{Z}, \quad x \mathscr{R} z \iff x \cdot z > 0$ by hypothesis, since the operation of multiplication is commutative on $\mathbb{Z}$ the following is true: $\forall x,z \in \mathbb{Z}, \quad z \mathscr{R} x \iff z \cdot x > 0$ hence, the relation is symmetrical. iii) is it a transitive relation? $\forall x,z \in \mathbb{Z}, \quad x \mathscr{R}z \iff x \cdot z > 0$ by hypothesys, if we take another ordered pair $\forall z,m \in \mathbb{Z}, \quad z \mathscr{R} m \iff z \cdot m > 0$ hence, if $x \mathscr{R}z, \quad z \mathscr{R} m \Rightarrow x \cdot m > 0$ i.e. if $x \cdot z > 0, \quad z \cdot m > 0 \Rightarrow x \cdot m > 0$ so the relation is transitive. iv) is it a anti-symmetrical relation? No. Because it is not true that $z \mathscr{R}x \iff x=z$, as we have seen in the symmetrical relation. v) is it a order relation? No. Because it is not anti-symmetrical. vi) is it a equivalence relation? Yes, because it is reflexive, symmetrical and transitive. What do you think about it? Please, can you give me any suggestions? Many thanks!","Considering on $\mathbb{Z}$ the following relation: $$\mathscr{R} = \left \{ (x,z) \in \mathbb{Z} \times \mathbb{Z} \quad \mbox{ such that } \quad xz > 0  \right \}$$ i.e. $\forall x,z \in \mathbb{Z}, x \mathscr{R} z \iff \mbox{ the product } \, \, x \cdot z > 0 $ Check if the relation $\mathscr{R}$ is: i) reflexive; ii) symmetrical; iii) transitive; iv) anti-symmetrical; v) of order; vi) of equivalence. What I have done is the following: i) is it a reflexive relation? $\forall x,x \in \mathbb{Z}, \quad x \mathscr{R} x \iff x\cdot x = x^2 > 0 $ since a square is always $> 0$ the relation is reflexive. ii) is it a symmetrical relation? $\forall x,z \in \mathbb{Z}, \quad x \mathscr{R} z \iff x \cdot z > 0$ by hypothesis, since the operation of multiplication is commutative on $\mathbb{Z}$ the following is true: $\forall x,z \in \mathbb{Z}, \quad z \mathscr{R} x \iff z \cdot x > 0$ hence, the relation is symmetrical. iii) is it a transitive relation? $\forall x,z \in \mathbb{Z}, \quad x \mathscr{R}z \iff x \cdot z > 0$ by hypothesys, if we take another ordered pair $\forall z,m \in \mathbb{Z}, \quad z \mathscr{R} m \iff z \cdot m > 0$ hence, if $x \mathscr{R}z, \quad z \mathscr{R} m \Rightarrow x \cdot m > 0$ i.e. if $x \cdot z > 0, \quad z \cdot m > 0 \Rightarrow x \cdot m > 0$ so the relation is transitive. iv) is it a anti-symmetrical relation? No. Because it is not true that $z \mathscr{R}x \iff x=z$, as we have seen in the symmetrical relation. v) is it a order relation? No. Because it is not anti-symmetrical. vi) is it a equivalence relation? Yes, because it is reflexive, symmetrical and transitive. What do you think about it? Please, can you give me any suggestions? Many thanks!",,"['discrete-mathematics', 'solution-verification', 'relations', 'equivalence-relations']"
89,"If $p$ and $q$ are prime numbers larger than $2$, then $pq + 1 $ is never prime","If  and  are prime numbers larger than , then  is never prime",p q 2 pq + 1 ,"I am trying to prove the following: If $p$ and $q$ are prime numbers larger than $2$, then $pq + 1 $ is never prime. Any ideas?","I am trying to prove the following: If $p$ and $q$ are prime numbers larger than $2$, then $pq + 1 $ is never prime. Any ideas?",,"['discrete-mathematics', 'prime-numbers']"
90,"How to prove for each positive integer $n$, the sum of the first $n$ odd positive integers is $n^2$?","How to prove for each positive integer , the sum of the first  odd positive integers is ?",n n n^2,"I'm new to induction so please bear with me. How can I prove using induction that, for each positive integer $n$, the sum of the first $n$ odd positive integers is $n^2$? I think $9$ can be an example since the sum of the first $9$ positive odd numbers is $1,3,5,7,9,11,13,15,17 = 81 = 9^2$, but where do I go from here.","I'm new to induction so please bear with me. How can I prove using induction that, for each positive integer $n$, the sum of the first $n$ odd positive integers is $n^2$? I think $9$ can be an example since the sum of the first $9$ positive odd numbers is $1,3,5,7,9,11,13,15,17 = 81 = 9^2$, but where do I go from here.",,"['discrete-mathematics', 'induction']"
91,The sum of three consecutive cubes numbers produces 9 multiple,The sum of three consecutive cubes numbers produces 9 multiple,,"I want to prove that $n^3 + (n+1)^3 + (n+2)^3$ is always a $9$ multiple I used induction by the way. I reach this expression:  $(n+1)^3 + (n+2)^3 + (n+3)^3$ But is a lot of time to calculate each three terms, so could you help me to achieve the induction formula Thanks in advance","I want to prove that $n^3 + (n+1)^3 + (n+2)^3$ is always a $9$ multiple I used induction by the way. I reach this expression:  $(n+1)^3 + (n+2)^3 + (n+3)^3$ But is a lot of time to calculate each three terms, so could you help me to achieve the induction formula Thanks in advance",,"['elementary-number-theory', 'discrete-mathematics', 'induction', 'divisibility', 'natural-numbers']"
92,Why is $n^2+4$ never divisible by $3$? [duplicate],Why is  never divisible by ? [duplicate],n^2+4 3,"This question already has answers here : Proving that $x^2 + 4$ is not divisible by $3$ (5 answers) Closed 8 years ago . Can somebody please explain why $n^2+4$ is never divisible by $3$?  I know there is an example with $n^2+1$, however a $4$ can be broken down to $3+1$, and factor out a three, which would be divisible by $4$.","This question already has answers here : Proving that $x^2 + 4$ is not divisible by $3$ (5 answers) Closed 8 years ago . Can somebody please explain why $n^2+4$ is never divisible by $3$?  I know there is an example with $n^2+1$, however a $4$ can be broken down to $3+1$, and factor out a three, which would be divisible by $4$.",,"['discrete-mathematics', 'proof-verification', 'modular-arithmetic', 'divisibility']"
93,"Discrete mathematics, divisibility [closed]","Discrete mathematics, divisibility [closed]",,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question How can I prove that for all $n\in\mathbf{N}$ that $6 | n^5 + 5n$? I tested for $n = 2$ and got $6 | 32 + 10 = 42$.,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question How can I prove that for all $n\in\mathbf{N}$ that $6 | n^5 + 5n$? I tested for $n = 2$ and got $6 | 32 + 10 = 42$.,,"['discrete-mathematics', 'divisibility']"
94,An easy pigeonhole principle problem: Please critique my mathematical reasoning.,An easy pigeonhole principle problem: Please critique my mathematical reasoning.,,"Imagine a $9 \times 9$ square array of pigeonholes, with one pigeon in each pigeonhole. Suppose that all at once, all the pigeons move up, down, left, or right by one hole. (The pigeons on the edges are not allowed to move out of the array.) Show that some pigeonhole winds up with two pigeons in it. Let each side of the square be n. There are $n^2$ pigeons and pigeonholes. If the pigeons are shifted in any direction, then there will be n empty pigeonholes on the side opposite to the direction. Furthermore, now $n^2$ pigeons are trying to fit into $n^2 - n$ pigeonholes. We can invoke the pigeon hole principle as follows: Let the entire set of pigeons be $X$ and the set of pigeonholes to be populated after the shift be $Y$ .  For $X$ and $Y$ and for some integer $k$ , if $X > k Y$ , and $f X: \to Y$ , then $f(x) = \ldots = f(x {\rm till\ index}\ k+1)$ . So, $81 > 72 k$ which means $k > 1.125$ which means $k = 2$ . This means that there are at least $3$ instances with $2$ pigeons in it. Now intuitively I know there ought to be $9$ instances. Where did I go wrong? Forgive me if I have butchered the whole thing. I am new to this type of math.","Imagine a square array of pigeonholes, with one pigeon in each pigeonhole. Suppose that all at once, all the pigeons move up, down, left, or right by one hole. (The pigeons on the edges are not allowed to move out of the array.) Show that some pigeonhole winds up with two pigeons in it. Let each side of the square be n. There are pigeons and pigeonholes. If the pigeons are shifted in any direction, then there will be n empty pigeonholes on the side opposite to the direction. Furthermore, now pigeons are trying to fit into pigeonholes. We can invoke the pigeon hole principle as follows: Let the entire set of pigeons be and the set of pigeonholes to be populated after the shift be .  For and and for some integer , if , and , then . So, which means which means . This means that there are at least instances with pigeons in it. Now intuitively I know there ought to be instances. Where did I go wrong? Forgive me if I have butchered the whole thing. I am new to this type of math.",9 \times 9 n^2 n^2 n^2 - n X Y X Y k X > k Y f X: \to Y f(x) = \ldots = f(x {\rm till\ index}\ k+1) 81 > 72 k k > 1.125 k = 2 3 2 9,"['discrete-mathematics', 'solution-verification', 'pigeonhole-principle']"
95,"Why is {1, 2, 3} an equivalence relation?","Why is {1, 2, 3} an equivalence relation?",,""" The equality relation (=) on a set of numbers such as {1, 2, 3} is an equivalence relation. "" I know the equality relation = is an equivalence relation in the set of real numbers. Because it can satisfy all three conditions of equivalence relation. (1) x=x, reflexive (2) x=y ⇒ y=x symmetric, (3) x=y∧y=z ⇒x=z, transitive But what does {1, 2, 3} have have to do with equality relation (=), which is an equivalence relation?",""" The equality relation (=) on a set of numbers such as {1, 2, 3} is an equivalence relation. "" I know the equality relation = is an equivalence relation in the set of real numbers. Because it can satisfy all three conditions of equivalence relation. (1) x=x, reflexive (2) x=y ⇒ y=x symmetric, (3) x=y∧y=z ⇒x=z, transitive But what does {1, 2, 3} have have to do with equality relation (=), which is an equivalence relation?",,['discrete-mathematics']
96,Fibonacci Numbers Proof: $ f_n = \binom n0 + \binom{n-1}1 +\dots+ \binom{n-k}k$,Fibonacci Numbers Proof:, f_n = \binom n0 + \binom{n-1}1 +\dots+ \binom{n-k}k,"Prove the following fibonacci sequence, which appear in Pascal's Triangle. I am not sure where to start on this, any pointers? $$ f_n = {n\choose0} + {n-1\choose1} + ... + {n-k\choose k}$$ where $\displaystyle k=\left\lfloor\frac{n}{2}\right\rfloor$","Prove the following fibonacci sequence, which appear in Pascal's Triangle. I am not sure where to start on this, any pointers? $$ f_n = {n\choose0} + {n-1\choose1} + ... + {n-k\choose k}$$ where $\displaystyle k=\left\lfloor\frac{n}{2}\right\rfloor$",,"['discrete-mathematics', 'summation', 'binomial-coefficients', 'fibonacci-numbers']"
97,"Evaluate and prove by induction: $\sum k{n\choose k},\sum \frac{1}{k(k+1)}$ [duplicate]",Evaluate and prove by induction:  [duplicate],"\sum k{n\choose k},\sum \frac{1}{k(k+1)}","This question already has answers here : Proving the summation formula using induction: $\sum_{k=1}^n \frac{1}{k(k+1)} = 1-\frac{1}{n+1}$ (5 answers) How to prove this binomial identity $\sum_{r=0}^n {r {n \choose r}} = n2^{n-1}$? (10 answers) Closed 7 years ago . $\displaystyle   0\cdot \binom{n}{0} + 1\cdot \binom{n}{1} + 2\binom{n}{2}+\cdots+(n-1)\cdot \binom{n}{n-1}+n\cdot \binom{n}{n}$ $\displaystyle\frac{1}{1\cdot 2} + \frac{1}{2\cdot 3}+\frac{1}{3\cdot 4} +\cdots+\frac{1}{(n-1)\cdot n}$ How do you find the sum of these and prove it by induction? Can someone help me get through this?","This question already has answers here : Proving the summation formula using induction: $\sum_{k=1}^n \frac{1}{k(k+1)} = 1-\frac{1}{n+1}$ (5 answers) How to prove this binomial identity $\sum_{r=0}^n {r {n \choose r}} = n2^{n-1}$? (10 answers) Closed 7 years ago . $\displaystyle   0\cdot \binom{n}{0} + 1\cdot \binom{n}{1} + 2\binom{n}{2}+\cdots+(n-1)\cdot \binom{n}{n-1}+n\cdot \binom{n}{n}$ $\displaystyle\frac{1}{1\cdot 2} + \frac{1}{2\cdot 3}+\frac{1}{3\cdot 4} +\cdots+\frac{1}{(n-1)\cdot n}$ How do you find the sum of these and prove it by induction? Can someone help me get through this?",,"['discrete-mathematics', 'summation', 'induction', 'binomial-coefficients']"
98,I don't understand the explanation of Proof by Contradiction,I don't understand the explanation of Proof by Contradiction,,"I was given this explanation in my notes to understand Proof by Contradiction: Proof by Contradiction We want to prove that $\ P(n) \to Q(n) $ is true. In a proof by contradiction, we assume by contradiction that $\ P(n) \to Q(n) $ is false, that is, that: $\ \neg (P(n) \to Q(n)) $ is true. The only way this might happen, is if $\ P(n) $ is true and $\ Q(n)$ is false. Thus we start with $\ P(n)$ true and $\ Q(n)$ false. If from there we deduce a contradiction, that is a statement of the form $\ C \wedge \neg C $ , which is always false, what we have proven is : $\ \neg (P(n) \to Q(n)) \to C \wedge \neg C$ , is true. This is equivalent to $\ P(n) \to Q(n) $ . To see that, set $\ S(n) = ""P(n) \to Q(n)""$ , and look at the truth table: What I don't understand is this line: "" $\ \neg (P(n) \to Q(n)) \to C \wedge \neg C$ , is true."" How is it true if previously stated that $\ \neg (P(n) \to Q(n))$ is True $\ C \wedge \neg C$ is False (a contradiction) But we know that... $\ P \to Q $ is always False? How am I interpreting this explanation wrongly? I am really confused right now... any help/explanation is very much appreciated, thanks!!! Original screenshot (in case I formatted the equations wrongly... I'm new to mathjax/latex thing):","I was given this explanation in my notes to understand Proof by Contradiction: Proof by Contradiction We want to prove that is true. In a proof by contradiction, we assume by contradiction that is false, that is, that: is true. The only way this might happen, is if is true and is false. Thus we start with true and false. If from there we deduce a contradiction, that is a statement of the form , which is always false, what we have proven is : , is true. This is equivalent to . To see that, set , and look at the truth table: What I don't understand is this line: "" , is true."" How is it true if previously stated that is True is False (a contradiction) But we know that... is always False? How am I interpreting this explanation wrongly? I am really confused right now... any help/explanation is very much appreciated, thanks!!! Original screenshot (in case I formatted the equations wrongly... I'm new to mathjax/latex thing):","\ P(n) \to Q(n)  \ P(n) \to Q(n)  \ \neg (P(n) \to Q(n))  \ P(n)  \ Q(n) \ P(n) \ Q(n) \ C \wedge \neg C  \ \neg (P(n) \to Q(n)) \to C \wedge \neg C \ P(n) \to Q(n)  \ S(n) = ""P(n) \to Q(n)"" \ \neg (P(n) \to Q(n)) \to C \wedge \neg C \ \neg (P(n) \to Q(n)) \ C \wedge \neg C \ P \to Q ","['discrete-mathematics', 'proof-verification', 'logic', 'proof-writing']"
99,"How to prove that $x^2+y^2+z^2=14^n$ holds for distinct integers $x,y,z$ for every natural $n$?",How to prove that  holds for distinct integers  for every natural ?,"x^2+y^2+z^2=14^n x,y,z n","Prove that for all natural numbers $n$, there exist distinct integers $x, y, z$ for which, $x^2+y^2+z^2=14^n$ How to prove this using mathematical induction? Some context: A related question asks for solutions of $x^2 + y^2 + z^2 = 3^{10}$ where the asker first tries to express $3^1$ and $3^2$ as sums of three squares and then combine these to construct a representation of $3^3$, and so on. However, none of the answers seem to use this approach. Legendre's three square theorem states that $n \in \mathbb{N}$ can be expressed as a sum of three squares if and only if $n$ is not of the form $4^a(8b+7)$, and $14^k$ clearly isn't. However, it does not guarantee that  $x,y,z$ are distinct and applying it  is not (at least not directly) a proof by induction.","Prove that for all natural numbers $n$, there exist distinct integers $x, y, z$ for which, $x^2+y^2+z^2=14^n$ How to prove this using mathematical induction? Some context: A related question asks for solutions of $x^2 + y^2 + z^2 = 3^{10}$ where the asker first tries to express $3^1$ and $3^2$ as sums of three squares and then combine these to construct a representation of $3^3$, and so on. However, none of the answers seem to use this approach. Legendre's three square theorem states that $n \in \mathbb{N}$ can be expressed as a sum of three squares if and only if $n$ is not of the form $4^a(8b+7)$, and $14^k$ clearly isn't. However, it does not guarantee that  $x,y,z$ are distinct and applying it  is not (at least not directly) a proof by induction.",,"['elementary-number-theory', 'discrete-mathematics', 'induction']"
