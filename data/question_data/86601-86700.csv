,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Weighted polynomial approximation on the half-line,Weighted polynomial approximation on the half-line,,"Let's $w : \mathbb R_+ \to \mathbb R_+^*$ a continuous function (I will only be interested in the case $w : t \mapsto e^{-t}$). We use $w$ to define the Banach space $C^0_w(\mathbb R_+)$ of continuous functions $f : \mathbb R_+ \to \mathbb R$ such that $fw \xrightarrow[+\infty]{}0$, endowed with the norm $\| f \| = \|fw\|_\infty = \sup_{\mathbb R_+} |fw|$. I want to prove that, when $w: t \mapsto e^{-t}$, the space of polynomials is dense in this Banach space. I think this is a special case of Bernstein's approximation problem, but I haven't found an explicit elementary proof with these keywords. Because of Weierstraß's approximation theorem and a small change of variables, it is enough to show that the functions $e_d : t \mapsto e^{-dt}$ ($d \in \mathbb N$) are in the closure of the space of polynomials. It is relatively easy to show this for $e_1$, because you can show that $$ \|e_1 - P_n \| = \|e_1(e_1 - P_n)\|_\infty = O\left(\frac 1{\sqrt n}\right),\tag{$*$}$$ where $P_n$ is the degree-$n$ Taylor polynomial of $e_1$ at $0$. If we denote by $\mathscr F$ the closure of the space of polynomials in our Banach space, we have proved $e_1 \in \mathscr F$. It seems that not much is needed to prove an equivalent result for the approximation of $e_d$. For instance, it would be enough to prove that all the $f_k : x \mapsto x^k e^{-x}$ are in $\mathscr F$ to kickstart a proof by induction: suppose all the $(f_k)$ are in $\mathscr F$ (so all the $\text{polynomial} \times e_1$ functions are, by linearity) and that $e_p$ is in $\mathscr F$ (so that we have a sequence of polynomials $(Q_n)_n$ converging to it w.r.t. the $\|\cdot\|$ norm). We then have $$\|e_1 Q_n - e_{p+1}\| = \|e_1(e_1 Q_n - e_{p+1})\|_\infty \leq \|e_1 Q_n - e_{p+1}\|_\infty = \|Q_n - e_p\| \xrightarrow[n\to\infty]{} 0.$$ However, I'm unable to prove that the $f_k$'s belong to $\mathscr F$, or more generally to make any significant progress on $e_1 \in \mathscr F$. Basically, $(*)$ doesn't give much maneuvering space... I'm under the impression that there are much more sophisticated approaches to this problem, but I would really appreciate any help towards an elementary proof of the result.","Let's $w : \mathbb R_+ \to \mathbb R_+^*$ a continuous function (I will only be interested in the case $w : t \mapsto e^{-t}$). We use $w$ to define the Banach space $C^0_w(\mathbb R_+)$ of continuous functions $f : \mathbb R_+ \to \mathbb R$ such that $fw \xrightarrow[+\infty]{}0$, endowed with the norm $\| f \| = \|fw\|_\infty = \sup_{\mathbb R_+} |fw|$. I want to prove that, when $w: t \mapsto e^{-t}$, the space of polynomials is dense in this Banach space. I think this is a special case of Bernstein's approximation problem, but I haven't found an explicit elementary proof with these keywords. Because of Weierstraß's approximation theorem and a small change of variables, it is enough to show that the functions $e_d : t \mapsto e^{-dt}$ ($d \in \mathbb N$) are in the closure of the space of polynomials. It is relatively easy to show this for $e_1$, because you can show that $$ \|e_1 - P_n \| = \|e_1(e_1 - P_n)\|_\infty = O\left(\frac 1{\sqrt n}\right),\tag{$*$}$$ where $P_n$ is the degree-$n$ Taylor polynomial of $e_1$ at $0$. If we denote by $\mathscr F$ the closure of the space of polynomials in our Banach space, we have proved $e_1 \in \mathscr F$. It seems that not much is needed to prove an equivalent result for the approximation of $e_d$. For instance, it would be enough to prove that all the $f_k : x \mapsto x^k e^{-x}$ are in $\mathscr F$ to kickstart a proof by induction: suppose all the $(f_k)$ are in $\mathscr F$ (so all the $\text{polynomial} \times e_1$ functions are, by linearity) and that $e_p$ is in $\mathscr F$ (so that we have a sequence of polynomials $(Q_n)_n$ converging to it w.r.t. the $\|\cdot\|$ norm). We then have $$\|e_1 Q_n - e_{p+1}\| = \|e_1(e_1 Q_n - e_{p+1})\|_\infty \leq \|e_1 Q_n - e_{p+1}\|_\infty = \|Q_n - e_p\| \xrightarrow[n\to\infty]{} 0.$$ However, I'm unable to prove that the $f_k$'s belong to $\mathscr F$, or more generally to make any significant progress on $e_1 \in \mathscr F$. Basically, $(*)$ doesn't give much maneuvering space... I'm under the impression that there are much more sophisticated approaches to this problem, but I would really appreciate any help towards an elementary proof of the result.",,"['functional-analysis', 'approximation-theory']"
1,Spectrum of Scaling Operator,Spectrum of Scaling Operator,,I'm considering this spectral problem I don't manage to solve. Suppose $T:L^2(\mathbb R)\rightarrow L^2(\mathbb R)$ is defined by: $$Tf(x)=\frac{1}{\sqrt2}f\Big(\frac{x}{2}\Big)$$ How can I calculate: $\bullet$ eigenvalues and eigenspaces $\bullet$ the whole spectrum I know $T$ is a unitary operator so $\sigma(T)\subseteq(S^1)$. However $T$ is not self adjoint so I can't conclude the reality of his spectrum. In the attempt of looking for $T$ eigenspaces I only discovered the only possibles eigenvalues for $T$ are $\pm1$ by checking the $L^2$ norms. But I can't find any possibly eigenfunction. Any references or advice? Thank you!,I'm considering this spectral problem I don't manage to solve. Suppose $T:L^2(\mathbb R)\rightarrow L^2(\mathbb R)$ is defined by: $$Tf(x)=\frac{1}{\sqrt2}f\Big(\frac{x}{2}\Big)$$ How can I calculate: $\bullet$ eigenvalues and eigenspaces $\bullet$ the whole spectrum I know $T$ is a unitary operator so $\sigma(T)\subseteq(S^1)$. However $T$ is not self adjoint so I can't conclude the reality of his spectrum. In the attempt of looking for $T$ eigenspaces I only discovered the only possibles eigenvalues for $T$ are $\pm1$ by checking the $L^2$ norms. But I can't find any possibly eigenfunction. Any references or advice? Thank you!,,"['functional-analysis', 'operator-theory', 'spectral-theory']"
2,Does projections to orthogonal summands closed $\implies$ subspace closed?,Does projections to orthogonal summands closed  subspace closed?,\implies,"Let $X$ be a inner product space, with orthogonal decomposition $X=V \oplus W$. Give $X$ the topology induced by the norm induced by the inner product. Let $E\subset X$ be a subspace such that the projections to $V, W$ (call them $\pi_V(E), \pi_W(E)$) are closed. Does this imply that $E$ is closed itself? Note that $X$ may not be complete; in fact I am mainly interested in the case where it is not complete. Any kind of help would be appreciated!","Let $X$ be a inner product space, with orthogonal decomposition $X=V \oplus W$. Give $X$ the topology induced by the norm induced by the inner product. Let $E\subset X$ be a subspace such that the projections to $V, W$ (call them $\pi_V(E), \pi_W(E)$) are closed. Does this imply that $E$ is closed itself? Note that $X$ may not be complete; in fact I am mainly interested in the case where it is not complete. Any kind of help would be appreciated!",,"['functional-analysis', 'inner-products']"
3,Show properties of the linear operator $L((a_n)_n)=\left(\frac{1}{n}*a_n\right)_n$,Show properties of the linear operator,L((a_n)_n)=\left(\frac{1}{n}*a_n\right)_n,"Let $L\colon \ell^p \rightarrow \ell^p$ such that $L((a_n)_n)= \left(\frac{1}{n}*a_n\right)_n$. 1) Determine $L'$(adjoint operator), $\ker(L)$, $\ker(L')$, $\operatorname{rg}(L)$, $\operatorname{rg}(L')$ as well as $\operatorname{cl}(\operatorname{rg}(L))$ and $\operatorname{cl}(\operatorname{rg}(L'))$. 2) Let $K$ be a bounded linear operator. Using $L$, show that $\operatorname{cl}(\operatorname{rg}(K')) \subseteq \ker(K)^\perp$ but equality does not hold in general. 3) $K$ surjective $\rightarrow$ $K'$ injective, but $\leftarrow$ does not hold i.g. 4) $K'$ surjective $\rightarrow$ $K$ injective, but $\leftarrow$ does not hold i.g. So far, I know: $\langle Lx,y \rangle = \langle x,L'y\rangle$ and so it follows $L=L'$. The kernel of $L$ is $(0)$. Then, from the lecture, I get $\operatorname{cl}(\operatorname{rg}(L))= \ker(L')_\perp = (here) \ker(L)_\perp = (0)_\perp = \ell^p$. How can I find $\operatorname{rg}(L)$? I need it to solve $2)$, $3)$ and $4)$. I appreciate any help.","Let $L\colon \ell^p \rightarrow \ell^p$ such that $L((a_n)_n)= \left(\frac{1}{n}*a_n\right)_n$. 1) Determine $L'$(adjoint operator), $\ker(L)$, $\ker(L')$, $\operatorname{rg}(L)$, $\operatorname{rg}(L')$ as well as $\operatorname{cl}(\operatorname{rg}(L))$ and $\operatorname{cl}(\operatorname{rg}(L'))$. 2) Let $K$ be a bounded linear operator. Using $L$, show that $\operatorname{cl}(\operatorname{rg}(K')) \subseteq \ker(K)^\perp$ but equality does not hold in general. 3) $K$ surjective $\rightarrow$ $K'$ injective, but $\leftarrow$ does not hold i.g. 4) $K'$ surjective $\rightarrow$ $K$ injective, but $\leftarrow$ does not hold i.g. So far, I know: $\langle Lx,y \rangle = \langle x,L'y\rangle$ and so it follows $L=L'$. The kernel of $L$ is $(0)$. Then, from the lecture, I get $\operatorname{cl}(\operatorname{rg}(L))= \ker(L')_\perp = (here) \ker(L)_\perp = (0)_\perp = \ell^p$. How can I find $\operatorname{rg}(L)$? I need it to solve $2)$, $3)$ and $4)$. I appreciate any help.",,"['functional-analysis', 'lp-spaces', 'adjoint-operators']"
4,About the self-adjoint extension of one linear differential operator,About the self-adjoint extension of one linear differential operator,,"I`m trying to solve some problems and I need your help. Consider $$A: \;\;-\frac{d^2y}{dx^2}: C[0,\pi] \to C[0,\pi];\;\;\; y(0)=y(\pi)=0$$. It is unbounded, closed and symmetric, but not self-adjoint. The question is how can I find conditions of existence of self-adjoint extension; what is the simpiest way to solve it? Is it necessary to find deficiency indices (the necessary and sufficient condition is an equality of deficiency indices) or this problem has a simple decision? And what literature would you advice? Thanks a lot.","I`m trying to solve some problems and I need your help. Consider $$A: \;\;-\frac{d^2y}{dx^2}: C[0,\pi] \to C[0,\pi];\;\;\; y(0)=y(\pi)=0$$. It is unbounded, closed and symmetric, but not self-adjoint. The question is how can I find conditions of existence of self-adjoint extension; what is the simpiest way to solve it? Is it necessary to find deficiency indices (the necessary and sufficient condition is an equality of deficiency indices) or this problem has a simple decision? And what literature would you advice? Thanks a lot.",,"['real-analysis', 'functional-analysis', 'analysis', 'operator-theory']"
5,Quotient of normed space ; Isometry,Quotient of normed space ; Isometry,,"I am struggling with the following problem: $T : \mathbb{X} \to \mathbb{Y}$ is a linear operator, and $\mathbb{X}$ , $\mathbb{Y}$ are normed spaces. Show that : $T$ is a ""quotient map"" iff the induced operator $T': \mathbb{X}/\ker(T) \to \mathbb{Y}$ is an isometry. (I'm working with a German textbook and in that terminology a quotient map between normed spaces $\mathbb{X}$ and $\mathbb{Y}$ is a linear operator that maps the open unit ball in $\mathbb{X}$ surjectively onto the open unit ball in $\mathbb{Y}$ ; don't know whether that is a standard). So far I could easily proof that if $T'$ is an isometry $T$ must be a ""quotient map"" , but I can't show the other implication, so I would appreciate a hint . Thanks so far Daniel","I am struggling with the following problem: $T : \mathbb{X} \to \mathbb{Y}$ is a linear operator, and $\mathbb{X}$ , $\mathbb{Y}$ are normed spaces. Show that : $T$ is a ""quotient map"" iff the induced operator $T': \mathbb{X}/\ker(T) \to \mathbb{Y}$ is an isometry. (I'm working with a German textbook and in that terminology a quotient map between normed spaces $\mathbb{X}$ and $\mathbb{Y}$ is a linear operator that maps the open unit ball in $\mathbb{X}$ surjectively onto the open unit ball in $\mathbb{Y}$ ; don't know whether that is a standard). So far I could easily proof that if $T'$ is an isometry $T$ must be a ""quotient map"" , but I can't show the other implication, so I would appreciate a hint . Thanks so far Daniel",,"['functional-analysis', 'normed-spaces', 'isometry']"
6,Product of uniformly convex spaces is uniformly convex,Product of uniformly convex spaces is uniformly convex,,"I've been looking for a not too complicated solution to the following problem: Let $X,Y$ be uniformly convex Banach spaces and for $1<p<\infty$ define the $p$-direct sum $X \oplus_p Y = X \times Y$ equipped with the norm,   $$ \lVert (x,y) \rVert_p = \left( \lVert x \rVert^p + \lVert y \rVert^p\right)^{\frac1p}$$   for $x \in X,$ $y \in Y.$ Show that $X \oplus_p Y$ is uniformly convex. Here we say a Banach space $X$ is uniformly convex if for all $\varepsilon >0,$ there is $\delta > 0$ such that for all $x,y \in X$ with $\lVert x \rVert , \lVert y \rVert \leq 1,$ $\lVert x -y \rVert > \varepsilon$ implies $\lVert \frac{x+y}2 \rVert < 1-\delta.$ If proving a particular case, say $p=2,$ is significantly easier/simpler I would also be interested in that. I don't have much to say for an attempt, as everything I've tried doesn't get me far. The main issue is that the condition $\lVert (x,y) \rVert_p \leq 1$ doesn't tell us much about the sizes of $\lVert x \rVert$ and $\lVert y \rVert$ which makes it difficult to apply the uniform convexity property of the two spaces. I did find a proof in Clarkson's original paper, where a generalisation of this result is shown. However I find the proof seems overly complicated and technical, defining a bunch of seemingly arbitrary quantities, passing to subsequences, making careful estimates, etc. I feel there should be a cleaner proof for this special case. Edit (11th Nov 2017) : As pointed out in the comments, my definition of uniform convexity was incorrect. It previously said $\lVert x -y \rVert < \varepsilon$ implies $\lVert \frac{x+y}2 \rVert > 1-\delta$ and has since been fixed.","I've been looking for a not too complicated solution to the following problem: Let $X,Y$ be uniformly convex Banach spaces and for $1<p<\infty$ define the $p$-direct sum $X \oplus_p Y = X \times Y$ equipped with the norm,   $$ \lVert (x,y) \rVert_p = \left( \lVert x \rVert^p + \lVert y \rVert^p\right)^{\frac1p}$$   for $x \in X,$ $y \in Y.$ Show that $X \oplus_p Y$ is uniformly convex. Here we say a Banach space $X$ is uniformly convex if for all $\varepsilon >0,$ there is $\delta > 0$ such that for all $x,y \in X$ with $\lVert x \rVert , \lVert y \rVert \leq 1,$ $\lVert x -y \rVert > \varepsilon$ implies $\lVert \frac{x+y}2 \rVert < 1-\delta.$ If proving a particular case, say $p=2,$ is significantly easier/simpler I would also be interested in that. I don't have much to say for an attempt, as everything I've tried doesn't get me far. The main issue is that the condition $\lVert (x,y) \rVert_p \leq 1$ doesn't tell us much about the sizes of $\lVert x \rVert$ and $\lVert y \rVert$ which makes it difficult to apply the uniform convexity property of the two spaces. I did find a proof in Clarkson's original paper, where a generalisation of this result is shown. However I find the proof seems overly complicated and technical, defining a bunch of seemingly arbitrary quantities, passing to subsequences, making careful estimates, etc. I feel there should be a cleaner proof for this special case. Edit (11th Nov 2017) : As pointed out in the comments, my definition of uniform convexity was incorrect. It previously said $\lVert x -y \rVert < \varepsilon$ implies $\lVert \frac{x+y}2 \rVert > 1-\delta$ and has since been fixed.",,"['functional-analysis', 'banach-spaces']"
7,Matrix Representation of an Operator (Volterra),Matrix Representation of an Operator (Volterra),,"Generally, how can I find the matrix of a given operator $K$ with respect to a given basis ${e_n}$? I thought I should use $\langle K(e_n),e_m\rangle$, is it the right way? In particular, how can I find the matrix representation of Volterra operator, i.e $K(\varphi)=\int_{a}^{b}k(t-s)\varphi(s)ds$? Is there easier way than the way I proposed?","Generally, how can I find the matrix of a given operator $K$ with respect to a given basis ${e_n}$? I thought I should use $\langle K(e_n),e_m\rangle$, is it the right way? In particular, how can I find the matrix representation of Volterra operator, i.e $K(\varphi)=\int_{a}^{b}k(t-s)\varphi(s)ds$? Is there easier way than the way I proposed?",,['functional-analysis']
8,Decomposition of a unitary representation into a sum of finite dimensional ones,Decomposition of a unitary representation into a sum of finite dimensional ones,,"Let $\pi$ be a unitary representation of a countable discrete group $\Gamma$ on a Hilbert space $H$. Suppose that there is a dense set $D$ of vectors in $H$ such that for every $x\in D$ the cyclic subrepresentation $\pi_x$ of $\pi$ given by $x$ contains a finite dimensional subrepresentation. Does it follow that $\pi$ is a sum of finite dimensional representations? Notice that when we strengthen the requirement from ""densely many"" to ""all"", i.e. we require that every cyclic subrepresentation contains a finite dimensional subrepresentation, then the conclusion above follows easily by the Zorn's lemma. I am curious if ""densely many"" is sufficient in the requirement. But perhaps there is some counterexample.","Let $\pi$ be a unitary representation of a countable discrete group $\Gamma$ on a Hilbert space $H$. Suppose that there is a dense set $D$ of vectors in $H$ such that for every $x\in D$ the cyclic subrepresentation $\pi_x$ of $\pi$ given by $x$ contains a finite dimensional subrepresentation. Does it follow that $\pi$ is a sum of finite dimensional representations? Notice that when we strengthen the requirement from ""densely many"" to ""all"", i.e. we require that every cyclic subrepresentation contains a finite dimensional subrepresentation, then the conclusion above follows easily by the Zorn's lemma. I am curious if ""densely many"" is sufficient in the requirement. But perhaps there is some counterexample.",,"['group-theory', 'functional-analysis', 'representation-theory', 'hilbert-spaces']"
9,What is the absolute minimum needed on a space to do differential calculus?,What is the absolute minimum needed on a space to do differential calculus?,,"A long time ago, I came across Lang's Differential Manifolds . Besides his definition of manifold, one thing that made me pretty nuts was this So after studing some real analysis and more linear algebra and topology, I came back to this page and began questioning this definition. He assumes all topological vector spaces in the text are going to be what he calls banachable (can be given a norm that induces the given topology and is complete in such norm). So I thought this definition was only a reestatement of the definition using the norm, but without the norm. But I really didn't understand this definition, this concept of tangency. After some more research I found Sadayuki Yamamuro's Differential Calculus in Topological Vector Spaces . Not only I can understand this concept (somehow) but I could translate this definition to topological vector spaces over any topological field. This concept of $M$-differentiation generalizes the Fréchet and (linear) Gâteaux derivatives and much more. So my question is: how far can this concepts of differentiability be generalized? Is Lang's definition with tangency to $0$ valid not only for banachable ones, but for arbitrary topological vector spaces? Is the $M$-differentiation the farthest we can go? Can something along this lines be done with modules?","A long time ago, I came across Lang's Differential Manifolds . Besides his definition of manifold, one thing that made me pretty nuts was this So after studing some real analysis and more linear algebra and topology, I came back to this page and began questioning this definition. He assumes all topological vector spaces in the text are going to be what he calls banachable (can be given a norm that induces the given topology and is complete in such norm). So I thought this definition was only a reestatement of the definition using the norm, but without the norm. But I really didn't understand this definition, this concept of tangency. After some more research I found Sadayuki Yamamuro's Differential Calculus in Topological Vector Spaces . Not only I can understand this concept (somehow) but I could translate this definition to topological vector spaces over any topological field. This concept of $M$-differentiation generalizes the Fréchet and (linear) Gâteaux derivatives and much more. So my question is: how far can this concepts of differentiability be generalized? Is Lang's definition with tangency to $0$ valid not only for banachable ones, but for arbitrary topological vector spaces? Is the $M$-differentiation the farthest we can go? Can something along this lines be done with modules?",,"['functional-analysis', 'derivatives', 'definition', 'topological-vector-spaces', 'frechet-derivative']"
10,Finite almost everywhere and essential supremum,Finite almost everywhere and essential supremum,,"I have difficulty in understanding the difference of the concepts ""finite almost everywhere"" and having finite essential supremum (as in $\Vert f \rVert_\infty= inf\{a \geq 0: \mu(\{x : |f(x)| >a \}) =0\} < \infty$. I know that if a function f is integrable then it is finite almost everywhere. Is $\lVert f \rVert_\infty < \infty $ the same as being bounded almost everywhere? A function such as $\frac{1}{\sqrt{x}}$ is finite almost everywhere on $[0,1]$ (since it is integrable) but not bounded almost everywhere? I would be very greatful if some one could help me and explain the difference and maybe come with some examples. Kind regards,","I have difficulty in understanding the difference of the concepts ""finite almost everywhere"" and having finite essential supremum (as in $\Vert f \rVert_\infty= inf\{a \geq 0: \mu(\{x : |f(x)| >a \}) =0\} < \infty$. I know that if a function f is integrable then it is finite almost everywhere. Is $\lVert f \rVert_\infty < \infty $ the same as being bounded almost everywhere? A function such as $\frac{1}{\sqrt{x}}$ is finite almost everywhere on $[0,1]$ (since it is integrable) but not bounded almost everywhere? I would be very greatful if some one could help me and explain the difference and maybe come with some examples. Kind regards,",,"['real-analysis', 'functional-analysis', 'measure-theory', 'lp-spaces']"
11,Does there hold that $(\sigma(A))^3=\sigma(A^3)$ in a Banach space?,Does there hold that  in a Banach space?,(\sigma(A))^3=\sigma(A^3),"Let $X$ be a Banach space over the field $\mathbb C$ of complex numbers, suppose that $A:X\to X$ is a bounded linear operator. Does there hold that $\sigma(A^3)=\{\lambda^3;\lambda\in\sigma(A)\}?$ Here $I:X\to X$ is the identity from $X$ to itself and we use the notation that $$\rho(A)=\{\lambda\in\mathbb C;\lambda I-A\ \hbox{has bounded inverse}\},\sigma(A)=\mathbb C\setminus\rho(A).$$ For the question above, I have some slight trials at this time. For any $\lambda\in\sigma(A),$ let us show that $\lambda^3\in\sigma(A^3).$ Arguing via contradiction and assuming that $\lambda^3\in\rho(A^3),$ that is, $\lambda^3I-A^3:X\to X$ is injective and also surjective. We note that $$\lambda^3 I-A^3=(\lambda I-A)(\lambda^2I+\lambda A+A^2)=(\lambda^2I+\lambda A+A^2)(\lambda I-A),$$ then $\lambda^2I+\lambda A+A^2:X\to X$ is injective and also surjective, and $\lambda I-A$ is injective, but it must not be surjective since $\lambda\in\sigma(A).$ For any operator $T:X\to X,$ we denote by $R(T)$ the range of $T.$ Since $R(\lambda I-A)\subsetneqq X$ and $(\lambda^2 I+\lambda A+A^2)|_{R(\lambda I-A)}:R(\lambda I-A)\to X$ is surjective, we conclude that $\lambda^2 I+\lambda A+A^2:X\to X$ should not be injective, a contradiction. On the other hand, if $\mu\in\sigma(A^3),$ let $\omega_1,\omega_2,\omega_3\in\mathbb C$ be the complex solutions of the equation $z^3=\mu.$ Then we obtain $$\mu I-A^3=\prod_{i=1}^3(\omega_iI-A),$$ and there must be some $i\in\{1,2,3\}$ such that $\omega_i I-A:X\to X$ does not possess bounded inverse, so $\omega_i\in\sigma(A).$ For above proof of my question, is it true? Any comments are welcome and thanks in advance!","Let $X$ be a Banach space over the field $\mathbb C$ of complex numbers, suppose that $A:X\to X$ is a bounded linear operator. Does there hold that $\sigma(A^3)=\{\lambda^3;\lambda\in\sigma(A)\}?$ Here $I:X\to X$ is the identity from $X$ to itself and we use the notation that $$\rho(A)=\{\lambda\in\mathbb C;\lambda I-A\ \hbox{has bounded inverse}\},\sigma(A)=\mathbb C\setminus\rho(A).$$ For the question above, I have some slight trials at this time. For any $\lambda\in\sigma(A),$ let us show that $\lambda^3\in\sigma(A^3).$ Arguing via contradiction and assuming that $\lambda^3\in\rho(A^3),$ that is, $\lambda^3I-A^3:X\to X$ is injective and also surjective. We note that $$\lambda^3 I-A^3=(\lambda I-A)(\lambda^2I+\lambda A+A^2)=(\lambda^2I+\lambda A+A^2)(\lambda I-A),$$ then $\lambda^2I+\lambda A+A^2:X\to X$ is injective and also surjective, and $\lambda I-A$ is injective, but it must not be surjective since $\lambda\in\sigma(A).$ For any operator $T:X\to X,$ we denote by $R(T)$ the range of $T.$ Since $R(\lambda I-A)\subsetneqq X$ and $(\lambda^2 I+\lambda A+A^2)|_{R(\lambda I-A)}:R(\lambda I-A)\to X$ is surjective, we conclude that $\lambda^2 I+\lambda A+A^2:X\to X$ should not be injective, a contradiction. On the other hand, if $\mu\in\sigma(A^3),$ let $\omega_1,\omega_2,\omega_3\in\mathbb C$ be the complex solutions of the equation $z^3=\mu.$ Then we obtain $$\mu I-A^3=\prod_{i=1}^3(\omega_iI-A),$$ and there must be some $i\in\{1,2,3\}$ such that $\omega_i I-A:X\to X$ does not possess bounded inverse, so $\omega_i\in\sigma(A).$ For above proof of my question, is it true? Any comments are welcome and thanks in advance!",,"['functional-analysis', 'spectral-theory']"
12,R.H.S. of Poisson equation localized $\Rightarrow$ Solution localized,R.H.S. of Poisson equation localized  Solution localized,\Rightarrow,"Let $\Omega\subset\mathbb{R}^d$ a connected open  set (which is not necessarily bounded).  Assume that $f\in C_0^\infty(\Omega)$ with $\operatorname{supp}(f)\subset K,$ with $K$ compactand let $u$ be a solution to the equation $$-\Delta u+u=f\quad\text{in }\Omega,\\ \quad\quad u\in H^1_0(\Omega).$$ I'm looking for a statement of the following type:  For every $\epsilon>0$ there exists a $R>0$ (depending only on $K$ but not on $f$) such that $$\|u\|_{L^2(\Omega\setminus B_R(0))}\leq \epsilon\|f\|_{L^2}.$$ This is easily obtained for $d=3$, $\Omega=\mathbb{R}^3$ using the fundamental solution, but the general case is not clear to me...","Let $\Omega\subset\mathbb{R}^d$ a connected open  set (which is not necessarily bounded).  Assume that $f\in C_0^\infty(\Omega)$ with $\operatorname{supp}(f)\subset K,$ with $K$ compactand let $u$ be a solution to the equation $$-\Delta u+u=f\quad\text{in }\Omega,\\ \quad\quad u\in H^1_0(\Omega).$$ I'm looking for a statement of the following type:  For every $\epsilon>0$ there exists a $R>0$ (depending only on $K$ but not on $f$) such that $$\|u\|_{L^2(\Omega\setminus B_R(0))}\leq \epsilon\|f\|_{L^2}.$$ This is easily obtained for $d=3$, $\Omega=\mathbb{R}^3$ using the fundamental solution, but the general case is not clear to me...",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'boundary-value-problem', 'elliptic-equations']"
13,The BV minimizing problem depends on a moving weighted parameter,The BV minimizing problem depends on a moving weighted parameter,,"Let $v\in L^2(Q)$ be given, where $Q:=(0,1)\times(0,1)$ is an unit square. Define a sequence of parameter function $\alpha_s$ by $$ \alpha_s(x):= \begin{cases} 1&\text{ if }x\in(1/2+s,1)\times(0,1)\\ 2&\text{ if }x\in(0,1/2+s)\times(0,1) \end{cases} $$ where $0<s<1/2$. Define  $$ u_s:=\operatorname{argmin}\{\|u-v\|_{L^2(Q)}^2+|\alpha_su|_{TV(Q)}:\,\,u\in BV(Q)\}\tag 1 $$ where $BV$ denotes the bounded variation space and $TV$ denotes the total variation seminorm. My question: do we have $u_s\to u_0$ in $L^1$ as $s\to 0$? ($u_0$ is defined by letting $s=0$ in $(1)$) I am also wondering what if I change $(1)$ by replacing $BV$ with the Ambrosio-Tortorelli functional, i.e., \begin{multline} (u_s,z_s):=\operatorname{argmin}\{\|u-v\|_{L^2(Q)}^2+\int_Q |\nabla u|^2(z^2+1)\alpha_sdx+\\ \int_Q[|\nabla z|^2+(1-z)^2]\alpha_s dx:\,\,u,z\in W^{1,2}(Q)\}\tag 2 \end{multline} Then, do we have $(u_s,z_s)\to (u_0,z_0)$ in $L^1$? or even weakly in $W^{1,2}$? Thank you!","Let $v\in L^2(Q)$ be given, where $Q:=(0,1)\times(0,1)$ is an unit square. Define a sequence of parameter function $\alpha_s$ by $$ \alpha_s(x):= \begin{cases} 1&\text{ if }x\in(1/2+s,1)\times(0,1)\\ 2&\text{ if }x\in(0,1/2+s)\times(0,1) \end{cases} $$ where $0<s<1/2$. Define  $$ u_s:=\operatorname{argmin}\{\|u-v\|_{L^2(Q)}^2+|\alpha_su|_{TV(Q)}:\,\,u\in BV(Q)\}\tag 1 $$ where $BV$ denotes the bounded variation space and $TV$ denotes the total variation seminorm. My question: do we have $u_s\to u_0$ in $L^1$ as $s\to 0$? ($u_0$ is defined by letting $s=0$ in $(1)$) I am also wondering what if I change $(1)$ by replacing $BV$ with the Ambrosio-Tortorelli functional, i.e., \begin{multline} (u_s,z_s):=\operatorname{argmin}\{\|u-v\|_{L^2(Q)}^2+\int_Q |\nabla u|^2(z^2+1)\alpha_sdx+\\ \int_Q[|\nabla z|^2+(1-z)^2]\alpha_s dx:\,\,u,z\in W^{1,2}(Q)\}\tag 2 \end{multline} Then, do we have $(u_s,z_s)\to (u_0,z_0)$ in $L^1$? or even weakly in $W^{1,2}$? Thank you!",,"['real-analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'bounded-variation']"
14,Modern focus of functional analysis and operator theory?,Modern focus of functional analysis and operator theory?,,"I have read several histories of functional analysis and operator theory, and they all focus on the importance of Hilbert's spectral theory, Frechet's metric spaces, Lebesgue integration theory, and unification work by Riesz. This work was all done about 100 years ago so I'm wondering what major advances have happened since? From reading these histories you'd get the impression that nothing of major note has happened in these fields since around 1940. So what topics do modern specialists in functional analysis and operator theory perform research in? Is it the case that all the widely applicable results were discovered 100 years ago and nowadays its all finding results in niche areas? Are there any recommendations for papers written in the last 20 years which are considered to be of major importances? What about some recent (last 5 years) papers that are worth reading?","I have read several histories of functional analysis and operator theory, and they all focus on the importance of Hilbert's spectral theory, Frechet's metric spaces, Lebesgue integration theory, and unification work by Riesz. This work was all done about 100 years ago so I'm wondering what major advances have happened since? From reading these histories you'd get the impression that nothing of major note has happened in these fields since around 1940. So what topics do modern specialists in functional analysis and operator theory perform research in? Is it the case that all the widely applicable results were discovered 100 years ago and nowadays its all finding results in niche areas? Are there any recommendations for papers written in the last 20 years which are considered to be of major importances? What about some recent (last 5 years) papers that are worth reading?",,"['functional-analysis', 'reference-request', 'operator-theory']"
15,Show that the inverse of the Laplacian is compact,Show that the inverse of the Laplacian is compact,,"Let $d\in\mathbb N$ $\Lambda\subseteq\mathbb R^d$ be bounded and open $\mathcal D(A):=\left\{u\in H_0^1(\Lambda):\Delta u\in L^2(\Lambda)\right\}$ and $$Au:=-\Delta u\;\;\;\text{for }u\in\mathcal D(A)$$ $(\mathcal D(A),A)$ is a linear symmetric operator on $L^2(\Lambda)$. Since $$\langle u,Au\rangle_{L^2(\Lambda)}=\left\|\nabla u\right\|_{L^2(\Lambda)}^2>0\;\;\;\text{ for all }u\in\mathcal D(A)\setminus\left\{0\right\}\;,\tag1$$ there is a unique linear operator $(\mathcal R(A),A^{-1})$ on $L^2(\Lambda)$ with $$\mathcal R(A):=\left\{Au:u\in\mathcal D(A)\right\}$$ and $$Au=v\Leftrightarrow u=A^{-1}v\;\;\;\text{for all }u\in\mathcal D(A)\text{and }v\in\mathcal R(A)\;.\tag2$$ I want to show that there is an orthonormal basis $(e_n)_{n\in\mathbb N}\subseteq\mathcal D(A)$ of $L^2(\Lambda)$ with $$A^{-1}e_n=\lambda_ne_n\tag3\;\;\;\text{or all }n\in\mathbb N$$ for some $(\lambda_n)_{n\in\mathbb N}\subseteq(0,\infty)$ with $$\lambda_{n+1}\le\lambda_n\;\;\;\text{for all }n\in\mathbb N\tag4\;.$$ Is it possible to do so by the Hilbert-Schmidt theorem ? We can show that $$\left\|u\right\|_{L^2(\Lambda)}\le C\left\|Au\right\|_{L^2(\Lambda)}\;\;\;\text{for all }u\in\mathcal D(A)\tag5$$ for some $C\ge 0$ and hence $$\left\|A^{-1}v\right\|_{L^2(\Lambda)}\le C\left\|v\right\|_{L^2(\Lambda)}\tag6\;,$$ i.e. $(\mathcal R(A),A^{-1})$ is a bounded operator on $L^2(\Lambda)$. Thus, there is a bounded linear operator $\tilde A^{-1}$ on $L^2(\Lambda)$ with $$\tilde A^{-1}v=A^{-1}v\;\;\;\text{for all }v\in\mathcal R(A)\tag 7\;.$$ Now, by the Rellich–Kondrachov theorem the inclusion $\iota$ from $H_0^1(\Lambda)$ into $L^2(\Lambda)$ is compact and hence $\tilde A^{-1}\iota$ is compact; but that's of no use here, is it?","Let $d\in\mathbb N$ $\Lambda\subseteq\mathbb R^d$ be bounded and open $\mathcal D(A):=\left\{u\in H_0^1(\Lambda):\Delta u\in L^2(\Lambda)\right\}$ and $$Au:=-\Delta u\;\;\;\text{for }u\in\mathcal D(A)$$ $(\mathcal D(A),A)$ is a linear symmetric operator on $L^2(\Lambda)$. Since $$\langle u,Au\rangle_{L^2(\Lambda)}=\left\|\nabla u\right\|_{L^2(\Lambda)}^2>0\;\;\;\text{ for all }u\in\mathcal D(A)\setminus\left\{0\right\}\;,\tag1$$ there is a unique linear operator $(\mathcal R(A),A^{-1})$ on $L^2(\Lambda)$ with $$\mathcal R(A):=\left\{Au:u\in\mathcal D(A)\right\}$$ and $$Au=v\Leftrightarrow u=A^{-1}v\;\;\;\text{for all }u\in\mathcal D(A)\text{and }v\in\mathcal R(A)\;.\tag2$$ I want to show that there is an orthonormal basis $(e_n)_{n\in\mathbb N}\subseteq\mathcal D(A)$ of $L^2(\Lambda)$ with $$A^{-1}e_n=\lambda_ne_n\tag3\;\;\;\text{or all }n\in\mathbb N$$ for some $(\lambda_n)_{n\in\mathbb N}\subseteq(0,\infty)$ with $$\lambda_{n+1}\le\lambda_n\;\;\;\text{for all }n\in\mathbb N\tag4\;.$$ Is it possible to do so by the Hilbert-Schmidt theorem ? We can show that $$\left\|u\right\|_{L^2(\Lambda)}\le C\left\|Au\right\|_{L^2(\Lambda)}\;\;\;\text{for all }u\in\mathcal D(A)\tag5$$ for some $C\ge 0$ and hence $$\left\|A^{-1}v\right\|_{L^2(\Lambda)}\le C\left\|v\right\|_{L^2(\Lambda)}\tag6\;,$$ i.e. $(\mathcal R(A),A^{-1})$ is a bounded operator on $L^2(\Lambda)$. Thus, there is a bounded linear operator $\tilde A^{-1}$ on $L^2(\Lambda)$ with $$\tilde A^{-1}v=A^{-1}v\;\;\;\text{for all }v\in\mathcal R(A)\tag 7\;.$$ Now, by the Rellich–Kondrachov theorem the inclusion $\iota$ from $H_0^1(\Lambda)$ into $L^2(\Lambda)$ is compact and hence $\tilde A^{-1}\iota$ is compact; but that's of no use here, is it?",,"['functional-analysis', 'operator-theory', 'compact-operators', 'laplacian', 'unbounded-operators']"
16,"Legendre-Fenchel transformation for $\varphi\, \Big(\,x\, ,\, f\,\big(\,\Phi\,(\,x\,)\,\big)\,\Big)$.",Legendre-Fenchel transformation for .,"\varphi\, \Big(\,x\, ,\, f\,\big(\,\Phi\,(\,x\,)\,\big)\,\Big)","The convex conjugate also known as Legendre–Fenchel transformation of a convex function $f:\mathbb{R}^n\to\mathbb{R}\cup\{+\infty\}$ is definite by  $$ f^{\ast}(x^\ast)=\sup_{x\in\mathbb{R}^n}\{\langle x,x^\ast\rangle -f(x)\} $$ Question. For what functions, $\varphi:\mathbb{R}\times\mathbb{R}\cup\{+\infty\}\to \mathbb{R}\cup\{+\infty\}$ and $\Phi: \mathbb{R}^n\to \mathbb{R}^n$  known a priori there are functions  $\psi: \mathbb{R}\times\mathbb{R}\cup\{+\infty\}\to \mathbb{R}\cup\{+\infty\}$ and $\Psi:\mathbb{R}^n\to \mathbb{R}^n$ such that   $$  \Big\lgroup \varphi\, \Big(\, x \, ,             \,f\circ \Phi\,(\,x\,)\,         \Big) \Big\rgroup^{\ast} = \psi \Big(             x^\ast,\,f^{\ast}\circ\Psi\,(\,x^\ast)\,      \Big) ? $$ In my efforts, I found in wikipedia a table below with some transformations that answer my question for some very particular cases.  To be more precise in what I am looking for a theorem which schematically says more or less the following. Theorem. Let a convex function  $f:\mathbb{R}^n\to \mathbb{R}\cup \{\infty\}$ ( not identically equal to infinity). Let functions $\varphi: \mathbb{R}\times \mathbb{R}\cup \{\infty\}\to \mathbb{R}\cup \{\infty\} $ and $\Phi: \mathbb{R}^n\to \mathbb{R}\cup \{\infty\}$. Supose that Assumption 1 : $\varphi$  satisfies the following suitable conditions... Assumption 2 : $\Phi$  satisfies the following suitable conditions... Then there are functions  $\psi: \mathbb{R}\times\mathbb{R}\cup\{+\infty\}\to \mathbb{R}\cup\{+\infty\}$ and $\Psi:\mathbb{R}^n\to \mathbb{R}^n$ such that   $$  \Big\lgroup \varphi\, \Big(\, x \, ,             \,f\circ \Phi\,(\,x\,)\,         \Big) \Big\rgroup^{\ast} = \psi \Big(             x^\ast,\,f^{\ast}\circ\Psi\,(\,x^\ast)\,      \Big)$$ In case $n = 1$ the first four lines of the table give a positive answer to my question under the condition that $\Phi$ and $\varphi$ are afim functions, that is, $$ \varphi (x,y) = \alpha +\beta \cdot x+  \gamma \cdot y  \qquad \Phi (x)= \lambda \cdot x + \delta \qquad \gamma >0  $$ then there are functions $\psi$ and $\Psi$ as above such that $$ \psi(x^\ast,y^\ast )= -\alpha -\delta\cdot\frac{x^\ast-\beta}{\lambda}\  +\lambda \cdot y^\ast  \qquad \Psi(x^\ast)=\frac{x^\ast -\beta}{\lambda\cdot \gamma} $$","The convex conjugate also known as Legendre–Fenchel transformation of a convex function $f:\mathbb{R}^n\to\mathbb{R}\cup\{+\infty\}$ is definite by  $$ f^{\ast}(x^\ast)=\sup_{x\in\mathbb{R}^n}\{\langle x,x^\ast\rangle -f(x)\} $$ Question. For what functions, $\varphi:\mathbb{R}\times\mathbb{R}\cup\{+\infty\}\to \mathbb{R}\cup\{+\infty\}$ and $\Phi: \mathbb{R}^n\to \mathbb{R}^n$  known a priori there are functions  $\psi: \mathbb{R}\times\mathbb{R}\cup\{+\infty\}\to \mathbb{R}\cup\{+\infty\}$ and $\Psi:\mathbb{R}^n\to \mathbb{R}^n$ such that   $$  \Big\lgroup \varphi\, \Big(\, x \, ,             \,f\circ \Phi\,(\,x\,)\,         \Big) \Big\rgroup^{\ast} = \psi \Big(             x^\ast,\,f^{\ast}\circ\Psi\,(\,x^\ast)\,      \Big) ? $$ In my efforts, I found in wikipedia a table below with some transformations that answer my question for some very particular cases.  To be more precise in what I am looking for a theorem which schematically says more or less the following. Theorem. Let a convex function  $f:\mathbb{R}^n\to \mathbb{R}\cup \{\infty\}$ ( not identically equal to infinity). Let functions $\varphi: \mathbb{R}\times \mathbb{R}\cup \{\infty\}\to \mathbb{R}\cup \{\infty\} $ and $\Phi: \mathbb{R}^n\to \mathbb{R}\cup \{\infty\}$. Supose that Assumption 1 : $\varphi$  satisfies the following suitable conditions... Assumption 2 : $\Phi$  satisfies the following suitable conditions... Then there are functions  $\psi: \mathbb{R}\times\mathbb{R}\cup\{+\infty\}\to \mathbb{R}\cup\{+\infty\}$ and $\Psi:\mathbb{R}^n\to \mathbb{R}^n$ such that   $$  \Big\lgroup \varphi\, \Big(\, x \, ,             \,f\circ \Phi\,(\,x\,)\,         \Big) \Big\rgroup^{\ast} = \psi \Big(             x^\ast,\,f^{\ast}\circ\Psi\,(\,x^\ast)\,      \Big)$$ In case $n = 1$ the first four lines of the table give a positive answer to my question under the condition that $\Phi$ and $\varphi$ are afim functions, that is, $$ \varphi (x,y) = \alpha +\beta \cdot x+  \gamma \cdot y  \qquad \Phi (x)= \lambda \cdot x + \delta \qquad \gamma >0  $$ then there are functions $\psi$ and $\Psi$ as above such that $$ \psi(x^\ast,y^\ast )= -\alpha -\delta\cdot\frac{x^\ast-\beta}{\lambda}\  +\lambda \cdot y^\ast  \qquad \Psi(x^\ast)=\frac{x^\ast -\beta}{\lambda\cdot \gamma} $$",,"['real-analysis', 'functional-analysis', 'analysis', 'convex-analysis']"
17,Example appliction of Nash-Moser inverse function theorem,Example appliction of Nash-Moser inverse function theorem,,"I have basic knowledge of PDE and know how to use the standard (Banach space) inverse function theorem to solve $$ -\Delta u+ g(u)=f $$ when $g(0)=g'(0)=0$ and $f$ is small: Define $A(u):=-\Delta u+g\circ u$. Then $A(0)=0$ $A'(0)v=-\Delta v$ is invertible for example if we consider $A\colon C^{2,\alpha}\to C^{0,\alpha}$ and $A'(0)\colon C^{2,\alpha}\to C^{0,\alpha}$. Therefore, for small enough $\|f\|_{C^{0,\alpha}}$, there is a solution $u\in C^{2,\alpha}$ of $A(u)=f$. Is there a similarly simple example for the application of the Nash-Moser inverse function theorem? A side question that is easier to answer than the main question: According to Wikipedia, the Nash-Moser theorem is helpful when the inverse of the derivative loses derivatives. Does this mean that the inverse is for example a map $C^{0,\beta}\to C^{2,\alpha}$ with $\beta>\alpha$ or does it actually mean that derivatives are lost in the sense that the inverse is for example a map $C^{2,\beta}\to C^{2,\alpha}$ with $\beta>\alpha$? In any case, why would this preclude application of the standard inverse function theorem (on smaller spaces)?","I have basic knowledge of PDE and know how to use the standard (Banach space) inverse function theorem to solve $$ -\Delta u+ g(u)=f $$ when $g(0)=g'(0)=0$ and $f$ is small: Define $A(u):=-\Delta u+g\circ u$. Then $A(0)=0$ $A'(0)v=-\Delta v$ is invertible for example if we consider $A\colon C^{2,\alpha}\to C^{0,\alpha}$ and $A'(0)\colon C^{2,\alpha}\to C^{0,\alpha}$. Therefore, for small enough $\|f\|_{C^{0,\alpha}}$, there is a solution $u\in C^{2,\alpha}$ of $A(u)=f$. Is there a similarly simple example for the application of the Nash-Moser inverse function theorem? A side question that is easier to answer than the main question: According to Wikipedia, the Nash-Moser theorem is helpful when the inverse of the derivative loses derivatives. Does this mean that the inverse is for example a map $C^{0,\beta}\to C^{2,\alpha}$ with $\beta>\alpha$ or does it actually mean that derivatives are lost in the sense that the inverse is for example a map $C^{2,\beta}\to C^{2,\alpha}$ with $\beta>\alpha$? In any case, why would this preclude application of the standard inverse function theorem (on smaller spaces)?",,"['functional-analysis', 'partial-differential-equations', 'nonlinear-analysis', 'inverse-function-theorem']"
18,"State space of $C([0,1])$",State space of,"C([0,1])","Consider the $C^*$-algebra $A := C(X)$, where $X$ is a compact Hausdorff space. Denote by $S(A)$ the state space of $A$. In the weak$^*$ topology this is a convex compact set such that $S(A)$ is the closed convex hull of its extreme points. By using the Riesz-Kakutani representation theorem it is easy to see that the pure states (extreme points of $S(A)$) are exactly the point evaluations. Is there an adhoc proof of this fact ?","Consider the $C^*$-algebra $A := C(X)$, where $X$ is a compact Hausdorff space. Denote by $S(A)$ the state space of $A$. In the weak$^*$ topology this is a convex compact set such that $S(A)$ is the closed convex hull of its extreme points. By using the Riesz-Kakutani representation theorem it is easy to see that the pure states (extreme points of $S(A)$) are exactly the point evaluations. Is there an adhoc proof of this fact ?",,"['functional-analysis', 'operator-algebras']"
19,Significance and application of Riesz Decomposition Theorem,Significance and application of Riesz Decomposition Theorem,,"The Riesz Decomposition Theorem in Operator Theory is given as: Let $a \in \mathcal{A}$ (for unital Banach algebra $\mathcal{A}$) Suppose $\sigma(a) = \sigma_1 \cup \sigma_2$ where $\sigma_1 \cap \sigma_2 = \emptyset$. Then: $\exists$ non-trivial idempotents $E_1~,E_2 \in \mathcal{A}$ such that $E_1 + E_2 = 1$. If $\mathcal{A} \subset \mathcal{L(X)}$ ($X$ Banach space) then $E_1X, ~E_2X$ are closed subspaces invariant  for $a$ and $E_1X \oplus E_2X = X$. If $a_k = aE_k$ then $\sigma(a_k) = \sigma_k$ (for $k=1,2$) and for any $f \in Hol(a)$ we have $$f(a_k) = f(a)E_k.$$ Question: What is the significance of these results, how is it most commonly used? At the moment it seems like an arbitrary collection of results, but as I understand it is an important result in operator and spectral theory. Also, what are the applications in quantum mechanics? Thanks.","The Riesz Decomposition Theorem in Operator Theory is given as: Let $a \in \mathcal{A}$ (for unital Banach algebra $\mathcal{A}$) Suppose $\sigma(a) = \sigma_1 \cup \sigma_2$ where $\sigma_1 \cap \sigma_2 = \emptyset$. Then: $\exists$ non-trivial idempotents $E_1~,E_2 \in \mathcal{A}$ such that $E_1 + E_2 = 1$. If $\mathcal{A} \subset \mathcal{L(X)}$ ($X$ Banach space) then $E_1X, ~E_2X$ are closed subspaces invariant  for $a$ and $E_1X \oplus E_2X = X$. If $a_k = aE_k$ then $\sigma(a_k) = \sigma_k$ (for $k=1,2$) and for any $f \in Hol(a)$ we have $$f(a_k) = f(a)E_k.$$ Question: What is the significance of these results, how is it most commonly used? At the moment it seems like an arbitrary collection of results, but as I understand it is an important result in operator and spectral theory. Also, what are the applications in quantum mechanics? Thanks.",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'applications', 'banach-algebras']"
20,Is there a unique finitely additive extension of a countably additive product probability measure to the product $\sigma$-algebra for finite products?,Is there a unique finitely additive extension of a countably additive product probability measure to the product -algebra for finite products?,\sigma,"Consider a finite collection of measure spaces $\{(A_i, \mathcal{A}_i)\}_{i=1}^N$ where each $\mathcal{A}_i$ is a $\sigma$-algebra. Let $\mathcal{A}$ be the algebra on $\prod_{i=1}^N A_i$ generated by the sets of the form $B_1\times\cdots\times B_N$ with $B_i \in \mathcal{A}_i$. Suppose that for each $i$ we have a countably additive probability measure $\tau_i$ on $\mathcal{A}_i$. Let $\tau$ be the measure on $\mathcal{A}$ defined by  $$\tau(B_1\times\cdots\times B_N) = \tau_1(B_1)\times\cdots\times\tau_N(B_N)$$ when $B_i \in \mathcal{A}_i$ for each $i$. The measure $\tau$ is countably additive on $\mathcal{A}$, so the Carathéodory extension theorem lets us extend $\tau$ to a countably additive measure (which we will call $\hat{\tau}$) on $\sigma(\mathcal{A})$. The extension $\hat{\tau}$ is the only countably additive extension of $\tau$ and it is a probability measure. My question: Is $\hat{\tau}$ the only finitely additive extension of $\tau$ to a probability measure on $\sigma(\mathcal{A})$? What if each $A_i$ is a separable metric space with the Borel $\sigma$-algebra? Note : By probability measure I mean a non-negative, finitely additive set function that assigns $1$ to the whole space. I.e, probability measure does not assume countable additivity. Second note : The answer to the question is yes when each $A_i$ is countable and $\mathcal{A}_i$ is the discrete $\sigma$-algebra. The reason is that we are able to write each set in $\sigma(\mathcal{A})$ as a countable union of sets in $\mathcal{A}$: Let $\mu$ be some finitely additive extension of $\tau$ to a probability measure. Since $\mu$ is a probability measure, it is monotone. Then, for any $B \in \sigma(\mathcal{A})$, $$\mu(B) \geq \sum_{b \in B} \tau(\{b\}) = \hat{\tau}(B)$$ and the same argument shows that $\mu(B^c) \geq \hat{\tau}(B^c)$. Since $\hat\tau$ and $\mu$ are finitely additive and assign probability $1$ to $A$, this implies that $\mu(B) = \hat{\tau}(B)$. Third note : The second note implies that the answer is yes when each $\tau_i$ is a (finite or countable) sum of point masses since we can just ignore all of the other points. An almost proof that the answer is yes : In Finitely Additive Measures by Yosida and Hewitt, Theorem 1.23 says that any non-negative finitely additive measure $\phi$ has a unique decomposition $\phi = \phi_c + \phi_p$ where $\phi_c$ is countably additive and non-negative and $\phi_p$ is purely finitely additive and non-negative. The measure $\phi_p$ being purely finitely additive means (for non-negative measures) that if $\psi$ is any countably additive measure with $0\leq\psi\leq \phi_p$, then $\psi = 0$. In our situation, we might conjecture that if $\tau'$ is any probability measure extending $\tau$, then $\tau'_c = \hat{\tau}$. This would mean that $\tau'_p(A) = 0$, so $\tau'_p = 0$. The important thing here was that we knew that $\tau'_p \geq 0$.","Consider a finite collection of measure spaces $\{(A_i, \mathcal{A}_i)\}_{i=1}^N$ where each $\mathcal{A}_i$ is a $\sigma$-algebra. Let $\mathcal{A}$ be the algebra on $\prod_{i=1}^N A_i$ generated by the sets of the form $B_1\times\cdots\times B_N$ with $B_i \in \mathcal{A}_i$. Suppose that for each $i$ we have a countably additive probability measure $\tau_i$ on $\mathcal{A}_i$. Let $\tau$ be the measure on $\mathcal{A}$ defined by  $$\tau(B_1\times\cdots\times B_N) = \tau_1(B_1)\times\cdots\times\tau_N(B_N)$$ when $B_i \in \mathcal{A}_i$ for each $i$. The measure $\tau$ is countably additive on $\mathcal{A}$, so the Carathéodory extension theorem lets us extend $\tau$ to a countably additive measure (which we will call $\hat{\tau}$) on $\sigma(\mathcal{A})$. The extension $\hat{\tau}$ is the only countably additive extension of $\tau$ and it is a probability measure. My question: Is $\hat{\tau}$ the only finitely additive extension of $\tau$ to a probability measure on $\sigma(\mathcal{A})$? What if each $A_i$ is a separable metric space with the Borel $\sigma$-algebra? Note : By probability measure I mean a non-negative, finitely additive set function that assigns $1$ to the whole space. I.e, probability measure does not assume countable additivity. Second note : The answer to the question is yes when each $A_i$ is countable and $\mathcal{A}_i$ is the discrete $\sigma$-algebra. The reason is that we are able to write each set in $\sigma(\mathcal{A})$ as a countable union of sets in $\mathcal{A}$: Let $\mu$ be some finitely additive extension of $\tau$ to a probability measure. Since $\mu$ is a probability measure, it is monotone. Then, for any $B \in \sigma(\mathcal{A})$, $$\mu(B) \geq \sum_{b \in B} \tau(\{b\}) = \hat{\tau}(B)$$ and the same argument shows that $\mu(B^c) \geq \hat{\tau}(B^c)$. Since $\hat\tau$ and $\mu$ are finitely additive and assign probability $1$ to $A$, this implies that $\mu(B) = \hat{\tau}(B)$. Third note : The second note implies that the answer is yes when each $\tau_i$ is a (finite or countable) sum of point masses since we can just ignore all of the other points. An almost proof that the answer is yes : In Finitely Additive Measures by Yosida and Hewitt, Theorem 1.23 says that any non-negative finitely additive measure $\phi$ has a unique decomposition $\phi = \phi_c + \phi_p$ where $\phi_c$ is countably additive and non-negative and $\phi_p$ is purely finitely additive and non-negative. The measure $\phi_p$ being purely finitely additive means (for non-negative measures) that if $\psi$ is any countably additive measure with $0\leq\psi\leq \phi_p$, then $\psi = 0$. In our situation, we might conjecture that if $\tau'$ is any probability measure extending $\tau$, then $\tau'_c = \hat{\tau}$. This would mean that $\tau'_p(A) = 0$, so $\tau'_p = 0$. The important thing here was that we knew that $\tau'_p \geq 0$.",,"['functional-analysis', 'measure-theory']"
21,Prove the space of bounded sequences is Banach,Prove the space of bounded sequences is Banach,,"http://www.math.ucla.edu/~tao/resource/general/121.1.00s/exam1sol.pdf Here is a proof, but I cannot fully understand why it does not give a proof that $x$ is a bounded sequence (i.e. $x$ is in the space). It seems that the proof only shows that the Cauchy sequence in the space converges to $x$. But $x$ is not shown to be definitely in the space.","http://www.math.ucla.edu/~tao/resource/general/121.1.00s/exam1sol.pdf Here is a proof, but I cannot fully understand why it does not give a proof that $x$ is a bounded sequence (i.e. $x$ is in the space). It seems that the proof only shows that the Cauchy sequence in the space converges to $x$. But $x$ is not shown to be definitely in the space.",,"['real-analysis', 'functional-analysis', 'proof-verification', 'proof-explanation', 'cauchy-sequences']"
22,Complemented $\ell_q$ subspaces of $(\oplus_n\ell_p^n)_\infty$,Complemented  subspaces of,\ell_q (\oplus_n\ell_p^n)_\infty,"Fix $1\leq p<\infty$, and denote \begin{equation*}(\oplus_n\ell_p^n)_\infty=\left\{\left((a_i^{(n)})_{i=1}^n\right)_{n=1}^\infty:\left(\|(a_i^{(n)})_{i=1}^n\|_p\right)_{n=1}^\infty\in\ell_\infty\right\}\end{equation*} i.e. the $\ell_\infty$-sum of $\ell_p^n$'s, endowed with the obvious norm.  Furthermore, if $X$ is a Banach space then we denote by $\ell_\infty(X)$ the $\ell_\infty$-sum of infinitely many copies of $X$. Question. For which values $q\in[1,\infty]$ is $\ell_q$ isomorphic to a complemented subspace of $(\oplus_n\ell_p^n)_\infty$? Let me summarize what I know so far.  Clearly, $q=\infty$ works.  Taking $q=p$ also works, as is mentioned in Remark 3.4 of the paper ""On the mutually non isomorphic $\ell_p(\ell_q)$ spaces"" by Cembranos/Mendoza. One might conjecture that these are the only $q$'s that work, but actually whenever $p\in(1,\infty)$ we also get $\ell_2$ complemented.  Here's how. Theorem 1. $(\oplus_n\ell_p^n)_\infty$ is isomorphic to $\ell_\infty(\ell_p)$. This is just from Remark 3.4 in Cembranos/Mendoza.  Let us give some more info from that paper. Corollary 1. The space $\ell_q$, $q\in[1,\infty]$, is isomorphic to a complemented subspace of $(\oplus_n\ell_1^n)_\infty$ if and only if $q=1$ or $q=\infty$. (See Prop. 6.1.)  On the other hand, Cembranos/Mendoza showed in Proposition 3.5 that $\ell_2$ is complemented in $\ell_\infty(\ell_p)$ whenever $1<p<\infty$.  Hence: Corollary 2. The space $\ell_2$ is isomorphic to a complemented subspace of $(\oplus_n\ell_p^n)_\infty$ if and only if $1<p<\infty$. Using Theorem 1 above to replace ""$\ell_\infty(\ell_p)$"" with ""$(\oplus_n\ell_p^n)_\infty$"" in Proposition 4.3 of Cembranos/Mendoza, we also have the following. Corollary 3. If the space $\ell_q$, $q\in(1,\infty)$, is isomorphic to a complemented subspace of $(\oplus_n\ell_p^n)_\infty$, $p\in(1,\infty)$, then either $1<p\leq q\leq 2$ or $2\leq q\leq p<\infty$.","Fix $1\leq p<\infty$, and denote \begin{equation*}(\oplus_n\ell_p^n)_\infty=\left\{\left((a_i^{(n)})_{i=1}^n\right)_{n=1}^\infty:\left(\|(a_i^{(n)})_{i=1}^n\|_p\right)_{n=1}^\infty\in\ell_\infty\right\}\end{equation*} i.e. the $\ell_\infty$-sum of $\ell_p^n$'s, endowed with the obvious norm.  Furthermore, if $X$ is a Banach space then we denote by $\ell_\infty(X)$ the $\ell_\infty$-sum of infinitely many copies of $X$. Question. For which values $q\in[1,\infty]$ is $\ell_q$ isomorphic to a complemented subspace of $(\oplus_n\ell_p^n)_\infty$? Let me summarize what I know so far.  Clearly, $q=\infty$ works.  Taking $q=p$ also works, as is mentioned in Remark 3.4 of the paper ""On the mutually non isomorphic $\ell_p(\ell_q)$ spaces"" by Cembranos/Mendoza. One might conjecture that these are the only $q$'s that work, but actually whenever $p\in(1,\infty)$ we also get $\ell_2$ complemented.  Here's how. Theorem 1. $(\oplus_n\ell_p^n)_\infty$ is isomorphic to $\ell_\infty(\ell_p)$. This is just from Remark 3.4 in Cembranos/Mendoza.  Let us give some more info from that paper. Corollary 1. The space $\ell_q$, $q\in[1,\infty]$, is isomorphic to a complemented subspace of $(\oplus_n\ell_1^n)_\infty$ if and only if $q=1$ or $q=\infty$. (See Prop. 6.1.)  On the other hand, Cembranos/Mendoza showed in Proposition 3.5 that $\ell_2$ is complemented in $\ell_\infty(\ell_p)$ whenever $1<p<\infty$.  Hence: Corollary 2. The space $\ell_2$ is isomorphic to a complemented subspace of $(\oplus_n\ell_p^n)_\infty$ if and only if $1<p<\infty$. Using Theorem 1 above to replace ""$\ell_\infty(\ell_p)$"" with ""$(\oplus_n\ell_p^n)_\infty$"" in Proposition 4.3 of Cembranos/Mendoza, we also have the following. Corollary 3. If the space $\ell_q$, $q\in(1,\infty)$, is isomorphic to a complemented subspace of $(\oplus_n\ell_p^n)_\infty$, $p\in(1,\infty)$, then either $1<p\leq q\leq 2$ or $2\leq q\leq p<\infty$.",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
23,Global inf-sup condition in Brezzi (Babuška-Brezzi or Ladyzhenskaya-Babuška-Brezzi) Theorem,Global inf-sup condition in Brezzi (Babuška-Brezzi or Ladyzhenskaya-Babuška-Brezzi) Theorem,,"I'm studing the Brezzi Theorem (also called Babuška-Brezzi or Ladyzhenskaya-Babuška-Brezzi Theorem). The Theorem 1 (on that link) ensures the continuous dependence of the solution, that is $$\|(u,\lambda)\|_{X\times M}\leq C\{\|f\|_{X^*}+\|g\|_{M^*}\}.$$ With this expresion and recalling that $$\|f\|_{X^*}=\sup_{v\in X}\dfrac{\langle f,v\rangle}{\|v\|_X}\quad\text{ and }\quad\|g\|_{M^*}=\sup_{\mu\in M}\dfrac{\langle g,\mu\rangle}{\|\mu\|_M}$$ we obtain that $$\|(u,\lambda)\|_{X\times M}\leq C\left\{\sup_{v\in X}\dfrac{\langle f,v\rangle}{\|v\|_X}+\sup_{\mu\in M}\dfrac{\langle g,\mu\rangle}{\|\mu\|_M}\right\}$$ $$=C\left\{\sup_{v\in X}\dfrac{a(u,v)+b(v,\lambda)}{\|v\|_X}+\sup_{\mu\in M}\dfrac{b({\color{red}u},\mu)}{\|\mu\|_M}\right\}$$ My question is, it is possible to prove the following? $$\boxed{\|(u,\lambda)\|_{X\times M}\leq C\left\{\sup_{(v,\mu)\in X\times M}\dfrac{a(u,v)+b(v,\lambda)+b({\color{red}u},\mu)}{\|(v,\mu)\|_{X\times M}}\right\}}$$ This is something like a global inf-sup condition.","I'm studing the Brezzi Theorem (also called Babuška-Brezzi or Ladyzhenskaya-Babuška-Brezzi Theorem). The Theorem 1 (on that link) ensures the continuous dependence of the solution, that is With this expresion and recalling that we obtain that My question is, it is possible to prove the following? This is something like a global inf-sup condition.","\|(u,\lambda)\|_{X\times M}\leq C\{\|f\|_{X^*}+\|g\|_{M^*}\}. \|f\|_{X^*}=\sup_{v\in X}\dfrac{\langle f,v\rangle}{\|v\|_X}\quad\text{ and }\quad\|g\|_{M^*}=\sup_{\mu\in M}\dfrac{\langle g,\mu\rangle}{\|\mu\|_M} \|(u,\lambda)\|_{X\times M}\leq C\left\{\sup_{v\in X}\dfrac{\langle f,v\rangle}{\|v\|_X}+\sup_{\mu\in M}\dfrac{\langle g,\mu\rangle}{\|\mu\|_M}\right\} =C\left\{\sup_{v\in X}\dfrac{a(u,v)+b(v,\lambda)}{\|v\|_X}+\sup_{\mu\in M}\dfrac{b({\color{red}u},\mu)}{\|\mu\|_M}\right\} \boxed{\|(u,\lambda)\|_{X\times M}\leq C\left\{\sup_{(v,\mu)\in X\times M}\dfrac{a(u,v)+b(v,\lambda)+b({\color{red}u},\mu)}{\|(v,\mu)\|_{X\times M}}\right\}}","['functional-analysis', 'partial-differential-equations', 'supremum-and-infimum']"
24,"$L \log L$-convexity in $L^{1,\infty}$",-convexity in,"L \log L L^{1,\infty}","It can be shown that the Lorentz space $L^{1,\infty}(\mathbb{R}^n)$ (also called weak $L^1$) is not normable and exhibits a lack of convexity. Namely, there exist a sequence $(u_n)\subseteq L^{1,\infty}(\mathbb{R}^n)$ of nonnegative functions and a sequence of real numbers $\lambda_n>0$ such that $\|u_n\|_{1,\infty}\le 1$, $\sum\lambda_n<\infty$, $\sum \lambda_n u_n\not\in L^{1,\infty}$. I read without reference that, however, there is a sort of $L\log L$-convexity: if $(u_n)\subseteq L^{1,\infty}$ is a bounded sequence, $\lambda_n>0$   and $\sum|\lambda_n|(1+|\log\lambda_n|)<\infty$ (or equivalently   $\lambda_n\to 0$ and $\sum|\lambda_n\log\lambda_n|<\infty$), then   $\sum\lambda_n u_n\in L^{1,\infty}$ (meaning that the partial sums converge in the topology of $L^{1,\infty}$). Where can I find a proof of this fact?","It can be shown that the Lorentz space $L^{1,\infty}(\mathbb{R}^n)$ (also called weak $L^1$) is not normable and exhibits a lack of convexity. Namely, there exist a sequence $(u_n)\subseteq L^{1,\infty}(\mathbb{R}^n)$ of nonnegative functions and a sequence of real numbers $\lambda_n>0$ such that $\|u_n\|_{1,\infty}\le 1$, $\sum\lambda_n<\infty$, $\sum \lambda_n u_n\not\in L^{1,\infty}$. I read without reference that, however, there is a sort of $L\log L$-convexity: if $(u_n)\subseteq L^{1,\infty}$ is a bounded sequence, $\lambda_n>0$   and $\sum|\lambda_n|(1+|\log\lambda_n|)<\infty$ (or equivalently   $\lambda_n\to 0$ and $\sum|\lambda_n\log\lambda_n|<\infty$), then   $\sum\lambda_n u_n\in L^{1,\infty}$ (meaning that the partial sums converge in the topology of $L^{1,\infty}$). Where can I find a proof of this fact?",,"['real-analysis', 'functional-analysis', 'reference-request']"
25,Equivalence of definitions of Sobolev space,Equivalence of definitions of Sobolev space,,"I'm reading through Steinbach's book on Eliptic Boundary Value Problems and struggling with understanding of the definition of Sobolev space He defines it as $$H^s(\mathbb R^n) := \{u \in \mathcal S^*(\mathbb R^n) \colon \mathcal J^s u \in L_{2}(\mathbb R^n) \}$$ Where $S(\mathbb R^n)$ is Schwartz space, $\mathcal J^s$ is a Bessel Operator  and $$S^*(\mathbb R^n):= \{T:S(\mathbb R^n) \mapsto \mathbb C : \text{ T linear functional}\}$$ But it can be also defined as:   $$H^s(\mathbb R^n) := W_{2}^{s}(\mathbb R^n) := \{u \in L_{2}(\mathbb R^n) : D^{a}u \in L_{2}(\mathbb R^n),|a| \leq s \} $$ I am struggling to understand how these definitions are the same, since from the first definition each element is a complex functional from Schwartz Space to C, whereas from the second definition each element is an integrable measurable function with integrable measurable weak derivatives. Thank you.","I'm reading through Steinbach's book on Eliptic Boundary Value Problems and struggling with understanding of the definition of Sobolev space He defines it as $$H^s(\mathbb R^n) := \{u \in \mathcal S^*(\mathbb R^n) \colon \mathcal J^s u \in L_{2}(\mathbb R^n) \}$$ Where $S(\mathbb R^n)$ is Schwartz space, $\mathcal J^s$ is a Bessel Operator  and $$S^*(\mathbb R^n):= \{T:S(\mathbb R^n) \mapsto \mathbb C : \text{ T linear functional}\}$$ But it can be also defined as:   $$H^s(\mathbb R^n) := W_{2}^{s}(\mathbb R^n) := \{u \in L_{2}(\mathbb R^n) : D^{a}u \in L_{2}(\mathbb R^n),|a| \leq s \} $$ I am struggling to understand how these definitions are the same, since from the first definition each element is a complex functional from Schwartz Space to C, whereas from the second definition each element is an integrable measurable function with integrable measurable weak derivatives. Thank you.",,"['functional-analysis', 'sobolev-spaces']"
26,Relationship between the distributional Laplacian and the weak Laplacian,Relationship between the distributional Laplacian and the weak Laplacian,,"Let $d\in\mathbb N$ $\Omega\subseteq\mathbb R^d$ be open $\langle\;\cdot\;,\;\cdot\;\rangle$ denote the $L^2(\Omega)$- or $L^2(\Omega,\mathbb R^d)$-inner product (depending on the context) $\mathcal D:=C_c^\infty(\Omega)$ and $$H:=\overline{\mathcal D}^{\langle\;\cdot\;,\;\cdot\;\rangle_H}$$ with $$\langle\phi,\psi\rangle_H:=\langle\phi,\psi\rangle+\langle\nabla\phi,\nabla\psi\rangle\;\;\;\text{for }\phi,\psi\in\mathcal D$$ Let $$\frac{\partial p}{\partial x_i}(\phi):=-p\left(\frac{\partial\phi}{\partial x_i}\right)\;\;\;\text{for }\phi\in\mathcal D$$ and $\nabla p:=\left(\frac{\partial p}{\partial x_1},\ldots,\frac{\partial p}{\partial x_d}\right)^T$ for $p\in\mathcal D'$ and $$(\nabla\cdot p)(\phi):=\sum_{i=1}^d\frac{\partial p_i}{\partial x_i}(\phi)\;\;\;\text{for }\phi\in\mathcal D$$ for $p\in(\mathcal D')^d$. Then, $$\Delta p:=\nabla\cdot\nabla p$$ is the distributional Laplacian of $p\in\mathcal D$ and it's easy to see that $$(\Delta p)(\phi)=p(\Delta\phi)\;\;\;\text{for all }\phi\in\mathcal D\;.\tag 1$$ Now, each $f\in L_{\text{loc}}^1(\Omega)$ can be identified with some unique $\langle f\rangle\in\mathcal D'$ via $$\langle f\rangle:=\left.\langle\;\cdot\;,f\rangle\right|_{\mathcal D}\;.$$ Let $\phi\in\mathcal D$. We can show that $\Delta\langle\phi\rangle$ has a unique extension $F\in H'$ with $$F(v)=-\langle\nabla v,\nabla\phi\rangle\;\;\;\text{for all }v\in H\;.\tag 2$$ We continue to denote $F$ by $\Delta\langle\phi\rangle$. In the same way $\Delta\langle\;\cdot\;\rangle:\mathcal D\to H'$ has a unique extension $L\in\mathfrak L(H,H')$ with $$(Lu)v=-\langle\nabla v,\nabla u\rangle\;\;\;\text{for all }u,v\in H\;.\tag 3$$ If $u\in L_{\text{loc}}^1(\Omega)$ is weakly differentiable, then $v\in L_{\text{loc}}^1(\Omega)$ is called weak Laplacian of $u$, if $$\langle\phi,v\rangle=-\langle\nabla u,\nabla\phi\rangle\;\;\;\text{for all }\phi\in\mathcal D\tag 4\;.$$ In that case, we write $\Delta u:=v$ and $$(\Delta\langle u\rangle)\psi=\langle\Delta u\rangle(\psi)=\langle\psi,\Delta u\rangle=-\langle\nabla\psi,\nabla u\rangle=(Lu)\psi\;\;\;\text{for all }\psi\in\mathcal D\;.\tag 5$$ If each $u\in H$ would admit a weak Laplacian $\Delta u$, it would make sense to continue to denote $L$ by $\Delta\langle\;\cdot\;\rangle$ and the relationship to the weak Laplacian would be clear. So, does each $u$ admit a weak Laplacian in the sense of $(4)$?","Let $d\in\mathbb N$ $\Omega\subseteq\mathbb R^d$ be open $\langle\;\cdot\;,\;\cdot\;\rangle$ denote the $L^2(\Omega)$- or $L^2(\Omega,\mathbb R^d)$-inner product (depending on the context) $\mathcal D:=C_c^\infty(\Omega)$ and $$H:=\overline{\mathcal D}^{\langle\;\cdot\;,\;\cdot\;\rangle_H}$$ with $$\langle\phi,\psi\rangle_H:=\langle\phi,\psi\rangle+\langle\nabla\phi,\nabla\psi\rangle\;\;\;\text{for }\phi,\psi\in\mathcal D$$ Let $$\frac{\partial p}{\partial x_i}(\phi):=-p\left(\frac{\partial\phi}{\partial x_i}\right)\;\;\;\text{for }\phi\in\mathcal D$$ and $\nabla p:=\left(\frac{\partial p}{\partial x_1},\ldots,\frac{\partial p}{\partial x_d}\right)^T$ for $p\in\mathcal D'$ and $$(\nabla\cdot p)(\phi):=\sum_{i=1}^d\frac{\partial p_i}{\partial x_i}(\phi)\;\;\;\text{for }\phi\in\mathcal D$$ for $p\in(\mathcal D')^d$. Then, $$\Delta p:=\nabla\cdot\nabla p$$ is the distributional Laplacian of $p\in\mathcal D$ and it's easy to see that $$(\Delta p)(\phi)=p(\Delta\phi)\;\;\;\text{for all }\phi\in\mathcal D\;.\tag 1$$ Now, each $f\in L_{\text{loc}}^1(\Omega)$ can be identified with some unique $\langle f\rangle\in\mathcal D'$ via $$\langle f\rangle:=\left.\langle\;\cdot\;,f\rangle\right|_{\mathcal D}\;.$$ Let $\phi\in\mathcal D$. We can show that $\Delta\langle\phi\rangle$ has a unique extension $F\in H'$ with $$F(v)=-\langle\nabla v,\nabla\phi\rangle\;\;\;\text{for all }v\in H\;.\tag 2$$ We continue to denote $F$ by $\Delta\langle\phi\rangle$. In the same way $\Delta\langle\;\cdot\;\rangle:\mathcal D\to H'$ has a unique extension $L\in\mathfrak L(H,H')$ with $$(Lu)v=-\langle\nabla v,\nabla u\rangle\;\;\;\text{for all }u,v\in H\;.\tag 3$$ If $u\in L_{\text{loc}}^1(\Omega)$ is weakly differentiable, then $v\in L_{\text{loc}}^1(\Omega)$ is called weak Laplacian of $u$, if $$\langle\phi,v\rangle=-\langle\nabla u,\nabla\phi\rangle\;\;\;\text{for all }\phi\in\mathcal D\tag 4\;.$$ In that case, we write $\Delta u:=v$ and $$(\Delta\langle u\rangle)\psi=\langle\Delta u\rangle(\psi)=\langle\psi,\Delta u\rangle=-\langle\nabla\psi,\nabla u\rangle=(Lu)\psi\;\;\;\text{for all }\psi\in\mathcal D\;.\tag 5$$ If each $u\in H$ would admit a weak Laplacian $\Delta u$, it would make sense to continue to denote $L$ by $\Delta\langle\;\cdot\;\rangle$ and the relationship to the weak Laplacian would be clear. So, does each $u$ admit a weak Laplacian in the sense of $(4)$?",,"['functional-analysis', 'operator-theory', 'sobolev-spaces', 'distribution-theory', 'weak-derivatives']"
27,"Given $S \in B(Y^{*}, X^{*})$, does there exist $T\in B(X,Y)$ such that $S=T^{*}$?","Given , does there exist  such that ?","S \in B(Y^{*}, X^{*}) T\in B(X,Y) S=T^{*}","Let $X, Y$ be Banach spaces, $S \in B(Y^{*}, X^{*})$. Does such operator $T \in B(X, Y)$ exist so that $T^{*}=S$? I suppose that the answer should be - no. Are there any hints that might help in constructing a counterexample? Any help would be much appreciated.","Let $X, Y$ be Banach spaces, $S \in B(Y^{*}, X^{*})$. Does such operator $T \in B(X, Y)$ exist so that $T^{*}=S$? I suppose that the answer should be - no. Are there any hints that might help in constructing a counterexample? Any help would be much appreciated.",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
28,Hadamard counterexample Dirichlet-problem,Hadamard counterexample Dirichlet-problem,,"Good afternoon, I try to understand the follwoing counterexample of Hadamard: The classical solution of $ \begin{cases} \Delta u = 0 ~~\text{ in }\Omega\\ u=g \text{ auf }~~ \partial \Omega \end{cases} $ with $u \in C^2(\Omega) \cap C(\partial \Omega)$ not always lies in $H^1(\Omega)$ . To show this Hadamard took the function $ \begin{equation}      u(r, \phi) = \sum\limits_{n=0}^{\infty}r^{n!}\frac{sin(n! \phi)}{n^2} \end{equation} $ in polar-coordinates on $\Omega =$ ""the unit-disk"". After computing the Laplacian in polar coordinates it was very easy to show that this function is indeed a classical solution (i.e. u harmonic) but now I am supposed to choose an appropriate boundary value function $g \in C(\partial \Omega)$ , such that this $u(r,\phi)$ is not in $H^1(\Omega)$ . Can someone help? By the way in our lecture we had the statement that harmonic functions have minimal seminorms, perhaps this could be useful.","Good afternoon, I try to understand the follwoing counterexample of Hadamard: The classical solution of with not always lies in . To show this Hadamard took the function in polar-coordinates on ""the unit-disk"". After computing the Laplacian in polar coordinates it was very easy to show that this function is indeed a classical solution (i.e. u harmonic) but now I am supposed to choose an appropriate boundary value function , such that this is not in . Can someone help? By the way in our lecture we had the statement that harmonic functions have minimal seminorms, perhaps this could be useful.","
\begin{cases}
\Delta u = 0 ~~\text{ in }\Omega\\
u=g \text{ auf }~~ \partial \Omega
\end{cases}
 u \in C^2(\Omega) \cap C(\partial \Omega) H^1(\Omega) 
\begin{equation}
     u(r, \phi) = \sum\limits_{n=0}^{\infty}r^{n!}\frac{sin(n! \phi)}{n^2}
\end{equation}
 \Omega = g \in C(\partial \Omega) u(r,\phi) H^1(\Omega)","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
29,When is a mapping the proximity operator of some convex function?,When is a mapping the proximity operator of some convex function?,,"Sorry for cross-posting from MO . It's been a few days and the question hasn't received any attention there. So, is there a characterization of mappings $p : \mathbb R^n \rightarrow \mathbb R^n$ which are proximity operators ( in the sense of Moreau ) of l.s.c (extended) real-valued functions ? That is, given $p : \mathbb R^n \rightarrow \mathbb R^n$, under what sufficient conditions does there exist an extended-valued l.s.c  convex function $g:\mathbb R^n \rightarrow (-\infty, +\infty]$ such that $$p(x) \equiv \mathrm{prox}_g(x) := \underset{z \in \mathbb R^n}{\text{argmin }}\frac{1}{2}\|z-x\|_2^2 + g(z) \;?$$ N.B: Of course it's necessary that $p$ be firmly-nonexpansive, and have other classical properties of prox operators. Motivation: In regularization techniques for signal / image processing, one usually proposes to minimize an energy of the form $f(x) + g(x)$, where $x=x^*$ is the image to be recovered from noisy / corrupted measures, $f(x)$ is a data fidelity term and measures the ""fit"" of the model, while $g(x)$ is a regularization term that imposes some structural constraints. For example, one can take $f(x) = \frac{1}{2}\|y-Ax\|_2^2$, under a additve Gaussian-noise assumption, where $y$ is the observed image and $A$ is a sensing linear operator, so that $y \approx Ax + \text{ noise}$, etc., etc. A brilliant idea that has been proposed in Social Sparsity! is to impose the penalty $g$ only implicitly, by instead constructing its proximal operator $p(x)$, i.e by stating the intended shrinkage action of $g$ on the model coefficients $x_j$. For a concrete example, think of a (fictional) world in which we didn't know about the $\ell_1$ norm, but instead decided to invent the Lasso by stating that the prox of the (unknown) $\ell_1$ penalty should shrink the coefficients according to the soft-thresholder $$(p(x))_j = st_{\lambda}(x_j) = sign(x_j)(|x_j| - \lambda)_+,$$ where $\lambda > 0$ is a regularization parameter and $sign(x_j): = -sign(-x_j) = 1$ if $ x_j > 0$ and $0$ else. Note that the above prox would correspond to a penalty $g(x) = \lambda \|x\|_1$, and acts component-wise only because we're assuming (in this example) a separable penalty. The question is then: How to show that $st_{\lambda}$ actually corresponds to the proximal operator of some penalty function. Update I've accepted an answer here , under the original MO post.","Sorry for cross-posting from MO . It's been a few days and the question hasn't received any attention there. So, is there a characterization of mappings $p : \mathbb R^n \rightarrow \mathbb R^n$ which are proximity operators ( in the sense of Moreau ) of l.s.c (extended) real-valued functions ? That is, given $p : \mathbb R^n \rightarrow \mathbb R^n$, under what sufficient conditions does there exist an extended-valued l.s.c  convex function $g:\mathbb R^n \rightarrow (-\infty, +\infty]$ such that $$p(x) \equiv \mathrm{prox}_g(x) := \underset{z \in \mathbb R^n}{\text{argmin }}\frac{1}{2}\|z-x\|_2^2 + g(z) \;?$$ N.B: Of course it's necessary that $p$ be firmly-nonexpansive, and have other classical properties of prox operators. Motivation: In regularization techniques for signal / image processing, one usually proposes to minimize an energy of the form $f(x) + g(x)$, where $x=x^*$ is the image to be recovered from noisy / corrupted measures, $f(x)$ is a data fidelity term and measures the ""fit"" of the model, while $g(x)$ is a regularization term that imposes some structural constraints. For example, one can take $f(x) = \frac{1}{2}\|y-Ax\|_2^2$, under a additve Gaussian-noise assumption, where $y$ is the observed image and $A$ is a sensing linear operator, so that $y \approx Ax + \text{ noise}$, etc., etc. A brilliant idea that has been proposed in Social Sparsity! is to impose the penalty $g$ only implicitly, by instead constructing its proximal operator $p(x)$, i.e by stating the intended shrinkage action of $g$ on the model coefficients $x_j$. For a concrete example, think of a (fictional) world in which we didn't know about the $\ell_1$ norm, but instead decided to invent the Lasso by stating that the prox of the (unknown) $\ell_1$ penalty should shrink the coefficients according to the soft-thresholder $$(p(x))_j = st_{\lambda}(x_j) = sign(x_j)(|x_j| - \lambda)_+,$$ where $\lambda > 0$ is a regularization parameter and $sign(x_j): = -sign(-x_j) = 1$ if $ x_j > 0$ and $0$ else. Note that the above prox would correspond to a penalty $g(x) = \lambda \|x\|_1$, and acts component-wise only because we're assuming (in this example) a separable penalty. The question is then: How to show that $st_{\lambda}$ actually corresponds to the proximal operator of some penalty function. Update I've accepted an answer here , under the original MO post.",,"['functional-analysis', 'reference-request', 'convex-analysis', 'signal-processing', 'image-processing']"
30,"Regularity, Dirichlet form","Regularity, Dirichlet form",,"I have a question about Dirichlet form. Let $\Omega$ be an Euclidean domain of $\mathbb{R}^{N}$ and  $X=\bar{\Omega}$. The measure $m$ on the Borel  $\sigma$ algebra $\mathcal{B}(X)$ is given by $m(A)=\lambda(A \cap \Omega)$ for all $A \in \mathcal{B}(X)$ with $\lambda $ the Lebesgue measure. It follows that $L^{2}(\Omega)=L^{2}(X,\mathcal{B}(X),m)$. We define a Dirichlet form on $L^{2}(\Omega)$ by  \begin{equation*} \mathcal{E}(f,g)=\int_{\Omega}\left(\nabla f,\nabla g \right)\,dx,\quad f,g \in \widetilde{H}^{1}(\Omega), \end{equation*} where $\widetilde{H}^{1}(\Omega)=\text{closure of }H^{1}(\Omega)\cap C_{c}(\bar{\Omega}) \text{ in } H^{1}(\Omega)$. $C_{c}(\bar{\Omega})$ denotes all continuous reak valued function on $\bar{\Omega}$ with support and $H^{1}(\Omega) \cap C_{c}(\bar{\Omega})=\left\{ f \left| \right._{\Omega} \in H^{1}(\Omega) : f \in C_{c}(\bar{\Omega}) \right\}$. Question I want to check the following assertion: \begin{align*} &(1) \quad \widetilde{H}^{1}(\Omega) \cap C_{c}(\bar{\Omega}) \text{ is dense in } C_{c}(\bar{\Omega}) \text{ w.r.t. sup norm}. \end{align*} My attempt (1): It is enough to show that for all $ f \in C_{c}(\bar{\Omega})$, $\epsilon>0$, there exists $g \in H_{1}(\Omega) \cap C_{c}(\bar{\Omega})$ such that $\|f-g\|<\epsilon$, where $\|\cdot\|$ is sup norm. Take $f \in C_{c}(\bar{\Omega})$. By Tietze extension theorem, we can find $F \in C_{c}(\mathbb{R}^{n})$ such that $F=f$ on $\bar{\Omega}$. Define $F_{\delta}=\int_{\mathbb{R}^{n}}j_{\delta}(x-y)F(y)\,dy$, where $j_{\delta}$ is standard mollifier. Then $F_{\delta } \to f$ uniformly on $\text{supp} [f]$ and $F_{\delta} \in C_{c}^{\infty}(\mathbb{R}^{n})$. But I don't know how to prove $F_{\delta} \left|_{\Omega} \right. \in H_{1}(\Omega) \cap C_{c}(\bar{\Omega})$. Please tell me how to prove (2). Thank you in advance.","I have a question about Dirichlet form. Let $\Omega$ be an Euclidean domain of $\mathbb{R}^{N}$ and  $X=\bar{\Omega}$. The measure $m$ on the Borel  $\sigma$ algebra $\mathcal{B}(X)$ is given by $m(A)=\lambda(A \cap \Omega)$ for all $A \in \mathcal{B}(X)$ with $\lambda $ the Lebesgue measure. It follows that $L^{2}(\Omega)=L^{2}(X,\mathcal{B}(X),m)$. We define a Dirichlet form on $L^{2}(\Omega)$ by  \begin{equation*} \mathcal{E}(f,g)=\int_{\Omega}\left(\nabla f,\nabla g \right)\,dx,\quad f,g \in \widetilde{H}^{1}(\Omega), \end{equation*} where $\widetilde{H}^{1}(\Omega)=\text{closure of }H^{1}(\Omega)\cap C_{c}(\bar{\Omega}) \text{ in } H^{1}(\Omega)$. $C_{c}(\bar{\Omega})$ denotes all continuous reak valued function on $\bar{\Omega}$ with support and $H^{1}(\Omega) \cap C_{c}(\bar{\Omega})=\left\{ f \left| \right._{\Omega} \in H^{1}(\Omega) : f \in C_{c}(\bar{\Omega}) \right\}$. Question I want to check the following assertion: \begin{align*} &(1) \quad \widetilde{H}^{1}(\Omega) \cap C_{c}(\bar{\Omega}) \text{ is dense in } C_{c}(\bar{\Omega}) \text{ w.r.t. sup norm}. \end{align*} My attempt (1): It is enough to show that for all $ f \in C_{c}(\bar{\Omega})$, $\epsilon>0$, there exists $g \in H_{1}(\Omega) \cap C_{c}(\bar{\Omega})$ such that $\|f-g\|<\epsilon$, where $\|\cdot\|$ is sup norm. Take $f \in C_{c}(\bar{\Omega})$. By Tietze extension theorem, we can find $F \in C_{c}(\mathbb{R}^{n})$ such that $F=f$ on $\bar{\Omega}$. Define $F_{\delta}=\int_{\mathbb{R}^{n}}j_{\delta}(x-y)F(y)\,dy$, where $j_{\delta}$ is standard mollifier. Then $F_{\delta } \to f$ uniformly on $\text{supp} [f]$ and $F_{\delta} \in C_{c}^{\infty}(\mathbb{R}^{n})$. But I don't know how to prove $F_{\delta} \left|_{\Omega} \right. \in H_{1}(\Omega) \cap C_{c}(\bar{\Omega})$. Please tell me how to prove (2). Thank you in advance.",,"['real-analysis', 'functional-analysis', 'stochastic-calculus']"
31,Strict inequality for logarithmic integrals,Strict inequality for logarithmic integrals,,"Let $0<a<b<1$. Does the following inequality hold: $$\max_{f\in L^2[0,a],\,\,\|f\|_2=1}\Bigg|\int_0^a\int_0^af(x)f(y)\ln|x-y|dxdy\Bigg|$$ $$<\max_{g\in L^2[0,b],\,\,\|g\|_2=1}\Bigg|\int_0^b\int_0^bg(x)g(y)\ln|x-y|dxdy\Bigg|$$ ?","Let $0<a<b<1$. Does the following inequality hold: $$\max_{f\in L^2[0,a],\,\,\|f\|_2=1}\Bigg|\int_0^a\int_0^af(x)f(y)\ln|x-y|dxdy\Bigg|$$ $$<\max_{g\in L^2[0,b],\,\,\|g\|_2=1}\Bigg|\int_0^b\int_0^bg(x)g(y)\ln|x-y|dxdy\Bigg|$$ ?",,"['functional-analysis', 'inequality']"
32,Bounded Operators: Topological Dual,Bounded Operators: Topological Dual,,"Given Hilbert spaces $\mathcal{H}$ and $\mathcal{K}$. Consider the bounded operators: $$\mathcal{B}(\mathcal{H},\mathcal{K}):=\{T:\mathcal{H}\to\mathcal{K}:\|T\|<\infty\}$$ Regard the linear functionals: $$l_{(\varphi,\psi)}T:=\langle T\varphi,\psi\rangle_\mathcal{K}:\quad|l_{(\varphi,\psi)}T|\leq\|\varphi\|_\mathcal{H}\|\psi\|_\mathcal{K}\cdot\|T\|$$ Do these exhaust its topological dual: $$\mathcal{B}(\mathcal{H},\mathcal{K})'=\overline{\langle\{l_{(\varphi,\psi)}:(\varphi,\psi)\in\mathcal{H}\times\mathcal{K}\}\rangle}$$ (I'm wondering about this already for some time.)","Given Hilbert spaces $\mathcal{H}$ and $\mathcal{K}$. Consider the bounded operators: $$\mathcal{B}(\mathcal{H},\mathcal{K}):=\{T:\mathcal{H}\to\mathcal{K}:\|T\|<\infty\}$$ Regard the linear functionals: $$l_{(\varphi,\psi)}T:=\langle T\varphi,\psi\rangle_\mathcal{K}:\quad|l_{(\varphi,\psi)}T|\leq\|\varphi\|_\mathcal{H}\|\psi\|_\mathcal{K}\cdot\|T\|$$ Do these exhaust its topological dual: $$\mathcal{B}(\mathcal{H},\mathcal{K})'=\overline{\langle\{l_{(\varphi,\psi)}:(\varphi,\psi)\in\mathcal{H}\times\mathcal{K}\}\rangle}$$ (I'm wondering about this already for some time.)",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
33,Example of an oscillation Young measure,Example of an oscillation Young measure,,"I'm taking a course in which Young measures are introduced for oscillation and concentration. I have understood the examples the lecturer has given us for concentration Young measures, but cannot get my head around the ones for oscillation. Here is an example: Let $v_j:=\sin(jx)$ , let $\Omega=(0,1)$ and let $\mathbb{E}_1$ be the space of ""1-admissible integrands"", that is the space of $\Phi \colon \Omega \times \mathbb{R}\to\mathbb{R}$ such that $\lim_{t\to\infty}\frac{\Phi(x,tz)}{t}$ exists for $z\in\{+1,-1\}$ . The functions $v_j$ may be viewed as 1-Young measures, which are viewed as elements of the dual space to $\mathbb{E_1}$ , under the duality relation \begin{align*} \langle\langle v_j,\Phi\rangle\rangle&:=\int_\Omega\int_\mathbb{R}\Phi(x,z)d\delta_{v_j(x)}dx \\  &=\int_{\Omega}\Phi(x,v_j(x))dx \end{align*} We claim that the $v_j\to v$ for some $v$ as Young measures in the sense that they tend weak* in $\mathbb{E}_1^*$ . That is, we claim that there exists a family $v=(v_x)_{\{x\in\Omega\}} $ where each $v_x$ is a probability measure on $\mathbb{R}$ such that for any $\Phi\in\mathbb{E}_1$ \begin{align*} \langle\langle v_j,\Phi\rangle\rangle &\to \langle\langle v,\Phi\rangle\rangle \\ &:= \int_\Omega\int_\mathbb{R} \Phi(x,z)dv_x(z)dx \end{align*} as $j\to\infty$ . Our lecturer claims that this Young measure $v$ is given by the pushforward of the Lebesgue measure restricted to $(0,2\pi)$ , under the map $\sin(\cdot)$ , divided by $2\pi$ , at all points $x\in\Omega$ . That is $$v_x=\sin(\cdot)_*\left(\left(\frac{1}{2\pi}\right)\mathcal{L}\llcorner(0,2\pi) \right) $$ Where the pushforward measure is defined as $f_*(\mathcal{L})(A)=\mathcal{L}(f^{-1}(A))$ . They also claim that this follows from the Riemann-Lebesgue lemma. Is anyone able to explain why this is the limit? It is not obvious to me how the integrals converge, let alone to what is stated. Many thanks for any advice, A.","I'm taking a course in which Young measures are introduced for oscillation and concentration. I have understood the examples the lecturer has given us for concentration Young measures, but cannot get my head around the ones for oscillation. Here is an example: Let , let and let be the space of ""1-admissible integrands"", that is the space of such that exists for . The functions may be viewed as 1-Young measures, which are viewed as elements of the dual space to , under the duality relation We claim that the for some as Young measures in the sense that they tend weak* in . That is, we claim that there exists a family where each is a probability measure on such that for any as . Our lecturer claims that this Young measure is given by the pushforward of the Lebesgue measure restricted to , under the map , divided by , at all points . That is Where the pushforward measure is defined as . They also claim that this follows from the Riemann-Lebesgue lemma. Is anyone able to explain why this is the limit? It is not obvious to me how the integrals converge, let alone to what is stated. Many thanks for any advice, A.","v_j:=\sin(jx) \Omega=(0,1) \mathbb{E}_1 \Phi \colon \Omega \times \mathbb{R}\to\mathbb{R} \lim_{t\to\infty}\frac{\Phi(x,tz)}{t} z\in\{+1,-1\} v_j \mathbb{E_1} \begin{align*}
\langle\langle v_j,\Phi\rangle\rangle&:=\int_\Omega\int_\mathbb{R}\Phi(x,z)d\delta_{v_j(x)}dx \\
 &=\int_{\Omega}\Phi(x,v_j(x))dx
\end{align*} v_j\to v v \mathbb{E}_1^* v=(v_x)_{\{x\in\Omega\}}  v_x \mathbb{R} \Phi\in\mathbb{E}_1 \begin{align*}
\langle\langle v_j,\Phi\rangle\rangle &\to \langle\langle v,\Phi\rangle\rangle \\
&:= \int_\Omega\int_\mathbb{R} \Phi(x,z)dv_x(z)dx
\end{align*} j\to\infty v (0,2\pi) \sin(\cdot) 2\pi x\in\Omega v_x=\sin(\cdot)_*\left(\left(\frac{1}{2\pi}\right)\mathcal{L}\llcorner(0,2\pi) \right)  f_*(\mathcal{L})(A)=\mathcal{L}(f^{-1}(A))","['functional-analysis', 'measure-theory', 'partial-differential-equations', 'calculus-of-variations']"
34,Taking the topological dual in terms of category theory,Taking the topological dual in terms of category theory,,"Consider the categories $\mathbf{Vect}$ of vector spaces $X$ with linear maps and $\mathbf{TopVect}$ of topological vector spaces $(X, \tau)$ with continuous linear maps both over $\mathbb{R}$. Taking the algebraic dual is a contravariant functor $* : \mathbf{Vect} \to \mathbf{Vect}$ with $X \mapsto X^*$ and $(f : X \to Y) \mapsto (f^* : Y^* \to X^*)$ (the transpose of $f$) with $(f^*(y^*))(x) := y^*(f(x))$. Similarly, it is also clear that taking the topological dual leads to a contravariant functor $' : \mathbf{TopVect} \to \mathbf{Vect}$ with $X \mapsto X'$ and $(f : X \to Y) \mapsto (f' : Y' \to X')$ with $(f'(y'))(x) := y'(f(x))$. In order to see that this is indeed a functor it is enough to observe that $f'$ is just $f^*$ restricted to $Y' \subseteq Y^*$ and is well-defined, i.e. $f^*|_{Y'} \subseteq X'$ due to continuity of $f$. We can also consider the ""taking the weak* topological dual"" as the contravariant functor $'_\sigma : \mathbf{TopVect} \to \mathbf{TopVect}$ with $X \mapsto X'_\sigma$ and $(f : X \to Y) \mapsto (f' : Y' \to X')$ with $(f'(y'))(x) := y'(f(x))$. Clearly, $'_\sigma$ is well-defined, i.e. $X'_\sigma$ is an object in $\mathbf{TopVect}$ and $f'$ is a morphism in $\mathbf{TopVect}$ since $f'$ is continuous (and linear) by the choice of the weak-* topology on both $X'$ and $Y'$. Similarly, one can also consider more general functors equipping $X'$ with some vector space topology type $\tau_{\text{source}}$ and $Y'$ with a topology type $\tau_{\text{target}}$ such that all the $f'$ are continuous. Questions: Is it possible to decompose the $'_\sigma$-functor into $'_\sigma = E_\sigma \circ \, '$ where $E_\sigma$ is some kind of ""equip with the weak* topology"" functor? The problem is, that we loose information about the space $X$ when performing $'$, but we need $X$ in order to define $E_\sigma$. One plausible solution is to redefine $'$ to $\bar{'} := (', id) : \mathbf{TopVect} \to \mathbf{TopVect} \times \mathbf{Vect}$, $X \mapsto (X', X)$ and set $E_\sigma : im(\bar{'}) \to \mathbf{TopVect}$ that sends the pair $(X', X)$ to the topological vector space $(X', \sigma(X', X))$ where $im(\bar{'})$ is the particular subcategory of $\mathbf{TopVect} \times \mathbf{Vect}$ that we can reach by $\bar{'}$. This construction seems to be rather ugly and artificial. Maybe there is a better description for such a decomposition. All these ""take some top. dual functors"" seem to be special instances of the ""take the algebraic dual"" functor. Is there a better more abstract point of view for such a relation?","Consider the categories $\mathbf{Vect}$ of vector spaces $X$ with linear maps and $\mathbf{TopVect}$ of topological vector spaces $(X, \tau)$ with continuous linear maps both over $\mathbb{R}$. Taking the algebraic dual is a contravariant functor $* : \mathbf{Vect} \to \mathbf{Vect}$ with $X \mapsto X^*$ and $(f : X \to Y) \mapsto (f^* : Y^* \to X^*)$ (the transpose of $f$) with $(f^*(y^*))(x) := y^*(f(x))$. Similarly, it is also clear that taking the topological dual leads to a contravariant functor $' : \mathbf{TopVect} \to \mathbf{Vect}$ with $X \mapsto X'$ and $(f : X \to Y) \mapsto (f' : Y' \to X')$ with $(f'(y'))(x) := y'(f(x))$. In order to see that this is indeed a functor it is enough to observe that $f'$ is just $f^*$ restricted to $Y' \subseteq Y^*$ and is well-defined, i.e. $f^*|_{Y'} \subseteq X'$ due to continuity of $f$. We can also consider the ""taking the weak* topological dual"" as the contravariant functor $'_\sigma : \mathbf{TopVect} \to \mathbf{TopVect}$ with $X \mapsto X'_\sigma$ and $(f : X \to Y) \mapsto (f' : Y' \to X')$ with $(f'(y'))(x) := y'(f(x))$. Clearly, $'_\sigma$ is well-defined, i.e. $X'_\sigma$ is an object in $\mathbf{TopVect}$ and $f'$ is a morphism in $\mathbf{TopVect}$ since $f'$ is continuous (and linear) by the choice of the weak-* topology on both $X'$ and $Y'$. Similarly, one can also consider more general functors equipping $X'$ with some vector space topology type $\tau_{\text{source}}$ and $Y'$ with a topology type $\tau_{\text{target}}$ such that all the $f'$ are continuous. Questions: Is it possible to decompose the $'_\sigma$-functor into $'_\sigma = E_\sigma \circ \, '$ where $E_\sigma$ is some kind of ""equip with the weak* topology"" functor? The problem is, that we loose information about the space $X$ when performing $'$, but we need $X$ in order to define $E_\sigma$. One plausible solution is to redefine $'$ to $\bar{'} := (', id) : \mathbf{TopVect} \to \mathbf{TopVect} \times \mathbf{Vect}$, $X \mapsto (X', X)$ and set $E_\sigma : im(\bar{'}) \to \mathbf{TopVect}$ that sends the pair $(X', X)$ to the topological vector space $(X', \sigma(X', X))$ where $im(\bar{'})$ is the particular subcategory of $\mathbf{TopVect} \times \mathbf{Vect}$ that we can reach by $\bar{'}$. This construction seems to be rather ugly and artificial. Maybe there is a better description for such a decomposition. All these ""take some top. dual functors"" seem to be special instances of the ""take the algebraic dual"" functor. Is there a better more abstract point of view for such a relation?",,"['functional-analysis', 'category-theory']"
35,Every self-adjoint trace class operator on $L^2$ has integral kernel,Every self-adjoint trace class operator on  has integral kernel,L^2,"Let $T$ be a self-adjoint trace-class operator on $L^2(\mathbb{R})$. Is is true that it can be represented as an integral operator. I thought the kernel would be $$k_T(x,y) =\sum_{i=1}^\infty \lambda_i \phi_i(x) \bar\phi_i(y).$$ Here $\{\phi_i\}$ is an eigenbasis of $T$, i.e. $T=\sum_i \lambda_i |\phi_i\rangle\langle\phi_i|$. Then, we have $$\int k_T(\cdot,y) f(y) = \int\sum_i \lambda_i \phi_i(\cdot) \bar\phi_i(y) f(y) dy = \sum_i \lambda_i \phi_i \langle \phi_i, f\rangle=\sum_i \lambda_i |\phi_i\rangle\langle\phi_i|f\rangle = Tf.$$ Is this correct?","Let $T$ be a self-adjoint trace-class operator on $L^2(\mathbb{R})$. Is is true that it can be represented as an integral operator. I thought the kernel would be $$k_T(x,y) =\sum_{i=1}^\infty \lambda_i \phi_i(x) \bar\phi_i(y).$$ Here $\{\phi_i\}$ is an eigenbasis of $T$, i.e. $T=\sum_i \lambda_i |\phi_i\rangle\langle\phi_i|$. Then, we have $$\int k_T(\cdot,y) f(y) = \int\sum_i \lambda_i \phi_i(\cdot) \bar\phi_i(y) f(y) dy = \sum_i \lambda_i \phi_i \langle \phi_i, f\rangle=\sum_i \lambda_i |\phi_i\rangle\langle\phi_i|f\rangle = Tf.$$ Is this correct?",,"['functional-analysis', 'eigenvalues-eigenvectors']"
36,Toroidal Harmonics?,Toroidal Harmonics?,,"So I end up with an interesting (at least for me) problem. It is probably very basic and someone out there might have solved this with a pencil behind their ear. Nevertheless, indulge me for a moment while I share my mathematical adventures with all of you and ask for wisdom. So I have a manifold $R = (\theta, \phi, W(\theta, \phi))$ where $\theta,\phi \in [-\pi,\pi]$ and $W \in \mathbb{R}$. I want to be able to find the metric tensor of this manifold at every point but to do that I need a way to write the function $W(\theta,\phi)$. I was thinking on writing $W$ as a linear combination of orthonormal functions of a complete set $\{f_k\}$ such that: $$ W(\theta, \phi) = \sum_k c_k f_k (\theta ,\phi) $$ My own mathematical immaturity led me to think about the Spherical Harmonics, however I learned that the angular coordinates used by Spherical Harmonics are not the same as my own. This, as it later became obvious, is because the coordinates in the Spherical Harmonics are (rather unsurprisingly) spherical , whereas my particular system of coordinates seems to be somewhat toroidal . So the way I see it, I need some kind of ""toroidal harmonics"". A set of functions defined in the toroidal coordinates that are complete on the ""unit Torus"" (is that how you call it when only the angles are allowed to vary?) in the same fashion that the spherical harmonics are complete on the unit sphere. Looking around I found out that there are functions called ""Toroidal Functions"". That looked promising for a moment but as far as I could tell, it wasn't exactly what I wanted, maybe it was but I didn't manage to understand it. I got stuck after that and didn't really find any complete set on a Torus. Maybe there aren't any or maybe I don't actually need one and everything I said here is kinda stupid. Anyway, I was hoping to hear you people on this.","So I end up with an interesting (at least for me) problem. It is probably very basic and someone out there might have solved this with a pencil behind their ear. Nevertheless, indulge me for a moment while I share my mathematical adventures with all of you and ask for wisdom. So I have a manifold $R = (\theta, \phi, W(\theta, \phi))$ where $\theta,\phi \in [-\pi,\pi]$ and $W \in \mathbb{R}$. I want to be able to find the metric tensor of this manifold at every point but to do that I need a way to write the function $W(\theta,\phi)$. I was thinking on writing $W$ as a linear combination of orthonormal functions of a complete set $\{f_k\}$ such that: $$ W(\theta, \phi) = \sum_k c_k f_k (\theta ,\phi) $$ My own mathematical immaturity led me to think about the Spherical Harmonics, however I learned that the angular coordinates used by Spherical Harmonics are not the same as my own. This, as it later became obvious, is because the coordinates in the Spherical Harmonics are (rather unsurprisingly) spherical , whereas my particular system of coordinates seems to be somewhat toroidal . So the way I see it, I need some kind of ""toroidal harmonics"". A set of functions defined in the toroidal coordinates that are complete on the ""unit Torus"" (is that how you call it when only the angles are allowed to vary?) in the same fashion that the spherical harmonics are complete on the unit sphere. Looking around I found out that there are functions called ""Toroidal Functions"". That looked promising for a moment but as far as I could tell, it wasn't exactly what I wanted, maybe it was but I didn't manage to understand it. I got stuck after that and didn't really find any complete set on a Torus. Maybe there aren't any or maybe I don't actually need one and everything I said here is kinda stupid. Anyway, I was hoping to hear you people on this.",,"['functional-analysis', 'differential-geometry']"
37,Comparing two sigma algebras in Hilbert spaces,Comparing two sigma algebras in Hilbert spaces,,"Let $H$ be a non-separable Hilbert space. We denote  $B$ by the sigma algebra generated by the norm topology in $H$. We also denote $B_{w}$ by the sigma algebra generated by the weak topology in $H$. Question: Is $B$ the same as $B_w$? Remark. When $H$ is separable, it is not difficult to see that they are the same.","Let $H$ be a non-separable Hilbert space. We denote  $B$ by the sigma algebra generated by the norm topology in $H$. We also denote $B_{w}$ by the sigma algebra generated by the weak topology in $H$. Question: Is $B$ the same as $B_w$? Remark. When $H$ is separable, it is not difficult to see that they are the same.",,"['functional-analysis', 'measure-theory', 'hilbert-spaces']"
38,Help to understand a Lemma about 'supremum of a family of measures',Help to understand a Lemma about 'supremum of a family of measures',,"I read the following Lemma from a paper but I can't understand the proof. Please help! Lemma: Let $\mu$ be a positive measure defined on the family of open   subsets of $\Omega$, which is super-additive on open sets with   disjoint compact closure. (Here $\Omega\subset \mathbb R^N$ is open   bounded with Lip boundary). Let $\lambda$ be a positive measure on   $\Omega$, let $\phi_i$ be positive Borel functions such that   $\mu(A)\geq \int_A \phi_i d\lambda$ for all open sets $A$ and let   $\phi(x)=\sup_i \phi_i(x)$.  Then $\mu(A)\geq \int_A\phi d\lambda$ for   all open sets $A$. and here is the proof. It is short. Proof: By the regularity of the measures $\phi_i\lambda$,   \begin{align*} \int_A \phi d\lambda &= \sup\left\{\sum_{i=1}^k\int_{B_i}\phi_i d\lambda:\,(B_i)\text{ Borel partition of }A,\,k\in \mathbb N\right\}\\ & = \sup\left\{\sum_{i=1}^k\int_{K_i}\phi_i d\lambda:\,(K_i)\text{ disjoint compact subsets of }A,\,k\in \mathbb N\right\}\\ & = \sup\left\{\sum_{i=1}^k\int_{A_i}\phi_i d\lambda:\,(A_i)\text{ disjoint open subsets of }A,\,k\in \mathbb N\right\}\leq \mu(A) \end{align*} Here is my questions... why the first equation holds? what does Borel partition means? I tried to search online but there no information about Borel partition... why can we change $B_i$ to $K_i$ to $A_i$ but without losing the equality? why only finitely many $B_i$'s? Should it be at least countably many?","I read the following Lemma from a paper but I can't understand the proof. Please help! Lemma: Let $\mu$ be a positive measure defined on the family of open   subsets of $\Omega$, which is super-additive on open sets with   disjoint compact closure. (Here $\Omega\subset \mathbb R^N$ is open   bounded with Lip boundary). Let $\lambda$ be a positive measure on   $\Omega$, let $\phi_i$ be positive Borel functions such that   $\mu(A)\geq \int_A \phi_i d\lambda$ for all open sets $A$ and let   $\phi(x)=\sup_i \phi_i(x)$.  Then $\mu(A)\geq \int_A\phi d\lambda$ for   all open sets $A$. and here is the proof. It is short. Proof: By the regularity of the measures $\phi_i\lambda$,   \begin{align*} \int_A \phi d\lambda &= \sup\left\{\sum_{i=1}^k\int_{B_i}\phi_i d\lambda:\,(B_i)\text{ Borel partition of }A,\,k\in \mathbb N\right\}\\ & = \sup\left\{\sum_{i=1}^k\int_{K_i}\phi_i d\lambda:\,(K_i)\text{ disjoint compact subsets of }A,\,k\in \mathbb N\right\}\\ & = \sup\left\{\sum_{i=1}^k\int_{A_i}\phi_i d\lambda:\,(A_i)\text{ disjoint open subsets of }A,\,k\in \mathbb N\right\}\leq \mu(A) \end{align*} Here is my questions... why the first equation holds? what does Borel partition means? I tried to search online but there no information about Borel partition... why can we change $B_i$ to $K_i$ to $A_i$ but without losing the equality? why only finitely many $B_i$'s? Should it be at least countably many?",,"['real-analysis', 'functional-analysis', 'measure-theory']"
39,"An open ball in $C[0, + \infty)$",An open ball in,"C[0, + \infty)","Consider the space $C[0, +\infty)$ of all continuous, real-valued functions on $[0, + \infty)$ with metric $$ d( \omega_1, \omega_2 ) = \sum_{n=1}^{\infty}  \frac{1}{2^n} \max_{t \in [0,n]} ( \min \{ |\omega_1 (t) - \omega_2 (t)| , 1\} ). $$ Let $\omega_0 \in C[0, +\infty)$, $\epsilon \in (0,1)$. We want to show that the ball $B(\omega_0, \epsilon)$ is contained in the $\sigma$-algebra generated by the collection of finite-dimensional cylinder sets of the form $$C= \{ \omega \in C[0, + \infty) \big| ( \omega(t_1) , \ldots, \omega(t_n)) \in A \}; \quad \quad n \geq 1, \quad \quad A \in \mathcal{B} ( \mathbb{R}^n),$$ where $t_1 , \ldots, t_n \in [0, +\infty)$. Can I argue as follows (in response to the hints provided below): Let $n_0$ be an integer such that $\frac{1}{n_0} < \epsilon$. Also, let $[0, n] \cap \mathbb{Q} = \{ t^{(n)}_1, t^{(n)}_2, \ldots \}$.   \begin{eqnarray} && B( \omega_0 , \epsilon) \\ & = & \bigcup_{ l \geq n_0} \bigcap_{k \in \mathbb{N}} \bigcap_{p \in \mathbb{N}} \bigg\{ \omega \bigg| \sum_{n=1}^k \frac{1}{2^n} \max_{t \in \{t^{(n)}_1, \ldots t^{(n)}_p \}} \bigg[ |w(t) - \omega_0 (t)| \wedge 1 \bigg] \leq \epsilon - \frac{1}{l} \bigg\} \end{eqnarray}   If we set $f: \mathbb{R}^p \rightarrow \mathbb{R}$ by    $$ f(x_1 , x_2 , \ldots , x_p) =  \sum_{n=1}^k \frac{1}{2^n} \max_{i \in \{1, 2, \ldots ,p \}} \bigg[ | x_i - \omega_0 (t^{(n)}_i)| \wedge 1 \bigg], $$   which is Borel-measurable.    Then,   $$ B( \omega_0 , \epsilon) = \bigcup_{ l \geq n_0} \bigcap_{k \in \mathbb{N}} \bigcap_{p \in \mathbb{N}} \bigg\{ \omega \bigg| \big( \omega (t^{(n)}_1) , \omega(t^{(n)}_2), \ldots, \omega(t^{(n)}_p) \big) \in f^{-1} \bigg( \bigg( -\infty, \epsilon - \frac{1}{l} \bigg] \bigg) \bigg\}$$","Consider the space $C[0, +\infty)$ of all continuous, real-valued functions on $[0, + \infty)$ with metric $$ d( \omega_1, \omega_2 ) = \sum_{n=1}^{\infty}  \frac{1}{2^n} \max_{t \in [0,n]} ( \min \{ |\omega_1 (t) - \omega_2 (t)| , 1\} ). $$ Let $\omega_0 \in C[0, +\infty)$, $\epsilon \in (0,1)$. We want to show that the ball $B(\omega_0, \epsilon)$ is contained in the $\sigma$-algebra generated by the collection of finite-dimensional cylinder sets of the form $$C= \{ \omega \in C[0, + \infty) \big| ( \omega(t_1) , \ldots, \omega(t_n)) \in A \}; \quad \quad n \geq 1, \quad \quad A \in \mathcal{B} ( \mathbb{R}^n),$$ where $t_1 , \ldots, t_n \in [0, +\infty)$. Can I argue as follows (in response to the hints provided below): Let $n_0$ be an integer such that $\frac{1}{n_0} < \epsilon$. Also, let $[0, n] \cap \mathbb{Q} = \{ t^{(n)}_1, t^{(n)}_2, \ldots \}$.   \begin{eqnarray} && B( \omega_0 , \epsilon) \\ & = & \bigcup_{ l \geq n_0} \bigcap_{k \in \mathbb{N}} \bigcap_{p \in \mathbb{N}} \bigg\{ \omega \bigg| \sum_{n=1}^k \frac{1}{2^n} \max_{t \in \{t^{(n)}_1, \ldots t^{(n)}_p \}} \bigg[ |w(t) - \omega_0 (t)| \wedge 1 \bigg] \leq \epsilon - \frac{1}{l} \bigg\} \end{eqnarray}   If we set $f: \mathbb{R}^p \rightarrow \mathbb{R}$ by    $$ f(x_1 , x_2 , \ldots , x_p) =  \sum_{n=1}^k \frac{1}{2^n} \max_{i \in \{1, 2, \ldots ,p \}} \bigg[ | x_i - \omega_0 (t^{(n)}_i)| \wedge 1 \bigg], $$   which is Borel-measurable.    Then,   $$ B( \omega_0 , \epsilon) = \bigcup_{ l \geq n_0} \bigcap_{k \in \mathbb{N}} \bigcap_{p \in \mathbb{N}} \bigg\{ \omega \bigg| \big( \omega (t^{(n)}_1) , \omega(t^{(n)}_2), \ldots, \omega(t^{(n)}_p) \big) \in f^{-1} \bigg( \bigg( -\infty, \epsilon - \frac{1}{l} \bigg] \bigg) \bigg\}$$",,"['analysis', 'functional-analysis', 'measure-theory', 'metric-spaces', 'continuity']"
40,Universal property of l^p-spaces,Universal property of l^p-spaces,,"The category $\mathsf{Ban_1}$ of Banach spaces together with short linear maps (i.e. those of norm $\leq 1$) seems to have a natural construction which interpolates between coproduct and product: Let $p \in [1,\infty]$ and let $(V_i)_{i \in I}$ be a family of Banach spaces over $\mathbb{K}=\mathbb{R},\mathbb{C}$. Then we may define a new Banach space $\bigoplus^p_{i \in I} V_i$ (how is this usually denoted?) as follows: The points are the sequences $(v_i)_{i \in I}$ with $v_i \in V_i$ and $\sum_{i \in I} \lVert v_i \rVert^p < \infty$. We let $\lVert (v_i)_{i \in I} \rVert := (\sum_{i \in I} \lVert v_i \rVert^p)^{1/p}$. For $p=\infty$ this has to be interpreted as $\lVert (v_i)_{i \in I} \rVert := \sup_{i \in I} \lVert v_i \rVert < \infty$. For $V_i=\mathbb{K}$ we get the usual space $l^p(I)$. If $p=1$, then $\bigoplus^1_{i \in I} V_i$ is the coproduct of $(V_i)_{i \in I}$. If $p=\infty$, then $\bigoplus^{\infty}_{i \in I} V_i$ is the product of $(V_i)_{i \in I}$. Question. Does $\bigoplus^p_{i \in I} V_i$ have a useful universal property if $1<p<\infty$? If necessary, you may work in a different category than $\mathsf{Ban_1}$. But would be nice if this category does not depend on $p$.","The category $\mathsf{Ban_1}$ of Banach spaces together with short linear maps (i.e. those of norm $\leq 1$) seems to have a natural construction which interpolates between coproduct and product: Let $p \in [1,\infty]$ and let $(V_i)_{i \in I}$ be a family of Banach spaces over $\mathbb{K}=\mathbb{R},\mathbb{C}$. Then we may define a new Banach space $\bigoplus^p_{i \in I} V_i$ (how is this usually denoted?) as follows: The points are the sequences $(v_i)_{i \in I}$ with $v_i \in V_i$ and $\sum_{i \in I} \lVert v_i \rVert^p < \infty$. We let $\lVert (v_i)_{i \in I} \rVert := (\sum_{i \in I} \lVert v_i \rVert^p)^{1/p}$. For $p=\infty$ this has to be interpreted as $\lVert (v_i)_{i \in I} \rVert := \sup_{i \in I} \lVert v_i \rVert < \infty$. For $V_i=\mathbb{K}$ we get the usual space $l^p(I)$. If $p=1$, then $\bigoplus^1_{i \in I} V_i$ is the coproduct of $(V_i)_{i \in I}$. If $p=\infty$, then $\bigoplus^{\infty}_{i \in I} V_i$ is the product of $(V_i)_{i \in I}$. Question. Does $\bigoplus^p_{i \in I} V_i$ have a useful universal property if $1<p<\infty$? If necessary, you may work in a different category than $\mathsf{Ban_1}$. But would be nice if this category does not depend on $p$.",,"['functional-analysis', 'category-theory', 'banach-spaces', 'lp-spaces', 'universal-property']"
41,Spectrum of a closed operator,Spectrum of a closed operator,,"Could someone please explain this fact: if $A$ is a closed operator and $A^{-1}$ is a compact operator, then spectrum of $A$ consist only of eigenvalues? I forgot to mention that operator $A^{-1}$ is bounded, but $A$ isn't continuous.","Could someone please explain this fact: if $A$ is a closed operator and $A^{-1}$ is a compact operator, then spectrum of $A$ consist only of eigenvalues? I forgot to mention that operator $A^{-1}$ is bounded, but $A$ isn't continuous.",,"['functional-analysis', 'operator-theory']"
42,Bishop-Phelps theorem,Bishop-Phelps theorem,,"Bishop-Phelps Theorem: If $E$ is a Banach space and $B\subseteq E$ is bounded, closed and convex, then the linear functionals on $E$, which attain their supremum on $B$, are norm-dense in $E^*$. Could someone give an example to show how this fails (if it does fail) when $E$ is not complete?","Bishop-Phelps Theorem: If $E$ is a Banach space and $B\subseteq E$ is bounded, closed and convex, then the linear functionals on $E$, which attain their supremum on $B$, are norm-dense in $E^*$. Could someone give an example to show how this fails (if it does fail) when $E$ is not complete?",,"['functional-analysis', 'banach-spaces']"
43,Learning Roadmap to Function Spaces,Learning Roadmap to Function Spaces,,"We are a small group of people that would like to start a reading course with the topic 'Function Spaces'.  So far, we have all attended some graduate courses in Functional Analysis, Measure Theory, PDEs and some Harmonic Analysis (about the first four chapters of Grafakos' first book). Especially, we enjoyed the part about Sobolev Spaces a lot and we would like to deepen our knowledge in that area. Furthermore, we would like to enter that huge zoo of function spaces that are important in the modern theory of PDEs (like Besov, Morrey-Capanato, Triebel-Lizorkin, Hardy, BMO, etc.), especially in the theory of regularity of solutions. However, we are a bit overwhelmed by the vastness of this field and don't know where to start and what to read. We intend to start with the paper Hitchhiker’s guide to the fractional Sobolev spaces first since we have no background knowledge in fractional Sobolev spaces yet and it seems to be a good resource. But what is next? Sure, we thought about the classical books like Triebel's 'Theory of Function Spaces' but in this book, a lot of proofs are missing.  Also, we found the book 'Morrey and Campanato Meet Besov, Lizorkin and Triebel' but it turned out to be very hard to read for a beginner. Could anybody give us some advice? We would be very grateful for a step-by-step listing of topics that we should study, together with some good resources (possibly with some exercises!) Thank you very much! =)","We are a small group of people that would like to start a reading course with the topic 'Function Spaces'.  So far, we have all attended some graduate courses in Functional Analysis, Measure Theory, PDEs and some Harmonic Analysis (about the first four chapters of Grafakos' first book). Especially, we enjoyed the part about Sobolev Spaces a lot and we would like to deepen our knowledge in that area. Furthermore, we would like to enter that huge zoo of function spaces that are important in the modern theory of PDEs (like Besov, Morrey-Capanato, Triebel-Lizorkin, Hardy, BMO, etc.), especially in the theory of regularity of solutions. However, we are a bit overwhelmed by the vastness of this field and don't know where to start and what to read. We intend to start with the paper Hitchhiker’s guide to the fractional Sobolev spaces first since we have no background knowledge in fractional Sobolev spaces yet and it seems to be a good resource. But what is next? Sure, we thought about the classical books like Triebel's 'Theory of Function Spaces' but in this book, a lot of proofs are missing.  Also, we found the book 'Morrey and Campanato Meet Besov, Lizorkin and Triebel' but it turned out to be very hard to read for a beginner. Could anybody give us some advice? We would be very grateful for a step-by-step listing of topics that we should study, together with some good resources (possibly with some exercises!) Thank you very much! =)",,"['functional-analysis', 'reference-request', 'partial-differential-equations']"
44,"Laplace transform of functions related to type $\mathcal{S}$, and the relation to entire functions","Laplace transform of functions related to type , and the relation to entire functions",\mathcal{S},"I have doubts in the following two questions      : What is the Laplace transform of $[x^k\varphi(x)]^{(q)}$, where $\varphi\in \mathcal{S}_\alpha^\beta$ and $-\infty<x<\infty$ , $k,q=0,1,2,...$? I know that the Fourier transform of $[x^k\varphi(x)]^{(q)}$ is $\xi^q\varphi^{(k)}(x)$. Also we know that Fourier transform takes differentiation to polynomial multiplication. Does a similar result hold for laplace Transform also or is it different ? How to prove the following assertion: If an entire function $\varphi$ satisfies $$|\varphi(x+iy)|\le C\exp(a|x|^h+b|y|^{\gamma}), \:\:\:h\le\gamma$$  where $a\lt0$ and $C>0$, then $\varphi\in \mathcal{S}_{1/h}^{1-1/{\gamma}}$, where $\mathcal{S}_\alpha^\beta$ is the Gelfand-Shilov space of type $\mathcal{S}$ defined here Any help will be welcome. Thanks.. Reference: Generalized Functions, Volume 2, by I.M Gelfand and G.E. Shilov","I have doubts in the following two questions      : What is the Laplace transform of $[x^k\varphi(x)]^{(q)}$, where $\varphi\in \mathcal{S}_\alpha^\beta$ and $-\infty<x<\infty$ , $k,q=0,1,2,...$? I know that the Fourier transform of $[x^k\varphi(x)]^{(q)}$ is $\xi^q\varphi^{(k)}(x)$. Also we know that Fourier transform takes differentiation to polynomial multiplication. Does a similar result hold for laplace Transform also or is it different ? How to prove the following assertion: If an entire function $\varphi$ satisfies $$|\varphi(x+iy)|\le C\exp(a|x|^h+b|y|^{\gamma}), \:\:\:h\le\gamma$$  where $a\lt0$ and $C>0$, then $\varphi\in \mathcal{S}_{1/h}^{1-1/{\gamma}}$, where $\mathcal{S}_\alpha^\beta$ is the Gelfand-Shilov space of type $\mathcal{S}$ defined here Any help will be welcome. Thanks.. Reference: Generalized Functions, Volume 2, by I.M Gelfand and G.E. Shilov",,"['functional-analysis', 'partial-differential-equations', 'laplace-transform', 'distribution-theory', 'gelfand-shilov-spaces']"
45,Why does minimizing $H[f] =\sum^{N}_{i=1}(y_i-f(x_i))^2+\lambda \| Pf \|^2 $ leads to solution of the form $ f(x) =\sum^N_{i=1}c_iG(x; x_i)+p(x)$?,Why does minimizing  leads to solution of the form ?,H[f] =\sum^{N}_{i=1}(y_i-f(x_i))^2+\lambda \| Pf \|^2   f(x) =\sum^N_{i=1}c_iG(x; x_i)+p(x),"I was reading the following paper of dimensionality reduction (1) and also one on theory of networks for approximations and learning (2) and was trying to understand how the regularization problem leads to the form of the predictor function $f$. In other words, I was trying to fully understand the details of how if one tries to minimize the functional: $$ H[f] = \sum^{N}_{i=1} (y_i - f(x_i))^2 + \lambda \| Pf \|^2 $$ why the solution of the variational problem has the following simple form: $$ f(x) = \sum^N_{i=1} c_i G(x ; x_i) + p(x)$$ where $G(x)$ is the Green's function of the self-adjoint differential operator $\hat{P}P$, $\hat{P}$ being the adjoint operator of P, $p(x)$ is a linear combination of functions that span the null space of $P$, and the coefficients $c_i$ satisfy a linear system of equations that depend on the $N$ ""examples"", i.e. the data to be approximated. Why is it that that it has to be a linear combination of the Green's function? Why does the Green's function matter in this case? I think they try to explain try to explain it on the second paper (2) but I didn't really understand the details. If someone understood the details better, I would be extremely grateful if they would explain it to me. To understand this I was going through the following videos: https://www.youtube.com/watch?v=4U3P0LcaJcw&index=27&list=PL4C6F6B595A5852E8 https://www.youtube.com/watch?v=6n0uINcvx_E&index=28&list=PL4C6F6B595A5852E8 https://www.youtube.com/watch?v=cE4ZWo3pcCk&index=29&list=PL4C6F6B595A5852E8 I think they explain it there too but I was having some issue understanding everything. I am still in the process of going through these videos but I will add additional details as they come up through the derivation.","I was reading the following paper of dimensionality reduction (1) and also one on theory of networks for approximations and learning (2) and was trying to understand how the regularization problem leads to the form of the predictor function $f$. In other words, I was trying to fully understand the details of how if one tries to minimize the functional: $$ H[f] = \sum^{N}_{i=1} (y_i - f(x_i))^2 + \lambda \| Pf \|^2 $$ why the solution of the variational problem has the following simple form: $$ f(x) = \sum^N_{i=1} c_i G(x ; x_i) + p(x)$$ where $G(x)$ is the Green's function of the self-adjoint differential operator $\hat{P}P$, $\hat{P}$ being the adjoint operator of P, $p(x)$ is a linear combination of functions that span the null space of $P$, and the coefficients $c_i$ satisfy a linear system of equations that depend on the $N$ ""examples"", i.e. the data to be approximated. Why is it that that it has to be a linear combination of the Green's function? Why does the Green's function matter in this case? I think they try to explain try to explain it on the second paper (2) but I didn't really understand the details. If someone understood the details better, I would be extremely grateful if they would explain it to me. To understand this I was going through the following videos: https://www.youtube.com/watch?v=4U3P0LcaJcw&index=27&list=PL4C6F6B595A5852E8 https://www.youtube.com/watch?v=6n0uINcvx_E&index=28&list=PL4C6F6B595A5852E8 https://www.youtube.com/watch?v=cE4ZWo3pcCk&index=29&list=PL4C6F6B595A5852E8 I think they explain it there too but I was having some issue understanding everything. I am still in the process of going through these videos but I will add additional details as they come up through the derivation.",,"['functional-analysis', 'optimization', 'calculus-of-variations', 'machine-learning']"
46,Versions of Riesz Representation Theorem until now,Versions of Riesz Representation Theorem until now,,"I am writing  on Riesz Representation Theorem. How this theorem was motivated and what further generalizations were done while it was on its way to where it is now.   Starting from the beginning, Frigyes Riesz originally proved the Riesz Representation Theorem on C[0,1] in 1909, which stated that ""Given the linear operation $A[f(x)]$ , we can determine the function   of bounded variation $α(x)$ , such that, for any continuous function $f(x)$ , we have $$A[f(x)]=\int_0^1f(x)dα(x).""$$ Then  more things were extended in this theorem and there were so many such representations were done from 1909 till now.. Some of them are: (a.)The Hilbert space representation theorem for the (continuous) dual space of a Hilbert space; (b.)The representation theorem for positive linear functionals on $C_c(X)$ , where X is a locally compact Hausdorff space; (c.) The representation theorem for bounded linear functionals on $C_c(X)$ , where X is a locally compact Hausdorff space; Then it is generalized to bounded linear operators: (d.) Let $S$ be a locally compact Hausdorff space, $X$ be a Banach space  and $T$ be a weakly compact operator from $C_0(S)$ to $ X$ . Then there exists a unique regular vector valued measure $\mu: \mathcal{B}(S)\to X$ , such that $$ T(f) = \int f  d\mu,  ~~f\in C_0(S).$$ (e.) $T:C_0(S,X)\to Y$ be a bounded linear operator where $S$ is  locally compact Hausdorff space and $X,Y$ are Banach spaces.Then if for every $x\in X$ , the bounded linear operator $T_x: C_0(S)\to Y$ defined by $$T_x(g)=T(g\circ x), \ \ g\in C_0(S) $$ is weakly compact, then there exists a Baire operator valued measure $m : \mathcal{C}(\mathcal{B}_a(S))\to L(X,Y)$ countably additive in strong operator topology such that $$T(f)=\int f\ dm , \ \ f\in C_0(S,X)$$ After that this result is extended to locally convex Hausdorff topological vector space also. Request: But the problem is, I do not know any exact years and many concepts those were added in this theorem.  So I'll be really grateful if I could be provided with all the details those I need to write properly and comprehensively on this theorem such as the years and the names of the mathematicians  who have been  generalizing to this theorem until now.   I really apreciate your help regarding what I asked  it for.","I am writing  on Riesz Representation Theorem. How this theorem was motivated and what further generalizations were done while it was on its way to where it is now.   Starting from the beginning, Frigyes Riesz originally proved the Riesz Representation Theorem on C[0,1] in 1909, which stated that ""Given the linear operation , we can determine the function   of bounded variation , such that, for any continuous function , we have Then  more things were extended in this theorem and there were so many such representations were done from 1909 till now.. Some of them are: (a.)The Hilbert space representation theorem for the (continuous) dual space of a Hilbert space; (b.)The representation theorem for positive linear functionals on , where X is a locally compact Hausdorff space; (c.) The representation theorem for bounded linear functionals on , where X is a locally compact Hausdorff space; Then it is generalized to bounded linear operators: (d.) Let be a locally compact Hausdorff space, be a Banach space  and be a weakly compact operator from to . Then there exists a unique regular vector valued measure , such that (e.) be a bounded linear operator where is  locally compact Hausdorff space and are Banach spaces.Then if for every , the bounded linear operator defined by is weakly compact, then there exists a Baire operator valued measure countably additive in strong operator topology such that After that this result is extended to locally convex Hausdorff topological vector space also. Request: But the problem is, I do not know any exact years and many concepts those were added in this theorem.  So I'll be really grateful if I could be provided with all the details those I need to write properly and comprehensively on this theorem such as the years and the names of the mathematicians  who have been  generalizing to this theorem until now.   I really apreciate your help regarding what I asked  it for.","A[f(x)] α(x) f(x) A[f(x)]=\int_0^1f(x)dα(x)."" C_c(X) C_c(X) S X T C_0(S)  X \mu: \mathcal{B}(S)\to X  T(f) = \int f  d\mu,  ~~f\in C_0(S). T:C_0(S,X)\to Y S X,Y x\in X T_x: C_0(S)\to Y T_x(g)=T(g\circ x), \ \ g\in C_0(S)  m : \mathcal{C}(\mathcal{B}_a(S))\to L(X,Y) T(f)=\int f\ dm , \ \ f\in C_0(S,X)","['real-analysis', 'functional-analysis', 'math-history', 'riesz-representation-theorem']"
47,Sobolev type embedding,Sobolev type embedding,,"Consider a compact manifold $M$ and a point $q \in M$. Let us say that  that the following inequality holds: $$ \Vert \varphi u\Vert_{L^p} \leq C\Vert \varphi u\Vert_{H^1},$$ where $\varphi \in C^\infty_c(M \setminus \{q\})$, that is, $\varphi$ is smooth and compactly supported away from $q$, and $C$ is independent of $\varphi$ and $u$. If we know that $u \in H^1 \cap L^p$, can we conclude from the above that  $$\Vert u\Vert_{L^p} \leq C\Vert u\Vert_{H^1}?$$ Edit: It seems that it suffices to claim that there exists a sequence $\varphi_k$ such that $\varphi_k u \to u$ in $L^p$-norm and $\varphi_k u \to u$ in $H^1$-norm. But I cannot justify the existence of such a sequence.","Consider a compact manifold $M$ and a point $q \in M$. Let us say that  that the following inequality holds: $$ \Vert \varphi u\Vert_{L^p} \leq C\Vert \varphi u\Vert_{H^1},$$ where $\varphi \in C^\infty_c(M \setminus \{q\})$, that is, $\varphi$ is smooth and compactly supported away from $q$, and $C$ is independent of $\varphi$ and $u$. If we know that $u \in H^1 \cap L^p$, can we conclude from the above that  $$\Vert u\Vert_{L^p} \leq C\Vert u\Vert_{H^1}?$$ Edit: It seems that it suffices to claim that there exists a sequence $\varphi_k$ such that $\varphi_k u \to u$ in $L^p$-norm and $\varphi_k u \to u$ in $H^1$-norm. But I cannot justify the existence of such a sequence.",,"['real-analysis', 'functional-analysis', 'sobolev-spaces']"
48,Topology of solution to a nonlinear eigenvalue problem,Topology of solution to a nonlinear eigenvalue problem,,"Consider the elliptic PDE: $$-\Delta u= f(x) u. $$ Assume that $f,u$ are defined in some reasonable bounded domain $\Omega \subset \mathbb{R}^n$ and impose the boundary condition $u=0$ on $\partial \Omega.$ Suppose first $f\equiv \lambda \in \mathbb{R}.$ Then is a fact that there are infinitely many, discrete choices of $\lambda$ such that this equation holds. I want to know more generally about the structure of the set of $f$ which admit solutions to the above equation. In particular, is the set of  $f$ such that the above equation holds ""exceptional"" in any sense? E.g. could the following statement be true?  ""for any $f \in C^0(\Omega)$ which admits a solution to the above equation, there exists $\epsilon>0$ such that if $\|g-f\|_{C^0} < \epsilon$ and $g$ also admits a solution to the equation then $f \equiv g.$"" (N.B. I am actually interested in the case where $f,u$ are defined on a closed manifold and $\Delta$ is the Laplace-Beltrami operator, but I have asked the question in the Euclidean setting since I assume this is more familiar to most people.)","Consider the elliptic PDE: $$-\Delta u= f(x) u. $$ Assume that $f,u$ are defined in some reasonable bounded domain $\Omega \subset \mathbb{R}^n$ and impose the boundary condition $u=0$ on $\partial \Omega.$ Suppose first $f\equiv \lambda \in \mathbb{R}.$ Then is a fact that there are infinitely many, discrete choices of $\lambda$ such that this equation holds. I want to know more generally about the structure of the set of $f$ which admit solutions to the above equation. In particular, is the set of  $f$ such that the above equation holds ""exceptional"" in any sense? E.g. could the following statement be true?  ""for any $f \in C^0(\Omega)$ which admits a solution to the above equation, there exists $\epsilon>0$ such that if $\|g-f\|_{C^0} < \epsilon$ and $g$ also admits a solution to the equation then $f \equiv g.$"" (N.B. I am actually interested in the case where $f,u$ are defined on a closed manifold and $\Delta$ is the Laplace-Beltrami operator, but I have asked the question in the Euclidean setting since I assume this is more familiar to most people.)",,"['functional-analysis', 'partial-differential-equations', 'eigenvalues-eigenvectors', 'harmonic-functions', 'laplacian']"
49,Riesz Lemma with $\alpha=1$ and Linear Bounded Functional,Riesz Lemma with  and Linear Bounded Functional,\alpha=1,"Show that on a normed linear space $X$, Riesz lemma with $\alpha=1 $ holds implies that every bounded linear functional attains its norm on the unit sphere of $X$. This is not a homework question and I have tried a huge amount of approaches (too much to describe my attempts in here), so excuse me for not showing my work. A good hint would be appreciated.","Show that on a normed linear space $X$, Riesz lemma with $\alpha=1 $ holds implies that every bounded linear functional attains its norm on the unit sphere of $X$. This is not a homework question and I have tried a huge amount of approaches (too much to describe my attempts in here), so excuse me for not showing my work. A good hint would be appreciated.",,[]
50,Complex moment problem,Complex moment problem,,"Let $X$ be a complex-valued random variable.  For simplicity, let us assume that $X$ is bounded.  If I know all of the $\mathbb{E}[X^k]$ then do I know the distribution of $X$?  I know it suffices to know all $\mathbb{E}[X^k\overline{X^l}]$.  What restrictions on $X$ might ensure that you only need to know the nonconjugate moments? My efforts here are that I know that there is a nonzero complex linear functional annihilating all holomorphic functions.  Trouble is I need a real linear functional.","Let $X$ be a complex-valued random variable.  For simplicity, let us assume that $X$ is bounded.  If I know all of the $\mathbb{E}[X^k]$ then do I know the distribution of $X$?  I know it suffices to know all $\mathbb{E}[X^k\overline{X^l}]$.  What restrictions on $X$ might ensure that you only need to know the nonconjugate moments? My efforts here are that I know that there is a nonzero complex linear functional annihilating all holomorphic functions.  Trouble is I need a real linear functional.",,"['real-analysis', 'complex-analysis', 'functional-analysis', 'probability-theory']"
51,Spectrum of periodic schrödinger operators,Spectrum of periodic schrödinger operators,,"In many articles it's stated, as if it's common knowledge, that any Schrödinger operator with periodic potenial has purely absolutely continuous spectrum. I've tried to actually find a theorem stateting this with no luck. I've looking in Reed and simon, Teschl and googled endlessly. I can't seem to find any theorem which states this is true in the case of a one dimensional periodic potential? Can you help me out?","In many articles it's stated, as if it's common knowledge, that any Schrödinger operator with periodic potenial has purely absolutely continuous spectrum. I've tried to actually find a theorem stateting this with no luck. I've looking in Reed and simon, Teschl and googled endlessly. I can't seem to find any theorem which states this is true in the case of a one dimensional periodic potential? Can you help me out?",,"['functional-analysis', 'operator-theory']"
52,When is the convolution of a product the product of convolutions?,When is the convolution of a product the product of convolutions?,,"Although the convolution of the product is not the product of the convolution, i.e. $$fg*h\neq (f*h)(g*h).$$ I am wondering if  this true (for a suitable class of functions) in the limit when one uses a delta net. A delta net is defined as: A net $\{(\varphi_{n})\}\in(0,1]$ of smooth functions on $\mathbb{R}^{n}$ is called a  delta net, if $supp( \varphi_{n})\rightarrow {0}$ as $n\rightarrow 0$ $\int\varphi_{n} d\mu\rightarrow $ 1 as $n\rightarrow 0$ $\varphi_{n}$ is uniformly bounded in $L^{1}(\Omega,\mu)$ For example if we consider  the convolution of $f*\varphi_{n}=f_{n}$ where $f$ is in $L_{loc}^{p}$ and if $g*\varphi_{n}=g_{n}$ is uniformly bounded then: $$\lim_{n\rightarrow 0}||f_{n}g_{n}-fg||_{p_{loc}}\rightarrow 0$$ Of course using the properties of convolutions one also has that: $$\lim_{n\rightarrow 0}||(fg)*\varphi_{n}-fg||_{p_{loc}}\rightarrow 0$$ I am wondering if anyone ones similar results for $L^{p}$ convergence, measure convergence, pointwise convergece, etc with different assumptions for $f$ and $g$.","Although the convolution of the product is not the product of the convolution, i.e. $$fg*h\neq (f*h)(g*h).$$ I am wondering if  this true (for a suitable class of functions) in the limit when one uses a delta net. A delta net is defined as: A net $\{(\varphi_{n})\}\in(0,1]$ of smooth functions on $\mathbb{R}^{n}$ is called a  delta net, if $supp( \varphi_{n})\rightarrow {0}$ as $n\rightarrow 0$ $\int\varphi_{n} d\mu\rightarrow $ 1 as $n\rightarrow 0$ $\varphi_{n}$ is uniformly bounded in $L^{1}(\Omega,\mu)$ For example if we consider  the convolution of $f*\varphi_{n}=f_{n}$ where $f$ is in $L_{loc}^{p}$ and if $g*\varphi_{n}=g_{n}$ is uniformly bounded then: $$\lim_{n\rightarrow 0}||f_{n}g_{n}-fg||_{p_{loc}}\rightarrow 0$$ Of course using the properties of convolutions one also has that: $$\lim_{n\rightarrow 0}||(fg)*\varphi_{n}-fg||_{p_{loc}}\rightarrow 0$$ I am wondering if anyone ones similar results for $L^{p}$ convergence, measure convergence, pointwise convergece, etc with different assumptions for $f$ and $g$.",,"['functional-analysis', 'convergence-divergence', 'sobolev-spaces']"
53,What does a well-posed problem imply?,What does a well-posed problem imply?,,"A well-posed problem in the sense of Hadamard states that: A solution exists The solution is unique The solution's behavior changes continuously with the initial conditions. Now in order to prove this kind of results there are several techniques that are used separately or in combination with each other. For example, using energy estimates, using $C^{0}$ semigroups, proving the existence and uniqueness of a Green function,etc. My question is: How much can be said if we start with a well-posed problem: Can we guarantee that a Green function exist and is unique? Is there always an operator $A$ that generates a $C_{0}$ semigroup? Is there always an energy inequality giving the correct control so if one started with those then one will be able to prove at least part of the well-possessedness? I am more familiar with hyperbolic PDE but I am interested in this kind of converses in elliptic and parabolic problems also if there are any result available. For the sake of concreteness I am most interested in the problem: $\Box_{g}\phi=0$  where $\Box_{g}$ is the wave operator in a Lorentzian manifold.","A well-posed problem in the sense of Hadamard states that: A solution exists The solution is unique The solution's behavior changes continuously with the initial conditions. Now in order to prove this kind of results there are several techniques that are used separately or in combination with each other. For example, using energy estimates, using $C^{0}$ semigroups, proving the existence and uniqueness of a Green function,etc. My question is: How much can be said if we start with a well-posed problem: Can we guarantee that a Green function exist and is unique? Is there always an operator $A$ that generates a $C_{0}$ semigroup? Is there always an energy inequality giving the correct control so if one started with those then one will be able to prove at least part of the well-possessedness? I am more familiar with hyperbolic PDE but I am interested in this kind of converses in elliptic and parabolic problems also if there are any result available. For the sake of concreteness I am most interested in the problem: $\Box_{g}\phi=0$  where $\Box_{g}$ is the wave operator in a Lorentzian manifold.",,"['functional-analysis', 'partial-differential-equations']"
54,Is it feasible to think of laplace transform and z transform as projections?,Is it feasible to think of laplace transform and z transform as projections?,,"For Fourier transform, it has been ingrained in my head that all we are doing is projecting a function onto its Fourier basis, namely $(1, cos(t), sin(t),...cos(nt), sin(nt) ...)$ Can anyone comment whether we can also think of the laplace transform and the z-transform as projections on their respective basis? On some level this is more difficult because the kernel of the laplace transform is $e^{st}$ which is not intuitive as to what the basis would be. More difficult is the z-transform, which has the kernel $z^{-k}$. In this case can we say that we are projecting our function onto a set of discrete basis $(1, z^{-1}, z^{-2}...z^{-n})$, where each $z$ is a complex number. It is not clear what these basis are. Can someone clarify this issue? Thanks.","For Fourier transform, it has been ingrained in my head that all we are doing is projecting a function onto its Fourier basis, namely $(1, cos(t), sin(t),...cos(nt), sin(nt) ...)$ Can anyone comment whether we can also think of the laplace transform and the z-transform as projections on their respective basis? On some level this is more difficult because the kernel of the laplace transform is $e^{st}$ which is not intuitive as to what the basis would be. More difficult is the z-transform, which has the kernel $z^{-k}$. In this case can we say that we are projecting our function onto a set of discrete basis $(1, z^{-1}, z^{-2}...z^{-n})$, where each $z$ is a complex number. It is not clear what these basis are. Can someone clarify this issue? Thanks.",,"['functional-analysis', 'fourier-analysis', 'laplace-transform', 'z-transform']"
55,Pointwise approximation of a closed operator,Pointwise approximation of a closed operator,,"If $T:\mathcal D(T) \rightarrow \mathcal Y$ is a closed operator from a Banach space $\mathcal X$ to a Banach space $\mathcal Y$, is it possible to find bounded operators $T_n\in \mathscr B(\mathcal X,\mathcal Y)$ such that $T_n x\rightarrow Tx$ for all $x\in \mathcal D (T)$? If $\mathcal X$ and $\mathcal Y$ are Hilbert spaces , the polar decomposition of $T$ together with the Borel functional calculus allows one to answer the question in the affirmative, but I am not sure how to proceed in the Banach space setting, even if I assume separability . Update: If the graph of $T$ has a Schauder basis , say $(x_n,Tx_n)_{n\in \mathbb N}$, then $(x_n)_{n\in \mathbb N}$ is a Schauder basis for  $\mathcal X$ and we can consider the bounded projections $P_j( \sum_{n\geq 1}a_n x_n )= \sum_{j\geq n\geq 1}a_n x_n$. In this case $T_n=TP_n$ furnishes an approximation. Update: If $\mathcal Y$ has a Schauder basis and $T$ has a bounded inverse, then the graph of T has a Schauder basis, so that $T$ can be approximated pointwise. Assume more generally that $\mathcal Y$ has a Schauder basis and that there is a bounded operator $B\in \mathscr B (\mathcal X,\mathcal Y)$ such that $T+B$ has a bounded inverse. Then $T+B$, and therefore also $T$, can be approximated pointwise by bounded operators. In case $\mathcal X=\mathcal Y$, this covers the case of a closed operator with non-empty resolvent set. Update: In the paper 'Gaussian Measures on a Banach Space', Kuelbs constructs, for any separable Banach space $B$, separable Hilbert spaces $H_1\subset B\subset H_2$, where the inclusions are dense, bounded embeddings. It is claimed by Gill, Basu, Zachary and Steadman in the paper 'Adjoint for Operators in Banach Spaces' that any closed and densely defined operator $T$ on $B$ extends to a closed and densely defined operator on $H_2$ (Theorem 4). This would seem like a large step towards an affirmative answer in the case of a separable Banach space. Unfortunately, I do not understand the proof of Theorem 4, in particular it is not clear to me why (in the notation of the paper) $\left.A'\right|_{H_2'}$ is densely defined. Edit: A comment in a paper uploaded to arxiv suggests to me that the statement of Theorem 4 was false. So this line of reasoning seems unproductive. Edit: There is now a counter example to Theorem 4. Kuelbs, J. , Gaussian measures on a Banach space , J. Funct. Anal. 5, 354-367 (1970). ZBL0194.44703 . Gill, Tepper L.; Basu, Sudeshna; Zachary, Woodford W.; Steadman, V. , Adjoint for operators in Banach spaces , Proc. Am. Math. Soc. 132, No. 5, 1429-1434 (2004). ZBL1048.46014 .","If $T:\mathcal D(T) \rightarrow \mathcal Y$ is a closed operator from a Banach space $\mathcal X$ to a Banach space $\mathcal Y$, is it possible to find bounded operators $T_n\in \mathscr B(\mathcal X,\mathcal Y)$ such that $T_n x\rightarrow Tx$ for all $x\in \mathcal D (T)$? If $\mathcal X$ and $\mathcal Y$ are Hilbert spaces , the polar decomposition of $T$ together with the Borel functional calculus allows one to answer the question in the affirmative, but I am not sure how to proceed in the Banach space setting, even if I assume separability . Update: If the graph of $T$ has a Schauder basis , say $(x_n,Tx_n)_{n\in \mathbb N}$, then $(x_n)_{n\in \mathbb N}$ is a Schauder basis for  $\mathcal X$ and we can consider the bounded projections $P_j( \sum_{n\geq 1}a_n x_n )= \sum_{j\geq n\geq 1}a_n x_n$. In this case $T_n=TP_n$ furnishes an approximation. Update: If $\mathcal Y$ has a Schauder basis and $T$ has a bounded inverse, then the graph of T has a Schauder basis, so that $T$ can be approximated pointwise. Assume more generally that $\mathcal Y$ has a Schauder basis and that there is a bounded operator $B\in \mathscr B (\mathcal X,\mathcal Y)$ such that $T+B$ has a bounded inverse. Then $T+B$, and therefore also $T$, can be approximated pointwise by bounded operators. In case $\mathcal X=\mathcal Y$, this covers the case of a closed operator with non-empty resolvent set. Update: In the paper 'Gaussian Measures on a Banach Space', Kuelbs constructs, for any separable Banach space $B$, separable Hilbert spaces $H_1\subset B\subset H_2$, where the inclusions are dense, bounded embeddings. It is claimed by Gill, Basu, Zachary and Steadman in the paper 'Adjoint for Operators in Banach Spaces' that any closed and densely defined operator $T$ on $B$ extends to a closed and densely defined operator on $H_2$ (Theorem 4). This would seem like a large step towards an affirmative answer in the case of a separable Banach space. Unfortunately, I do not understand the proof of Theorem 4, in particular it is not clear to me why (in the notation of the paper) $\left.A'\right|_{H_2'}$ is densely defined. Edit: A comment in a paper uploaded to arxiv suggests to me that the statement of Theorem 4 was false. So this line of reasoning seems unproductive. Edit: There is now a counter example to Theorem 4. Kuelbs, J. , Gaussian measures on a Banach space , J. Funct. Anal. 5, 354-367 (1970). ZBL0194.44703 . Gill, Tepper L.; Basu, Sudeshna; Zachary, Woodford W.; Steadman, V. , Adjoint for operators in Banach spaces , Proc. Am. Math. Soc. 132, No. 5, 1429-1434 (2004). ZBL1048.46014 .",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces', 'unbounded-operators']"
56,"Do mathematicians consider functional integration to be good mathematics? If so, what is it?","Do mathematicians consider functional integration to be good mathematics? If so, what is it?",,"I am trying to learn about path integration in physics and, from what I understand, this means learning to do functional integrals. (Note: I know what a functional is and I also have done functional differentiation.) But I went to the Wikipedia page and also did some googling and came up with nothing intelligible that explained (as far as I could see) what a functional integral was and how to do it. This either means info about it is hard to find or I am not understanding it. I am physicist who is wary of the way some physicists do mathematics. Example: the Dirac delta function isn't a function at all but has something to do with distributions. So is the notion of a functional integral a legitimate mathematical concept? If it is, can you also explain what it is and/or provide a reference so I can learn about it myself. EDIT: Question: Would a bounty help this question get answered?","I am trying to learn about path integration in physics and, from what I understand, this means learning to do functional integrals. (Note: I know what a functional is and I also have done functional differentiation.) But I went to the Wikipedia page and also did some googling and came up with nothing intelligible that explained (as far as I could see) what a functional integral was and how to do it. This either means info about it is hard to find or I am not understanding it. I am physicist who is wary of the way some physicists do mathematics. Example: the Dirac delta function isn't a function at all but has something to do with distributions. So is the notion of a functional integral a legitimate mathematical concept? If it is, can you also explain what it is and/or provide a reference so I can learn about it myself. EDIT: Question: Would a bounty help this question get answered?",,"['calculus', 'functional-analysis']"
57,Check proof about range of bounded linear operator.,Check proof about range of bounded linear operator.,,"I have to prove that the range $\mathcal{R}(T)$ of bounded linear operator $T:X\rightarrow Y$; $X,Y$ normed spaces need not be closed in $Y$. As a hint I'm given that I could consider $T:\mathcal{l^{\infty}}\rightarrow \mathcal{l^{\infty}}$ where $y=Tx$ is such that $y_n=\frac{x_n}{n}$. Now my attempt is as follows: We take the sequence $y^{(n)}=(1,\frac{1}{\sqrt{2}},..., \frac{1}{\sqrt{n}}, 0,0,...)$. Then clearly we can take for each $y^{(n)}$ a $x^{(n)}=(1, \frac{2}{\sqrt{2}},...,\frac{n}{\sqrt{n}},0,0,...)\in \mathcal{l^{\infty}}$ so that $Tx^{(n)}=y^{(n)}$, and thus $y^{(n)}\in \mathcal{R}(T)$. Consider, the limit $y=\lim_{n}y^{(n)}=(1,\frac{1}{\sqrt{2}},\frac{1}{\sqrt{3}},...)\in \mathcal{l^{\infty}}$. If this were to be in $\mathcal{R}(T)$, then we must have $x=(1, \frac{2}{\sqrt{2}},\frac{3}{\sqrt{3}},...)\in \mathcal{l^{\infty}}$, but this is clearly not the case, since $x$ is a sequence increasing to $\infty$. Thus we have a converging sequence in $\mathcal{R}(T)$, whose limit is not in $\mathcal{R}(T)$, and thus $\mathcal{R}(T)$ cannot be closed. I wonder if this is correct, and even if it is I'm still curious about other proofs of this statements, with or without use of the suggested operator. Thanks.","I have to prove that the range $\mathcal{R}(T)$ of bounded linear operator $T:X\rightarrow Y$; $X,Y$ normed spaces need not be closed in $Y$. As a hint I'm given that I could consider $T:\mathcal{l^{\infty}}\rightarrow \mathcal{l^{\infty}}$ where $y=Tx$ is such that $y_n=\frac{x_n}{n}$. Now my attempt is as follows: We take the sequence $y^{(n)}=(1,\frac{1}{\sqrt{2}},..., \frac{1}{\sqrt{n}}, 0,0,...)$. Then clearly we can take for each $y^{(n)}$ a $x^{(n)}=(1, \frac{2}{\sqrt{2}},...,\frac{n}{\sqrt{n}},0,0,...)\in \mathcal{l^{\infty}}$ so that $Tx^{(n)}=y^{(n)}$, and thus $y^{(n)}\in \mathcal{R}(T)$. Consider, the limit $y=\lim_{n}y^{(n)}=(1,\frac{1}{\sqrt{2}},\frac{1}{\sqrt{3}},...)\in \mathcal{l^{\infty}}$. If this were to be in $\mathcal{R}(T)$, then we must have $x=(1, \frac{2}{\sqrt{2}},\frac{3}{\sqrt{3}},...)\in \mathcal{l^{\infty}}$, but this is clearly not the case, since $x$ is a sequence increasing to $\infty$. Thus we have a converging sequence in $\mathcal{R}(T)$, whose limit is not in $\mathcal{R}(T)$, and thus $\mathcal{R}(T)$ cannot be closed. I wonder if this is correct, and even if it is I'm still curious about other proofs of this statements, with or without use of the suggested operator. Thanks.",,"['functional-analysis', 'proof-verification', 'operator-theory']"
58,Convergence of the solution of Volterra integral equation with convergent kernel.,Convergence of the solution of Volterra integral equation with convergent kernel.,,"Consider the following Volterra integral equation $$ g(t) = \int_0^t K_n(t,s)w_n(s) ds $$ where $g(t)$ and $K_n(t,s)$ are known(continuous) and $K_n(t,s)\geq K_{n+1}(t,s)$ for all $t,s$. Moreover, $K_n(t,s)$ converges to $K(t,s)$. The conditions of $K_n(t,s)$ are as follows : $K_n(t,s)\neq 0 $ for each n and for all t,s. $\frac{\partial K_n(t,s)}{\partial t}$ is continuous for each n. $K(t,s)\neq 0 $ for all t,s. Conditions 1, 2 are sufficient to gurantee the existence of solution $w_n(s)$. Then, can we say that the solutions $w_n(s)$ also converges to some function $w(s)$? If so, how can i prove it?","Consider the following Volterra integral equation $$ g(t) = \int_0^t K_n(t,s)w_n(s) ds $$ where $g(t)$ and $K_n(t,s)$ are known(continuous) and $K_n(t,s)\geq K_{n+1}(t,s)$ for all $t,s$. Moreover, $K_n(t,s)$ converges to $K(t,s)$. The conditions of $K_n(t,s)$ are as follows : $K_n(t,s)\neq 0 $ for each n and for all t,s. $\frac{\partial K_n(t,s)}{\partial t}$ is continuous for each n. $K(t,s)\neq 0 $ for all t,s. Conditions 1, 2 are sufficient to gurantee the existence of solution $w_n(s)$. Then, can we say that the solutions $w_n(s)$ also converges to some function $w(s)$? If so, how can i prove it?",,"['real-analysis', 'functional-analysis', 'lebesgue-integral', 'functional-equations', 'integral-equations']"
59,Conditions for Taylor formula,Conditions for Taylor formula,,"I know that, if $F:X\to Y$, where $X,Y$ are Banach spaces, is a map whose $n$-th Fréchet derivative $x\mapsto F^{(n)}(x)$ is continuous as a function of $x$ in a neighbourhood of $x_0\in X$, then the Taylor formula of $F$ in $x_0$ holds:$$F(x_0+h)=F(x_0)+F'(x_0)h+\frac{1}{2!}F''(x)(h,h)+...+\frac{1}{n!}F^{(n)}(x_0)(h,...,h)+\omega(x,h)$$where $\|\omega(x,h)\|=o(\|h\|^n),h\to 0$ and $F^{(n)}(x_0)$ is the $n$-linear form corresponding to the $n$-th derivative. I have never see the condition of continuity of $F^{(n)}$ in $x_0$ relaxed either in the general case or when $X=\mathbb{R}^n$, $Y=\mathbb{R}$ (contrarily tom what happens when $X=\mathbb{R}=Y$, when De l'Hôpital's rule can be used and the assumption of the continuity of $F^{(n)}$ avoided). Can that assumption be relaxed? I am asking that because Kolmogorov-Fomin's Элементы теории функций и функционального анализа proves the Taylor expansion under the continuity assumption (p. 491 here ), but then proves the following theorem, which has the Hessian matrix test as a particular case, without saying that $F''$ must be continuous by using the Taylor expansion $F(x_0+h)=F(x_0)+F'(x_0)h+\frac{1}{2!}F''(x)(h,h)$ $+o(\|h\|^2)$: if functional $F:X\to\mathbb{R}$ where $X$ is a Banach space and (1) $F'(x_0)=0$ and (2) $F''(x_0)$ is strongly positive, i.e. $\exists c>0:\forall h\in X\quad F''(x_0)(h,h)\ge c\|h\|^2$, then $F$ has a minimum in $x_0$.","I know that, if $F:X\to Y$, where $X,Y$ are Banach spaces, is a map whose $n$-th Fréchet derivative $x\mapsto F^{(n)}(x)$ is continuous as a function of $x$ in a neighbourhood of $x_0\in X$, then the Taylor formula of $F$ in $x_0$ holds:$$F(x_0+h)=F(x_0)+F'(x_0)h+\frac{1}{2!}F''(x)(h,h)+...+\frac{1}{n!}F^{(n)}(x_0)(h,...,h)+\omega(x,h)$$where $\|\omega(x,h)\|=o(\|h\|^n),h\to 0$ and $F^{(n)}(x_0)$ is the $n$-linear form corresponding to the $n$-th derivative. I have never see the condition of continuity of $F^{(n)}$ in $x_0$ relaxed either in the general case or when $X=\mathbb{R}^n$, $Y=\mathbb{R}$ (contrarily tom what happens when $X=\mathbb{R}=Y$, when De l'Hôpital's rule can be used and the assumption of the continuity of $F^{(n)}$ avoided). Can that assumption be relaxed? I am asking that because Kolmogorov-Fomin's Элементы теории функций и функционального анализа proves the Taylor expansion under the continuity assumption (p. 491 here ), but then proves the following theorem, which has the Hessian matrix test as a particular case, without saying that $F''$ must be continuous by using the Taylor expansion $F(x_0+h)=F(x_0)+F'(x_0)h+\frac{1}{2!}F''(x)(h,h)$ $+o(\|h\|^2)$: if functional $F:X\to\mathbb{R}$ where $X$ is a Banach space and (1) $F'(x_0)=0$ and (2) $F''(x_0)$ is strongly positive, i.e. $\exists c>0:\forall h\in X\quad F''(x_0)(h,h)\ge c\|h\|^2$, then $F$ has a minimum in $x_0$.",,"['real-analysis', 'functional-analysis', 'multivariable-calculus', 'banach-spaces', 'taylor-expansion']"
60,Derivative of norm in Hilbert space,Derivative of norm in Hilbert space,,"I read (p. 485 here ) that the Fréchet derivative of norm (non-linear) functional $p:H\to\mathbb{R}$, $x\mapsto\|x\|$ is $\frac{x}{\|x\|}$ for all $x\ne 0$, which I think to be intended as the linear functional, which is what the Fréchet derivative $p'(x)\in \mathscr{L}(H,\mathbb{R})$ should be, defined by $h\mapsto\langle\frac{x}{\|x\|},h\rangle$. I suspect $H$ is intended to be a real Hilbert space, although Kolmogorov-Fomin's says nothing about the scalar field. As always, before asking here, I searched the Internet, but only find this page from this very site. Can anybody point to a proof of $p'(x)h=\langle\frac{x}{\|x\|},h\rangle$? I $\infty$-ly thank you!","I read (p. 485 here ) that the Fréchet derivative of norm (non-linear) functional $p:H\to\mathbb{R}$, $x\mapsto\|x\|$ is $\frac{x}{\|x\|}$ for all $x\ne 0$, which I think to be intended as the linear functional, which is what the Fréchet derivative $p'(x)\in \mathscr{L}(H,\mathbb{R})$ should be, defined by $h\mapsto\langle\frac{x}{\|x\|},h\rangle$. I suspect $H$ is intended to be a real Hilbert space, although Kolmogorov-Fomin's says nothing about the scalar field. As always, before asking here, I searched the Internet, but only find this page from this very site. Can anybody point to a proof of $p'(x)h=\langle\frac{x}{\|x\|},h\rangle$? I $\infty$-ly thank you!",,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
61,Is the spectrum of a first order PDO always unbounded from both sides?,Is the spectrum of a first order PDO always unbounded from both sides?,,"Let $E \to X$ be a smooth vector bundle over a compact Riemannian manifold $X$ and assume that $P:\Gamma(E) \to \Gamma(E)$ is a self-adjoint partial differential operator of order $1$. We think of this operator as an unbounded operator $P:L^2(E) \to L^2(E)$ densely defined on the first order Sobolev space $H^1(E)$. The spectrum $spec(P)$ is always a discrete subset of the real line. Is $spec(P) \subset \mathbf{R}$ always unbounded from both sides? In case the order of $P$ is $2$, the claim is wrong for sure (just consider the Laplacian). For example, if $P$ is a Dirac Operator, the claim is always true.","Let $E \to X$ be a smooth vector bundle over a compact Riemannian manifold $X$ and assume that $P:\Gamma(E) \to \Gamma(E)$ is a self-adjoint partial differential operator of order $1$. We think of this operator as an unbounded operator $P:L^2(E) \to L^2(E)$ densely defined on the first order Sobolev space $H^1(E)$. The spectrum $spec(P)$ is always a discrete subset of the real line. Is $spec(P) \subset \mathbf{R}$ always unbounded from both sides? In case the order of $P$ is $2$, the claim is wrong for sure (just consider the Laplacian). For example, if $P$ is a Dirac Operator, the claim is always true.",,"['functional-analysis', 'differential-geometry', 'operator-theory', 'spectral-theory', 'global-analysis']"
62,"Is the left regular representation of an algebra, always faithful?","Is the left regular representation of an algebra, always faithful?",,"Let $\mathcal{A}$ be a unital associative algebra with a countable basis $\mathcal{b}$ over $\mathbb{C}$. Let $H=l^2(b)$ be the Hilbert space generated by $\mathcal{b}$. Let $H_0 = \{v \in H \ \vert \ a.v \in H \  \forall a \in \mathcal{A}  \}$   and $\rho$ the left regular representation of $\mathcal{A}$ on $H_0$. Question : Is $H_0$ a dense subspace of $H$ and $\rho$ faithful?  Else what are the first counter-examples? Also  what would be the (minimal) additional assumptions for having $H_0$ dense and $\rho$ faithful? Remark : the problem seems reduce to the type of closure on $\mathcal{A}$ (see the comments below). Remark : for the Heisenberg algebra $\mathcal{A} = \langle a,b \ \vert \ [a,b]=1 \rangle$, then $H_0$ is dense and $\rho$ faithful, whereas $\mathcal{A}$ can't have a Banach structure (see here ).","Let $\mathcal{A}$ be a unital associative algebra with a countable basis $\mathcal{b}$ over $\mathbb{C}$. Let $H=l^2(b)$ be the Hilbert space generated by $\mathcal{b}$. Let $H_0 = \{v \in H \ \vert \ a.v \in H \  \forall a \in \mathcal{A}  \}$   and $\rho$ the left regular representation of $\mathcal{A}$ on $H_0$. Question : Is $H_0$ a dense subspace of $H$ and $\rho$ faithful?  Else what are the first counter-examples? Also  what would be the (minimal) additional assumptions for having $H_0$ dense and $\rho$ faithful? Remark : the problem seems reduce to the type of closure on $\mathcal{A}$ (see the comments below). Remark : for the Heisenberg algebra $\mathcal{A} = \langle a,b \ \vert \ [a,b]=1 \rangle$, then $H_0$ is dense and $\rho$ faithful, whereas $\mathcal{A}$ can't have a Banach structure (see here ).",,"['abstract-algebra', 'functional-analysis', 'representation-theory', 'operator-algebras', 'banach-algebras']"
63,Can a Norm be Induced by two Different Complex Inner Products?,Can a Norm be Induced by two Different Complex Inner Products?,,"Let $(X,\|\cdot\|)$ be a normed vector space over $\mathbb{C}$. If $\|x\|=\sqrt{\langle x,x\rangle}$ and $\|x\|=\sqrt{\langle x,x\rangle'}$ for all $x\in X$ where $\langle,\rangle$ and $\langle,\rangle'$ are complex inner products, then must we have $\langle,\rangle=\langle,\rangle'$ ? If $X$ is a vector space over $\mathbb{R}$, I think the answer is yes. Indeed, since $$ \forall x\in X:\|x\|=\sqrt{\langle x,x\rangle}=\sqrt{\langle x,x\rangle'}\implies\forall x\in X:\langle x,x\rangle=\langle x,x\rangle' $$ then for $x,y\in X$ we have $\langle x+y,x+y\rangle=\langle x+y,x+y\rangle'$ and expanding we see that $\langle x,y\rangle=\langle x,y\rangle'$. But, in the complex case, I can only get $\Re\langle x,y\rangle=\Re\langle x,y\rangle'$ with this argument.","Let $(X,\|\cdot\|)$ be a normed vector space over $\mathbb{C}$. If $\|x\|=\sqrt{\langle x,x\rangle}$ and $\|x\|=\sqrt{\langle x,x\rangle'}$ for all $x\in X$ where $\langle,\rangle$ and $\langle,\rangle'$ are complex inner products, then must we have $\langle,\rangle=\langle,\rangle'$ ? If $X$ is a vector space over $\mathbb{R}$, I think the answer is yes. Indeed, since $$ \forall x\in X:\|x\|=\sqrt{\langle x,x\rangle}=\sqrt{\langle x,x\rangle'}\implies\forall x\in X:\langle x,x\rangle=\langle x,x\rangle' $$ then for $x,y\in X$ we have $\langle x+y,x+y\rangle=\langle x+y,x+y\rangle'$ and expanding we see that $\langle x,y\rangle=\langle x,y\rangle'$. But, in the complex case, I can only get $\Re\langle x,y\rangle=\Re\langle x,y\rangle'$ with this argument.",,"['functional-analysis', 'vector-spaces', 'normed-spaces']"
64,Is there a complete orthornomal basis of a Hilbert space which takes positive values on a discrete set?,Is there a complete orthornomal basis of a Hilbert space which takes positive values on a discrete set?,,"Is there a complete orthonormal basis $\{f_n\}$ (of continuous functions) of the Hilbert space of square integrable functions on $[0,\,\infty)$ for which there exists a countable set $S\subset [0,\,\infty)$ such that $\forall x \in S$ we have $f_n(x)\geq 0,\, \forall n?$ Or could anyone point me to a paper on a similar topic? Thank you in advance.","Is there a complete orthonormal basis $\{f_n\}$ (of continuous functions) of the Hilbert space of square integrable functions on $[0,\,\infty)$ for which there exists a countable set $S\subset [0,\,\infty)$ such that $\forall x \in S$ we have $f_n(x)\geq 0,\, \forall n?$ Or could anyone point me to a paper on a similar topic? Thank you in advance.",,"['analysis', 'functional-analysis', 'fourier-analysis']"
65,Non-separability of the Cadlag functions equipped with the topology of uniform convergence on compacts,Non-separability of the Cadlag functions equipped with the topology of uniform convergence on compacts,,"Consider the space $D:=D([0,\infty),\mathbb{R}^N)$ of component-wise right continuous functions with left limits. Endow $D$ with the metric $$d(\psi,\tilde{\psi}):=\sum_{n=1}^{\infty}2^{-n}||\psi-\tilde{\psi}||_{[0,n]}\wedge1$$ where $||\psi-\tilde{\psi}||_{[0,n]}:=\sup_{t\in[0,n]}|\psi(t)-\tilde{\psi}(t)|$. How can we deduce that $(D,d)$ is not a separable metric space? If we take $e\in S^{N-1}$, a unit vector on the sphere, and set $\psi_t(\tau)=\mathbf{1}_{[t,\infty)}e$ for $t\in[0,1]$, then if we can show that $||\psi_t-\psi_s||_{[0,1]}=1$ for all $t\neq s$ where $s,t\in[0,1]$, then this could mean that there is no countable dense subset in $D$. However, I am unsure as to how to complete the argument.","Consider the space $D:=D([0,\infty),\mathbb{R}^N)$ of component-wise right continuous functions with left limits. Endow $D$ with the metric $$d(\psi,\tilde{\psi}):=\sum_{n=1}^{\infty}2^{-n}||\psi-\tilde{\psi}||_{[0,n]}\wedge1$$ where $||\psi-\tilde{\psi}||_{[0,n]}:=\sup_{t\in[0,n]}|\psi(t)-\tilde{\psi}(t)|$. How can we deduce that $(D,d)$ is not a separable metric space? If we take $e\in S^{N-1}$, a unit vector on the sphere, and set $\psi_t(\tau)=\mathbf{1}_{[t,\infty)}e$ for $t\in[0,1]$, then if we can show that $||\psi_t-\psi_s||_{[0,1]}=1$ for all $t\neq s$ where $s,t\in[0,1]$, then this could mean that there is no countable dense subset in $D$. However, I am unsure as to how to complete the argument.",,"['analysis', 'functional-analysis', 'probability-theory']"
66,$H^{1/2}$ function but not better,function but not better,H^{1/2},"I am looking for an example of a function $f: [0, 1] \longrightarrow \mathbb{R}$ that is in the Sobolev space of order $1/2$, $H^{1/2}([0, 1])$, but not in the Sobolev space of order $1/2 + \varepsilon$, for any $\varepsilon$. Functions with discontinuities like the Rectangular function or the sawtooth wave are in the Sobolev spaces of order $s< 1/2$, but not equal to $s$.","I am looking for an example of a function $f: [0, 1] \longrightarrow \mathbb{R}$ that is in the Sobolev space of order $1/2$, $H^{1/2}([0, 1])$, but not in the Sobolev space of order $1/2 + \varepsilon$, for any $\varepsilon$. Functions with discontinuities like the Rectangular function or the sawtooth wave are in the Sobolev spaces of order $s< 1/2$, but not equal to $s$.",,"['functional-analysis', 'functions', 'sobolev-spaces']"
67,Show that $S^{\perp \perp} \equiv (S^\perp)^\perp$ is the closure of $S$.,Show that  is the closure of .,S^{\perp \perp} \equiv (S^\perp)^\perp S,"Suppose $S$ is a (not neccessarily closed) subspace of a Hilbert space $H$. Show that $S^{\perp \perp} \equiv (S^\perp)^\perp$ is the closure of $S$. I know that if $X\in H$, that $X^\perp$ is a closed subspace, but not really sure where to go from there?","Suppose $S$ is a (not neccessarily closed) subspace of a Hilbert space $H$. Show that $S^{\perp \perp} \equiv (S^\perp)^\perp$ is the closure of $S$. I know that if $X\in H$, that $X^\perp$ is a closed subspace, but not really sure where to go from there?",,['functional-analysis']
68,Isomorphism between $C^\infty_0(B_1)$ and $\mathscr{S}(\mathbb{R}^n)$,Isomorphism between  and,C^\infty_0(B_1) \mathscr{S}(\mathbb{R}^n),"Background: Related question I am trying to prove, that the countably-normed spaces $C^\infty_0(B_1)$ on the open unit ball (i.e. function and all derivatives vanish at the boundary) in $\mathbb{R}^n$ and the Schwartz Space $\mathscr{S}(\mathbb{R}^n)$ are isomorphic. Here, $\mathscr{S}$ carries the usual Schwartz topology and $C^\infty_0(B_1)$ the locally convex topology induced by the family $\|\varphi\|_i=\sup_{x\in B_1}\max_{|\alpha|\leq i}|D^\alpha\varphi|$. My ansatz is to use, that the open unit ball and whole $\mathbb{R}^n$ are diffeomorphic, e.g. via the diffeomorphism $$ h:x\rightarrow \frac{x}{\sqrt{1+|x|^2}} $$ therefore my guess for the isomorphism is $$ I:C^\infty_0(B_1)\rightarrow \mathscr{S}(\mathbb{R}^n), f\rightarrow f\circ h $$ However, I am unable to prove, that $I$ and $I^{-1}$ are continuous with respect to the locally convex topology. Concretely, I have to show that for every pair $p,q\in \mathbb{N}$ there exist $r\in \mathbb{N},C>0$ with $$ \sup_{x\in \mathbb{R}^n}\max_{\alpha\leq q} (1+|x|^2)^p|D^\alpha (\varphi \circ h) | \leq C \sup_{x\in B_1}\max_{\alpha\leq r} |D^\alpha \varphi | $$ for all $\varphi\in C_0^\infty(B_1)$, similar for $I^{-1}$. The crux about the continuity has to be, that the vanishing at the boundary of $B_1$ for some function $\varphi$ somehow also implies the vanishing at infinity for $I(\varphi)$, however, I am not able to formulate a clean proof for this. Does anybody have an idea or a reference? I found a similar statement in Treves (Topological Vector Spaces) Theorem 51.4, unfortunately, the proof of the theorem was ""left as exercise"", and I am obviously too dumb to solve it. I would greatly appreciate any help!","Background: Related question I am trying to prove, that the countably-normed spaces $C^\infty_0(B_1)$ on the open unit ball (i.e. function and all derivatives vanish at the boundary) in $\mathbb{R}^n$ and the Schwartz Space $\mathscr{S}(\mathbb{R}^n)$ are isomorphic. Here, $\mathscr{S}$ carries the usual Schwartz topology and $C^\infty_0(B_1)$ the locally convex topology induced by the family $\|\varphi\|_i=\sup_{x\in B_1}\max_{|\alpha|\leq i}|D^\alpha\varphi|$. My ansatz is to use, that the open unit ball and whole $\mathbb{R}^n$ are diffeomorphic, e.g. via the diffeomorphism $$ h:x\rightarrow \frac{x}{\sqrt{1+|x|^2}} $$ therefore my guess for the isomorphism is $$ I:C^\infty_0(B_1)\rightarrow \mathscr{S}(\mathbb{R}^n), f\rightarrow f\circ h $$ However, I am unable to prove, that $I$ and $I^{-1}$ are continuous with respect to the locally convex topology. Concretely, I have to show that for every pair $p,q\in \mathbb{N}$ there exist $r\in \mathbb{N},C>0$ with $$ \sup_{x\in \mathbb{R}^n}\max_{\alpha\leq q} (1+|x|^2)^p|D^\alpha (\varphi \circ h) | \leq C \sup_{x\in B_1}\max_{\alpha\leq r} |D^\alpha \varphi | $$ for all $\varphi\in C_0^\infty(B_1)$, similar for $I^{-1}$. The crux about the continuity has to be, that the vanishing at the boundary of $B_1$ for some function $\varphi$ somehow also implies the vanishing at infinity for $I(\varphi)$, however, I am not able to formulate a clean proof for this. Does anybody have an idea or a reference? I found a similar statement in Treves (Topological Vector Spaces) Theorem 51.4, unfortunately, the proof of the theorem was ""left as exercise"", and I am obviously too dumb to solve it. I would greatly appreciate any help!",,"['functional-analysis', 'distribution-theory', 'locally-convex-spaces']"
69,Shorter proof for $T$ compact and $x_n \to x$ weaky then $Tx_n \to Tx$ strongly,Shorter proof for  compact and  weaky then  strongly,T x_n \to x Tx_n \to Tx,"I proved that if $X,Y$ are Banach spaces and $T: X \to Y$ is compact and $x_n \to x$ weakly then $Tx_n \to Tx$ strongly. I am now wondering if there is a shorter proof? Here is my proof: Let $x_n \to x$ weakly. By this result here $T$ is norm-norm continuous if and only if it is weak-weak continuous. Hence $Tx_n \to Tx$ weakly. Next note that because $x_n\to x$ weakly the sequence $x_n$ is bounded. Hence $S=\{x_n\}\cup \{x\}$ is bounded. Since $T$ is compact it follows that $Tx_n$ has a (norm) convergent subsequence. Let's call it $Tx_{n_k}$. Since strong convergence implies weak convergence,  $Tx_{n_k}$ converges weakly and since the weak topology is Hausdorff we use uniqueness of the limit to get that $Tx_{n_k}$ converges to $Tx$ weakly. Finally, since $Tx_n$ has the same limit in the weak topology and in the strong topology, $Tx_{n_k} \to Tx$ strongly. The proof seems to long in general but I am particularly unhappy with using the result I link to. Any ideas how to make this proof neater?","I proved that if $X,Y$ are Banach spaces and $T: X \to Y$ is compact and $x_n \to x$ weakly then $Tx_n \to Tx$ strongly. I am now wondering if there is a shorter proof? Here is my proof: Let $x_n \to x$ weakly. By this result here $T$ is norm-norm continuous if and only if it is weak-weak continuous. Hence $Tx_n \to Tx$ weakly. Next note that because $x_n\to x$ weakly the sequence $x_n$ is bounded. Hence $S=\{x_n\}\cup \{x\}$ is bounded. Since $T$ is compact it follows that $Tx_n$ has a (norm) convergent subsequence. Let's call it $Tx_{n_k}$. Since strong convergence implies weak convergence,  $Tx_{n_k}$ converges weakly and since the weak topology is Hausdorff we use uniqueness of the limit to get that $Tx_{n_k}$ converges to $Tx$ weakly. Finally, since $Tx_n$ has the same limit in the weak topology and in the strong topology, $Tx_{n_k} \to Tx$ strongly. The proof seems to long in general but I am particularly unhappy with using the result I link to. Any ideas how to make this proof neater?",,[]
70,Functions with compact support,Functions with compact support,,"I have a question about a convergence of functions with compact support. SETTING Let $d\geq 3$ and  $U \subset \mathbb{R^{d}}$ be open and $dx$= Lebesgue measure on $U$. Let $b_{i},c,d_{i} \in L^{1}_{loc}(U;dx) ,\,1 \leq i \leq d$, such that $cdx-\sum_{i=1}^{d} \frac{\partial b_{i}}{\partial x_{i}} \geq 0$ and $cdx-\sum_{i=1}^{d} \frac{\partial d_{i}}{\partial x_{i}} \geq0$ in the sense of Schwartz distributions. Suppose $b_{i}+d_{i} \in L^{d}_{loc}(U;dx)$, $1\leq i \leq d$, and $c \in L^{d/2}_{loc}(U;dx)$ then I want to show the following assertion: For any $u_{n} \in C_{0}^{\infty}(U)$, $n=1,2,\cdots$, with $u_{n}\to0$ and $\frac{\partial u_{n}}{\partial x_{i}}\to 0 $, $1\leq i \leq d$, in $L^{2}(U;dx)$ there exists a subsequence $(u_{n_{k}})_{k=1}^{\infty}$ with $u_{n_{k}} \to 0$ $\mu$-a.e. Here $\mu=2cdx-\sum_{i=1}^{d} \frac{\partial(b_{i}+d_{i})}{\partial x_{i}}$ (positive radon measure) Solution(unfinished) For any $v \in C_{0}^{\infty}(U)$, $v \geq0 $ on $U$, put $h_{n}=u_{n}v\quad(n=1,2,...)$ . Then ${\rm supp}\,h_{n} \subset K$ for some compact set $K \subset U$ and all $n \in \mathbb{N}$. \begin{eqnarray*} \frac{1}{2} \int h_{n}^{2} d \mu&=& \int _{K} h_{n}^{2} d\mu\\ &=& \sum_{i=1}^{d} \int_{K} h_{n} \frac{\partial h_{n}}{ \partial x_{i}} (b_{i}+d_{i})dx+\int_{K} h_{n}^{2}c dx\\ &\leq& \left( \sum_{i=1}^{d} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)}^{2}  \right)^{1/2}  \left(\sum_{i=1}^{d}\left\|1_{K}\frac{\partial h_{n}}{ \partial x_{i}}\right\|^{2}_{L^{2}(dx)} \right)^{1/2} +\|h_{n}^{2}1_{K}c \|_{L^{1}(dx)}\\ &\leq&\left( \sum_{i=1}^{d} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)}^{2}  \right)^{1/2}  \left(\sum_{i=1}^{d}\left\|\frac{\partial h_{n}}{ \partial x_{i}}\right\|^{2}_{L^{2}(dx)} \right)^{1/2} +\|h_{n}^{2}1_{K}c \|_{L^{1}(dx)}\\ \end{eqnarray*} By the following inequality (It is called Sobolev Lemma): $\exists C>0$ s.t. $\forall u \in C_{0}^{\infty}(U)$, $ \|u\|_{L^{q}(dx)} \leq C  \left(\sum_{i=1}^{d} \int \left|\frac{ \partial u}{\partial x_{i}} \right|^{2}dx \right)^{1/2}$ where $1/q+1/d=1/2$. \begin{eqnarray*} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)} \leq C_{1} \left( \sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)} \right)^{1/2} \|1_{K}(b_{i}+d_{i})\|_{L^d(dx)} \end{eqnarray*} \begin{eqnarray*} \|u_{n}^{2}1_{K}c\|_{L^{1}(dx)} \leq C_{2} \left( \sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)} \right)^{1/2} \|1_{K}c\|_{L^{d/2}(dx)} \end{eqnarray*} Since $u_{n}\to0$ and $\frac{\partial u_{n}}{\partial x_{i}}\to 0 $, $1\leq i \leq d$, in $L^{2}(U;dx)$, $\sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)}\to 0$ Hence $\int h_{n}^{2} d\mu \to 0$ and there exists $(h_{n_{k}})_{k=1}^{\infty}$ with $h_{n_{k}} \to 0$ $\mu$-a.e. . Because $h_{n_{k}}=u_{n_{k}}v$ $k=1,2,...$ and ${\rm supp}\,v \subset K$, I can get $u_{n_{k}}\to 0$ $\mu$-a.e. on ${\rm supp}\,v $. Can I get $u_{n_{k}}\to 0 $ $\mu$-a.e.? Thanks.","I have a question about a convergence of functions with compact support. SETTING Let $d\geq 3$ and  $U \subset \mathbb{R^{d}}$ be open and $dx$= Lebesgue measure on $U$. Let $b_{i},c,d_{i} \in L^{1}_{loc}(U;dx) ,\,1 \leq i \leq d$, such that $cdx-\sum_{i=1}^{d} \frac{\partial b_{i}}{\partial x_{i}} \geq 0$ and $cdx-\sum_{i=1}^{d} \frac{\partial d_{i}}{\partial x_{i}} \geq0$ in the sense of Schwartz distributions. Suppose $b_{i}+d_{i} \in L^{d}_{loc}(U;dx)$, $1\leq i \leq d$, and $c \in L^{d/2}_{loc}(U;dx)$ then I want to show the following assertion: For any $u_{n} \in C_{0}^{\infty}(U)$, $n=1,2,\cdots$, with $u_{n}\to0$ and $\frac{\partial u_{n}}{\partial x_{i}}\to 0 $, $1\leq i \leq d$, in $L^{2}(U;dx)$ there exists a subsequence $(u_{n_{k}})_{k=1}^{\infty}$ with $u_{n_{k}} \to 0$ $\mu$-a.e. Here $\mu=2cdx-\sum_{i=1}^{d} \frac{\partial(b_{i}+d_{i})}{\partial x_{i}}$ (positive radon measure) Solution(unfinished) For any $v \in C_{0}^{\infty}(U)$, $v \geq0 $ on $U$, put $h_{n}=u_{n}v\quad(n=1,2,...)$ . Then ${\rm supp}\,h_{n} \subset K$ for some compact set $K \subset U$ and all $n \in \mathbb{N}$. \begin{eqnarray*} \frac{1}{2} \int h_{n}^{2} d \mu&=& \int _{K} h_{n}^{2} d\mu\\ &=& \sum_{i=1}^{d} \int_{K} h_{n} \frac{\partial h_{n}}{ \partial x_{i}} (b_{i}+d_{i})dx+\int_{K} h_{n}^{2}c dx\\ &\leq& \left( \sum_{i=1}^{d} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)}^{2}  \right)^{1/2}  \left(\sum_{i=1}^{d}\left\|1_{K}\frac{\partial h_{n}}{ \partial x_{i}}\right\|^{2}_{L^{2}(dx)} \right)^{1/2} +\|h_{n}^{2}1_{K}c \|_{L^{1}(dx)}\\ &\leq&\left( \sum_{i=1}^{d} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)}^{2}  \right)^{1/2}  \left(\sum_{i=1}^{d}\left\|\frac{\partial h_{n}}{ \partial x_{i}}\right\|^{2}_{L^{2}(dx)} \right)^{1/2} +\|h_{n}^{2}1_{K}c \|_{L^{1}(dx)}\\ \end{eqnarray*} By the following inequality (It is called Sobolev Lemma): $\exists C>0$ s.t. $\forall u \in C_{0}^{\infty}(U)$, $ \|u\|_{L^{q}(dx)} \leq C  \left(\sum_{i=1}^{d} \int \left|\frac{ \partial u}{\partial x_{i}} \right|^{2}dx \right)^{1/2}$ where $1/q+1/d=1/2$. \begin{eqnarray*} \|h_{n}1_{K}(b_{i}+d_{i})\|_{L^{2}(dx)} \leq C_{1} \left( \sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)} \right)^{1/2} \|1_{K}(b_{i}+d_{i})\|_{L^d(dx)} \end{eqnarray*} \begin{eqnarray*} \|u_{n}^{2}1_{K}c\|_{L^{1}(dx)} \leq C_{2} \left( \sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)} \right)^{1/2} \|1_{K}c\|_{L^{d/2}(dx)} \end{eqnarray*} Since $u_{n}\to0$ and $\frac{\partial u_{n}}{\partial x_{i}}\to 0 $, $1\leq i \leq d$, in $L^{2}(U;dx)$, $\sum_{i=1}^{d}  \left\| \frac{\partial h_{n}}{\partial x_{i}} \right\|^{2}_{L^{2}(dx)}\to 0$ Hence $\int h_{n}^{2} d\mu \to 0$ and there exists $(h_{n_{k}})_{k=1}^{\infty}$ with $h_{n_{k}} \to 0$ $\mu$-a.e. . Because $h_{n_{k}}=u_{n_{k}}v$ $k=1,2,...$ and ${\rm supp}\,v \subset K$, I can get $u_{n_{k}}\to 0$ $\mu$-a.e. on ${\rm supp}\,v $. Can I get $u_{n_{k}}\to 0 $ $\mu$-a.e.? Thanks.",,"['real-analysis', 'functional-analysis']"
71,Uniform continuity of the function $x(t)=e^{tA}x$,Uniform continuity of the function,x(t)=e^{tA}x,"Let $A$ be a bounded operator on a Banach space $X$. Consider the exponential function $x(t)=e^{tA}x:=\sum_{n=0}^{+\infty}\dfrac{t^nA^n}{n!}x$, for all $t\in \mathbb{R}$, where $x\in X$. If the function $t\mapsto x(t)=e^{tA}x$ is bounded in $\mathbb{R}$ then it is uniformly continuous. In fact $x(t)$ is a solution of the ordinary differential equation $$x'(t)=Ax(t).$$ It follows that  $$x(t)=x(0)+\int_0^tAx(u)du.$$ Then $$\left|x(t)-x(s) \right|=\left|\int_s^tAx(u)du\right|\leq  \left|A\right| \left|x\right|_\infty \left|t-s\right|.$$ So $x(t)$ is even Lipshitz. We can visualize this intuitively in the case $X=\mathbb{R}$, the function $x(t)=e^{ta}x$ is bounded if and only if $a$ is pure imaginary, so $x(t)$ has the form $\cos(\omega t)+i\sin(\omega t)$ which is uniformly continuous. My question concerns the case when $A$ is an unbounded operator which generates a strongly continuous group of operators $(T(t))_{t\in \mathbb{R}}$. We consider now the function $x(t)=T(t)x$. I tried to do the same manipulations as the function $t\mapsto e^{tA}x$. From some properties of strongly continuous groups we have $\int_0^tT(u)xdu\in D(A)$ for all $x\in X$, where $D(A)$ is the domain of $A$. In addition $$x(t)=T(t)x=x+A\int_0^tT(u)xdu=x+A\int_0^tx(u)du$$ Using this I tried $$\left|x(t)-x(s) \right|=\left|A\int_s^tx(u)du\right|.$$ But I stopped here since $A$ is not bounded. So my question is what can we say in this case ? is $x(t)=T(t)x$ uniformly continuous if it is bounded on $\mathbb{R}$ ?","Let $A$ be a bounded operator on a Banach space $X$. Consider the exponential function $x(t)=e^{tA}x:=\sum_{n=0}^{+\infty}\dfrac{t^nA^n}{n!}x$, for all $t\in \mathbb{R}$, where $x\in X$. If the function $t\mapsto x(t)=e^{tA}x$ is bounded in $\mathbb{R}$ then it is uniformly continuous. In fact $x(t)$ is a solution of the ordinary differential equation $$x'(t)=Ax(t).$$ It follows that  $$x(t)=x(0)+\int_0^tAx(u)du.$$ Then $$\left|x(t)-x(s) \right|=\left|\int_s^tAx(u)du\right|\leq  \left|A\right| \left|x\right|_\infty \left|t-s\right|.$$ So $x(t)$ is even Lipshitz. We can visualize this intuitively in the case $X=\mathbb{R}$, the function $x(t)=e^{ta}x$ is bounded if and only if $a$ is pure imaginary, so $x(t)$ has the form $\cos(\omega t)+i\sin(\omega t)$ which is uniformly continuous. My question concerns the case when $A$ is an unbounded operator which generates a strongly continuous group of operators $(T(t))_{t\in \mathbb{R}}$. We consider now the function $x(t)=T(t)x$. I tried to do the same manipulations as the function $t\mapsto e^{tA}x$. From some properties of strongly continuous groups we have $\int_0^tT(u)xdu\in D(A)$ for all $x\in X$, where $D(A)$ is the domain of $A$. In addition $$x(t)=T(t)x=x+A\int_0^tT(u)xdu=x+A\int_0^tx(u)du$$ Using this I tried $$\left|x(t)-x(s) \right|=\left|A\int_s^tx(u)du\right|.$$ But I stopped here since $A$ is not bounded. So my question is what can we say in this case ? is $x(t)=T(t)x$ uniformly continuous if it is bounded on $\mathbb{R}$ ?",,"['functional-analysis', 'ordinary-differential-equations', 'operator-theory', 'banach-spaces', 'semigroup-of-operators']"
72,Criteria to prove that a map is a tempered distribution,Criteria to prove that a map is a tempered distribution,,"There is any simple sufficient condition to determine if a function is a tempered distribution? For example, given the map : $$ F \phi = \int_\epsilon^\infty \! \frac {\phi(x)}{\sqrt{x}} \, \mathrm{d}x. $$ I can prove that this is a tempered distribution with consideration about topology (for every epsilon this distribution is associated with an $L^2$ function, ecc..), but how can I do it using the definition?","There is any simple sufficient condition to determine if a function is a tempered distribution? For example, given the map : $$ F \phi = \int_\epsilon^\infty \! \frac {\phi(x)}{\sqrt{x}} \, \mathrm{d}x. $$ I can prove that this is a tempered distribution with consideration about topology (for every epsilon this distribution is associated with an $L^2$ function, ecc..), but how can I do it using the definition?",,"['functional-analysis', 'distribution-theory']"
73,Trace class operators problem,Trace class operators problem,,"Let $\mathcal{B}_1(\mathcal{H})$ be the set of trace class operators in a Hilbert space $\mathcal{H}$ and $\mathcal{H}^{(d)} = \bigoplus_{i=1}^d \mathcal{H}$ with $1 \leq d \leq \infty$. If $C \in \mathcal{B}_1(\mathcal{H}^{(d)})$ with matrix representation $C=(C_{jk})$, does the series $\sum_kC_{kk}$ converges in the trace norm?","Let $\mathcal{B}_1(\mathcal{H})$ be the set of trace class operators in a Hilbert space $\mathcal{H}$ and $\mathcal{H}^{(d)} = \bigoplus_{i=1}^d \mathcal{H}$ with $1 \leq d \leq \infty$. If $C \in \mathcal{B}_1(\mathcal{H}^{(d)})$ with matrix representation $C=(C_{jk})$, does the series $\sum_kC_{kk}$ converges in the trace norm?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
74,Differentiation of norm in Banach space (explanation of text needed),Differentiation of norm in Banach space (explanation of text needed),,"Let $Y$ be uniformly smooth Banach space. Consider the convex $C^1$ functional $\Phi:Y \to \mathbb{R}$ defined $$\Phi(y) = \frac{1}{q}\Vert y \Vert^q_{Y}.$$ Its derivative $\varphi:Y \to Y'$ is a monotone operator satisfying   $$\langle \varphi(y), y \rangle = \Vert y \Vert^q_Y.$$ How to prove this? I presume this refers to the Gateaux derivative but I cannot get anywhere after forming the directional derivative expression. Is the proof hard? Let $u \in L^p_{loc}(0,T;X) \cap L^q_{loc}(0,T;Y)$ be such that $\varphi(u) \in L^{q'}_{loc}(0,T;Y')$ is weakly differentiable with $(\varphi(u))' \in L^{p'}_{loc}(0,T;X')$. Then   $$\frac{d}{dt}\frac{1}{q'}\Vert u(t) \Vert^q_Y = \langle (\varphi(u))', u \rangle$$   holds in the sense of distributions on $(0,T)$. I don't obtain this: I don't get the factor of $\frac{1}{q'}$. I get: $$-\int_0^T \psi(t)\langle (\varphi(u))', u \rangle = \int_0^T \psi'(t)\langle (\varphi(u)), u \rangle = \int_0^T \psi'(t)\Vert u(t) \Vert^q$$ by the equation above. So I get $$\frac{d}{dt}\Vert u(t) \Vert^q_Y = \langle (\varphi(u))', u \rangle.$$ Where did I go wrong? Thanks for any help. EDIT Source is http://link.springer.com/article/10.1007%2Fs10492-012-0004-0 , section A.3 in the appendix.","Let $Y$ be uniformly smooth Banach space. Consider the convex $C^1$ functional $\Phi:Y \to \mathbb{R}$ defined $$\Phi(y) = \frac{1}{q}\Vert y \Vert^q_{Y}.$$ Its derivative $\varphi:Y \to Y'$ is a monotone operator satisfying   $$\langle \varphi(y), y \rangle = \Vert y \Vert^q_Y.$$ How to prove this? I presume this refers to the Gateaux derivative but I cannot get anywhere after forming the directional derivative expression. Is the proof hard? Let $u \in L^p_{loc}(0,T;X) \cap L^q_{loc}(0,T;Y)$ be such that $\varphi(u) \in L^{q'}_{loc}(0,T;Y')$ is weakly differentiable with $(\varphi(u))' \in L^{p'}_{loc}(0,T;X')$. Then   $$\frac{d}{dt}\frac{1}{q'}\Vert u(t) \Vert^q_Y = \langle (\varphi(u))', u \rangle$$   holds in the sense of distributions on $(0,T)$. I don't obtain this: I don't get the factor of $\frac{1}{q'}$. I get: $$-\int_0^T \psi(t)\langle (\varphi(u))', u \rangle = \int_0^T \psi'(t)\langle (\varphi(u)), u \rangle = \int_0^T \psi'(t)\Vert u(t) \Vert^q$$ by the equation above. So I get $$\frac{d}{dt}\Vert u(t) \Vert^q_Y = \langle (\varphi(u))', u \rangle.$$ Where did I go wrong? Thanks for any help. EDIT Source is http://link.springer.com/article/10.1007%2Fs10492-012-0004-0 , section A.3 in the appendix.",,"['functional-analysis', 'reference-request', 'operator-theory', 'banach-spaces', 'weak-derivatives']"
75,Projection and Pseudocontraction on Hilbert space,Projection and Pseudocontraction on Hilbert space,,"Let $H$ be a real Hilbert space with inner product $\langle\cdot, \cdot \rangle: H \times H \rightarrow \mathbb{R}$, and induced norm $\left\| \cdot \right\|: H \rightarrow \mathbb{R}_{\geq 0}$. Let $X \subset H$ be a closed, bounded, convex set and $P_X: H \rightarrow X$ the metric projection onto $X$, i.e., $P_X(x) := \arg \min_{y \in X} \left\| x-y\right\|$. Let $f: H \rightarrow H$ be a pseudocontraction, i.e., $$ \left\| f(x) - f(y) \right\|^2 \leq \left\| x-y\right\|^2 + \left\| f(x) - f(y) - (x-y) \right\|^2 $$ for all $x,y \in H$. I am looking for additional assumptions on $f$ and $X$ such that the mapping $P_X(f(\cdot))$ is a pseudocontraction as well. Observations and comments: $P_X$ is firmly nonexpansive , i.e.,  $$ \left\| P_X(x) - P_X(y) \right\|^2 \leq \langle x-y, P_X(x) - P_X(y) \rangle $$ $f$ is a pseudocontraction if and only if $x \mapsto x - f(x)$ is accretive. A map $g: H \rightarrow H$ is accretive if $ \langle g(x) - g(y), z \rangle \geq 0$ for all $x,y \in H$, $z \in J(x-y)$, where $J$ is the normalized duality mapping, i.e., $J(x) = \{ z \in X^* \mid \left\| z \right\|^2 = \left\| x \right\|^2 = \langle x, z \rangle \}$. $f$ is a pseudocontraction if and only if $$ \langle f(x) - f(y), x-y \rangle \leq \left\| x-y\right\|^2 $$ for all $x,y \in H$. $f$ is a pseudocontraction if and only if $I - f$ is monotone ; $g: H \rightarrow H$ is monotone if $\langle g(x) - g(y), x-y\rangle \geq 0$ for all $x,y \in H$. The composition of a firmly nonexpansive mapping with a pseudocontraction is not always a pseudocontraction.","Let $H$ be a real Hilbert space with inner product $\langle\cdot, \cdot \rangle: H \times H \rightarrow \mathbb{R}$, and induced norm $\left\| \cdot \right\|: H \rightarrow \mathbb{R}_{\geq 0}$. Let $X \subset H$ be a closed, bounded, convex set and $P_X: H \rightarrow X$ the metric projection onto $X$, i.e., $P_X(x) := \arg \min_{y \in X} \left\| x-y\right\|$. Let $f: H \rightarrow H$ be a pseudocontraction, i.e., $$ \left\| f(x) - f(y) \right\|^2 \leq \left\| x-y\right\|^2 + \left\| f(x) - f(y) - (x-y) \right\|^2 $$ for all $x,y \in H$. I am looking for additional assumptions on $f$ and $X$ such that the mapping $P_X(f(\cdot))$ is a pseudocontraction as well. Observations and comments: $P_X$ is firmly nonexpansive , i.e.,  $$ \left\| P_X(x) - P_X(y) \right\|^2 \leq \langle x-y, P_X(x) - P_X(y) \rangle $$ $f$ is a pseudocontraction if and only if $x \mapsto x - f(x)$ is accretive. A map $g: H \rightarrow H$ is accretive if $ \langle g(x) - g(y), z \rangle \geq 0$ for all $x,y \in H$, $z \in J(x-y)$, where $J$ is the normalized duality mapping, i.e., $J(x) = \{ z \in X^* \mid \left\| z \right\|^2 = \left\| x \right\|^2 = \langle x, z \rangle \}$. $f$ is a pseudocontraction if and only if $$ \langle f(x) - f(y), x-y \rangle \leq \left\| x-y\right\|^2 $$ for all $x,y \in H$. $f$ is a pseudocontraction if and only if $I - f$ is monotone ; $g: H \rightarrow H$ is monotone if $\langle g(x) - g(y), x-y\rangle \geq 0$ for all $x,y \in H$. The composition of a firmly nonexpansive mapping with a pseudocontraction is not always a pseudocontraction.",,"['functional-analysis', 'operator-theory', 'convex-analysis', 'hilbert-spaces', 'projective-geometry']"
76,Are pseudo(micro)-local operators pseudodifferential?,Are pseudo(micro)-local operators pseudodifferential?,,"$\DeclareMathOperator{supp}{supp} \DeclareMathOperator{sing}{sing}$Let $\Omega$ be a domain with compact closure in $\mathbb R^n$. Consider a linear operator $A \colon X \to X$ satisfying one of the following conditions: $X = C^\infty_c(\mathbb R^n)$, $\forall u \in X \; \supp Au \subseteq\supp u$ (locality), $X = \mathscr E'(\mathbb R^n)$, $\forall u \in X \; \sing\supp Au \subseteq \sing\supp u$ (pseudo-locality), $X = \mathscr E'(\mathbb R^n)$, $\forall u \in X \; WF(Au) \subseteq WF(u)$ (micro-locality). The famous Peetre's theorem, 1959, states that if 1. holds then $A|_{\Omega}$ is a linear differential operator with smooth coefficients. The converse is clearly true. Now if $A$ is a proper pseudodifferential operator then 2. and 3. hold. But is the converse true? Is it true that if 2. or 3. holds then $A|_{\Omega}$ is a pseudodifferential operator?","$\DeclareMathOperator{supp}{supp} \DeclareMathOperator{sing}{sing}$Let $\Omega$ be a domain with compact closure in $\mathbb R^n$. Consider a linear operator $A \colon X \to X$ satisfying one of the following conditions: $X = C^\infty_c(\mathbb R^n)$, $\forall u \in X \; \supp Au \subseteq\supp u$ (locality), $X = \mathscr E'(\mathbb R^n)$, $\forall u \in X \; \sing\supp Au \subseteq \sing\supp u$ (pseudo-locality), $X = \mathscr E'(\mathbb R^n)$, $\forall u \in X \; WF(Au) \subseteq WF(u)$ (micro-locality). The famous Peetre's theorem, 1959, states that if 1. holds then $A|_{\Omega}$ is a linear differential operator with smooth coefficients. The converse is clearly true. Now if $A$ is a proper pseudodifferential operator then 2. and 3. hold. But is the converse true? Is it true that if 2. or 3. holds then $A|_{\Omega}$ is a pseudodifferential operator?",,"['analysis', 'functional-analysis', 'partial-differential-equations', 'microlocal-analysis', 'pseudo-differential-operators']"
77,Proper functions,Proper functions,,"I'm a bit confused with the definition of proper function, i.e.: ""$f: X \to Y$ is proper if the inverse image of every compact set in $Y$ is compact in $X$."" Can anyone provide a more intuitive definition (even if less formal)? Some simple examples of proper and non proper functions would help a lot. Edit : As additional question, is there a simple way to verify that a certain function is proper?","I'm a bit confused with the definition of proper function, i.e.: ""$f: X \to Y$ is proper if the inverse image of every compact set in $Y$ is compact in $X$."" Can anyone provide a more intuitive definition (even if less formal)? Some simple examples of proper and non proper functions would help a lot. Edit : As additional question, is there a simple way to verify that a certain function is proper?",,"['functional-analysis', 'definition']"
78,Bounded operators with closed range,Bounded operators with closed range,,Under what conditions the sum of two closed range operators have a closed range? the result is true if the ranges are orthogonal(hilbert space),Under what conditions the sum of two closed range operators have a closed range? the result is true if the ranges are orthogonal(hilbert space),,"['functional-analysis', 'operator-theory']"
79,Reproducing kernel Hilbert sapce,Reproducing kernel Hilbert sapce,,"I encountered the following claim (verbatim): Theorem Let $V$ be a subspace of $L^2(\mathbb{R})$ and $\{e_n\}$ be a orthonormal basis of $V$. The $V$ is a reproducing kernel Hilbert space with kernel $$ K(x,y) = \sum_n e_n(x)e_n(y). $$ For any function $f \in V$, $$ f(y) = \int f(x) K(x,y) dy. $$ Questions : I am under the impression that a RKHS is a Hilbert space of functions, where pointwise evaluation is a bounded functional. $L^2$ is not even a space of functions, how does the claim make sense (e.g. take an ONB for the entire $L^2$)? Also, are there no convergence requirements on the reproducing kernel $K$, or is it purely formal?","I encountered the following claim (verbatim): Theorem Let $V$ be a subspace of $L^2(\mathbb{R})$ and $\{e_n\}$ be a orthonormal basis of $V$. The $V$ is a reproducing kernel Hilbert space with kernel $$ K(x,y) = \sum_n e_n(x)e_n(y). $$ For any function $f \in V$, $$ f(y) = \int f(x) K(x,y) dy. $$ Questions : I am under the impression that a RKHS is a Hilbert space of functions, where pointwise evaluation is a bounded functional. $L^2$ is not even a space of functions, how does the claim make sense (e.g. take an ONB for the entire $L^2$)? Also, are there no convergence requirements on the reproducing kernel $K$, or is it purely formal?",,"['functional-analysis', 'reference-request', 'hilbert-spaces']"
80,Derivative of infimum in variational problem,Derivative of infimum in variational problem,,"Let $\mathcal{E}(\phi,\alpha), \phi\in \mathcal{D}$ be a functional on some domain $\mathcal{D}$ that depends on a parameter $\alpha$. In the expression $$\frac{\partial}{\partial \alpha} \inf_{\phi \in D}\{\mathcal{E}(\phi,\alpha)\},$$ is there a way to justify exchanging the derivative and the infimum? What  conditions does $\mathcal{E}$ and possibly the domain have to fulfill for that?","Let $\mathcal{E}(\phi,\alpha), \phi\in \mathcal{D}$ be a functional on some domain $\mathcal{D}$ that depends on a parameter $\alpha$. In the expression $$\frac{\partial}{\partial \alpha} \inf_{\phi \in D}\{\mathcal{E}(\phi,\alpha)\},$$ is there a way to justify exchanging the derivative and the infimum? What  conditions does $\mathcal{E}$ and possibly the domain have to fulfill for that?",,"['functional-analysis', 'calculus-of-variations']"
81,Regularity theorem for Laplacian,Regularity theorem for Laplacian,,"Let $\Omega \subset \mathbb R^d$ be a bounded domain, $d>2$. Let $f \in C^\infty(\Omega)$. If $u \in L^2$ is a distributional solution of $\Delta u = f$ in $\Omega$ then $u \in C^\infty(\Omega)$ and it is a classical solution. This can be easily proved: we can explicitly specify one of the solutions of $\Delta u = f$ of class $С^\infty$, it is $u' = K*f$, where $K$ is the Newton kernel. Next we can easily show that any solution of $\Delta u = 0$ is $C^\infty$ from what we can derive that $u = u' + (u-u') \in C^\infty$. More precisely this procedure is described in these lecture notes, p.8, thm. 2. The situation is more complicated in the case when $f \in H^k$, where $H^k$ is the Sobolev space, $k \geq 0$. In this case I expect to show that if $u$ is a distributional solution of $\Delta u = f$ then $u \in H^{k+2}$ and $\Delta u = f$ a.e. As above we represent $u = u'+(u-u')$ where $u'$ is some particular distributional solution of $\Delta u = f$. The problem is to show that we can specify such particular solution in the class $H^{k+2}$. Formally we can take convolution of distributions $K*f$, but I'm not sure that $K*f \in H^{k+2}$ since $K$ is not in $L^2$ for $d \geq 4$. Is there a way to generalize the above approach to prove regularity in this Sobolev case? P.S. I know about other ways to prove regularity, e.g. [Bers, Schechter], but I'm interested if the approach for $C^\infty$ functions is easily extendable.","Let $\Omega \subset \mathbb R^d$ be a bounded domain, $d>2$. Let $f \in C^\infty(\Omega)$. If $u \in L^2$ is a distributional solution of $\Delta u = f$ in $\Omega$ then $u \in C^\infty(\Omega)$ and it is a classical solution. This can be easily proved: we can explicitly specify one of the solutions of $\Delta u = f$ of class $С^\infty$, it is $u' = K*f$, where $K$ is the Newton kernel. Next we can easily show that any solution of $\Delta u = 0$ is $C^\infty$ from what we can derive that $u = u' + (u-u') \in C^\infty$. More precisely this procedure is described in these lecture notes, p.8, thm. 2. The situation is more complicated in the case when $f \in H^k$, where $H^k$ is the Sobolev space, $k \geq 0$. In this case I expect to show that if $u$ is a distributional solution of $\Delta u = f$ then $u \in H^{k+2}$ and $\Delta u = f$ a.e. As above we represent $u = u'+(u-u')$ where $u'$ is some particular distributional solution of $\Delta u = f$. The problem is to show that we can specify such particular solution in the class $H^{k+2}$. Formally we can take convolution of distributions $K*f$, but I'm not sure that $K*f \in H^{k+2}$ since $K$ is not in $L^2$ for $d \geq 4$. Is there a way to generalize the above approach to prove regularity in this Sobolev case? P.S. I know about other ways to prove regularity, e.g. [Bers, Schechter], but I'm interested if the approach for $C^\infty$ functions is easily extendable.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'distribution-theory']"
82,"In a separable Hilbert space, can you write an operator from $\mathcal H$ to $\mathcal H$ as a column-finite matrix?","In a separable Hilbert space, can you write an operator from  to  as a column-finite matrix?",\mathcal H \mathcal H,"In this question, we are representing an operator $T$ as a matrix with respect to an orthonormal basis $\left\{e_n : n \in \mathbb{N}\right\}$. To do so, we let $t_{ij} = \langle T(e_j),e_i\rangle$. The question is asking us to show that the orthonormal basis can be chosen such that the number of non-zero entries in each column is finite. So this basically amounts to finding an orthonormal basis such that $\langle T(e_j),e_i\rangle$ is $0$ for all but finitely many elements of the basis. I'm not entirely sure how to begin for this question. My approach was to first find such a basis for $l^2(\mathbb{N})$ and then maybe use the isomorphism between $\mathcal H$ and $l^2(\mathbb{N})$, but I wasn't even able to get that far.","In this question, we are representing an operator $T$ as a matrix with respect to an orthonormal basis $\left\{e_n : n \in \mathbb{N}\right\}$. To do so, we let $t_{ij} = \langle T(e_j),e_i\rangle$. The question is asking us to show that the orthonormal basis can be chosen such that the number of non-zero entries in each column is finite. So this basically amounts to finding an orthonormal basis such that $\langle T(e_j),e_i\rangle$ is $0$ for all but finitely many elements of the basis. I'm not entirely sure how to begin for this question. My approach was to first find such a basis for $l^2(\mathbb{N})$ and then maybe use the isomorphism between $\mathcal H$ and $l^2(\mathbb{N})$, but I wasn't even able to get that far.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
83,Dyadic approach to Marcinkiewicz interpolation for Lorentz Spaces,Dyadic approach to Marcinkiewicz interpolation for Lorentz Spaces,,"In Exercise 21 , in a note for professor Terrence Tao on his own blog http://terrytao.wordpress.com/2009/03/30/245c-notes-1-interpolation-of-lp-spaces/ Exercise 21 Suppose we are in the situation of the Marcinkiewicz interpolation theorem, with the hypotheses $p_0\le q_0$, $p_1\le q_1$ replaced by $p_0\ne p_1$. Show that for all $0\lt\theta\lt1$, and $1\leq r \leq \infty$ there exits a $B\gt0$ such that   $$ \|Tf\|_{L^{\large q_\theta,r}(Y)} \leq B \|f\|_{L^{\large p_\theta , r }(X)} $$   for all simple functions $f$ of finite measure support, where the Lorentz norms $L^{p,q}$ were defined in Exercise 7. (Hint: repeat the proof of the Marcinkiewicz interpolation theorem, but partition the sum $\sum_{n,m}$ into regions of the form $\{n\alpha q_\theta-mp_\theta=k+O(1)\}$ for integer $k$. Obtain a bound for each summand which decreases geometrically as $k\to\pm\infty$.) Conclude that the hypotheses $p_0\le q_0$, $p_1\le q_1$ in the Marcinkiewicz interpolation theorem can be replaced by $p_\theta\le q_\theta$. This Lorentz space version of the interpolation theorem is in some sense the “right” version of the theorem, but the Lorentz spaces are slightly more technical to deal with than the Lebesgue spaces, and the Lebesgue space version of Marcinkiewicz interpolation is largely sufficient for most applications. I can see how to approach it using duality between $L^{q,r}$ and $L^{q',r'}$ in case that $q_{\theta} > 1$ , but I want to know also how to approach it using tao approach sketched in a comment in the same note where he introduced a frequency envelope.The following is the comment ( I suggest reading his proof of marinkiewicz ) ah, yes, this is a little delicate, in part because the decomposition of f used here is actually not the optimal one for this problem – it decomposes the height  of the function dyadically (vertical dyadic decomposition), when in fact it is the width  that ought to be dyadically decomposed (horizontal dyadic decomposition). One can still recover from this point by decomposing the sequence  into dyadic pieces, but this is quite messy.Another approach is to use frequency envelopes. Pick a small $\epsilon$ and replace $a_ m $ by the slightly larger envelope $ b_m : = \sup_{m'} 2^{\epsilon |m-m'|} a_{m'}$ ' The point of doing so is that the $b_m $ obey a Lipschitz property $2^{-\epsilon |m-m'|} b_{m'} \leq b_m \leq 2^{\epsilon |m-m'|} b_{m'} $ but are still summable in $l^1$ . One then chooses $c_{n,m}$  to be adapted to the crossover point between the two quantities in the $\min $ (modifying the $n \alpha q_{\theta} - m p_{\theta} $  term by some multiple of $\log b_m$ ); as long as the Lipschitz parameter $\epsilon$  is small enough, one will still be able to close the argument I only want to see how frequency envelopes work . Thanks","In Exercise 21 , in a note for professor Terrence Tao on his own blog http://terrytao.wordpress.com/2009/03/30/245c-notes-1-interpolation-of-lp-spaces/ Exercise 21 Suppose we are in the situation of the Marcinkiewicz interpolation theorem, with the hypotheses $p_0\le q_0$, $p_1\le q_1$ replaced by $p_0\ne p_1$. Show that for all $0\lt\theta\lt1$, and $1\leq r \leq \infty$ there exits a $B\gt0$ such that   $$ \|Tf\|_{L^{\large q_\theta,r}(Y)} \leq B \|f\|_{L^{\large p_\theta , r }(X)} $$   for all simple functions $f$ of finite measure support, where the Lorentz norms $L^{p,q}$ were defined in Exercise 7. (Hint: repeat the proof of the Marcinkiewicz interpolation theorem, but partition the sum $\sum_{n,m}$ into regions of the form $\{n\alpha q_\theta-mp_\theta=k+O(1)\}$ for integer $k$. Obtain a bound for each summand which decreases geometrically as $k\to\pm\infty$.) Conclude that the hypotheses $p_0\le q_0$, $p_1\le q_1$ in the Marcinkiewicz interpolation theorem can be replaced by $p_\theta\le q_\theta$. This Lorentz space version of the interpolation theorem is in some sense the “right” version of the theorem, but the Lorentz spaces are slightly more technical to deal with than the Lebesgue spaces, and the Lebesgue space version of Marcinkiewicz interpolation is largely sufficient for most applications. I can see how to approach it using duality between $L^{q,r}$ and $L^{q',r'}$ in case that $q_{\theta} > 1$ , but I want to know also how to approach it using tao approach sketched in a comment in the same note where he introduced a frequency envelope.The following is the comment ( I suggest reading his proof of marinkiewicz ) ah, yes, this is a little delicate, in part because the decomposition of f used here is actually not the optimal one for this problem – it decomposes the height  of the function dyadically (vertical dyadic decomposition), when in fact it is the width  that ought to be dyadically decomposed (horizontal dyadic decomposition). One can still recover from this point by decomposing the sequence  into dyadic pieces, but this is quite messy.Another approach is to use frequency envelopes. Pick a small $\epsilon$ and replace $a_ m $ by the slightly larger envelope $ b_m : = \sup_{m'} 2^{\epsilon |m-m'|} a_{m'}$ ' The point of doing so is that the $b_m $ obey a Lipschitz property $2^{-\epsilon |m-m'|} b_{m'} \leq b_m \leq 2^{\epsilon |m-m'|} b_{m'} $ but are still summable in $l^1$ . One then chooses $c_{n,m}$  to be adapted to the crossover point between the two quantities in the $\min $ (modifying the $n \alpha q_{\theta} - m p_{\theta} $  term by some multiple of $\log b_m$ ); as long as the Lipschitz parameter $\epsilon$  is small enough, one will still be able to close the argument I only want to see how frequency envelopes work . Thanks",,"['real-analysis', 'analysis', 'functional-analysis', 'operator-theory']"
84,proof for a basis in $L^2$,proof for a basis in,L^2,"I know, correct me if I am wrong, that the functions $H_n(x)\exp(-x^2/2)$ form a complete basis in $L^2(\mathbb{R},dx)$, where $H_n(x)$ is the $n$th Hermite polynomial. This must be true also for $x^n\exp(-x^2/2)$ with $n\in\mathbb{N}_0$. Does someone know a proof of the latter or can give me a reference? Since I am not a mathematician, I will really appreciate it if the proof contains all the details that might puzzle a non-mathematician. I also have the problem to choose functions $f_k$ such that \begin{equation} \int_{-\infty}^{+\infty}f_k(x)x^n\exp(-x^2)dx = \delta_{kn} \mbox{.} \end{equation} Does anyone know a method to construct the $f_k$s?","I know, correct me if I am wrong, that the functions $H_n(x)\exp(-x^2/2)$ form a complete basis in $L^2(\mathbb{R},dx)$, where $H_n(x)$ is the $n$th Hermite polynomial. This must be true also for $x^n\exp(-x^2/2)$ with $n\in\mathbb{N}_0$. Does someone know a proof of the latter or can give me a reference? Since I am not a mathematician, I will really appreciate it if the proof contains all the details that might puzzle a non-mathematician. I also have the problem to choose functions $f_k$ such that \begin{equation} \int_{-\infty}^{+\infty}f_k(x)x^n\exp(-x^2)dx = \delta_{kn} \mbox{.} \end{equation} Does anyone know a method to construct the $f_k$s?",,"['functional-analysis', 'hilbert-spaces']"
85,"For $A$ self-adjoint, $\sup_{|x|=1}\langle Ax,x\rangle = \max \sigma(A)$","For  self-adjoint,","A \sup_{|x|=1}\langle Ax,x\rangle = \max \sigma(A)","For a self-adjoint operator $A$ on a Hilbert space $H$, one has $\sup_{|x|=1}\langle Ax,x \rangle = \max\sigma(A)$. I want to prove this using the spectral theorem. My idea is: Let $a = \max\sigma(A)$. Choose for $n \in \mathbb{N}$ a unit-length vector $x_n \in \mathbb{E}((a-\frac{1}{n}, a])H$, where $\mathbb{E}$ is the spectral measure.  Then $\langle Ax_n,x_n\rangle$ should converge to $\max\sigma(A)$. More precisely, $\int_{\sigma(A)}\lambda d\mu_{x_n,x_n} = \int_{\sigma(A)}\lambda d\langle\mathbb{E}_\lambda x_n,x_n\rangle$. If $\lambda \in [c,d]$ with $[c,d] \cap (a-\frac{1}{n}, a] = \emptyset$, then $\mathbb{E}_\lambda x_n = \mathbb{E}_\lambda \mathbb{E}((a-\frac{1}{n}, a])x_n = 0$. It follows from this that $\int_{\sigma(A)}\lambda d\langle\mathbb{E}_\lambda x_n,x_n\rangle = \int_{\sigma(A) \cap (a-\frac{1}{n}, a]}\lambda d\langle\mathbb{E}_\lambda x_n,x_n\rangle$ Why does the last integral converge to $a$? One should show that $\langle\mathbb{E}_\lambda x_n,x_n\rangle$ converges to $1$? Can someone help me?","For a self-adjoint operator $A$ on a Hilbert space $H$, one has $\sup_{|x|=1}\langle Ax,x \rangle = \max\sigma(A)$. I want to prove this using the spectral theorem. My idea is: Let $a = \max\sigma(A)$. Choose for $n \in \mathbb{N}$ a unit-length vector $x_n \in \mathbb{E}((a-\frac{1}{n}, a])H$, where $\mathbb{E}$ is the spectral measure.  Then $\langle Ax_n,x_n\rangle$ should converge to $\max\sigma(A)$. More precisely, $\int_{\sigma(A)}\lambda d\mu_{x_n,x_n} = \int_{\sigma(A)}\lambda d\langle\mathbb{E}_\lambda x_n,x_n\rangle$. If $\lambda \in [c,d]$ with $[c,d] \cap (a-\frac{1}{n}, a] = \emptyset$, then $\mathbb{E}_\lambda x_n = \mathbb{E}_\lambda \mathbb{E}((a-\frac{1}{n}, a])x_n = 0$. It follows from this that $\int_{\sigma(A)}\lambda d\langle\mathbb{E}_\lambda x_n,x_n\rangle = \int_{\sigma(A) \cap (a-\frac{1}{n}, a]}\lambda d\langle\mathbb{E}_\lambda x_n,x_n\rangle$ Why does the last integral converge to $a$? One should show that $\langle\mathbb{E}_\lambda x_n,x_n\rangle$ converges to $1$? Can someone help me?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
86,Measurable structure on the space of probability measures,Measurable structure on the space of probability measures,,"My advisor only half-jokingly mentioned that sometimes people like to consider the measurable structure on $P(X)$ where X is a locally compact polish space and $P(.)$ denotes the probability measures with the topology of distributional convergence. (Which is the same as a weak * topology as seen through Riesz Representation.)  People then consider $P^n(X)$. I have also seen other sources defining the measurable structure on $P(X)$ not by referring to the topology and saying it's borel, but rather choosing the smallest $\sigma$ field so that all of the maps $\theta \mapsto \theta(A)$ as $A$ varies over the Borel subsets of $X$ are measurable.  My question is why this is equivalent to the description where you take the $\sigma$ field to be the Borel of the weak* topology, i.e. the topology with the notion of convergence $\theta_n \rightarrow \theta$ if and only if $\forall f$ bounded continuous on $X$ we have $\int f d\theta_n \rightarrow \int f d\theta$. (I am talking about this as if it's a weak * topology and using Riesz representation because this notion is equivalent to requiring it only for those $f$ which are vanishing at infinity.) If it is not true for $X$ as general as I've stated, then please explain why it is true for $\mathbb{R}=X$, if it is. Progress so far: Seeing that the borel description makes the family of maps $\theta \mapsto \theta(A)$ measurable, hence the borel description contains the other one.  This was done by seeing that $A$ can actually just range over open sets, and then approximating the indicator of open sets pointwise by continuous functions.  Also, I know that $P(X)$ is a compact metric space. EDIT: I should take back that I see that $P(X)$ is a compact metric space.  It is not one in general.  If X is as I said, then is it at least locally compact Polish?  Banach Aoglu gives the metric.  Not sure how to get the other 3 required properties.","My advisor only half-jokingly mentioned that sometimes people like to consider the measurable structure on $P(X)$ where X is a locally compact polish space and $P(.)$ denotes the probability measures with the topology of distributional convergence. (Which is the same as a weak * topology as seen through Riesz Representation.)  People then consider $P^n(X)$. I have also seen other sources defining the measurable structure on $P(X)$ not by referring to the topology and saying it's borel, but rather choosing the smallest $\sigma$ field so that all of the maps $\theta \mapsto \theta(A)$ as $A$ varies over the Borel subsets of $X$ are measurable.  My question is why this is equivalent to the description where you take the $\sigma$ field to be the Borel of the weak* topology, i.e. the topology with the notion of convergence $\theta_n \rightarrow \theta$ if and only if $\forall f$ bounded continuous on $X$ we have $\int f d\theta_n \rightarrow \int f d\theta$. (I am talking about this as if it's a weak * topology and using Riesz representation because this notion is equivalent to requiring it only for those $f$ which are vanishing at infinity.) If it is not true for $X$ as general as I've stated, then please explain why it is true for $\mathbb{R}=X$, if it is. Progress so far: Seeing that the borel description makes the family of maps $\theta \mapsto \theta(A)$ measurable, hence the borel description contains the other one.  This was done by seeing that $A$ can actually just range over open sets, and then approximating the indicator of open sets pointwise by continuous functions.  Also, I know that $P(X)$ is a compact metric space. EDIT: I should take back that I see that $P(X)$ is a compact metric space.  It is not one in general.  If X is as I said, then is it at least locally compact Polish?  Banach Aoglu gives the metric.  Not sure how to get the other 3 required properties.",,"['real-analysis', 'analysis', 'functional-analysis', 'measure-theory', 'probability-theory']"
87,Masas in quotients,Masas in quotients,,"Let $A$ be a von Neumann algebra and let $B$ be a norm-closed ideal of $A$ (but not necessarily WOT-closed). What one has to assume about $A$ and $B$ to ensure that if $M\subset A$ is a maximal abelian subalgebra, then $M / (B\cap M)$ is a maximal algebian subalgebra of $A/B$? This is the case for $A=B(H)$ and $B=K(H)$.","Let $A$ be a von Neumann algebra and let $B$ be a norm-closed ideal of $A$ (but not necessarily WOT-closed). What one has to assume about $A$ and $B$ to ensure that if $M\subset A$ is a maximal abelian subalgebra, then $M / (B\cap M)$ is a maximal algebian subalgebra of $A/B$? This is the case for $A=B(H)$ and $B=K(H)$.",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
88,"What is $H^1([0,1]) \otimes H^1([0,1])$?",What is ?,"H^1([0,1]) \otimes H^1([0,1])","Let $H^1([0,1])$ denote the Sobolev space $H^1$ on the interval $[0,1]$. What is $H^1([0,1]) \otimes H^1([0,1])$? Here, $\otimes$ the tensor product of Hilbert spaces. In particular, how is that object related to $H^1([0,1]^2)$?","Let $H^1([0,1])$ denote the Sobolev space $H^1$ on the interval $[0,1]$. What is $H^1([0,1]) \otimes H^1([0,1])$? Here, $\otimes$ the tensor product of Hilbert spaces. In particular, how is that object related to $H^1([0,1]^2)$?",,"['functional-analysis', 'hilbert-spaces', 'sobolev-spaces', 'tensor-products']"
89,Invertibility of elements in a Banach algebra,Invertibility of elements in a Banach algebra,,"Let $X=L^1\cap L^2$, and $\hat{X}$ be the Banach algebra of the image under Fourier transform of $X$. Then do the unital extension $1\dot{+}\hat{X}$ of $X$ by adding a constant function with the norm given by: $$ |c+\hat{f}|_{1\dot{+}\hat{X}}=|c|+|\hat{f}|_{\hat{X}} $$ Now my question is: for an element $f=\alpha+\hat{h}$ in $1\dot{+}\hat{X}$, what is the necessary and sufficient condition for $f$ to be invertible? I was informed that this may have something to do with the Wiener theorem, which is probably the one dealing with the invertibility of an element of the Wiener algebra consisting of functions with absolutely convergent Fourier coefficients, but I didn't see how it works. So can someone help me with this problem? Thank you!","Let $X=L^1\cap L^2$, and $\hat{X}$ be the Banach algebra of the image under Fourier transform of $X$. Then do the unital extension $1\dot{+}\hat{X}$ of $X$ by adding a constant function with the norm given by: $$ |c+\hat{f}|_{1\dot{+}\hat{X}}=|c|+|\hat{f}|_{\hat{X}} $$ Now my question is: for an element $f=\alpha+\hat{h}$ in $1\dot{+}\hat{X}$, what is the necessary and sufficient condition for $f$ to be invertible? I was informed that this may have something to do with the Wiener theorem, which is probably the one dealing with the invertibility of an element of the Wiener algebra consisting of functions with absolutely convergent Fourier coefficients, but I didn't see how it works. So can someone help me with this problem? Thank you!",,"['functional-analysis', 'banach-algebras']"
90,Don't understand this proof of equivalence of weak solutions to PDE,Don't understand this proof of equivalence of weak solutions to PDE,,"I'm trying to understand the proof that (c) implies (a) here in the following proposition (here, $\mathcal{V} = L^2(0,T;V)$). See the very last line in the image for that part: $$$$ $$$$ I give here Proposition 1.1 which the proof uses.  $$$$ I do not understand how it's used in the proof. I'd appreciate an explanation. Thank you. Here, $$W_2(0,T) = \{u \in \mathcal V : u' \in \mathcal V'\}$$ and (All images cut from Showalter's book Monotone Operators in Banach Space )","I'm trying to understand the proof that (c) implies (a) here in the following proposition (here, $\mathcal{V} = L^2(0,T;V)$). See the very last line in the image for that part: $$$$ $$$$ I give here Proposition 1.1 which the proof uses.  $$$$ I do not understand how it's used in the proof. I'd appreciate an explanation. Thank you. Here, $$W_2(0,T) = \{u \in \mathcal V : u' \in \mathcal V'\}$$ and (All images cut from Showalter's book Monotone Operators in Banach Space )",,"['functional-analysis', 'measure-theory', 'banach-spaces', 'hilbert-spaces']"
91,Operator completly continuous,Operator completly continuous,,"For $\lambda>0$, let $v(t)=\lambda \phi(t)$. Consider the BVP   consisting of the equation $$u'''=\lambda[f(t,[u-v]^*+\gamma)+M(t)] ,t\in (0,1)$$ and (BC):$u(0)=u'(p)=\int_q^1 w(s)u''(s)=0 , (\frac12<p<q<1)$ $[u-v]^* = u-v ~~\text{if}~~ u-v\geq 0 ~~\text{or}~~ [u-v]^*=0 ~~\text{if}~~ u-v<0 $ $G(t,s)$ is the Green function ,$ G(t,s)\leq a(t) b(s)$ $w(t)$ is nondecreasing and $w(t)>0$ on $(q,1]$ $e:[0,1]\rightarrow \mathbb{R}$ continuous and $e \in L(0,1)$ $\gamma(t)=\int_0^1 G(t,s) e(s) ds , \gamma(t)>0  \,\text{on} \,[0,1]$ $ M \in L(0,1)$ such that $M(t)>0$ on $(0,1)$ and $f(t,x+\gamma(t))\geq -M(t)$ fot $(t,x)\in (0,1)\times [0,\infty)$ There exist $r>0$ and $g\in L(0,1)$ such that $$f(t,x+\gamma(t))+M(t) \leq g(t)\,\text{for}(t,x)\in [0,1]\times[0,r]$$ $\phi(t)=\int_0^1 G(t,s) M(s) ds$ How to prove that  the operator  $T:K\rightarrow C[0,1]$ such that $K=\lbrace u\in C[0,1], u(t)\geq a(t)\,||u|| \text{on} [0,1] \rbrace  \subset C[0,1]$ $$Tu(t)=\lambda \int_0^1 G(t,s)[f(s,[u(s)-v(s)]^*+\gamma(s))+M(s) ds$$ is completely   continuous 1)to prove that $T$ is continuous : We take $(u_n)_n\in K$ which converge uniformally to $u$ in $K$ , and i must prove that $(Tu_n)$ converge uniformally to $(Tu)$ $|Tu_n(t)-Tu(t)|\leq\lambda \int_0^1 G(t,s)|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))| ds$ $ \leq \lambda ||a|| ||b||\int_0^1|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))| ds$ and then $\max_{t\in [0,1]} |T u_n(t)-Tu(t)| \leq $ $\lambda ||a|| ||b|| \int_0^1|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))| $ for all  $s \in [0,1],|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))|\rightarrow 0 $ and $|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))|\leq $ $ \displaystyle 2\max_{(s,x)\in [0,1]\times [0,||u||]} |f(s,x+\gamma(s))|$ fro Lebesgue we have $||T u_n-T u|| \rightarrow 0$,  hence the continuity. $x\in[0,||u||], ~~~\text{because}~~~ 0\leq [u(t)-v(t)]^*\leq u(t)\leq ||u||$ it's true ? 2) for the equicontinuity: Let $t_1,t_2\in [0,1] $ and $u\in K$ then $|Tu(t_1)-Tu(t_2)|\leq \lambda \int_0^1 |G(t_1,s)-G(t_2,s)|[f(s,[u(s)-v(s)]^*+\gamma(s))+ M(s)] ds $ $\leq \lambda \displaystyle \max_{[0,1]\times [0,||u||]}|f(s,x+\gamma(s))|+||M|| \int_0^1 |G(t_1,s)-G(t_2,s)| ds$ Let $\varepsilon >0$ , $G$ is the Green's function so it is uniformally contiuous , $\exists \delta>0$: $\forall t_1,t_2 \in [0,1], \forall s \in [0,1], |t_1-t_2|<\delta \Rightarrow |G(t_1,s)-G(t_2,s)|\leq \varepsilon$ so $TK $ is equicontinuous . it is true ? Please ; help me Thank you . (Article: Positive solutions of third semiposone boundary value problems, proof of theorem 2.1 )","For $\lambda>0$, let $v(t)=\lambda \phi(t)$. Consider the BVP   consisting of the equation $$u'''=\lambda[f(t,[u-v]^*+\gamma)+M(t)] ,t\in (0,1)$$ and (BC):$u(0)=u'(p)=\int_q^1 w(s)u''(s)=0 , (\frac12<p<q<1)$ $[u-v]^* = u-v ~~\text{if}~~ u-v\geq 0 ~~\text{or}~~ [u-v]^*=0 ~~\text{if}~~ u-v<0 $ $G(t,s)$ is the Green function ,$ G(t,s)\leq a(t) b(s)$ $w(t)$ is nondecreasing and $w(t)>0$ on $(q,1]$ $e:[0,1]\rightarrow \mathbb{R}$ continuous and $e \in L(0,1)$ $\gamma(t)=\int_0^1 G(t,s) e(s) ds , \gamma(t)>0  \,\text{on} \,[0,1]$ $ M \in L(0,1)$ such that $M(t)>0$ on $(0,1)$ and $f(t,x+\gamma(t))\geq -M(t)$ fot $(t,x)\in (0,1)\times [0,\infty)$ There exist $r>0$ and $g\in L(0,1)$ such that $$f(t,x+\gamma(t))+M(t) \leq g(t)\,\text{for}(t,x)\in [0,1]\times[0,r]$$ $\phi(t)=\int_0^1 G(t,s) M(s) ds$ How to prove that  the operator  $T:K\rightarrow C[0,1]$ such that $K=\lbrace u\in C[0,1], u(t)\geq a(t)\,||u|| \text{on} [0,1] \rbrace  \subset C[0,1]$ $$Tu(t)=\lambda \int_0^1 G(t,s)[f(s,[u(s)-v(s)]^*+\gamma(s))+M(s) ds$$ is completely   continuous 1)to prove that $T$ is continuous : We take $(u_n)_n\in K$ which converge uniformally to $u$ in $K$ , and i must prove that $(Tu_n)$ converge uniformally to $(Tu)$ $|Tu_n(t)-Tu(t)|\leq\lambda \int_0^1 G(t,s)|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))| ds$ $ \leq \lambda ||a|| ||b||\int_0^1|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))| ds$ and then $\max_{t\in [0,1]} |T u_n(t)-Tu(t)| \leq $ $\lambda ||a|| ||b|| \int_0^1|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))| $ for all  $s \in [0,1],|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))|\rightarrow 0 $ and $|f(s,[u_n(s)-v(s)]^*+\gamma(s))-f(s,[u(s)-v(s)]^*+\gamma(s))|\leq $ $ \displaystyle 2\max_{(s,x)\in [0,1]\times [0,||u||]} |f(s,x+\gamma(s))|$ fro Lebesgue we have $||T u_n-T u|| \rightarrow 0$,  hence the continuity. $x\in[0,||u||], ~~~\text{because}~~~ 0\leq [u(t)-v(t)]^*\leq u(t)\leq ||u||$ it's true ? 2) for the equicontinuity: Let $t_1,t_2\in [0,1] $ and $u\in K$ then $|Tu(t_1)-Tu(t_2)|\leq \lambda \int_0^1 |G(t_1,s)-G(t_2,s)|[f(s,[u(s)-v(s)]^*+\gamma(s))+ M(s)] ds $ $\leq \lambda \displaystyle \max_{[0,1]\times [0,||u||]}|f(s,x+\gamma(s))|+||M|| \int_0^1 |G(t_1,s)-G(t_2,s)| ds$ Let $\varepsilon >0$ , $G$ is the Green's function so it is uniformally contiuous , $\exists \delta>0$: $\forall t_1,t_2 \in [0,1], \forall s \in [0,1], |t_1-t_2|<\delta \Rightarrow |G(t_1,s)-G(t_2,s)|\leq \varepsilon$ so $TK $ is equicontinuous . it is true ? Please ; help me Thank you . (Article: Positive solutions of third semiposone boundary value problems, proof of theorem 2.1 )",,"['analysis', 'functional-analysis', 'measure-theory', 'partial-differential-equations']"
92,Solution to $\Delta_g u = \delta-1$ on a 2-sphere.,Solution to  on a 2-sphere.,\Delta_g u = \delta-1,"Let $S^2$ be the two-sphere, endowed with a Riemannian metric $g$, such that the volume of the sphere w.r.t. this metric is $4\pi$. Let $a \in S^2$. I am looking for an easy way to prove that the equation $$ \Delta_g u = 4 \pi \delta_a -1 $$ has a solution $u \in W^{1,p}$, $p \in (1,2)$. This is an attempt I made: the weak formulation of this equation is $$ -\int_{S^2} (\nabla \phi, \nabla u)_g d\mu_g = 4 \pi\phi(a) -\int_{S^2} \phi d\mu_g , $$ where integration is performed with respect to the measure induced by $g$, and $(\cdot, \cdot)_g$ is the inner product w.r.t. $g$. We notice that the RHS of the previous equation is an element of $(W^{1,p})'$, for $p > 2$, by Sobolev embedding. I would then like to use some kind of  representation of $(W^{1,p})'$ to conclude that this functional can be represented as $$ \int_{S^2} (\nabla \phi, \nabla u)_g d\mu_g $$ for some $u$. Are there any ways to conclude? I guess this is pretty standard stuff, I would be very grateful if anyone could provide me a reference.","Let $S^2$ be the two-sphere, endowed with a Riemannian metric $g$, such that the volume of the sphere w.r.t. this metric is $4\pi$. Let $a \in S^2$. I am looking for an easy way to prove that the equation $$ \Delta_g u = 4 \pi \delta_a -1 $$ has a solution $u \in W^{1,p}$, $p \in (1,2)$. This is an attempt I made: the weak formulation of this equation is $$ -\int_{S^2} (\nabla \phi, \nabla u)_g d\mu_g = 4 \pi\phi(a) -\int_{S^2} \phi d\mu_g , $$ where integration is performed with respect to the measure induced by $g$, and $(\cdot, \cdot)_g$ is the inner product w.r.t. $g$. We notice that the RHS of the previous equation is an element of $(W^{1,p})'$, for $p > 2$, by Sobolev embedding. I would then like to use some kind of  representation of $(W^{1,p})'$ to conclude that this functional can be represented as $$ \int_{S^2} (\nabla \phi, \nabla u)_g d\mu_g $$ for some $u$. Are there any ways to conclude? I guess this is pretty standard stuff, I would be very grateful if anyone could provide me a reference.",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'riemannian-geometry']"
93,Problem of Scottish Book,Problem of Scottish Book,,"Does anyone know if the problem 50 to Banach written in The Scottish Book is resolved? The problem is: Prove that the integral of denjoy is a Baire functional in the space M ( that is to say, in the space of measurable functions) Thanks","Does anyone know if the problem 50 to Banach written in The Scottish Book is resolved? The problem is: Prove that the integral of denjoy is a Baire functional in the space M ( that is to say, in the space of measurable functions) Thanks",,"['functional-analysis', 'reference-request']"
94,Interpretation for the Functional Determinant,Interpretation for the Functional Determinant,,"Let $S:V \rightarrow V$ be a linear operator on the function space $V$. It is possible to define a functional determinant for $S$ via the zeta function regularization process. In specific we define first the associated $\zeta$-function $\zeta_S(z):=\text{Tr}(S^{-z})$ for $\Re(z)>>0$, then we extend $\zeta_S(z)$ by analytic continuation, and finally we define the functional determinant by $\det(S):=\text{exp}(-\zeta_s'(0))$. The details of the definition are rather clear, but I'm puzzled about the meaning of the construction. Question What does the functional determinant tell us about the operator $S$? To be more specific, what can we say about $S$ if $\det(S)=0$?","Let $S:V \rightarrow V$ be a linear operator on the function space $V$. It is possible to define a functional determinant for $S$ via the zeta function regularization process. In specific we define first the associated $\zeta$-function $\zeta_S(z):=\text{Tr}(S^{-z})$ for $\Re(z)>>0$, then we extend $\zeta_S(z)$ by analytic continuation, and finally we define the functional determinant by $\det(S):=\text{exp}(-\zeta_s'(0))$. The details of the definition are rather clear, but I'm puzzled about the meaning of the construction. Question What does the functional determinant tell us about the operator $S$? To be more specific, what can we say about $S$ if $\det(S)=0$?",,['functional-analysis']
95,What is visualization of gradient flow of a functional?,What is visualization of gradient flow of a functional?,,"I don't work on functional analysis but during my study, I faced gradient of a functional. I read its definition, but I can not understand why it is a useful tool? Why if a flow can be written as a gradient flow, we would be happy?! I know the answer about the gradient of a function, but have no idea about the gradient of a functional! Can anyone help me? Thanks for your attention!","I don't work on functional analysis but during my study, I faced gradient of a functional. I read its definition, but I can not understand why it is a useful tool? Why if a flow can be written as a gradient flow, we would be happy?! I know the answer about the gradient of a function, but have no idea about the gradient of a functional! Can anyone help me? Thanks for your attention!",,"['functional-analysis', 'differential-geometry', 'partial-differential-equations', 'gradient-flows']"
96,Topics of advanced functional analysis,Topics of advanced functional analysis,,"I did a course in introductory functional analysis and liked it. Now I want to learn more functional analysis with the goal of maybe eventually doing research (phd). I tried to find out what (advanced) functional analysis is about here but the list isn't so helpful. From it I gather among other things I want to learn about spectral theory and operator theory but items like ""Banach–Mazur theorem"" and so on doesn't seem to be a ""topic"". Where can I look to get an overview of topics in functional analysis? I want to use the information you can give me to pick a few topics and then books about them to prepare myself. Thank you.","I did a course in introductory functional analysis and liked it. Now I want to learn more functional analysis with the goal of maybe eventually doing research (phd). I tried to find out what (advanced) functional analysis is about here but the list isn't so helpful. From it I gather among other things I want to learn about spectral theory and operator theory but items like ""Banach–Mazur theorem"" and so on doesn't seem to be a ""topic"". Where can I look to get an overview of topics in functional analysis? I want to use the information you can give me to pick a few topics and then books about them to prepare myself. Thank you.",,['functional-analysis']
97,Inverse of Identity plus Volterra operator,Inverse of Identity plus Volterra operator,,"consider the following operator or $L_2(0,1)$, $(Pw)(x)=w(x)+\int_0^x K(x,y)w(y)dy+\int_x^1 K(y,x)w(y)dy$, where the integral kernel is a polynomial. I am trying to construct the inverse of this operator, I can construct inverses of the operators where the integral kernel is just a function of $y$, but I don't know how to proceed for the operator $P$. Note that the operator $P$ is self-adjoint. Any help would be most helpful, thanks.","consider the following operator or $L_2(0,1)$, $(Pw)(x)=w(x)+\int_0^x K(x,y)w(y)dy+\int_x^1 K(y,x)w(y)dy$, where the integral kernel is a polynomial. I am trying to construct the inverse of this operator, I can construct inverses of the operators where the integral kernel is just a function of $y$, but I don't know how to proceed for the operator $P$. Note that the operator $P$ is self-adjoint. Any help would be most helpful, thanks.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
98,Show that the linear operator $(Tf)(x)=\frac{1}{\pi} \int_0^{\infty} \frac{f(y)}{(x+y)} dy$ satisfies $\|T\|\leq 1$.,Show that the linear operator  satisfies .,(Tf)(x)=\frac{1}{\pi} \int_0^{\infty} \frac{f(y)}{(x+y)} dy \|T\|\leq 1,"Show that the linear operator $T$ given by $(Tf)(x) = \frac{1}{\pi} \int_0^{\infty} \frac{f(y)}{(x+y)} dy$ is bounded on $L^2(0, \infty)$ with norm $||T|| \leq 1$. The professor also wrote, $``$In fact, you should observe that $||T|| = 1$, where $$||T|| = \sup\limits_{f\neq 0}\frac{||Tf||_2}{||f||_2}.""$$","Show that the linear operator $T$ given by $(Tf)(x) = \frac{1}{\pi} \int_0^{\infty} \frac{f(y)}{(x+y)} dy$ is bounded on $L^2(0, \infty)$ with norm $||T|| \leq 1$. The professor also wrote, $``$In fact, you should observe that $||T|| = 1$, where $$||T|| = \sup\limits_{f\neq 0}\frac{||Tf||_2}{||f||_2}.""$$",,"['real-analysis', 'analysis']"
99,"Is this function in the Sobolev space $H^{2,-s}(\mathbb{R}^3)$?",Is this function in the Sobolev space ?,"H^{2,-s}(\mathbb{R}^3)","I have the function $$f(x)=\frac{e^{iz|x-y|}}{4\pi|x-y|}$$ with $y\in\mathbb{R}^3$ and $\Im z>0$. Let $s>\frac{1}{2}$. Clearly it is not in $H^{2,-s}(\mathbb{R}^3)$ for the singularity of order $|x-y|^{-1}$. Now I consider the function $$F(x)=\frac{e^{iz|x-y|}-1}{4\pi|x-y|}$$ so that $$\lim_{|x-y|\to 0}  F(x)=iz$$. Does $F(x)\in H^{2,-s}(\mathbb{R}^3)$? According to me yes because $$\Delta_xF(x)=-zf(z)-\delta_y+\delta_y=-zf(x)$$ where $\delta_y$ is the Dirac distribution in $y$. (I've used the relation ($-\Delta-z)f(x)=\delta_y$)","I have the function $$f(x)=\frac{e^{iz|x-y|}}{4\pi|x-y|}$$ with $y\in\mathbb{R}^3$ and $\Im z>0$. Let $s>\frac{1}{2}$. Clearly it is not in $H^{2,-s}(\mathbb{R}^3)$ for the singularity of order $|x-y|^{-1}$. Now I consider the function $$F(x)=\frac{e^{iz|x-y|}-1}{4\pi|x-y|}$$ so that $$\lim_{|x-y|\to 0}  F(x)=iz$$. Does $F(x)\in H^{2,-s}(\mathbb{R}^3)$? According to me yes because $$\Delta_xF(x)=-zf(z)-\delta_y+\delta_y=-zf(x)$$ where $\delta_y$ is the Dirac distribution in $y$. (I've used the relation ($-\Delta-z)f(x)=\delta_y$)",,"['analysis', 'functional-analysis', 'sobolev-spaces']"
