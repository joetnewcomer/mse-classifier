,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is composition of surjective continuous function with discontinuous function discontinuous?,Is composition of surjective continuous function with discontinuous function discontinuous?,,"Let $I_1,I_2,I_3$ be intervals $\subset \mathbb{R}$ . Suppose $f:I_1 \to I_2$ is a surjective continuous function and $g: I_2 \to I_3$ is a discontinuous function. Must the composition $g \circ f$ be discontinuous? There are some easy counter-examples if $f$ is not assumed to be surjective, e.g. taking $f$ to be a constant function, or in a way that ""dodges"" the discontinuous point(s) of $g$ . However if such ""dodging"" is prohibited, I fail to construct such functions nor find an answer from many similar questions on this site. So I am interested to know whether counter-examples exist? If not, is there a proof? Does it have something to do with intermediate value theorem?","Let be intervals . Suppose is a surjective continuous function and is a discontinuous function. Must the composition be discontinuous? There are some easy counter-examples if is not assumed to be surjective, e.g. taking to be a constant function, or in a way that ""dodges"" the discontinuous point(s) of . However if such ""dodging"" is prohibited, I fail to construct such functions nor find an answer from many similar questions on this site. So I am interested to know whether counter-examples exist? If not, is there a proof? Does it have something to do with intermediate value theorem?","I_1,I_2,I_3 \subset \mathbb{R} f:I_1 \to I_2 g: I_2 \to I_3 g \circ f f f g","['calculus', 'functions', 'continuity']"
1,Finding all continuous function which maps any sequence in geometric progression to another geometric progression,Finding all continuous function which maps any sequence in geometric progression to another geometric progression,,Find all continuous functions $f:\mathbb{R}\rightarrow\mathbb{R}$ such that for any geometric progression $x_n$ the sequence $f(x_n)$ is also a geometric progression. I tried first by taking constant sequences. But it does not helps much.,Find all continuous functions such that for any geometric progression the sequence is also a geometric progression. I tried first by taking constant sequences. But it does not helps much.,f:\mathbb{R}\rightarrow\mathbb{R} x_n f(x_n),"['functions', 'continuity', 'geometric-progressions']"
2,Optimization exercise regarding a circle and a function,Optimization exercise regarding a circle and a function,,"A circle $\omega$ centered at $K$ , $(0.5,0.5)$ is tangent to the $x$ - and $y$ -axes. Consider the function $$f(x):=\frac{8}{4+x^2} \; \forall x\in\mathbb{R}$$ and a point $P\in f$ such that the distance between $\omega$ and $P$ is minimal. Determinate the coordinates of $P$ . My attempt so far: It's trivial that the radius of $\omega$ is $\frac{1}{2}$ which might be proven for instance through reductio ad absurdum and the Pythagorean theorem . Now, it is a well-known fact, that the Euclidean distance $d$ between $\omega$ and some point $Q(x_q |f(x_q))$ is $$d=\rvert \sqrt{\big(x_q-\frac{1}{2}\bigr)^2+\big(f(x_q)-\frac{1}{2}\bigr)^2}-\frac{1}{2}\lvert$$ This looks something like this I've tried to simplify the expression and tried to determinate de zeros of the derivative without success since the expression I came up with was to ugly to work with. So, if you've achieved to solve the problem this way 'nicer', I would appreciate if you could show me how. Anyhow, I was wondering if there is a nicer way to approach this problem, rather than the analytical one, which might be the case since this exercise is though for 15-years-old students... Thanks in advanced","A circle centered at , is tangent to the - and -axes. Consider the function and a point such that the distance between and is minimal. Determinate the coordinates of . My attempt so far: It's trivial that the radius of is which might be proven for instance through reductio ad absurdum and the Pythagorean theorem . Now, it is a well-known fact, that the Euclidean distance between and some point is This looks something like this I've tried to simplify the expression and tried to determinate de zeros of the derivative without success since the expression I came up with was to ugly to work with. So, if you've achieved to solve the problem this way 'nicer', I would appreciate if you could show me how. Anyhow, I was wondering if there is a nicer way to approach this problem, rather than the analytical one, which might be the case since this exercise is though for 15-years-old students... Thanks in advanced","\omega K (0.5,0.5) x y f(x):=\frac{8}{4+x^2} \; \forall x\in\mathbb{R} P\in f \omega P P \omega \frac{1}{2} d \omega Q(x_q |f(x_q)) d=\rvert \sqrt{\big(x_q-\frac{1}{2}\bigr)^2+\big(f(x_q)-\frac{1}{2}\bigr)^2}-\frac{1}{2}\lvert","['functions', 'optimization', 'circles']"
3,Is there a name for $f\mapsto g\circ f\circ g^{-1}$?,Is there a name for ?,f\mapsto g\circ f\circ g^{-1},"Let $H$ and $K$ sets, $f:H\to H$ a map and $g:H\to K$ a bijection. Then $g$ induces a map $f^g:K\to K$ by $f^g:=g\circ f\circ g^{-1}$ . Is there a name for the map $f\to f^g$ ? In the special case when $H$ is a group, $K=H$ and both $f$ and $g$ are automorphisms of $H$ then $f\to f^g$ is conjugation of $f$ by $g$ . But what is it in general? Induced map? Pushforward? Lifting?","Let and sets, a map and a bijection. Then induces a map by . Is there a name for the map ? In the special case when is a group, and both and are automorphisms of then is conjugation of by . But what is it in general? Induced map? Pushforward? Lifting?",H K f:H\to H g:H\to K g f^g:K\to K f^g:=g\circ f\circ g^{-1} f\to f^g H K=H f g H f\to f^g f g,"['functions', 'terminology']"
4,Rolle's theorem on $e^x\sin x-1=0$,Rolle's theorem on,e^x\sin x-1=0,"Prove that between any two real roots of the equation $e^x\sin x-1=0$ the equation $e^x\cos x+1=0$ has at least one root. My attempts: By Rolle's theorem, the derivative of $e^x\sin x-1=0$ has at least one root between the roots $(\text{let}\ a,b)$ of $e^x\sin x-1=0$ $$f'(x)=e^x\sin x +e^x\cos x=\overbrace{\underbrace{(e^x\sin x-1)}_{2). \text{ no root in}\ (a,b)} +\underbrace{(e^x\cos x+1)}_{1,2\implies\text{ no root in}\ (a,b)}}^{\text{1). at least one root in}\ (a,b)}=0,\ x\in(a,b)$$ I found alternative proof of this here , but please don't mark this as duplicate as I want to know what's the wrong with what is tried.","Prove that between any two real roots of the equation $e^x\sin x-1=0$ the equation $e^x\cos x+1=0$ has at least one root. My attempts: By Rolle's theorem, the derivative of $e^x\sin x-1=0$ has at least one root between the roots $(\text{let}\ a,b)$ of $e^x\sin x-1=0$ $$f'(x)=e^x\sin x +e^x\cos x=\overbrace{\underbrace{(e^x\sin x-1)}_{2). \text{ no root in}\ (a,b)} +\underbrace{(e^x\cos x+1)}_{1,2\implies\text{ no root in}\ (a,b)}}^{\text{1). at least one root in}\ (a,b)}=0,\ x\in(a,b)$$ I found alternative proof of this here , but please don't mark this as duplicate as I want to know what's the wrong with what is tried.",,"['calculus', 'real-analysis', 'functions', 'roots', 'rolles-theorem']"
5,"Let $f : R \to R$ be twice differentiable, $f (x+\pi$) = $f(x)$, $f''(x) + f(x) \geq 0$ $∀$ $x\in {R}$. Prove that $f(x)\geq0$ $∀$ $x\in {R}$","Let  be twice differentiable, ) = ,   . Prove that",f : R \to R f (x+\pi f(x) f''(x) + f(x) \geq 0 ∀ x\in {R} f(x)\geq0 ∀ x\in {R},"I came across this question: Let $f : R \to R$ be a twice differentiable function such that $f (x+\pi$) =  $f(x)$ and $f''(x) + f(x) \geq 0$ $∀$ $x\in {R}$. Prove that $f(x)\geq0$ $∀$ $x\in {R}$ My teacher suggested me to define a function $g: R\to R$  for a real number $a\in R$, where $g(x) = f'(x+a) \sin x - f(x+a)\cos x$ $\therefore g'(x) = \sin x(f(x+a) + f''(x+a))\geq 0$ $∀$ $x\in [0,\pi]$ Hence for every $a\in R$ $g(\pi) - g(0)\geq 0$ $\because$ $g(\pi) -g(0) = f(a+\pi)+f(a) = 2f(a)$ $\therefore$ $2f(a) \geq0$ $\therefore$ $f(a) \geq0$ My Problem: Everything seems okay with the method he suggested, but how do I know how to define $g(x)$ the way he did. Is there any other way to do this question? If not, can someone please help me in identifying why my teacher went for that particular definition of $g(x)$? Thanks for comments/suggestions.","I came across this question: Let $f : R \to R$ be a twice differentiable function such that $f (x+\pi$) =  $f(x)$ and $f''(x) + f(x) \geq 0$ $∀$ $x\in {R}$. Prove that $f(x)\geq0$ $∀$ $x\in {R}$ My teacher suggested me to define a function $g: R\to R$  for a real number $a\in R$, where $g(x) = f'(x+a) \sin x - f(x+a)\cos x$ $\therefore g'(x) = \sin x(f(x+a) + f''(x+a))\geq 0$ $∀$ $x\in [0,\pi]$ Hence for every $a\in R$ $g(\pi) - g(0)\geq 0$ $\because$ $g(\pi) -g(0) = f(a+\pi)+f(a) = 2f(a)$ $\therefore$ $2f(a) \geq0$ $\therefore$ $f(a) \geq0$ My Problem: Everything seems okay with the method he suggested, but how do I know how to define $g(x)$ the way he did. Is there any other way to do this question? If not, can someone please help me in identifying why my teacher went for that particular definition of $g(x)$? Thanks for comments/suggestions.",,"['calculus', 'functions', 'derivatives']"
6,Counting zeros of parametrical functions.,Counting zeros of parametrical functions.,,"Today I was trying to do this exercise: Find for which $\lambda \in \mathbb{R}$ $$x+x^2=\arctan(\lambda x+x^2)$$ has exactly one solution. My attempt : Let's define $f(x)=x+x^2-\arctan(\lambda x + x^2)$. Finding solutions of that equation is equivalent to find zeros of this function. We note that $f(x)$ is bounded below by some constant $-M$ as its limits are both $+\infty$ as $x \to \pm \infty$ and it is a continuous function. Let's try to study its derivative: $$f'(x)=\frac{2x^5+(4\lambda+1)x^4+(2\lambda+2\lambda^2)x^3+\lambda^2x^2+1-\lambda}{1+(\lambda x+x^2)^2}$$ so clearly its sign depends only on the numerator which is a polynomial of degree $5$ in $x$. Before going on we should notice that there are mainly 4 cases to consider: $$\lambda>1, \quad \lambda=1, \quad \lambda=0, \quad \lambda < 1 \wedge \lambda \neq 0;$$ The problem is that I don't really know how to study the sign of the derivative as it's difficult to study the numerator sign. I tried to avoid studying the sign of the numerator by noting that if we approach the problem in another way, comparing the two functions $g(x)=x+x^2$ and $h(x)=\arctan(\lambda x+x^2)$ we notice that $h(x)$ has only one global minimum in $x= -\frac{\lambda}{2}$ and $g(0)=h(0)=0$ so clearly we should pay attention (expecially in the case $\lambda=1$) on which function is bigger than the other one. Now I'm stuck and I don't know how to proceed anymore. Any hint or help is really appreciated.","Today I was trying to do this exercise: Find for which $\lambda \in \mathbb{R}$ $$x+x^2=\arctan(\lambda x+x^2)$$ has exactly one solution. My attempt : Let's define $f(x)=x+x^2-\arctan(\lambda x + x^2)$. Finding solutions of that equation is equivalent to find zeros of this function. We note that $f(x)$ is bounded below by some constant $-M$ as its limits are both $+\infty$ as $x \to \pm \infty$ and it is a continuous function. Let's try to study its derivative: $$f'(x)=\frac{2x^5+(4\lambda+1)x^4+(2\lambda+2\lambda^2)x^3+\lambda^2x^2+1-\lambda}{1+(\lambda x+x^2)^2}$$ so clearly its sign depends only on the numerator which is a polynomial of degree $5$ in $x$. Before going on we should notice that there are mainly 4 cases to consider: $$\lambda>1, \quad \lambda=1, \quad \lambda=0, \quad \lambda < 1 \wedge \lambda \neq 0;$$ The problem is that I don't really know how to study the sign of the derivative as it's difficult to study the numerator sign. I tried to avoid studying the sign of the numerator by noting that if we approach the problem in another way, comparing the two functions $g(x)=x+x^2$ and $h(x)=\arctan(\lambda x+x^2)$ we notice that $h(x)$ has only one global minimum in $x= -\frac{\lambda}{2}$ and $g(0)=h(0)=0$ so clearly we should pay attention (expecially in the case $\lambda=1$) on which function is bigger than the other one. Now I'm stuck and I don't know how to proceed anymore. Any hint or help is really appreciated.",,"['calculus', 'real-analysis', 'functions']"
7,Higher order factorials.,Higher order factorials.,,"The function $y=x!$ can be drawn using the gamma functions, what could function would give higher order factorials like $y=x!!$ where $x!! = x\cdot(x-2)\cdot(x-4)\cdot\ldots\cdot5\cdot3\cdot1$ . I have this: $$\prod\limits_{n=0}^{\lfloor x/k\rfloor-1}(x-kn)$$ Where k is the amount of !'s but obviously this is only valid for integer k, but I'm looking for something which would make would make sense and be continuous for non-integers.","The function can be drawn using the gamma functions, what could function would give higher order factorials like where . I have this: Where k is the amount of !'s but obviously this is only valid for integer k, but I'm looking for something which would make would make sense and be continuous for non-integers.",y=x! y=x!! x!! = x\cdot(x-2)\cdot(x-4)\cdot\ldots\cdot5\cdot3\cdot1 \prod\limits_{n=0}^{\lfloor x/k\rfloor-1}(x-kn),"['functions', 'factorial', 'gamma-function']"
8,A function in terms of another function,A function in terms of another function,,"I have two functions that are polynomials. For example: $$F=x^2+2x+1  \hspace{5mm} \text{ and } \hspace{5mm} G=2x^2-x+2$$ I need to write one of these two functions in terms of the other one. For the example above the answer would be: $G$ as a function of $F$ is: $G=2F-5F^{1/2}+5$ As you know, depending on the complexity of $F$ and $G$, doing such a manipulation can be very difficult. Therefore, I am wondering if there is a known mathematical way to do this algebraic manipulation. Please note that the general format of $F$ and $G$ is always as below: $$F=\sum(ai × xi^i)|i=0,1,2,…,N$$ $$G=\sum(bi × xi^i)|i=0,1,2,…,N$$  Thank you!","I have two functions that are polynomials. For example: $$F=x^2+2x+1  \hspace{5mm} \text{ and } \hspace{5mm} G=2x^2-x+2$$ I need to write one of these two functions in terms of the other one. For the example above the answer would be: $G$ as a function of $F$ is: $G=2F-5F^{1/2}+5$ As you know, depending on the complexity of $F$ and $G$, doing such a manipulation can be very difficult. Therefore, I am wondering if there is a known mathematical way to do this algebraic manipulation. Please note that the general format of $F$ and $G$ is always as below: $$F=\sum(ai × xi^i)|i=0,1,2,…,N$$ $$G=\sum(bi × xi^i)|i=0,1,2,…,N$$  Thank you!",,['functions']
9,Negative part of convex function is globally Lipschitz continuous?,Negative part of convex function is globally Lipschitz continuous?,,"Suppose $f:R^n\to R$ is a convex function. Define the the negative part $f^- (x) = |\min\{0, f(x) \}|$. Is $f^-(x)$ globally Lipschitz continuous in $x$? I think it is since if it not then the epigraph of $f$ is not a convex set and we have a contradiction. Edit: Let me clarify my thinking. I think $f^-$ is globally Lipschitz continuous because if it is not, then the epigraph of $f$ is not a convex set. But I don't know how to show this.","Suppose $f:R^n\to R$ is a convex function. Define the the negative part $f^- (x) = |\min\{0, f(x) \}|$. Is $f^-(x)$ globally Lipschitz continuous in $x$? I think it is since if it not then the epigraph of $f$ is not a convex set and we have a contradiction. Edit: Let me clarify my thinking. I think $f^-$ is globally Lipschitz continuous because if it is not, then the epigraph of $f$ is not a convex set. But I don't know how to show this.",,"['real-analysis', 'functions', 'convex-analysis', 'lipschitz-functions']"
10,Does integrating over different curves give different results?,Does integrating over different curves give different results?,,"When we're integrating a one variable function, there is only one path to follow between points $a$ and $b$. $F(b)=F(a)+h(f(a)+f(a+h)+f(a+2h)+........)$ where $h$ is very small. So, we approach from $a$ to $b$ in steps of $h$ along the line joining unique path joining $a$ and $b$. I was wondering what if we have a multi-variable function $f(x,y)$. What does it mean to integrate $f(x,y)$ from $(a,b)$ to $(c,d)$? Clearly, there isn't a unique path joining $(a,b)$ and $(c,d)$. We have partial integration: $$\int_{(a,b)}^{(c,d)} f(x,y)dxdy=\int_{a}^{c}f(x,b)dx+\int_{b}^{d}f(c,y)dy$$ But that's basically doing it in two steps, first keeping $y$ constant then $x$ constant. How can we vary both $x$ and $y$ simultaneously? I thought of finding a curve which contains both the points $(a,b)$ and $(c,d)$ and varying both variables simultaneously along that path. Suppose $g(x)$ is a curve such that $g(a)=b$ and $g(c)=d$. Then we can replace $y$ with $g(x)$ to get: $$\int_{(a,b)}^{(c,d)} f(x,y)dxdy=\int_a^b f(x,g(x))g'(x)dx$$ Does this integration of $f(x,y)$ from $(a,b)$ to $(c,d)$ depend on the choice of curve $g(x)$?","When we're integrating a one variable function, there is only one path to follow between points $a$ and $b$. $F(b)=F(a)+h(f(a)+f(a+h)+f(a+2h)+........)$ where $h$ is very small. So, we approach from $a$ to $b$ in steps of $h$ along the line joining unique path joining $a$ and $b$. I was wondering what if we have a multi-variable function $f(x,y)$. What does it mean to integrate $f(x,y)$ from $(a,b)$ to $(c,d)$? Clearly, there isn't a unique path joining $(a,b)$ and $(c,d)$. We have partial integration: $$\int_{(a,b)}^{(c,d)} f(x,y)dxdy=\int_{a}^{c}f(x,b)dx+\int_{b}^{d}f(c,y)dy$$ But that's basically doing it in two steps, first keeping $y$ constant then $x$ constant. How can we vary both $x$ and $y$ simultaneously? I thought of finding a curve which contains both the points $(a,b)$ and $(c,d)$ and varying both variables simultaneously along that path. Suppose $g(x)$ is a curve such that $g(a)=b$ and $g(c)=d$. Then we can replace $y$ with $g(x)$ to get: $$\int_{(a,b)}^{(c,d)} f(x,y)dxdy=\int_a^b f(x,g(x))g'(x)dx$$ Does this integration of $f(x,y)$ from $(a,b)$ to $(c,d)$ depend on the choice of curve $g(x)$?",,"['calculus', 'integration']"
11,"Proof verification: system of functional equations: $f(0)=1$, $f\bigl(f(n)\bigr)=n$ and $f\bigl(f(n+2)+2\bigr)=n$","Proof verification: system of functional equations: ,  and",f(0)=1 f\bigl(f(n)\bigr)=n f\bigl(f(n+2)+2\bigr)=n,"A problem in Putnam Competition 1992(?). The question asked: Prove that, the only solution of the system of functional equation with respect to $f:\mathbb Z\to\mathbb Z$ : $$ \begin{cases} f\bigl(f(n)\bigr)=n\\ f\bigl(f(n+2)+2\bigr)=n\\ f(0)=1 \end{cases} $$ is $f(n)=1-n$ . I know that the usual way is to construct another solution, and show that the difference between the two solutions is zero. But I want to use equivalence condition this time. (i.e. Prove that the system is equivalent to say that $f(n)=1-n$ ). Now, we have $$f\bigl(f(n)\bigr)=f\bigl(f(n+2)+2\bigr)$$ Take $f$ on both sides. $$f\Bigl(f\bigl(f(n)\bigr)\Bigr)=f\Bigl(f\bigl(f(n+2)+2\bigr)\Bigr)$$ Again by the first equation, $$f(n)=f(n+2)+2$$ And another useful thing is that, $$f(1)=f\bigl(f(0)\bigr)=0$$ So, the original system is equivalent to say the recurrent relation $$ \begin{cases} f(n)=f(n+2)+2\\ f(0)=1\\ f(1)=0 \end{cases} $$ The sequence-like function  satisfying above is unique, trivially (as for all integers, we could find an unique image of it). So our proof is actually done already as $f(n)=1-n$ is simply a solution. Q.E.D. In my proof, I used a lot of equivalence condition. I know that my proof is valid if the conditions are actually equivalent. I think so for myself, but I want peer reviews also. Thanks in advance.","A problem in Putnam Competition 1992(?). The question asked: Prove that, the only solution of the system of functional equation with respect to : is . I know that the usual way is to construct another solution, and show that the difference between the two solutions is zero. But I want to use equivalence condition this time. (i.e. Prove that the system is equivalent to say that ). Now, we have Take on both sides. Again by the first equation, And another useful thing is that, So, the original system is equivalent to say the recurrent relation The sequence-like function  satisfying above is unique, trivially (as for all integers, we could find an unique image of it). So our proof is actually done already as is simply a solution. Q.E.D. In my proof, I used a lot of equivalence condition. I know that my proof is valid if the conditions are actually equivalent. I think so for myself, but I want peer reviews also. Thanks in advance.","f:\mathbb Z\to\mathbb Z 
\begin{cases}
f\bigl(f(n)\bigr)=n\\
f\bigl(f(n+2)+2\bigr)=n\\
f(0)=1
\end{cases}
 f(n)=1-n f(n)=1-n f\bigl(f(n)\bigr)=f\bigl(f(n+2)+2\bigr) f f\Bigl(f\bigl(f(n)\bigr)\Bigr)=f\Bigl(f\bigl(f(n+2)+2\bigr)\Bigr) f(n)=f(n+2)+2 f(1)=f\bigl(f(0)\bigr)=0 
\begin{cases}
f(n)=f(n+2)+2\\
f(0)=1\\
f(1)=0
\end{cases}
 f(n)=1-n","['functions', 'solution-verification', 'contest-math', 'functional-equations']"
12,Inverse of 2D-functions,Inverse of 2D-functions,,"Consider a function $g: \mathbb{R}^2 \to \mathbb{R}$ and another function $h: \mathbb{R}^2 \to \mathbb{R}$. Does there always exist a function $f$ s.t. $g(f(x),f(y)) = h(x,y)$ ? I can construct simple cases eg. $g(x,y)=x+y$,  $h(x,y)=x^2+y^2+xy$ and then put values to get contradiction in $f(x) + f(y) = x^2 + y^2 + xy$ but I am not sure what is the correct approach to solve the general problem. I see that for $g: \mathbb{R} \to \mathbb{R}$ this is straightforward as $f(x) = g^{-1}h(x)$, so $f$ exists if $g$ is invertible.","Consider a function $g: \mathbb{R}^2 \to \mathbb{R}$ and another function $h: \mathbb{R}^2 \to \mathbb{R}$. Does there always exist a function $f$ s.t. $g(f(x),f(y)) = h(x,y)$ ? I can construct simple cases eg. $g(x,y)=x+y$,  $h(x,y)=x^2+y^2+xy$ and then put values to get contradiction in $f(x) + f(y) = x^2 + y^2 + xy$ but I am not sure what is the correct approach to solve the general problem. I see that for $g: \mathbb{R} \to \mathbb{R}$ this is straightforward as $f(x) = g^{-1}h(x)$, so $f$ exists if $g$ is invertible.",,"['functions', 'inverse-function']"
13,"Prove that $\sin(x)\geq\ln(x+1)$ for any $x\in[0,\frac{\pi}{2}]$",Prove that  for any,"\sin(x)\geq\ln(x+1) x\in[0,\frac{\pi}{2}]","Prove that $\sin(x)\geq\ln(x+1)$ for any $x\in[0,\frac{\pi}{2}]$ I tried to consider $f(x)=\sin(x)-\ln(x+1)$ for $x\in[0,\frac{\pi}{2}]$, $f(0)=0,f(\frac{\pi}{2}) > 0$. Then $f'(x)=\cos(x)-\frac{1}{x+1}$, to anser my question i need to show, that exists some $c\in(0,\frac{\pi}{2})$: $f'(c)=0$, for any $x\in(0,c)$: $f'(x) > 0$ and  for any $x\in(c,\frac{\pi}{2})$: $f'(x) < 0$. I'm having trouble with this. Maybe there is simpler way to prove that $\sin(x)\geq\ln(x+1)$ for any $x\in[0,\frac{\pi}{2}]$?","Prove that $\sin(x)\geq\ln(x+1)$ for any $x\in[0,\frac{\pi}{2}]$ I tried to consider $f(x)=\sin(x)-\ln(x+1)$ for $x\in[0,\frac{\pi}{2}]$, $f(0)=0,f(\frac{\pi}{2}) > 0$. Then $f'(x)=\cos(x)-\frac{1}{x+1}$, to anser my question i need to show, that exists some $c\in(0,\frac{\pi}{2})$: $f'(c)=0$, for any $x\in(0,c)$: $f'(x) > 0$ and  for any $x\in(c,\frac{\pi}{2})$: $f'(x) < 0$. I'm having trouble with this. Maybe there is simpler way to prove that $\sin(x)\geq\ln(x+1)$ for any $x\in[0,\frac{\pi}{2}]$?",,"['calculus', 'functions']"
14,why are convex functions defined as functions who's epigraph is a convex set?,why are convex functions defined as functions who's epigraph is a convex set?,,"A convex real-function is a function such that all points above the function's graph form a convex set. Why isn't it defined instead the opposite way: a function such that all points below it form a convex set? Is there a particular reason for this? edit : my question really is: Is there some kind of similarity that convex sets share with convex functions, but not with concave functions, which would explain why we use the same term for these different things?","A convex real-function is a function such that all points above the function's graph form a convex set. Why isn't it defined instead the opposite way: a function such that all points below it form a convex set? Is there a particular reason for this? edit : my question really is: Is there some kind of similarity that convex sets share with convex functions, but not with concave functions, which would explain why we use the same term for these different things?",,"['functions', 'convex-analysis', 'definition']"
15,Approximation of piecewise linear function by smooth function,Approximation of piecewise linear function by smooth function,,"I am reading a paper: Target enumeration via integration over planar sensor networks And I would like to know if there is any reference which deals with approximating piecewise linear functions defined in $\mathbb{R}^n$ by smooth ones. Maybe that reference could cover the procedure, the errors... Even a reference for the case $n=2$ would be nice. My question arises as I would like to apply some techniques from Morse theory but I have a piecewise linear interpolation of some counting functions. Thanks in advance and any help would be appreciated","I am reading a paper: Target enumeration via integration over planar sensor networks And I would like to know if there is any reference which deals with approximating piecewise linear functions defined in $\mathbb{R}^n$ by smooth ones. Maybe that reference could cover the procedure, the errors... Even a reference for the case $n=2$ would be nice. My question arises as I would like to apply some techniques from Morse theory but I have a piecewise linear interpolation of some counting functions. Thanks in advance and any help would be appreciated",,"['functions', 'reference-request', 'special-functions', 'approximation', 'approximation-theory']"
16,Functions vs. Operators,Functions vs. Operators,,"Let $\mathsf{I}$ be an operator that takes as input $x$ and returns $x$. Then $\mathsf{I}$ is not a function . 1 Why is this not a function? According to Lambda Calculus and Combinators , $\mathsf{I}$ is not a function in the set theoretic sense (that is, $\mathsf{I}$ cannot be represented as a set of ordered pairs): In ZF, each set $S$ has an identity function $\mathsf{I}_S$ with domain $S$, but there is no 'universal' identity which can be applied to everything. Question 1: Is this because if $\mathsf{I}$ were a function, then its domain would be some universal class $U$ that contained everything (and hence would run into Russell's paradox, implying $U$ cannot be a set)? 2 Why can't set-theoretic functions be applied to themselves? Consider that $\mathsf{I}x = x$ implies that $\mathsf{I} \mathsf{I} = \mathsf{I}$. This seems to make sense. But this implies that $\mathsf{I}$ is in its own ""domain"", which can evidently never happen in ZFC: [T]he axiom of foundation ... prevents functions from being applied to themselves. Now the axiom of foundation , according to Wikipedia, states in English that [E]very non-empty set $A$ contains an element that is disjoint from $A$. But it hardly seems evident from this why this means a function cannot be applied to itself. Question 2: Why can a set theoretic function $f$ not be in its own domain? 3 Modeling operators in ZFC The operator concept can be modelled in standard ZF set theory if, roughly speaking, we interpret operators as infinite sequences of functions (satisfying certain conditions), instead of as single functions. The author does not explain how this works. Question 3: How do we model operators like $\mathsf{I}$ in ZFC?","Let $\mathsf{I}$ be an operator that takes as input $x$ and returns $x$. Then $\mathsf{I}$ is not a function . 1 Why is this not a function? According to Lambda Calculus and Combinators , $\mathsf{I}$ is not a function in the set theoretic sense (that is, $\mathsf{I}$ cannot be represented as a set of ordered pairs): In ZF, each set $S$ has an identity function $\mathsf{I}_S$ with domain $S$, but there is no 'universal' identity which can be applied to everything. Question 1: Is this because if $\mathsf{I}$ were a function, then its domain would be some universal class $U$ that contained everything (and hence would run into Russell's paradox, implying $U$ cannot be a set)? 2 Why can't set-theoretic functions be applied to themselves? Consider that $\mathsf{I}x = x$ implies that $\mathsf{I} \mathsf{I} = \mathsf{I}$. This seems to make sense. But this implies that $\mathsf{I}$ is in its own ""domain"", which can evidently never happen in ZFC: [T]he axiom of foundation ... prevents functions from being applied to themselves. Now the axiom of foundation , according to Wikipedia, states in English that [E]very non-empty set $A$ contains an element that is disjoint from $A$. But it hardly seems evident from this why this means a function cannot be applied to itself. Question 2: Why can a set theoretic function $f$ not be in its own domain? 3 Modeling operators in ZFC The operator concept can be modelled in standard ZF set theory if, roughly speaking, we interpret operators as infinite sequences of functions (satisfying certain conditions), instead of as single functions. The author does not explain how this works. Question 3: How do we model operators like $\mathsf{I}$ in ZFC?",,"['functions', 'set-theory']"
17,"Why isn't f(x^2) a horizontal stretch of f(x) by a factor of ""1/x""?","Why isn't f(x^2) a horizontal stretch of f(x) by a factor of ""1/x""?",,"I know this question seems silly, but it came to mind while reading about transforming functions. Is the statement ""y=f(kx) results from scaling the graph of y=f(x) horizontally by a factor of 1/k"" not applicable when k=x? A thorough explanation would be appreciated.","I know this question seems silly, but it came to mind while reading about transforming functions. Is the statement ""y=f(kx) results from scaling the graph of y=f(x) horizontally by a factor of 1/k"" not applicable when k=x? A thorough explanation would be appreciated.",,"['functions', 'graphing-functions']"
18,"if the equation $(x-2)e^x+a(x-1)^2=0$ have two real roots,Prove $a>0$","if the equation  have two real roots,Prove",(x-2)e^x+a(x-1)^2=0 a>0,"if the equation $$(x-2)e^x+a(x-1)^2=0,x\in R$$ have two real roots. show that $$a>0$$ Following is a  solution since $$-a=\dfrac{(x-2)e^x}{(x-1)^2}$$ Let $$g(x)=\dfrac{(x-2)e^x}{(x-1)^2}\Longrightarrow  g'(x)=\dfrac{e^x(x^2-4x+5)}{(x-1)^3}$$ so we have $$x>1,g'(x)>0\Longrightarrow g(x)\in (-\infty,+\infty)$$ and  $$x<1,g'(x)<0\Longrightarrow g(x)\in (-\infty,0)$$ then have following Fig if $-a=g(x)$ have two real roots,then $-a<0$,so we have $a>0$ $\color{red} {Is ~there ~any ~other~ solution?and ~I~ want ~more ~solution}$","if the equation $$(x-2)e^x+a(x-1)^2=0,x\in R$$ have two real roots. show that $$a>0$$ Following is a  solution since $$-a=\dfrac{(x-2)e^x}{(x-1)^2}$$ Let $$g(x)=\dfrac{(x-2)e^x}{(x-1)^2}\Longrightarrow  g'(x)=\dfrac{e^x(x^2-4x+5)}{(x-1)^3}$$ so we have $$x>1,g'(x)>0\Longrightarrow g(x)\in (-\infty,+\infty)$$ and  $$x<1,g'(x)<0\Longrightarrow g(x)\in (-\infty,0)$$ then have following Fig if $-a=g(x)$ have two real roots,then $-a<0$,so we have $a>0$ $\color{red} {Is ~there ~any ~other~ solution?and ~I~ want ~more ~solution}$",,['functions']
19,Do functions whose domains are infinite sets sequentially or simultaneously map their elements,Do functions whose domains are infinite sets sequentially or simultaneously map their elements,,"Here are two equivalent definitions of the axiom of choice Let $x$ be a set. Suppose that if $y,w \in x$, then $y \neq \varnothing$ and $y\cap w = \varnothing$. Then there is a set $z$ such that if $y \in x$, then $y \cap z$ contains a single element. and Let $I$ be a nonempty, indexing set and let $\{A_i\}_{i\in I}$ be a family of nonempty sets indexed by $I$. Then there is a function $f: I \rightarrow \bigcup_{i \rightarrow I} A_i$ such that $f(i) \in A_i$ for all $i \in I$. The text says with regards to the first definition that if we want to choose one element from each set in an infinite family of nonempty sets, we must make the choices simultaneously instead of sequentially. I would like to know where in either definition it can be understood that the elements are chosen at the same time rather than one-by-one, or is this just mere terminology as to be didactily correct yet mathematically irrelevant. The author also mentions that in proving that if $f: A \rightarrow B$ is surjective, then $f$ has a right inverse, one element $a \in A$ is chosen simultaneously such that $b = f(a)$, which leads me to also wonder if whenever we say, ""Let $a \in A$ such that $b = f(a)$"", we mean that the elements in $A$ are being simultaneously mapped by $f$ to a $b$; and if that's true, then when would $f$ sequentially map the elements in $A$ to some of the elements in $B$? I know my issue with understanding how the elements are chosen is so trivial as to be a mere distracting quibble, but I really want some clarification. Note that this is not an axiom of choice question, since I'm really just curious as to how the elements are selected and in what ways do we distinctly want elements to be sequentially or simultaneously chosen.","Here are two equivalent definitions of the axiom of choice Let $x$ be a set. Suppose that if $y,w \in x$, then $y \neq \varnothing$ and $y\cap w = \varnothing$. Then there is a set $z$ such that if $y \in x$, then $y \cap z$ contains a single element. and Let $I$ be a nonempty, indexing set and let $\{A_i\}_{i\in I}$ be a family of nonempty sets indexed by $I$. Then there is a function $f: I \rightarrow \bigcup_{i \rightarrow I} A_i$ such that $f(i) \in A_i$ for all $i \in I$. The text says with regards to the first definition that if we want to choose one element from each set in an infinite family of nonempty sets, we must make the choices simultaneously instead of sequentially. I would like to know where in either definition it can be understood that the elements are chosen at the same time rather than one-by-one, or is this just mere terminology as to be didactily correct yet mathematically irrelevant. The author also mentions that in proving that if $f: A \rightarrow B$ is surjective, then $f$ has a right inverse, one element $a \in A$ is chosen simultaneously such that $b = f(a)$, which leads me to also wonder if whenever we say, ""Let $a \in A$ such that $b = f(a)$"", we mean that the elements in $A$ are being simultaneously mapped by $f$ to a $b$; and if that's true, then when would $f$ sequentially map the elements in $A$ to some of the elements in $B$? I know my issue with understanding how the elements are chosen is so trivial as to be a mere distracting quibble, but I really want some clarification. Note that this is not an axiom of choice question, since I'm really just curious as to how the elements are selected and in what ways do we distinctly want elements to be sequentially or simultaneously chosen.",,"['functions', 'elementary-set-theory', 'terminology']"
20,Properties of $f(x)=\ln(1+x^2)+x+2$ vs $g(x)=\cosh x+\sinh x$,Properties of  vs,f(x)=\ln(1+x^2)+x+2 g(x)=\cosh x+\sinh x,"This is from an MCQ contest. Consider the two functions: $f(x)=\ln(1+x^2)+x+2$ et $g(x)=ch(x)+sh(x)$. The real number $c$ such that: $(f^{-1})'(2)=g(c)$ $1]$ $c=-1$ $2]$ $c=0$ $3]$ $c=1$ $4]$ None of the above statements is correct My Thoughts: note that : $$\left(f^{-1}\right)^\prime (y)=\frac{1}{f'\left(f^{-1}(y)\right)}.$$ and  $$ch(x)+sh(x)=e^x$$ but first we should check $f$ it's invertible or not indeed, $f$ is strictly increasing continuous on $\mathbb{R}$ since  $$f'(x)=\dfrac{(x+1)^{2}}{x^2+1}\geq 0$$ then $f$ is invertible thus has inverse function $$f(x)=y\iff x=f^{-1}(x) \\ \ln(1+x^2)+x+2=y $$ i'm stuck here Any help will be apprecited","This is from an MCQ contest. Consider the two functions: $f(x)=\ln(1+x^2)+x+2$ et $g(x)=ch(x)+sh(x)$. The real number $c$ such that: $(f^{-1})'(2)=g(c)$ $1]$ $c=-1$ $2]$ $c=0$ $3]$ $c=1$ $4]$ None of the above statements is correct My Thoughts: note that : $$\left(f^{-1}\right)^\prime (y)=\frac{1}{f'\left(f^{-1}(y)\right)}.$$ and  $$ch(x)+sh(x)=e^x$$ but first we should check $f$ it's invertible or not indeed, $f$ is strictly increasing continuous on $\mathbb{R}$ since  $$f'(x)=\dfrac{(x+1)^{2}}{x^2+1}\geq 0$$ then $f$ is invertible thus has inverse function $$f(x)=y\iff x=f^{-1}(x) \\ \ln(1+x^2)+x+2=y $$ i'm stuck here Any help will be apprecited",,"['real-analysis', 'functions', 'contest-math']"
21,Existence of a monotone subadditive function with a jump on its values,Existence of a monotone subadditive function with a jump on its values,,"Let $f$ be a nonnegative function defined on the power of the set of positive integers for which: $f(X) \le f(Y) \le f(\mathbf{N})=1$ if $X\subseteq Y$; $f(X\cup Y)\le f(X)+f(Y)$; for each $X$ and each $y \in [0,f(X)]$ there exists $Y \subseteq X$ such that $f(Y)=y$. Fix a set $A$ such that $f(A)<1$. Does there exist a set $B$ containing $A$ such that  $$ f(A)<f(B)<1 \,\,? $$","Let $f$ be a nonnegative function defined on the power of the set of positive integers for which: $f(X) \le f(Y) \le f(\mathbf{N})=1$ if $X\subseteq Y$; $f(X\cup Y)\le f(X)+f(Y)$; for each $X$ and each $y \in [0,f(X)]$ there exists $Y \subseteq X$ such that $f(Y)=y$. Fix a set $A$ such that $f(A)<1$. Does there exist a set $B$ containing $A$ such that  $$ f(A)<f(B)<1 \,\,? $$",,"['real-analysis', 'functions']"
22,Integration: The Periodic Function and its Properties,Integration: The Periodic Function and its Properties,,"I am aware that if $f(x)$ is a periodic function with period $T$ then: 1.) $\int^{nT}_{0}f(x)\,dx = n\int^{T}_{0}f(x)\,dx$, for $n$ an integer. 2.) $\int^{T+a}_{a}f(x)\,dx = \int^{T}_{0}f(x)\,dx$, for some constant $a$. There are many wonderful and imaginative proofs of the above properties, but my question is this: Can you think of any particularly interesting integrals that would otherwise be very difficult to evaluate without these rules? I think it would be rather interesting to see how the properties can be used to simplify more complex problems. Thanks.","I am aware that if $f(x)$ is a periodic function with period $T$ then: 1.) $\int^{nT}_{0}f(x)\,dx = n\int^{T}_{0}f(x)\,dx$, for $n$ an integer. 2.) $\int^{T+a}_{a}f(x)\,dx = \int^{T}_{0}f(x)\,dx$, for some constant $a$. There are many wonderful and imaginative proofs of the above properties, but my question is this: Can you think of any particularly interesting integrals that would otherwise be very difficult to evaluate without these rules? I think it would be rather interesting to see how the properties can be used to simplify more complex problems. Thanks.",,"['calculus', 'integration', 'functions', 'periodic-functions']"
23,"Real Analysis: Given $A_1$, $A_2$, $A_3$, which set is open, which is closed?","Real Analysis: Given , , , which set is open, which is closed?",A_1 A_2 A_3,"a. $A_1 = \{x: \sin(1/x) =0\}$ Clearly $\sin(1/x) = 0$ for $x = \frac{1}{n\pi}$, what can we say about this set? b. $A_2 = \{x: x\sin(1/x)= 0 \}$ Again $\sin(1/x) = 0$ for $x = \frac{1}{n\pi}$, is there any difference between this set and $A_1$? c. $A_3 = \{x: \sin(1/x) > 0 \}$ $\sin(\frac{1}{x}) > 0$ if $\frac{1}{x} > \sin^{-1} (0) $, so $x > 0$ is an open set. Am I correct?","a. $A_1 = \{x: \sin(1/x) =0\}$ Clearly $\sin(1/x) = 0$ for $x = \frac{1}{n\pi}$, what can we say about this set? b. $A_2 = \{x: x\sin(1/x)= 0 \}$ Again $\sin(1/x) = 0$ for $x = \frac{1}{n\pi}$, is there any difference between this set and $A_1$? c. $A_3 = \{x: \sin(1/x) > 0 \}$ $\sin(\frac{1}{x}) > 0$ if $\frac{1}{x} > \sin^{-1} (0) $, so $x > 0$ is an open set. Am I correct?",,"['real-analysis', 'functions']"
24,Substitution with functional equations,Substitution with functional equations,,I've found this nice introduction worksheet that I started to work through with the goal to get a better understanding of functions and finding them in equations. I've gotten so far but in this one solution there is a few steps that is REALLY unclear. I'd appreciate if someone can check the edited screenshot and give me some pointers. Thank you!,I've found this nice introduction worksheet that I started to work through with the goal to get a better understanding of functions and finding them in equations. I've gotten so far but in this one solution there is a few steps that is REALLY unclear. I'd appreciate if someone can check the edited screenshot and give me some pointers. Thank you!,,"['functions', 'functional-equations']"
25,How to find the function for six step operation,How to find the function for six step operation,,"I am trying to find a function for the following scenario: Rotating the red arrow will produce a nice sine wave as illustrated to the right of the hexagon. But I need to rotate the blue arrow, and at the same time limit the magnitude according to the hexagon. That means that the magnitude will be 1 at every 60 degrees, and decrease to 0.866 at 60+30 degrees before increasing back to 1. Something like this: Lastly, i am going to use this varying value in a new sine wave function. That function will look like the dotted curve in the picture below: But I cannot find the actual function to produce such a curve. (I need it to make a figure about six step operation in electric motor drives) Hope you can help me","I am trying to find a function for the following scenario: Rotating the red arrow will produce a nice sine wave as illustrated to the right of the hexagon. But I need to rotate the blue arrow, and at the same time limit the magnitude according to the hexagon. That means that the magnitude will be 1 at every 60 degrees, and decrease to 0.866 at 60+30 degrees before increasing back to 1. Something like this: Lastly, i am going to use this varying value in a new sine wave function. That function will look like the dotted curve in the picture below: But I cannot find the actual function to produce such a curve. (I need it to make a figure about six step operation in electric motor drives) Hope you can help me",,['functions']
26,Identification of a function: $\sum_{k=1}^\infty(\log(k))^n\frac{z^k}{k}$,Identification of a function:,\sum_{k=1}^\infty(\log(k))^n\frac{z^k}{k},"I recently came across the following function $$\sum_{k=1}^\infty(\log(k))^n\frac{z^k}{k}$$ I found it while dealing with the polylogarithm function, $Li_n (z)$ (Notice that if instead of $(\log(k))^n$ we had $k^n$ then the above expression would become $Li_{1-n}(z)$. Still these functions are quite different.) I was wondering if this function is known, and if there are good numerical approximations to estimate it? Thank you in advance for your help.","I recently came across the following function $$\sum_{k=1}^\infty(\log(k))^n\frac{z^k}{k}$$ I found it while dealing with the polylogarithm function, $Li_n (z)$ (Notice that if instead of $(\log(k))^n$ we had $k^n$ then the above expression would become $Li_{1-n}(z)$. Still these functions are quite different.) I was wondering if this function is known, and if there are good numerical approximations to estimate it? Thank you in advance for your help.",,"['calculus', 'sequences-and-series', 'functions', 'special-functions', 'polylogarithm']"
27,Plotting discrete time signals involving sumations in matlab.,Plotting discrete time signals involving sumations in matlab.,,Many of the examples I've encountered while looking for an answer are simple functions that do not involve summations. Suppose I have the following function; f(n) = sum(n*cos(n-k)) from k=-infinity to infinity How would I go about making the discrete plot in MATLAB?,Many of the examples I've encountered while looking for an answer are simple functions that do not involve summations. Suppose I have the following function; f(n) = sum(n*cos(n-k)) from k=-infinity to infinity How would I go about making the discrete plot in MATLAB?,,"['functions', 'summation', 'graphing-functions', 'matlab', 'signal-processing']"
28,"Infinitely differentiable $f: \mathbb{R} \to \mathbb{R}$ such that for each $n \geq 0$, $f^{(n)}(x)=0$ if and only if $x=0$","Infinitely differentiable  such that for each ,  if and only if",f: \mathbb{R} \to \mathbb{R} n \geq 0 f^{(n)}(x)=0 x=0,I am looking for a function $f:\mathbb{R} \to \mathbb{R}$ that satisfies these properties: i) $f$ is infinitely differentiable. ii) $f$ and all its derivatives should intersect the $x$-axis only at the origin.,I am looking for a function $f:\mathbb{R} \to \mathbb{R}$ that satisfies these properties: i) $f$ is infinitely differentiable. ii) $f$ and all its derivatives should intersect the $x$-axis only at the origin.,,"['calculus', 'functions', 'derivatives']"
29,How many numbers are less than million such that their digits sum is $\le 19$?,How many numbers are less than million such that their digits sum is ?,\le 19,"How many numbers are less than million such that their digits sum is $\le 19$? This question is a Generating-Functions exercise. The solution claims the answer is the coefficient of $x^{19}$ in: $$ \left( 1 + x + x^2 + ... + x^9 \right)^6 \left(\frac{1}{1-x}\right) $$ The left term is obvious, but why multiplying by $\frac{1}{1-x}$? In general, if $F(x)$ generates $a_n$ then $\frac{F(x)}{1-x}$ generates $\sum\limits_{k=0}^n a_k$, but I don't see is that fitting here.","How many numbers are less than million such that their digits sum is $\le 19$? This question is a Generating-Functions exercise. The solution claims the answer is the coefficient of $x^{19}$ in: $$ \left( 1 + x + x^2 + ... + x^9 \right)^6 \left(\frac{1}{1-x}\right) $$ The left term is obvious, but why multiplying by $\frac{1}{1-x}$? In general, if $F(x)$ generates $a_n$ then $\frac{F(x)}{1-x}$ generates $\sum\limits_{k=0}^n a_k$, but I don't see is that fitting here.",,"['calculus', 'functions', 'generating-functions']"
30,Are there some functions that cannot be optimized using calculus?,Are there some functions that cannot be optimized using calculus?,,"I've been working on a project to maximize a functions output using a genetic algorithm. However, from the limited calculus I know I thought there were methods to find the maximum of a mathematical function using calculus? I'd assume the reason genetic algorithms are sometimes used to maximize functions is because there are functions where the mathematical methods don't work. If I'm correct, what are those conditions? I'd guess that maybe it's because the function is not continuous or differentiable?","I've been working on a project to maximize a functions output using a genetic algorithm. However, from the limited calculus I know I thought there were methods to find the maximum of a mathematical function using calculus? I'd assume the reason genetic algorithms are sometimes used to maximize functions is because there are functions where the mathematical methods don't work. If I'm correct, what are those conditions? I'd guess that maybe it's because the function is not continuous or differentiable?",,"['calculus', 'functions', 'optimization', 'artificial-intelligence']"
31,Question about function notation,Question about function notation,,"I'm learning function notation and will soon be doing Calculus - having trouble with this question: Question: Find the x- and y- intercept of each function: $f(x) = x^2 + 3x$ If I set x to 0, I find out that Y would be obviously equal to 0. I'm not sure how to do that for the other value. I try: $f(x) = x^2 + 3x$ $y = x^2 + 3x$ $0 = x^2 + 3x$ $-3x = x^2$ I don't know what to do from there, if I even did anything correct On another topic, is their any easy introductory book for Calculus I?","I'm learning function notation and will soon be doing Calculus - having trouble with this question: Question: Find the x- and y- intercept of each function: $f(x) = x^2 + 3x$ If I set x to 0, I find out that Y would be obviously equal to 0. I'm not sure how to do that for the other value. I try: $f(x) = x^2 + 3x$ $y = x^2 + 3x$ $0 = x^2 + 3x$ $-3x = x^2$ I don't know what to do from there, if I even did anything correct On another topic, is their any easy introductory book for Calculus I?",,['functions']
32,Use Cantor-Schroder-Bernstein to prove |X1|=|X2|,Use Cantor-Schroder-Bernstein to prove |X1|=|X2|,,"If  $X_1 = \left\{\text{all functions }f: \mathbb{ R}\rightarrow \mathbb{ R}\right\}$ and $X_2=\left\{\text{all functions }g:\mathbb{R}\rightarrow\mathbb{R}\text{ such that }g(0)=0\right\}$, $a)$ Use Cantor-Schroder-Bernstein to prove |$X_1$|=|$X_2$| $b)$ Find a concrete bijection between both sets For part $a)$ I said that because $X_2 \subseteq X_1$, then $|X_2|\leq|X_1|$. So now I just need to find an injection between $X_1$ and $X_2$. I have tried a couple of functions but I always get that two functions in $X_1$ that differ only on their value for $x=0$ map to the same function in $X_2$, so it's not injective. So I don't know how to procede from here. Any help would be greatly appreciated.","If  $X_1 = \left\{\text{all functions }f: \mathbb{ R}\rightarrow \mathbb{ R}\right\}$ and $X_2=\left\{\text{all functions }g:\mathbb{R}\rightarrow\mathbb{R}\text{ such that }g(0)=0\right\}$, $a)$ Use Cantor-Schroder-Bernstein to prove |$X_1$|=|$X_2$| $b)$ Find a concrete bijection between both sets For part $a)$ I said that because $X_2 \subseteq X_1$, then $|X_2|\leq|X_1|$. So now I just need to find an injection between $X_1$ and $X_2$. I have tried a couple of functions but I always get that two functions in $X_1$ that differ only on their value for $x=0$ map to the same function in $X_2$, so it's not injective. So I don't know how to procede from here. Any help would be greatly appreciated.",,"['elementary-set-theory', 'functions']"
33,$\textbf{Q}$ fails to prove some correct $\forall$-rudimentary sentence,fails to prove some correct -rudimentary sentence,\textbf{Q} \forall,"Show that the existence of a semirecursive set that is not recursive   implies that any consistent, axiomatizable extension of Q fails to   prove some correct $\forall$-rudimentary sentence. I have the following facts: Every recursive function is representable in Q (and by an $\exists$-rudimentary formula). Every recursive relation is definable in Q (and by an $\exists$-rudimentary formula). If $T$ is a consistent, axiomatizable theory containing Q : Every set semi-definable in $T$ is semirecursive. Every set definable in $T$ is recursive. Every total function representable in $T$ is recursive. Are there any examples of semirecursive sets where this structure holds? Or must their existence be proven mathematically?","Show that the existence of a semirecursive set that is not recursive   implies that any consistent, axiomatizable extension of Q fails to   prove some correct $\forall$-rudimentary sentence. I have the following facts: Every recursive function is representable in Q (and by an $\exists$-rudimentary formula). Every recursive relation is definable in Q (and by an $\exists$-rudimentary formula). If $T$ is a consistent, axiomatizable theory containing Q : Every set semi-definable in $T$ is semirecursive. Every set definable in $T$ is recursive. Every total function representable in $T$ is recursive. Are there any examples of semirecursive sets where this structure holds? Or must their existence be proven mathematically?",,"['functions', 'logic', 'computability']"
34,Maximum of product of two functions,Maximum of product of two functions,,"Let's have two (real continuous differentiable) functions such that $f(x)$ is bounded (from below and from above), positive ($f(x)>0$), and is strictly increasing ($f'(x)>0$, $\forall x$). $g(x)$ is bounded (from below and from above) and has exactly one maximum ($g'(x_0) = 0$ ; $g(x)<g(x_0), \forall x \ne x_0$) It then follows that function $h(x)=f(x)g(x)$ is also bounded.  However, additional conditions on either $f(x)$ or $g(x)$ must apply in order for the function $h(x)$ to have again only one maximum. The question is. What are the additional sufficient conditions on either $f(x)$ or $g(x)$ so that the product $h(x)=f(x)g(x)$ would have again only one maximum? (Thanks to gammatester for pointing this out).","Let's have two (real continuous differentiable) functions such that $f(x)$ is bounded (from below and from above), positive ($f(x)>0$), and is strictly increasing ($f'(x)>0$, $\forall x$). $g(x)$ is bounded (from below and from above) and has exactly one maximum ($g'(x_0) = 0$ ; $g(x)<g(x_0), \forall x \ne x_0$) It then follows that function $h(x)=f(x)g(x)$ is also bounded.  However, additional conditions on either $f(x)$ or $g(x)$ must apply in order for the function $h(x)$ to have again only one maximum. The question is. What are the additional sufficient conditions on either $f(x)$ or $g(x)$ so that the product $h(x)=f(x)g(x)$ would have again only one maximum? (Thanks to gammatester for pointing this out).",,"['calculus', 'functions', 'optimization']"
35,Structure of partial recursive function over recursively enumerable guard,Structure of partial recursive function over recursively enumerable guard,,"I read that the function  $$ f(n) = \left\{   \begin{array}{l l}     g(n) & \quad \text{if $n \in A$}\\     \text{undefined} & \quad \text{otherwise}   \end{array} \right. $$ is recursive if $g(n)$ is recursive and the guard $if$ $n \in A$ is recursively enumerable (since the always $\text{undefined}$ function is recursive). I read also that if the $else$ part is not always $undefined$, we cannot conclude that $f$ is not recursive. Could anyone please explain why we should use the always undefined function in the else part when we have an r.e. guard? And also if $f$ was defined as follows, what conditions should $h(n)$ fulfil (apart from being always undefined) so that $f$ is recursive. $$ f(n) = \left\{   \begin{array}{l l}     g(n) & \quad \text{if $n \in A$}\\     h(n) & \quad \text{otherwise}   \end{array} \right. $$","I read that the function  $$ f(n) = \left\{   \begin{array}{l l}     g(n) & \quad \text{if $n \in A$}\\     \text{undefined} & \quad \text{otherwise}   \end{array} \right. $$ is recursive if $g(n)$ is recursive and the guard $if$ $n \in A$ is recursively enumerable (since the always $\text{undefined}$ function is recursive). I read also that if the $else$ part is not always $undefined$, we cannot conclude that $f$ is not recursive. Could anyone please explain why we should use the always undefined function in the else part when we have an r.e. guard? And also if $f$ was defined as follows, what conditions should $h(n)$ fulfil (apart from being always undefined) so that $f$ is recursive. $$ f(n) = \left\{   \begin{array}{l l}     g(n) & \quad \text{if $n \in A$}\\     h(n) & \quad \text{otherwise}   \end{array} \right. $$",,"['functions', 'computability', 'recursion']"
36,Cantor-Bernstein Theorem proof,Cantor-Bernstein Theorem proof,,"I am self studying real analysis and I am doing an exercise which is proving the Cantor-Bernstein Theorem. Question: Assume there exists a 1-1 function $f:X \rightarrow Y$ and another 1-1 function $g:Y \rightarrow X$. Follow the steps to show that there exists a 1-1, onto function $h:X \rightarrow Y$ and hence $X \sim Y$. a) The range of $f$ is defined by $f(X) = \{y \in Y : y = f(x) \ \text{for some} \ x \in X\}$. Let $y \in f(X)$. Explain why there exists a unique $x \in X$ such that $f(x) = y$. Now define $f^{-1}(y) = x$, and show that $f^{-1}$ is a 1-1 function from $f(X)$ onto $X$. In a similar way, we can also define the 1-1, onto function $g^{-1}: g(Y) \rightarrow Y$. b) Let $x \in X$ be arbitrary. Let the chain $C_x$ be the set consisting of all elements of the form: $$\cdots, f^{-1}(g^{-1}(x)), g^{-1}(x), x, f(x), g(f(x)), f(g(f(x))), \cdots $$ Explain why the number of elements to the left of $x$ in the above chain may be zero, finite, or infinite. c) Show that any two chains are either identical or completely disjoint. d) Note that the terms in the chain above alternate between elements of $X$ and elements of $Y$, i.e., $$\cdots, \underbrace{f^{-1}(g^{-1}(x))}_{\in X}, \underbrace{g^{-1}(x)}_{\in Y}, \underbrace{x}_{\in X}, \underbrace{f(x)}_{\in Y}, \underbrace{g(f(x))}_{\in X}, \underbrace{f(g(f(x)))}_{\in Y}, \cdots  \ \ \ \ \ \ \ \ \ \ (1)$$ Given a chain $C_x$, focus on $C_x \cap Y$, which is just the part of the chain that belongs to $Y$. Define the set $A$ to be the union of all chains $C_x$ satisfying $C_x \cap Y \subseteq f(X)$. Let $B$ be the set of the union of the remaining chains not in $A$. Show that any chain contained in $B$ must be of the form: $$y, g(y), f(g(y)), g(f(g(y))), \cdots $$ where $y$ is an element of $Y$ that is not in $f(X)$. Queries: OK, I can do parts a) to c) , it is part d) which is confusing me right now. Here is my attempt so far. Let $C_{x_0}$ be a chain in $B$, then clearly $C_{x_0} \cap Y \not \subseteq f(X)$, which means there must exist some $y \in Y$ with $y \in C_{x_0}$ such that $y \not \in f(X)$. Referring to expression $(1)$, clearly elements like $f(x_0)$, $f(g(f(x_0)))$, $\cdots$ must be an element of $f(X)$ by definition. So it must be a term of the form like $g^{-1}(x_0)$ which is not an element of $f(X)$. Now I am not exactly sure how to complete the remainder of the question, that is, the chains in $B$ must be of the form given in the question.","I am self studying real analysis and I am doing an exercise which is proving the Cantor-Bernstein Theorem. Question: Assume there exists a 1-1 function $f:X \rightarrow Y$ and another 1-1 function $g:Y \rightarrow X$. Follow the steps to show that there exists a 1-1, onto function $h:X \rightarrow Y$ and hence $X \sim Y$. a) The range of $f$ is defined by $f(X) = \{y \in Y : y = f(x) \ \text{for some} \ x \in X\}$. Let $y \in f(X)$. Explain why there exists a unique $x \in X$ such that $f(x) = y$. Now define $f^{-1}(y) = x$, and show that $f^{-1}$ is a 1-1 function from $f(X)$ onto $X$. In a similar way, we can also define the 1-1, onto function $g^{-1}: g(Y) \rightarrow Y$. b) Let $x \in X$ be arbitrary. Let the chain $C_x$ be the set consisting of all elements of the form: $$\cdots, f^{-1}(g^{-1}(x)), g^{-1}(x), x, f(x), g(f(x)), f(g(f(x))), \cdots $$ Explain why the number of elements to the left of $x$ in the above chain may be zero, finite, or infinite. c) Show that any two chains are either identical or completely disjoint. d) Note that the terms in the chain above alternate between elements of $X$ and elements of $Y$, i.e., $$\cdots, \underbrace{f^{-1}(g^{-1}(x))}_{\in X}, \underbrace{g^{-1}(x)}_{\in Y}, \underbrace{x}_{\in X}, \underbrace{f(x)}_{\in Y}, \underbrace{g(f(x))}_{\in X}, \underbrace{f(g(f(x)))}_{\in Y}, \cdots  \ \ \ \ \ \ \ \ \ \ (1)$$ Given a chain $C_x$, focus on $C_x \cap Y$, which is just the part of the chain that belongs to $Y$. Define the set $A$ to be the union of all chains $C_x$ satisfying $C_x \cap Y \subseteq f(X)$. Let $B$ be the set of the union of the remaining chains not in $A$. Show that any chain contained in $B$ must be of the form: $$y, g(y), f(g(y)), g(f(g(y))), \cdots $$ where $y$ is an element of $Y$ that is not in $f(X)$. Queries: OK, I can do parts a) to c) , it is part d) which is confusing me right now. Here is my attempt so far. Let $C_{x_0}$ be a chain in $B$, then clearly $C_{x_0} \cap Y \not \subseteq f(X)$, which means there must exist some $y \in Y$ with $y \in C_{x_0}$ such that $y \not \in f(X)$. Referring to expression $(1)$, clearly elements like $f(x_0)$, $f(g(f(x_0)))$, $\cdots$ must be an element of $f(X)$ by definition. So it must be a term of the form like $g^{-1}(x_0)$ which is not an element of $f(X)$. Now I am not exactly sure how to complete the remainder of the question, that is, the chains in $B$ must be of the form given in the question.",,"['functions', 'elementary-set-theory']"
37,Fibonacci induction stuck in adding functions together,Fibonacci induction stuck in adding functions together,,"Using Fibonacci... I am Proving: $$f_3 + f_6 + \cdots + f_{3n} = \frac12(f_{3n+2}-1) $$ I did the assumption of $f_1$ which gave $\mathrm{LHS}=2=\mathrm{RHS}$. For the second part where it is $n+1$ I am having problem adding the RHS: $$f_3 + f_6 + \cdots + f_{3n}+ f_{3(n+1)} = \frac12(f_{3(n+1)+2}-1) $$ Here is the problem as I have no knowledge of how to make the function into the previous: $$\mathrm{RHS} = \frac12(f_{3n+2}-1)+f_{3(n+1)} $$ Thanks in advance... Also, if anyone got any information on properties for functions would be greatly appreciated. Edit: Aww I understand now because in Fibonacci we can see that F(0) + f(1) = f(2) so in that perspective you can add them like that. ^^ Thank you guys... btw, it is not letting me up vote, Mark good answer, or comment","Using Fibonacci... I am Proving: $$f_3 + f_6 + \cdots + f_{3n} = \frac12(f_{3n+2}-1) $$ I did the assumption of $f_1$ which gave $\mathrm{LHS}=2=\mathrm{RHS}$. For the second part where it is $n+1$ I am having problem adding the RHS: $$f_3 + f_6 + \cdots + f_{3n}+ f_{3(n+1)} = \frac12(f_{3(n+1)+2}-1) $$ Here is the problem as I have no knowledge of how to make the function into the previous: $$\mathrm{RHS} = \frac12(f_{3n+2}-1)+f_{3(n+1)} $$ Thanks in advance... Also, if anyone got any information on properties for functions would be greatly appreciated. Edit: Aww I understand now because in Fibonacci we can see that F(0) + f(1) = f(2) so in that perspective you can add them like that. ^^ Thank you guys... btw, it is not letting me up vote, Mark good answer, or comment",,"['functions', 'induction', 'fibonacci-numbers']"
38,Proving that there exists a local minimum between two local maximums of a continuous function,Proving that there exists a local minimum between two local maximums of a continuous function,,Suppose f is a continuous function that has local maximums at points $x_{1}$ and $x_{2}$. How do I prove that there is a third point between these two points which is a local minimum of f? Need some help thanks.,Suppose f is a continuous function that has local maximums at points $x_{1}$ and $x_{2}$. How do I prove that there is a third point between these two points which is a local minimum of f? Need some help thanks.,,['real-analysis']
39,Logarithmic function,Logarithmic function,,Compute the value of $f\bigl(\frac{1}{400}\bigr)$ if the function is defined as follows : $f(xy) = f(x) + f(y)$ and $f(4)= 16$,Compute the value of $f\bigl(\frac{1}{400}\bigr)$ if the function is defined as follows : $f(xy) = f(x) + f(y)$ and $f(4)= 16$,,['functions']
40,Inverse function of $y=x+kx^3$,Inverse function of,y=x+kx^3,"I want to invert the following function with respect to $x$: $$f(x, k)=x+k x^3$$ where typical values for $x$ are between $0$ and $100$ and typical values for $k$ are between $-0.00005$ and $0.00005$. Further, it is known that: $$k >-\frac{1}{3x^2}$$ therefore, the function should be invertible. The derivatives: $$\begin{align}\frac{df}{dx}&=1+3kx^2\\ \frac{df}{dk} &= x^3\end{align}$$ are non-negative for all possible values of x and k. So the Function $f$ is monotonically increasing in both dimensions. I need the function $g(y, k)$ so that $g(f(x, k), k) = x$ for all $x$ and all $k$. What I have tried: The following function returns correct values for all $k>0$. For negative $k$ it does not work (returns complex numbers). $$w = \sqrt[3]{\frac{y}{2 k} + \sqrt{\frac{y^2}{4 k^2} + \frac{1}{27 k^3}}}\\ g(y,k) = w - \frac{1}{3 kw}$$","I want to invert the following function with respect to $x$: $$f(x, k)=x+k x^3$$ where typical values for $x$ are between $0$ and $100$ and typical values for $k$ are between $-0.00005$ and $0.00005$. Further, it is known that: $$k >-\frac{1}{3x^2}$$ therefore, the function should be invertible. The derivatives: $$\begin{align}\frac{df}{dx}&=1+3kx^2\\ \frac{df}{dk} &= x^3\end{align}$$ are non-negative for all possible values of x and k. So the Function $f$ is monotonically increasing in both dimensions. I need the function $g(y, k)$ so that $g(f(x, k), k) = x$ for all $x$ and all $k$. What I have tried: The following function returns correct values for all $k>0$. For negative $k$ it does not work (returns complex numbers). $$w = \sqrt[3]{\frac{y}{2 k} + \sqrt{\frac{y^2}{4 k^2} + \frac{1}{27 k^3}}}\\ g(y,k) = w - \frac{1}{3 kw}$$",,"['functions', 'inverse']"
41,If $f$ = $f^{-1}$ then $f(x) = x$ for some $x$,If  =  then  for some,f f^{-1} f(x) = x x,"I would like to know if the following suffices to prove the proposition below. While I can't see anything wrong with it, it gives me a strange feeling. Proposition: If $f$ is a continuous function on $\mathbb{R}$ and $f = f^{-1}$, prove that there is at least one $x$ such that $f(x) = x$. Proof: If there did not exist such an $x$, then we would have $f(y) > y$ or $f(y) < y$ for all $y \in \mathbb{R}$. Assume the former. In such a case, it follows that $$ f(f(y)) > f (y) > y $$ yet by definition we have $f = f^{-1}$ and so $$ f(f(y)) = y $$ This is a contradiction and proves the assertion.","I would like to know if the following suffices to prove the proposition below. While I can't see anything wrong with it, it gives me a strange feeling. Proposition: If $f$ is a continuous function on $\mathbb{R}$ and $f = f^{-1}$, prove that there is at least one $x$ such that $f(x) = x$. Proof: If there did not exist such an $x$, then we would have $f(y) > y$ or $f(y) < y$ for all $y \in \mathbb{R}$. Assume the former. In such a case, it follows that $$ f(f(y)) > f (y) > y $$ yet by definition we have $f = f^{-1}$ and so $$ f(f(y)) = y $$ This is a contradiction and proves the assertion.",,"['real-analysis', 'functions']"
42,Proof with function composition,Proof with function composition,,"Prove or disprove the following statement:   Function $f: S \rightarrow S$, where $S$ is non-empty, is bijective if and only if there exist unique functions $g, h : S \rightarrow S$ such that   $$ f \circ g = f ~~~~ \text{and} ~~~~ h \circ f = f$$ Since this is a logical equivalence I need to prove both implications. $A$ is that $f$ is bijective. $B$ that $g$ and $h$ are unique. If I assume that $g$ and $h$ aren't unique I can use the inverse of $f$ to easily show the contradiction. How to prove $B \implies A$?","Prove or disprove the following statement:   Function $f: S \rightarrow S$, where $S$ is non-empty, is bijective if and only if there exist unique functions $g, h : S \rightarrow S$ such that   $$ f \circ g = f ~~~~ \text{and} ~~~~ h \circ f = f$$ Since this is a logical equivalence I need to prove both implications. $A$ is that $f$ is bijective. $B$ that $g$ and $h$ are unique. If I assume that $g$ and $h$ aren't unique I can use the inverse of $f$ to easily show the contradiction. How to prove $B \implies A$?",,[]
43,If $f \circ g$ is onto then $f$ is onto and if $f \circ g$ is one-to-one then $g$ is one-to-one,If  is onto then  is onto and if  is one-to-one then  is one-to-one,f \circ g f f \circ g g,"I am trying to make a picture in my head so I can understand and remember the rules. So if $f \circ g$ is onto, it is onto because the function $f$ maps every element from a set $B$ to a set $C$ (thus $f$ is onto) and if $f \circ g$ is one-to-one then every element from set $A$ is mapping an element of set $B$ (and thus is one-to-one). If both $f$ and $g$ is onto then $f \circ g$ is onto and if both $f$ and $g$ is one-to-one then $f \circ g$ is one-to-one and if both $f$ and $g$ are bijective then $f \circ g$ is bijective? If $f \circ g$ is bijective, we can't say anything, but that $f$ is onto and that $g$ is one-to-one? If $f$ is onto and $g$ is one-to-one, nothing can be said? If $g$ is one-to-one and $g$ is onto, nothing can be said?","I am trying to make a picture in my head so I can understand and remember the rules. So if $f \circ g$ is onto, it is onto because the function $f$ maps every element from a set $B$ to a set $C$ (thus $f$ is onto) and if $f \circ g$ is one-to-one then every element from set $A$ is mapping an element of set $B$ (and thus is one-to-one). If both $f$ and $g$ is onto then $f \circ g$ is onto and if both $f$ and $g$ is one-to-one then $f \circ g$ is one-to-one and if both $f$ and $g$ are bijective then $f \circ g$ is bijective? If $f \circ g$ is bijective, we can't say anything, but that $f$ is onto and that $g$ is one-to-one? If $f$ is onto and $g$ is one-to-one, nothing can be said? If $g$ is one-to-one and $g$ is onto, nothing can be said?",,"['functions', 'elementary-set-theory', 'function-and-relation-composition']"
44,"Suppose I've an equation $1/x = 5$, then is it the same as an equation $5x=1$?","Suppose I've an equation , then is it the same as an equation ?",1/x = 5 5x=1,"This is giving me some headache. Suppose I have an equation $$\frac{1}{x}=5$$ Then is this equation the same as $$1=5x\quad ?$$ Now the domain of $x$ in the first equation is $\mathbb{R}\setminus \{0\}$, however the domain of $x$ in the second equation is the whole $\mathbb{R}$. Does rearranging terms change the meaning (I don't know the right word here) of equations?","This is giving me some headache. Suppose I have an equation $$\frac{1}{x}=5$$ Then is this equation the same as $$1=5x\quad ?$$ Now the domain of $x$ in the first equation is $\mathbb{R}\setminus \{0\}$, however the domain of $x$ in the second equation is the whole $\mathbb{R}$. Does rearranging terms change the meaning (I don't know the right word here) of equations?",,['functions']
45,Can piecewise defined functions always be differentiated piece by piece?,Can piecewise defined functions always be differentiated piece by piece?,,Guess you have a function $f(x) : \mathbb{R} \rightarrow \mathbb{R}$ (or a subset of $\mathbb{R}$) with $f (x) := \begin{cases} x^3  & \text{if } x \geq 0 \\ x^2 & \text{otherwise} \end{cases} $. The derivative $f': \mathbb{R} \rightarrow \mathbb{R}$ of $f(x)$ is $f' (x) := \begin{cases} 3 \cdot x^2  & \text{if } x \geq 0 \\ 2 \cdot x & \text{otherwise} \end{cases}$. To get this derivative I could simply differentiate the first part and the second part. Can you calculate the derivative of every piecewise defined function this way? I recently saw Thomae's function: $f(x)=\begin{cases}   \frac{1}{q}  &\text{ if } x=\frac{p}{q}\mbox{ is a rational number}\\   0            &\text{ if } x \mbox{ is irrational}.  \end{cases}$ I thought there might be a differentiable function which is defined like that and which can't be derived simply by deriving it piece by piece.,Guess you have a function $f(x) : \mathbb{R} \rightarrow \mathbb{R}$ (or a subset of $\mathbb{R}$) with $f (x) := \begin{cases} x^3  & \text{if } x \geq 0 \\ x^2 & \text{otherwise} \end{cases} $. The derivative $f': \mathbb{R} \rightarrow \mathbb{R}$ of $f(x)$ is $f' (x) := \begin{cases} 3 \cdot x^2  & \text{if } x \geq 0 \\ 2 \cdot x & \text{otherwise} \end{cases}$. To get this derivative I could simply differentiate the first part and the second part. Can you calculate the derivative of every piecewise defined function this way? I recently saw Thomae's function: $f(x)=\begin{cases}   \frac{1}{q}  &\text{ if } x=\frac{p}{q}\mbox{ is a rational number}\\   0            &\text{ if } x \mbox{ is irrational}.  \end{cases}$ I thought there might be a differentiable function which is defined like that and which can't be derived simply by deriving it piece by piece.,,"['functions', 'derivatives']"
46,Domain with $\cosh(x)$,Domain with,\cosh(x),"Take the function $$y=\frac{\sqrt{\cosh\left(\frac{1+x}{x^2}\right) - 1}}{e^{\frac{2}{x-1}\log\left|x-1\right|}+1}$$ I have to find the domain of this function. These are the condition that I set up: $$\begin{cases} e^{\frac{2}{x-1}\log\left|x-1\right|}+1\neq 0&(1)\\ x-1\neq0&(2)\\ \left|x-1\right|>0&(3)\\ \cosh\left(\frac{1+x}{x^2}\right) - 1\ge0&(4)\\ x^2\neq0&(5) \end{cases}$$ And these are the results: $$\begin{cases} \forall x \in\mathbb{R}&(1)\\ x\neq1&(3)\\ \forall x \in\mathbb{R}&(4)\\ x\neq0&(5) \end{cases}$$ $(1)$ Denominator $(2)$ Denominator of the exponent $(3)$ Argument of the logarithm $(4)$ Argument of the root $(5)$ Denominator of the argument of $\cosh$ And this is the definition set of $y$: $$x\in(-\infty, 0)\cup(0, 1)\cup(1, +\infty)$$ I deleted $(2)$ because it's included in the $(3)$. The $(1)$ is verified for all $x$ because it's an exponential and because I set up the $(3)$ To solve $(3)$ I made the $\vee$ between $x-1<0$ and $x-1>0$. The $(4)$ is verfied for all $x$ because the range of $\cosh(x)$ is $[1;+\infty)$, so it's always greater or equal than $1$. So, is it correct? Or I was wrong something?","Take the function $$y=\frac{\sqrt{\cosh\left(\frac{1+x}{x^2}\right) - 1}}{e^{\frac{2}{x-1}\log\left|x-1\right|}+1}$$ I have to find the domain of this function. These are the condition that I set up: $$\begin{cases} e^{\frac{2}{x-1}\log\left|x-1\right|}+1\neq 0&(1)\\ x-1\neq0&(2)\\ \left|x-1\right|>0&(3)\\ \cosh\left(\frac{1+x}{x^2}\right) - 1\ge0&(4)\\ x^2\neq0&(5) \end{cases}$$ And these are the results: $$\begin{cases} \forall x \in\mathbb{R}&(1)\\ x\neq1&(3)\\ \forall x \in\mathbb{R}&(4)\\ x\neq0&(5) \end{cases}$$ $(1)$ Denominator $(2)$ Denominator of the exponent $(3)$ Argument of the logarithm $(4)$ Argument of the root $(5)$ Denominator of the argument of $\cosh$ And this is the definition set of $y$: $$x\in(-\infty, 0)\cup(0, 1)\cup(1, +\infty)$$ I deleted $(2)$ because it's included in the $(3)$. The $(1)$ is verified for all $x$ because it's an exponential and because I set up the $(3)$ To solve $(3)$ I made the $\vee$ between $x-1<0$ and $x-1>0$. The $(4)$ is verfied for all $x$ because the range of $\cosh(x)$ is $[1;+\infty)$, so it's always greater or equal than $1$. So, is it correct? Or I was wrong something?",,['functions']
47,System of equations with Lambert $W$ function,System of equations with Lambert  function,W,"I have a system of equations with two equations containing the Lambert $W$ function as follows, $$\begin{cases} x = 1 - W_0(\frac{C_1 e^{y + 1}}{y + 1}) \\ y = 1 - W_0(\frac{C_2 e^{x + 1}}{x + 1}) \end{cases}$$ I have already solved the system numerically using a simple iterative method. A gentleman told me that the answer to the system is $y = \frac{k_1 - k_2 x}{k_1 x - k_2}$ where $k_1 = C_2 - C_1$ and $k_2 = C_2 - C_1$ but I have no clue how can one compute the answer. How can I get the answer to the system (i.e the steps)? While we have two curves in the system of equation, the intersection (i.e the answer of the system) must be a point not a curve. But $y = \frac{k_1 - k_2 x}{k_1 x - k_2}$ is a hyperbola. How can I describe it?","I have a system of equations with two equations containing the Lambert $W$ function as follows, $$\begin{cases} x = 1 - W_0(\frac{C_1 e^{y + 1}}{y + 1}) \\ y = 1 - W_0(\frac{C_2 e^{x + 1}}{x + 1}) \end{cases}$$ I have already solved the system numerically using a simple iterative method. A gentleman told me that the answer to the system is $y = \frac{k_1 - k_2 x}{k_1 x - k_2}$ where $k_1 = C_2 - C_1$ and $k_2 = C_2 - C_1$ but I have no clue how can one compute the answer. How can I get the answer to the system (i.e the steps)? While we have two curves in the system of equation, the intersection (i.e the answer of the system) must be a point not a curve. But $y = \frac{k_1 - k_2 x}{k_1 x - k_2}$ is a hyperbola. How can I describe it?",,"['functions', 'lambert-w']"
48,"Definition of functions based on ""fuzzy"" truth table","Definition of functions based on ""fuzzy"" truth table",,"I'm stuck on this problem: I have a ""truth-table"" (well, I don't know if it can be called truth table, if there aren't true/false values only): string |  a |  b ---------------------       x |  1 |  0       z |  1 |  0      xx |  1 |  1      xz |  1 |  1      zx |  1 | -1      zz |  1 | -1     xxx |  0 |  1     xxz |  0 |  1     xzx |  2 |  1     xzz |  2 |  1     zxx |  2 | -1     zxz |  2 | -1     zzx |  0 | -1     zzz |  0 | -1 ... the list goes on for string of any length, e.g. xxzxxzxxzzxzzxx -> a = -4, b = -1. I can calculate the a and b values from a given string, but the number of steps grows with the length of the string. I am hoping for some kind of better algorithm. Edit: Here is my original algorithm: rotation = 0 // 0 -> up, 1 -> right, 2 -> down, 3 -> left pos_x = 0    // this is the ""b"" pos_y = 0    // this is the ""a""  function rotate (n):     rotation += n     rotation %= 4 // result is positive integer, e.g. -1 % 4 = 3  function forward (n):     if n == 0: pos_y++     if n == 1: pos_x++     if n == 2: pos_y--     if n == 3: pos_x--  for char in string:     forward()     if char == ""x"": rotate(1)  // to the right     else:           rotate(-1) // to the left I can easily get the final rotation from a string: function final_rotation (n):     rot = (number of occurences of ""x"") - (number of occurences of ""z"")     rot %= 4     return rot But the pos_x and pos_y (or a and b)? No idea :/ The Karnaugh-maps came to my mind - but I'm unsure how to deal with this, since the values of a and b aren't true/false, but integers. Also it looks like it's ternary logic, because of the three possible states of string[position] - x, z, none . As far as I understand this, the last (rightmost) letter of a string doesn't have a say in what the a and b values will be. But what does? So, my question is - how to find the algorithm for a and b ?","I'm stuck on this problem: I have a ""truth-table"" (well, I don't know if it can be called truth table, if there aren't true/false values only): string |  a |  b ---------------------       x |  1 |  0       z |  1 |  0      xx |  1 |  1      xz |  1 |  1      zx |  1 | -1      zz |  1 | -1     xxx |  0 |  1     xxz |  0 |  1     xzx |  2 |  1     xzz |  2 |  1     zxx |  2 | -1     zxz |  2 | -1     zzx |  0 | -1     zzz |  0 | -1 ... the list goes on for string of any length, e.g. xxzxxzxxzzxzzxx -> a = -4, b = -1. I can calculate the a and b values from a given string, but the number of steps grows with the length of the string. I am hoping for some kind of better algorithm. Edit: Here is my original algorithm: rotation = 0 // 0 -> up, 1 -> right, 2 -> down, 3 -> left pos_x = 0    // this is the ""b"" pos_y = 0    // this is the ""a""  function rotate (n):     rotation += n     rotation %= 4 // result is positive integer, e.g. -1 % 4 = 3  function forward (n):     if n == 0: pos_y++     if n == 1: pos_x++     if n == 2: pos_y--     if n == 3: pos_x--  for char in string:     forward()     if char == ""x"": rotate(1)  // to the right     else:           rotate(-1) // to the left I can easily get the final rotation from a string: function final_rotation (n):     rot = (number of occurences of ""x"") - (number of occurences of ""z"")     rot %= 4     return rot But the pos_x and pos_y (or a and b)? No idea :/ The Karnaugh-maps came to my mind - but I'm unsure how to deal with this, since the values of a and b aren't true/false, but integers. Also it looks like it's ternary logic, because of the three possible states of string[position] - x, z, none . As far as I understand this, the last (rightmost) letter of a string doesn't have a say in what the a and b values will be. But what does? So, my question is - how to find the algorithm for a and b ?",,"['algorithms', 'functions', 'fuzzy-logic']"
49,Hardy-Littlewood maximal function of a function supported in the unit ball,Hardy-Littlewood maximal function of a function supported in the unit ball,,"This question comes from Stein’s Note on the class $L\log L$ . In the proof for Theorem 1, which establishes for an integrable function $f\in L^1(\mathbb R^n)$ supported on a finite ball $B$ , that the (centered) Hardy-Littlewood maximal function $Mf$ is integrable implies $f\in L\log L$ , i.e. $\int_B |f|\log^+|f|dx\lt\infty$ , the following is stated: We observe that if $f$ is supported in $B$ and $Mf$ is integrable over $B$ , then $Mf$ is integrable over $B’$ . In fact, suppose for simplicity that $B=\{x:|x|\le 1\}$ , and $B’=\{x:|x|\le 2\}$ . Then if $x\in B’-B$ , we can easily verify that $Mf(x)\le cMf(\bar x)$ , where $\bar x=x/|x|^2$ . Here $c=n^{n/2}\omega_n$ , where $n$ is the dimension of the space and $\omega_n$ is the volume of the unit $n$ -dimensional ball. However, I don’t find this obvious. It seems rather counterintuitive how the factor $n^{n/2}$ comes in, as that was the factor between the volume of a cube and a ball with the same (or proportional) diameter. This is how $c$ appeared in the paper at first. For reference, please see this other post . But in the part quoted above, there didn’t seem to be any obvious cubes involved. Some observations: $Mf(\bar x)$ is achieved at $B(x,r)$ with $r=\min(|\bar x|,1-|\bar x|)$ , since the argument inside the supremum (in the definition of $Mf$ ) could be thought of as a kind of concentration, and if the ball contains a region outside of the support of $f$ , this concentration will be diluted. If $n=1, \dfrac{1}{|B(x,r)|}\int_{B(x,r)\cap [-1,1]}|f|$ increases with $r$ for $x\in B’-B$ if $B(x,r)\cap [-1,1]$ is a nonempty proper subset of $[-1,1]$ . $Mf(x)$ is achieved when $B(x,r)$ covers all of $[-1,1]$ . It seems this is generalizable to higher dimensions, although I haven’t yet been successful in rigorously showing that. $|x-\bar x|=|x|-1/|x|$ . If $r\gt |x-\bar x|$ , then $B(\bar x,r)\supset B(x,r-|x-\bar x|$ . Either a rigorous proof of the quoted part or an intuitive argument would be appreciated. In the meantime I might add more stuff if I do find more related to this part.","This question comes from Stein’s Note on the class . In the proof for Theorem 1, which establishes for an integrable function supported on a finite ball , that the (centered) Hardy-Littlewood maximal function is integrable implies , i.e. , the following is stated: We observe that if is supported in and is integrable over , then is integrable over . In fact, suppose for simplicity that , and . Then if , we can easily verify that , where . Here , where is the dimension of the space and is the volume of the unit -dimensional ball. However, I don’t find this obvious. It seems rather counterintuitive how the factor comes in, as that was the factor between the volume of a cube and a ball with the same (or proportional) diameter. This is how appeared in the paper at first. For reference, please see this other post . But in the part quoted above, there didn’t seem to be any obvious cubes involved. Some observations: is achieved at with , since the argument inside the supremum (in the definition of ) could be thought of as a kind of concentration, and if the ball contains a region outside of the support of , this concentration will be diluted. If increases with for if is a nonempty proper subset of . is achieved when covers all of . It seems this is generalizable to higher dimensions, although I haven’t yet been successful in rigorously showing that. . If , then . Either a rigorous proof of the quoted part or an intuitive argument would be appreciated. In the meantime I might add more stuff if I do find more related to this part.","L\log L f\in L^1(\mathbb R^n) B Mf f\in L\log L \int_B |f|\log^+|f|dx\lt\infty f B Mf B Mf B’ B=\{x:|x|\le 1\} B’=\{x:|x|\le 2\} x\in B’-B Mf(x)\le cMf(\bar x) \bar x=x/|x|^2 c=n^{n/2}\omega_n n \omega_n n n^{n/2} c Mf(\bar x) B(x,r) r=\min(|\bar x|,1-|\bar x|) Mf f n=1, \dfrac{1}{|B(x,r)|}\int_{B(x,r)\cap [-1,1]}|f| r x\in B’-B B(x,r)\cap [-1,1] [-1,1] Mf(x) B(x,r) [-1,1] |x-\bar x|=|x|-1/|x| r\gt |x-\bar x| B(\bar x,r)\supset B(x,r-|x-\bar x|","['real-analysis', 'functions', 'lebesgue-measure', 'intuition']"
50,Smoothening a continuous piecewiese smooth function on $\mathbb R$ around one point only?,Smoothening a continuous piecewiese smooth function on  around one point only?,\mathbb R,"Let $f:\mathbb R \to \mathbb R$ be a continuous function and smooth on $(-\infty,0)$ and $(0,+\infty)$ respectively. For any $\epsilon>0, a>0$ , can we always find a smooth function $g:\mathbb R \to \mathbb R$ such that $g|_{\mathbb R\backslash (-a,a)}=f$ and the uniform norm $\|g-f\|_{\mathbb R}<\epsilon$ ? Is there an explicit construction (I am okay with abtract non-constructive proof, though)? I am aware of https://en.wikipedia.org/wiki/Mollifier , but the convolution there changes $f$ globally not locally.","Let be a continuous function and smooth on and respectively. For any , can we always find a smooth function such that and the uniform norm ? Is there an explicit construction (I am okay with abtract non-constructive proof, though)? I am aware of https://en.wikipedia.org/wiki/Mollifier , but the convolution there changes globally not locally.","f:\mathbb R \to \mathbb R (-\infty,0) (0,+\infty) \epsilon>0, a>0 g:\mathbb R \to \mathbb R g|_{\mathbb R\backslash (-a,a)}=f \|g-f\|_{\mathbb R}<\epsilon f","['real-analysis', 'calculus', 'functions']"
51,Increasing quintic polynomial,Increasing quintic polynomial,,"If $$ f(x) = \frac{x^5}{5} + \frac{x^4}{4} + x^3 + \frac{kx^2}{2} + x $$ is a real valued function, then find the interval for $k$ such that $f(x)$ is increasing for all $x$ . My attempt: For $f'(x) \geq 0$ , I have been able to ascertain that $y=-kx$ needs to be tangent to the curve $$ x^4 + x^3 + 3x^2 + 1. $$ But then I get a very complicated set of equations, which seem difficult to solve without the help of a computer.","If is a real valued function, then find the interval for such that is increasing for all . My attempt: For , I have been able to ascertain that needs to be tangent to the curve But then I get a very complicated set of equations, which seem difficult to solve without the help of a computer.","
f(x) = \frac{x^5}{5} + \frac{x^4}{4} + x^3 + \frac{kx^2}{2} + x
 k f(x) x f'(x) \geq 0 y=-kx 
x^4 + x^3 + 3x^2 + 1.
","['calculus', 'functions', 'derivatives']"
52,Coefficients of Chebyshev polynomials,Coefficients of Chebyshev polynomials,,"Not long ago, I derived the formula for Chebyshev polynomials $$T_{n}\left( x\right)= \sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}{n \choose 2k}x^{n-2k}\left( x^2-1\right)^{k}$$ How to extract the coefficients of this polynomial of degree $n$ ? I tried using Newton's binomial but got a double sum $$\sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}{n \choose 2k}x^{n-2k}\left(  \sum_{m=0}^{k} {k \choose m} x^{2m}\left( -1\right)^{k-m}  \right) \\ \sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}\sum_{m=0}^{k}\left( -1\right)^{k-m} {n \choose 2k}  \cdot {k \choose m} x^{n+2m-2k}\\  $$ Now how to continue counting this sum ? What would it look like to change the order of summation and would it do anything ? What else did I try ? Well, I worked out the sum $$\sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}{n \choose 2k}x^{n-2k}\left( x^2-1\right)^{k} $$ for $n=8$ and I hypothesized that $$T_{n}\left( x\right)= \sum_{k=0}^{\lfloor \frac{n}{2} \rfloor}  \sum_{m=k}^{\lfloor \frac{n}{2} \rfloor}\left( -1\right)^{k}{n \choose 2m}  \cdot {m \choose k} x^{n-2k} $$ However, it would be useful to demonstrate the correctness of this hypothesis and count the sum of $$\sum_{m=k}^{\lfloor \frac{n}{2} \rfloor}{n \choose 2m}  \cdot {m \choose k}$$ Here I would like to point out that Wolfram Alpha counts this sum incorrectly $$\sum_{m=k}^{\lfloor \frac{n}{2}\rfloor}{{n \choose 2m} \cdot  {m \choose k}}  = \frac{n}{2n-2k}  \cdot 2^{n-2k} \cdot {n - k \choose k}$$ And it would even be a nice result but first of all it is not quite correct ( Have you noticed why ?) and secondly it comes from a hypothesis I made after dissecting the formula for $n=8$ . It seems to me that this hypothesis of mine would be enough to prove by induction after n but how would it look? How to calculate the coefficients of the Chebyshev polynomial ? Are you sure they will be the sum of products of Bernoulli numbers and Newton symbol since, after working out the formula, I came out that it would be $$T_{n}\left( x\right)= \sum_{k=0}^{\lfloor\frac{n}{2}\rfloor}  \sum_{m=k}^{\lfloor\frac{n}{2}\rfloor}\left( -1\right)^{k} {n \choose 2m} \cdot  {m \choose k}  x^{n-2k}$$ Please help.","Not long ago, I derived the formula for Chebyshev polynomials How to extract the coefficients of this polynomial of degree ? I tried using Newton's binomial but got a double sum Now how to continue counting this sum ? What would it look like to change the order of summation and would it do anything ? What else did I try ? Well, I worked out the sum for and I hypothesized that However, it would be useful to demonstrate the correctness of this hypothesis and count the sum of Here I would like to point out that Wolfram Alpha counts this sum incorrectly And it would even be a nice result but first of all it is not quite correct ( Have you noticed why ?) and secondly it comes from a hypothesis I made after dissecting the formula for . It seems to me that this hypothesis of mine would be enough to prove by induction after n but how would it look? How to calculate the coefficients of the Chebyshev polynomial ? Are you sure they will be the sum of products of Bernoulli numbers and Newton symbol since, after working out the formula, I came out that it would be Please help.","T_{n}\left( x\right)= \sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}{n \choose 2k}x^{n-2k}\left( x^2-1\right)^{k} n \sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}{n \choose 2k}x^{n-2k}\left(  \sum_{m=0}^{k} {k \choose m} x^{2m}\left( -1\right)^{k-m}  \right) \\
\sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}\sum_{m=0}^{k}\left( -1\right)^{k-m} {n \choose 2k}  \cdot {k \choose m} x^{n+2m-2k}\\
  \sum_{k=0}^{\lfloor  \frac{n}{2} \rfloor}{n \choose 2k}x^{n-2k}\left( x^2-1\right)^{k}  n=8 T_{n}\left( x\right)= \sum_{k=0}^{\lfloor \frac{n}{2} \rfloor}  \sum_{m=k}^{\lfloor \frac{n}{2} \rfloor}\left( -1\right)^{k}{n \choose 2m}  \cdot {m \choose k} x^{n-2k}  \sum_{m=k}^{\lfloor \frac{n}{2} \rfloor}{n \choose 2m}  \cdot {m \choose k} \sum_{m=k}^{\lfloor \frac{n}{2}\rfloor}{{n \choose 2m} \cdot  {m \choose k}}  = \frac{n}{2n-2k}  \cdot 2^{n-2k} \cdot {n - k \choose k} n=8 T_{n}\left( x\right)= \sum_{k=0}^{\lfloor\frac{n}{2}\rfloor}  \sum_{m=k}^{\lfloor\frac{n}{2}\rfloor}\left( -1\right)^{k} {n \choose 2m} \cdot  {m \choose k}  x^{n-2k}","['functions', 'elementary-functions', 'chebyshev-polynomials']"
53,"Are there any results associated with $\int_{0}^{n} f(x)f(x+1) \cdots f(x+n) \,dx$?",Are there any results associated with ?,"\int_{0}^{n} f(x)f(x+1) \cdots f(x+n) \,dx","I recently found a YouTube video that solves the following integral: $\int_{0}^{1} \ln(x)\ln(x+1) \,dx$ This made me curious if we could generalize the integral and if there are any results or bounds associated with it. Is $\int_{0}^{n} f(x)f(x+1) \cdots f(x+n) \,dx$ guaranteed to have a closed-form solution, if we assume that $f:[a,b]\rightarrow \mathbb{R}$ is continuous? This is my first post so my apologies if there's something wrong with my post.","I recently found a YouTube video that solves the following integral: This made me curious if we could generalize the integral and if there are any results or bounds associated with it. Is guaranteed to have a closed-form solution, if we assume that is continuous? This is my first post so my apologies if there's something wrong with my post.","\int_{0}^{1} \ln(x)\ln(x+1) \,dx \int_{0}^{n} f(x)f(x+1) \cdots f(x+n) \,dx f:[a,b]\rightarrow \mathbb{R}","['calculus', 'integration', 'functions']"
54,$g$ attains both maximum and minimum over $\mathbb{R}$. $f$ is continuous on range of $g$. Does $f\circ g$ necessarily attain maximum on $\mathbb{R}$?,attains both maximum and minimum over .  is continuous on range of . Does  necessarily attain maximum on ?,g \mathbb{R} f g f\circ g \mathbb{R},"Let $g:\mathbb{R}\to\mathbb{R}$ be a function (not necessarily continuous) which attains both its maximum and minimum on $\mathbb{R}$ . Let $f:\mathbb{R} \to \mathbb{R}$ is a function which is continuous on range of $g$ . Does $f\circ g$ necessarily have a maximum on $\mathbb{R}$ ? Prove or provide a counterexample. My Solution: I don't think that it necessarily attains its maximum on $\mathbb{R}$ . I had thought of the following example: Let $$g(x) := \begin{cases} x^2 &\text{if}\; 0<x\leq 10 \\\; 1&\text{otherwise}\\ \end{cases}$$ The range of $g$ is $(0,100]$ . let $f(x) = \frac{1}{\sqrt x}$ . Note that $f$ is continuous on the range of $g$ . $$(f \circ g )(x)= \begin{cases} \frac{1}{x}&\text{if}\;0<x\leq 10\\ 1&\text{otherwise}\\ \end{cases}$$ $(f \circ g )(x)$ does not attain its maximum on $\mathbb{R}$ . This is the example that I could come up with, however, $g(x)$ doesn't attain its minimum on $\mathbb{R}$ . I am unable to tweak it in a way so as to ensure that it does and the rest of it holds as well. Another example that I could come up with was the following: Let $$g(x) := \begin{cases} 1+x&\text{if}\; 0<x\leq100\\  -1&\text{otherwise} \end{cases}$$ The range of $g$ is $(1,101] \cup \{-1\}$ . Let $f(x) := \frac1x$ for all $x\in \mathbb{R}\backslash\{0\}$ . $$(f\circ g)(x)=\begin{cases} \frac1{1+x}&\text{if}\;0<x\leq 100\\ -1&\text{otherwise} \end{cases}$$ $g$ attains both maximum and minimum and $f\circ g$ does not attain its maximum. But I am unsure if $f$ is continuous on range of $g$ or not. $\frac1x$ is continuous everywhere except at $x=0$ . Is that justification enough?","Let be a function (not necessarily continuous) which attains both its maximum and minimum on . Let is a function which is continuous on range of . Does necessarily have a maximum on ? Prove or provide a counterexample. My Solution: I don't think that it necessarily attains its maximum on . I had thought of the following example: Let The range of is . let . Note that is continuous on the range of . does not attain its maximum on . This is the example that I could come up with, however, doesn't attain its minimum on . I am unable to tweak it in a way so as to ensure that it does and the rest of it holds as well. Another example that I could come up with was the following: Let The range of is . Let for all . attains both maximum and minimum and does not attain its maximum. But I am unsure if is continuous on range of or not. is continuous everywhere except at . Is that justification enough?","g:\mathbb{R}\to\mathbb{R} \mathbb{R} f:\mathbb{R} \to \mathbb{R} g f\circ g \mathbb{R} \mathbb{R} g(x) := \begin{cases}
x^2 &\text{if}\; 0<x\leq 10 \\\; 1&\text{otherwise}\\
\end{cases} g (0,100] f(x) = \frac{1}{\sqrt x} f g (f \circ g )(x)=
\begin{cases}
\frac{1}{x}&\text{if}\;0<x\leq 10\\ 1&\text{otherwise}\\
\end{cases} (f \circ g )(x) \mathbb{R} g(x) \mathbb{R} g(x) := \begin{cases}
1+x&\text{if}\; 0<x\leq100\\ 
-1&\text{otherwise}
\end{cases} g (1,101] \cup \{-1\} f(x) := \frac1x x\in \mathbb{R}\backslash\{0\} (f\circ g)(x)=\begin{cases}
\frac1{1+x}&\text{if}\;0<x\leq 100\\ -1&\text{otherwise}
\end{cases} g f\circ g f g \frac1x x=0","['real-analysis', 'functions', 'optimization', 'continuity']"
55,How do I find the function and derivative of an unknown curve?,How do I find the function and derivative of an unknown curve?,,"I have $x$ and $y$ values to plot the curve and I need to find a tangent line of slope 1 that intersects the curve (and the point at which it intersects). I was trying to do polynomial and exponential regression to model the data and fit the curve (in R) but cannot get it to work. It fits a majority of the data but not the curve and I need the function of the curve to find the derivative and tangent. I don't completely understand the math behind the modeling but all I know is that the fit is inaccurate when I plot it against my data. Is there any way I solve this mathematically? The curve starts slightly downwards, then slopes up gradually before it goes up exponentially If you do a density plot, most of the values are towards the lower end of y. the values of y are right skewed . This could be influencing my model, so would one solution be to remove multiple prior points? UPDATE: I tried to limit the number of points and now my plot looks like this (the line plotted is $8.950433e^{-20}\times1.006621^x$ ). The formula for the line was from taking the exponential regression of the data. From the formula, it kind of makes sense why it's a line but how do I get it to curve?","I have and values to plot the curve and I need to find a tangent line of slope 1 that intersects the curve (and the point at which it intersects). I was trying to do polynomial and exponential regression to model the data and fit the curve (in R) but cannot get it to work. It fits a majority of the data but not the curve and I need the function of the curve to find the derivative and tangent. I don't completely understand the math behind the modeling but all I know is that the fit is inaccurate when I plot it against my data. Is there any way I solve this mathematically? The curve starts slightly downwards, then slopes up gradually before it goes up exponentially If you do a density plot, most of the values are towards the lower end of y. the values of y are right skewed . This could be influencing my model, so would one solution be to remove multiple prior points? UPDATE: I tried to limit the number of points and now my plot looks like this (the line plotted is ). The formula for the line was from taking the exponential regression of the data. From the formula, it kind of makes sense why it's a line but how do I get it to curve?",x y 8.950433e^{-20}\times1.006621^x,"['functions', 'approximation', 'regression', 'mathematical-modeling', 'tangent-line']"
56,function decomposition given $f(g(x))$ and $g(f(x))$,function decomposition given  and,f(g(x)) g(f(x)),"Problem Find functions $f(x)$ and $g(x)$ such that $f(g(x))=x^2-2x-4$ and $g(f(x))=x^2-6x+6$ . Finding some points Notice that $f(g(f(x)))=f^2(x)-2f(x)-4=f(x^2-6x+6)$ and the equation $x^2-6x+6=x$ has roots $1$ and $6$ . This gives $f^2(1)-2f(1)-4=f(1)$ and $f^2(6)-2f(6)-4=f(6)$ . The former gives $f(1)=4$ or $f(1)=-1$ while the latter gives $f(6)=4$ or $f(6)=-1$ . Note that $g(f(1))=1$ and $g(f(6))=6$ . We have [( $f(1)=4$ and $g(4)=1$ ) or ( $f(1)=-1$ and $g(-1)=1$ )] and [( $f(6)=4$ and $g(4)=6$ ) or ( $f(6)=-1$ and $g(-1)=6$ )]. Similarly, notice that $g(f(g(x)))=g^2(x)-6g(x)+6=g(x^2-2x-4)$ and the equation $x^2-2x-4=x$ has roots $-1$ and $4$ . This gives $g^2(-1)-6g(-1)+6=g(-1)$ and $g^2(4)-6g(4)+6=g(4)$ . The former gives $g(-1)=1$ or $g(-1)=6$ while the latter gives $g(4)=1$ or $g(4)=6$ . Note that $f(g(-1))=-1$ and $f(g(4))=4$ . We have [( $g(-1)=1$ and $f(1)=-1$ ) or ( $g(-1)=6$ and $f(6)=-1$ )] and [( $g(4)=1$ and $f(1)=4$ ) or ( $g(4)=6$ and $f(6)=4$ )]. Polynomial solutions Assume that $f(x)$ and $g(x)$ are polynomials. Since $f(g(x))$ and $g(f(x))$ are monic and of degree $2=1\cdot 2$ . One of $f(x)$ and $g(x)$ is monic and of degree $2$ and the other is monic and of degree $1$ . Case 1: $f(x)$ is of degree $1$ . Let $f(x)=x+k$ . Then $f^{-1}(x)=x-k$ . Then $g(x)=f^{-1}(f(g(x)))=x^2-2x-4-k$ and $g(x)=g(f(f^{-1}(x)))=(x-k)^2-6(x-k)+6$ . By compare the coefficient of the $x$ term, $k=-2$ . Hence, $f(x)=x-2$ and $g(x)=x^2-2x-2$ . Case 2: $g(x)$ is of degree $1$ . Let $g(x)=x+k$ . Then $g^{-1}(x)=x-k$ . Then $f(x)=g^{-1}(g(f(x)))=x^2-6x+6-k$ and $f(x)=f(g(g^{-1}(x)))=(x-k)^2-2(x-k)-4$ . By compare the coefficient of the $x$ term, $k=2$ . Hence, $f(x)=x^2-6x+4$ and $g(x)=x+2$ . Question Notice that the solution in Case 1 matches the point ( $f(1)=-1$ and $g(-1)=1$ ) and the solution in Case 2 matches the points ( $f(6)=4$ and $g(4)=6$ ). My question is what solution (should be non-polynomial) of $f(x)$ and $g(x)$ matches the remaining points, namely ( $f(1)=4$ and $g(4)=1$ ) and ( $f(6)=-1$ and $g(-1)=6$ ).","Problem Find functions and such that and . Finding some points Notice that and the equation has roots and . This gives and . The former gives or while the latter gives or . Note that and . We have [( and ) or ( and )] and [( and ) or ( and )]. Similarly, notice that and the equation has roots and . This gives and . The former gives or while the latter gives or . Note that and . We have [( and ) or ( and )] and [( and ) or ( and )]. Polynomial solutions Assume that and are polynomials. Since and are monic and of degree . One of and is monic and of degree and the other is monic and of degree . Case 1: is of degree . Let . Then . Then and . By compare the coefficient of the term, . Hence, and . Case 2: is of degree . Let . Then . Then and . By compare the coefficient of the term, . Hence, and . Question Notice that the solution in Case 1 matches the point ( and ) and the solution in Case 2 matches the points ( and ). My question is what solution (should be non-polynomial) of and matches the remaining points, namely ( and ) and ( and ).",f(x) g(x) f(g(x))=x^2-2x-4 g(f(x))=x^2-6x+6 f(g(f(x)))=f^2(x)-2f(x)-4=f(x^2-6x+6) x^2-6x+6=x 1 6 f^2(1)-2f(1)-4=f(1) f^2(6)-2f(6)-4=f(6) f(1)=4 f(1)=-1 f(6)=4 f(6)=-1 g(f(1))=1 g(f(6))=6 f(1)=4 g(4)=1 f(1)=-1 g(-1)=1 f(6)=4 g(4)=6 f(6)=-1 g(-1)=6 g(f(g(x)))=g^2(x)-6g(x)+6=g(x^2-2x-4) x^2-2x-4=x -1 4 g^2(-1)-6g(-1)+6=g(-1) g^2(4)-6g(4)+6=g(4) g(-1)=1 g(-1)=6 g(4)=1 g(4)=6 f(g(-1))=-1 f(g(4))=4 g(-1)=1 f(1)=-1 g(-1)=6 f(6)=-1 g(4)=1 f(1)=4 g(4)=6 f(6)=4 f(x) g(x) f(g(x)) g(f(x)) 2=1\cdot 2 f(x) g(x) 2 1 f(x) 1 f(x)=x+k f^{-1}(x)=x-k g(x)=f^{-1}(f(g(x)))=x^2-2x-4-k g(x)=g(f(f^{-1}(x)))=(x-k)^2-6(x-k)+6 x k=-2 f(x)=x-2 g(x)=x^2-2x-2 g(x) 1 g(x)=x+k g^{-1}(x)=x-k f(x)=g^{-1}(g(f(x)))=x^2-6x+6-k f(x)=f(g(g^{-1}(x)))=(x-k)^2-2(x-k)-4 x k=2 f(x)=x^2-6x+4 g(x)=x+2 f(1)=-1 g(-1)=1 f(6)=4 g(4)=6 f(x) g(x) f(1)=4 g(4)=1 f(6)=-1 g(-1)=6,['functions']
57,What kind of function represents the Sophomore's Dream sum?,What kind of function represents the Sophomore's Dream sum?,,"I came across the following sum while studying the integral of $x^x$ : $$\int_0^1 x^x \,\text{d}x = \sum_{n=1}^\infty \frac{(-1)^{n-1}}{n^n} = 0.783430510712... $$ When I saw this, my first instinct was to think of the Dirichlet Eta Function : $$\eta({s}) = \sum_{n=1}^\infty \frac{(-1)^{n-1}}{n^s}$$ However, the term in the exponent of $n$ is, itself, changing with the sum, so this can't be it. I tried looking at other similar zeta functions , but most of them had the same issue. Is there a defined function that represents the former sum? I couldn't find one through my own research. Edit: (1) I now know that the official name for this sum is the Sophomore's Dream . However, I am still wondering if there is a way to represent this function using a zeta function, or something else that is similar. This question's previous title was ""Is this sum a variation of a zeta function, or something else?"" (2) Another similar function might be the series expansion of the principal Lambert W Function : $$W_0(x) = \sum_{n=1}^\infty \frac{(-n)^{n-1}}{n!}, |x|<\frac1e$$","I came across the following sum while studying the integral of : When I saw this, my first instinct was to think of the Dirichlet Eta Function : However, the term in the exponent of is, itself, changing with the sum, so this can't be it. I tried looking at other similar zeta functions , but most of them had the same issue. Is there a defined function that represents the former sum? I couldn't find one through my own research. Edit: (1) I now know that the official name for this sum is the Sophomore's Dream . However, I am still wondering if there is a way to represent this function using a zeta function, or something else that is similar. This question's previous title was ""Is this sum a variation of a zeta function, or something else?"" (2) Another similar function might be the series expansion of the principal Lambert W Function :","x^x \int_0^1 x^x \,\text{d}x = \sum_{n=1}^\infty \frac{(-1)^{n-1}}{n^n} = 0.783430510712...  \eta({s}) = \sum_{n=1}^\infty \frac{(-1)^{n-1}}{n^s} n W_0(x) = \sum_{n=1}^\infty \frac{(-n)^{n-1}}{n!}, |x|<\frac1e","['functions', 'summation']"
58,Let $f(x)=\begin{cases}2x+a;&x\ge-1\\bx^2+3;&x\lt-1\end{cases}$ and $g(x)=\begin{cases}x+4;&0\le x\le4\\-3x-2;&-2\lt x\lt0\end{cases}$ then $g(f(x))$,Let  and  then,f(x)=\begin{cases}2x+a;&x\ge-1\\bx^2+3;&x\lt-1\end{cases} g(x)=\begin{cases}x+4;&0\le x\le4\\-3x-2;&-2\lt x\lt0\end{cases} g(f(x)),"Let $$f(x)=\begin{cases}2x+a;&x\ge-1\\bx^2+3;&x\lt-1\end{cases}$$ and $$g(x)=\begin{cases}x+4;&0\le x\le4\\-3x-2;&-2\lt x\lt0\end{cases}$$ then $g(f(x))$ is not defined if $(1)\;a\in(10,\infty),b\in(5,\infty)$ $(2)\;a\in(4,10),b\in(5,\infty)$ $(3)\;a\in(10,\infty),b\in(0,1)$ $(4)\;a\in(4,10),b\in(1,5)$ My Attempt: $$g(f(x))=\begin{cases}f(x)+4;&0\le f(x)\le4\\-3f(x)-2;&-2\lt f(x)\lt0\end{cases}$$ So, $g(f(x))$ will not be defined if $f(x)\gt4$ or $f(x)\le-2$ Also, $f(x)=2x+a$ is an increasing function. So, its minimum value is at $x=-1$ i.e. $a-2$ For $g(f(x))$ to be not defined $a-2\gt4\implies a\gt6$ Also, $f(x)=bx^2+3$ is a parabola. If $b\lt0$ then it's a downward parabola, and its maximum value is $b+3$ . For $g(f(x))$ to be not defined, $b+3\le-2\implies b\le-5$ (is this correct?) If $b\gt0$ then $f(x)$ is an upward parabola and its minimum value is $b+3$ . For $g(f(x))$ to be not defined, $b+3\gt4\implies b\gt1$ Accordingly, I think option $(1)$ is correct. But is there a way to find the exhaustive domain of $a?$ In the hint, they have written $-2+a\gt8, b+3\gt8$ Seems like they have calculated the value of $g(x)$ at $x=4$ and then compared it with the values of $f(x)$ . But shouldn't we be comparing the domain (and not the range) of $g(x)$ with the range of $f(x)?$","Let and then is not defined if My Attempt: So, will not be defined if or Also, is an increasing function. So, its minimum value is at i.e. For to be not defined Also, is a parabola. If then it's a downward parabola, and its maximum value is . For to be not defined, (is this correct?) If then is an upward parabola and its minimum value is . For to be not defined, Accordingly, I think option is correct. But is there a way to find the exhaustive domain of In the hint, they have written Seems like they have calculated the value of at and then compared it with the values of . But shouldn't we be comparing the domain (and not the range) of with the range of","f(x)=\begin{cases}2x+a;&x\ge-1\\bx^2+3;&x\lt-1\end{cases} g(x)=\begin{cases}x+4;&0\le x\le4\\-3x-2;&-2\lt x\lt0\end{cases} g(f(x)) (1)\;a\in(10,\infty),b\in(5,\infty) (2)\;a\in(4,10),b\in(5,\infty) (3)\;a\in(10,\infty),b\in(0,1) (4)\;a\in(4,10),b\in(1,5) g(f(x))=\begin{cases}f(x)+4;&0\le f(x)\le4\\-3f(x)-2;&-2\lt f(x)\lt0\end{cases} g(f(x)) f(x)\gt4 f(x)\le-2 f(x)=2x+a x=-1 a-2 g(f(x)) a-2\gt4\implies a\gt6 f(x)=bx^2+3 b\lt0 b+3 g(f(x)) b+3\le-2\implies b\le-5 b\gt0 f(x) b+3 g(f(x)) b+3\gt4\implies b\gt1 (1) a? -2+a\gt8, b+3\gt8 g(x) x=4 f(x) g(x) f(x)?","['functions', 'inequality', 'conic-sections', 'piecewise-continuity']"
59,What determines how to treat single variable PDEs and thus their constants of integration?,What determines how to treat single variable PDEs and thus their constants of integration?,,"When solving a first-order ODE (perhaps there is also a way to extend this to a higher order ODE) for $y(x)$ , it is possible to shift perspective and consider $x$ to be a function of $y$ by manipulating the differential forms.  For example, $\frac{dy}{dx} = h(y)$ can be solved as $\frac{dx}{dy} = \frac{1}{h(y)}$ , which may be easier.  The moral of the story, very crudely stated, seems to be that derivatives are slopes, and we can inquire about the slope of any variable with respect to any other, regardless of which variables are ""actually independent"" at the end of the day. When solving a first-order PDE such as $u_t + 2xu_x = 0$ , one of the steps involves considering either $\frac{dt}{dx}$ or $\frac{dx}{dt}$ , even though both $x$ and $t$ are independent variables, which I'm fine with due to the above paragraph.  However, either of these derivatives are situated within a horizontal slice of $\mathbb{R}^3$ , where $u$ is the dimension orthogonal to that slice.  Thus these derivatives should technically be partials, and the ""ODEs"" they create technically single variable PDEs, and more importantly, the constant of integration encountered when we solve either of these ""ODEs"" should be a function of $u$ .  In this particular problem (solved using the choices made in the above timestamped video), we would get $x = K(u)e^{2t}$ , which produces the correct solution $u = f(xe^{-2t})$ after dividing through by $e^{2t}$ and taking $K^{-1}$ of both sides.  In other solution methods for first-order PDEs, constants are explicitly written as functions . Does thinking about the constant of integration as a function in the context of first-order PDEs always work as it does here, or is this a coincidence?  If not, then why is it correct to use a genuine constant here instead of a function of the dimension not involved in the derivative?  Again, I'm drawing the conclusion from the first paragraph that $u$ not ""actually"" being an independent variable makes little difference in this context. For separation of variables problems, it is similarly common to shorthand partial derivatives as ordinary derivatives once things are separated.  For example, if the PDE is $u_{xx} + u_{yy} = 0$ , and thus one of the separated equations is $Y_{yy} = \lambda Y$ , we often pretend this is the same thing as $Y'' = \lambda Y$ .  However, we are really solving the former, which takes place within a $2$ -dimensional slice of $\mathbb{R}^3$ , not the latter, which takes place within $\mathbb{R}^2$ .  Thus, if we solve it by guessing the particular solution $Y = e^{\sqrt\lambda y}$ and finding the general solution via reduction of order , it seems like we should, for both integrations that occur within reduction of order, write the constants as arbitrary functions of $x$ , since integrating within a ""constant $x$ slice"" of $\mathbb{R}^3$ should yield that arbitrary function.  Why is it correct to use a genuine constant here? Is there a systematic way to decide when integration constants in a three-dimensional problem should be functions, or does it come down to memorizing the decisions presented along with each solution method?","When solving a first-order ODE (perhaps there is also a way to extend this to a higher order ODE) for , it is possible to shift perspective and consider to be a function of by manipulating the differential forms.  For example, can be solved as , which may be easier.  The moral of the story, very crudely stated, seems to be that derivatives are slopes, and we can inquire about the slope of any variable with respect to any other, regardless of which variables are ""actually independent"" at the end of the day. When solving a first-order PDE such as , one of the steps involves considering either or , even though both and are independent variables, which I'm fine with due to the above paragraph.  However, either of these derivatives are situated within a horizontal slice of , where is the dimension orthogonal to that slice.  Thus these derivatives should technically be partials, and the ""ODEs"" they create technically single variable PDEs, and more importantly, the constant of integration encountered when we solve either of these ""ODEs"" should be a function of .  In this particular problem (solved using the choices made in the above timestamped video), we would get , which produces the correct solution after dividing through by and taking of both sides.  In other solution methods for first-order PDEs, constants are explicitly written as functions . Does thinking about the constant of integration as a function in the context of first-order PDEs always work as it does here, or is this a coincidence?  If not, then why is it correct to use a genuine constant here instead of a function of the dimension not involved in the derivative?  Again, I'm drawing the conclusion from the first paragraph that not ""actually"" being an independent variable makes little difference in this context. For separation of variables problems, it is similarly common to shorthand partial derivatives as ordinary derivatives once things are separated.  For example, if the PDE is , and thus one of the separated equations is , we often pretend this is the same thing as .  However, we are really solving the former, which takes place within a -dimensional slice of , not the latter, which takes place within .  Thus, if we solve it by guessing the particular solution and finding the general solution via reduction of order , it seems like we should, for both integrations that occur within reduction of order, write the constants as arbitrary functions of , since integrating within a ""constant slice"" of should yield that arbitrary function.  Why is it correct to use a genuine constant here? Is there a systematic way to decide when integration constants in a three-dimensional problem should be functions, or does it come down to memorizing the decisions presented along with each solution method?",y(x) x y \frac{dy}{dx} = h(y) \frac{dx}{dy} = \frac{1}{h(y)} u_t + 2xu_x = 0 \frac{dt}{dx} \frac{dx}{dt} x t \mathbb{R}^3 u u x = K(u)e^{2t} u = f(xe^{-2t}) e^{2t} K^{-1} u u_{xx} + u_{yy} = 0 Y_{yy} = \lambda Y Y'' = \lambda Y 2 \mathbb{R}^3 \mathbb{R}^2 Y = e^{\sqrt\lambda y} x x \mathbb{R}^3,"['functions', 'partial-differential-equations', '3d', 'surfaces', 'constants']"
60,"Prove that $f(x)^2+f(x+1)^2 = f(2x+1)$ for the function $f$ satisfying $f(x)=f(x-1)+f(x-2), f(1)=f(2)=1.$",Prove that  for the function  satisfying,"f(x)^2+f(x+1)^2 = f(2x+1) f f(x)=f(x-1)+f(x-2), f(1)=f(2)=1.","Prove that $f(x)^2+f(x+1)^2 = f(2x+1)$ for the function $f$ satisfying $f(x)=f(x-1)+f(x-2), f(1)=f(2)=1.$ I know how to prove it, but it is interesting so I am posting it. The first hint is: \begin{align} &\text{Try to prove this first: } \\ &f(x)=f(x-1)+f(x-2) \\ &=2f(x-2)+f(x-3) \\ &=3f(x-3)+2f(x-4) \\ &= 5f(x-4)+3f(x-3) \\ &= \cdot \cdot \cdot \end{align} The second hint is: $\text{According to the first hint: } f(x)=f(k+1)f(x-k)+f(k)f(x-k-1). $ Check this to see that your proof is the same as mine. \begin{align} &f(x)=f(x-1)+f(x-2) = f(2)f(x-1)+f(1)f(x-2). \ \\ \ \\ &f(x-1)=f(x-2)+f(x-3) \\ &\Rightarrow f(x)=f(2)(f(x-2)+f(x-3))+f(1)f(x-2)=(f(1)+f(2))f(x-2) \\ &+f(2)f(x-3)=f(3)f(x-2)+f(2)f(x-3). \ \\ \ \\ &f(x-2)=f(x-3)+f(x-4). \\ &\Rightarrow f(x)=f(3)(f(x-3)+f(x-4))+f(2)f(x-3)=(f(2)+f(3))f(x-3) \\ &+f(3)f(x-4)=f(4)f(x-3)+f(3)f(x-4). \\ &\cdot \\ &\cdot \\ &\cdot \\ &\therefore f(x)=f(k+1)f(x-k)+f(k)f(x-k-1). \\ &x=2k+1; \ f(2k+1)=f(k)^2+f(k+1)^2. \\ \ \\ &\therefore f(x)^2+f(x+1)^2=f(2x+1).\end{align} p.s. if you have another solution, please post it as an answer with a spoiler. (>! another answer with no enter )","Prove that for the function satisfying I know how to prove it, but it is interesting so I am posting it. The first hint is: The second hint is: Check this to see that your proof is the same as mine. p.s. if you have another solution, please post it as an answer with a spoiler. (>! another answer with no enter )","f(x)^2+f(x+1)^2 = f(2x+1) f f(x)=f(x-1)+f(x-2), f(1)=f(2)=1. \begin{align} &\text{Try to prove this first: } \\ &f(x)=f(x-1)+f(x-2) \\ &=2f(x-2)+f(x-3) \\ &=3f(x-3)+2f(x-4) \\ &= 5f(x-4)+3f(x-3) \\ &= \cdot \cdot \cdot \end{align} \text{According to the first hint: } f(x)=f(k+1)f(x-k)+f(k)f(x-k-1).  \begin{align} &f(x)=f(x-1)+f(x-2) = f(2)f(x-1)+f(1)f(x-2). \ \\ \ \\ &f(x-1)=f(x-2)+f(x-3) \\ &\Rightarrow f(x)=f(2)(f(x-2)+f(x-3))+f(1)f(x-2)=(f(1)+f(2))f(x-2) \\ &+f(2)f(x-3)=f(3)f(x-2)+f(2)f(x-3). \ \\ \ \\ &f(x-2)=f(x-3)+f(x-4). \\ &\Rightarrow f(x)=f(3)(f(x-3)+f(x-4))+f(2)f(x-3)=(f(2)+f(3))f(x-3) \\ &+f(3)f(x-4)=f(4)f(x-3)+f(3)f(x-4). \\ &\cdot \\ &\cdot \\ &\cdot \\ &\therefore f(x)=f(k+1)f(x-k)+f(k)f(x-k-1). \\ &x=2k+1; \ f(2k+1)=f(k)^2+f(k+1)^2. \\ \ \\ &\therefore f(x)^2+f(x+1)^2=f(2x+1).\end{align}","['functions', 'functional-equations']"
61,How to prove a non-monotone function is non-negative in some given interval?,How to prove a non-monotone function is non-negative in some given interval?,,"Consider the function $f(x, n) = -\left(2n+3\right) x^{n}+\left(2n+1\right)x^{\left(n+1\right)}+4\left(n+1\right)x^{\left(2n\right)}-\left(4n+1\right)x^{\left(2n+1\right)}+1, x\in (0, 1), n=1, 2,\cdots$ . We'd like to prove $f(x, n)$ is non-negative $\forall x \in (0, 1), n=1, 2, \cdots$ . Something I tried. We can plot the function in the interval and find it's positive and non-monotone. But since it is difficult to determine the root where the derivative is 0, I have no idea how to prove it is always positive in the interval $(0, 1)$ for and $n=1, 2, \cdots$ . I tried to compute the partial derivative about $n$ , but the partial derivative is not always positive or negative. Here is the graph for the partial derivative. Is there any way to prove the nonnegativity?","Consider the function . We'd like to prove is non-negative . Something I tried. We can plot the function in the interval and find it's positive and non-monotone. But since it is difficult to determine the root where the derivative is 0, I have no idea how to prove it is always positive in the interval for and . I tried to compute the partial derivative about , but the partial derivative is not always positive or negative. Here is the graph for the partial derivative. Is there any way to prove the nonnegativity?","f(x, n) = -\left(2n+3\right) x^{n}+\left(2n+1\right)x^{\left(n+1\right)}+4\left(n+1\right)x^{\left(2n\right)}-\left(4n+1\right)x^{\left(2n+1\right)}+1, x\in (0, 1), n=1, 2,\cdots f(x, n) \forall x \in (0, 1), n=1, 2, \cdots (0, 1) n=1, 2, \cdots n","['real-analysis', 'calculus', 'functions']"
62,How to perform mathematically valid steps while finding a solution? [closed],How to perform mathematically valid steps while finding a solution? [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 years ago . Improve this question Before having deeper understanding of Domain, I took many  mathematical steps as granted. For e.g. $i) \frac{1}{\frac{1}{cos(x)}}=cos(x)$ $ii)\frac{1}{cosec(x)}=sin(x)$ $iii) \sqrt{x-2}*\sqrt{x+2}=\sqrt{x^2-4}$ But after learning Domains pretty nicely, I can see the equations the new way, in more mathematically stricter sense. Say, $\frac{1}{\frac{1}{cos(x)}}$ has domain $x=R-(2n+1)\frac{\pi}{2}$ whereas $cos(x)$ has domain $R$ . Also, $\frac{1}{cosec(x)}$ has domain $(R-n\pi)$ and $sin(x)$ has domain $R$ . $\sqrt{x-2}*\sqrt{x+2}$ has domain $[2,\infty)$ whereas $\sqrt{x^2-4}$ has domain $(-\infty,-2]\cup[2,\infty)$ . Clearly, $i),ii),iii)$ are not always True. In everyday life, checking and verifying every possible operation while calculating a solution makes the entire process slow and tiresome (as of my present situation). So, what approach would be correct to follow while solving a problem? Checking and verifying every step?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 years ago . Improve this question Before having deeper understanding of Domain, I took many  mathematical steps as granted. For e.g. But after learning Domains pretty nicely, I can see the equations the new way, in more mathematically stricter sense. Say, has domain whereas has domain . Also, has domain and has domain . has domain whereas has domain . Clearly, are not always True. In everyday life, checking and verifying every possible operation while calculating a solution makes the entire process slow and tiresome (as of my present situation). So, what approach would be correct to follow while solving a problem? Checking and verifying every step?","i) \frac{1}{\frac{1}{cos(x)}}=cos(x) ii)\frac{1}{cosec(x)}=sin(x) iii) \sqrt{x-2}*\sqrt{x+2}=\sqrt{x^2-4} \frac{1}{\frac{1}{cos(x)}} x=R-(2n+1)\frac{\pi}{2} cos(x) R \frac{1}{cosec(x)} (R-n\pi) sin(x) R \sqrt{x-2}*\sqrt{x+2} [2,\infty) \sqrt{x^2-4} (-\infty,-2]\cup[2,\infty) i),ii),iii)","['calculus', 'functions']"
63,Is it true that the domain of this function is finite?,Is it true that the domain of this function is finite?,,"(This is a subproblem that came up as I was proving that $\{e: \phi_e(x) \text{ has infinite domain}\}$ is $\Pi_2$ -complete.) Let $A$ be a set of natural numbers and suppose $$n\in A\iff \forall y_1\exists y_2 T(n,y_1,y_2)$$ (where $T$ is a (computable) relation). Consider this  partial function on pairs of natural numbers: $$(n,x) \mapsto 1\text{ if }\forall y_1\leq x\exists y_2 T(n,y_1,y_2)\\(n,x)\text{ is undefined otherwise} $$ If $n\in A$ , then the above function as a function of $x$ is total. Is it true that if $n\notin A$ , then this function (again as a function of $x$ ) has finite domain? I think so, and I think this is a trivial result but I can't wrap my head around proving it in a formal way. Here's what I think informally: if $n\notin A$ , then the first condition in the definition may be true for small $x$ , but starting from some $x_0$ , that wouldn't be true. Is this indeed the case? I can't connect this with the negation of $x\in A$ i.e. with $\exists y_1\forall y_2 \neg  T(n,y_2,y_3) $ . Edit: I modified the original function. Does the new function has a finite domain as a function of $x$ when $x\notin A$ ? If not, I was wondering if there's a way to modify this function further so that (1) it remains computable, (2) if $n\in A$ , the domain is still infinite, (3) if $n\notin A$ , the domain is finite?","(This is a subproblem that came up as I was proving that is -complete.) Let be a set of natural numbers and suppose (where is a (computable) relation). Consider this  partial function on pairs of natural numbers: If , then the above function as a function of is total. Is it true that if , then this function (again as a function of ) has finite domain? I think so, and I think this is a trivial result but I can't wrap my head around proving it in a formal way. Here's what I think informally: if , then the first condition in the definition may be true for small , but starting from some , that wouldn't be true. Is this indeed the case? I can't connect this with the negation of i.e. with . Edit: I modified the original function. Does the new function has a finite domain as a function of when ? If not, I was wondering if there's a way to modify this function further so that (1) it remains computable, (2) if , the domain is still infinite, (3) if , the domain is finite?","\{e: \phi_e(x) \text{ has infinite domain}\} \Pi_2 A n\in A\iff \forall y_1\exists y_2 T(n,y_1,y_2) T (n,x) \mapsto 1\text{ if }\forall y_1\leq x\exists y_2 T(n,y_1,y_2)\\(n,x)\text{ is undefined otherwise}  n\in A x n\notin A x n\notin A x x_0 x\in A \exists y_1\forall y_2 \neg  T(n,y_2,y_3)  x x\notin A n\in A n\notin A","['functions', 'logic', 'predicate-logic', 'computability', 'quantifiers']"
64,Can a function have a best quadratic approximation around a point but not a second derivative there?,Can a function have a best quadratic approximation around a point but not a second derivative there?,,"Taylor's Theorem says that for a function $f : \mathbb{R} \to \mathbb{R}$ which is $n$ times differentiable around a point $a$ , there exists a function $h_n(x)$ such that $$f(x) = \left(f(a) + \sum_{k=1}^n \frac{f^{(k)}(a)}{k!}(x-a)^k\right) + h_n(x)(x-a)^n$$ and $\lim_{x\to a} h_n(x) = 0$ . I understand the theorem, its motivation and meaning and its proof. A quadratic approximation around a point $a$ exists then if we can write $f(x) = f(a) + b(x-a) + c(x-a)^2 + h_2(x)(x-a)^2$ where $h_2(x) \to 0$ as $x\to a$ . Now, looking deeper into this subject, I've noticed that the existence of a linear approximation implies the differentiability at the point so that they are equivalent (the other direction being proved via Taylor Theorem or otherwise). Indeed $$ \frac{d}{dx}\big(h_1(x)(x-a)\big)|_{x=a} = \lim_{x\to a} \frac{h_1(x)(x-a)}{x-a} = \lim_{x\to a} h_1(x) = 0$$ So I've wondered whether the existence of such a quadratic approximation implies the existence of the second derivative at the point $a$ . At first it seemed true to me but then I found this example: Let $g : \mathbb{R} \to \mathbb{R}$ , $g(x) = \begin{cases} 0, & x\notin\mathbb{Q} \\ (x-1)^3, & x\in\mathbb{Q} \end{cases}$ . It's not hard to see that this function is only continuous at $x=1$ and the derivative exists there, $g'(1) = 0$ . Then, if we define $u : \mathbb{R} \to \mathbb{R}, u(x) = \frac{g(x)}{(x-1)^2}$ and $u(1) := 0$ , we have $u(x) \to 0$ as $x\to 1$ . So, for the function $f : \mathbb{R} \to \mathbb{R}, f(x) = 5 + 2(x-1) + 3(x-1)^2 + u(x)(x-1)^2$ , the quadratic approximation around $x=1$ exists, but, since $f$ is only differentiable at that point, not around it, the second derivative there doesn't even make sense. Is there anything wrong with this or the two concepts (the existence of the second derivative at a point and the existence of a best quadratic approximation around that point) are really not equivalent?","Taylor's Theorem says that for a function which is times differentiable around a point , there exists a function such that and . I understand the theorem, its motivation and meaning and its proof. A quadratic approximation around a point exists then if we can write where as . Now, looking deeper into this subject, I've noticed that the existence of a linear approximation implies the differentiability at the point so that they are equivalent (the other direction being proved via Taylor Theorem or otherwise). Indeed So I've wondered whether the existence of such a quadratic approximation implies the existence of the second derivative at the point . At first it seemed true to me but then I found this example: Let , . It's not hard to see that this function is only continuous at and the derivative exists there, . Then, if we define and , we have as . So, for the function , the quadratic approximation around exists, but, since is only differentiable at that point, not around it, the second derivative there doesn't even make sense. Is there anything wrong with this or the two concepts (the existence of the second derivative at a point and the existence of a best quadratic approximation around that point) are really not equivalent?","f : \mathbb{R} \to \mathbb{R} n a h_n(x) f(x) = \left(f(a) + \sum_{k=1}^n \frac{f^{(k)}(a)}{k!}(x-a)^k\right) + h_n(x)(x-a)^n \lim_{x\to a} h_n(x) = 0 a f(x) = f(a) + b(x-a) + c(x-a)^2 + h_2(x)(x-a)^2 h_2(x) \to 0 x\to a  \frac{d}{dx}\big(h_1(x)(x-a)\big)|_{x=a} = \lim_{x\to a} \frac{h_1(x)(x-a)}{x-a} = \lim_{x\to a} h_1(x) = 0 a g : \mathbb{R} \to \mathbb{R} g(x) = \begin{cases} 0, & x\notin\mathbb{Q} \\ (x-1)^3, & x\in\mathbb{Q} \end{cases} x=1 g'(1) = 0 u : \mathbb{R} \to \mathbb{R}, u(x) = \frac{g(x)}{(x-1)^2} u(1) := 0 u(x) \to 0 x\to 1 f : \mathbb{R} \to \mathbb{R}, f(x) = 5 + 2(x-1) + 3(x-1)^2 + u(x)(x-1)^2 x=1 f","['calculus', 'functions', 'taylor-expansion']"
65,"Function defined ""over"" a set or ""on"" a set?","Function defined ""over"" a set or ""on"" a set?",,"Is the sentence Given an Euclidean space $X$ , over which a function $f: X → \mathbb R$ is defined ... correct, or do I write Given an Euclidean space $X$ , on which a function $f: X → \mathbb R$ is defined ... in my publication? With Since a function is defined on its entire domain, ... https://en.wikipedia.org/wiki/Domain_of_a_function seems to favour the second, while I saw the first in quite a few of places at math.stackexchange.com, e.g. What is the measure of functions defined over $\overline{\mathbb{Q}}$ . EDIT: https://english.stackexchange.com/questions/117234/function-defined-on-over-the-set-a suggests that it would be ""on"" if $f$ is defined on arbitrary set and ""over"" if the function is defined over sort of (algebraic) structure (or strictly speaking over the underlying set), where the structure is somewhat ""respected"" by the function. So it might be be Given an Euclidean space $X$ , over which a function $f: X → \mathbb R$ is defined  ... Given a set $X$ , on which a function $f: X → \mathbb R$ is defined ... What is to make of this (as mathematicians, instead of linguists ;-))?","Is the sentence Given an Euclidean space , over which a function is defined ... correct, or do I write Given an Euclidean space , on which a function is defined ... in my publication? With Since a function is defined on its entire domain, ... https://en.wikipedia.org/wiki/Domain_of_a_function seems to favour the second, while I saw the first in quite a few of places at math.stackexchange.com, e.g. What is the measure of functions defined over $\overline{\mathbb{Q}}$ . EDIT: https://english.stackexchange.com/questions/117234/function-defined-on-over-the-set-a suggests that it would be ""on"" if is defined on arbitrary set and ""over"" if the function is defined over sort of (algebraic) structure (or strictly speaking over the underlying set), where the structure is somewhat ""respected"" by the function. So it might be be Given an Euclidean space , over which a function is defined  ... Given a set , on which a function is defined ... What is to make of this (as mathematicians, instead of linguists ;-))?",X f: X → \mathbb R X f: X → \mathbb R f X f: X → \mathbb R X f: X → \mathbb R,"['functions', 'terminology']"
66,Problem involving maximum and minimum of a continuous function,Problem involving maximum and minimum of a continuous function,,"Let $f:\mathbb{R}\to\mathbb{R}$ be a continuous function. We denote, for every $x\in\mathbb{R}$ , with $m(x)$ and $M(x)$ the minimum and maximum of $f$ on the interval $[x-1,x]$ . Show that, if $m(x)+M(x)=0,\forall x\in\mathbb{R}$ , then the functions $m$ and $M$ are constant. I have tried to prove that $f$ is periodic, but I didn't managed to do it; I'm not sure it's even true...","Let be a continuous function. We denote, for every , with and the minimum and maximum of on the interval . Show that, if , then the functions and are constant. I have tried to prove that is periodic, but I didn't managed to do it; I'm not sure it's even true...","f:\mathbb{R}\to\mathbb{R} x\in\mathbb{R} m(x) M(x) f [x-1,x] m(x)+M(x)=0,\forall x\in\mathbb{R} m M f","['real-analysis', 'analysis']"
67,Applying the Lambert W function for a new equation,Applying the Lambert W function for a new equation,,"I am a physical chemist, and we are trying to model a simple process.  We ended up arriving at the following equation. \begin{align} ax^{-7/2}e^{-bx(ln(cx)-1)}=1 \end{align} We'd like to solve for $x$ .  All constants ( $a$ , $b$ , $c$ ) are real, positive. a is on the order of 31 and b and c are on the order of the -3. I have found the following relationship from the following: (Edwards, https://arxiv.org/pdf/1902.08910.pdf ) \begin{align} y=ax^be^{cx^d}+f \end{align} Can be inverted into \begin{align} x=\left[\frac{b}{cd} W\left(\frac{cd(y-f)^{\frac{d}{b}}}{ba^{\frac{d}{b}}}\right)\right]^{1/d} \end{align} Where W is the Lambert W function. But obviously I have a $\ln(x)$ in the exponential function. We'd love to find a good expression for x, either exact, or approximate through expansion.  We can check it against a numerical solution. Any ideas?  Thanks all!","I am a physical chemist, and we are trying to model a simple process.  We ended up arriving at the following equation. We'd like to solve for .  All constants ( , , ) are real, positive. a is on the order of 31 and b and c are on the order of the -3. I have found the following relationship from the following: (Edwards, https://arxiv.org/pdf/1902.08910.pdf ) Can be inverted into Where W is the Lambert W function. But obviously I have a in the exponential function. We'd love to find a good expression for x, either exact, or approximate through expansion.  We can check it against a numerical solution. Any ideas?  Thanks all!","\begin{align}
ax^{-7/2}e^{-bx(ln(cx)-1)}=1
\end{align} x a b c \begin{align}
y=ax^be^{cx^d}+f
\end{align} \begin{align}
x=\left[\frac{b}{cd} W\left(\frac{cd(y-f)^{\frac{d}{b}}}{ba^{\frac{d}{b}}}\right)\right]^{1/d}
\end{align} \ln(x)","['functions', 'special-functions']"
68,Function for the orbit of the International Space Station,Function for the orbit of the International Space Station,,"For a maths task in school, I am investigating the orbit of the International Space Station around the Earth. I understand that when the 3D movement in space is represented on a 2D  surface, the relationship is not sinusoidal, however I have created the following (simple) model, which I am unsure is the most accurate. Below you can also find my calculated values with the formula (in red), compared to the actual values from an online API. Any help would be greatly appreciated! $y=51.64*\sin(x-304)$ (This only applies for one of the curves (the one pictured below), as the wave is translated 22.5 degrees to the right after each cycle.) My data can be found in the following google doc: https://docs.google.com/spreadsheets/d/1Ac8yQn8ybdtZWK8JyKAOIw46o3UJufAoidR5unjVeHs/edit?usp=sharing This is the graph Thank you in advance!","For a maths task in school, I am investigating the orbit of the International Space Station around the Earth. I understand that when the 3D movement in space is represented on a 2D  surface, the relationship is not sinusoidal, however I have created the following (simple) model, which I am unsure is the most accurate. Below you can also find my calculated values with the formula (in red), compared to the actual values from an online API. Any help would be greatly appreciated! (This only applies for one of the curves (the one pictured below), as the wave is translated 22.5 degrees to the right after each cycle.) My data can be found in the following google doc: https://docs.google.com/spreadsheets/d/1Ac8yQn8ybdtZWK8JyKAOIw46o3UJufAoidR5unjVeHs/edit?usp=sharing This is the graph Thank you in advance!",y=51.64*\sin(x-304),"['functions', 'trigonometry', 'classical-mechanics']"
69,$f$ is continuous and open implies $f$ injective,is continuous and open implies  injective,f f,"Question: Let $f: \mathbb R \to \mathbb R$ be continuous and open, that is if $A \subset \mathbb R$ is open then $f(A) \subset \mathbb R$ is open. Prove that $f$ is injective. Attempt: Suppose $f$ is not injective then there exit $x, y \in \mathbb R$ such that $$x < y \implies f(x) = f(y) = c$$ Take the closed inteval $[x,y] \subset \mathbb R$, as $f$ is continuous then $\displaystyle {f|_{[x,y]}}$ is continuous, by Weierstrass Theorem we have that $f$ has a maximum or a minimum point. Let's assume $m = \max \{f(a) ; a \in [x,y]\}$. Now there is  $x' \in [x,y]$ such that $f(x') = m$. If we take the open $(x'-\delta, x'+\delta)$ centered at $x'$ and  we have (1)  If $m = c$ then $f$ is constant on the interval $[x,y]$ and $f((x'-\delta, x'+\delta)) = \{c\}$ which is closed, thus a contradiction; (2)  If $m \neq c$ then we would have $f((x'-\delta,  x'+\delta)) = (b, m]$, where $b$ can also be $b = \infty$. Again a contradiction. Well, this is my least embarassing attempt. I'm not sure how to show $(2)$ $100 \%$. I have also tried to show $f^{-1}f(A) = A$ for any $A \subset \mathbb R$, tried to work on the connected space  $\mathbb R$ by finding a contradiction using the intervals $E_{[f > c]}$ and  $E_{[f < c]}$ open when $A$ is open. Any thoughts? Note: I've already seen this to try something out, but the fact that $f$ is monotone on this exercise comes as a consequence.","Question: Let $f: \mathbb R \to \mathbb R$ be continuous and open, that is if $A \subset \mathbb R$ is open then $f(A) \subset \mathbb R$ is open. Prove that $f$ is injective. Attempt: Suppose $f$ is not injective then there exit $x, y \in \mathbb R$ such that $$x < y \implies f(x) = f(y) = c$$ Take the closed inteval $[x,y] \subset \mathbb R$, as $f$ is continuous then $\displaystyle {f|_{[x,y]}}$ is continuous, by Weierstrass Theorem we have that $f$ has a maximum or a minimum point. Let's assume $m = \max \{f(a) ; a \in [x,y]\}$. Now there is  $x' \in [x,y]$ such that $f(x') = m$. If we take the open $(x'-\delta, x'+\delta)$ centered at $x'$ and  we have (1)  If $m = c$ then $f$ is constant on the interval $[x,y]$ and $f((x'-\delta, x'+\delta)) = \{c\}$ which is closed, thus a contradiction; (2)  If $m \neq c$ then we would have $f((x'-\delta,  x'+\delta)) = (b, m]$, where $b$ can also be $b = \infty$. Again a contradiction. Well, this is my least embarassing attempt. I'm not sure how to show $(2)$ $100 \%$. I have also tried to show $f^{-1}f(A) = A$ for any $A \subset \mathbb R$, tried to work on the connected space  $\mathbb R$ by finding a contradiction using the intervals $E_{[f > c]}$ and  $E_{[f < c]}$ open when $A$ is open. Any thoughts? Note: I've already seen this to try something out, but the fact that $f$ is monotone on this exercise comes as a consequence.",,"['real-analysis', 'analysis', 'continuity']"
70,"$f: A \rightarrow C$ and $g: B \rightarrow C$, prove $f \cup g: A \cup B \rightarrow C$ iff $f \restriction (A \cap B) = g \restriction (A \cap B)$","and , prove  iff",f: A \rightarrow C g: B \rightarrow C f \cup g: A \cup B \rightarrow C f \restriction (A \cap B) = g \restriction (A \cap B),"Suppose $f: A \rightarrow C$ and $g: B \rightarrow C$ . Prove that $f \cup g: A \cup B \rightarrow C$ iff $f \restriction (A \cap B) = g \restriction (A \cap B) $ My attempt: If I'm getting the definition of the restriction correctly, we have $$ f \restriction (A \cap B) = f \cap \bigl((A \cap B) \times C\bigr)$$ and $$ g \restriction (A \cap B) = g \cap \bigl((A \cap B) \times C\bigr)$$ $(\rightarrow)$ Suppose $f \cup g: A \cup B \rightarrow C$ Take $(x,y) \in f \restriction (A \cap B)$ . Then $(x,y) \in (A \cap B) \times C$ and $x \in B$ . Since $x \in B$ , there exists some $b \in B$ such that $(x,b) \in g$ . Since $(x,b) \in f \cup g$ and $(x,y) \in f \cup g$ , we conclude that $y = b$ . Hence $(x,y) \in g \restriction A \cap B$ , and $f \restriction (A \cap B) \subseteq g \restriction (A \cap B)$ . By the identical reasoning, we can show that $g \restriction (A \cap B) \subseteq f \restriction (A \cap B)$ $(\leftarrow)$ Suppose $f \restriction (A \cap B) = g \restriction (A \cap B)$ Existence: Take $x \in A \cup B$ . Then $x \in A$ or $x \in B$ , which implies that there exists some $c \in C $ such that either $(x,c) \in f$ or $(x,c) \in g$ . Hence $(x,c) \in f \cup g$ . Uniqueness: Suppose $(x,y),(x,p) \in f \cup g$ . If both elements are either in $f$ or in $g$ , then clearly $y = p$ . Suppose $(x,y) \in f$ and $(x,p) \in g$ . Since $x \in A \cap B$ and $y \in C$ , we have $(x,y) \in (A \cap B) \times C$ and therefore $(x,y) \in f \restriction A \cap B$ By the similar reasoning, we have $(x,p) \in g \restriction A \cap B$ . For all $x$ in $Dom(f \restriction A \cap B)$ there is only one $k \in Ran(f \restriction A \cap B)$ such that $(x,k) \in f \restriction A \cap B$ The same reasoning applies to $g \restriction A \cap B$ . Since $f \restriction (A \cap B) = g \restriction (A \cap B) $ , we have $p = y$ . If $(x,p) \in f$ and $(x,y) \in g$ , then by the same reasoning, we conclude that $p = y$ We've shown existence and uniqueness, hence the result $$f \cup g: A \cup B \rightarrow C$$ $\Box$ Is it correct?","Suppose and . Prove that iff My attempt: If I'm getting the definition of the restriction correctly, we have and Suppose Take . Then and . Since , there exists some such that . Since and , we conclude that . Hence , and . By the identical reasoning, we can show that Suppose Existence: Take . Then or , which implies that there exists some such that either or . Hence . Uniqueness: Suppose . If both elements are either in or in , then clearly . Suppose and . Since and , we have and therefore By the similar reasoning, we have . For all in there is only one such that The same reasoning applies to . Since , we have . If and , then by the same reasoning, we conclude that We've shown existence and uniqueness, hence the result Is it correct?","f: A \rightarrow C g: B \rightarrow C f \cup g: A \cup B \rightarrow C f \restriction (A \cap B) = g \restriction (A \cap B)   f \restriction (A \cap B) = f \cap \bigl((A \cap B) \times C\bigr)  g \restriction (A \cap B) = g \cap \bigl((A \cap B) \times C\bigr) (\rightarrow) f \cup g: A \cup B \rightarrow C (x,y) \in f \restriction (A \cap B) (x,y) \in (A \cap B) \times C x \in B x \in B b \in B (x,b) \in g (x,b) \in f \cup g (x,y) \in f \cup g y = b (x,y) \in g \restriction A \cap B f \restriction (A \cap B) \subseteq g \restriction (A \cap B) g \restriction (A \cap B) \subseteq f \restriction (A \cap B) (\leftarrow) f \restriction (A \cap B) = g \restriction (A \cap B) x \in A \cup B x \in A x \in B c \in C  (x,c) \in f (x,c) \in g (x,c) \in f \cup g (x,y),(x,p) \in f \cup g f g y = p (x,y) \in f (x,p) \in g x \in A \cap B y \in C (x,y) \in (A \cap B) \times C (x,y) \in f \restriction A \cap B (x,p) \in g \restriction A \cap B x Dom(f \restriction A \cap B) k \in Ran(f \restriction A \cap B) (x,k) \in f \restriction A \cap B g \restriction A \cap B f \restriction (A \cap B) = g \restriction (A \cap B)  p = y (x,p) \in f (x,y) \in g p = y f \cup g: A \cup B \rightarrow C \Box","['functions', 'proof-verification', 'elementary-set-theory']"
71,Questions about Approximating a Function at Infinity,Questions about Approximating a Function at Infinity,,"I was playing around today and happened across a nice method for approximating functions at infinity. The first example of a function I found that my method worked for was $$f(x) = \frac{1}{1+x^2}$$ The method is outlined as follows. Define an auxiliary function $g$ as $$g(x) := f\left(\frac{1}{x}\right)$$ Since $g$ is analytic everywhere except possibly at the point $0$ , we can express $g$ as $$g(x) = \sum_{n=0}^\infty\frac{g^{(n)}(x_0)}{n!}(x-x_0)^n$$ for any point $x_0 \neq 0$ . Now define $f_a$ as $$f_a(x) := \lim_{x_0 \to 0}\sum_{n=0}^\infty\frac{g^{(n)}(x_0)}{n!}\left(\frac{1}{x}-x_0\right)^n$$ I truncated the series definition of $f_a$ at the third term and took $x_0 = 0.0001$ . Then I plotted the resulting graph (Dotted Blue) and compared it to the graph of $f$ (Solid Black) as shown below. So we can see that "" $f_a$ approximates $f$ at infinity"", in some sense. I suspect that this method is related to asymptotic expansions, but I am having trouble formalizing the ideas presented here. My two questions are: Formally, what is the process that I am getting at here? For what class of functions can we expect this method to work? Being analytic is a pretty obvious requirement, but the method also seemed to fail for functions like $\dfrac{\sin(x)}{1+x^2}$ . Moreover, if anyone has some online references that they could point me to for more information, that would be appreciated as well.","I was playing around today and happened across a nice method for approximating functions at infinity. The first example of a function I found that my method worked for was The method is outlined as follows. Define an auxiliary function as Since is analytic everywhere except possibly at the point , we can express as for any point . Now define as I truncated the series definition of at the third term and took . Then I plotted the resulting graph (Dotted Blue) and compared it to the graph of (Solid Black) as shown below. So we can see that "" approximates at infinity"", in some sense. I suspect that this method is related to asymptotic expansions, but I am having trouble formalizing the ideas presented here. My two questions are: Formally, what is the process that I am getting at here? For what class of functions can we expect this method to work? Being analytic is a pretty obvious requirement, but the method also seemed to fail for functions like . Moreover, if anyone has some online references that they could point me to for more information, that would be appreciated as well.",f(x) = \frac{1}{1+x^2} g g(x) := f\left(\frac{1}{x}\right) g 0 g g(x) = \sum_{n=0}^\infty\frac{g^{(n)}(x_0)}{n!}(x-x_0)^n x_0 \neq 0 f_a f_a(x) := \lim_{x_0 \to 0}\sum_{n=0}^\infty\frac{g^{(n)}(x_0)}{n!}\left(\frac{1}{x}-x_0\right)^n f_a x_0 = 0.0001 f f_a f \dfrac{\sin(x)}{1+x^2},"['calculus', 'functions', 'asymptotics', 'taylor-expansion', 'approximation']"
72,What does the plot/graph of an associative function on the unit square look like?,What does the plot/graph of an associative function on the unit square look like?,,"I have a function $f(x,y):[0,1]\times[0,1]\rightarrow[0,1]$ . Let's say that I plot the function as a heat map (that is, I color each pixel in the square $[0,1]\times[0,1]$ according to the value of the function at that point) I'm interested in knowing what the plot would look like given that the function is associative: $f(x,f(y,z))=f(f(x,y),z)$ for all $x,y,z$ . Commutative functions $f(x,y)=f(y,x)$ have a plot which is mirror-symmetric along the diagonal of the square. Is there, similarly, some simple visual property that characterizes all associative functions (and only them)? (To make it simpler, we may assume that we are talking about a ""regular-enough"" function, e.g. piecewise continuous or something like that, so that it would make sense to speak about its plot)","I have a function . Let's say that I plot the function as a heat map (that is, I color each pixel in the square according to the value of the function at that point) I'm interested in knowing what the plot would look like given that the function is associative: for all . Commutative functions have a plot which is mirror-symmetric along the diagonal of the square. Is there, similarly, some simple visual property that characterizes all associative functions (and only them)? (To make it simpler, we may assume that we are talking about a ""regular-enough"" function, e.g. piecewise continuous or something like that, so that it would make sense to speak about its plot)","f(x,y):[0,1]\times[0,1]\rightarrow[0,1] [0,1]\times[0,1] f(x,f(y,z))=f(f(x,y),z) x,y,z f(x,y)=f(y,x)","['functions', 'graphing-functions', 'associativity']"
73,Possible mistake in Apostol calculus: integration of the logarithm function,Possible mistake in Apostol calculus: integration of the logarithm function,,"The exercise set 6.9 of calculus I Apostol lists the following to find the antiderivative: $$a) \int \log^2(x)\;dx$$ The solution in the back of the book is: $$b)\; x\log^2|x| - 2x\log|x| + 2x + C$$ I think that the answer should be the same, except all $\log|x| \rightarrow \log(x)$ . By definition, we have $\log(x)$ and not $\log|x|$ . It means that the logarithm $\log(x)$ under integration cannot accept any negative term. Hence, its antiderivative should not accept it either, because the derivative of (b) is $\log^2|x|$ , which is clearly different to me than $\log^2(x)$ . Is it a mistake in Apostol, or I do not understand something about the domains here?","The exercise set 6.9 of calculus I Apostol lists the following to find the antiderivative: The solution in the back of the book is: I think that the answer should be the same, except all . By definition, we have and not . It means that the logarithm under integration cannot accept any negative term. Hence, its antiderivative should not accept it either, because the derivative of (b) is , which is clearly different to me than . Is it a mistake in Apostol, or I do not understand something about the domains here?",a) \int \log^2(x)\;dx b)\; x\log^2|x| - 2x\log|x| + 2x + C \log|x| \rightarrow \log(x) \log(x) \log|x| \log(x) \log^2|x| \log^2(x),"['calculus', 'functions', 'logarithms']"
74,Are all n-ary operators simply compositions of binary operators?,Are all n-ary operators simply compositions of binary operators?,,"Take for example $A \times B \cdot C$ = $(A \times B) \cdot C$ where $A, B, C$ are 3-component real vectors. We can define a 3-nary operator $\times - \cdot$ that is a composition of the two common binary operators $\times$ and $\cdot$. The same thing happens with most functions (operators) - the way we calculate them is by doing smaller binary problems and adding together. Every time I try to come up with an $(n > 2)$-ary operator my mind automatically looks for binary operators. So, the question is, do there exist operators (of some weird kind in some branch of math) that cannot be decomposed into 2-ary and 1-ary operators? Thanks.","Take for example $A \times B \cdot C$ = $(A \times B) \cdot C$ where $A, B, C$ are 3-component real vectors. We can define a 3-nary operator $\times - \cdot$ that is a composition of the two common binary operators $\times$ and $\cdot$. The same thing happens with most functions (operators) - the way we calculate them is by doing smaller binary problems and adding together. Every time I try to come up with an $(n > 2)$-ary operator my mind automatically looks for binary operators. So, the question is, do there exist operators (of some weird kind in some branch of math) that cannot be decomposed into 2-ary and 1-ary operators? Thanks.",,"['elementary-set-theory', 'logic']"
75,Finding functions $f: \Bbb R_*^+ \to \Bbb R_*^+$ with certain properties,Finding functions  with certain properties,f: \Bbb R_*^+ \to \Bbb R_*^+,Find the functions $f:\Bbb R_*^+ \to \Bbb R_*^+$ such that: $$f(x)f \left(\frac{1}{x}\right)=1$$,Find the functions $f:\Bbb R_*^+ \to \Bbb R_*^+$ such that: $$f(x)f \left(\frac{1}{x}\right)=1$$,,"['functions', 'functional-equations']"
76,On integer solutions of $2\sqrt{\sqrt{2x}+\sqrt{y}}=\sqrt{x}+\sqrt{2y}$,On integer solutions of,2\sqrt{\sqrt{2x}+\sqrt{y}}=\sqrt{x}+\sqrt{2y},"$\textsf{Background}$ From the double-angle formula $\cos2\alpha=2\cos^2\alpha-1$ , we can get $$\cos15^\circ=\sqrt{\frac{1+\cos30^\circ}2}=\frac{\sqrt{2+\sqrt3}}2$$ but we also know that it is equivalent to $\dfrac{\sqrt6+\sqrt2}4$ . This is an example of an equality such that $$2\sqrt{\sqrt{2x}+\sqrt{y}}=\sqrt{x}+\sqrt{2y}$$ after some rearranging. We can write $y$ in terms of $x$ without much bother: $$y=2+\frac x2+2\sqrt{1+\sqrt{2x}}-\sqrt{2x(1+\sqrt{2x})}.$$ But when are $x$ and $y$ integers? Here is a plot of the curve: Some obvious solutions are $(0,0)$ , $(0,4)$ , $(2,3)$ and $(32,0)$ . Of course, $x=2k$ for some integer $k$ , leaving us with $$y=2+k+2\sqrt{1+2\sqrt k}-2\sqrt{k(1+2\sqrt k)}$$ Hence this boils down to finding $k$ such that $$(1-\sqrt k)\sqrt{1+2\sqrt k}$$ is an integer. Any advances on this?","From the double-angle formula , we can get but we also know that it is equivalent to . This is an example of an equality such that after some rearranging. We can write in terms of without much bother: But when are and integers? Here is a plot of the curve: Some obvious solutions are , , and . Of course, for some integer , leaving us with Hence this boils down to finding such that is an integer. Any advances on this?","\textsf{Background} \cos2\alpha=2\cos^2\alpha-1 \cos15^\circ=\sqrt{\frac{1+\cos30^\circ}2}=\frac{\sqrt{2+\sqrt3}}2 \dfrac{\sqrt6+\sqrt2}4 2\sqrt{\sqrt{2x}+\sqrt{y}}=\sqrt{x}+\sqrt{2y} y x y=2+\frac x2+2\sqrt{1+\sqrt{2x}}-\sqrt{2x(1+\sqrt{2x})}. x y (0,0) (0,4) (2,3) (32,0) x=2k k y=2+k+2\sqrt{1+2\sqrt k}-2\sqrt{k(1+2\sqrt k)} k (1-\sqrt k)\sqrt{1+2\sqrt k}","['real-analysis', 'elementary-number-theory', 'functions']"
77,Suppose $f : \mathbb{R} \rightarrow \mathbb{R}$ is a function with the following properties,Suppose  is a function with the following properties,f : \mathbb{R} \rightarrow \mathbb{R},"I've been stuck on the following math question: Let $f : \mathbb{R} \rightarrow \mathbb{R}$ have two derivatives with $f(0) = 0$ and $f'(x) \leq f(x)$ for all $x$ . Is $f(x) = 0$ for all $x$ ? I've tested several functions, and I believe the answer is true. I have no clue about how to prove this statement though. For example, if we have a constant function $f(x) = c$ , then we must have $c = 0$ due to the $f(0) = 0$ condition. I've also tried polynomial and trignometric functions, and I cannot find a counterexample. I thought about somehow using the Mean Value Theorem or Rolle's Theorem, but I didn't get anywhere with either of those.","I've been stuck on the following math question: Let have two derivatives with and for all . Is for all ? I've tested several functions, and I believe the answer is true. I have no clue about how to prove this statement though. For example, if we have a constant function , then we must have due to the condition. I've also tried polynomial and trignometric functions, and I cannot find a counterexample. I thought about somehow using the Mean Value Theorem or Rolle's Theorem, but I didn't get anywhere with either of those.",f : \mathbb{R} \rightarrow \mathbb{R} f(0) = 0 f'(x) \leq f(x) x f(x) = 0 x f(x) = c c = 0 f(0) = 0,['real-analysis']
78,Periodicity criteria for $f'(x)=P^{m}(f(x))$,Periodicity criteria for,f'(x)=P^{m}(f(x)),"$$f'(x)=P^{m}(f(x))$$ ,where $P(x)$ is a polynomial, m is a real number. $x\in\mathbb{C}$ and $f:\mathbb{C}\to\mathbb{C}$ I would like to find a criteria to define if $f(x)$ is a periodic function or not. I also want to find the period value that depends on polynomial constants and $m$ if the function ( $f(x)$ ) is periodic. My attempt for it: Example 1: $P(x)=x$ , and $m=1$ : Thus our problem is to find period for: $$f'(x)=f(x)$$ If we derivative both side , we can get that $$f''(x)=f'(x)=f(x)$$ Generally; $$f^{(n)}(x)=f(x)$$ a periodic function must satisfy $f(x+T)=f(x)$ , where $T$ is minimal period . Taylor expansion of $f(x+T)$ : $$ f(x+T) =f(x)+\frac{Tf'(x)}{1!}+\frac{T^2f''(x)}{2!}+.....=\sum_{n=0}^{\infty} \frac{T^nf^{(n)}(x)}{n!}  $$ $$ f(x+T) =f(x)+\frac{Tf(x)}{1!}+\frac{T^2f(x)}{2!}+.....=\sum_{n=0}^{\infty} \frac{T^nf(x)}{n!} =f(x) \sum_{n=0}^{\infty} \frac{T^n}{n!}=f(x) $$ Thus, $$\sum_{n=0}^{\infty} \frac{T^n}{n!}=1$$ We know that $$\sum_{n=0}^{\infty} \frac{T^n}{n!}=e^{T}=1$$ Minimal period : $T=2\pi i$ , Example 2: $P(x)=a^2-x^2$ , and $m=\frac{1}{2}$ : Thus our problem is to find period for $$f'(x)=\sqrt{a^2-f^2(x)}$$ If we derivative both side , we can get that $$f''(x)=-\frac{f'(x)f(x)}{\sqrt{a^2-f^2(x)}}=-f(x)$$ $$f'''(x)=-f'(x)$$ $$f^{(4)}(x)=-f''(x)=f(x)$$ $$f^{(5)}(x)=f'(x)$$ . . . a periodic function must satisfy $f(x+T)=f(x)$ , where $T$ is minimal period . Taylor expansion of $f(x+T)$ : $$ f(x+T) =f(x)+\frac{Tf'(x)}{1!}+\frac{T^2f''(x)}{2!}+.....=\sum_{n=0}^{\infty} \frac{T^nf^{(n)}(x)}{n!}  $$ $$ f(x+T) =f(x)+\frac{Tf'(x)}{1!}-\frac{T^2f(x)}{2!}-\frac{T^3f'(x)}{3!}+.....=f(x)\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n}}{(2n)!}+f'(x)\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n+1}}{(2n+1)!}=f(x) $$ Thus, $$f(x)(-1+\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n}}{(2n)!})+f'(x)\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n+1}}{(2n+1)!}=0$$ We get $$\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n}}{(2n)!}=1$$ $$\cos{T}=1$$ and $$\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n+1}}{(2n+1)!}=0$$ $$\sin{T}=0$$ The common solution of 2 equations above is Minimal period : $T=2\pi$ , The solution attempt for General Problem: $$P(x)=a_0+a_1x+\frac{a_2}{2!}x^2+\frac{a_3}{3!}x^3+....+\frac{a_n}{n!}x^n$$ $$f'(x)=P^{m}(f(x))$$ If we follow the same strategy; Apply derivative both side , so we can get that $$f''(x)=mP^{m-1}(f(x))P'(f(x))f'(x)$$ $$f''(x)=mP^{2m-1}(f(x))P'(f(x))=m (f'(x))^{(2m-1)/m}P'(f(x))$$ We can see that if $m=1/2$ then it simplifies to $$f''(x)=\frac{P'(f(x))}{2}$$ $$f'''(x)=f'(x)\frac{P''(f(x))}{2}$$ $$f^{(4)}(x)=\frac{P'(f(x))P''(f(x))}{4}+f'(x)^2\frac{P'''(f(x))}{2}$$ $$f^{(4)}(x)=\frac{P'(f(x))P''(f(x))}{4}+(P^{1/2}(f(x))^2\frac{P'''(f(x))}{2}$$ $$f^{(4)}(x)=\frac{P'(f(x))P''(f(x))}{4}+\frac{P(f(x))P'''(f(x))}{2}$$ But this approach does not help so much like my examples. Could you please help me what we can do if the function is periodic or not? Thanks a lot for advice and answers",",where is a polynomial, m is a real number. and I would like to find a criteria to define if is a periodic function or not. I also want to find the period value that depends on polynomial constants and if the function ( ) is periodic. My attempt for it: Example 1: , and : Thus our problem is to find period for: If we derivative both side , we can get that Generally; a periodic function must satisfy , where is minimal period . Taylor expansion of : Thus, We know that Minimal period : , Example 2: , and : Thus our problem is to find period for If we derivative both side , we can get that . . . a periodic function must satisfy , where is minimal period . Taylor expansion of : Thus, We get and The common solution of 2 equations above is Minimal period : , The solution attempt for General Problem: If we follow the same strategy; Apply derivative both side , so we can get that We can see that if then it simplifies to But this approach does not help so much like my examples. Could you please help me what we can do if the function is periodic or not? Thanks a lot for advice and answers",f'(x)=P^{m}(f(x)) P(x) x\in\mathbb{C} f:\mathbb{C}\to\mathbb{C} f(x) m f(x) P(x)=x m=1 f'(x)=f(x) f''(x)=f'(x)=f(x) f^{(n)}(x)=f(x) f(x+T)=f(x) T f(x+T)  f(x+T) =f(x)+\frac{Tf'(x)}{1!}+\frac{T^2f''(x)}{2!}+.....=\sum_{n=0}^{\infty} \frac{T^nf^{(n)}(x)}{n!}    f(x+T) =f(x)+\frac{Tf(x)}{1!}+\frac{T^2f(x)}{2!}+.....=\sum_{n=0}^{\infty} \frac{T^nf(x)}{n!} =f(x) \sum_{n=0}^{\infty} \frac{T^n}{n!}=f(x)  \sum_{n=0}^{\infty} \frac{T^n}{n!}=1 \sum_{n=0}^{\infty} \frac{T^n}{n!}=e^{T}=1 T=2\pi i P(x)=a^2-x^2 m=\frac{1}{2} f'(x)=\sqrt{a^2-f^2(x)} f''(x)=-\frac{f'(x)f(x)}{\sqrt{a^2-f^2(x)}}=-f(x) f'''(x)=-f'(x) f^{(4)}(x)=-f''(x)=f(x) f^{(5)}(x)=f'(x) f(x+T)=f(x) T f(x+T)  f(x+T) =f(x)+\frac{Tf'(x)}{1!}+\frac{T^2f''(x)}{2!}+.....=\sum_{n=0}^{\infty} \frac{T^nf^{(n)}(x)}{n!}    f(x+T) =f(x)+\frac{Tf'(x)}{1!}-\frac{T^2f(x)}{2!}-\frac{T^3f'(x)}{3!}+.....=f(x)\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n}}{(2n)!}+f'(x)\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n+1}}{(2n+1)!}=f(x)  f(x)(-1+\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n}}{(2n)!})+f'(x)\sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n+1}}{(2n+1)!}=0 \sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n}}{(2n)!}=1 \cos{T}=1 \sum_{n=0}^{\infty} \frac{(-1)^{n}T^{2n+1}}{(2n+1)!}=0 \sin{T}=0 T=2\pi P(x)=a_0+a_1x+\frac{a_2}{2!}x^2+\frac{a_3}{3!}x^3+....+\frac{a_n}{n!}x^n f'(x)=P^{m}(f(x)) f''(x)=mP^{m-1}(f(x))P'(f(x))f'(x) f''(x)=mP^{2m-1}(f(x))P'(f(x))=m (f'(x))^{(2m-1)/m}P'(f(x)) m=1/2 f''(x)=\frac{P'(f(x))}{2} f'''(x)=f'(x)\frac{P''(f(x))}{2} f^{(4)}(x)=\frac{P'(f(x))P''(f(x))}{4}+f'(x)^2\frac{P'''(f(x))}{2} f^{(4)}(x)=\frac{P'(f(x))P''(f(x))}{4}+(P^{1/2}(f(x))^2\frac{P'''(f(x))}{2} f^{(4)}(x)=\frac{P'(f(x))P''(f(x))}{4}+\frac{P(f(x))P'''(f(x))}{2},"['sequences-and-series', 'functions', 'periodic-functions']"
79,Are functions satisfying a certain inequality monotone,Are functions satisfying a certain inequality monotone,,"Let $f: (0, \infty) \rightarrow (0,\infty)$ be a continuous function which satisfies the inequality $$f(x) + f(y) \geq 2f(x+y).$$ Is $f$ necessarily monotone?","Let $f: (0, \infty) \rightarrow (0,\infty)$ be a continuous function which satisfies the inequality $$f(x) + f(y) \geq 2f(x+y).$$ Is $f$ necessarily monotone?",,"['functions', 'functional-equations', 'monotone-functions']"
80,$f$ is $1-1$ iff $f(A)\cap f(B)\subset f(A\cap B)$,is  iff,f 1-1 f(A)\cap f(B)\subset f(A\cap B),"I propose that a function $f: X\rightarrow Y$ is injective if and only if for all subsets $A,B$ of $X$, $f(A)\cap f(B)\subset f(A\cap B)$. Let $f$ be $1-1$ and $A,B\subset X$. Let $y\in f(A)\cap f(B)$. Then there is $x_A\in A$ and $x_B\in B$ such that $y=f(x_A)=f(x_B)$. Since the function is injective, it must be the case that $x_A=x_B=x$ (say). $x\in A\cap B$. So $y=f(x)\in f(A\cap B)$. Therefore $f(A)\cap f(B)\subset f(A\cap B)$. Suppose now, that for all subsets $A,B$ of $X$ that $f(A)\cap f(B)\subset f(A\cap B)$ holds. Let $x_1,x_2\in X$ such that $f(x_1)=f(x_2)=y$ (say). Let $A:=${$x_1$} and $B:=${$x_2$}. If possible let $x_1≠x_2$. Then $A\cap B=\phi \implies f(A\cap B)=\phi.$ But, $f(A)\cap f(B)=${$y$}, which is nonempty. This contradicts the hypothesis. So $x_1=x_2$. It follows that $f$ is injective. Is the proof correct? Is there a simpler proof or an easy way to understand/visualize why this is true?","I propose that a function $f: X\rightarrow Y$ is injective if and only if for all subsets $A,B$ of $X$, $f(A)\cap f(B)\subset f(A\cap B)$. Let $f$ be $1-1$ and $A,B\subset X$. Let $y\in f(A)\cap f(B)$. Then there is $x_A\in A$ and $x_B\in B$ such that $y=f(x_A)=f(x_B)$. Since the function is injective, it must be the case that $x_A=x_B=x$ (say). $x\in A\cap B$. So $y=f(x)\in f(A\cap B)$. Therefore $f(A)\cap f(B)\subset f(A\cap B)$. Suppose now, that for all subsets $A,B$ of $X$ that $f(A)\cap f(B)\subset f(A\cap B)$ holds. Let $x_1,x_2\in X$ such that $f(x_1)=f(x_2)=y$ (say). Let $A:=${$x_1$} and $B:=${$x_2$}. If possible let $x_1≠x_2$. Then $A\cap B=\phi \implies f(A\cap B)=\phi.$ But, $f(A)\cap f(B)=${$y$}, which is nonempty. This contradicts the hypothesis. So $x_1=x_2$. It follows that $f$ is injective. Is the proof correct? Is there a simpler proof or an easy way to understand/visualize why this is true?",,"['functions', 'proof-verification', 'intuition']"
81,What is the correct function expression for the given graph and it's Fourier series?,What is the correct function expression for the given graph and it's Fourier series?,,"I first thought it was $$x\left(t\right)=\frac{4}{T}t$$ for $$0<t<T/4$$ But that would be the case if it wasn't periodic, then i thought that it was: $x\left(t\right)=\frac{4}{T}\left(t-T\right)$ But i'm not sure, and don't know how to plot it on graphing software to test it out. Can someone help me out? EDIT: The problem I had at hand is to find the Fourier series for this function and I tried for both the functions I had written here earlier, but neither got me the right solution, so I'm not sure now. Here is what I did so far:","I first thought it was $$x\left(t\right)=\frac{4}{T}t$$ for $$0<t<T/4$$ But that would be the case if it wasn't periodic, then i thought that it was: $x\left(t\right)=\frac{4}{T}\left(t-T\right)$ But i'm not sure, and don't know how to plot it on graphing software to test it out. Can someone help me out? EDIT: The problem I had at hand is to find the Fourier series for this function and I tried for both the functions I had written here earlier, but neither got me the right solution, so I'm not sure now. Here is what I did so far:",,['functions']
82,"Methods for finding some function $h$ with the property that, given two functions $f,g$, then $h\circ f=g\circ h$ is true?","Methods for finding some function  with the property that, given two functions , then  is true?","h f,g h\circ f=g\circ h","Given two functions $f,g$, I need to find a function $h$ such that $h\circ f=g\circ h$. For example, if $f(x)=x+1$ and $g(x)=x-1$ where $f,g:\Bbb Z\to\Bbb Z$. Then $h$ must have the property that $h(f(x))=g(h(x))\iff h(x+1)=h(x)-1$. Here it is easy to see that if $h(x)=-x$ the property holds, because $-(x+1)=-x-1$. Another example is if $f(x)=x+1$ and $g(x)=2x$, then $h(x+1)=2h(x)$ must be true, and if $h(x)=2^x$, then $h$ has the said property. But in this examples $h$ is found just intuitively, is there a general way to find $h$ for any given two functions $f$ and $g$? If there is not a general way, is there some specific way with specific choices of $f$ and $g$? Thanks.","Given two functions $f,g$, I need to find a function $h$ such that $h\circ f=g\circ h$. For example, if $f(x)=x+1$ and $g(x)=x-1$ where $f,g:\Bbb Z\to\Bbb Z$. Then $h$ must have the property that $h(f(x))=g(h(x))\iff h(x+1)=h(x)-1$. Here it is easy to see that if $h(x)=-x$ the property holds, because $-(x+1)=-x-1$. Another example is if $f(x)=x+1$ and $g(x)=2x$, then $h(x+1)=2h(x)$ must be true, and if $h(x)=2^x$, then $h$ has the said property. But in this examples $h$ is found just intuitively, is there a general way to find $h$ for any given two functions $f$ and $g$? If there is not a general way, is there some specific way with specific choices of $f$ and $g$? Thanks.",,"['functions', 'elementary-set-theory']"
83,Smallest prime of the form $68^k+k!+1$?,Smallest prime of the form ?,68^k+k!+1,"Let $f(n)$ be the smallest integer $k\ge 1$ such that $$n^k+k!+1$$ is prime or undefined if no such $k$ exists. I determined the values $f(n)$ for the even numbers $2,4,6,\cdots $ and $f(56)$ turned out to be $2138$ giving the huge prime $$56^{2138}+2138!+1$$ with $6194$ digits found by the PFGW-program (a software checking large numbers for primality). The first even $n$ for which I do not know whether $f(n)$ is defined is $n=68$ Is there a prime of the form $68^k+k!+1$ with integer $k\ge 1$ ? If such a $k$ exists , it must be greater than $24\ 000$.","Let $f(n)$ be the smallest integer $k\ge 1$ such that $$n^k+k!+1$$ is prime or undefined if no such $k$ exists. I determined the values $f(n)$ for the even numbers $2,4,6,\cdots $ and $f(56)$ turned out to be $2138$ giving the huge prime $$56^{2138}+2138!+1$$ with $6194$ digits found by the PFGW-program (a software checking large numbers for primality). The first even $n$ for which I do not know whether $f(n)$ is defined is $n=68$ Is there a prime of the form $68^k+k!+1$ with integer $k\ge 1$ ? If such a $k$ exists , it must be greater than $24\ 000$.",,"['functions', 'prime-numbers', 'factorial']"
84,Proof that a function is bijective if and only if it is both surjective and injective,Proof that a function is bijective if and only if it is both surjective and injective,,"I am given the usual definitions for surjectivity and injectivity, but I am introduced with an alternative formulation of bijectivity: Suppose $X$ and $Y$ are sets and $f:X\rightarrow Y$ a mapping. This mapping is said to be bijective if $\exists g:Y\rightarrow X$ such that $\forall x\in X,\ y\in Y$, $f(g(y))=y$ and $g(f(x))=x$. I have to proof that in this sense, bijectivity is equivalent to simultaneous injectivity and surjectivity. Now from bijectivity, I found it quite easy to prove the other two conditions. The other way around, however, poses some difficulty. My proof: Suppose $f:X\rightarrow Y$ is surjective and injective. I define the function $g:Y\rightarrow X$ by $g(y)=x\Longleftrightarrow f(x)=y$. Surjectivity of $f$ implies $\forall y\in Y\ \exists x\in X$ such that $f(x)=y$, thus $f(g(y))=y$. Now suppose $x,z\in X$ and $f(x)=f(z)$. Along with the definition of $g$ this implies $g(f(z))=x$. From injectivity follows $x=z$, thus $g(f(x))=x$. First of all, initially, I have not shown that $g$ is well-defined. I am not sure how to actually prove this, or if it is even necessary here. However, using surjectivity of $f$ is it easy to see that $g$ maps every value of $Y$. Can I conclude from this that the function is well-defined, or is there more to say on the matter? I suppose I would also have to show that $g$ cannot take on two different values of $x$ for the same $y$. Also, suppose I have proven that $g$ is indeed well-defined, is my proof as presented above correct? Thank you for your help! EDIT: From a discussion in the comments of an answer, I have come to realise that perhaps I have misused the term ""well-defined"". Since I don't really understand the formal definition, I will re-state a part of my question as follows: can I directly use $g$ as defined above, or do I have to prove that it is ""okay"" to use it? I'm really not sure how to say this anymore... intuitively, I would say that ""okay"" means that the definition itself does not produce any inconsistencies. If it is necessary to prove something about it prior to using it, what is it?","I am given the usual definitions for surjectivity and injectivity, but I am introduced with an alternative formulation of bijectivity: Suppose $X$ and $Y$ are sets and $f:X\rightarrow Y$ a mapping. This mapping is said to be bijective if $\exists g:Y\rightarrow X$ such that $\forall x\in X,\ y\in Y$, $f(g(y))=y$ and $g(f(x))=x$. I have to proof that in this sense, bijectivity is equivalent to simultaneous injectivity and surjectivity. Now from bijectivity, I found it quite easy to prove the other two conditions. The other way around, however, poses some difficulty. My proof: Suppose $f:X\rightarrow Y$ is surjective and injective. I define the function $g:Y\rightarrow X$ by $g(y)=x\Longleftrightarrow f(x)=y$. Surjectivity of $f$ implies $\forall y\in Y\ \exists x\in X$ such that $f(x)=y$, thus $f(g(y))=y$. Now suppose $x,z\in X$ and $f(x)=f(z)$. Along with the definition of $g$ this implies $g(f(z))=x$. From injectivity follows $x=z$, thus $g(f(x))=x$. First of all, initially, I have not shown that $g$ is well-defined. I am not sure how to actually prove this, or if it is even necessary here. However, using surjectivity of $f$ is it easy to see that $g$ maps every value of $Y$. Can I conclude from this that the function is well-defined, or is there more to say on the matter? I suppose I would also have to show that $g$ cannot take on two different values of $x$ for the same $y$. Also, suppose I have proven that $g$ is indeed well-defined, is my proof as presented above correct? Thank you for your help! EDIT: From a discussion in the comments of an answer, I have come to realise that perhaps I have misused the term ""well-defined"". Since I don't really understand the formal definition, I will re-state a part of my question as follows: can I directly use $g$ as defined above, or do I have to prove that it is ""okay"" to use it? I'm really not sure how to say this anymore... intuitively, I would say that ""okay"" means that the definition itself does not produce any inconsistencies. If it is necessary to prove something about it prior to using it, what is it?",,"['functions', 'elementary-set-theory', 'proof-verification']"
85,Find the domain and range of $y=\sqrt {x-2}$,Find the domain and range of,y=\sqrt {x-2},"Find the domain and range of $y=\sqrt {x-2}$ My Attempt: $$y=\sqrt {x-2}$$ For $y$ to be defined, $$(x-2)\geq 0$$ $$x\geq 2$$ So $dom(f)=[2,\infty)$.","Find the domain and range of $y=\sqrt {x-2}$ My Attempt: $$y=\sqrt {x-2}$$ For $y$ to be defined, $$(x-2)\geq 0$$ $$x\geq 2$$ So $dom(f)=[2,\infty)$.",,['functions']
86,Closed Form for $\sum_{n=0}^{\infty}x^{2^n}$,Closed Form for,\sum_{n=0}^{\infty}x^{2^n},"I am looking to find a closed form for $$f(x)=\sum_{n=0}^{\infty}x^{2^n}$$ $f$ exists on $|x|<1$ and we can immediately see that $f$ satisfies the functional equation $$f(x^2)=f(x)-x$$ Thus we only need to know $f$ on either $(-1, 0]$ or $[0,1)$. I really don't know how to proceed from here though. I would have thought this closed form was already known since it's so close to a geometric series, but I haven't been able to find it.","I am looking to find a closed form for $$f(x)=\sum_{n=0}^{\infty}x^{2^n}$$ $f$ exists on $|x|<1$ and we can immediately see that $f$ satisfies the functional equation $$f(x^2)=f(x)-x$$ Thus we only need to know $f$ on either $(-1, 0]$ or $[0,1)$. I really don't know how to proceed from here though. I would have thought this closed form was already known since it's so close to a geometric series, but I haven't been able to find it.",,"['calculus', 'sequences-and-series', 'functions', 'functional-equations']"
87,Find $f(x)$ where $ f(x)+f\left(\frac{1-x}x\right)=x$,Find  where,f(x)  f(x)+f\left(\frac{1-x}x\right)=x,What function satisfies $ f(x)+f\left(\frac{1-x}x\right)=x$ ?,What function satisfies $ f(x)+f\left(\frac{1-x}x\right)=x$ ?,,"['calculus', 'algebra-precalculus', 'functional-equations']"
88,Find the range of the following differentiable function,Find the range of the following differentiable function,,Let $f: R\to R$ be a differentiable function defined by $$f\left(\frac{x+y}{3} \right)=\frac{2+f(x)+f(y)}{3}$$  for all real $x$ and $y$ and $f'(2)=2$. Then (i) what is the range of $f(|x|)$ ? (ii)what is the number of solutions of the equation $x^2+(f(|x|))^2=9$? Progress: (i) $f\left(\frac{x+y}{3} \right)=\frac{2+f(x)+f(y)}{3} \implies f'\left(\frac{x+y}{3} \right). \left(1+y'\right)=f'(x)+f'(y)$. I stuck here.How can I find the range? and how can I find the number of solutions? Edit: $f\left(\frac{x+y}{3} \right)=\frac{2+f(x)+f(y)}{3} \implies f'\left(\frac{x+y}{3} \right). \left(1+y'\right)=f'(x)+f'(y) y'$.,Let $f: R\to R$ be a differentiable function defined by $$f\left(\frac{x+y}{3} \right)=\frac{2+f(x)+f(y)}{3}$$  for all real $x$ and $y$ and $f'(2)=2$. Then (i) what is the range of $f(|x|)$ ? (ii)what is the number of solutions of the equation $x^2+(f(|x|))^2=9$? Progress: (i) $f\left(\frac{x+y}{3} \right)=\frac{2+f(x)+f(y)}{3} \implies f'\left(\frac{x+y}{3} \right). \left(1+y'\right)=f'(x)+f'(y)$. I stuck here.How can I find the range? and how can I find the number of solutions? Edit: $f\left(\frac{x+y}{3} \right)=\frac{2+f(x)+f(y)}{3} \implies f'\left(\frac{x+y}{3} \right). \left(1+y'\right)=f'(x)+f'(y) y'$.,,"['functions', 'derivatives']"
89,A method to evaluate functional roots of $e^x$,A method to evaluate functional roots of,e^x,"I've an idea to find exact function $f(x)$ such that $f(f(x))=e^x$. But it involves solving complicated systems of non-linear equations, the skills for which I don't have. Here's how I intend to do it: The Taylor series of $e^x$ around $x=0$ is: $$1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+\frac{x^4}{4!}+......$$ If we assume our required function $f(x)$ to be: $$f(x)=a_nx^n+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+......a_2x^2+a_1x+a_0$$ i.e. a polynomial of degree $n$. From that we can get $f(f(x))$. I think it can be proved that the  $f(f(x))$ that we get will have terms containing all the powers of $x$ ranging from $x^{(n^2)}$ to $x^0$ (i.e. a constant term). Now, when $x$ is small the higher power terms don't matter, so we ignore the terms containing $x^{n+1}$, $x^{n+2}$.........$x^{(n^2)}$. After ignoring these terms, the remaining terms contain these powers of $x$: $x^0$, $x$, $x^2$,........$x^n$. Now, we compare the coefficients of these terms with the coefficients of the like powers of $x$ in the Taylor series of $e^x$. In this way, we get $n+1$ equations in $n+1$ variables. Now, we solve these equations to get the coefficients $a_0,a_1,a_2......a_n$. These will be functions of $n$ (I think). Now we apply $\lim_{n\rightarrow \infty}$ to these functions to get the exact value of coefficients. It would be a stressful task to solve those non-linear equations to get the coefficients in terms of $n$. But would this method work? EDIT: Even if $x$ is not small, the higher power terms can be ignored because the higher power terms will have very large factorials in their denominators. Also, we're applying $\lim_{n\rightarrow \infty}$ in the end and $\lim_{n\rightarrow \infty}\frac{x^n}{n!}=0$ for any finite $x$. EDIT:By using a first degree polynomial, I got this function, which when applied twice to $c$ gives you exactly $a^c$(not approximately because I didn't have to ignore any terms in case of a first degree polynomial) : $$x\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$  Problem is it itself depends upon $c$, so I guess there's a family of these square-root functions. Similarly, the $n^{th}$ root of $a^x$ at $x=c$ is: $$x(a^c\log_ea)^{\frac{1}{n}}+\frac{a^c(1-c\log_ea)}{\sum_{k=0}^{n-1}(a^c\log_ea)^{\frac{k}{n}}}$$ $$=x(a^c\log_ea)^{\frac{1}{n}}+\frac{a^c(1-c\log_ea)((a^c\log_ea)^{\frac{1}{n}}-1)}{a^c\log_ea-1}$$ At $x=c$, my square-root function is: $$c\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$. Now substituting this in place of $x$ is my function gives, $$\left(c\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}\right)\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$ $$=ca^c\log_ea+a^c(1-c\log_ea)$$ $$=a^c$$","I've an idea to find exact function $f(x)$ such that $f(f(x))=e^x$. But it involves solving complicated systems of non-linear equations, the skills for which I don't have. Here's how I intend to do it: The Taylor series of $e^x$ around $x=0$ is: $$1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+\frac{x^4}{4!}+......$$ If we assume our required function $f(x)$ to be: $$f(x)=a_nx^n+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+......a_2x^2+a_1x+a_0$$ i.e. a polynomial of degree $n$. From that we can get $f(f(x))$. I think it can be proved that the  $f(f(x))$ that we get will have terms containing all the powers of $x$ ranging from $x^{(n^2)}$ to $x^0$ (i.e. a constant term). Now, when $x$ is small the higher power terms don't matter, so we ignore the terms containing $x^{n+1}$, $x^{n+2}$.........$x^{(n^2)}$. After ignoring these terms, the remaining terms contain these powers of $x$: $x^0$, $x$, $x^2$,........$x^n$. Now, we compare the coefficients of these terms with the coefficients of the like powers of $x$ in the Taylor series of $e^x$. In this way, we get $n+1$ equations in $n+1$ variables. Now, we solve these equations to get the coefficients $a_0,a_1,a_2......a_n$. These will be functions of $n$ (I think). Now we apply $\lim_{n\rightarrow \infty}$ to these functions to get the exact value of coefficients. It would be a stressful task to solve those non-linear equations to get the coefficients in terms of $n$. But would this method work? EDIT: Even if $x$ is not small, the higher power terms can be ignored because the higher power terms will have very large factorials in their denominators. Also, we're applying $\lim_{n\rightarrow \infty}$ in the end and $\lim_{n\rightarrow \infty}\frac{x^n}{n!}=0$ for any finite $x$. EDIT:By using a first degree polynomial, I got this function, which when applied twice to $c$ gives you exactly $a^c$(not approximately because I didn't have to ignore any terms in case of a first degree polynomial) : $$x\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$  Problem is it itself depends upon $c$, so I guess there's a family of these square-root functions. Similarly, the $n^{th}$ root of $a^x$ at $x=c$ is: $$x(a^c\log_ea)^{\frac{1}{n}}+\frac{a^c(1-c\log_ea)}{\sum_{k=0}^{n-1}(a^c\log_ea)^{\frac{k}{n}}}$$ $$=x(a^c\log_ea)^{\frac{1}{n}}+\frac{a^c(1-c\log_ea)((a^c\log_ea)^{\frac{1}{n}}-1)}{a^c\log_ea-1}$$ At $x=c$, my square-root function is: $$c\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$. Now substituting this in place of $x$ is my function gives, $$\left(c\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}\right)\sqrt{a^c\log_ea}+\frac{a^c(1-c\log_ea)}{\sqrt{a^c\log_ea}+1}$$ $$=ca^c\log_ea+a^c(1-c\log_ea)$$ $$=a^c$$",,"['functions', 'polynomials']"
90,The playoff function,The playoff function,,"The setting Let's consider a single elimination tournament with $n=2^r$ teams. Usually the playoff tree is seeded in a way that the two top teams can meet no earlier than in the finals. Top 4 can't eliminate each other before semifinals etc. The playoff bracket that guarantees these properties is the one where the top team gets paired with the last team, second with second-to-last etc. To pair the second round matchups, rank the first round pairs according to the higher seed and use the same rule. In the end the playoff tree of 16 teams should look like this: 1 (p1)    wp1 16         (p1.2)     wp1.2 9 (p8)    wp8 8                    (p1.3)         wp1.3 5 (p5)    wp5 12         (p4.2)     wp4.2 13 (p4)    wp4 4                                  (p1.4)         wp1.4 3 (p3)    wp3 14         (p3.2)     wp3.2 11 (p6)    wp6 6                    (p2.3)         wp2.3 7 (p7)    wp7 10         (p2.2)     wp2.2 15 (p2)    wp2 2 With p[p] I mark a pair, a wp[p] is the winner of the pair p[p] . A good playoff tree is the one where any subtree has the same properties as described necessary for the whole tree. For example, consider this subtree in the upper tree: 3 (p3)    wp3 14         (p3.2)     wp3.2 11 (p6)    wp6 6 The two higher seeded teams (3 and 6) as on the very opposite sides of the bracket and can only meet at the latest stage. The strongest team here (3) is paired against the weakest of these (14). The question Let's number the slots in a round from top to the bottom. Given s(A) - the seeding of team A and n - the number of teams, what will be the function that would return i - the number of slot for this team in the bracket. What would be the inverse function (given slot number, return the teams seed - useful to find the opponent). Examples In a round of 16 ( n=16 ) we must place team with seed s=13 in the bracket. The slot number must be i=7 - that team must be the first in the 4th pair. For the inverse function, given that we placed s=13 in the 4th pair, we must find the opponent which will be the second team in that pair. So, given n=16 and the slot number i=8 we must get s=4 - seed of the 13s opponent. I am looking for a function that would be applicable for arbitrary n instead of hardcoding the seed-slot relations for limited number of n values. A note This is a problem that is usually solved programmatically either by hardcoding an ordering or by an iterative process. I am interested if it's replacable with a single mathematical function that you could plug in a number and get another one out for any n . The relation between seeds and slots is a uniquely (if you always start with 1st seed) defined bijection so obviously you could just say that the function exists and let's call it pOff(s) . As you could probably guess, I am interested if this function is expressable with another, previously defined functions (special functions, complex numbers etc. is ok if necessary).","The setting Let's consider a single elimination tournament with $n=2^r$ teams. Usually the playoff tree is seeded in a way that the two top teams can meet no earlier than in the finals. Top 4 can't eliminate each other before semifinals etc. The playoff bracket that guarantees these properties is the one where the top team gets paired with the last team, second with second-to-last etc. To pair the second round matchups, rank the first round pairs according to the higher seed and use the same rule. In the end the playoff tree of 16 teams should look like this: 1 (p1)    wp1 16         (p1.2)     wp1.2 9 (p8)    wp8 8                    (p1.3)         wp1.3 5 (p5)    wp5 12         (p4.2)     wp4.2 13 (p4)    wp4 4                                  (p1.4)         wp1.4 3 (p3)    wp3 14         (p3.2)     wp3.2 11 (p6)    wp6 6                    (p2.3)         wp2.3 7 (p7)    wp7 10         (p2.2)     wp2.2 15 (p2)    wp2 2 With p[p] I mark a pair, a wp[p] is the winner of the pair p[p] . A good playoff tree is the one where any subtree has the same properties as described necessary for the whole tree. For example, consider this subtree in the upper tree: 3 (p3)    wp3 14         (p3.2)     wp3.2 11 (p6)    wp6 6 The two higher seeded teams (3 and 6) as on the very opposite sides of the bracket and can only meet at the latest stage. The strongest team here (3) is paired against the weakest of these (14). The question Let's number the slots in a round from top to the bottom. Given s(A) - the seeding of team A and n - the number of teams, what will be the function that would return i - the number of slot for this team in the bracket. What would be the inverse function (given slot number, return the teams seed - useful to find the opponent). Examples In a round of 16 ( n=16 ) we must place team with seed s=13 in the bracket. The slot number must be i=7 - that team must be the first in the 4th pair. For the inverse function, given that we placed s=13 in the 4th pair, we must find the opponent which will be the second team in that pair. So, given n=16 and the slot number i=8 we must get s=4 - seed of the 13s opponent. I am looking for a function that would be applicable for arbitrary n instead of hardcoding the seed-slot relations for limited number of n values. A note This is a problem that is usually solved programmatically either by hardcoding an ordering or by an iterative process. I am interested if it's replacable with a single mathematical function that you could plug in a number and get another one out for any n . The relation between seeds and slots is a uniquely (if you always start with 1st seed) defined bijection so obviously you could just say that the function exists and let's call it pOff(s) . As you could probably guess, I am interested if this function is expressable with another, previously defined functions (special functions, complex numbers etc. is ok if necessary).",,"['functions', 'discrete-mathematics']"
91,$f(x)\in\mathbb{Q}[x]$ such that $f(\mathbb{Z})\subseteq \mathbb{Z}$ Then show that $f$ has the following form,such that  Then show that  has the following form,f(x)\in\mathbb{Q}[x] f(\mathbb{Z})\subseteq \mathbb{Z} f,"Let $f(x)\in\mathbb{Q}[x]$ be a polynomial of degree $n$ such that $f(\mathbb{Z})\subseteq \mathbb{Z}$. I want to show that $f$ has the following form $$f(x)=\sum_{j=0}^{j=n} a_{j}\binom{x}{j}$$ with $a_{j}\in \mathbb{Z}$ Attempt: Base case $n=0$, is clear Induction Hypothesis: Assume the result for degree$=n-1$ Consider the polynomial $\Delta f(x)=f(x+1)-f(x)$. One can observe that it has degree $n-1$, so  $\Delta f$ has the above mentioned form. Can I deduce something from here ? Any other approach ? Kindly correct the tags if necessary, I am studying Hilbert Polynomial and Hilbert Series. If I am correct, The above problem characterize all numerical polynomial.","Let $f(x)\in\mathbb{Q}[x]$ be a polynomial of degree $n$ such that $f(\mathbb{Z})\subseteq \mathbb{Z}$. I want to show that $f$ has the following form $$f(x)=\sum_{j=0}^{j=n} a_{j}\binom{x}{j}$$ with $a_{j}\in \mathbb{Z}$ Attempt: Base case $n=0$, is clear Induction Hypothesis: Assume the result for degree$=n-1$ Consider the polynomial $\Delta f(x)=f(x+1)-f(x)$. One can observe that it has degree $n-1$, so  $\Delta f$ has the above mentioned form. Can I deduce something from here ? Any other approach ? Kindly correct the tags if necessary, I am studying Hilbert Polynomial and Hilbert Series. If I am correct, The above problem characterize all numerical polynomial.",,"['functions', 'polynomials', 'induction']"
92,Graphing Complicated Functions,Graphing Complicated Functions,,"Recently, I was bombarded by dozens to ""sketch/graph the following function"" exercises. Some such functions are $y=x\sqrt{\frac{x}{4-x}}$ (cissoid of Diocles) , $y=e^{-x^2}$ (probability curve) , $y=x+\frac{1}{x}$ (trident of Newton) , and $y=\log{(\log x)}$. Currently, I have 2 methods: dumbly and tediously find $f(x)$ of several $x$ and plot the points; then interpolate the curve; or, plug the functions into Wolfram|Alpha (which isn't really me sketching the graph). Are there any methods that quicken the process of sketching a graph? I was thinking of a few methods, but they seem almost as tedious as functions get more complicated. For example, regarding the trident of Newton (see above): sketch $y=x$ and $y= \frac{1}{x}$ on the same graph. Then add the $y$ values to assemble the curve $y = x + \frac{1}{x}$. $^\text{Note: I added the soft-question tag because this question doesn't solve a particular problem; if this tag is not needed, feel free to remove it.}$","Recently, I was bombarded by dozens to ""sketch/graph the following function"" exercises. Some such functions are $y=x\sqrt{\frac{x}{4-x}}$ (cissoid of Diocles) , $y=e^{-x^2}$ (probability curve) , $y=x+\frac{1}{x}$ (trident of Newton) , and $y=\log{(\log x)}$. Currently, I have 2 methods: dumbly and tediously find $f(x)$ of several $x$ and plot the points; then interpolate the curve; or, plug the functions into Wolfram|Alpha (which isn't really me sketching the graph). Are there any methods that quicken the process of sketching a graph? I was thinking of a few methods, but they seem almost as tedious as functions get more complicated. For example, regarding the trident of Newton (see above): sketch $y=x$ and $y= \frac{1}{x}$ on the same graph. Then add the $y$ values to assemble the curve $y = x + \frac{1}{x}$. $^\text{Note: I added the soft-question tag because this question doesn't solve a particular problem; if this tag is not needed, feel free to remove it.}$",,"['functions', 'soft-question', 'graphing-functions']"
93,Approximation of Riemann integrable function with a continuous function,Approximation of Riemann integrable function with a continuous function,,"I have proved that if $f \in R[a,b]$ and given $\epsilon > 0$ there exists a continuous function $g$ such that $$\int_a^b |f-g| < \epsilon$$ I was wondering if using this fact there is some way to show that there is also some continuous function $h$ such that $$\int_a^b |f-h|^2 < \epsilon$$ Any help will be appreciated, thanks :)","I have proved that if $f \in R[a,b]$ and given $\epsilon > 0$ there exists a continuous function $g$ such that $$\int_a^b |f-g| < \epsilon$$ I was wondering if using this fact there is some way to show that there is also some continuous function $h$ such that $$\int_a^b |f-h|^2 < \epsilon$$ Any help will be appreciated, thanks :)",,['real-analysis']
94,Is there a name for $\frac{1}{\frac{1}{x} + \frac{1}{y}}$?,Is there a name for ?,\frac{1}{\frac{1}{x} + \frac{1}{y}},"The function $$\frac{1}{\;\;\dfrac{1}{x} + \dfrac1{y}\;\;}$$ shows up a lot, e.g., in parallel resistance or series conductance.  Does it have a name?  It is similar to harmonic mean with the difference that the numerator is one rather than the number of terms. Can it be called harmonic sum?  I think it stands to reason that since: you can replace $n$ series resistors with $n$ equal resistors having resistance equal to the mean of those resistors, you can replace $n$ parallel resistors with $n$ equal reistors having resistance equal to the harmonic mean of those resistance, and you can replace $n$ series resistor with 1 resistor having resistance equal to the sum of those resistors, then — by analogy — you should be able to replace $n$ parallel resistors with 1 resistor having resistance equal to the “harmonic sum” of those resistors. That is, mean is to harmonic mean as sum is to “ harmonic sum ”.","The function $$\frac{1}{\;\;\dfrac{1}{x} + \dfrac1{y}\;\;}$$ shows up a lot, e.g., in parallel resistance or series conductance.  Does it have a name?  It is similar to harmonic mean with the difference that the numerator is one rather than the number of terms. Can it be called harmonic sum?  I think it stands to reason that since: you can replace $n$ series resistors with $n$ equal resistors having resistance equal to the mean of those resistors, you can replace $n$ parallel resistors with $n$ equal reistors having resistance equal to the harmonic mean of those resistance, and you can replace $n$ series resistor with 1 resistor having resistance equal to the sum of those resistors, then — by analogy — you should be able to replace $n$ parallel resistors with 1 resistor having resistance equal to the “harmonic sum” of those resistors. That is, mean is to harmonic mean as sum is to “ harmonic sum ”.",,['functions']
95,Studies about $\sum_{k=1}^{n} x^{\frac 1k}$,Studies about,\sum_{k=1}^{n} x^{\frac 1k},"Are there any studies about this function?  $$f(x,n)=\sum_{k=1}^{n} x^{1/k}=x+x^{1/2}+x^{1/3}+x^{1/4}+\cdots +x^{1/n}$$ EDIT: My first notes about it. $f(1,n)=n$ $f'(1,n)=H_n$ $\int_0^1 \frac{f(x,n)}x\cdot dx=\frac{n^2+n}2$ where $f'(x,n)=\frac{d}{dx}f(x,n)$ To avoid fractional powers we can let $x=y^{n!}$ to change it into integer-powers, but the obtained polynomial does not have uniform paterm of powers. $$f(y,n)=\sum_{k=1}^{n}y^{n!/k}=y^{n!}+y^{n!/2}+y^{n!/3}+y^{n!/4}+\cdots+y^{n!/n}$$ $$=y^{n!/n}\left(y^{n!-(n!/n)}+y^{(n!/2)-(n!/n)}+y^{(n!/3)-(n!/n)}+y^{(n!/4)-(n!/n)}+\cdots+y^{(n!/(n-1))-(n!/n)}+1\right)$$ As example let $n=4$ $$f(y,4)=y^6(y^{18}+y^6+y^2+y+1)$$","Are there any studies about this function?  $$f(x,n)=\sum_{k=1}^{n} x^{1/k}=x+x^{1/2}+x^{1/3}+x^{1/4}+\cdots +x^{1/n}$$ EDIT: My first notes about it. $f(1,n)=n$ $f'(1,n)=H_n$ $\int_0^1 \frac{f(x,n)}x\cdot dx=\frac{n^2+n}2$ where $f'(x,n)=\frac{d}{dx}f(x,n)$ To avoid fractional powers we can let $x=y^{n!}$ to change it into integer-powers, but the obtained polynomial does not have uniform paterm of powers. $$f(y,n)=\sum_{k=1}^{n}y^{n!/k}=y^{n!}+y^{n!/2}+y^{n!/3}+y^{n!/4}+\cdots+y^{n!/n}$$ $$=y^{n!/n}\left(y^{n!-(n!/n)}+y^{(n!/2)-(n!/n)}+y^{(n!/3)-(n!/n)}+y^{(n!/4)-(n!/n)}+\cdots+y^{(n!/(n-1))-(n!/n)}+1\right)$$ As example let $n=4$ $$f(y,4)=y^6(y^{18}+y^6+y^2+y+1)$$",,"['sequences-and-series', 'functions', 'reference-request', 'summation', 'power-series']"
96,Continuity of a function of product spaces,Continuity of a function of product spaces,,"Let $f: X \times Y \rightarrow Z $ such that. $ \forall x_0 \in X , f_{x_0} : Y \rightarrow Z, y\mapsto f(x_0,y)$ is continuous. $ \forall y_0 \in Y , f_{y_0} : X \rightarrow Z, x \mapsto f(x,y_0)$ is continuous. How i can prove that $f$ is continuous? Thanks in advance.","Let $f: X \times Y \rightarrow Z $ such that. $ \forall x_0 \in X , f_{x_0} : Y \rightarrow Z, y\mapsto f(x_0,y)$ is continuous. $ \forall y_0 \in Y , f_{y_0} : X \rightarrow Z, x \mapsto f(x,y_0)$ is continuous. How i can prove that $f$ is continuous? Thanks in advance.",,['general-topology']
97,"Does cube root have domain $(-\infty ,+\infty )$ or not?",Does cube root have domain  or not?,"(-\infty ,+\infty )","I have an exercise for home to find the domain of : $$f(x)= {\sqrt[5]{(1/3)^x - (1/9)}\over \sqrt[3]{e^x - 1}} $$ The solution given by our teachers (and the book itself) is $(0,2]$. My problem is that the cube root and the 5th root can have negative numbers in it... So you only take the denominator $ 0$... However our teacher says this is wrong and we should take the roots $\ge 0$ Can someone explain me why?","I have an exercise for home to find the domain of : $$f(x)= {\sqrt[5]{(1/3)^x - (1/9)}\over \sqrt[3]{e^x - 1}} $$ The solution given by our teachers (and the book itself) is $(0,2]$. My problem is that the cube root and the 5th root can have negative numbers in it... So you only take the denominator $ 0$... However our teacher says this is wrong and we should take the roots $\ge 0$ Can someone explain me why?",,['functions']
98,What is the name for a function that behaves symmetrically when its arguments are scaled?,What is the name for a function that behaves symmetrically when its arguments are scaled?,,"In other words, is there a name for this property of a function $f$: $$f(\alpha x_1,x_2,\ldots,x_n) = f(x_1,\alpha x_2,\ldots,x_n) = \ldots = f(x_1,x_2,\ldots,\alpha x_n)$$ Edit: I appreciate the answers received; however, they focus on identifying the functions that have this property rather than giving the right term (if it exists). This question is about terminology. Even though the set of functions with this property is rather narrow, I was wondering whether there's a term or a combination of terms that would describe it. There are terms for similarly stated properties (e.g. symmetry and homogeneity/scale invariance); so I was hoping this property could be described as succinctly.","In other words, is there a name for this property of a function $f$: $$f(\alpha x_1,x_2,\ldots,x_n) = f(x_1,\alpha x_2,\ldots,x_n) = \ldots = f(x_1,x_2,\ldots,\alpha x_n)$$ Edit: I appreciate the answers received; however, they focus on identifying the functions that have this property rather than giving the right term (if it exists). This question is about terminology. Even though the set of functions with this property is rather narrow, I was wondering whether there's a term or a combination of terms that would describe it. There are terms for similarly stated properties (e.g. symmetry and homogeneity/scale invariance); so I was hoping this property could be described as succinctly.",,"['functions', 'terminology', 'symmetry']"
99,Prove that $f$ is invertible,Prove that  is invertible,f,"Did I show enough to prove $f$ is invertible? Alternatively is there a more efficient way to do so? Thanks in advance for any help. Let $f : X \rightarrow Y $a nd $g : Y \rightarrow X$ be functions. Assume $g\circ f$ is injective and   $f\circ g$ is surjective. Prove that $f$ is invertible i)First assume $a, b \in X$ and $f(a) = f(b)$. Then $(g \circ f)(a) = g(f(a)) = g(f(b)) =(g \circ f)(b)$. However, $g \circ f$ is injective. Therefore $a = b$. ii)Next assume $a \in X$. Since $f \circ g$ is surjective. Then there is $b\in Y$ such that $(f \circ g)(b) = a$. Set $c = g(b)$. Then $f(c) = f(g(b)) = a$ and $a \in Range(f)$. Since $a$ is arbitrary it follows that $Range(f) = X$. Thus since $f$ is both injective and surjective it is bijective and equivalently invertible.","Did I show enough to prove $f$ is invertible? Alternatively is there a more efficient way to do so? Thanks in advance for any help. Let $f : X \rightarrow Y $a nd $g : Y \rightarrow X$ be functions. Assume $g\circ f$ is injective and   $f\circ g$ is surjective. Prove that $f$ is invertible i)First assume $a, b \in X$ and $f(a) = f(b)$. Then $(g \circ f)(a) = g(f(a)) = g(f(b)) =(g \circ f)(b)$. However, $g \circ f$ is injective. Therefore $a = b$. ii)Next assume $a \in X$. Since $f \circ g$ is surjective. Then there is $b\in Y$ such that $(f \circ g)(b) = a$. Set $c = g(b)$. Then $f(c) = f(g(b)) = a$ and $a \in Range(f)$. Since $a$ is arbitrary it follows that $Range(f) = X$. Thus since $f$ is both injective and surjective it is bijective and equivalently invertible.",,"['functions', 'proof-verification']"
