,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,The discriminant of cyclotomic polynomial $\Phi_n(x)$,The discriminant of cyclotomic polynomial,\Phi_n(x),"Let $\Phi_n(x)$ be a cyclotomic polynomial, $n\in \mathbb{N}$ . Prove that $\mathrm{Disc}(\Phi_n(x)) = (-1)^{\frac {\phi(n)}{2}}n^{\phi(n)}\prod_{p\mid n,\, p\text{ prime}} {p}^{\frac {\phi(n)}{1-p}}$ I've found a solution for prime $n$ . For arbitrary $n$ we have $D(\Phi_n(x))=\prod_{\substack{1\le j<k\le n\\\gcd(j,n)=\gcd(k,n)=1}}(e^{\frac{2k\pi i}{n}}-e^{\frac{2j\pi i}{n}})^2$ . Also we have $\Phi_n(X) = \frac{x^n-1}{\prod_{d|n, d<n} \Phi_d(x)}$ . What can I get from that?","Let be a cyclotomic polynomial, . Prove that I've found a solution for prime . For arbitrary we have . Also we have . What can I get from that?","\Phi_n(x) n\in \mathbb{N} \mathrm{Disc}(\Phi_n(x)) = (-1)^{\frac {\phi(n)}{2}}n^{\phi(n)}\prod_{p\mid n,\, p\text{ prime}} {p}^{\frac {\phi(n)}{1-p}} n n D(\Phi_n(x))=\prod_{\substack{1\le j<k\le n\\\gcd(j,n)=\gcd(k,n)=1}}(e^{\frac{2k\pi i}{n}}-e^{\frac{2j\pi i}{n}})^2 \Phi_n(X) = \frac{x^n-1}{\prod_{d|n, d<n} \Phi_d(x)}","['abstract-algebra', 'polynomials', 'cyclotomic-polynomials', 'discriminant']"
1,"Show that if $G$ is abelian, and $|G| \equiv2 \mod 4$, then the number of elements of order $2$ in $G$ is $1$.","Show that if  is abelian, and , then the number of elements of order  in  is .",G |G| \equiv2 \mod 4 2 G 1,"I've tried proving it by contradiction, assuming the number of elements is different than one, which, by Sylows $3$, implies that $|G|=2^xm$ with $m$ odd. With that I managed to show that $m\equiv1\mod4$, but kinda got stuck there...","I've tried proving it by contradiction, assuming the number of elements is different than one, which, by Sylows $3$, implies that $|G|=2^xm$ with $m$ odd. With that I managed to show that $m\equiv1\mod4$, but kinda got stuck there...",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'sylow-theory']"
2,Prove that $R$ is commutative [duplicate],Prove that  is commutative [duplicate],R,"This question already has answers here : If $x^{2}-x\in Z(R)$ for all $x\in R$, then $R$ is commutative. (2 answers) Closed 5 years ago . Let $R$ be a ring such that   $$ x^2-x \in C(R) \quad \forall x \in R,$$   where $C(R)$ is the center of $R$. Prove that $R$ is commutative. I cannot find any route to proceed. How can I start? Please give hints instead of full solution.","This question already has answers here : If $x^{2}-x\in Z(R)$ for all $x\in R$, then $R$ is commutative. (2 answers) Closed 5 years ago . Let $R$ be a ring such that   $$ x^2-x \in C(R) \quad \forall x \in R,$$   where $C(R)$ is the center of $R$. Prove that $R$ is commutative. I cannot find any route to proceed. How can I start? Please give hints instead of full solution.",,"['abstract-algebra', 'ring-theory']"
3,Casimir Operator of $\mathfrak{sl}_n(\mathbb{C})$.,Casimir Operator of .,\mathfrak{sl}_n(\mathbb{C}),"If I have the Lie algebra $\mathfrak{g} = \mathfrak{sl}_n(\mathbb{C})$ and the trace form $B(x,y) = \text{tr}(x,y)$ for $x, y \in \mathfrak{g}$ how does one calculate by which scalar the Casimir element $C \in Z(\mathscr{U}(\mathfrak{g}))$ acts on the highest weight module $V(\lambda)$? I know that one defines the Casimir by $C = \sum_i x_i x_i^*$ where $\{x_i\}$ is a basis for the Lie algebra and $\{x_i^*\}$ a dual basis, which are arbitrary (i.e. C is independent of the choice of bases). I have calculated by hand some simple examples (n=3 acts by the scalar $\frac{8}{3}$ for example on V(2)). How should one proceed in general? Thanks.","If I have the Lie algebra $\mathfrak{g} = \mathfrak{sl}_n(\mathbb{C})$ and the trace form $B(x,y) = \text{tr}(x,y)$ for $x, y \in \mathfrak{g}$ how does one calculate by which scalar the Casimir element $C \in Z(\mathscr{U}(\mathfrak{g}))$ acts on the highest weight module $V(\lambda)$? I know that one defines the Casimir by $C = \sum_i x_i x_i^*$ where $\{x_i\}$ is a basis for the Lie algebra and $\{x_i^*\}$ a dual basis, which are arbitrary (i.e. C is independent of the choice of bases). I have calculated by hand some simple examples (n=3 acts by the scalar $\frac{8}{3}$ for example on V(2)). How should one proceed in general? Thanks.",,"['abstract-algebra', 'representation-theory', 'lie-algebras']"
4,Find the polynomials which satisfy the condition $f(x)\mid f(x^2)$,Find the polynomials which satisfy the condition,f(x)\mid f(x^2),"I want find the polynomials which satisfy the condition   $$f(x)\mid f(x^2).$$ I want to find such polynomials with integer coefficients , real number coefficients and complex number coefficients . For example, $x$ and $x-1$ are the linear polynomials which satisfy this condition. Here is one way to find the $2$-degree polynomials with integer coefficients .   Let the quadratic be $p=ax^2+bx+c$, so its value at $x^2$ is $q=ax^4+bx^2+c$. If $p$ is to be a divisor of $q$ let the other factor be $dx^2+ex+f.$ Equating coefficients gives equations [1]  $ad=a,$ [2] $ae+bd=0,$ [3] $af+be+cd=b,$ [4] $bf+ce=0,$ [5] $cf=c.$ Now we know $a,c$ are nonzero (else $p$ is not quadratic, or is reducible). So from [1] and [5] we have $d=f=1.$ Then from [2] and [4] we obtain $ae=ce.$ Here $e=0$ leads to $b=0$ from either [2] or [4], and [3] then reads $a+c=0$, so that $p=a(x^2-1)$ which is reducible. So we may assume $e$ is nonzero, and also $a=c.$ At this point, [2] and [4] say the same thing, namely $ae+b=0.$ So we may replace $b=-ae$ in [3] (with its $c$ replaced by $a$) obtaining   $a+(-ae)e+a=-ae,$ which on factoring gives $a(2-e)(e+1)=0.$ The possibility $e=2$ then leads after some algebra to $2a+b=0$ and $p=a(x-1)^2$ which is reducible, while the possibility $e=-1$ leads to $a=b$ and then $p=ax^2+ax+a$ as claimed. Should we list out all the irreducible degree polynomials and then check if these polynomials satisfy the condition $x$ $x+1$ $x^2 + x + 1$ $x^3 + x^2 + 1$ $x^3 + x + 1$ $ x^4 + x^3 + x^2 + x + 1 $ $ x^4 + x^3 + 1 $ $ x^4 + x + 1 $ With the real number coefficients which can be factored into $$(x-c_1)(x-c_2)\cdots(x^2-2a_1x-(a_1^2+b_1^2))(x^2-2a_2x-(a_2^2+b_2^2))\cdots$$ If all of these linear terms and quadratic terms satisfy $$f(x)\mid f(x^2),$$ this polynomial satisfy too? So what's pattern in the real number polynomials?","I want find the polynomials which satisfy the condition   $$f(x)\mid f(x^2).$$ I want to find such polynomials with integer coefficients , real number coefficients and complex number coefficients . For example, $x$ and $x-1$ are the linear polynomials which satisfy this condition. Here is one way to find the $2$-degree polynomials with integer coefficients .   Let the quadratic be $p=ax^2+bx+c$, so its value at $x^2$ is $q=ax^4+bx^2+c$. If $p$ is to be a divisor of $q$ let the other factor be $dx^2+ex+f.$ Equating coefficients gives equations [1]  $ad=a,$ [2] $ae+bd=0,$ [3] $af+be+cd=b,$ [4] $bf+ce=0,$ [5] $cf=c.$ Now we know $a,c$ are nonzero (else $p$ is not quadratic, or is reducible). So from [1] and [5] we have $d=f=1.$ Then from [2] and [4] we obtain $ae=ce.$ Here $e=0$ leads to $b=0$ from either [2] or [4], and [3] then reads $a+c=0$, so that $p=a(x^2-1)$ which is reducible. So we may assume $e$ is nonzero, and also $a=c.$ At this point, [2] and [4] say the same thing, namely $ae+b=0.$ So we may replace $b=-ae$ in [3] (with its $c$ replaced by $a$) obtaining   $a+(-ae)e+a=-ae,$ which on factoring gives $a(2-e)(e+1)=0.$ The possibility $e=2$ then leads after some algebra to $2a+b=0$ and $p=a(x-1)^2$ which is reducible, while the possibility $e=-1$ leads to $a=b$ and then $p=ax^2+ax+a$ as claimed. Should we list out all the irreducible degree polynomials and then check if these polynomials satisfy the condition $x$ $x+1$ $x^2 + x + 1$ $x^3 + x^2 + 1$ $x^3 + x + 1$ $ x^4 + x^3 + x^2 + x + 1 $ $ x^4 + x^3 + 1 $ $ x^4 + x + 1 $ With the real number coefficients which can be factored into $$(x-c_1)(x-c_2)\cdots(x^2-2a_1x-(a_1^2+b_1^2))(x^2-2a_2x-(a_2^2+b_2^2))\cdots$$ If all of these linear terms and quadratic terms satisfy $$f(x)\mid f(x^2),$$ this polynomial satisfy too? So what's pattern in the real number polynomials?",,"['abstract-algebra', 'polynomials', 'field-theory', 'irreducible-polynomials']"
5,Abelian group (Commutative group) [duplicate],Abelian group (Commutative group) [duplicate],,"This question already has an answer here : Show that $\forall x,y\in G$, $(xy)^2=x^2y^2\iff G $ is an abelian group. (1 answer) Closed 5 years ago . Prove that if in a group $(ab)^2= a^2 b^2$ then the group is commutative. I am having a hard time doing this. Here is what I have so far: Proof: $a^2 b^2= a^1 a^1 b^1 b^1$ =$aa^{-1}bb$ =ebb Hence,$aa^{-1}=e$ I am stuck, I do not know if this is the right process in proving this","This question already has an answer here : Show that $\forall x,y\in G$, $(xy)^2=x^2y^2\iff G $ is an abelian group. (1 answer) Closed 5 years ago . Prove that if in a group $(ab)^2= a^2 b^2$ then the group is commutative. I am having a hard time doing this. Here is what I have so far: Proof: $a^2 b^2= a^1 a^1 b^1 b^1$ =$aa^{-1}bb$ =ebb Hence,$aa^{-1}=e$ I am stuck, I do not know if this is the right process in proving this",,['abstract-algebra']
6,Products in the slice category Sets/I,Products in the slice category Sets/I,,"I'm trying to work my way through a category theory textbook on my own (Awodey's) and came across a problem asking about groups in a slice category $\mathbf{Sets}/I$ for any set $I$. For a group to exist in a category, Awodey said it must have finite products, which makes sense, since we need products to define a binary operation. Which led me to think about what a product is in $\mathbf{Sets}/I$ I figured the obvious candidate would likely be an arrow whose domain is the product in $\mathbf{Sets}$ but that doesn't seem to work, as follows. Let $I$ be the set $\{1,2\}$, then consider the sets $\{1\}$, $\{2\}$. For objects in the slice category, take functions $i,j$ which will be the embeddings $\{1\}\rightarrow \{1,2\}$ and $\{2\}\rightarrow \{1,2\}$ respectively. Suppose there is a product $i\times j$ which has as its domain the set $\{(1,2)\}$. Let $\bar 1,\bar 2:\{(1,2)\}\rightarrow \{1,2\}$ denote the constant functions which map to 1 and 2 respectively. Then, $i\circ \bar 1:\{(1,2)\}\rightarrow \{1,2\}$ is the constant function which maps to 1, and $i\circ\bar 2$ is the constant function which maps to 2. There's no single choice for $i\times j$ which makes it an actual candidate to be a product. (I also don't think disjoint union works, it doesn't satisfy the UMP I don't think.) So then, what is a product in $\mathbf{Sets}/I$, and if it is some function from the product in $\mathbf{Sets}$ where's the mistake in my reasoning above?","I'm trying to work my way through a category theory textbook on my own (Awodey's) and came across a problem asking about groups in a slice category $\mathbf{Sets}/I$ for any set $I$. For a group to exist in a category, Awodey said it must have finite products, which makes sense, since we need products to define a binary operation. Which led me to think about what a product is in $\mathbf{Sets}/I$ I figured the obvious candidate would likely be an arrow whose domain is the product in $\mathbf{Sets}$ but that doesn't seem to work, as follows. Let $I$ be the set $\{1,2\}$, then consider the sets $\{1\}$, $\{2\}$. For objects in the slice category, take functions $i,j$ which will be the embeddings $\{1\}\rightarrow \{1,2\}$ and $\{2\}\rightarrow \{1,2\}$ respectively. Suppose there is a product $i\times j$ which has as its domain the set $\{(1,2)\}$. Let $\bar 1,\bar 2:\{(1,2)\}\rightarrow \{1,2\}$ denote the constant functions which map to 1 and 2 respectively. Then, $i\circ \bar 1:\{(1,2)\}\rightarrow \{1,2\}$ is the constant function which maps to 1, and $i\circ\bar 2$ is the constant function which maps to 2. There's no single choice for $i\times j$ which makes it an actual candidate to be a product. (I also don't think disjoint union works, it doesn't satisfy the UMP I don't think.) So then, what is a product in $\mathbf{Sets}/I$, and if it is some function from the product in $\mathbf{Sets}$ where's the mistake in my reasoning above?",,"['abstract-algebra', 'category-theory']"
7,"Show that $\mathbb{Q}(a)/\mathbb{Q}$ is normal, where $a$ is a root of the irreducible polynomial $x^3-3x-1$","Show that  is normal, where  is a root of the irreducible polynomial",\mathbb{Q}(a)/\mathbb{Q} a x^3-3x-1,"We have that $E=\mathbb{Q}(a)$, where $a\in \mathbb{C}$ is a root of the irreducible polynomial $x^3-3x-1\in \mathbb{Q}[x]$. I want to show that $E/\mathbb{Q}$ is normal. I have done the following: Let $b\in E$.  A basis of the extension is $1, a, a^2$. So, $b$ can be written as $$b=q_0+q_1a+q_2a^2$$ We have to find the minimal irreducible polynomial of $b$ over $\mathbb{Q}$ and compute the other roots to check if they are in $E$, or not? Since $[E:\mathbb{Q}]=3$, we have that $\deg m(b,\mathbb{Q})\leq 3$. So, the general form of that polynomial is $Ax^3+Bx^2+Cx+D$. So, do we have to replace $x$ with $b=q_0+q_1a+q_2a^2$, compute that polynomial, knowing that $a^3=3a+1$, and find the other roots? Or is there an other way to show that?","We have that $E=\mathbb{Q}(a)$, where $a\in \mathbb{C}$ is a root of the irreducible polynomial $x^3-3x-1\in \mathbb{Q}[x]$. I want to show that $E/\mathbb{Q}$ is normal. I have done the following: Let $b\in E$.  A basis of the extension is $1, a, a^2$. So, $b$ can be written as $$b=q_0+q_1a+q_2a^2$$ We have to find the minimal irreducible polynomial of $b$ over $\mathbb{Q}$ and compute the other roots to check if they are in $E$, or not? Since $[E:\mathbb{Q}]=3$, we have that $\deg m(b,\mathbb{Q})\leq 3$. So, the general form of that polynomial is $Ax^3+Bx^2+Cx+D$. So, do we have to replace $x$ with $b=q_0+q_1a+q_2a^2$, compute that polynomial, knowing that $a^3=3a+1$, and find the other roots? Or is there an other way to show that?",,"['abstract-algebra', 'extension-field', 'irreducible-polynomials']"
8,Maximal ideals of $\mathbb{Z}[\sqrt{-5}]$,Maximal ideals of,\mathbb{Z}[\sqrt{-5}],"Let $\mathbb{Z}$ be the ring of integers, and $R=\mathbb{Z}[\sqrt{-5}]=\{a+\sqrt{-5}b\mid a, b\in\mathbb{Z}\}$ . Is there any characterization for maximal ideals of $R$ with respect to maximal ideals of $\mathbb{Z}$ or other description for them? Thanks for any help.","Let be the ring of integers, and . Is there any characterization for maximal ideals of with respect to maximal ideals of or other description for them? Thanks for any help.","\mathbb{Z} R=\mathbb{Z}[\sqrt{-5}]=\{a+\sqrt{-5}b\mid a, b\in\mathbb{Z}\} R \mathbb{Z}","['abstract-algebra', 'ideals', 'maximal-and-prime-ideals']"
9,"Ideal of $\mathbb{Z}[\sqrt{10}]$: principal, prime or maximal?","Ideal of : principal, prime or maximal?",\mathbb{Z}[\sqrt{10}],"my task is following Let $I=\{a+b\sqrt{10}:13\mid2a-b\}$ be a subset of the ring $\mathbb{Z}[\sqrt{10}]$. Decide if $I$ is an ideal of $\mathbb{Z}[\sqrt{10}]$ and if so, decide if it is principal, prime or maximal. I've proved that $I$ is ideal indeed (addition is trivial and it is closed under multiplication because $13\mid2a-b\ \Leftrightarrow\ 13\mid a-20b$). But I have problem with the properties of $I$. I know that $I$ is prime/maximal iff $\mathbb{Z}[\sqrt{10}]/I$ is an integral domain / a field. I don't know, how to continue -- $I$ is kernel of some ring homomorphism, but I have no idea how to use it. I suppose we would like to use something like $f:\mathbb{Z}[\sqrt{10}]\to\mathbb{Z}_{13},a+b\sqrt{10}\mapsto[2a-b]_{13}$ but is this even a map?... Edit: oh, of course $f$ is a map, since the element $a+b\sqrt{10}$ represents only itself...","my task is following Let $I=\{a+b\sqrt{10}:13\mid2a-b\}$ be a subset of the ring $\mathbb{Z}[\sqrt{10}]$. Decide if $I$ is an ideal of $\mathbb{Z}[\sqrt{10}]$ and if so, decide if it is principal, prime or maximal. I've proved that $I$ is ideal indeed (addition is trivial and it is closed under multiplication because $13\mid2a-b\ \Leftrightarrow\ 13\mid a-20b$). But I have problem with the properties of $I$. I know that $I$ is prime/maximal iff $\mathbb{Z}[\sqrt{10}]/I$ is an integral domain / a field. I don't know, how to continue -- $I$ is kernel of some ring homomorphism, but I have no idea how to use it. I suppose we would like to use something like $f:\mathbb{Z}[\sqrt{10}]\to\mathbb{Z}_{13},a+b\sqrt{10}\mapsto[2a-b]_{13}$ but is this even a map?... Edit: oh, of course $f$ is a map, since the element $a+b\sqrt{10}$ represents only itself...",,"['abstract-algebra', 'ring-theory', 'ideals', 'maximal-and-prime-ideals']"
10,Does there exist a non-PIR in which every countably generated prime ideal is principal?,Does there exist a non-PIR in which every countably generated prime ideal is principal?,,"Is there a commutative ring $R$ such that all the countably generated primes are principal, but $R$ is not a principal ideal ring? I know that if all the prime ideals are principal, then all the ideals are principal (see here ; this answer doesn't need $R$ to ba a domain at all). On the other hand, any commutative ring such that countably generated ideals are principal, is a PIR (see here ). Notice that since the ring $R$ of algebraic integers is a non-Noetherian Bezout domain, all the finitely-generated (prime) ideals are principal, but $R$ is not a PIR. I tried some examples of non-PIR rings without too many prime ideals. The extreme case is only one prime ideal, for instance Artin and local, but the unique prime ideal wasn't principal in the examples I found. As pointed out by Alex Youcis in the comment below, this can't work since any Artin ring is noetherian. I wanted to search for local zero-dimensional rings, but I didn't know how. Thank you for your help!","Is there a commutative ring $R$ such that all the countably generated primes are principal, but $R$ is not a principal ideal ring? I know that if all the prime ideals are principal, then all the ideals are principal (see here ; this answer doesn't need $R$ to ba a domain at all). On the other hand, any commutative ring such that countably generated ideals are principal, is a PIR (see here ). Notice that since the ring $R$ of algebraic integers is a non-Noetherian Bezout domain, all the finitely-generated (prime) ideals are principal, but $R$ is not a PIR. I tried some examples of non-PIR rings without too many prime ideals. The extreme case is only one prime ideal, for instance Artin and local, but the unique prime ideal wasn't principal in the examples I found. As pointed out by Alex Youcis in the comment below, this can't work since any Artin ring is noetherian. I wanted to search for local zero-dimensional rings, but I didn't know how. Thank you for your help!",,"['abstract-algebra', 'commutative-algebra', 'ideals', 'maximal-and-prime-ideals']"
11,Are there multidimensional algebraic numbers that aren't algebraic numbers?,Are there multidimensional algebraic numbers that aren't algebraic numbers?,,"Note, in the following, when I'm talking about solutions in multiple dimensions compared to ones in one dimension, what I mean is that each coordinate on its own should be considered a single-dimensional solution. So for instance, if I get $\begin{bmatrix} x\\ y \end{bmatrix} = \begin{bmatrix} s_1\\ s_2 \end{bmatrix}$, then I consider $s_1$ and $s_2$ two separate solutions, eventhough they normally clearly are only one solution of a two-dimensional problem. This is so I can actually compare with one-dimensional solutions. The whole premise of the question wouldn't make sense if not for that. The set of algebraic numbers is the set of roots of polynomials of arbitrary degree $n$ with integer coefficients $a_i$. $$P_n{\left[x\right]} = \sum_{i = 0}^{n}{a_i x^i}\\ \mathbb{\overline{Q}_n} : \left\{ x | P_n{\left[x\right]} = 0 \right\}\\ \mathbb{\overline{Q}} : \text{values of } \mathbb{\overline{Q}_n}\text{ for any } n.$$ If you try plugging in algebraic numbers as coefficients for those polynomials, you won't find anything new. The solutions will all be algebraic numbers as well. Is this also true if you allow higher-dimensional polynomials? Say you have a polynomial of the form $a_{2 0} x^2 + a_{0 2} y^2 + a_{1 1} x y + a_{1 0} x + a_{0 1} y + a_{0 0} = 0$ where $a_{i j} \in \mathbb{Z}$ and $a_{2 0}, a_{0 2}, a_{1 1}$ can't all be zero. If I'm not mistaken, this will not yet suffice since you'll get infinitely many solutions that form a $1$-dimensional subspace. So let's add a second polynomial of the same form to fix a couple points. $$\begin{align*} a_{2 0} x^2 + a_{0 2} y^2 + a_{1 1} x y + a_{1 0} x + a_{0 1} y + a_{0 0} & = 0 \\ b_{2 0} x^2 + b_{0 2} y^2 + b_{1 1} x y + b_{1 0} x + b_{0 1} y + b_{0 0} & = 0 \\ a_{i j}, b_{i j} & \in \mathbb{Z} \end{align*}$$ and the six highest degree terms can't all be zero, so that at least one polynomial has degree $2$. As long as these equations are independent, only a discrete finite set of solutions should be left over. I declare these solutions to be two-dimensional algebraic numbers of the second degree. Are these solutions the same as (one-dimensional) algebraic numbers? By trying out this scheme for the first degree case (so just systems of linear equations), it is easy to see that the results will just be rational numbers which already are fully covered by (one-dimensional) first degree algebraic numbers (i.e. Integers and Rational Numbers). Based on that result, my hunch is that the answer to the title question will be negative: Algebraic numbers already fully cover this case for all degrees and all dimensions. But of course, the degree $1$ case is trivially represented in linear algebra, so it could easily be the case that non-algebraic solutions exist only for higher degrees. So is my hunch correct? Bonus question 1: (Assuming my hunch is right) Will higher dimensional solutions change in degree? I.e. Can I represent (one-dimensional) algebraic numbers of degree $>n$ as solutions to systems of multidimensional polynomial equations of degree $n$? Solution counting henceforth will be in the normal sense: $\begin{bmatrix} x\\y\end{bmatrix} = \begin{bmatrix}s_1\\s_2\end{bmatrix}$ is only one solution. Bonus question 2: Up to how many solutions will a system of polynomial equations of degree $n$ in $d$ dimensions generally have?","Note, in the following, when I'm talking about solutions in multiple dimensions compared to ones in one dimension, what I mean is that each coordinate on its own should be considered a single-dimensional solution. So for instance, if I get $\begin{bmatrix} x\\ y \end{bmatrix} = \begin{bmatrix} s_1\\ s_2 \end{bmatrix}$, then I consider $s_1$ and $s_2$ two separate solutions, eventhough they normally clearly are only one solution of a two-dimensional problem. This is so I can actually compare with one-dimensional solutions. The whole premise of the question wouldn't make sense if not for that. The set of algebraic numbers is the set of roots of polynomials of arbitrary degree $n$ with integer coefficients $a_i$. $$P_n{\left[x\right]} = \sum_{i = 0}^{n}{a_i x^i}\\ \mathbb{\overline{Q}_n} : \left\{ x | P_n{\left[x\right]} = 0 \right\}\\ \mathbb{\overline{Q}} : \text{values of } \mathbb{\overline{Q}_n}\text{ for any } n.$$ If you try plugging in algebraic numbers as coefficients for those polynomials, you won't find anything new. The solutions will all be algebraic numbers as well. Is this also true if you allow higher-dimensional polynomials? Say you have a polynomial of the form $a_{2 0} x^2 + a_{0 2} y^2 + a_{1 1} x y + a_{1 0} x + a_{0 1} y + a_{0 0} = 0$ where $a_{i j} \in \mathbb{Z}$ and $a_{2 0}, a_{0 2}, a_{1 1}$ can't all be zero. If I'm not mistaken, this will not yet suffice since you'll get infinitely many solutions that form a $1$-dimensional subspace. So let's add a second polynomial of the same form to fix a couple points. $$\begin{align*} a_{2 0} x^2 + a_{0 2} y^2 + a_{1 1} x y + a_{1 0} x + a_{0 1} y + a_{0 0} & = 0 \\ b_{2 0} x^2 + b_{0 2} y^2 + b_{1 1} x y + b_{1 0} x + b_{0 1} y + b_{0 0} & = 0 \\ a_{i j}, b_{i j} & \in \mathbb{Z} \end{align*}$$ and the six highest degree terms can't all be zero, so that at least one polynomial has degree $2$. As long as these equations are independent, only a discrete finite set of solutions should be left over. I declare these solutions to be two-dimensional algebraic numbers of the second degree. Are these solutions the same as (one-dimensional) algebraic numbers? By trying out this scheme for the first degree case (so just systems of linear equations), it is easy to see that the results will just be rational numbers which already are fully covered by (one-dimensional) first degree algebraic numbers (i.e. Integers and Rational Numbers). Based on that result, my hunch is that the answer to the title question will be negative: Algebraic numbers already fully cover this case for all degrees and all dimensions. But of course, the degree $1$ case is trivially represented in linear algebra, so it could easily be the case that non-algebraic solutions exist only for higher degrees. So is my hunch correct? Bonus question 1: (Assuming my hunch is right) Will higher dimensional solutions change in degree? I.e. Can I represent (one-dimensional) algebraic numbers of degree $>n$ as solutions to systems of multidimensional polynomial equations of degree $n$? Solution counting henceforth will be in the normal sense: $\begin{bmatrix} x\\y\end{bmatrix} = \begin{bmatrix}s_1\\s_2\end{bmatrix}$ is only one solution. Bonus question 2: Up to how many solutions will a system of polynomial equations of degree $n$ in $d$ dimensions generally have?",,"['abstract-algebra', 'algebraic-geometry', 'polynomials', 'roots']"
12,Let $G$ be a finite group and $g \in G$. Then the order of $g$ is finite.,Let  be a finite group and . Then the order of  is finite.,G g \in G g,"Let $G$ be a finite group and $g \in G$. Then the order of $g$ is finite. I know that  if $g$ has finite order, then $g^k = e$ for a finite $k$, but i'm not really sure how to get started showing this. Since there is a finite number of elements in $G$, it makes intuitive sense that this result should be true.","Let $G$ be a finite group and $g \in G$. Then the order of $g$ is finite. I know that  if $g$ has finite order, then $g^k = e$ for a finite $k$, but i'm not really sure how to get started showing this. Since there is a finite number of elements in $G$, it makes intuitive sense that this result should be true.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
13,Every module is a direct limit of finitely presented modules,Every module is a direct limit of finitely presented modules,,"I want to solve the problem in the title. A right $R$-module $M$ is finitely presented if there is an exact sequence $$0\to K\to R^n\to M\to 0$$ with $K$ finitely generated, or equivalently if there is a sequence $$R^m\to R^n\to M\to 0.$$ Let $M\in\text{Mod}-R$ and consider $\mathcal{S}=\{N\leq M :N\text{ is finitely presented}\}$. $\mathcal{S}$ is a poset with $\subseteq$ relation. It's also directed: in fact If $N_1, N_2$ are finitely presented, then we have exact sequences $$0\to K_1\to R^{n_1}\to N_1\to 0$$ $$0\to K_2\to R^{n_2}\to N_2\to 0$$ So $$0\to K_1\oplus K_2\to R^{n_1+n_2}\to N_1\oplus N_2\to 0$$ $K_1\oplus K_2$ is finitely generated, so $N_1\oplus N_2$ is finitely presented. So i can consider $\displaystyle \varinjlim_{N\in \mathcal{}S}N=\bigoplus_{N\in \mathcal{S}}N=\bigcup_{N\in\mathcal{S}}N$.  I want that it is $M$. So i have to prove that each $m\in M$ belongs to some finitely presented submodule of $M$.","I want to solve the problem in the title. A right $R$-module $M$ is finitely presented if there is an exact sequence $$0\to K\to R^n\to M\to 0$$ with $K$ finitely generated, or equivalently if there is a sequence $$R^m\to R^n\to M\to 0.$$ Let $M\in\text{Mod}-R$ and consider $\mathcal{S}=\{N\leq M :N\text{ is finitely presented}\}$. $\mathcal{S}$ is a poset with $\subseteq$ relation. It's also directed: in fact If $N_1, N_2$ are finitely presented, then we have exact sequences $$0\to K_1\to R^{n_1}\to N_1\to 0$$ $$0\to K_2\to R^{n_2}\to N_2\to 0$$ So $$0\to K_1\oplus K_2\to R^{n_1+n_2}\to N_1\oplus N_2\to 0$$ $K_1\oplus K_2$ is finitely generated, so $N_1\oplus N_2$ is finitely presented. So i can consider $\displaystyle \varinjlim_{N\in \mathcal{}S}N=\bigoplus_{N\in \mathcal{S}}N=\bigcup_{N\in\mathcal{S}}N$.  I want that it is $M$. So i have to prove that each $m\in M$ belongs to some finitely presented submodule of $M$.",,"['abstract-algebra', 'category-theory', 'modules', 'limits-colimits']"
14,$G$ is a $p$-group $\implies $ $G$ has a normal subgroup of $p^k \ \forall k$,is a -group   has a normal subgroup of,G p \implies  G p^k \ \forall k,"I am a beginner to $p$ -groups, so please help me with the following qustion: If $|G|=p^n$ , where $p$ is prime, and $0\le k\le n$ , then $G$ contains a normal subgroup of order $p^k$ . My work: I have just been able to prove that $G$ has a normal subgroup of order $p$ . Since $G$ is a $p$ group, its center $Z(G)\ne \{e\}$ $\therefore$ $Z(G)$ is $p$ -subgroup of $G$ .By Cauchy's lemma, there is an element $a\in Z(G)$ such that $|a|=p$ .Then $N=\langle a\rangle$ is a subgroup of order $p$ .Moreover since every subgroup of $Z(G)$ is normal in $G$ , $\therefore$ $N\triangleleft G$ . Now I dont know how to proceed. Maybe induction will help? Or is there some better way?","I am a beginner to -groups, so please help me with the following qustion: If , where is prime, and , then contains a normal subgroup of order . My work: I have just been able to prove that has a normal subgroup of order . Since is a group, its center is -subgroup of .By Cauchy's lemma, there is an element such that .Then is a subgroup of order .Moreover since every subgroup of is normal in , . Now I dont know how to proceed. Maybe induction will help? Or is there some better way?",p |G|=p^n p 0\le k\le n G p^k G p G p Z(G)\ne \{e\} \therefore Z(G) p G a\in Z(G) |a|=p N=\langle a\rangle p Z(G) G \therefore N\triangleleft G,"['abstract-algebra', 'finite-groups', 'normal-subgroups', 'p-groups']"
15,$\beta\alpha$ in ideal $I$ for all $\alpha\in I$ $\implies$ $\beta$ is algebraic integer,in ideal  for all    is algebraic integer,\beta\alpha I \alpha\in I \implies \beta,"This is my second question on Problem 8.21 on p.119 of The Theory of Algebraic Numbers by Harry Pollard and Harold G. Diamond (Dover edition); my first question has been answered . Let $R=\mathcal O_K$ be the ring of integers of an algebraic field $K=\mathbb Q(\theta)$ for some $\theta$ algebraic over $\mathbb Q$. If $I\ne\{0\}$ is an ideal of $R$ and $\beta\in K$ is such that $\beta\alpha\in I$ for all $\alpha\in I$, prove that $\beta\in R$. It is important that $K$ and $R$ be so defined, otherwise the result won't be true, as the counterexamples in my first question show. By studying the counterexamples, I presume that what may be important here are principally generated ideals. The ideal $I$ need not be principal but (by Theorem 8.13 on p.109 of the book) there exists an ideal $J\ne\{0\}$ such that the product $IJ$ is principally generated by a rational integer, i.e. $IJ=(c)$ where $c\in\mathbb Z$. I suspect this may be useful in solving the problem. Another notion which may be useful is, given an ideal $I$, the set defined as $I^{-1}=\{\gamma\in K:\gamma\alpha\in R\ \text{for all}\ \alpha\in I\}$. Thus $\beta\in I^{-1}$ in the problem. If $J$ is an ideal, $JI^{-1}$ is defined as the set of all finite sums of products of elements of $J$ and of $I^{-1}$; if $J\subseteq I$ then $JI^{-1}$ is an ideal. I have been puzzling over this problem for a while and would welcome any help with it. Thanks.","This is my second question on Problem 8.21 on p.119 of The Theory of Algebraic Numbers by Harry Pollard and Harold G. Diamond (Dover edition); my first question has been answered . Let $R=\mathcal O_K$ be the ring of integers of an algebraic field $K=\mathbb Q(\theta)$ for some $\theta$ algebraic over $\mathbb Q$. If $I\ne\{0\}$ is an ideal of $R$ and $\beta\in K$ is such that $\beta\alpha\in I$ for all $\alpha\in I$, prove that $\beta\in R$. It is important that $K$ and $R$ be so defined, otherwise the result won't be true, as the counterexamples in my first question show. By studying the counterexamples, I presume that what may be important here are principally generated ideals. The ideal $I$ need not be principal but (by Theorem 8.13 on p.109 of the book) there exists an ideal $J\ne\{0\}$ such that the product $IJ$ is principally generated by a rational integer, i.e. $IJ=(c)$ where $c\in\mathbb Z$. I suspect this may be useful in solving the problem. Another notion which may be useful is, given an ideal $I$, the set defined as $I^{-1}=\{\gamma\in K:\gamma\alpha\in R\ \text{for all}\ \alpha\in I\}$. Thus $\beta\in I^{-1}$ in the problem. If $J$ is an ideal, $JI^{-1}$ is defined as the set of all finite sums of products of elements of $J$ and of $I^{-1}$; if $J\subseteq I$ then $JI^{-1}$ is an ideal. I have been puzzling over this problem for a while and would welcome any help with it. Thanks.",,"['abstract-algebra', 'algebraic-number-theory', 'ideals']"
16,Commutative endomorphism rings.,Commutative endomorphism rings.,,"Let $A$ be a commutative ring, and $M$ an $A$ -module. Are there some reasonably general conditions (both on $A$ or $M$ ) assuring that the ring $\mathrm{End}_A(M)$ is commutative? I am also interested in classes of $A$ -modules which have this property. Do they have a name?","Let be a commutative ring, and an -module. Are there some reasonably general conditions (both on or ) assuring that the ring is commutative? I am also interested in classes of -modules which have this property. Do they have a name?",A M A A M \mathrm{End}_A(M) A,"['abstract-algebra', 'modules']"
17,Infinitely many primes $\equiv 3 \mod 4$,Infinitely many primes,\equiv 3 \mod 4,"Question 1 Is the following proof of the infinitude of primes $\equiv 1\mod 4$ okay? Consider a prime divisor $p\mid (n!)^2+1$. Then $(n!)^2\equiv -1 \mod p$, hence $n!$ has multiplicative order $4$ in $\Bbb F_p^\times$ (question: is this conclusion true? what did I use here?) . Thus $n!\in \Bbb F_p^\times$ generates a subgroup of order $4$ and by Lagrange, $4\mid p-1$, i.e. $p\equiv 1\mod 4$. Now we do the same thing, replacing $n$ by $p$. This will give a new prime $\equiv 1\mod 4$ and this prime is bigger than $p$ (otherwise it would divide $1$). Question 2 My lecture notes say that from this one can conclude that there are infinitely many primes $p\equiv 3\mod 4$ by considering $n!-1$, which leaves remainder $3$ upon division by $4$. How does this imply infinitude of such primes?","Question 1 Is the following proof of the infinitude of primes $\equiv 1\mod 4$ okay? Consider a prime divisor $p\mid (n!)^2+1$. Then $(n!)^2\equiv -1 \mod p$, hence $n!$ has multiplicative order $4$ in $\Bbb F_p^\times$ (question: is this conclusion true? what did I use here?) . Thus $n!\in \Bbb F_p^\times$ generates a subgroup of order $4$ and by Lagrange, $4\mid p-1$, i.e. $p\equiv 1\mod 4$. Now we do the same thing, replacing $n$ by $p$. This will give a new prime $\equiv 1\mod 4$ and this prime is bigger than $p$ (otherwise it would divide $1$). Question 2 My lecture notes say that from this one can conclude that there are infinitely many primes $p\equiv 3\mod 4$ by considering $n!-1$, which leaves remainder $3$ upon division by $4$. How does this imply infinitude of such primes?",,"['abstract-algebra', 'elementary-number-theory']"
18,"Why can we interchange ""primes"" and ""irreducibles"" in the definition of UFD?","Why can we interchange ""primes"" and ""irreducibles"" in the definition of UFD?",,"On Wikipedia, UFD is defined as an integral domain in which every element can be uniquely factored as product of primes (irreducibles), up to multiplication by units and arrangement. My question is about why primes or irreducibles can be interchangeably placed in definition. I mean, in other words, are following two definitions equivalent? (1) $R$ is an integral domain in which every element can be uniquely factored as product of primes (up to unit multiplication and permutation). (2) $R$ is an integral domain in which every element can be uniquely factored as product of irreducibles (up to unit multiplication and permutation). (from comments below, my question actually boils down to following:) If in a domain, every element can be uniquely factored into product of primes, then certainly it can be decomposed into irreducibles; how can we ensure uniqueness into irreducible factorization?","On Wikipedia, UFD is defined as an integral domain in which every element can be uniquely factored as product of primes (irreducibles), up to multiplication by units and arrangement. My question is about why primes or irreducibles can be interchangeably placed in definition. I mean, in other words, are following two definitions equivalent? (1) is an integral domain in which every element can be uniquely factored as product of primes (up to unit multiplication and permutation). (2) is an integral domain in which every element can be uniquely factored as product of irreducibles (up to unit multiplication and permutation). (from comments below, my question actually boils down to following:) If in a domain, every element can be uniquely factored into product of primes, then certainly it can be decomposed into irreducibles; how can we ensure uniqueness into irreducible factorization?",R R,"['abstract-algebra', 'ring-theory', 'definition', 'unique-factorization-domains']"
19,Neat method to show that $\mathbb{Q}(2^{1/3}) \ne \mathbb{Q}(3^{1/3}) $? [duplicate],Neat method to show that ? [duplicate],\mathbb{Q}(2^{1/3}) \ne \mathbb{Q}(3^{1/3}) ,"This question already has answers here : Prove $\sqrt[3]{3} \notin \mathbb{Q}(\sqrt[3]{2})$ [duplicate] (5 answers) Closed 5 years ago . I am wondering how to show looking obvious $\mathbb{Q}(2^{\frac{1}{3}}) \ne \mathbb{Q}(3^{\frac{1}{3}}) $? This question has appeared to compute the order of $\text{Gal}(\mathbb{Q}(2^{\frac{1}{3}},3^{\frac{1}{3}},\xi_3)/\mathbb{Q})$ where $\xi_3$ is a primitive root of unity. I already know to show this by brutal force by assumimg $2^{\frac{1}{3}}=a+b\cdot2^{\frac{1}{3}}+c\cdot 2^{\frac{2}{3}}$ for some $a,b,c\in \mathbb{Q}$ and take 3rd power on both side and compare their coefficients. But its too boring. Is there any neat method?","This question already has answers here : Prove $\sqrt[3]{3} \notin \mathbb{Q}(\sqrt[3]{2})$ [duplicate] (5 answers) Closed 5 years ago . I am wondering how to show looking obvious $\mathbb{Q}(2^{\frac{1}{3}}) \ne \mathbb{Q}(3^{\frac{1}{3}}) $? This question has appeared to compute the order of $\text{Gal}(\mathbb{Q}(2^{\frac{1}{3}},3^{\frac{1}{3}},\xi_3)/\mathbb{Q})$ where $\xi_3$ is a primitive root of unity. I already know to show this by brutal force by assumimg $2^{\frac{1}{3}}=a+b\cdot2^{\frac{1}{3}}+c\cdot 2^{\frac{2}{3}}$ for some $a,b,c\in \mathbb{Q}$ and take 3rd power on both side and compare their coefficients. But its too boring. Is there any neat method?",,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
20,"Homomorphism from $(\Bbb Q,+)$ to a finite group",Homomorphism from  to a finite group,"(\Bbb Q,+)","Prove that if $f$ is a homomorphism from $(\Bbb Q,+)$ to a finite group $G$ then $f(q)=e_G$ for all $q$ in $\Bbb Q$. I attempted the following: Firsty I reason that $f(1)$ generates the entire image, because $f(p/q)=p/qf(1)$. But since $f[\Bbb Q]$ is an infinite subgroup of $G$ and $G$ itself is finite we are forced to let $f(1)=e_G$. Is this ok?","Prove that if $f$ is a homomorphism from $(\Bbb Q,+)$ to a finite group $G$ then $f(q)=e_G$ for all $q$ in $\Bbb Q$. I attempted the following: Firsty I reason that $f(1)$ generates the entire image, because $f(p/q)=p/qf(1)$. But since $f[\Bbb Q]$ is an infinite subgroup of $G$ and $G$ itself is finite we are forced to let $f(1)=e_G$. Is this ok?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
21,Prove $\exp(\mathrm{Tr}(X))=\det(\exp(X))$,Prove,\exp(\mathrm{Tr}(X))=\det(\exp(X)),Show that $\exp(\mathrm{Tr}(X))=\det(\exp(X))$ where $X$ is a matrix using the concept of the Jordan normal form I realised this formula by considering that: $\det(\exp(X))=\exp(\lambda_1) \times\cdots \times \exp(\lambda_n)=\exp(\lambda_1 + \cdots + \lambda_n)=\exp(\mathrm{Tr}(X))$ $\lambda_i$ are eigenvalues of $X$ I was unsure how to prove it using the Jordan normal form - could you help me please?,Show that $\exp(\mathrm{Tr}(X))=\det(\exp(X))$ where $X$ is a matrix using the concept of the Jordan normal form I realised this formula by considering that: $\det(\exp(X))=\exp(\lambda_1) \times\cdots \times \exp(\lambda_n)=\exp(\lambda_1 + \cdots + \lambda_n)=\exp(\mathrm{Tr}(X))$ $\lambda_i$ are eigenvalues of $X$ I was unsure how to prove it using the Jordan normal form - could you help me please?,,"['abstract-algebra', 'representation-theory', 'exponential-function', 'matrix-equations', 'jordan-normal-form']"
22,Showing that $x^4 + 4x^3 + 11x^2 + 10x + 9$ is irreducible over $\mathbb{Q}$,Showing that  is irreducible over,x^4 + 4x^3 + 11x^2 + 10x + 9 \mathbb{Q},"Let $p(x) = x^4 + 4x^3 + 11x^2 + 10x + 9$. How to how that it is irreducible over $\mathbb{Q}$? The first thing I tried was Eisenstein, but that obviously doesn't work with the polynomial in that form. Then I looked at $p$ in $\mathbb{F}_2$ and $\mathbb{F}_5$ in order to show that it irreducible in one of them and then to use Gauß' Theorem. However, it turns out that $p$ is reducible over both fields. I've seen people use nifty substitutions in connection with the Eisenstein criterion. I tried to represent $p$ in terms of $x+1$, but that doesn't seem to work, either. Now I'm at my wit's end. What else could I try?","Let $p(x) = x^4 + 4x^3 + 11x^2 + 10x + 9$. How to how that it is irreducible over $\mathbb{Q}$? The first thing I tried was Eisenstein, but that obviously doesn't work with the polynomial in that form. Then I looked at $p$ in $\mathbb{F}_2$ and $\mathbb{F}_5$ in order to show that it irreducible in one of them and then to use Gauß' Theorem. However, it turns out that $p$ is reducible over both fields. I've seen people use nifty substitutions in connection with the Eisenstein criterion. I tried to represent $p$ in terms of $x+1$, but that doesn't seem to work, either. Now I'm at my wit's end. What else could I try?",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
23,"Information about Problem. Let $a_1,\cdots,a_n\in\mathbb{Z}$ with $\gcd(a_1,\cdots,a_n)=1$. Then there exists a $n\times n$ matrix $A$ ...",Information about Problem. Let  with . Then there exists a  matrix  ...,"a_1,\cdots,a_n\in\mathbb{Z} \gcd(a_1,\cdots,a_n)=1 n\times n A","I would like to find some information about the following propositions, and unfortunately I haven't been able to find any. Let $a_1,\dots,a_n\in\mathbb{Z}$ with $\gcd(a_1,\dots,a_n)=1$. Then there exists a matrix $A\in M_{n\times n}(\mathbb{Z})$ with first row $(a_1,\dots, a_n)$ such that $\det A=1$. Or in another case: Let $F$ be a field and $f_1,\dots,f_n\in\mathbb{F}[x_1,\dots, x_r]$ with $\gcd(f_1,\dots,f_n)=1$. Then there exists a matrix $A\in M_{n\times n}(F[x_1,\dots,x_r])$ with first row $(f_1,\dots, f_n)$ such that $\det A=1$. Does somebody know something about this problem? Thanks. Note: I found the problem stated here but I haven't found any more info. In the link, it says: This fundamental question generated an enormous amount of mathematics (giving birth to some new fields) and was finally settled almost simultaneously by D. Quillen and A. A. Suslin, independently.  Now, there are fairly elementary proofs of this which require only some knowledge of polynomials and a good background in linear algebra.  This could be an excellent project for someone who wants to learn some important and interesting mathematics.","I would like to find some information about the following propositions, and unfortunately I haven't been able to find any. Let $a_1,\dots,a_n\in\mathbb{Z}$ with $\gcd(a_1,\dots,a_n)=1$. Then there exists a matrix $A\in M_{n\times n}(\mathbb{Z})$ with first row $(a_1,\dots, a_n)$ such that $\det A=1$. Or in another case: Let $F$ be a field and $f_1,\dots,f_n\in\mathbb{F}[x_1,\dots, x_r]$ with $\gcd(f_1,\dots,f_n)=1$. Then there exists a matrix $A\in M_{n\times n}(F[x_1,\dots,x_r])$ with first row $(f_1,\dots, f_n)$ such that $\det A=1$. Does somebody know something about this problem? Thanks. Note: I found the problem stated here but I haven't found any more info. In the link, it says: This fundamental question generated an enormous amount of mathematics (giving birth to some new fields) and was finally settled almost simultaneously by D. Quillen and A. A. Suslin, independently.  Now, there are fairly elementary proofs of this which require only some knowledge of polynomials and a good background in linear algebra.  This could be an excellent project for someone who wants to learn some important and interesting mathematics.",,"['abstract-algebra', 'principal-ideal-domains', 'euclidean-algorithm']"
24,"$N\rtimes H$ is isomorphic to $N'\rtimes H$ over $H$, then $N\simeq N'$?","is isomorphic to  over , then ?",N\rtimes H N'\rtimes H H N\simeq N',"Let $s:H\hookrightarrow G$ be an inclusion of groups and $f,f':G\to H$ be two morphisms s.t. $f\circ s = f'\circ s = \mathrm{id}_H$. Then can we conclude that $\mathrm{Ker}(f) \simeq \mathrm{Ker}(f')$? (The title is an equivalent version of the question)","Let $s:H\hookrightarrow G$ be an inclusion of groups and $f,f':G\to H$ be two morphisms s.t. $f\circ s = f'\circ s = \mathrm{id}_H$. Then can we conclude that $\mathrm{Ker}(f) \simeq \mathrm{Ker}(f')$? (The title is an equivalent version of the question)",,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
25,"Is $\mathbb{Z}[x,y,z]$ an $\mathbb{N}$-graded ring?",Is  an -graded ring?,"\mathbb{Z}[x,y,z] \mathbb{N}","I know that my question seems to be obvious, but I really need the answer Let $\mathbb{Z}[x, y, z]$ be a polynomial ring.  I know that it is a $\mathbb{Z}$-graded ring, but is it not in fact $\mathbb{N}$-graded?  I don't see why it is not $\mathbb{N}$-graded if we consider the degrees of polynomials.  But when I tried to use Nakayama's Lemma (the graded version), my professor told me that we cannot use it for any polynomial ring with coefficients in $\mathbb{Z}$. Any help? Thanks.","I know that my question seems to be obvious, but I really need the answer Let $\mathbb{Z}[x, y, z]$ be a polynomial ring.  I know that it is a $\mathbb{Z}$-graded ring, but is it not in fact $\mathbb{N}$-graded?  I don't see why it is not $\mathbb{N}$-graded if we consider the degrees of polynomials.  But when I tried to use Nakayama's Lemma (the graded version), my professor told me that we cannot use it for any polynomial ring with coefficients in $\mathbb{Z}$. Any help? Thanks.",,"['abstract-algebra', 'ring-theory', 'graded-rings']"
26,Fixed subfield of the field of rational functions,Fixed subfield of the field of rational functions,,Let $K(X)$ be the field of rational functions of $X$ over some field $K$. Let $\phi: K(X) \rightarrow K(X)$ be the $K$-morphism such that $\phi (X)=1-X$. We have $L:=\{ f\in K(X) : \phi (f)=f\}$. Find some element $Y \in K(X)$ such that $K(Y)=L$. I am fairly certain that $Y=(2X-1)^{2}$ and can easily show that $K(Y) \subset L$. I am having some trouble with showing that $L \subset K(Y)$.,Let $K(X)$ be the field of rational functions of $X$ over some field $K$. Let $\phi: K(X) \rightarrow K(X)$ be the $K$-morphism such that $\phi (X)=1-X$. We have $L:=\{ f\in K(X) : \phi (f)=f\}$. Find some element $Y \in K(X)$ such that $K(Y)=L$. I am fairly certain that $Y=(2X-1)^{2}$ and can easily show that $K(Y) \subset L$. I am having some trouble with showing that $L \subset K(Y)$.,,"['abstract-algebra', 'field-theory', 'galois-theory']"
27,Local properties of morphisms of schemes,Local properties of morphisms of schemes,,"In Hartshorne Proposition II.5.8, he shows, given a morphism $f \colon X \to Y$ where X and Y are schemes and $\mathcal{G}$ a quasi-coherent sheaf of $\mathcal{O}_{Y}$- modules, that $f^{*}\mathcal{G}$ is a quasi-coherent sheaf of $\mathcal{O}_{X}$-modules. Similarly, he shows that given $f$ quasicompact and separated, that the pushforward of a quasi-coherent sheaf is quasi-coherent. My question concerns his reduction to the affine case. I understand that the quasi-coherent property is local, since it can be checked on an affine cover by definition, so for proving that the pullback of a quasi-coherent sheaf is quasi-coherent, one can assume $X$ to be affine. However, why is one allowed to also assume $Y$ to be affine as it is done in the proof, while for proving the pushforward, one can only assume $Y$ affine and not $X$?","In Hartshorne Proposition II.5.8, he shows, given a morphism $f \colon X \to Y$ where X and Y are schemes and $\mathcal{G}$ a quasi-coherent sheaf of $\mathcal{O}_{Y}$- modules, that $f^{*}\mathcal{G}$ is a quasi-coherent sheaf of $\mathcal{O}_{X}$-modules. Similarly, he shows that given $f$ quasicompact and separated, that the pushforward of a quasi-coherent sheaf is quasi-coherent. My question concerns his reduction to the affine case. I understand that the quasi-coherent property is local, since it can be checked on an affine cover by definition, so for proving that the pullback of a quasi-coherent sheaf is quasi-coherent, one can assume $X$ to be affine. However, why is one allowed to also assume $Y$ to be affine as it is done in the proof, while for proving the pushforward, one can only assume $Y$ affine and not $X$?",,"['abstract-algebra', 'algebraic-geometry', 'sheaf-theory', 'schemes', 'quasicoherent-sheaves']"
28,"When is an ideal also a ring, and could then be anything said about its relation to the original ring","When is an ideal also a ring, and could then be anything said about its relation to the original ring",,"If $R$ is a ring with unity $1$, then $S \subseteq R$ is called a subring if it is itself a ring with $1 \in S$. A subset $I \subseteq R$ is called an ideal if it is a group with respect to addition and $rx, xs \in I$ for each $r,s \in $ and $x \in I$. With these definitions an ideal $I$ is a subring iff $1 \in I$ iff $I = R$, hence there are no proper ideals that are also subrings of $R$. If we change the definition and look at rings without requiring an identity, then every ideal is also a subring, but not every subring needs to be an ideal. This could be read on wikipedia . There it is also stated that not every ideal has itself an identity, examples as given there are $\mathbb Z$ and $\mathbb Z \times \mathbb Z$, other are in quotient polynomial rings, where ideals have identites, see for example this post . But lets look at rings with unity from now on. If an ideal has unity, then it is itself a ring with unity, but the identity might be different, and I ask myself it what sense is the ring structure on the ideal then different from the ring structure on the given ring. What are the conditions that ensure that ideals have identites, and hence form rings by themself? And what is the relation to the original ring? Could we give a ring homomorphism from the ring to the ideal then? I give a special case, which came up on a recent question of mine (see the linked one above), and is in some way related to representation theory, where similar constructions are used. Let $R$ be a ring with unity, then $R$ could be regarded as $R$-module by its regular action on itself, and the $R$-submodules are precisely the ideals then. Now suppose (considered as a module) we have $R = I \oplus J$ for two $R$-submodules. In the module we have $R / I \cong J$ as modules, i.e. we have a module isomorphism. Now if we look at $R$ as a ring again, then $I$ and $J$ are ideals, and so we can built the quotient ring $R / I$. Now I want to look at the relation of this quotient ring to $J$ (or $R / I$ as a module), and want to know if they are isomorphis as rings. In this special case if we write $1 = 1_I + 1_J$, then $1_J$ is an identity in $J$, as for $x \in J$ we have $x = x1 = x(1_I + 1_J) = x1_I + x1_J$ and $x1_I \in I$ and $x1_I \in J$ by the ideal properties, hence $x = x1_J$. So $J$ has a unity and is a ring. The map $\pi : R \to J$ gives a surjective homomorphism (it is like a projection) and its kernel is precisely $I$, hence $R / I \cong J$. But this situation is very special. But in general, when are ideals also rings with unity, and what is their relation to the original ring?","If $R$ is a ring with unity $1$, then $S \subseteq R$ is called a subring if it is itself a ring with $1 \in S$. A subset $I \subseteq R$ is called an ideal if it is a group with respect to addition and $rx, xs \in I$ for each $r,s \in $ and $x \in I$. With these definitions an ideal $I$ is a subring iff $1 \in I$ iff $I = R$, hence there are no proper ideals that are also subrings of $R$. If we change the definition and look at rings without requiring an identity, then every ideal is also a subring, but not every subring needs to be an ideal. This could be read on wikipedia . There it is also stated that not every ideal has itself an identity, examples as given there are $\mathbb Z$ and $\mathbb Z \times \mathbb Z$, other are in quotient polynomial rings, where ideals have identites, see for example this post . But lets look at rings with unity from now on. If an ideal has unity, then it is itself a ring with unity, but the identity might be different, and I ask myself it what sense is the ring structure on the ideal then different from the ring structure on the given ring. What are the conditions that ensure that ideals have identites, and hence form rings by themself? And what is the relation to the original ring? Could we give a ring homomorphism from the ring to the ideal then? I give a special case, which came up on a recent question of mine (see the linked one above), and is in some way related to representation theory, where similar constructions are used. Let $R$ be a ring with unity, then $R$ could be regarded as $R$-module by its regular action on itself, and the $R$-submodules are precisely the ideals then. Now suppose (considered as a module) we have $R = I \oplus J$ for two $R$-submodules. In the module we have $R / I \cong J$ as modules, i.e. we have a module isomorphism. Now if we look at $R$ as a ring again, then $I$ and $J$ are ideals, and so we can built the quotient ring $R / I$. Now I want to look at the relation of this quotient ring to $J$ (or $R / I$ as a module), and want to know if they are isomorphis as rings. In this special case if we write $1 = 1_I + 1_J$, then $1_J$ is an identity in $J$, as for $x \in J$ we have $x = x1 = x(1_I + 1_J) = x1_I + x1_J$ and $x1_I \in I$ and $x1_I \in J$ by the ideal properties, hence $x = x1_J$. So $J$ has a unity and is a ring. The map $\pi : R \to J$ gives a surjective homomorphism (it is like a projection) and its kernel is precisely $I$, hence $R / I \cong J$. But this situation is very special. But in general, when are ideals also rings with unity, and what is their relation to the original ring?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'modules', 'ideals']"
29,Saturation of a multiplicatively closed subset,Saturation of a multiplicatively closed subset,,"Exercise 3.7 of Atiyah-MacDonald asks the reader: if $A$ is a commutative ring and $\mathfrak{a} \triangleleft A$ an ideal, find the saturation of $1 + \mathfrak{a}$. Previously we have shown that the saturation of a multiplicatively closed subset $S$ is the complement of the union of prime ideals not meeting $S$. Are they just looking for the fact that the saturation is the complement of the union of all $\mathfrak{p}$ prime such that $\mathfrak{p} + \mathfrak{a} \neq R$? Or is there more to say?","Exercise 3.7 of Atiyah-MacDonald asks the reader: if $A$ is a commutative ring and $\mathfrak{a} \triangleleft A$ an ideal, find the saturation of $1 + \mathfrak{a}$. Previously we have shown that the saturation of a multiplicatively closed subset $S$ is the complement of the union of prime ideals not meeting $S$. Are they just looking for the fact that the saturation is the complement of the union of all $\mathfrak{p}$ prime such that $\mathfrak{p} + \mathfrak{a} \neq R$? Or is there more to say?",,"['abstract-algebra', 'commutative-algebra', 'ideals']"
30,Higher ramification groups of Galois extension of order $p^2$,Higher ramification groups of Galois extension of order,p^2,"Let $p\in \mathbb{Z}$ be a prime number and $K/\mathbb{Q}$ be a Galois extension of degree $p^2$ over $\mathbb{Q}$. Suppose that $P\subset \mathcal{O}_K$ is the only prime ramified over $p$. Let $G:=\text{Gal}(K/\mathbb{Q})$ and recall the definition of the higher ramification groups, for $m\ge 0$ $$V_m(P\mid p):=\{\sigma\in G: \sigma(x)\equiv x\pmod {P^{m+1}} \;\forall x\in \mathcal{O}_K\}$$ (in particular $V_0$ is the inertia group). It's easy to show that $|V_0|=p^2$ (because $P$ is totally ramified over $p$) and that $|V_1|=p^2$ (since $V_1$ is the $p$-Sylow of $V_0$). Now I have to show that the first ramification group having order $<p^2$ has order $p$. I know that $V_{m}/V_{m+1}$ is sum of cyclic groups of order $p$, but this is not sufficient to conclude. Any ideas?","Let $p\in \mathbb{Z}$ be a prime number and $K/\mathbb{Q}$ be a Galois extension of degree $p^2$ over $\mathbb{Q}$. Suppose that $P\subset \mathcal{O}_K$ is the only prime ramified over $p$. Let $G:=\text{Gal}(K/\mathbb{Q})$ and recall the definition of the higher ramification groups, for $m\ge 0$ $$V_m(P\mid p):=\{\sigma\in G: \sigma(x)\equiv x\pmod {P^{m+1}} \;\forall x\in \mathcal{O}_K\}$$ (in particular $V_0$ is the inertia group). It's easy to show that $|V_0|=p^2$ (because $P$ is totally ramified over $p$) and that $|V_1|=p^2$ (since $V_1$ is the $p$-Sylow of $V_0$). Now I have to show that the first ramification group having order $<p^2$ has order $p$. I know that $V_{m}/V_{m+1}$ is sum of cyclic groups of order $p$, but this is not sufficient to conclude. Any ideas?",,"['abstract-algebra', 'algebraic-number-theory', 'galois-theory', 'ramification']"
31,How to interpret a line equation in 4-point geometry (affine plane of order 2).,How to interpret a line equation in 4-point geometry (affine plane of order 2).,,"I am currently reading ""Basic Notions of Algebra"" by Igor Shafarevich. In the first chapter example of a coordinatization of 4-point geometry is given. Set of axioms: Through any two distinct points there is one and only one line. Given any line and a point not on it, there exists one and only one other line through the point and not intersecting the line (that is, parallel to it). There exist three points not on any line. In this geometry we have 4 points A, B, C, D and 6 lines AB, CD; AD, BC; AC, BD. The families of parallel lines are separated by semicolons. Let $\Bbb{0,1}$ be symbols with operations $+$ and $\times$ such that $$ \begin{array}{cc} \begin{array}{c|cc} \text{+} & 0 & 1\\ \hline 0 & 0 & 1\\ 1 & 1 & 0\\ \end{array} & \begin{array}{c|cc} \times & 0 & 1\\ \hline 0 & 0 & 0\\ 1 & 0 & 1\\ \end{array} \end{array} $$ The pair of quantities 0 and 1 with operations defined on them as above serve us in coordinatising the ""geometry"". For this, we give points coordinates (X, Y) as follows: A = (0, 0), B = (0, 1), C = (1, 0), D = (1, 1). It is easy to check that the lines of the geometry are then defined by the linear equations: $$ \begin{array}{ccc} & AB: 1X = 0;      & CD: 1X = 1; & AD: 1X + 1Y = 0;\\ & BC: 1X + 1Y = 1; & AC: 1Y = 0; & BD: 1Y = 1;\\ \end{array} $$ The question is: how does one should interpret this equations? Any suggestions will be appreciated.","I am currently reading ""Basic Notions of Algebra"" by Igor Shafarevich. In the first chapter example of a coordinatization of 4-point geometry is given. Set of axioms: Through any two distinct points there is one and only one line. Given any line and a point not on it, there exists one and only one other line through the point and not intersecting the line (that is, parallel to it). There exist three points not on any line. In this geometry we have 4 points A, B, C, D and 6 lines AB, CD; AD, BC; AC, BD. The families of parallel lines are separated by semicolons. Let $\Bbb{0,1}$ be symbols with operations $+$ and $\times$ such that $$ \begin{array}{cc} \begin{array}{c|cc} \text{+} & 0 & 1\\ \hline 0 & 0 & 1\\ 1 & 1 & 0\\ \end{array} & \begin{array}{c|cc} \times & 0 & 1\\ \hline 0 & 0 & 0\\ 1 & 0 & 1\\ \end{array} \end{array} $$ The pair of quantities 0 and 1 with operations defined on them as above serve us in coordinatising the ""geometry"". For this, we give points coordinates (X, Y) as follows: A = (0, 0), B = (0, 1), C = (1, 0), D = (1, 1). It is easy to check that the lines of the geometry are then defined by the linear equations: $$ \begin{array}{ccc} & AB: 1X = 0;      & CD: 1X = 1; & AD: 1X + 1Y = 0;\\ & BC: 1X + 1Y = 1; & AC: 1Y = 0; & BD: 1Y = 1;\\ \end{array} $$ The question is: how does one should interpret this equations? Any suggestions will be appreciated.",,"['abstract-algebra', 'finite-geometry']"
32,"If $M$ is compact, every maximal ideal in $F$ arises in this way as a point of $M$?","If  is compact, every maximal ideal in  arises in this way as a point of ?",M F M,"For any smooth manifold $M$, the collection $F = C^\infty(M, \mathbb{R})$ of smooth real valued functions on $M$ can be made into a ring, and every point $x \in M$ determines a ring homomorphism $F \to \mathbb{R}$ in $F$. If $M$ is compact, how do I see that every maximal ideal in $F$ arises in this way from a point of $M$?","For any smooth manifold $M$, the collection $F = C^\infty(M, \mathbb{R})$ of smooth real valued functions on $M$ can be made into a ring, and every point $x \in M$ determines a ring homomorphism $F \to \mathbb{R}$ in $F$. If $M$ is compact, how do I see that every maximal ideal in $F$ arises in this way from a point of $M$?",,"['abstract-algebra', 'differential-geometry', 'ring-theory', 'manifolds', 'differential-topology']"
33,A non-abelian group of order $p^3$,A non-abelian group of order,p^3,"I am trying to show that for a non-abelian group of order $p^3$ for $p$ prime there exist a short exact sequence  $$ 1\rightarrow \mathbb{Z}_{p}\overset{j}{\rightarrow}G \overset{p}{\rightarrow}\mathbb{Z}_{p}\times \mathbb{Z}_{p}\rightarrow 1 $$ I have proved that the center of $G$ is $\mathbb{Z}_{p}$, which contains also the commutator of $G$. The center is a subgroup of $G$, so the first map $j$ is obviously an inclusion. Now I am stuck in the proof of the surjectivity of $p$ and that $\operatorname{Im}(j)=\operatorname{Ker}(p)$. Can anybody help me with this question? I would appreciate any comments and hints.","I am trying to show that for a non-abelian group of order $p^3$ for $p$ prime there exist a short exact sequence  $$ 1\rightarrow \mathbb{Z}_{p}\overset{j}{\rightarrow}G \overset{p}{\rightarrow}\mathbb{Z}_{p}\times \mathbb{Z}_{p}\rightarrow 1 $$ I have proved that the center of $G$ is $\mathbb{Z}_{p}$, which contains also the commutator of $G$. The center is a subgroup of $G$, so the first map $j$ is obviously an inclusion. Now I am stuck in the proof of the surjectivity of $p$ and that $\operatorname{Im}(j)=\operatorname{Ker}(p)$. Can anybody help me with this question? I would appreciate any comments and hints.",,"['abstract-algebra', 'group-theory']"
34,$[G:Z(G)] = n$ prove that each conjugacy class has at most n elements,prove that each conjugacy class has at most n elements,[G:Z(G)] = n,$[G:Z(G)] = n$ prove that each conjugacy class has at most n elements. what i tried - I know from the orbit stabiliser theorem that $|G| = \sum_{x_i} |G:C(x_i)| + |Z(G)|$ Because Z(G) < G i also know from Lagrange theorem that: $|G| = |Z(G)| * [G:Z(G)] = |Z(G)| * n$ i know that the size of each conjugacy class is $|G:C(x_i)|$ here I'm stuck.. any help will be appreciated,$[G:Z(G)] = n$ prove that each conjugacy class has at most n elements. what i tried - I know from the orbit stabiliser theorem that $|G| = \sum_{x_i} |G:C(x_i)| + |Z(G)|$ Because Z(G) < G i also know from Lagrange theorem that: $|G| = |Z(G)| * [G:Z(G)] = |Z(G)| * n$ i know that the size of each conjugacy class is $|G:C(x_i)|$ here I'm stuck.. any help will be appreciated,,"['abstract-algebra', 'normal-subgroups']"
35,"If $p(x,y) \in \mathbb{Q}[x,y]$ is such that $p(x,e^x) = 0$, then $p(x,y) = 0$ too.","If  is such that , then  too.","p(x,y) \in \mathbb{Q}[x,y] p(x,e^x) = 0 p(x,y) = 0","Suppose that for some two variable rational polynomial that evaluation of the second variable at $e^x$ gives 0, then the evaluation at any $y$ also gives 0. I've seen a proof that uses a calculus-based limiting argument, but I was wondering if there was some sort of algebraic proof, maybe using the transcendence of $e$ over $\mathbb{Q}$? Any ideas? Thanks!","Suppose that for some two variable rational polynomial that evaluation of the second variable at $e^x$ gives 0, then the evaluation at any $y$ also gives 0. I've seen a proof that uses a calculus-based limiting argument, but I was wondering if there was some sort of algebraic proof, maybe using the transcendence of $e$ over $\mathbb{Q}$? Any ideas? Thanks!",,['abstract-algebra']
36,What is a permutation representation in regard to group actions,What is a permutation representation in regard to group actions,,"I have read the definition of a permutation representation from Dummit and Foote, and Wiki, but I don't understand. Can I please have an example? I get the impression that we can write a group action normally as: $$G\times X\to X, (g,x)\mapsto g\cdot x$$ Or we can write it as a permutation representation, i.e. a group action does: $$\begin{pmatrix}1&2&3&4\\\sigma(1)&\sigma(2)&\sigma(3)&\sigma(4)\end{pmatrix}$$ Is that all a permutation representation refers to?","I have read the definition of a permutation representation from Dummit and Foote, and Wiki, but I don't understand. Can I please have an example? I get the impression that we can write a group action normally as: $$G\times X\to X, (g,x)\mapsto g\cdot x$$ Or we can write it as a permutation representation, i.e. a group action does: $$\begin{pmatrix}1&2&3&4\\\sigma(1)&\sigma(2)&\sigma(3)&\sigma(4)\end{pmatrix}$$ Is that all a permutation representation refers to?",,"['abstract-algebra', 'group-theory', 'group-actions']"
37,Degree of a splitting field,Degree of a splitting field,,"I came across something related to the degree of a splitting field for a polynomial over a field $K$.  Let's suppose $p \in K[x]$ with degree $n$, and $p$ has irreducible factors $f_{1}, \ldots, f_{c}$ with respective degrees $d_{1}, \ldots, d_{c}$. Ok, I know we can construct the splitting field as a tower of extensions.  BUT here is the question: According to Wikipedia, the degree of the splitting field is $\leq n!$, but why $n!$? Is there any way to achieve this bound? I would guess that the degree would be bound by $\prod_{i} d_{i}$, which could never be this big no matter the values of the $d_{i}$.  Where is the error in my thinking?","I came across something related to the degree of a splitting field for a polynomial over a field $K$.  Let's suppose $p \in K[x]$ with degree $n$, and $p$ has irreducible factors $f_{1}, \ldots, f_{c}$ with respective degrees $d_{1}, \ldots, d_{c}$. Ok, I know we can construct the splitting field as a tower of extensions.  BUT here is the question: According to Wikipedia, the degree of the splitting field is $\leq n!$, but why $n!$? Is there any way to achieve this bound? I would guess that the degree would be bound by $\prod_{i} d_{i}$, which could never be this big no matter the values of the $d_{i}$.  Where is the error in my thinking?",,"['abstract-algebra', 'galois-theory', 'splitting-field']"
38,Is $K := \mathbb{Q}(\cos (2\pi / 11))$ a Galois extension over $\mathbb{Q}$?,Is  a Galois extension over ?,K := \mathbb{Q}(\cos (2\pi / 11)) \mathbb{Q},"I believe that it is because $\cos(2\pi / 11) = (\zeta + \zeta^{-1})/2$ where $\zeta = e^{2\pi i/11}$ is a primitive $11$-th root of unity, and so $K$ is a subfield of $\mathbb{Q}(\zeta)$ with corresponding subgroup $H$ of $\mbox{Gal}(\mathbb{Q}(\zeta)/\mathbb{Q})$. Since the latter is isomorphic to $\mathbb{Z}/10$, $H$ is in particular normal and so $K$ is Galois over $\mathbb{Q}$. Is this argument sufficient? It seems that this argument would also work in the case that $11$ is replaced with a composite number - is that true?","I believe that it is because $\cos(2\pi / 11) = (\zeta + \zeta^{-1})/2$ where $\zeta = e^{2\pi i/11}$ is a primitive $11$-th root of unity, and so $K$ is a subfield of $\mathbb{Q}(\zeta)$ with corresponding subgroup $H$ of $\mbox{Gal}(\mathbb{Q}(\zeta)/\mathbb{Q})$. Since the latter is isomorphic to $\mathbb{Z}/10$, $H$ is in particular normal and so $K$ is Galois over $\mathbb{Q}$. Is this argument sufficient? It seems that this argument would also work in the case that $11$ is replaced with a composite number - is that true?",,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
39,"If $m$ divides $n$, find a free resolution of $\mathbb{Z}/m$ as a $\mathbb{Z}/n$-module.","If  divides , find a free resolution of  as a -module.",m n \mathbb{Z}/m \mathbb{Z}/n,"If $m$ divides $n$, find a free resolution of $\mathbb{Z}/m$ as a $\mathbb{Z}/n$-module. I have tried this one and got $0 \leftarrow \mathbb{Z}/m \leftarrow \mathbb{Z}/n \leftarrow \mathbb{Z}/n$. The map $\mathbb{Z}/n \to \mathbb{Z}/n$ is multiplication by $m$, but I couldn't go further. Please help me.","If $m$ divides $n$, find a free resolution of $\mathbb{Z}/m$ as a $\mathbb{Z}/n$-module. I have tried this one and got $0 \leftarrow \mathbb{Z}/m \leftarrow \mathbb{Z}/n \leftarrow \mathbb{Z}/n$. The map $\mathbb{Z}/n \to \mathbb{Z}/n$ is multiplication by $m$, but I couldn't go further. Please help me.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'homological-algebra']"
40,How to tell if a given equation is not a class equation of a group?,How to tell if a given equation is not a class equation of a group?,,"Which of the following cannot  be  a  class  equation  of  a  group  of  order $10$? $1+1+1+2+5=10$ $1+2+3+4  =10$ $1+2+2+5  =10$ $1+1+2+2+2+2=10$ As I  can  see options 2, 1  and  4  are  not   class  equations as $3$  does  not  divide  $10$  and  for 4, $|Z(G)|=2$  will  make  the  group  abelian and  the  equation  absurd. So the only possibility is option 3. But Iam  not  sure  whether there could be other arguments besides the ones I  have used to dismiss 1, 2, 4 that could dismiss also 3.","Which of the following cannot  be  a  class  equation  of  a  group  of  order $10$? $1+1+1+2+5=10$ $1+2+3+4  =10$ $1+2+2+5  =10$ $1+1+2+2+2+2=10$ As I  can  see options 2, 1  and  4  are  not   class  equations as $3$  does  not  divide  $10$  and  for 4, $|Z(G)|=2$  will  make  the  group  abelian and  the  equation  absurd. So the only possibility is option 3. But Iam  not  sure  whether there could be other arguments besides the ones I  have used to dismiss 1, 2, 4 that could dismiss also 3.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
41,Determine all maximal and prime ideals of the polynomial ring $\Bbb C[x]$,Determine all maximal and prime ideals of the polynomial ring,\Bbb C[x],"Determine all maximal and prime ideals of the polynomial ring $\Bbb C[x]$ My attempt: Note that $\Bbb F[x]$ where $\Bbb F$ is any field is a Euclidean domain, and importantly, that means that it is also a PID. As a PID, prime ideals are the same as maximal ideals. Since $\Bbb C$ is a field, we know that the polynomial ring $\Bbb C[x]$ is a ED and PID. So then it is easier to think about this question in terms of prime ideals: Prime ideals are ideals such that $ab\in P \implies a\in P$ or $b\in P$. For $a,b\in \Bbb C[x]$. So then, if a polynomial is in the ideal, then all of its linear factors are. This means that the generator for this ideal must be one of these factors. In fact, any polynomial that is reducible can't be the generator for this ideal, and therefore the prime ideals must be generated by irreducibles. In $\Bbb C[x]$ it would seem by algebraic closure, the only irreducibles are linear polynomials. Therefore all prime/maximal ideals of $\Bbb C[x]$ are of the form $(x-\alpha)$, $\alpha\in \Bbb C$. Note: that although $(0)$ is irreducible, it is not maximal. (I think we just say it is excluded?) Is my proof valid?","Determine all maximal and prime ideals of the polynomial ring $\Bbb C[x]$ My attempt: Note that $\Bbb F[x]$ where $\Bbb F$ is any field is a Euclidean domain, and importantly, that means that it is also a PID. As a PID, prime ideals are the same as maximal ideals. Since $\Bbb C$ is a field, we know that the polynomial ring $\Bbb C[x]$ is a ED and PID. So then it is easier to think about this question in terms of prime ideals: Prime ideals are ideals such that $ab\in P \implies a\in P$ or $b\in P$. For $a,b\in \Bbb C[x]$. So then, if a polynomial is in the ideal, then all of its linear factors are. This means that the generator for this ideal must be one of these factors. In fact, any polynomial that is reducible can't be the generator for this ideal, and therefore the prime ideals must be generated by irreducibles. In $\Bbb C[x]$ it would seem by algebraic closure, the only irreducibles are linear polynomials. Therefore all prime/maximal ideals of $\Bbb C[x]$ are of the form $(x-\alpha)$, $\alpha\in \Bbb C$. Note: that although $(0)$ is irreducible, it is not maximal. (I think we just say it is excluded?) Is my proof valid?",,"['abstract-algebra', 'ring-theory', 'proof-verification', 'maximal-and-prime-ideals']"
42,The identity elements of two multiplication satisfying interchange law.,The identity elements of two multiplication satisfying interchange law.,,"Let $M$ be a set, and $\circ_1,\circ_2$ two binary operations defined on $M$ satisfying that both $(M,\circ_1),(M,\circ_2)$ are semigroups and $(a\circ_1 b)\circ_2(c\circ_1 d)=(a\circ_2 c)\circ_1(b\circ_2 d)$. It is well known that if both $\circ_1$ and $\circ_2$ admit identity elements, then the two operations coincide and are commutative. My question is, supposing only $\circ_1$ admits an identity element, can we deduce that $\circ_2$ admits an identity element, too?","Let $M$ be a set, and $\circ_1,\circ_2$ two binary operations defined on $M$ satisfying that both $(M,\circ_1),(M,\circ_2)$ are semigroups and $(a\circ_1 b)\circ_2(c\circ_1 d)=(a\circ_2 c)\circ_1(b\circ_2 d)$. It is well known that if both $\circ_1$ and $\circ_2$ admit identity elements, then the two operations coincide and are commutative. My question is, supposing only $\circ_1$ admits an identity element, can we deduce that $\circ_2$ admits an identity element, too?",,"['abstract-algebra', 'category-theory', 'semigroups', 'universal-algebra']"
43,"What is the kernel of $K[x^2,x^3][T] \to K[x]$, defined by $T \mapsto x$?","What is the kernel of , defined by ?","K[x^2,x^3][T] \to K[x] T \mapsto x","Consider $K[x^2,x^3] \subset K[x]$, where $x$ is an indeterminate over a (zero characteristic) field $K$. Clearly, $x$ vanishes the following polynomials $\in K[x^2,x^3][T]$: $f(T)=x^2T-x^3$, $g(T)=T^2-x^2$, $h(T)=T^3-x^3$, etc. I wish to find the kernel of the surjective homomorphism $K[x^2,x^3][T] \to K[x]$, defined by $T \mapsto x$; in other words, what are the generators of the kernel? (Obviously, $f(T), g(T), h(T)$ are all in the kernel).","Consider $K[x^2,x^3] \subset K[x]$, where $x$ is an indeterminate over a (zero characteristic) field $K$. Clearly, $x$ vanishes the following polynomials $\in K[x^2,x^3][T]$: $f(T)=x^2T-x^3$, $g(T)=T^2-x^2$, $h(T)=T^3-x^3$, etc. I wish to find the kernel of the surjective homomorphism $K[x^2,x^3][T] \to K[x]$, defined by $T \mapsto x$; in other words, what are the generators of the kernel? (Obviously, $f(T), g(T), h(T)$ are all in the kernel).",,"['abstract-algebra', 'ring-theory', 'commutative-algebra']"
44,"Show that $\mathbb{C}[x,y]/(x^2+y^2-1)$ is a UFD. [duplicate]",Show that  is a UFD. [duplicate],"\mathbb{C}[x,y]/(x^2+y^2-1)","This question already has answers here : Ring of trigonometric functions with real coefficients (3 answers) Closed 9 years ago . I am trying to prove that the ring $\mathbb{C}[x,y]/(x^2+y^2-1)$ is a UFD. I have an hint, that suggests to find an isomorphism between $\mathbb{C}[x,y]/(x^2+y^2-1)$ and $\mathbb{C}[e^{it},e^{-it}]$, but to be honest I don't see it. Please, could you give me a hand? I would to solve my problem completely, any kind of suggestion is fully appreciated. Update : user Daniel McLaury helped me in showing the isomorphism - so now it remains only to see that this ring is actually an UFD. Thanks in advance. Cheers","This question already has answers here : Ring of trigonometric functions with real coefficients (3 answers) Closed 9 years ago . I am trying to prove that the ring $\mathbb{C}[x,y]/(x^2+y^2-1)$ is a UFD. I have an hint, that suggests to find an isomorphism between $\mathbb{C}[x,y]/(x^2+y^2-1)$ and $\mathbb{C}[e^{it},e^{-it}]$, but to be honest I don't see it. Please, could you give me a hand? I would to solve my problem completely, any kind of suggestion is fully appreciated. Update : user Daniel McLaury helped me in showing the isomorphism - so now it remains only to see that this ring is actually an UFD. Thanks in advance. Cheers",,"['abstract-algebra', 'ring-theory']"
45,Finding the character table of this group,Finding the character table of this group,,"if $ G = <a,b| a^9 = b^3 = 1, bab^{-1} = a^4> $ of order 27 then know the following, that any element can be written as $b^ka^n$ with n $\in [0,8], k\in[0,2]$ and that the 11 conjugacy classes are as follows: $\{1\}\{a^3\}\{a^6\}\{a,a^4,a^7\}\{a^2,a^5,a^8\}\{b,ba^3,ba^6\}\{ba,ba^7,ba^4\}\{ba^2,ba^5,ba^8\}\{b^2,b^2a^3,b^2a^6\}\{b^2a,b^2a^4,b^2a^7\}\{b^2a^2,b^2a^5,b^2a^8\}$ Then if H is a normal subgroup generated by $a$ with linear character $\rho$ such that $\rho(a) = e^{2\pi i/9}$, how would i compute the induced character $\rho^G$ as well as the character table I know there will be 11 irreducible characters of G but am unsure as to how to start with filling in the entries of the table. As this is a past exam question with no solution i have no source of hints to point me in the right direction for the answer any help would be greatly appreciated","if $ G = <a,b| a^9 = b^3 = 1, bab^{-1} = a^4> $ of order 27 then know the following, that any element can be written as $b^ka^n$ with n $\in [0,8], k\in[0,2]$ and that the 11 conjugacy classes are as follows: $\{1\}\{a^3\}\{a^6\}\{a,a^4,a^7\}\{a^2,a^5,a^8\}\{b,ba^3,ba^6\}\{ba,ba^7,ba^4\}\{ba^2,ba^5,ba^8\}\{b^2,b^2a^3,b^2a^6\}\{b^2a,b^2a^4,b^2a^7\}\{b^2a^2,b^2a^5,b^2a^8\}$ Then if H is a normal subgroup generated by $a$ with linear character $\rho$ such that $\rho(a) = e^{2\pi i/9}$, how would i compute the induced character $\rho^G$ as well as the character table I know there will be 11 irreducible characters of G but am unsure as to how to start with filling in the entries of the table. As this is a past exam question with no solution i have no source of hints to point me in the right direction for the answer any help would be greatly appreciated",,"['abstract-algebra', 'group-theory', 'representation-theory', 'characters']"
46,"For a polynomial $f\in K[x]$, when is there a constant $c\in K$ such that $f+c$ is irreducible?","For a polynomial , when is there a constant  such that  is irreducible?",f\in K[x] c\in K f+c,"I was working on a different problem when the following question occurred to me: For a polynomial $f\in K[x]$, is there always a constant $c\in K$ such that $f+c$ is irreducible? Obviously this is false for some fields, consider $x^2$ over $\mathbb{F}_2$, $x^2$ factors as does $x^2+1$. In general it must be false for finite fields as $x^q+c$ has a root at $c$ for all $c$ in $\mathbb{F}_q$. Or take any algebraically closed field, trivially this cannot be done for a nonlinear polynomial since all nonlinear polynomials are reducible. If $K=\mathbb{R}$, then this is also clearly false for any polynomial of degree greater than 2, but it is true for polynomials of degree 2, since $x^2+ax+b$ has discriminant $a^2-4b$ so for $b>a^2/4$, the polynomial is irreducible. So my question is actually the following: Are there any fields for which this is true for all polynomials? Also is it true in for all fields in the restricted sense? I.e. as in $\mathbb{R}$, true for all polynomials of at most degree $n$ and only true for these polynomials. Note that $n$ may be 1. Also can we compute this $n$? I guess what I'm asking is when can I add a constant to make a polynomial irreducible? Also interesting is the case when $K$ is replaced with a ring. I have no idea how to begin this question, any suggestions would be appreciated. I would prefer a good indication of what direction to go if it would be reasonable to solve this problem with my background (undergraduate algebra/number theory/basic galois theory/very little analysis) rather than a complete solution, but either is appreciated. I should mention that I did google this and found nothing, but if you find something, that would also be appreciated. Thanks, I hope I'm not missing something obvious.","I was working on a different problem when the following question occurred to me: For a polynomial $f\in K[x]$, is there always a constant $c\in K$ such that $f+c$ is irreducible? Obviously this is false for some fields, consider $x^2$ over $\mathbb{F}_2$, $x^2$ factors as does $x^2+1$. In general it must be false for finite fields as $x^q+c$ has a root at $c$ for all $c$ in $\mathbb{F}_q$. Or take any algebraically closed field, trivially this cannot be done for a nonlinear polynomial since all nonlinear polynomials are reducible. If $K=\mathbb{R}$, then this is also clearly false for any polynomial of degree greater than 2, but it is true for polynomials of degree 2, since $x^2+ax+b$ has discriminant $a^2-4b$ so for $b>a^2/4$, the polynomial is irreducible. So my question is actually the following: Are there any fields for which this is true for all polynomials? Also is it true in for all fields in the restricted sense? I.e. as in $\mathbb{R}$, true for all polynomials of at most degree $n$ and only true for these polynomials. Note that $n$ may be 1. Also can we compute this $n$? I guess what I'm asking is when can I add a constant to make a polynomial irreducible? Also interesting is the case when $K$ is replaced with a ring. I have no idea how to begin this question, any suggestions would be appreciated. I would prefer a good indication of what direction to go if it would be reasonable to solve this problem with my background (undergraduate algebra/number theory/basic galois theory/very little analysis) rather than a complete solution, but either is appreciated. I should mention that I did google this and found nothing, but if you find something, that would also be appreciated. Thanks, I hope I'm not missing something obvious.",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
47,Is it possible to prove $g^{|G|}=e$ in all finite groups without talking about cosets? [duplicate],Is it possible to prove  in all finite groups without talking about cosets? [duplicate],g^{|G|}=e,"This question already has answers here : Is there a way to prove that the order of an element in a group divides the order of the Group, WITHOUT USING LAGRANGE'S (2 answers) Closed 3 years ago . Let $G$ be a finite group, and $g$ be a an element of $G$. How could we go about proving $g^{|G|}=e$ without using cosets? I would admit Lagrange's theorem if a proof without talking about cosets can be found. I have a proof for abelian groups which basically consists in taking the usual proof of Euler's theorem and using it in a group, I do not know if it can be modified to work in arbitrary finite groups. The proof is as follows: the function from $G$ to $G$ that consists of mapping $h$ to $gh$ is a bijection. Therefore $\prod\limits_{h\in G}h=\prod\limits_{h\in G}gh$ but because of commutativity $\prod\limits_{h\in G}gh=\prod\limits_{h\in G}g\prod\limits_{h\in G}h=g^{|G|}\prod\limits_{h\in G}h$. So we have $\prod\limits_{h\in G}h=g^{|G|}\prod\limits_{h\in G}h$. The cancellation property yields $e=g^{|G|}$. I am looking for some support as to why it may be hard to prove this result without talking about cosets, or if possible an actual proof without cosets. Thank you very much in advance, regards.","This question already has answers here : Is there a way to prove that the order of an element in a group divides the order of the Group, WITHOUT USING LAGRANGE'S (2 answers) Closed 3 years ago . Let $G$ be a finite group, and $g$ be a an element of $G$. How could we go about proving $g^{|G|}=e$ without using cosets? I would admit Lagrange's theorem if a proof without talking about cosets can be found. I have a proof for abelian groups which basically consists in taking the usual proof of Euler's theorem and using it in a group, I do not know if it can be modified to work in arbitrary finite groups. The proof is as follows: the function from $G$ to $G$ that consists of mapping $h$ to $gh$ is a bijection. Therefore $\prod\limits_{h\in G}h=\prod\limits_{h\in G}gh$ but because of commutativity $\prod\limits_{h\in G}gh=\prod\limits_{h\in G}g\prod\limits_{h\in G}h=g^{|G|}\prod\limits_{h\in G}h$. So we have $\prod\limits_{h\in G}h=g^{|G|}\prod\limits_{h\in G}h$. The cancellation property yields $e=g^{|G|}$. I am looking for some support as to why it may be hard to prove this result without talking about cosets, or if possible an actual proof without cosets. Thank you very much in advance, regards.",,"['abstract-algebra', 'group-theory', 'alternative-proof']"
48,Ring and sum of idempotent elements,Ring and sum of idempotent elements,,"Let $R$ be a ring with identity which for every $x\in R$ there exist two idempotent elements $e_1,e_2$ such that $x=e_1+e_2$ and $e_1e_2=e_2e_1$. Prove that: $x^3=x$ for every $x\in R$.","Let $R$ be a ring with identity which for every $x\in R$ there exist two idempotent elements $e_1,e_2$ such that $x=e_1+e_2$ and $e_1e_2=e_2e_1$. Prove that: $x^3=x$ for every $x\in R$.",,"['abstract-algebra', 'ring-theory']"
49,$\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is ring isomorphic to $\mathbb{Z}_n$.,is ring isomorphic to .,\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2}) \mathbb{Z}_n,"what would be an $n$ such that $\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is ring isomorphic to $\mathbb{Z}_n$? This problem was on a qualification test. Here's how I solved it, but I'm not satisfied with my answer since it is too intuitive. Let $I=(3-\sqrt{2})$. Since $3+I=\sqrt{2}+I$, $9+I=2+I$ hence $7+I=I$. Hence the characteristic of the quotient ring $\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is not greater than $7$. For this reason, I expected $n$ would be $7$. Define $\phi(1)=\bar{1}$ and $\phi(\sqrt{2})=\bar{3}$. Since $2$ is square-free the function $\phi:\mathbb{Z}[\sqrt{2}]\rightarrow \mathbb{Z}_7$ is well defined. Then, it can be directly checked that $\phi$ is a ring epimorphism. Let $a+b\sqrt{2}\in \ker(\phi)$. Then, $a+3b \equiv 0 \pmod 7$ Thus for some $k$, $a+3b=7k$. Note that every element in $(3-\sqrt{2})$ is of the form $3c-2d+\sqrt{2}(3d-c)$. Define $A=3-2k, B= 3k-1$. Note that $a+3b=7k=A+3B$. Thus, $a=A+3l$ and $b=B-l$ for some $l$. Thus. $a=(3+3l) - 2k , b=3k - (1+l)$. Thus, $a+b\sqrt{2}\in I$. This shows that $\ker(\phi)=I$. This proves the problem. Q.E.D. Is there another way to prove this?","what would be an $n$ such that $\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is ring isomorphic to $\mathbb{Z}_n$? This problem was on a qualification test. Here's how I solved it, but I'm not satisfied with my answer since it is too intuitive. Let $I=(3-\sqrt{2})$. Since $3+I=\sqrt{2}+I$, $9+I=2+I$ hence $7+I=I$. Hence the characteristic of the quotient ring $\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is not greater than $7$. For this reason, I expected $n$ would be $7$. Define $\phi(1)=\bar{1}$ and $\phi(\sqrt{2})=\bar{3}$. Since $2$ is square-free the function $\phi:\mathbb{Z}[\sqrt{2}]\rightarrow \mathbb{Z}_7$ is well defined. Then, it can be directly checked that $\phi$ is a ring epimorphism. Let $a+b\sqrt{2}\in \ker(\phi)$. Then, $a+3b \equiv 0 \pmod 7$ Thus for some $k$, $a+3b=7k$. Note that every element in $(3-\sqrt{2})$ is of the form $3c-2d+\sqrt{2}(3d-c)$. Define $A=3-2k, B= 3k-1$. Note that $a+3b=7k=A+3B$. Thus, $a=A+3l$ and $b=B-l$ for some $l$. Thus. $a=(3+3l) - 2k , b=3k - (1+l)$. Thus, $a+b\sqrt{2}\in I$. This shows that $\ker(\phi)=I$. This proves the problem. Q.E.D. Is there another way to prove this?",,"['abstract-algebra', 'alternative-proof']"
50,Splitting field and polynomial of minimal degree,Splitting field and polynomial of minimal degree,,"Let's assume that we have a splitting field $F$ over $\mathbb Q$ that is a finite extension. Let $p(x)$ be the polynomial in $\mathbb Q[x]$ that has $F$ as a splitting field and is of minimal degree. Is it correct that if $\mathrm{Gal}(F/\mathbb Q)$ is isomorphic to $S_n$ then $\deg p(x)=n$ ? If yes, is it true that, more generally, $\deg p(x)$ equals $n$ , where $n$ is the minimal natural number such that $\mathrm{Gal}(F/\mathbb Q)$ is contained in $S_n$ ? Thanks a lot in advance.","Let's assume that we have a splitting field over that is a finite extension. Let be the polynomial in that has as a splitting field and is of minimal degree. Is it correct that if is isomorphic to then ? If yes, is it true that, more generally, equals , where is the minimal natural number such that is contained in ? Thanks a lot in advance.",F \mathbb Q p(x) \mathbb Q[x] F \mathrm{Gal}(F/\mathbb Q) S_n \deg p(x)=n \deg p(x) n n \mathrm{Gal}(F/\mathbb Q) S_n,"['abstract-algebra', 'galois-theory']"
51,Is the product of all conjugates of some subgroup independent of the order?,Is the product of all conjugates of some subgroup independent of the order?,,"Let $G$ be a finite group and $A \le G$. Let $A^G = \{ A_1, A_2, \ldots, A_n \}$ be all the conjugates of $A$, i.e. each $A_i$ equals $A^g$ for some $g \in G$. Then I want to show that $$  A_1 A_2 \cdots A_n = A_{\pi(1)} A_{\pi(2)} \cdots A_{\pi(n)} $$ for each permutation $\pi \in \mathcal S_n$. I guess I have to apply $ba = ab^a$, but If I move some element, i.e. consider $a,b \in A$ and $a^g b^h \in A^gA^h$, then $a^g b^h = b^h (a^g)^{b^h}$ and $(a^g)^{b^h}$ need not be in $A^g$? (also in general I guess two conjugates of a subgroup need not commute, i.e. $A^g A^h \ne A^h A^g$ in general, right?). Any hints (maybe how to apply $ba = ab^a$ correctly...) how to solve it?","Let $G$ be a finite group and $A \le G$. Let $A^G = \{ A_1, A_2, \ldots, A_n \}$ be all the conjugates of $A$, i.e. each $A_i$ equals $A^g$ for some $g \in G$. Then I want to show that $$  A_1 A_2 \cdots A_n = A_{\pi(1)} A_{\pi(2)} \cdots A_{\pi(n)} $$ for each permutation $\pi \in \mathcal S_n$. I guess I have to apply $ba = ab^a$, but If I move some element, i.e. consider $a,b \in A$ and $a^g b^h \in A^gA^h$, then $a^g b^h = b^h (a^g)^{b^h}$ and $(a^g)^{b^h}$ need not be in $A^g$? (also in general I guess two conjugates of a subgroup need not commute, i.e. $A^g A^h \ne A^h A^g$ in general, right?). Any hints (maybe how to apply $ba = ab^a$ correctly...) how to solve it?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'permutations']"
52,Kummer Theory - Example of Subgroup of $K^{*}$ containing $K^{*m}$ for global fields.,Kummer Theory - Example of Subgroup of  containing  for global fields.,K^{*} K^{*m},"I am trying to understand Kummer theory and I wish to apply it to global fields, so our field $K$ containing $\mu_m$ should be $\mathbb{Q}(\zeta_m)$. Let $B$ be a subgroup of $K^{*}$ containing $K^{*m}$. We define $K_B:=K(B^{1/m})$ to be the compositum of all $K(a^{1/m})$ such that $a\in B$. Define $G=\text{Gal}(K_B/K)$. (This is necessarily a Galois extension as $K_B$ is a splitting field for $x^n-a$ for any $a\in B$.) We then have the Kummer Pairing,  $$\kappa:G\:\text{x}\:B\rightarrow B$$ given by $\kappa(\sigma,a)=\frac{\sigma(\alpha)}{\alpha}$, for $\alpha^m=a$. My question is this: Can we think of an explicit example of $B$ such that $(B:K^{*m})$ is finite? I am struggling to see how this works","I am trying to understand Kummer theory and I wish to apply it to global fields, so our field $K$ containing $\mu_m$ should be $\mathbb{Q}(\zeta_m)$. Let $B$ be a subgroup of $K^{*}$ containing $K^{*m}$. We define $K_B:=K(B^{1/m})$ to be the compositum of all $K(a^{1/m})$ such that $a\in B$. Define $G=\text{Gal}(K_B/K)$. (This is necessarily a Galois extension as $K_B$ is a splitting field for $x^n-a$ for any $a\in B$.) We then have the Kummer Pairing,  $$\kappa:G\:\text{x}\:B\rightarrow B$$ given by $\kappa(\sigma,a)=\frac{\sigma(\alpha)}{\alpha}$, for $\alpha^m=a$. My question is this: Can we think of an explicit example of $B$ such that $(B:K^{*m})$ is finite? I am struggling to see how this works",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'kummer-theory']"
53,prove the set of all functions such that $f:\mathbb{Z} \to \mathbb{Z}$ where $|f(x)-f(y)|=|x-y|$ form a group under composition,prove the set of all functions such that  where  form a group under composition,f:\mathbb{Z} \to \mathbb{Z} |f(x)-f(y)|=|x-y|,"Let f be a function $f:\mathbb{Z} \to \mathbb{Z}$ where $|f(x)-f(y)|=|x-y|$ prove that the set of all such functions forms a group under composition. I think this is the set of all linear functions, yes? since $f(x)=x+z$, $z\in \mathbb{Z}$, satisfies this property. It just 'shifts' this 'gap' in some direction along the number line. I assume this works: Let $a,b \in \mathbb{Z}$ then $|f(x)-f(y)|=|a+z-(b+z)|=|a-b+(z-z)|=|a-b|$ I think this has closure since the composition $f(g(x))=f(x+z)=x+2z$ where $2z \in \mathbb{Z}$ since $(Z,+)$ is itself a group. I am not really sure how to identify and prove the existence of the identity here since this is dealing with a set of functions. Any guidance/hints? And as a note - If you've noticed me posting abstract alg. questions over the past day or two it is because I am doing ever problem/exercise/proof given by our prof. over the course of the last month to prepare myself for an exam! None of these are assigned for grading.","Let f be a function $f:\mathbb{Z} \to \mathbb{Z}$ where $|f(x)-f(y)|=|x-y|$ prove that the set of all such functions forms a group under composition. I think this is the set of all linear functions, yes? since $f(x)=x+z$, $z\in \mathbb{Z}$, satisfies this property. It just 'shifts' this 'gap' in some direction along the number line. I assume this works: Let $a,b \in \mathbb{Z}$ then $|f(x)-f(y)|=|a+z-(b+z)|=|a-b+(z-z)|=|a-b|$ I think this has closure since the composition $f(g(x))=f(x+z)=x+2z$ where $2z \in \mathbb{Z}$ since $(Z,+)$ is itself a group. I am not really sure how to identify and prove the existence of the identity here since this is dealing with a set of functions. Any guidance/hints? And as a note - If you've noticed me posting abstract alg. questions over the past day or two it is because I am doing ever problem/exercise/proof given by our prof. over the course of the last month to prepare myself for an exam! None of these are assigned for grading.",,['abstract-algebra']
54,$ Aut(G) \text{ is cyclic} \Rightarrow G \text{ is cyclic}$?,?, Aut(G) \text{ is cyclic} \Rightarrow G \text{ is cyclic},"Let $G$ be a group. Is true that, if $Aut(G)$ be a cyclic group then, $G$ is cyclic?! I know that $ Aut(G) \text{ is cyclic} \Rightarrow G \text{ is Abelian}$, but above question asks something stronger!","Let $G$ be a group. Is true that, if $Aut(G)$ be a cyclic group then, $G$ is cyclic?! I know that $ Aut(G) \text{ is cyclic} \Rightarrow G \text{ is Abelian}$, but above question asks something stronger!",,"['abstract-algebra', 'group-theory']"
55,do you need $P$ prime to show that $R/P$ is a PID if $R$ is a PID?,do you need  prime to show that  is a PID if  is a PID?,P R/P R,"My question relates to this question , which is exercise 3 in Section 8.2 of Dummit and Foote. They ask to prove that a quotient of a PID by a prime ideal is again a PID. The answers to the previous question point out that in a PID $R$ a prime ideal is maximal, the quotient is a field, and any field is a PID since its only ideals are $0=(0)$ and $R=(1)$. Fine, but before I turned to SE I undertook to answer this is on my own, and I came up with the following argument: Let $P$ be an ideal of PID $R$, $\bar R=R/P$ the quotient, $\bar I$ any ideal of $\bar R$ and $\varphi$ the natural homomorphism from $R\to\bar R$. By the lattice isomorphism theorem $I=\varphi^{-1}(\bar I)$ is an ideal of $R$ that contains $P$. Since $R$ is a PID, there is an $a\in R$ such that $I=(a)$. Now let $\bar b$ be any element of $\bar I$, and $b$ a representative of $\bar b$ in $R$. Then there is some $r\in R$ such that $b=ra$. Since $\varphi$ is a homomorphism, $\varphi(b)=\bar b=\varphi(r)\varphi(a)=\bar r\bar a$. Therefore $\bar I=(\bar a)$, and $\bar I$ is principal. Since this argument placed no restrictions on $\bar I$, every ideal of $\bar R$ is principal. $\square$ I was bothered by this because I have always learned that if you don't use everything you're given when solving a problem, you're probably missing something, and I made no use of the information that $P$ is a prime ideal. So here's my question: do you need the fact that $P$ is prime to prove that $R/P$ is a PID? If so, where did I go wrong? Can someone give me a counterexample so I can see where the argument fails? Muchas gracias!","My question relates to this question , which is exercise 3 in Section 8.2 of Dummit and Foote. They ask to prove that a quotient of a PID by a prime ideal is again a PID. The answers to the previous question point out that in a PID $R$ a prime ideal is maximal, the quotient is a field, and any field is a PID since its only ideals are $0=(0)$ and $R=(1)$. Fine, but before I turned to SE I undertook to answer this is on my own, and I came up with the following argument: Let $P$ be an ideal of PID $R$, $\bar R=R/P$ the quotient, $\bar I$ any ideal of $\bar R$ and $\varphi$ the natural homomorphism from $R\to\bar R$. By the lattice isomorphism theorem $I=\varphi^{-1}(\bar I)$ is an ideal of $R$ that contains $P$. Since $R$ is a PID, there is an $a\in R$ such that $I=(a)$. Now let $\bar b$ be any element of $\bar I$, and $b$ a representative of $\bar b$ in $R$. Then there is some $r\in R$ such that $b=ra$. Since $\varphi$ is a homomorphism, $\varphi(b)=\bar b=\varphi(r)\varphi(a)=\bar r\bar a$. Therefore $\bar I=(\bar a)$, and $\bar I$ is principal. Since this argument placed no restrictions on $\bar I$, every ideal of $\bar R$ is principal. $\square$ I was bothered by this because I have always learned that if you don't use everything you're given when solving a problem, you're probably missing something, and I made no use of the information that $P$ is a prime ideal. So here's my question: do you need the fact that $P$ is prime to prove that $R/P$ is a PID? If so, where did I go wrong? Can someone give me a counterexample so I can see where the argument fails? Muchas gracias!",,"['abstract-algebra', 'principal-ideal-domains', 'maximal-and-prime-ideals']"
56,Modern algebra and set theory: ZFC vs. NBG,Modern algebra and set theory: ZFC vs. NBG,,"This may be somewhat of a philosophical question and is probably nitpicking, but it is also one that has always bothered me a little: Is it not more natural consider NBG set theory as the foundation for modern algebra as opposed to traditional ZFC? To me, ZF has always seemed sort of hacky, for lack of a better word, as if it has been patched and patched over the years; kind of how windows vista would look today if it were still in use. It is no doubt an extremely powerful theory, but the point is that in modern application ZF tends to be somewhat inadequate, seemingly always requiring a work around; thus, hacky. On the other hand, NBG deals with classes directly, and is just for all intents and purposes more accessible from the algebraic viewpoint, especially from the point of view of lattice and order theory, all the way to class field theory. NBG is just better equipped for the job. I guess an easier way to say all of this is that while ZF is more concerned with objects, NBG is designed to exploit the relationships between objects, which, in my opinion is more fundamental to not only mathematics, but to logic itself. NBG is implemented naturally to exhibit the abilities of comparison and deduction, which can be argued to form the basis for the concept of logic, in and of itself. Am I crazy, or has anyone else ever felt this way?","This may be somewhat of a philosophical question and is probably nitpicking, but it is also one that has always bothered me a little: Is it not more natural consider NBG set theory as the foundation for modern algebra as opposed to traditional ZFC? To me, ZF has always seemed sort of hacky, for lack of a better word, as if it has been patched and patched over the years; kind of how windows vista would look today if it were still in use. It is no doubt an extremely powerful theory, but the point is that in modern application ZF tends to be somewhat inadequate, seemingly always requiring a work around; thus, hacky. On the other hand, NBG deals with classes directly, and is just for all intents and purposes more accessible from the algebraic viewpoint, especially from the point of view of lattice and order theory, all the way to class field theory. NBG is just better equipped for the job. I guess an easier way to say all of this is that while ZF is more concerned with objects, NBG is designed to exploit the relationships between objects, which, in my opinion is more fundamental to not only mathematics, but to logic itself. NBG is implemented naturally to exhibit the abilities of comparison and deduction, which can be argued to form the basis for the concept of logic, in and of itself. Am I crazy, or has anyone else ever felt this way?",,"['abstract-algebra', 'soft-question', 'set-theory', 'foundations']"
57,The group $E(\mathbb{F}_p)$ has exactly $p+1$ elements,The group  has exactly  elements,E(\mathbb{F}_p) p+1,"Let $E/\mathbb{F}_p$ the elliptic curve $y^2=x^3+Ax$. We suppose that $p \geq 7$ and $p \equiv 3 \pmod {4}$. I want to show that the group $E(\mathbb{F}_p)$ has exactly $p+1$ elements. I was wondering if we could use the rank of the group.. Do you have an idea? EDIT : There are the following possibilities: If the point $(x,y)$ is in $E(\mathbb{F}_p)$, then the point $(x,-y)$ is also in $E(\mathbb{F}_p)$. If the point $(-x,y)$ is in $E(\mathbb{F}_p)$, then the point $(-x,-y)$ is also in $E(\mathbb{F}_p)$. $y^2=f(x)$ $f(x)=x^3+Ax \Rightarrow f(-x)=-f(x)$ Let $(x,  y)$ be a point in $E(\mathbb{F}_p)$. Then $f(x)$ is a square. If $(-x,  y)$ would also be a point in $E(\mathbb{F}_p)$, then $f(-x)$ would also be a square, and then $-f(x)$ would be a square, so $-1$ would be a square. That cannot be true, since $p \equiv 3 \pmod 4$. Is this correct? But I still don't understand how we can count the solutions. Could you explain it to me?","Let $E/\mathbb{F}_p$ the elliptic curve $y^2=x^3+Ax$. We suppose that $p \geq 7$ and $p \equiv 3 \pmod {4}$. I want to show that the group $E(\mathbb{F}_p)$ has exactly $p+1$ elements. I was wondering if we could use the rank of the group.. Do you have an idea? EDIT : There are the following possibilities: If the point $(x,y)$ is in $E(\mathbb{F}_p)$, then the point $(x,-y)$ is also in $E(\mathbb{F}_p)$. If the point $(-x,y)$ is in $E(\mathbb{F}_p)$, then the point $(-x,-y)$ is also in $E(\mathbb{F}_p)$. $y^2=f(x)$ $f(x)=x^3+Ax \Rightarrow f(-x)=-f(x)$ Let $(x,  y)$ be a point in $E(\mathbb{F}_p)$. Then $f(x)$ is a square. If $(-x,  y)$ would also be a point in $E(\mathbb{F}_p)$, then $f(-x)$ would also be a square, and then $-f(x)$ would be a square, so $-1$ would be a square. That cannot be true, since $p \equiv 3 \pmod 4$. Is this correct? But I still don't understand how we can count the solutions. Could you explain it to me?",,"['abstract-algebra', 'group-theory', 'algebraic-geometry', 'elliptic-curves']"
58,Solving $x^2 \equiv a (\text{mod }6)$,Solving,x^2 \equiv a (\text{mod }6),"While preparig for the winter exams I am doing some old exam questions, but cannot get past the following question: Find all $0 \le a \lt 6 \in \mathbb{Z}$ where $x \in \mathbb{Z}: x^2 \equiv \text{a (mod 6)}$ I can do some trial and error solution, but pretty sure it can be done in a more fancy manner... Any help is appreciated","While preparig for the winter exams I am doing some old exam questions, but cannot get past the following question: Find all $0 \le a \lt 6 \in \mathbb{Z}$ where $x \in \mathbb{Z}: x^2 \equiv \text{a (mod 6)}$ I can do some trial and error solution, but pretty sure it can be done in a more fancy manner... Any help is appreciated",,['abstract-algebra']
59,If a nilpotent group $A$ act on a group $G$ then $G$ is solvable.,If a nilpotent group  act on a group  then  is solvable.,A G G,"Theorem: If a nilpotent group $A$ act on $G$ by automorphism and $C_G(A)=e$ then $G$ is solvable. I hope that the statement of theorem is true. It should belong to Hartley, but when I googled it I could not find the the theorem. If someone provides the whole statement of the theorem with source, I would be thankful.","Theorem: If a nilpotent group $A$ act on $G$ by automorphism and $C_G(A)=e$ then $G$ is solvable. I hope that the statement of theorem is true. It should belong to Hartley, but when I googled it I could not find the the theorem. If someone provides the whole statement of the theorem with source, I would be thankful.",,"['abstract-algebra', 'group-theory', 'reference-request', 'finite-groups']"
60,What is the meaning of $x*\sqrt{3} \mod 1$?,What is the meaning of ?,x*\sqrt{3} \mod 1,"What is the meaning of $x*\sqrt{3} \mod 1$?  I'm trying to understand this: $$5( x*\sqrt{3} \mod 1) $$ If we talk about: $x=19,22,48,98$ what will be the result? I don't know how to calculate it.","What is the meaning of $x*\sqrt{3} \mod 1$?  I'm trying to understand this: $$5( x*\sqrt{3} \mod 1) $$ If we talk about: $x=19,22,48,98$ what will be the result? I don't know how to calculate it.",,['abstract-algebra']
61,Automorphism of algebraic closure $\overline{{\bf F}}_p$.,Automorphism of algebraic closure .,\overline{{\bf F}}_p,"Problem : I want to give an concrete example of automorphism of $\overline{{\bf F}}_p$ which fixes ${\bf F}_p$, where $$\overline{{\bf F}}_p =\bigcup_{n\geq 1} {\bf F}_{p^n} $$ and ${\bf F}_{p^n} $ is finite extension over a finite field  ${\bf F}_p$, i.e., splitting of $$ x^{p^n} -x =0$$ Automorphism of ${\bf F}_{p^n}$ : Let $\alpha$ be some solution of the equation. Then ${\bf F}_{p^n}$ is a vector space over a basis $$ \alpha,\ \alpha^p,\ \alpha^{p^2},\ \cdots , \ \alpha^{p^{n-1}} $$ Hence any element has the form $$ \sum_{i=0}^{n-1} a_i \alpha^{p^i} ,\ a_i\in {\bf F}_i$$ Here $Frobenius$ map, which is a generator of ${\bf Z}_n={\rm Aut}\ ({\bf F}_{p^n}/{\bf F}_p) $, is $$ \sum_{i=0}^{n-1} a_i \alpha^{p^i} \mapsto\sum_{i=0}^{n-1} a_i \alpha^{p^{i+1}} $$ Note that here $a_i \alpha^{p^i},\ a_i\neq 0$ is not fixed. Proof : Recall the fact that $$ {\bf F}_{p^n}\subseteq {\bf F}_{p^{nt}} $$ Consider a equation $x^{p^{nt}} -x=0$. Let $\beta$ be a solution which plays a role of $\alpha$. Then $$ \alpha =\beta +\beta^{p^n}+\cdots + \beta^{p(t-1)n } $$ We have a claim : If $\sigma\in {\rm Aut}\ ({\bf F}_{p^{nt}}/{\bf F}_p)$ and $\sigma(\alpha)=\alpha^p$, then $$\sigma(\beta)=\beta^p$$ If this is true, $q$ is a prime, and $f\in {\rm Aut}\ (\overline{{\bf F}}_p/{\bf F}_p)$ s.t. $$  f(x)=x^p,\ x\in {\bf F}_{p^{n}} $$ then by the above argument we have $$ y\mapsto y^p,\ y\in {\bf F}_{p^{qn}}$$ Hence $f$ is $$ y\mapsto y^p,\ \forall y\in \overline{{\bf F}}_p$$ Am I right ? If so, how can we prove a claim ?","Problem : I want to give an concrete example of automorphism of $\overline{{\bf F}}_p$ which fixes ${\bf F}_p$, where $$\overline{{\bf F}}_p =\bigcup_{n\geq 1} {\bf F}_{p^n} $$ and ${\bf F}_{p^n} $ is finite extension over a finite field  ${\bf F}_p$, i.e., splitting of $$ x^{p^n} -x =0$$ Automorphism of ${\bf F}_{p^n}$ : Let $\alpha$ be some solution of the equation. Then ${\bf F}_{p^n}$ is a vector space over a basis $$ \alpha,\ \alpha^p,\ \alpha^{p^2},\ \cdots , \ \alpha^{p^{n-1}} $$ Hence any element has the form $$ \sum_{i=0}^{n-1} a_i \alpha^{p^i} ,\ a_i\in {\bf F}_i$$ Here $Frobenius$ map, which is a generator of ${\bf Z}_n={\rm Aut}\ ({\bf F}_{p^n}/{\bf F}_p) $, is $$ \sum_{i=0}^{n-1} a_i \alpha^{p^i} \mapsto\sum_{i=0}^{n-1} a_i \alpha^{p^{i+1}} $$ Note that here $a_i \alpha^{p^i},\ a_i\neq 0$ is not fixed. Proof : Recall the fact that $$ {\bf F}_{p^n}\subseteq {\bf F}_{p^{nt}} $$ Consider a equation $x^{p^{nt}} -x=0$. Let $\beta$ be a solution which plays a role of $\alpha$. Then $$ \alpha =\beta +\beta^{p^n}+\cdots + \beta^{p(t-1)n } $$ We have a claim : If $\sigma\in {\rm Aut}\ ({\bf F}_{p^{nt}}/{\bf F}_p)$ and $\sigma(\alpha)=\alpha^p$, then $$\sigma(\beta)=\beta^p$$ If this is true, $q$ is a prime, and $f\in {\rm Aut}\ (\overline{{\bf F}}_p/{\bf F}_p)$ s.t. $$  f(x)=x^p,\ x\in {\bf F}_{p^{n}} $$ then by the above argument we have $$ y\mapsto y^p,\ y\in {\bf F}_{p^{qn}}$$ Hence $f$ is $$ y\mapsto y^p,\ \forall y\in \overline{{\bf F}}_p$$ Am I right ? If so, how can we prove a claim ?",,"['abstract-algebra', 'vector-spaces', 'finite-fields', 'extension-field']"
62,"Describe explicitly $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m)$.",Describe explicitly .,"\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m)","Describe explicitly $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) := \{\varphi:\mathbb{Z}_n \rightarrow \mathbb{Z}_m \mid \mathbb{Z}\text{-linear homomorphism}\}$ There is an answer to this question that says $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_{(n,m)}$ where $(n,m)=\gcd(n,m)$. But I am having some trouble seeing this. For the sake of an argument, suppose the above answer is true, that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_{(n,m)}$. Suppose $n=4$ and $m=8$. Then $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_4, \mathbb{Z}_8) \cong \mathbb{Z}_4$. Now consider each of the following maps in $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_4, \mathbb{Z}_8)$: $\varphi_1(1)=1$ $\varphi_2(1)=2$ $\varphi_3(1)=3$ $\varphi_4(1)=4$ $\varphi_5(1)=5$ $\varphi_6(1)=6$ $\varphi_7(1)=7$ Are each of these maps not unique? If there are two that are identical, could you please explain which two and why? Thank you! My alternate answer is that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_m$, since I think each $\varphi \in \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m)$ is uniquely determined by where it maps $\varphi(1) \in \mathbb{Z}_m$.","Describe explicitly $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) := \{\varphi:\mathbb{Z}_n \rightarrow \mathbb{Z}_m \mid \mathbb{Z}\text{-linear homomorphism}\}$ There is an answer to this question that says $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_{(n,m)}$ where $(n,m)=\gcd(n,m)$. But I am having some trouble seeing this. For the sake of an argument, suppose the above answer is true, that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_{(n,m)}$. Suppose $n=4$ and $m=8$. Then $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_4, \mathbb{Z}_8) \cong \mathbb{Z}_4$. Now consider each of the following maps in $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_4, \mathbb{Z}_8)$: $\varphi_1(1)=1$ $\varphi_2(1)=2$ $\varphi_3(1)=3$ $\varphi_4(1)=4$ $\varphi_5(1)=5$ $\varphi_6(1)=6$ $\varphi_7(1)=7$ Are each of these maps not unique? If there are two that are identical, could you please explain which two and why? Thank you! My alternate answer is that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_m$, since I think each $\varphi \in \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m)$ is uniquely determined by where it maps $\varphi(1) \in \mathbb{Z}_m$.",,"['abstract-algebra', 'ring-theory']"
63,Characterize the natural numbers $n$ such that there is a surjective group homomorphism from $S_n$ to $S_{n-1}$.,Characterize the natural numbers  such that there is a surjective group homomorphism from  to .,n S_n S_{n-1},"This has always been one of my most favorite exercises from Group Theory, and I was surprised to see that this hasn't been asked before. To repeat: Characterize the natural numbers $n$ such that there is a surjective group homomorphism from $S_n$ to $S_{n-1}$. I have a solution which I will post in a couple days (if someone doesn't recreate it), but I am more interested in seeing how other people would approach this problem. I am very interested in alternate proofs of this characterization.","This has always been one of my most favorite exercises from Group Theory, and I was surprised to see that this hasn't been asked before. To repeat: Characterize the natural numbers $n$ such that there is a surjective group homomorphism from $S_n$ to $S_{n-1}$. I have a solution which I will post in a couple days (if someone doesn't recreate it), but I am more interested in seeing how other people would approach this problem. I am very interested in alternate proofs of this characterization.",,"['abstract-algebra', 'group-theory']"
64,Terminal objects of the category of morphisms,Terminal objects of the category of morphisms,,"I'm reading Basic Category Theory for Computer Scientists by Benjamin C. Pierce and in exercice 1.4.6 , he asks what the terminal objects are in $Set^\to$. Let $C$ be a category. The category $C^\to$ is defined as a category so that: An objet in $C^\to$ is an arrow in $C$ An arrow in $C^\to$ from $f:A\to B$ to $f':A'\to B'$ is a pair $(a,b)$ so that the following diagram commutes $$\require{AMScd} \begin{CD} A @>{a}>> A'\\ @V{f}VV @V{f'}VV \\ B @>{b}>> B' \end{CD}$$ I think I have solved this exercice (but I'd really appreciate comments on the proofs): Theorem 1 : Terminal objects in $Set^\to$ are isomorphisms whose codomain is a terminal object in $Set$: Lemma 2 : Given a morphism $f:A\to B$ and an isomorphism $f':A'\to B'$, $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$ is equivalent to $\exists !b:B\to B'$. Proof 2 : Since $f'$ is an isomorphism, $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$ is equivalent to $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$. We now prove that $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$ is equivalent to $\exists !b:B\to B'$. ""$\Longrightarrow$"": Suppose $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$. The existence of $b:B\to B'$ is trivial. Suppose there were two function $b_1:B\to B'$ and $b_2:B\to B'$. By setting $a_1:=f;b_1;f'^{-1}$ and $a_2:=f;b_2;f'^{-1}$, we contradict the uniqueness hypothesis. So $\exists !b:B\to B'$. ""$\Longleftarrow$"": Suppose $\exists !b$. Defining $a:=f;b;f'^{-1}$, we get the existence of $(a:A\to A',b:B\to B')$. The uniqueness of $b$ is given by the hypothesis and the uniqueness of $a$ for a given $b$ is ensured by the equation so $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$. Proof 1 : ""$\Longleftarrow$"": Let $f':A'\to B'$ be an isomorphism so that $B'$ is terminal in $Set$. By definition, we have $\forall B \in Set, \exists !b:B\to B'$. This is equivalent to $\forall A,B\in Set, \forall f:A\to B, \exists !b:B\to B'$ which is, by Lemma 1, equivalent to $\forall A,B\in Set, \forall f:A\to B, \exists !(a:A\to A',b:B\to B'), f;b=a;f'$. So $f'$ is terminal in $Set^\to$. ""$\Longrightarrow$"": Let $f':A'\to B'$ be a terminal object in $Set^\to$ (where $A'$ and $B'$ are objects of $Set$). To prove that $f'$ is injective, suppose it is not. We can find $x,y\in A'$ so that $x\not=y$ but $f(x)=f(y)$. And then the function $$s:\left\{\begin{array}{ll} x\mapsto y\\ y\mapsto x\\ \lambda\mapsto \lambda \text{ for } \lambda\not\in\{x,y\} \end{array}\right.$$ that swaps $x$ and $y$ is a valid candidate for $a$. Since $Id_A$ is a distinct valid candidate, $a$ is not unique which is absurd so $f'$ is injective. $$\require{AMScd} \begin{CD} {A'} @>{a:=Id_A\mid a := s}>> A'\\ @V{f'}VV @V{f'}VV \\ {B'} @>{b}>> B' \end{CD}$$ To prove that $f'$ is surjective, suppose it is not. We can find $y\in B'$ so that $\forall x\in A', f(x)\not=y$. If $B'$ contains an element $z\in B'$ so that $z\not= y$, the function $$p:\left\{\begin{array}{ll} y\mapsto z\\ \lambda\mapsto \lambda \text{ for } \lambda\not=y \end{array}\right.$$ that sends all elements to themselves except $y$ which is sent to $z$ is a valid candidate for $b$. Since $Id_B$ is a distinct valid candidate, $b$ is not unique which is absurd. If $B'=\{y\}$, $\forall x\in A', f(x)\not = y$ has to be vacuously true so $A'=\emptyset$. Setting $A:=\{y\}$, $B:=\{y\}$ and $f:=Id_{\{y\}}$, we don't have the existence of $a$ which is absurd. $$\require{AMScd} \begin{CD} {A:=\{y\}} @>{a}>> A'=\emptyset\\ @V{f:=Id_{\{y\}}}VV @V{f'}VV \\ {B:=\{y\}} @>{b}>> B'=\{y\} \end{CD}$$ Since both cases are absurd, $f'$ is surjective. Since $f'$ is injective and surjective, it is bijective and is therefore an isomorphism in $Set$. For any object $X$ of $Set$, we can take $A:=X$, $B:=X$ and $f:=Id_X$.  $$\require{AMScd} \begin{CD} A:=X @>{a}>> A'\\ @V{f:=Id_X}VV @V{f'}VV \\ B:=X @>{b}>> B' \end{CD}$$ We have $\exists !(a:X\to A',b:X\to B'), f;b=a;f'$ which is, by Lemma 1, equivalent to $\exists !b:X\to B'$. So $B'$ is terminal in $Set$. I tried to generalize this to all categories. Lemma 1 seems to be general and doesn't need any modification. In Theorem 1, the part that becomes hard is proving that $f'$ is an isomorphism. I assume I should prove that it's both monic and epic and then find a right-inverse (or a left-inverse) to prove it's an isomorphism but I wasn't able to do any of that. So my question is: Is there a generalisation of Theorem 1 for all categories? If yes, then I'd like to know the exact statement, and maybe a hint on the direction that I should take (including waiting to know more stuff if need be) but no proof (unless it's a hidden proof or a linked proof or any proof that I won't see until I want to). If not, then I'd like to know if there is a generalisation for some categories (I assume there must be something to be done with algebra categories but I haven't looked into it yet). I'd also like to see an example where it fails (hidden or linked and with juste a hint in the question if it's an example one can find). Thank you in advance.","I'm reading Basic Category Theory for Computer Scientists by Benjamin C. Pierce and in exercice 1.4.6 , he asks what the terminal objects are in $Set^\to$. Let $C$ be a category. The category $C^\to$ is defined as a category so that: An objet in $C^\to$ is an arrow in $C$ An arrow in $C^\to$ from $f:A\to B$ to $f':A'\to B'$ is a pair $(a,b)$ so that the following diagram commutes $$\require{AMScd} \begin{CD} A @>{a}>> A'\\ @V{f}VV @V{f'}VV \\ B @>{b}>> B' \end{CD}$$ I think I have solved this exercice (but I'd really appreciate comments on the proofs): Theorem 1 : Terminal objects in $Set^\to$ are isomorphisms whose codomain is a terminal object in $Set$: Lemma 2 : Given a morphism $f:A\to B$ and an isomorphism $f':A'\to B'$, $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$ is equivalent to $\exists !b:B\to B'$. Proof 2 : Since $f'$ is an isomorphism, $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$ is equivalent to $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$. We now prove that $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$ is equivalent to $\exists !b:B\to B'$. ""$\Longrightarrow$"": Suppose $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$. The existence of $b:B\to B'$ is trivial. Suppose there were two function $b_1:B\to B'$ and $b_2:B\to B'$. By setting $a_1:=f;b_1;f'^{-1}$ and $a_2:=f;b_2;f'^{-1}$, we contradict the uniqueness hypothesis. So $\exists !b:B\to B'$. ""$\Longleftarrow$"": Suppose $\exists !b$. Defining $a:=f;b;f'^{-1}$, we get the existence of $(a:A\to A',b:B\to B')$. The uniqueness of $b$ is given by the hypothesis and the uniqueness of $a$ for a given $b$ is ensured by the equation so $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$. Proof 1 : ""$\Longleftarrow$"": Let $f':A'\to B'$ be an isomorphism so that $B'$ is terminal in $Set$. By definition, we have $\forall B \in Set, \exists !b:B\to B'$. This is equivalent to $\forall A,B\in Set, \forall f:A\to B, \exists !b:B\to B'$ which is, by Lemma 1, equivalent to $\forall A,B\in Set, \forall f:A\to B, \exists !(a:A\to A',b:B\to B'), f;b=a;f'$. So $f'$ is terminal in $Set^\to$. ""$\Longrightarrow$"": Let $f':A'\to B'$ be a terminal object in $Set^\to$ (where $A'$ and $B'$ are objects of $Set$). To prove that $f'$ is injective, suppose it is not. We can find $x,y\in A'$ so that $x\not=y$ but $f(x)=f(y)$. And then the function $$s:\left\{\begin{array}{ll} x\mapsto y\\ y\mapsto x\\ \lambda\mapsto \lambda \text{ for } \lambda\not\in\{x,y\} \end{array}\right.$$ that swaps $x$ and $y$ is a valid candidate for $a$. Since $Id_A$ is a distinct valid candidate, $a$ is not unique which is absurd so $f'$ is injective. $$\require{AMScd} \begin{CD} {A'} @>{a:=Id_A\mid a := s}>> A'\\ @V{f'}VV @V{f'}VV \\ {B'} @>{b}>> B' \end{CD}$$ To prove that $f'$ is surjective, suppose it is not. We can find $y\in B'$ so that $\forall x\in A', f(x)\not=y$. If $B'$ contains an element $z\in B'$ so that $z\not= y$, the function $$p:\left\{\begin{array}{ll} y\mapsto z\\ \lambda\mapsto \lambda \text{ for } \lambda\not=y \end{array}\right.$$ that sends all elements to themselves except $y$ which is sent to $z$ is a valid candidate for $b$. Since $Id_B$ is a distinct valid candidate, $b$ is not unique which is absurd. If $B'=\{y\}$, $\forall x\in A', f(x)\not = y$ has to be vacuously true so $A'=\emptyset$. Setting $A:=\{y\}$, $B:=\{y\}$ and $f:=Id_{\{y\}}$, we don't have the existence of $a$ which is absurd. $$\require{AMScd} \begin{CD} {A:=\{y\}} @>{a}>> A'=\emptyset\\ @V{f:=Id_{\{y\}}}VV @V{f'}VV \\ {B:=\{y\}} @>{b}>> B'=\{y\} \end{CD}$$ Since both cases are absurd, $f'$ is surjective. Since $f'$ is injective and surjective, it is bijective and is therefore an isomorphism in $Set$. For any object $X$ of $Set$, we can take $A:=X$, $B:=X$ and $f:=Id_X$.  $$\require{AMScd} \begin{CD} A:=X @>{a}>> A'\\ @V{f:=Id_X}VV @V{f'}VV \\ B:=X @>{b}>> B' \end{CD}$$ We have $\exists !(a:X\to A',b:X\to B'), f;b=a;f'$ which is, by Lemma 1, equivalent to $\exists !b:X\to B'$. So $B'$ is terminal in $Set$. I tried to generalize this to all categories. Lemma 1 seems to be general and doesn't need any modification. In Theorem 1, the part that becomes hard is proving that $f'$ is an isomorphism. I assume I should prove that it's both monic and epic and then find a right-inverse (or a left-inverse) to prove it's an isomorphism but I wasn't able to do any of that. So my question is: Is there a generalisation of Theorem 1 for all categories? If yes, then I'd like to know the exact statement, and maybe a hint on the direction that I should take (including waiting to know more stuff if need be) but no proof (unless it's a hidden proof or a linked proof or any proof that I won't see until I want to). If not, then I'd like to know if there is a generalisation for some categories (I assume there must be something to be done with algebra categories but I haven't looked into it yet). I'd also like to see an example where it fails (hidden or linked and with juste a hint in the question if it's an example one can find). Thank you in advance.",,"['category-theory', 'abstract-algebra']"
65,Any subgroup of an abelian group is undistorted.,Any subgroup of an abelian group is undistorted.,,I need some help with the following math problem.  I am studying some notes on Geometric Group Theory and I came across the following problem. Prove: Any subgroup of an abelian group is undistorted. A subgroup $H$ of a group $G$ is said to undistorted if the inclusion map of $H$ into $G$ is a quasi-isometric embedding.  That is we think of $G$ and $H$ as being identified their unique up to quasi-isomorphism Cayley graphs.,I need some help with the following math problem.  I am studying some notes on Geometric Group Theory and I came across the following problem. Prove: Any subgroup of an abelian group is undistorted. A subgroup $H$ of a group $G$ is said to undistorted if the inclusion map of $H$ into $G$ is a quasi-isometric embedding.  That is we think of $G$ and $H$ as being identified their unique up to quasi-isomorphism Cayley graphs.,,"['abstract-algebra', 'group-theory', 'geometric-group-theory']"
66,Unique normal subgroups of every possible order,Unique normal subgroups of every possible order,,Can one characterize groups $G$ for which there is a unique normal subgroup of order $d$ for every divisor of the order of $G$? For example must they be solvable?,Can one characterize groups $G$ for which there is a unique normal subgroup of order $d$ for every divisor of the order of $G$? For example must they be solvable?,,"['abstract-algebra', 'group-theory', 'finite-groups', 'solvable-groups']"
67,"Suppose that $R$ is a commutative ring and $|R|=30$. If $I$ is an ideal of $R$ and $|I|=10$, prove that $I$ is maximal ideal","Suppose that  is a commutative ring and . If  is an ideal of  and , prove that  is maximal ideal",R |R|=30 I R |I|=10 I,"Suppose that $R$ is a commutative ring and $|R|=30$. If $I$ is an ideal of $R$ and $|I|=10$, prove that $I$ is maximal ideal Solution: $|R/I|=3 \implies R/I \approx Z_3$ which is a field. If $R$ is a commutative ring with unity and $I$ is an ideal, then $R/I$ is a field if and only if $I$ is a maximal ideal. Hence, in this problem, $I$ is a maximal ideal iff $R$ contains a unity. How do we prove that $R$ must contain a unity? I know that a finite commutative ring with no zero divisors definitely contains a unity. But, then $R$ has not been stated to not contain zero divisors either. Thank you for your help..","Suppose that $R$ is a commutative ring and $|R|=30$. If $I$ is an ideal of $R$ and $|I|=10$, prove that $I$ is maximal ideal Solution: $|R/I|=3 \implies R/I \approx Z_3$ which is a field. If $R$ is a commutative ring with unity and $I$ is an ideal, then $R/I$ is a field if and only if $I$ is a maximal ideal. Hence, in this problem, $I$ is a maximal ideal iff $R$ contains a unity. How do we prove that $R$ must contain a unity? I know that a finite commutative ring with no zero divisors definitely contains a unity. But, then $R$ has not been stated to not contain zero divisors either. Thank you for your help..",,"['abstract-algebra', 'ring-theory']"
68,"Prove that if $H$ is a characteristic subgroup of $K$, and $K$ is a normal subgroup of $G$, then $H$ is a normal subgroup of $G$","Prove that if  is a characteristic subgroup of , and  is a normal subgroup of , then  is a normal subgroup of",H K K G H G,"$H$ is a characteristic subgroup of $K$ if $\Phi(H)=H~\forall~\Phi\in Aut(K).$ Prove that if $H$ is a characteristic subgroup of $K$, and $K$ is a normal subgroup of $G$, then $H$ is a normal subgroup of $G$ Attempt: Suppose $h \in H, k \in K$ Given that $\Phi(H) = H ~~\forall~~ \Phi~\in Aut(K).$ Since, $Inn (K) \subset Aut(K) \implies k^{-1}Hk = H \implies H \vartriangleleft K$ .... $(1)$ Also, it's given that $K \vartriangleleft G$ .....$(2)$ From $(1),(2): H \vartriangleleft K \vartriangleleft G$ But, I don't think this means that $H \vartriangleleft G?$ Is there something which I am missing? Thank you for your help","$H$ is a characteristic subgroup of $K$ if $\Phi(H)=H~\forall~\Phi\in Aut(K).$ Prove that if $H$ is a characteristic subgroup of $K$, and $K$ is a normal subgroup of $G$, then $H$ is a normal subgroup of $G$ Attempt: Suppose $h \in H, k \in K$ Given that $\Phi(H) = H ~~\forall~~ \Phi~\in Aut(K).$ Since, $Inn (K) \subset Aut(K) \implies k^{-1}Hk = H \implies H \vartriangleleft K$ .... $(1)$ Also, it's given that $K \vartriangleleft G$ .....$(2)$ From $(1),(2): H \vartriangleleft K \vartriangleleft G$ But, I don't think this means that $H \vartriangleleft G?$ Is there something which I am missing? Thank you for your help",,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
69,Proving that the transformation obtained from an adjoint pair is natural,Proving that the transformation obtained from an adjoint pair is natural,,"I am reading Homological Algebra by J.J. Rotman and am unable to do this problem.  Given an adjoint pair $(F,G)$ where $F : \mathcal{C} \to \mathcal{D} $ and $G : \mathcal{D} \to \mathcal{C} $ are two covariant functors, we can obtain a natural transformation $ \eta : \mathbb{1_{\mathcal{C}}} \to GF $.  I understand the definition of $\eta$ but am unable to prove that the transformation is natural. Couls someone please help me prove that for $f \in Hom (C,C')$, $GF(f)\eta_C=\eta_{C'}f$ ? Thanks !","I am reading Homological Algebra by J.J. Rotman and am unable to do this problem.  Given an adjoint pair $(F,G)$ where $F : \mathcal{C} \to \mathcal{D} $ and $G : \mathcal{D} \to \mathcal{C} $ are two covariant functors, we can obtain a natural transformation $ \eta : \mathbb{1_{\mathcal{C}}} \to GF $.  I understand the definition of $\eta$ but am unable to prove that the transformation is natural. Couls someone please help me prove that for $f \in Hom (C,C')$, $GF(f)\eta_C=\eta_{C'}f$ ? Thanks !",,"['abstract-algebra', 'category-theory', 'adjoint-functors']"
70,A question about fields containing a copy of $\Bbb{Q}$,A question about fields containing a copy of,\Bbb{Q},"When we say a field contains a copy of the field of rational numbers $\Bbb{Q}$, what does this really mean? Does it mean it contains a field isomorphic to $\Bbb{Q}$, or does it mean it contains $\Bbb{Q}$ itself? Also, say the field contains $\Bbb{Q}$. Consider the element $a+a+a=3a$. Here, does $3$ belong to $\Bbb{Q}$? Or is $3a$ just a way of representing $a+a+a$? Thanks","When we say a field contains a copy of the field of rational numbers $\Bbb{Q}$, what does this really mean? Does it mean it contains a field isomorphic to $\Bbb{Q}$, or does it mean it contains $\Bbb{Q}$ itself? Also, say the field contains $\Bbb{Q}$. Consider the element $a+a+a=3a$. Here, does $3$ belong to $\Bbb{Q}$? Or is $3a$ just a way of representing $a+a+a$? Thanks",,"['abstract-algebra', 'field-theory']"
71,Endomorphisms of direct sum and division ring,Endomorphisms of direct sum and division ring,,"How to prove that    $$\operatorname{End}_R(V^{ \oplus n }) \cong M_n(D),$$ where $V$ is a simple left $R$-module and $D=\operatorname{End}_R(V)$. This is part of the proof finally leads to prove that ring is simple and left semi-simple if and only if it is isomorphic to $M_n(D)$ for some division ring $D$, and what's already been proved is that $End_R(V \oplus W) \cong End_R(V) \oplus End_R(W)$ and its corollary.","How to prove that    $$\operatorname{End}_R(V^{ \oplus n }) \cong M_n(D),$$ where $V$ is a simple left $R$-module and $D=\operatorname{End}_R(V)$. This is part of the proof finally leads to prove that ring is simple and left semi-simple if and only if it is isomorphic to $M_n(D)$ for some division ring $D$, and what's already been proved is that $End_R(V \oplus W) \cong End_R(V) \oplus End_R(W)$ and its corollary.",,"['abstract-algebra', 'ring-theory', 'modules', 'noncommutative-algebra', 'division-algebras']"
72,Is the algebraic subextension of a finitely generated field extension finitely generated?,Is the algebraic subextension of a finitely generated field extension finitely generated?,,"This question is motivated by this other question (and its answer). Suppose we have a field $F$, possibly imperfect. Consider the finitely generated field extension $F(a_1,\ldots,a_n)$. Is it always true that $K=F(a_1,\ldots,a_n)\cap F^{\textrm{alg}}$ is finitely generated? The proof from 1 generalises to case when $F$ is perfect (or more generally when $F(a_1,\ldots,a_n)$ is separable over $F$, I guess), thanks to the primitive element theorem. But what about the general case? What if the initial extension is inseparable?","This question is motivated by this other question (and its answer). Suppose we have a field $F$, possibly imperfect. Consider the finitely generated field extension $F(a_1,\ldots,a_n)$. Is it always true that $K=F(a_1,\ldots,a_n)\cap F^{\textrm{alg}}$ is finitely generated? The proof from 1 generalises to case when $F$ is perfect (or more generally when $F(a_1,\ldots,a_n)$ is separable over $F$, I guess), thanks to the primitive element theorem. But what about the general case? What if the initial extension is inseparable?",,"['abstract-algebra', 'field-theory']"
73,"let $S_4$ denote the group of permutations of $\{1,2,3,4\}$ and let $H$ be a sub group of $S_4$ of order $6$ .",let  denote the group of permutations of  and let  be a sub group of  of order  .,"S_4 \{1,2,3,4\} H S_4 6","Let $S_4$ denote the group of permutations of $\{1,2,3,4\}$ and let $H$ be a sub group of $S_4$ of order $6$ . Show that $\exists~ i \in \{1,2,3,4\}$ which is fixed by each element of $H$. Attempt: As per the given question, $H$ is a sub group of $S_4$ of order $6$ . We have to prove that $\exists~ i \in \{1,2,3,4\} ~ s.t. ~ \alpha(i) = i ~\forall ~\alpha \in H$ . So, If i prove that $ H \subseteq Stab_G (i)$ , then I can prove the same. Now, by orbit stabilizer theorem , we have $|G| = |Stab_G (i)|~|Orb_G(i)|$ . { So, if $G$ is a group of permutation of a set $S$. For $\forall ~s \in S$,   $orb_G(s)= \{\phi(s)~ | ~~\phi \in G .$ The set $orb_G(s)$ is a subset of $S$ called the orbit of $s$ under $G$. } We also know that $Stab_G(i)$ is a subgroup of $G$. IF i show that $\exists ~orb_G(i)$ such that $| orb_G(i) |=4$ under $G$, then we are done because $Stab_G (i)$ is already a subgroup of $G$. So, my problem boils down to finding an $i$ such that $| orb_G(i) |=4$ EDIT : I also know that Since $S_4$ has no elements of order $6$, by Lagrange's theorem the elements of H must have orders $2$ or $3 $ which means they can be which are  $2$ cycled or $3$ cycled How do I find such an $i$. Do i now write all the elements of $S_4$? Writing down everything seems tedious and impractical though ? Help will be really appreciated. Thank you.","Let $S_4$ denote the group of permutations of $\{1,2,3,4\}$ and let $H$ be a sub group of $S_4$ of order $6$ . Show that $\exists~ i \in \{1,2,3,4\}$ which is fixed by each element of $H$. Attempt: As per the given question, $H$ is a sub group of $S_4$ of order $6$ . We have to prove that $\exists~ i \in \{1,2,3,4\} ~ s.t. ~ \alpha(i) = i ~\forall ~\alpha \in H$ . So, If i prove that $ H \subseteq Stab_G (i)$ , then I can prove the same. Now, by orbit stabilizer theorem , we have $|G| = |Stab_G (i)|~|Orb_G(i)|$ . { So, if $G$ is a group of permutation of a set $S$. For $\forall ~s \in S$,   $orb_G(s)= \{\phi(s)~ | ~~\phi \in G .$ The set $orb_G(s)$ is a subset of $S$ called the orbit of $s$ under $G$. } We also know that $Stab_G(i)$ is a subgroup of $G$. IF i show that $\exists ~orb_G(i)$ such that $| orb_G(i) |=4$ under $G$, then we are done because $Stab_G (i)$ is already a subgroup of $G$. So, my problem boils down to finding an $i$ such that $| orb_G(i) |=4$ EDIT : I also know that Since $S_4$ has no elements of order $6$, by Lagrange's theorem the elements of H must have orders $2$ or $3 $ which means they can be which are  $2$ cycled or $3$ cycled How do I find such an $i$. Do i now write all the elements of $S_4$? Writing down everything seems tedious and impractical though ? Help will be really appreciated. Thank you.",,"['abstract-algebra', 'group-theory', 'permutations']"
74,The group structure of elliptic curve over $\mathbb F_p$,The group structure of elliptic curve over,\mathbb F_p,"I want to find the group of the elliptic curve $y^2=x^3-x$ over $\mathbb F_p$ for all primes $p \le 29$. But I know only 1 fact about the structure of this group: $E(\mathbb F_p)=\mathbb Z/m \mathbb Z \times \mathbb Z/nm\mathbb Z$ for $\gcd (m,p)=1, p =1 \mod m$. It doesn't really help. Is there any method to find the group without huge calculation?","I want to find the group of the elliptic curve $y^2=x^3-x$ over $\mathbb F_p$ for all primes $p \le 29$. But I know only 1 fact about the structure of this group: $E(\mathbb F_p)=\mathbb Z/m \mathbb Z \times \mathbb Z/nm\mathbb Z$ for $\gcd (m,p)=1, p =1 \mod m$. It doesn't really help. Is there any method to find the group without huge calculation?",,"['abstract-algebra', 'finite-fields', 'elliptic-curves']"
75,The definition the group of rigid motions in $\mathbb R^3$ of a tetrahedron,The definition the group of rigid motions in  of a tetrahedron,\mathbb R^3,"In Dummit & Foote's Abstract Algebra text, page 28 the following problem appears: 9 . Let $G$ be the group of rigid motions in $\mathbb R^3$ of a tetrahedron. Show that $|G|=12$. Apparently, I misunderstand something. In page 23 the authors define the dihedral group $D_{2n}$ with the same wording, ""rigid motions"": For each $n \in \mathbb{Z}^+$, $n \geq 3$ let $D_{2n}$ be the set of symmetries of a regular $n$-gon, where a symmetry is any rigid motion of the $n$-gon... Here they allow for the symmetries to be reflections, thus getting $|D_{2n}|=2n$. However, following that approach I find that the $G$ in problem 9 has order $|G|=24$. Am I doing something wrong? Is there a mistake in the formulation of the problem? Thanks!","In Dummit & Foote's Abstract Algebra text, page 28 the following problem appears: 9 . Let $G$ be the group of rigid motions in $\mathbb R^3$ of a tetrahedron. Show that $|G|=12$. Apparently, I misunderstand something. In page 23 the authors define the dihedral group $D_{2n}$ with the same wording, ""rigid motions"": For each $n \in \mathbb{Z}^+$, $n \geq 3$ let $D_{2n}$ be the set of symmetries of a regular $n$-gon, where a symmetry is any rigid motion of the $n$-gon... Here they allow for the symmetries to be reflections, thus getting $|D_{2n}|=2n$. However, following that approach I find that the $G$ in problem 9 has order $|G|=24$. Am I doing something wrong? Is there a mistake in the formulation of the problem? Thanks!",,"['abstract-algebra', 'group-theory']"
76,"Proving that the order of $(a,b)$ is the lcm of $|a|,|b|$",Proving that the order of  is the lcm of,"(a,b) |a|,|b|","I want to solve the following exercise from Dummit & Foote's Abstract Algebra text: Prove that the elements $(a,1)$ and $(1,b)$ of $A \times B$ commute and deduce that the order of $(a,b)$ is the least common multiple of $|a|$ and $|b|$. The first part is easy: $$(a,1)(1,b)=(a \star 1,1 \diamond b)=(a,b)=(1 \star a,b \diamond 1)=(1,b)(a,1) $$ The second part isn't that much harder to prove. The thing is I can't see how a proof can be deduced by the mere fact that $(a,1)$ and $(1,b)$ commute. Is such a proof possible? Thanks.","I want to solve the following exercise from Dummit & Foote's Abstract Algebra text: Prove that the elements $(a,1)$ and $(1,b)$ of $A \times B$ commute and deduce that the order of $(a,b)$ is the least common multiple of $|a|$ and $|b|$. The first part is easy: $$(a,1)(1,b)=(a \star 1,1 \diamond b)=(a,b)=(1 \star a,b \diamond 1)=(1,b)(a,1) $$ The second part isn't that much harder to prove. The thing is I can't see how a proof can be deduced by the mere fact that $(a,1)$ and $(1,b)$ commute. Is such a proof possible? Thanks.",,"['abstract-algebra', 'group-theory']"
77,"If $G$ is finite simple and $H \le G$ has index $2m$, then an involution of $G$ is conjugate to one in $H$","If  is finite simple and  has index , then an involution of  is conjugate to one in",G H \le G 2m G H,"I have been trying to prove the following for a while now, with plenty of attempts and ideas, but no success.  I would appreciate a gentle nudge in the right direction. Suppose that $G$ is a finite simple group with $|G|>2$. a) Let $H \le G$, where $|G:H|=2m$, and $m$ is odd.  If $t \in G$ has order $2$, show that $t$ is conjugate in $G$ to some element of $H$. b) Suppose that a Sylow $2$-subgroup of $G$ is isomorphic to the dihedral group $D_8$ (of order $8$).  Show that $G$ has a unique conjugacy class of involutions. For (a) I am given the hint to let $G$ act on the right cosets of $H$ via right multiplication. Let $Ha$, $Hb$ be distinct right cosets of $H$ in $G$.  Then $Ha\cdot (a^{-1}b)=Haa^{-1}b=Hb$, so the action is transitive.  It follows that there is only one orbit, with size $2m$.  By the orbit-stabilizer theorem, this tells us that $|G:G_{Ha}|=2m$ for any $Ha \in G/H$ ($G_{Ha}$ is the stabilizer of $Ha$ in $G$).  I have been racking my brain trying to find a way to show that $t$ fixes some $Ha$, because then $Ha \cdot t = Hat = Ha$, and it follows that $Hata^{-1}=H$ and $ata^{-1} \in H$, giving the desired result. I'm not sure how to use the assumptions that $G$ is simple and $|G:H|=2m$.  What I can say is that the kernel of the action of $G$ on $H$ must be trivial.  Already I mentioned that $|G:H|=2m$ gives us the size of the single orbit is $2m$, and this says that the $|G:G_{Ha}|=2m$ for each $Ha$.  I'm not sure what the significance of $m$ being odd is, because G/H is only a set and not a group (in this case).  I haven't managed to deduce any useful group properties from it, either. Another possibility is to show that $|H|$ is divisible by $2$.  Then $H$ contains an involution which is contained in some Sylow $2$-subgroup of $G$, and all of these (there must be more than one since $G$ is simple) are conjugate, so I think this may give us what we need. Again, I'd appreciate a hint (only) on how to proceed.  Thanks.","I have been trying to prove the following for a while now, with plenty of attempts and ideas, but no success.  I would appreciate a gentle nudge in the right direction. Suppose that $G$ is a finite simple group with $|G|>2$. a) Let $H \le G$, where $|G:H|=2m$, and $m$ is odd.  If $t \in G$ has order $2$, show that $t$ is conjugate in $G$ to some element of $H$. b) Suppose that a Sylow $2$-subgroup of $G$ is isomorphic to the dihedral group $D_8$ (of order $8$).  Show that $G$ has a unique conjugacy class of involutions. For (a) I am given the hint to let $G$ act on the right cosets of $H$ via right multiplication. Let $Ha$, $Hb$ be distinct right cosets of $H$ in $G$.  Then $Ha\cdot (a^{-1}b)=Haa^{-1}b=Hb$, so the action is transitive.  It follows that there is only one orbit, with size $2m$.  By the orbit-stabilizer theorem, this tells us that $|G:G_{Ha}|=2m$ for any $Ha \in G/H$ ($G_{Ha}$ is the stabilizer of $Ha$ in $G$).  I have been racking my brain trying to find a way to show that $t$ fixes some $Ha$, because then $Ha \cdot t = Hat = Ha$, and it follows that $Hata^{-1}=H$ and $ata^{-1} \in H$, giving the desired result. I'm not sure how to use the assumptions that $G$ is simple and $|G:H|=2m$.  What I can say is that the kernel of the action of $G$ on $H$ must be trivial.  Already I mentioned that $|G:H|=2m$ gives us the size of the single orbit is $2m$, and this says that the $|G:G_{Ha}|=2m$ for each $Ha$.  I'm not sure what the significance of $m$ being odd is, because G/H is only a set and not a group (in this case).  I haven't managed to deduce any useful group properties from it, either. Another possibility is to show that $|H|$ is divisible by $2$.  Then $H$ contains an involution which is contained in some Sylow $2$-subgroup of $G$, and all of these (there must be more than one since $G$ is simple) are conjugate, so I think this may give us what we need. Again, I'd appreciate a hint (only) on how to proceed.  Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'simple-groups']"
78,Cartesian Product of Boundedly Finite Groups,Cartesian Product of Boundedly Finite Groups,,"Let $G$ be the cartesian product of countably many finite groups $H_\alpha$,  $\alpha\in \omega$. Assume also that there exists an $ n\in\mathbb N$ such that $|H_\alpha|\leq n,\, \forall \alpha\in \omega$. Is $G$ locally finite? Is there an easy way to prove it? Notation A group $G$ is said to be locally finite iff every finitely generated subgroup is finite.","Let $G$ be the cartesian product of countably many finite groups $H_\alpha$,  $\alpha\in \omega$. Assume also that there exists an $ n\in\mathbb N$ such that $|H_\alpha|\leq n,\, \forall \alpha\in \omega$. Is $G$ locally finite? Is there an easy way to prove it? Notation A group $G$ is said to be locally finite iff every finitely generated subgroup is finite.",,"['abstract-algebra', 'group-theory']"
79,Does no zero divisors in quotient ring imply no zero divisors in original ring?,Does no zero divisors in quotient ring imply no zero divisors in original ring?,,"Let $R$ be a ring and let $I$ be a proper ideal of $R$. If $R/I$ has no zero divisors, then is it true that $R$ has no zero divisors? My attempt: Suppose $R$ has zero divisors, say $ab=0$ for some $a,b\in R^*$. Then $(a+I)(b+I)=ab+I=I$. However, I cannot exclude the case where $a,b\in I$. Any ideas?","Let $R$ be a ring and let $I$ be a proper ideal of $R$. If $R/I$ has no zero divisors, then is it true that $R$ has no zero divisors? My attempt: Suppose $R$ has zero divisors, say $ab=0$ for some $a,b\in R^*$. Then $(a+I)(b+I)=ab+I=I$. However, I cannot exclude the case where $a,b\in I$. Any ideas?",,"['abstract-algebra', 'ring-theory']"
80,Reference Request: Characters of Finite General Linear Groups,Reference Request: Characters of Finite General Linear Groups,,"I've been looking at J.A. Green's article The Characters of Finite General Linear Groups and it seems that Green in this article comes up with a way of calculating all irreducible characters of a given general linear group over a finite field $GL_n(\mathbb{F}_q)$, where $q$ is a prime power. The article is quite old though, and really tough to read. Would anyone happen to know a more recent or more easily digestible source for this material? Thanks!","I've been looking at J.A. Green's article The Characters of Finite General Linear Groups and it seems that Green in this article comes up with a way of calculating all irreducible characters of a given general linear group over a finite field $GL_n(\mathbb{F}_q)$, where $q$ is a prime power. The article is quite old though, and really tough to read. Would anyone happen to know a more recent or more easily digestible source for this material? Thanks!",,"['abstract-algebra', 'reference-request', 'representation-theory', 'characters']"
81,Prove that the Gaussian rationals is the field of fractions of the Gaussian integers,Prove that the Gaussian rationals is the field of fractions of the Gaussian integers,,"I'm looking to prove that $\Bbb Q[i] = \{ p + qi : p, q \in \Bbb Q \}$ is the field of fractions of $\Bbb Z[i] = \{p + qi : p, q \in Z\}$. I am familiar with definition of a field of fractions. For example, I understand that if one has an integral domain $D$, it can be embedded in a field of fractions $F_D$, and every element of $F_D$ can be written as the quotient of two elements in $D$. However I have been confused by two questions: (1) If one has a field $F$, and one can show that any element in $F$ can be expressed as the quotient of two elements in an integral domain $D$, does that imply that $F$ is the field of fractions of $D$? (i.e. Would it suffice in my case to show that every element in $\Bbb Q[i]$ can be written as a the quotient of 2 elements of $\Bbb Z[i]$?) (2) How can I show that element in $\Bbb Q[i]$ can be written as a the quotient of 2 elements of $\Bbb Z[i]$? When I write an element of $\Bbb Q[i]$ like $$q = \frac ab + \frac cdi$$ I get mixed up trying to come up with 2 elements of $\Bbb Z[i]$ that could equal that. I set $z = u+vi$ and $w = x+yi$, equate $q = z/w$ and I end up with these equations like this: $$a = ux + vy; b = x^2 + y^2; c = vx - uv; d = x^2 + y^2$$ This doesn't strike me as the way to go. Possibly there is a way to take advantage of fact that the elements are equivalence classes, but I'm not seeing it. Thank you very much!","I'm looking to prove that $\Bbb Q[i] = \{ p + qi : p, q \in \Bbb Q \}$ is the field of fractions of $\Bbb Z[i] = \{p + qi : p, q \in Z\}$. I am familiar with definition of a field of fractions. For example, I understand that if one has an integral domain $D$, it can be embedded in a field of fractions $F_D$, and every element of $F_D$ can be written as the quotient of two elements in $D$. However I have been confused by two questions: (1) If one has a field $F$, and one can show that any element in $F$ can be expressed as the quotient of two elements in an integral domain $D$, does that imply that $F$ is the field of fractions of $D$? (i.e. Would it suffice in my case to show that every element in $\Bbb Q[i]$ can be written as a the quotient of 2 elements of $\Bbb Z[i]$?) (2) How can I show that element in $\Bbb Q[i]$ can be written as a the quotient of 2 elements of $\Bbb Z[i]$? When I write an element of $\Bbb Q[i]$ like $$q = \frac ab + \frac cdi$$ I get mixed up trying to come up with 2 elements of $\Bbb Z[i]$ that could equal that. I set $z = u+vi$ and $w = x+yi$, equate $q = z/w$ and I end up with these equations like this: $$a = ux + vy; b = x^2 + y^2; c = vx - uv; d = x^2 + y^2$$ This doesn't strike me as the way to go. Possibly there is a way to take advantage of fact that the elements are equivalence classes, but I'm not seeing it. Thank you very much!",,"['abstract-algebra', 'ring-theory', 'field-theory']"
82,Example of a Short Exact Sequence,Example of a Short Exact Sequence,,"I know that $A$ is a $\mathbb{Z}$-module. And I have a short exact sequence of the form $0 \rightarrow \mathbb{Z}/2\mathbb{Z} \rightarrow A \rightarrow \mathbb{Z}/2\mathbb{Z} \rightarrow 0$ is there anything to be said about $A$ ? That is to say, Can I find $A$? I recall that $\mathbb{Z}/2\mathbb{Z}$ is neither projective nor injective as a $\mathbb{Z}$-module so the sequence probably doesn't split. Or does it?","I know that $A$ is a $\mathbb{Z}$-module. And I have a short exact sequence of the form $0 \rightarrow \mathbb{Z}/2\mathbb{Z} \rightarrow A \rightarrow \mathbb{Z}/2\mathbb{Z} \rightarrow 0$ is there anything to be said about $A$ ? That is to say, Can I find $A$? I recall that $\mathbb{Z}/2\mathbb{Z}$ is neither projective nor injective as a $\mathbb{Z}$-module so the sequence probably doesn't split. Or does it?",,"['abstract-algebra', 'modules']"
83,Viewing Laurent polynomials as a localization of $R[X]$?,Viewing Laurent polynomials as a localization of ?,R[X],"I believe that the Laurent polynomials over a ring $R$ are simply the localization of $R[X]$ at $S=\{X^n:n\geq 0\}$. However, I've always thought as Laurent polynomials as like ""polynomials"" in that they form a ring with specified addition and multiplication operations, not as equivalence classes in $S^{-1}R$. If you're coming at this from these two different viewpoints, what would it mean that the Laurent polynomials are the localization of $R[X]$ at $S$? Would that essentially mean that there is a ring isomorphism between then identifying an equivalence class with a Laurent polynomial as follows? $$ (\sum_{i=0}^m r_iX^i)/X^n\leftrightarrow \sum_{i=0}^m r_iX^{i-n} $$ Is that what is formally meant?","I believe that the Laurent polynomials over a ring $R$ are simply the localization of $R[X]$ at $S=\{X^n:n\geq 0\}$. However, I've always thought as Laurent polynomials as like ""polynomials"" in that they form a ring with specified addition and multiplication operations, not as equivalence classes in $S^{-1}R$. If you're coming at this from these two different viewpoints, what would it mean that the Laurent polynomials are the localization of $R[X]$ at $S$? Would that essentially mean that there is a ring isomorphism between then identifying an equivalence class with a Laurent polynomial as follows? $$ (\sum_{i=0}^m r_iX^i)/X^n\leftrightarrow \sum_{i=0}^m r_iX^{i-n} $$ Is that what is formally meant?",,"['abstract-algebra', 'commutative-algebra']"
84,Prime ideals in a principal ideal ring,Prime ideals in a principal ideal ring,,"I know that in a principal ideal DOMAIN every $\neq 0$ prime ideal is maximal. is this also true for just a commutative principal ideal ring? It seems to be true for $\mathbf{Z}/n\mathbf{Z}$ ($>1$, is always a PIR) innit? as every finite integral domain is a field.","I know that in a principal ideal DOMAIN every $\neq 0$ prime ideal is maximal. is this also true for just a commutative principal ideal ring? It seems to be true for $\mathbf{Z}/n\mathbf{Z}$ ($>1$, is always a PIR) innit? as every finite integral domain is a field.",,['abstract-algebra']
85,Minimal Ideal of a Commutative Ring with Unity,Minimal Ideal of a Commutative Ring with Unity,,"Can anyone help me prove this? This one is from Malik's Fundamentals of Abstract Algebra . An ideal $I$ of a ring $R$ is called a minimal ideal if $I≠{0}$ and there does not exist any ideal $J$ of R such that ${0}≠J⊂I$. If $I$ is a minimal ideal of a commutative ring $R$ with $1$, show that either $I^2={0}$ or $I=eR$ for some idempotent $e∈R$.","Can anyone help me prove this? This one is from Malik's Fundamentals of Abstract Algebra . An ideal $I$ of a ring $R$ is called a minimal ideal if $I≠{0}$ and there does not exist any ideal $J$ of R such that ${0}≠J⊂I$. If $I$ is a minimal ideal of a commutative ring $R$ with $1$, show that either $I^2={0}$ or $I=eR$ for some idempotent $e∈R$.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'ideals']"
86,Example of Artinian ring which is not a finitely generated k-algebra,Example of Artinian ring which is not a finitely generated k-algebra,,In wikipedia it says: Let $A$ be a commutative Noetherian ring with unity. Let $k$ be a field and $A$ finitely generated $k$-algebra. Then $A$ is Artinian if and only if $A$ is finitely generated as $k$-module. Can anybody give me an example of Artinian ring which is a $k$-algebra but not finitely generated?,In wikipedia it says: Let $A$ be a commutative Noetherian ring with unity. Let $k$ be a field and $A$ finitely generated $k$-algebra. Then $A$ is Artinian if and only if $A$ is finitely generated as $k$-module. Can anybody give me an example of Artinian ring which is a $k$-algebra but not finitely generated?,,"['abstract-algebra', 'commutative-algebra']"
87,T. Y. Lam's definition for the rank of a projective module,T. Y. Lam's definition for the rank of a projective module,,"This is a concept from Lectures on Modules and Rings of T. Y. Lam. It's on page 34-35 of the book. Throughout this post, $R$ will be used to denote a commutative ring. Let $P$ be a f.g $R-$projective module. For any prime ideal $\mathfrak{p} \subset R$, the localization $P_{\mathfrak{p}} := P \otimes_R R_{\mathfrak{p}}$ is also a f.g projective $R_{\mathfrak{p}}-$module. $\color{green}{\textbf{I get this part. Yay!!!}}$ Since $R_{\mathfrak{p}}$ is a local ring, $P_{\mathfrak{p}}$ must actually be free (by FC 19.29). $\color{green}{\textbf{Sounds good!!!}}$, say $P_{\mathfrak{p}} \cong R_{\mathfrak{p}}^{n_{\mathfrak{p}}}$ (for some $n_\mathfrak{p} \in \mathbb{N}$), so we have a function $f: \text{Spec}(R) \to \mathbb{Z}$, sending each $\mathfrak{p}$ to $n_\mathfrak{p}$. If that function $f$ is constant, i.e $n_\mathfrak{p} = n, \forall \mathfrak{p} \in \text{Spec}{R}$, we shall say that $P$ has rank $n$. And denote it as: $\text{rk}(P) = n$. $\color{red}{\textbf{What I don't really get is the idea behind this definition.}}$. And then, the author leaves a fact unproved: Fact. Let $P$, $Q$ be two f.g projective $R-$modules of rank $n$, and $m$ respectively. Show that $\text{rk}(P^*) = n$, and $\text{rk}(P\otimes_RQ) = nm$, where $P^* = \text{Hom}_R(P; R)$. I think it should be very easy, since the author doesn't prove it. So here's my try on the problem. Since $P$, $Q$ are both f.g $R-$projective, there exists $R-$modules $P'$, and $Q'$, such that $R^i = P\oplus P'$, and $R^j = Q\oplus Q'$. So we'll have: $R^i = \text{Hom}(R^i,R) = \text{Hom}(P \oplus P',R) = \text{Hom}(P,R) \oplus \text{Hom}(P',R)$ $R^j = \text{Hom}(R^j,R) = \text{Hom}(Q \oplus Q',R) = \text{Hom}(Q,R) \oplus \text{Hom}(Q',R)$ So basically, we'll have $P \oplus P' \cong \text{Hom}(P,R) \oplus \text{Hom}(P',R)$, and $Q \oplus Q' \cong \text{Hom}(Q,R) \oplus \text{Hom}(Q',R)$. How can I proceed from here? Is this the correct way to start? I just wanna ask 2 things: Firstly, can you guys please give me the idea (or some motivation) behind this definition for the rank of a projective modules? Secondly, can you guys check my work (are there any subtle errors, or something), and give me a little push on the problem? :( Thank you so much for your help, And have a good day,","This is a concept from Lectures on Modules and Rings of T. Y. Lam. It's on page 34-35 of the book. Throughout this post, $R$ will be used to denote a commutative ring. Let $P$ be a f.g $R-$projective module. For any prime ideal $\mathfrak{p} \subset R$, the localization $P_{\mathfrak{p}} := P \otimes_R R_{\mathfrak{p}}$ is also a f.g projective $R_{\mathfrak{p}}-$module. $\color{green}{\textbf{I get this part. Yay!!!}}$ Since $R_{\mathfrak{p}}$ is a local ring, $P_{\mathfrak{p}}$ must actually be free (by FC 19.29). $\color{green}{\textbf{Sounds good!!!}}$, say $P_{\mathfrak{p}} \cong R_{\mathfrak{p}}^{n_{\mathfrak{p}}}$ (for some $n_\mathfrak{p} \in \mathbb{N}$), so we have a function $f: \text{Spec}(R) \to \mathbb{Z}$, sending each $\mathfrak{p}$ to $n_\mathfrak{p}$. If that function $f$ is constant, i.e $n_\mathfrak{p} = n, \forall \mathfrak{p} \in \text{Spec}{R}$, we shall say that $P$ has rank $n$. And denote it as: $\text{rk}(P) = n$. $\color{red}{\textbf{What I don't really get is the idea behind this definition.}}$. And then, the author leaves a fact unproved: Fact. Let $P$, $Q$ be two f.g projective $R-$modules of rank $n$, and $m$ respectively. Show that $\text{rk}(P^*) = n$, and $\text{rk}(P\otimes_RQ) = nm$, where $P^* = \text{Hom}_R(P; R)$. I think it should be very easy, since the author doesn't prove it. So here's my try on the problem. Since $P$, $Q$ are both f.g $R-$projective, there exists $R-$modules $P'$, and $Q'$, such that $R^i = P\oplus P'$, and $R^j = Q\oplus Q'$. So we'll have: $R^i = \text{Hom}(R^i,R) = \text{Hom}(P \oplus P',R) = \text{Hom}(P,R) \oplus \text{Hom}(P',R)$ $R^j = \text{Hom}(R^j,R) = \text{Hom}(Q \oplus Q',R) = \text{Hom}(Q,R) \oplus \text{Hom}(Q',R)$ So basically, we'll have $P \oplus P' \cong \text{Hom}(P,R) \oplus \text{Hom}(P',R)$, and $Q \oplus Q' \cong \text{Hom}(Q,R) \oplus \text{Hom}(Q',R)$. How can I proceed from here? Is this the correct way to start? I just wanna ask 2 things: Firstly, can you guys please give me the idea (or some motivation) behind this definition for the rank of a projective modules? Secondly, can you guys check my work (are there any subtle errors, or something), and give me a little push on the problem? :( Thank you so much for your help, And have a good day,",,"['abstract-algebra', 'modules', 'projective-module']"
88,Tensor product of a finitely generated abelian group and the field of rational numbers,Tensor product of a finitely generated abelian group and the field of rational numbers,,"Let $G$ be a a finitely generated abelian group. Then $G\otimes_\mathbb{Z} \mathbb{Q} = 0$ if and only if $G$ is a finite group. The ""if"" part is easy. The ""only if"" part can be proved using the fundamental theorem of finitely generated abelian groups . Can we prove it without using the theorem?","Let $G$ be a a finitely generated abelian group. Then $G\otimes_\mathbb{Z} \mathbb{Q} = 0$ if and only if $G$ is a finite group. The ""if"" part is easy. The ""only if"" part can be proved using the fundamental theorem of finitely generated abelian groups . Can we prove it without using the theorem?",,"['abstract-algebra', 'abelian-groups', 'tensor-products']"
89,"Find all prime and maximal ideals of $\mathbb C[x,y]$ that contain $I=\langle x^2 + 1, y + 3\rangle$",Find all prime and maximal ideals of  that contain,"\mathbb C[x,y] I=\langle x^2 + 1, y + 3\rangle","I want to find all prime and maximal ideals of $\mathbb C[x,y]$ that contain $I=\langle x^2 + 1, y + 3\rangle$. My approach is that I know that if $f(x)$ is irreducible then $ < f(x) > $ is a prime ideal. So, if I factor $x^2+1$ into $(x+i)(x-i)$ then those are irreducible factors in $C[x,y]$. And $y+3$ is also irreducible over $C[x,y]$. So then the prime ideals that contain $I$ should be: $< x+i, y+3 >$ $< x-i, y+3 >$ Is this true? Can I say that $< x-i, y+3 >$ is prime because $f(x,y) = (x-i) + (y+3)$ is irreducible over $C[x,y]$ or how do I motivate that? I'm kind of unfamiliar with working with ideals in two variabels, and ideals generated by two elements, so I'm not quite sure how I can use the theorems that I know from one-variable. I also don't know how I can show that these ideals are also maximal. Since $C[x,y]$ is not a PID then I can't draw the conclusion that just because the ideals are prime that they are also maximal. Also, just for verification that I understood it right. The elements of the ideal $I=< x^2 + 1, y + 3 >$ are all elements of the form $f(x,y) \times (x^2+1) + g(x,y)\times(y+3)$. So therefor it is true that the ideals that I suggested both contain $I$? Thankful for any help!","I want to find all prime and maximal ideals of $\mathbb C[x,y]$ that contain $I=\langle x^2 + 1, y + 3\rangle$. My approach is that I know that if $f(x)$ is irreducible then $ < f(x) > $ is a prime ideal. So, if I factor $x^2+1$ into $(x+i)(x-i)$ then those are irreducible factors in $C[x,y]$. And $y+3$ is also irreducible over $C[x,y]$. So then the prime ideals that contain $I$ should be: $< x+i, y+3 >$ $< x-i, y+3 >$ Is this true? Can I say that $< x-i, y+3 >$ is prime because $f(x,y) = (x-i) + (y+3)$ is irreducible over $C[x,y]$ or how do I motivate that? I'm kind of unfamiliar with working with ideals in two variabels, and ideals generated by two elements, so I'm not quite sure how I can use the theorems that I know from one-variable. I also don't know how I can show that these ideals are also maximal. Since $C[x,y]$ is not a PID then I can't draw the conclusion that just because the ideals are prime that they are also maximal. Also, just for verification that I understood it right. The elements of the ideal $I=< x^2 + 1, y + 3 >$ are all elements of the form $f(x,y) \times (x^2+1) + g(x,y)\times(y+3)$. So therefor it is true that the ideals that I suggested both contain $I$? Thankful for any help!",,"['abstract-algebra', 'ideals']"
90,If $M$ is finitely generated then $M/N$ is finitely generated.,If  is finitely generated then  is finitely generated.,M M/N,Let $N$ be a submodule of $R$-module $M$. Prove that if $M$ is finitely generated then $M/N$ is finitely generated. Help me some hints.,Let $N$ be a submodule of $R$-module $M$. Prove that if $M$ is finitely generated then $M/N$ is finitely generated. Help me some hints.,,"['abstract-algebra', 'modules']"
91,The intersection of two Sylow p-subgroups has the same order,The intersection of two Sylow p-subgroups has the same order,,Let $G$ be a finite group and assume it has more than one Sylow $p$-subgroup. It is known that order of intersection of two Sylow p-subgroups may change depending on the pairs of Sylow p-subgroups. I wonder whether there is a condition which guarantees that intersection of any two Sylow $p$-subgroups has the same order. Thanks for your help.,Let $G$ be a finite group and assume it has more than one Sylow $p$-subgroup. It is known that order of intersection of two Sylow p-subgroups may change depending on the pairs of Sylow p-subgroups. I wonder whether there is a condition which guarantees that intersection of any two Sylow $p$-subgroups has the same order. Thanks for your help.,,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
92,radical of I is the entire ring R implies I=R?,radical of I is the entire ring R implies I=R?,,Can anyone prove that: radical of I (ideal) is the entire ring R implies I=R? The ring has a unit and commutative. Thanks...,Can anyone prove that: radical of I (ideal) is the entire ring R implies I=R? The ring has a unit and commutative. Thanks...,,"['abstract-algebra', 'ring-theory']"
93,Reference request: Graduate Algebra book for self study,Reference request: Graduate Algebra book for self study,,"I have had little exposure to algebra during my undergraduate degree, covering essentially only the basics of group theory with an emphasis on the symmetries of Euclidean space, and a course on Galois theory. I hugely enjoyed these subjects and I'd love to learn more algebra. However I need to do this in self - study mode, and also I'd need to narrow the topics a little. I am doing a PhD in topological analysis so the background material I study these days is broadly differential geometry, functional analysis, algebraic topology. I do not confine my interests to these (interesting!) areas in general but I have to restrain myself due to time constraints. Question 1: What are the most suitable topics in algebra that I could study on the side? I already have some ideas, such as multilinear algebra, module theory, Clifford algebras (I need to understand Dirac operators) or homological algebra, but I am not sure these are actually the ""optimal"" choices (subject to the constraint that I need to focus on finishing my PhD). Another way to go would be Lie theory and Representation theory (closely related and very useful in ""my"" area, though not purely algebraic). But as I said there may be better choices, also I am aware that my suggestions differ widely with regards to their generality. Another topic that I dearly wish to become familiar with is Category theory! If I find the time to spend more time with Algebra I'd prefer to do it from the point of view of Category theory. Question 2: What are the recommendable graduate level books on Algebra that are well suited for self - study, focus on the appropriate topics (as suggested above, for example) and take Category theory into account? (By graduate level I mean that I have some mathematical maturity, though my Algebra background is weak.) Many thanks!","I have had little exposure to algebra during my undergraduate degree, covering essentially only the basics of group theory with an emphasis on the symmetries of Euclidean space, and a course on Galois theory. I hugely enjoyed these subjects and I'd love to learn more algebra. However I need to do this in self - study mode, and also I'd need to narrow the topics a little. I am doing a PhD in topological analysis so the background material I study these days is broadly differential geometry, functional analysis, algebraic topology. I do not confine my interests to these (interesting!) areas in general but I have to restrain myself due to time constraints. Question 1: What are the most suitable topics in algebra that I could study on the side? I already have some ideas, such as multilinear algebra, module theory, Clifford algebras (I need to understand Dirac operators) or homological algebra, but I am not sure these are actually the ""optimal"" choices (subject to the constraint that I need to focus on finishing my PhD). Another way to go would be Lie theory and Representation theory (closely related and very useful in ""my"" area, though not purely algebraic). But as I said there may be better choices, also I am aware that my suggestions differ widely with regards to their generality. Another topic that I dearly wish to become familiar with is Category theory! If I find the time to spend more time with Algebra I'd prefer to do it from the point of view of Category theory. Question 2: What are the recommendable graduate level books on Algebra that are well suited for self - study, focus on the appropriate topics (as suggested above, for example) and take Category theory into account? (By graduate level I mean that I have some mathematical maturity, though my Algebra background is weak.) Many thanks!",,"['abstract-algebra', 'reference-request', 'book-recommendation']"
94,Show that quotient ring of a $\Bbb C$-algebra by a maximal ideal is isomorphic to $\mathbb{C}$.,Show that quotient ring of a -algebra by a maximal ideal is isomorphic to .,\Bbb C \mathbb{C},"Let $R = \mathbb{C}[x_1,...,x_n]/I$ be a quotient of a polynomial ring over $\mathbb{C}$, and let $M$ be a maximal ideal of $R$. How do I show that quotient ring $R/M$ is isomorphic to $\mathbb{C}$? So I use the fact that $M$ is a maximal ideal of $R$ if and only if $R/M$ is a field. Obviously $\mathbb{C}$ is a field. How would I use this theorem? Hilbert's Nullstellensatz: the maximal ideals of the polynomial ring $\mathbb{C}[x_1,...x_n]$ are in bijective correspondence with points of complex n-dimensional plane. A point a in $\mathbb{C^n}$ corresponds to the kernel of a substitution map which sends f(x) in $\mathbb{C}[x_1,...x_n]$ to f(a). the kernel of this map is the ideal generated by linear polynomials with roots consisting of the components of a","Let $R = \mathbb{C}[x_1,...,x_n]/I$ be a quotient of a polynomial ring over $\mathbb{C}$, and let $M$ be a maximal ideal of $R$. How do I show that quotient ring $R/M$ is isomorphic to $\mathbb{C}$? So I use the fact that $M$ is a maximal ideal of $R$ if and only if $R/M$ is a field. Obviously $\mathbb{C}$ is a field. How would I use this theorem? Hilbert's Nullstellensatz: the maximal ideals of the polynomial ring $\mathbb{C}[x_1,...x_n]$ are in bijective correspondence with points of complex n-dimensional plane. A point a in $\mathbb{C^n}$ corresponds to the kernel of a substitution map which sends f(x) in $\mathbb{C}[x_1,...x_n]$ to f(a). the kernel of this map is the ideal generated by linear polynomials with roots consisting of the components of a",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'ideals']"
95,Group generated by a conjugacy class,Group generated by a conjugacy class,,"Let $G$ be a group, $x \in G$, and $S = \{ x^g \mid g \in G\}$. Suppose $\langle S \rangle = G$ and that $H$ and $K$ are  subgroups of $G$ with $S \subseteq H \cup K$. Show that $H=G$ or $K=G$. This is a problem from Kurzweil & Stellmacher's Theory of Finite Groups .  If we let $\langle x \rangle = A$, then $G$ is the product of the distinct conjugates of $A$ in any order,   $G=A_1 A_2 \cdots A_k$, because they generate $G$. Using this I've managed to show $G=HK$. Also $k≥3$ because a group can't be the product of two proper conjugate subgroups. The picture emerging  is that since one of $H$, $K$ has to contain two distinct  $A_i$,  somehow that forces  it to be the whole group. Of course this only works if the cyclic subgroups generated by each individual generator of $G$ have finite index, which is not guaranteed in this introductory-level problem. I suspect I'm overlooking something simple. Any help would be greatly appreciated.","Let $G$ be a group, $x \in G$, and $S = \{ x^g \mid g \in G\}$. Suppose $\langle S \rangle = G$ and that $H$ and $K$ are  subgroups of $G$ with $S \subseteq H \cup K$. Show that $H=G$ or $K=G$. This is a problem from Kurzweil & Stellmacher's Theory of Finite Groups .  If we let $\langle x \rangle = A$, then $G$ is the product of the distinct conjugates of $A$ in any order,   $G=A_1 A_2 \cdots A_k$, because they generate $G$. Using this I've managed to show $G=HK$. Also $k≥3$ because a group can't be the product of two proper conjugate subgroups. The picture emerging  is that since one of $H$, $K$ has to contain two distinct  $A_i$,  somehow that forces  it to be the whole group. Of course this only works if the cyclic subgroups generated by each individual generator of $G$ have finite index, which is not guaranteed in this introductory-level problem. I suspect I'm overlooking something simple. Any help would be greatly appreciated.",,"['abstract-algebra', 'group-theory']"
96,How to think about the object $A\otimes_kk'$.,How to think about the object .,A\otimes_kk',"Let $k'/k$ be a finite extension of fields, and let $A$ be a finitely generated commutative $k'$-algebra.  Through $k\hookrightarrow k'$ we can consider $A$ to be a finitely generated commutative $k$-algebra, and then we can consider the $k'$-algebra $A\otimes_kk'$. Are $A$ and $A\otimes_kk'$ isomorphic as $k'$-algebras?  If not, can we consider $A$ as a subalgebra of $A\otimes_kk'$ via $a\mapsto a\otimes 1$?  I believe this map has the right inverse $a\otimes c\mapsto ca$.  Are there conditions we can impose which make the two $k'$-algebras isomorphic? In general, I'm having trouble thinking about the object $A\otimes_kk'$.  For $A$, I just think of some quotient of a polynomial ring over $k'$.  Perhaps my question reduces to asking about the object $k'\otimes_kk'$?","Let $k'/k$ be a finite extension of fields, and let $A$ be a finitely generated commutative $k'$-algebra.  Through $k\hookrightarrow k'$ we can consider $A$ to be a finitely generated commutative $k$-algebra, and then we can consider the $k'$-algebra $A\otimes_kk'$. Are $A$ and $A\otimes_kk'$ isomorphic as $k'$-algebras?  If not, can we consider $A$ as a subalgebra of $A\otimes_kk'$ via $a\mapsto a\otimes 1$?  I believe this map has the right inverse $a\otimes c\mapsto ca$.  Are there conditions we can impose which make the two $k'$-algebras isomorphic? In general, I'm having trouble thinking about the object $A\otimes_kk'$.  For $A$, I just think of some quotient of a polynomial ring over $k'$.  Perhaps my question reduces to asking about the object $k'\otimes_kk'$?",,"['abstract-algebra', 'field-theory', 'tensor-products']"
97,Computing Conjugacy Classes of Subgroups in GAP,Computing Conjugacy Classes of Subgroups in GAP,,"GAP has the command ConjugacyClassesSubgroups which gives a list of the conjugacy classes of a finite group $G$.  Is there a way I can specify further what types of subgroups GAP reports?  For instance, can I ask GAP to only list conjugacy classes of subgroups of a certain order or isomorphism type? I'm interested in computing $p$-groups, and I'm hoping to cut down on computation time by instructing GAP to ignore all other subgroups. Magma has parameters like OrderEqual and OrderDividing when computing subgroups.  I'm looking for a similar function with GAP.","GAP has the command ConjugacyClassesSubgroups which gives a list of the conjugacy classes of a finite group $G$.  Is there a way I can specify further what types of subgroups GAP reports?  For instance, can I ask GAP to only list conjugacy classes of subgroups of a certain order or isomorphism type? I'm interested in computing $p$-groups, and I'm hoping to cut down on computation time by instructing GAP to ignore all other subgroups. Magma has parameters like OrderEqual and OrderDividing when computing subgroups.  I'm looking for a similar function with GAP.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'computer-algebra-systems', 'gap']"
98,A group with two non trivial subgroups is cyclic,A group with two non trivial subgroups is cyclic,,Let $G$ be a group. Suppose that $G$ has at most two nontrivial subgroups. Show that $G$ is cyclic. Can anyone help me please to solve the problem?,Let $G$ be a group. Suppose that $G$ has at most two nontrivial subgroups. Show that $G$ is cyclic. Can anyone help me please to solve the problem?,,"['abstract-algebra', 'group-theory', 'cyclic-groups']"
99,Relation between semidirect products of groups and kernels of homomorphisms,Relation between semidirect products of groups and kernels of homomorphisms,,"I want to ask a question related to semidirect products. If we have two groups $G$ and $H$ and two homomorphisms $\varphi_{1}, \varphi_{2}: H \to \operatorname{Aut(G)}$ and we know that $\ker(\varphi_{1})$ not isomorphic to $\ker(\varphi_{2})$, then can we make sure that semidirect products defined by the two homomorphisms are not isomorphic. If yes, then how? Thanks so much. I really appreciate it.","I want to ask a question related to semidirect products. If we have two groups $G$ and $H$ and two homomorphisms $\varphi_{1}, \varphi_{2}: H \to \operatorname{Aut(G)}$ and we know that $\ker(\varphi_{1})$ not isomorphic to $\ker(\varphi_{2})$, then can we make sure that semidirect products defined by the two homomorphisms are not isomorphic. If yes, then how? Thanks so much. I really appreciate it.",,"['abstract-algebra', 'group-theory', 'semidirect-product']"
