,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Conditional probability (urns and balls),Conditional probability (urns and balls),,"From an urn, containing 6 white and 12 black balls, one takes balls randomly one by one until the second white ball appears.  What is the probability that: 1) second white ball appears on the second step 2) second white ball appears on the third step 3) second white ball appears on the k-th step My solution is the following. The probability of the second white ball is $$Pr(X=2)=\frac{6}{18}\frac{5}{17}$$ The probability of the third white ball is $$Pr(X=3)=\frac{6}{18}\frac{12}{17}\frac{5}{16}+ \frac{12}{18}\frac{6}{17}\frac{5}{16} = \frac{2⋅6⋅5⋅12}{18⋅17⋅16} $$ Therefore, the probability $$Pr(X=k)=\frac{(k-1)⋅6⋅5⋅(18-k)!⋅12!}{18!⋅(12-k+2)!}$$ Could somebody, please, check my solution, especially the third part. Thank you.","From an urn, containing 6 white and 12 black balls, one takes balls randomly one by one until the second white ball appears.  What is the probability that: 1) second white ball appears on the second step 2) second white ball appears on the third step 3) second white ball appears on the k-th step My solution is the following. The probability of the second white ball is The probability of the third white ball is Therefore, the probability Could somebody, please, check my solution, especially the third part. Thank you.",Pr(X=2)=\frac{6}{18}\frac{5}{17} Pr(X=3)=\frac{6}{18}\frac{12}{17}\frac{5}{16}+ \frac{12}{18}\frac{6}{17}\frac{5}{16} = \frac{2⋅6⋅5⋅12}{18⋅17⋅16}  Pr(X=k)=\frac{(k-1)⋅6⋅5⋅(18-k)!⋅12!}{18!⋅(12-k+2)!},"['probability', 'balls-in-bins']"
1,Two type of balls in a bag,Two type of balls in a bag,,"In a bag there are $15$ red and $5$ white balls. Two balls are chosen at random and one is found to be red. The probability that the second one is also red is? I have attempted this question by counting all the favorable cases: Both red $(15×14)$ One red one white $(15×5)$ Our case is both red. The probability is, by Baye's theorem, $\dfrac{15×14}{15×14+15×5}$ . However, the answer is not $\dfrac{14}{19}$ but $\dfrac{7}{12}$ .","In a bag there are red and white balls. Two balls are chosen at random and one is found to be red. The probability that the second one is also red is? I have attempted this question by counting all the favorable cases: Both red One red one white Our case is both red. The probability is, by Baye's theorem, . However, the answer is not but .",15 5 (15×14) (15×5) \dfrac{15×14}{15×14+15×5} \dfrac{14}{19} \dfrac{7}{12},[]
2,Probability of getting 6 k times in a row,Probability of getting 6 k times in a row,,What is the probability of getting $6$ $K$ times in a row when rolling a dice N times? I thought it's $(1/6)^k*(5/6)^{n-k}$ and that times $N-K+1$ since there are $N-K+1$ ways to place an array of consecutive elements to $N$ places.,What is the probability of getting $6$ $K$ times in a row when rolling a dice N times? I thought it's $(1/6)^k*(5/6)^{n-k}$ and that times $N-K+1$ since there are $N-K+1$ ways to place an array of consecutive elements to $N$ places.,,['probability']
3,Combinatorics) Painting a cube - how to prove constructive counting method?,Combinatorics) Painting a cube - how to prove constructive counting method?,,"In the classic counting problem where you have to give the number of possible ways to paint a cube with 6 different colors, A well-known approach is constructive counting: fixing the first color to one of the faces, assuming the cube is fixed in some position relative to that colored face, and then going about painting the rest of the faces with the remaining 5 colors. This goes : $1 \cdot 5 \cdot 3! = 6/6 \cdot 5 \cdot 3!$ Obviously, ""fixing"" is equivalent to assuming that the 6 different starting options we have in the beginning for the first color are all going to end up with the same set of 6-color arrangement, with the cardinality (the number of elements in the set) being $30$. More specifically, if we assume each element of the set is a permutation or an arrangement of the 6 colors on the cube, each of the 6 starting options enumerate the same set. Since in this case, the problem space is quite small and visualization of why ""fixing"" doesn't cause problem is obvious. But, generally in these counting problems, when you use the constructive counting method, If we have $\{a,b,c,d,e\}$ to arrange, how can we show that progressing in the order of $abcde$ and $cdeab$ (or any different order) indeed count the same set? How can you prove that your method does not miss out anything? i.e. the set constructed by the method is actually surjective? I would also really appreciate it if you can explain what the domain of this relation How can you show that your method does not over-count? i.e. the set constructed is indeed a set and does not contain any duplicate elements by choosing different options at one level of construction. Refer to this post I was blocked from commenting on this one and my questions are aimed at different targets.","In the classic counting problem where you have to give the number of possible ways to paint a cube with 6 different colors, A well-known approach is constructive counting: fixing the first color to one of the faces, assuming the cube is fixed in some position relative to that colored face, and then going about painting the rest of the faces with the remaining 5 colors. This goes : $1 \cdot 5 \cdot 3! = 6/6 \cdot 5 \cdot 3!$ Obviously, ""fixing"" is equivalent to assuming that the 6 different starting options we have in the beginning for the first color are all going to end up with the same set of 6-color arrangement, with the cardinality (the number of elements in the set) being $30$. More specifically, if we assume each element of the set is a permutation or an arrangement of the 6 colors on the cube, each of the 6 starting options enumerate the same set. Since in this case, the problem space is quite small and visualization of why ""fixing"" doesn't cause problem is obvious. But, generally in these counting problems, when you use the constructive counting method, If we have $\{a,b,c,d,e\}$ to arrange, how can we show that progressing in the order of $abcde$ and $cdeab$ (or any different order) indeed count the same set? How can you prove that your method does not miss out anything? i.e. the set constructed by the method is actually surjective? I would also really appreciate it if you can explain what the domain of this relation How can you show that your method does not over-count? i.e. the set constructed is indeed a set and does not contain any duplicate elements by choosing different options at one level of construction. Refer to this post I was blocked from commenting on this one and my questions are aimed at different targets.",,"['probability', 'combinatorics', 'discrete-mathematics', 'proof-writing']"
4,Conditional expectation of multivariate normal distribution with inequality condition,Conditional expectation of multivariate normal distribution with inequality condition,,"Let $X_1, X_2, X_3$ be jointly normal with means $\mu_1,\mu_2,\mu_3$ and covariances  $\sigma_{ij}$. I know that $$ \mathbb{E}[X_1\mid X_2=x_2]=\mu_1+\frac{\sigma_{12}}{\sigma_2^2}(x_2-\mu_2) $$ and $$ \mathbb{E}[X_1\mid X_2<x_2]=\mu_1-\sigma_{12}\frac{\phi(\frac{x_2-\mu_2}{\sigma_2})}{\Phi(\frac{x_2-\mu_2}{\sigma_2})} $$ where $\phi$ and $\Phi$ are the density and probability distribution functions for the standard normal distribution. Is there a similar expression for $$ \mathbb{E}[X_1\mid X_2=x_2,X_3<x_3]~? $$ Thank you in advance.","Let $X_1, X_2, X_3$ be jointly normal with means $\mu_1,\mu_2,\mu_3$ and covariances  $\sigma_{ij}$. I know that $$ \mathbb{E}[X_1\mid X_2=x_2]=\mu_1+\frac{\sigma_{12}}{\sigma_2^2}(x_2-\mu_2) $$ and $$ \mathbb{E}[X_1\mid X_2<x_2]=\mu_1-\sigma_{12}\frac{\phi(\frac{x_2-\mu_2}{\sigma_2})}{\Phi(\frac{x_2-\mu_2}{\sigma_2})} $$ where $\phi$ and $\Phi$ are the density and probability distribution functions for the standard normal distribution. Is there a similar expression for $$ \mathbb{E}[X_1\mid X_2=x_2,X_3<x_3]~? $$ Thank you in advance.",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'normal-distribution']"
5,description of dual space of space of Radon measure equipped with topology of weak convergence,description of dual space of space of Radon measure equipped with topology of weak convergence,,"Let $\mathcal{M}(\mathbb R)$ be the space of Radon measures, equipped with topology $\tau$ generated by the following ""weak convergence"": $$ \mu_n \rightarrow \mu \quad \text{iff} \quad \int f \, d\mu_n \rightarrow \int f \, d\mu \quad  $$ for all continuous function $f$ with quadratic growth: $|f(x)|\leq C(1+|x|^2)$ for some $C>0$ . Let $\mathcal{M}_2(\mathbb R)$ be the subspace of $\mathcal{M}(\mathbb R)$ that contains all Radon measures with finite second moment. I would like to know if there is a description of the topological dual of $(\mathcal{M}(\mathbb R),\tau)$ and $(\mathcal{M}_2(\mathbb R),\tau)$ . I know $\mathcal{M}(\mathbb R)$ is the dual of $C_0(\mathbb R)$ , so we have $$ (\mathcal{M}(\mathbb R),\sigma(\mathcal{M}(\mathbb R),C_0(\mathbb R)))^*=C_0(\mathbb R) $$ where $\sigma(\mathcal{M}(\mathbb R)$ is the weak star topology. It is also obvious that convergence $\tau$ implies convergence in the weak star topology. So I was hopping the dual of  dual of $(\mathcal{M}(\mathbb R),\tau)$ or $(\mathcal{M}_2(\mathbb R),\tau)$ would just be the family of continuous functions wit quadratic growth. I also notice that $\tau$ convergence is the same as convergence in Wasserstein 2 distance, when restricted to probability measures with finite second moment. I will also be interested to see if there is any connection. I hope my question makes sense and looking forward to any hints and ideas!","Let be the space of Radon measures, equipped with topology generated by the following ""weak convergence"": for all continuous function with quadratic growth: for some . Let be the subspace of that contains all Radon measures with finite second moment. I would like to know if there is a description of the topological dual of and . I know is the dual of , so we have where is the weak star topology. It is also obvious that convergence implies convergence in the weak star topology. So I was hopping the dual of  dual of or would just be the family of continuous functions wit quadratic growth. I also notice that convergence is the same as convergence in Wasserstein 2 distance, when restricted to probability measures with finite second moment. I will also be interested to see if there is any connection. I hope my question makes sense and looking forward to any hints and ideas!","\mathcal{M}(\mathbb R) \tau 
\mu_n \rightarrow \mu \quad \text{iff} \quad \int f \, d\mu_n \rightarrow \int f \, d\mu \quad 
 f |f(x)|\leq C(1+|x|^2) C>0 \mathcal{M}_2(\mathbb R) \mathcal{M}(\mathbb R) (\mathcal{M}(\mathbb R),\tau) (\mathcal{M}_2(\mathbb R),\tau) \mathcal{M}(\mathbb R) C_0(\mathbb R) 
(\mathcal{M}(\mathbb R),\sigma(\mathcal{M}(\mathbb R),C_0(\mathbb R)))^*=C_0(\mathbb R)
 \sigma(\mathcal{M}(\mathbb R) \tau (\mathcal{M}(\mathbb R),\tau) (\mathcal{M}_2(\mathbb R),\tau) \tau","['probability', 'functional-analysis', 'measure-theory']"
6,Find probability that Rahul examines fewer policies than toby,Find probability that Rahul examines fewer policies than toby,,"$$ \underline{ \bf Attempt} $$ Let $X$ and $Y$ be the policies examined by rahul and toby, respectively. By the manner this problem is phrased we have two Bernoulli r.v. For instance, $X$ has probability success of $0.1$, thus $$ p_X(x) = {n \choose x} 0.1^x 0.8^{n-x}$$ and similarly $$ p_Y(y) = {n \choose y} 0.2^y 0.9^{n-y} $$ Now, since $X$ and $Y$ are given to be independent, we have $$ p_{XY}(x,y) = {n \choose x} {n \choose y}  0.1^x 0.8^{n-x} 0.2^y 0.9^{n-y} $$ Now, we want to find $$ P(X<Y) $$ But, for discrete case how do we compute this? Do we compute $$ \sum_{x<y} p_{XY}(x,y) $$ Perhaps my solution is not really the right to do this problem?","$$ \underline{ \bf Attempt} $$ Let $X$ and $Y$ be the policies examined by rahul and toby, respectively. By the manner this problem is phrased we have two Bernoulli r.v. For instance, $X$ has probability success of $0.1$, thus $$ p_X(x) = {n \choose x} 0.1^x 0.8^{n-x}$$ and similarly $$ p_Y(y) = {n \choose y} 0.2^y 0.9^{n-y} $$ Now, since $X$ and $Y$ are given to be independent, we have $$ p_{XY}(x,y) = {n \choose x} {n \choose y}  0.1^x 0.8^{n-x} 0.2^y 0.9^{n-y} $$ Now, we want to find $$ P(X<Y) $$ But, for discrete case how do we compute this? Do we compute $$ \sum_{x<y} p_{XY}(x,y) $$ Perhaps my solution is not really the right to do this problem?",,['probability']
7,Puzzling Dice Roll Probability Problem,Puzzling Dice Roll Probability Problem,,"Mark and Jacob are taking turns rolling a fair die. Mark rolls first. What is the probability that Mark will roll an odd number before Jacob rolls a $4$? This just has me stumped... I'm not too familiar with summations, so simple answers are appreciated","Mark and Jacob are taking turns rolling a fair die. Mark rolls first. What is the probability that Mark will roll an odd number before Jacob rolls a $4$? This just has me stumped... I'm not too familiar with summations, so simple answers are appreciated",,"['probability', 'dice']"
8,Law of large numbers problem and calculation of max expected value,Law of large numbers problem and calculation of max expected value,,"We've got to prove that $\frac{M_{n}}{\ln(n)}\rightarrow 1$ a.s. Where $M_{n}=\max\left\{{X_{1},...,X_{n}}\right\}$ , with $X_{i}\sim \mathrm{exp}(1)$ i.i.d. So it is obvious that we will have to use the Law of Large Numbers. First I thought to rewrite it as $\frac{M_{n}}{n}\frac{n}{\ln(n)}$, and apply LLN for first fraction and take the limit for the second one, but $\frac{n}{\ln(n)}$ diverges. My second thought was to calculate Cdf of $M_{n}$ and apply LLN for $S_{n}=\sum_{k=1}^{n}M_{k}$ and see if I take something like the following $\lim_{n\rightarrow \infty}\frac{S_{n}}{n}\rightarrow \ln(n)$ But I don't know how to derive $\mathbb{E}(M_{n})$ (the cdf of $M_{n}$ is $(1-e^{-x})^{n}$ , for $x\geq 0$). Im on the right track?? Any help would be great.","We've got to prove that $\frac{M_{n}}{\ln(n)}\rightarrow 1$ a.s. Where $M_{n}=\max\left\{{X_{1},...,X_{n}}\right\}$ , with $X_{i}\sim \mathrm{exp}(1)$ i.i.d. So it is obvious that we will have to use the Law of Large Numbers. First I thought to rewrite it as $\frac{M_{n}}{n}\frac{n}{\ln(n)}$, and apply LLN for first fraction and take the limit for the second one, but $\frac{n}{\ln(n)}$ diverges. My second thought was to calculate Cdf of $M_{n}$ and apply LLN for $S_{n}=\sum_{k=1}^{n}M_{k}$ and see if I take something like the following $\lim_{n\rightarrow \infty}\frac{S_{n}}{n}\rightarrow \ln(n)$ But I don't know how to derive $\mathbb{E}(M_{n})$ (the cdf of $M_{n}$ is $(1-e^{-x})^{n}$ , for $x\geq 0$). Im on the right track?? Any help would be great.",,"['probability', 'probability-theory', 'probability-distributions', 'expectation', 'law-of-large-numbers']"
9,A generalization of Kolmogorov's maximal inequality,A generalization of Kolmogorov's maximal inequality,,"Suppose $X_1, X_2, \ldots$ are independent random variables with $E(X_n) = 0$ for all $n$. For $\varepsilon > 0$, define $A_n = \left\{\max\limits_{1 \leqslant k \leqslant n} |S_k| \geqslant \varepsilon\right\}$ for all $n$, where $S_n = \sum\limits_{k = 1}^n X_k$ for all $n$. Prove that for any real $r \geqslant 1$,$$\varepsilon^r P(A_n) \leqslant E(|S_n|^r I_{A_n}) \leqslant E(|S_n|^r). \quad \forall n \geqslant 1$$ This is from the problem set of my homework and it appears to be a really nice generalization of Kolmogorov's inequality. However, when I was trying to imitate the standard proof of Kolmogorov's inequality and the proof given by Sergio for cases in which $r$ is an even integer, there occurred the problem that binomial expansion cannot be properly applied to general cases in which $r$ is an arbitrary real. I wonder if the step that uses binomial expansion in the proof of Kolmogorov's inequality is correct for this generalization or if there is a proof that avoids this particular step. Thanks!","Suppose $X_1, X_2, \ldots$ are independent random variables with $E(X_n) = 0$ for all $n$. For $\varepsilon > 0$, define $A_n = \left\{\max\limits_{1 \leqslant k \leqslant n} |S_k| \geqslant \varepsilon\right\}$ for all $n$, where $S_n = \sum\limits_{k = 1}^n X_k$ for all $n$. Prove that for any real $r \geqslant 1$,$$\varepsilon^r P(A_n) \leqslant E(|S_n|^r I_{A_n}) \leqslant E(|S_n|^r). \quad \forall n \geqslant 1$$ This is from the problem set of my homework and it appears to be a really nice generalization of Kolmogorov's inequality. However, when I was trying to imitate the standard proof of Kolmogorov's inequality and the proof given by Sergio for cases in which $r$ is an even integer, there occurred the problem that binomial expansion cannot be properly applied to general cases in which $r$ is an arbitrary real. I wonder if the step that uses binomial expansion in the proof of Kolmogorov's inequality is correct for this generalization or if there is a proof that avoids this particular step. Thanks!",,"['probability', 'inequality']"
10,Probability to get a particular string.,Probability to get a particular string.,,"We are generating a strings of length $n$ . The string consists of $n_1$ $1`s$ and $n_2$ $2`s$ . Where $n_1+n_2=n $ . All permutations of the string are equally likely. What is the probability of the event $A({m}_{11},{m}_{12},{m}_{21},{m}_{22} ) = \{{v}_{11} = {m}_{11},{v}_{12} = {m}_{12},{v}_{21} = {m}_{21},{v}_{22} = {m}_{22}\}$ ? What will be the probability space in the case? How can I build it? ${v}_{ij}$ - denotes the number of occurrences in the string when the j goes immediately after i. For example, if we have the following string $122212212121$ , then ${v}_{11} = 0, {v}_{12} = 4, {v}_{21} = 4, {v}_{22} = 3$ . I can not get how to build the probability space in the case. I tried to compute the probability of $A$ by noting that there are $2^n$ strings we can get. Then I thought about using Markov chain to compute the number of strings which would be inappropriate for the event $A$ and subtracting them from $2^n$ and dividing the result by $2^n$ due to the classic definition of the probability. I would like to get a better way to compute the probability of the event $A$ if it is possible and to get the idea behind building the probability space.","We are generating a strings of length . The string consists of and . Where . All permutations of the string are equally likely. What is the probability of the event ? What will be the probability space in the case? How can I build it? - denotes the number of occurrences in the string when the j goes immediately after i. For example, if we have the following string , then . I can not get how to build the probability space in the case. I tried to compute the probability of by noting that there are strings we can get. Then I thought about using Markov chain to compute the number of strings which would be inappropriate for the event and subtracting them from and dividing the result by due to the classic definition of the probability. I would like to get a better way to compute the probability of the event if it is possible and to get the idea behind building the probability space.","n n_1 1`s n_2 2`s n_1+n_2=n  A({m}_{11},{m}_{12},{m}_{21},{m}_{22} ) = \{{v}_{11} = {m}_{11},{v}_{12} = {m}_{12},{v}_{21} = {m}_{21},{v}_{22} = {m}_{22}\} {v}_{ij} 122212212121 {v}_{11} = 0, {v}_{12} = 4, {v}_{21} = 4, {v}_{22} = 3 A 2^n A 2^n 2^n A","['probability', 'probability-theory']"
11,Negative Binomial with $4$ white faces before $3$ black faces,Negative Binomial with  white faces before  black faces,4 3,"Suppose that a fair $6$-sided die having $2$ black faces and $4$ white faces will be rolled repeatedly. What is the probability that $4$ rolls resulting in a white face occur before $3$ rolls resulting in a black face? Attemped Solution: I'm trying to make use of the following negative binomial formula: $n$ trials, given $k$ success: ${n-1}\choose{k-1}$$p^k$$(1-p)^{n-k}$ In our case, $n$ can be $4,5$, or $6$ and $k$ is fixed at $4$. $3\choose{3}$$(\frac{2}{3})$$^4$(${1}\over{3}$)$^0$+$4\choose3$(${2}\over{3}$)$^4$(${1}\over{3}$)+$5\choose3$(${2}\over{3}$)$^4$(${1}\over{3}$)$^2$ = $.680$ Is this a valid solution? I would also be interested in alternative solutions.","Suppose that a fair $6$-sided die having $2$ black faces and $4$ white faces will be rolled repeatedly. What is the probability that $4$ rolls resulting in a white face occur before $3$ rolls resulting in a black face? Attemped Solution: I'm trying to make use of the following negative binomial formula: $n$ trials, given $k$ success: ${n-1}\choose{k-1}$$p^k$$(1-p)^{n-k}$ In our case, $n$ can be $4,5$, or $6$ and $k$ is fixed at $4$. $3\choose{3}$$(\frac{2}{3})$$^4$(${1}\over{3}$)$^0$+$4\choose3$(${2}\over{3}$)$^4$(${1}\over{3}$)+$5\choose3$(${2}\over{3}$)$^4$(${1}\over{3}$)$^2$ = $.680$ Is this a valid solution? I would also be interested in alternative solutions.",,"['probability', 'combinatorics', 'negative-binomial']"
12,Rain droplets falling on a line,Rain droplets falling on a line,,"Suppose there is a line of length $L$ cm. And it begins to rain at a constant rate of one droplet per second. Once a drop strike the line and it wets 1 cm of the line. What is the expected number of droplets it takes to wet the whole line? The following condition was suggested by Henry : To avoid the boundary problem, each point on the line within a distance of $\frac{1}{2}$ the point struck is wetted. The centre of the drop can be anywhere on the line (so if near the end would cover less than 1 but at least $\frac{1}{2}$ cm of the line. The discrete version of this problem is a classical coupon collector problem ，I am curious what would happen in the continuous case. The related post of this problem is rain droplets falling in a table . Any help will be appreciated. Thanks in advance.","Suppose there is a line of length $L$ cm. And it begins to rain at a constant rate of one droplet per second. Once a drop strike the line and it wets 1 cm of the line. What is the expected number of droplets it takes to wet the whole line? The following condition was suggested by Henry : To avoid the boundary problem, each point on the line within a distance of $\frac{1}{2}$ the point struck is wetted. The centre of the drop can be anywhere on the line (so if near the end would cover less than 1 but at least $\frac{1}{2}$ cm of the line. The discrete version of this problem is a classical coupon collector problem ，I am curious what would happen in the continuous case. The related post of this problem is rain droplets falling in a table . Any help will be appreciated. Thanks in advance.",,"['probability', 'probability-theory', 'stochastic-processes', 'computer-science', 'geometric-probability']"
13,Does $p$-value change with sample size?,Does -value change with sample size?,p,"I was wondering how $p$ -values change with sample size or is their any relation between the two. To my knowledge, a $p$ -value denotes the probability of finding observed or more extreme results than the null hypothesis claims (typically no difference). Based on the following example, let your null hypothesis be that there exists no difference in the amount of heads and tails you flip on a fair coin, that is you flip the same exact amount and your alternative be that a difference does exist. You flip a fair coin $n = 10$ times and get $7$ heads and $3$ tails, which suggests a relatively low $p$ -value. But as you flip this coin more times (say $n = 100$ ) and now get $45$ heads and $55$ tails, your $p$ -value increases - which results in you being more likely to fail to reject the null over the alternative hypothesis. Thus, does increasing sample size, increase $p$ -values in general?","I was wondering how -values change with sample size or is their any relation between the two. To my knowledge, a -value denotes the probability of finding observed or more extreme results than the null hypothesis claims (typically no difference). Based on the following example, let your null hypothesis be that there exists no difference in the amount of heads and tails you flip on a fair coin, that is you flip the same exact amount and your alternative be that a difference does exist. You flip a fair coin times and get heads and tails, which suggests a relatively low -value. But as you flip this coin more times (say ) and now get heads and tails, your -value increases - which results in you being more likely to fail to reject the null over the alternative hypothesis. Thus, does increasing sample size, increase -values in general?",p p n = 10 7 3 p n = 100 45 55 p p,['probability']
14,How many days are needed to cover at least half of all birthdays in a group of people?,How many days are needed to cover at least half of all birthdays in a group of people?,,"My question is related to this question . I am wondering if we have a large crowd of $2000$ people: what is the expected minimum number days of the year we have to pick in order for at least half of the birthdays of the crowd to be in one of those days? To be clear: with $2000$ people the average number of birthdays for any day is between $5$ and $6$, but there surely will be days where $10$ or even $12$ people have their birthday. So, knowing the birthdays of all people, I want to pick as many of those days, so that with as few days as possible I do cover half of the birthdays. That should be a good bit below $183$ I would think. In fact, my intuition is that for a crowd of $2000$, this would be $100$ or so, but I could be way off, so I would like to know. I also have the feeling that with a crowd of this size, we can make a fairly precise prediction as to how many days are needed. That is, if the expected number of days we need to cover at least $1000$ of the $2000$ birthdays is $100$, I would guess that the actual number of days with an actual crowd will be fairly close that that expected number. That is, I would like to have a result that says something like: There is a $95$% chance that the actual number of days lies within the interval $[X-Y,X+Y]$. I am just guessing: $X=100$ and $Y=5$ How far am I off? I welcome any kind of mathematical analysis, but I also welcome computer simulated approximations for this. And of course, while I am particularly interested in a crowd size of $2000$, feel free to provide a general answer in terms of $n$.","My question is related to this question . I am wondering if we have a large crowd of $2000$ people: what is the expected minimum number days of the year we have to pick in order for at least half of the birthdays of the crowd to be in one of those days? To be clear: with $2000$ people the average number of birthdays for any day is between $5$ and $6$, but there surely will be days where $10$ or even $12$ people have their birthday. So, knowing the birthdays of all people, I want to pick as many of those days, so that with as few days as possible I do cover half of the birthdays. That should be a good bit below $183$ I would think. In fact, my intuition is that for a crowd of $2000$, this would be $100$ or so, but I could be way off, so I would like to know. I also have the feeling that with a crowd of this size, we can make a fairly precise prediction as to how many days are needed. That is, if the expected number of days we need to cover at least $1000$ of the $2000$ birthdays is $100$, I would guess that the actual number of days with an actual crowd will be fairly close that that expected number. That is, I would like to have a result that says something like: There is a $95$% chance that the actual number of days lies within the interval $[X-Y,X+Y]$. I am just guessing: $X=100$ and $Y=5$ How far am I off? I welcome any kind of mathematical analysis, but I also welcome computer simulated approximations for this. And of course, while I am particularly interested in a crowd size of $2000$, feel free to provide a general answer in terms of $n$.",,"['probability', 'statistics', 'poisson-distribution', 'birthday']"
15,Probability of rolling X successes with differently sized dice,Probability of rolling X successes with differently sized dice,,"I'm trying out different systems for a board game, and my (weak) probability skills are failing me. The basic mechanic is as follows: you roll a number of six-sided dice (d6). Any die showing 5 or more is a success. A specific bonus can ""upgrade"" part of your pool to a larger die (let's say a 10-sided dice, or d10). So for example: regular roll : roll 7d6; any die showing 5 or more is one success. same roll with bonus : roll 4d6 and 3d10; any die showing 5 or more is one success. I'd like to learn how to calculate the chance of getting X successes with the mixed pool (either ""X"" successes or ""X or more"" successes). this thread thaught me how to find the probability for the homogenous pool, but I have no idea how to change the formula to accomodate the differently-sized dice. I would like to learn the general formula, to be adjusted for different size of dice (such as d8 and d12) and for a larger or smaller pool of mixed dice as well. Thanks in advance, sorry for any English mistake I may have made.","I'm trying out different systems for a board game, and my (weak) probability skills are failing me. The basic mechanic is as follows: you roll a number of six-sided dice (d6). Any die showing 5 or more is a success. A specific bonus can ""upgrade"" part of your pool to a larger die (let's say a 10-sided dice, or d10). So for example: regular roll : roll 7d6; any die showing 5 or more is one success. same roll with bonus : roll 4d6 and 3d10; any die showing 5 or more is one success. I'd like to learn how to calculate the chance of getting X successes with the mixed pool (either ""X"" successes or ""X or more"" successes). this thread thaught me how to find the probability for the homogenous pool, but I have no idea how to change the formula to accomodate the differently-sized dice. I would like to learn the general formula, to be adjusted for different size of dice (such as d8 and d12) and for a larger or smaller pool of mixed dice as well. Thanks in advance, sorry for any English mistake I may have made.",,"['probability', 'dice']"
16,Show that two random variables are independent,Show that two random variables are independent,,"I'm learning probability and need help with the following problem : Let $X_1, X_2$ be independent and identically distributed random variables with probability density function $$f(x_i) = \begin{cases} \lambda_i e^{\lambda_i x_i}, & x_i > 0 \;\; (i = 1, 2) \\ 0 & \text{elsewhere}.\end{cases}$$ $(1)$ Find the distribution of the random variable $V = \min(X_1, X_2)$. $(2)$ Show that the random variables $Z = X_1/(X_1+X_2)$ and $X_1+X_2$ are independent. Since I'm having difficulties for $(2)$, I'm going to share my work for $(1)$. $(1)$ If two variables are iid, then they must have the same distribution. Which means they have the same parameters. So I assumed $\lambda_1 = \lambda_2$, i.e. $$X_1, X_2 \overset{idd}\sim exp(rate = \lambda).$$ To find the distribution of the minimum, we look at cdfs. The cdf for the individual $X_i$’s is $$F(x)  = \int_{-\infty}^{x} f(u) \, du = \int_{0}^{x} f(u) \, du =  \int_{0}^{x} \lambda e^{-\lambda u} \, du = 1 - e^{-\lambda x}.$$ The cdf for $V$, the minimum, is : \begin{align*} F_V(v) = P(V \leq v)  &= P(\min(X_1, X_2) \leq v) \\ \\ &= 1 - P(\min(X_1, X_2) > v) \\ \\ &\overset{indep}= 1 - P(X_1 > v) \cdot P(X_2 > v) \\ \\ &\overset{ident}= 1 - [P(X_1 > v)]^n. \end{align*} From are computed cdf, we have that $$P(X_1 > v) = 1 - P(X_1 \leq v) = 1 - (1 - e^{-\lambda v}) = e^{-\lambda v}.$$ So, the cdf for the minimum $V$ is $$F_V(v) = 1 - [e^{-\lambda v}]^2 = 1 - e^{-\lambda 2 v}.$$ The pdf for the minimum is $$f_V(v) = F'_V(v) = 2\lambda e^{-2\lambda v}.$$ So we proved that $$V \sim exp(rate  = 2\lambda).$$ Is my work correct for $(1)$? Unfortunately I have no idea how to solve $(2)$. Any help would be appreciated.","I'm learning probability and need help with the following problem : Let $X_1, X_2$ be independent and identically distributed random variables with probability density function $$f(x_i) = \begin{cases} \lambda_i e^{\lambda_i x_i}, & x_i > 0 \;\; (i = 1, 2) \\ 0 & \text{elsewhere}.\end{cases}$$ $(1)$ Find the distribution of the random variable $V = \min(X_1, X_2)$. $(2)$ Show that the random variables $Z = X_1/(X_1+X_2)$ and $X_1+X_2$ are independent. Since I'm having difficulties for $(2)$, I'm going to share my work for $(1)$. $(1)$ If two variables are iid, then they must have the same distribution. Which means they have the same parameters. So I assumed $\lambda_1 = \lambda_2$, i.e. $$X_1, X_2 \overset{idd}\sim exp(rate = \lambda).$$ To find the distribution of the minimum, we look at cdfs. The cdf for the individual $X_i$’s is $$F(x)  = \int_{-\infty}^{x} f(u) \, du = \int_{0}^{x} f(u) \, du =  \int_{0}^{x} \lambda e^{-\lambda u} \, du = 1 - e^{-\lambda x}.$$ The cdf for $V$, the minimum, is : \begin{align*} F_V(v) = P(V \leq v)  &= P(\min(X_1, X_2) \leq v) \\ \\ &= 1 - P(\min(X_1, X_2) > v) \\ \\ &\overset{indep}= 1 - P(X_1 > v) \cdot P(X_2 > v) \\ \\ &\overset{ident}= 1 - [P(X_1 > v)]^n. \end{align*} From are computed cdf, we have that $$P(X_1 > v) = 1 - P(X_1 \leq v) = 1 - (1 - e^{-\lambda v}) = e^{-\lambda v}.$$ So, the cdf for the minimum $V$ is $$F_V(v) = 1 - [e^{-\lambda v}]^2 = 1 - e^{-\lambda 2 v}.$$ The pdf for the minimum is $$f_V(v) = F'_V(v) = 2\lambda e^{-2\lambda v}.$$ So we proved that $$V \sim exp(rate  = 2\lambda).$$ Is my work correct for $(1)$? Unfortunately I have no idea how to solve $(2)$. Any help would be appreciated.",,[]
17,Collection of Graphs,Collection of Graphs,,"Let $n \in \mathbb{N}$ and $r \in \mathbb{R}$. We say that $(V, G_{1}, G_{2}, ..., G_{t})$ is a $(r,n)$-collection if $V$ is a set of $n$ vertices, and $G_{1}, G_{2}, ..., G_{t}$ are $t = n^{20}$ graphs on $V$ such that $\chi(G_{i}) \ge r$ for every $i$. We say that a $(r,n)$-collection $(V, G_{1}, G_{2}, ..., G_{t})$ is special if there exist $U \subseteq V$ such that $|U| \le 2n/3$ and $\chi(G_{i}[U]) \ge r/3$ for every $i$. Is it true that for sufficiently large $n$, every $(r,n)$-collection is  special: (i) when $r = 3n^{0.1}$? (ii) when $r = 3\log_{2}(n)$? Now I don't really know how to approach this question. I tried to use martingales but I don't understand how to use it here. I also don't know how to construct graphs with such chromatic numbers.","Let $n \in \mathbb{N}$ and $r \in \mathbb{R}$. We say that $(V, G_{1}, G_{2}, ..., G_{t})$ is a $(r,n)$-collection if $V$ is a set of $n$ vertices, and $G_{1}, G_{2}, ..., G_{t}$ are $t = n^{20}$ graphs on $V$ such that $\chi(G_{i}) \ge r$ for every $i$. We say that a $(r,n)$-collection $(V, G_{1}, G_{2}, ..., G_{t})$ is special if there exist $U \subseteq V$ such that $|U| \le 2n/3$ and $\chi(G_{i}[U]) \ge r/3$ for every $i$. Is it true that for sufficiently large $n$, every $(r,n)$-collection is  special: (i) when $r = 3n^{0.1}$? (ii) when $r = 3\log_{2}(n)$? Now I don't really know how to approach this question. I tried to use martingales but I don't understand how to use it here. I also don't know how to construct graphs with such chromatic numbers.",,"['probability', 'combinatorics', 'graph-theory']"
18,5 boys and 3 girls are to be arranged such that only one girl has a boy adjacent to her . Find the number such arrangement,5 boys and 3 girls are to be arranged such that only one girl has a boy adjacent to her . Find the number such arrangement,,Suppose 5 boys and 3 girls are to be arranged  such that only one girl has a boy  adjacent to her . Find the number such arrangement . My work :  I think there are only  such  possible arrangment $2 \times 3!\times 5! $ . If the girls are aren't together then one girl will have two boys adjacent to her .So girls must be to-gather and they should be at the either of the two extreme side of the arrangement of the  boys . There are two possible side that one of the $3$ girls can take . Now the girls can arrange among themselves in $3!$ ways and boys can arrange among themselves in $5!$ ways.So there are about $3!\times 5! $ arrangements when girls are together and are at the left of the $5$-boys . Similarly there are $3!\times 5!$ other cases when girls are to be put on the left . So total cases= $2\times 3! \times 5! $,Suppose 5 boys and 3 girls are to be arranged  such that only one girl has a boy  adjacent to her . Find the number such arrangement . My work :  I think there are only  such  possible arrangment $2 \times 3!\times 5! $ . If the girls are aren't together then one girl will have two boys adjacent to her .So girls must be to-gather and they should be at the either of the two extreme side of the arrangement of the  boys . There are two possible side that one of the $3$ girls can take . Now the girls can arrange among themselves in $3!$ ways and boys can arrange among themselves in $5!$ ways.So there are about $3!\times 5! $ arrangements when girls are together and are at the left of the $5$-boys . Similarly there are $3!\times 5!$ other cases when girls are to be put on the left . So total cases= $2\times 3! \times 5! $,,"['probability', 'combinatorics', 'proof-verification', 'permutations', 'combinations']"
19,Distances between randomly distributed points in a ball,Distances between randomly distributed points in a ball,,"Say I have a 3-ball with radius $R$. If I randomly pick 2 points from the inside of the ball, the probability that the euclidean distance between the points (labeled 1 and 2) takes on a particular value $r = r_{12} = r_{21}$ is given by the probability density function (PDF) \begin{equation} P_3 (r) = \frac{3 r^{2}}{R^3} - \frac{9 r^{3}}{4 R^4} + \frac{3 r^{5}}{16 R^6} \end{equation} as described in https://arxiv.org/pdf/math-ph/0201046.pdf , equation 15. If I were to pick $N$ points from the inside of this ball simultaneously, there would be $N(N-1)/2$ distances between pairs of different points. Is it possible to express the PDF $P(r_1, r_2, \dots{}, r_{N(N-1)/2}$), where $r_1, r_2, \dots{}, r_{N(N-1)/2}$ are distances between pairs of different points, using the pair-wise PDF $P_3(r)$ ? Does there exist some other closed-form solution for such distribution, or a solution for some shape other than a ball ? In this case, it is obviously not $P_3(r) \times P_3(r) \times \dots{} \times P_3(r)$, because, for example, when 2 points are at a distance $2R$, a third point cannot be at a distance $2R$ from both of them, but such PDF would allow it.","Say I have a 3-ball with radius $R$. If I randomly pick 2 points from the inside of the ball, the probability that the euclidean distance between the points (labeled 1 and 2) takes on a particular value $r = r_{12} = r_{21}$ is given by the probability density function (PDF) \begin{equation} P_3 (r) = \frac{3 r^{2}}{R^3} - \frac{9 r^{3}}{4 R^4} + \frac{3 r^{5}}{16 R^6} \end{equation} as described in https://arxiv.org/pdf/math-ph/0201046.pdf , equation 15. If I were to pick $N$ points from the inside of this ball simultaneously, there would be $N(N-1)/2$ distances between pairs of different points. Is it possible to express the PDF $P(r_1, r_2, \dots{}, r_{N(N-1)/2}$), where $r_1, r_2, \dots{}, r_{N(N-1)/2}$ are distances between pairs of different points, using the pair-wise PDF $P_3(r)$ ? Does there exist some other closed-form solution for such distribution, or a solution for some shape other than a ball ? In this case, it is obviously not $P_3(r) \times P_3(r) \times \dots{} \times P_3(r)$, because, for example, when 2 points are at a distance $2R$, a third point cannot be at a distance $2R$ from both of them, but such PDF would allow it.",,"['probability', 'probability-distributions', 'euclidean-geometry', 'random']"
20,image of a set under a polynomial in $Z_p$ intersecting every interval of length $p/k^{2/3}$,image of a set under a polynomial in  intersecting every interval of length,Z_p p/k^{2/3},"I am trying to solve the following question: Prove that there exists a constant $c > 0$ so that:   For every $p$   prime, and any $A \subseteq \mathbb Z_p, |A| = k$ there exists a   polynomial $f$ of degree at most 3, so that $\{f(a)| a\in A\}$   intersects every interval of length at least $\frac{cp}{k^{2/3}}$. Now, I have already proved that we can have a linear polynomial so that the image intersects every interval of length $\frac{cp}{\sqrt k}$. I tried to apply the same method here, trying to utilize the fact that I have more freedom to choose the coefficients. This is my attempt at a solution: Choose randomly $x, y, z, w \in \mathbb Z_p$ and consider the polynomial $f(a) = xa^3 +ya^2+za-w$. Denote $A = \{a_1, a_2, \ldots , a_k\}$ and we can assume that $0\notin A$. For every $1 \le i \ne j \le k$ let $X_{ij}$ be the indicator random variable for the event $f(a_i) \in [0,u] \land f(a_j) \in [u+1, 2u+1]$ where $u \sim \frac{p}{k^{2/3}}$. Let $X = \sum_{i \ne j} X_{ij}$. Now, $E[X] = \sum_{i \ne j} E[X_{ij}] = k(k-1)(u+1)^2/p^2 \sim k^{2/3}$. Using Chebyshev's inequality we can bound:  $$\mathrm {Pr}(X=0) \le \frac{Var[X]}{E[X]^2} \le \frac{1}{E[X]} + \frac{1}{E[X]^2}\sum_{(i,j) \ne (i', j')}Cov(X_{ij}, X_{i'j'})$$ If the covariance term was zero then we'd get $\mathrm {Pr}(X=0) \le \frac{1}{E[X]} \sim \frac{1}{k^{2/3}}$. Then the expected value of the intervals missed by the image of $f$ would be $\sim\frac{p}{k^{2/3}} \sim u$ but this is a contradiction since if an interval of length $2u$ is missed then $u+1$ of its subintervals are also missed (I disregard the constants here to save time). However when calculating the covariance term I get  $$Cov(X_{ij}, X_{il}) = \frac{(u+1)^3}{p^3} - \frac{(u+1)^4}{p^4} \sim \frac{(u+1)^3}{p^3} \sim \frac{1}{k^2}$$ The summation over all $i,j,l$ gives the order of magnitude of $k$ so when divided by $E[X]^2$ I get a term $\sim \frac{1}{k^{1/3}}$ which is much bigger than the $1/E[X]$ term so the proof fails. Now I'm stuck. Any help will be appreciated :)","I am trying to solve the following question: Prove that there exists a constant $c > 0$ so that:   For every $p$   prime, and any $A \subseteq \mathbb Z_p, |A| = k$ there exists a   polynomial $f$ of degree at most 3, so that $\{f(a)| a\in A\}$   intersects every interval of length at least $\frac{cp}{k^{2/3}}$. Now, I have already proved that we can have a linear polynomial so that the image intersects every interval of length $\frac{cp}{\sqrt k}$. I tried to apply the same method here, trying to utilize the fact that I have more freedom to choose the coefficients. This is my attempt at a solution: Choose randomly $x, y, z, w \in \mathbb Z_p$ and consider the polynomial $f(a) = xa^3 +ya^2+za-w$. Denote $A = \{a_1, a_2, \ldots , a_k\}$ and we can assume that $0\notin A$. For every $1 \le i \ne j \le k$ let $X_{ij}$ be the indicator random variable for the event $f(a_i) \in [0,u] \land f(a_j) \in [u+1, 2u+1]$ where $u \sim \frac{p}{k^{2/3}}$. Let $X = \sum_{i \ne j} X_{ij}$. Now, $E[X] = \sum_{i \ne j} E[X_{ij}] = k(k-1)(u+1)^2/p^2 \sim k^{2/3}$. Using Chebyshev's inequality we can bound:  $$\mathrm {Pr}(X=0) \le \frac{Var[X]}{E[X]^2} \le \frac{1}{E[X]} + \frac{1}{E[X]^2}\sum_{(i,j) \ne (i', j')}Cov(X_{ij}, X_{i'j'})$$ If the covariance term was zero then we'd get $\mathrm {Pr}(X=0) \le \frac{1}{E[X]} \sim \frac{1}{k^{2/3}}$. Then the expected value of the intervals missed by the image of $f$ would be $\sim\frac{p}{k^{2/3}} \sim u$ but this is a contradiction since if an interval of length $2u$ is missed then $u+1$ of its subintervals are also missed (I disregard the constants here to save time). However when calculating the covariance term I get  $$Cov(X_{ij}, X_{il}) = \frac{(u+1)^3}{p^3} - \frac{(u+1)^4}{p^4} \sim \frac{(u+1)^3}{p^3} \sim \frac{1}{k^2}$$ The summation over all $i,j,l$ gives the order of magnitude of $k$ so when divided by $E[X]^2$ I get a term $\sim \frac{1}{k^{1/3}}$ which is much bigger than the $1/E[X]$ term so the proof fails. Now I'm stuck. Any help will be appreciated :)",,"['probability', 'combinatorics', 'polynomials', 'additive-combinatorics', 'probabilistic-method']"
21,Writing a probability in terms of the edges of a simplex,Writing a probability in terms of the edges of a simplex,,"I describe the problem dimension $2$, but it could be generalized to $n$ dimensions. So we have $X_{1}, X_{2}, X_{3}$ three $iid$ random variables of continuous law $F(x,y)$ on $\Bbb R^2$. Let's denote by $S[X_{1}, X_{2}, X_{3}]$ the simplex generated by those random variables. Given a point $(x,y)$, is it possible to write $P((x,y)\in S[X_{1}, X_{2}, X_{3}])$ as a function $g$ of $F(x,y)$ ? For example, in dimension $1$, $P(x\in [X_{1}, X_{2}]) = 2F(x)(1-F(x))$. Thank you","I describe the problem dimension $2$, but it could be generalized to $n$ dimensions. So we have $X_{1}, X_{2}, X_{3}$ three $iid$ random variables of continuous law $F(x,y)$ on $\Bbb R^2$. Let's denote by $S[X_{1}, X_{2}, X_{3}]$ the simplex generated by those random variables. Given a point $(x,y)$, is it possible to write $P((x,y)\in S[X_{1}, X_{2}, X_{3}])$ as a function $g$ of $F(x,y)$ ? For example, in dimension $1$, $P(x\in [X_{1}, X_{2}]) = 2F(x)(1-F(x))$. Thank you",,"['probability', 'geometry', 'probability-theory', 'geometric-probability']"
22,How do I compute hitting time in a finite Markov chain? (to quantify my Machi Koro pwnage),How do I compute hitting time in a finite Markov chain? (to quantify my Machi Koro pwnage),,"In a game of Machi Koro, I had the Sushi Bar (active) while my opponent had a Wheat Field and Bakery with no low-roll buildings available. I want to know how long they have to roll before they can afford the Train Station. That is, they're engaged in a Markov chain where the state space is ""0 to 4 coins"" ($\{0, 1, 2, 3, 4\}$) and I want to know the probability, for each $n$, that they reach $4$ for the first time after exactly $n$ transitions (preferably for all starting states, but just for zero is interesting enough).  I might also be interested in the cumulative version: for each $n$, what's the likelihood that they'll have reached $4$ at least once after $n$ transitions. The transition probabilities are as follows: from $k$ coins, $k < 4$: to $1$ with probability $1/6$; otherwise, to $k$ with probability $3/6$ and to $k+1$ with probability $2/6$.  Since the transitions from $4$ to anything are not interesting, I'll just define them arbitrarily as $4$ to $4$ with probability $1$ (really they'll spend all their coins, but the questions don't care what happens after $4$ is reached). Spelled out: $ \left[ \begin{matrix} 3/6 & 3/6 &     &     & \\     & 4/6 & 2/6 &     & \\     & 1/6 & 3/6 & 2/6 & \\     & 1/6 &     & 3/6 & 2/6 \\     &     &     &     & 1 \end{matrix} \right] $ (The probability in row $i$ column $j$ is the probability of transition from $i$ to $j$ coins in a single step.) Some analysis: in the transition graph, there are strongly connected components $\{0\}, \{1, 2, 3\}$ and $\{4\}$ with transitions $0 \rightarrow 1$ and $3 \rightarrow 4$. Maybe it helps to analyse each scc separately. You go from zero coins to one in $k$ steps, $k > 0$, with probability $2^{-k}$; the big one essentially boils down to ""how soon will you increment your state three times in a row (each w. prob. $2/6$) without falling back to $1$ (w. p. $1/6$ each step)"". I'm not sure how to analyze this, though. I could probably spell my way through https://en.wikipedia.org/wiki/Markov_chain but given that my matrix-fu is a little rusty, some hand-holding would be appreciated. Edit : Come to think of it, given the City Hall the transition from $0$ is to $1$ with probability $1$. The 50/50-out-of-0 would occur if I had three Cafés instead of the Sushi Bar and we were playing without the Harbor expansion.  Feel free to analyze either—or both! Also, for purposes of simplifying the math, in both cases I'm ignoring the fact that my opponent earns a coin whenever I roll a 1.","In a game of Machi Koro, I had the Sushi Bar (active) while my opponent had a Wheat Field and Bakery with no low-roll buildings available. I want to know how long they have to roll before they can afford the Train Station. That is, they're engaged in a Markov chain where the state space is ""0 to 4 coins"" ($\{0, 1, 2, 3, 4\}$) and I want to know the probability, for each $n$, that they reach $4$ for the first time after exactly $n$ transitions (preferably for all starting states, but just for zero is interesting enough).  I might also be interested in the cumulative version: for each $n$, what's the likelihood that they'll have reached $4$ at least once after $n$ transitions. The transition probabilities are as follows: from $k$ coins, $k < 4$: to $1$ with probability $1/6$; otherwise, to $k$ with probability $3/6$ and to $k+1$ with probability $2/6$.  Since the transitions from $4$ to anything are not interesting, I'll just define them arbitrarily as $4$ to $4$ with probability $1$ (really they'll spend all their coins, but the questions don't care what happens after $4$ is reached). Spelled out: $ \left[ \begin{matrix} 3/6 & 3/6 &     &     & \\     & 4/6 & 2/6 &     & \\     & 1/6 & 3/6 & 2/6 & \\     & 1/6 &     & 3/6 & 2/6 \\     &     &     &     & 1 \end{matrix} \right] $ (The probability in row $i$ column $j$ is the probability of transition from $i$ to $j$ coins in a single step.) Some analysis: in the transition graph, there are strongly connected components $\{0\}, \{1, 2, 3\}$ and $\{4\}$ with transitions $0 \rightarrow 1$ and $3 \rightarrow 4$. Maybe it helps to analyse each scc separately. You go from zero coins to one in $k$ steps, $k > 0$, with probability $2^{-k}$; the big one essentially boils down to ""how soon will you increment your state three times in a row (each w. prob. $2/6$) without falling back to $1$ (w. p. $1/6$ each step)"". I'm not sure how to analyze this, though. I could probably spell my way through https://en.wikipedia.org/wiki/Markov_chain but given that my matrix-fu is a little rusty, some hand-holding would be appreciated. Edit : Come to think of it, given the City Hall the transition from $0$ is to $1$ with probability $1$. The 50/50-out-of-0 would occur if I had three Cafés instead of the Sushi Bar and we were playing without the Harbor expansion.  Feel free to analyze either—or both! Also, for purposes of simplifying the math, in both cases I'm ignoring the fact that my opponent earns a coin whenever I roll a 1.",,"['probability', 'matrices', 'recreational-mathematics', 'markov-chains', 'dice']"
23,Math behind the match stick game in The Goal,Math behind the match stick game in The Goal,,"I just finished reading The Goal by Eliyahu M. Goldratt. It's a good book, and from my understanding, pretty well known. Goldratt is a a physicist who turned his scientific scrutiny to production line management, and his book is about how mathematical thinking can help your business. In it, he describes a game used to illustrate the flow of a production line. It goes like this: There are five people sitting in a line with a few boxes of matches at one end. The goal is to move as many matches as possible to the end of the line. In one turn, the first first person in the line rolls a six sided die and moves that number of matches down the line. The next person then rolls the die and moves that number of matches down the line, and so on. That's one turn. You repeat that process a given number of times and then count the number of matches moved all the way through (""throughput"") and count the matches that are still sitting in between the people waiting to be moved (""inventory""). You want to maximize throughput and minimize inventory build up. To be explicit, if on the first turn the first player rolls a 4 and the second player rolls a 6, they can only move 4 because there's only 4 available to move. But if there are more matches waiting in the inventory (perhaps because the person before them is getting high rolls while they've been getting low rolls), then they take from that pile. So if there are 2 already in inventory, player 1 rolls a 4 and player 2 rolls a 6, there are 6 available matches, so they can move all 6 down the line. Hopefully that's clear. Here is the question, or rather questions: What is the expected value for throughput after $n$ turns? What about the expected inventory waiting for each person after $n$ turns? How does the number of people affect these values? What if the dice are more abstract, like a 17 sided die with four 6s, three 12s, etc. Just an abstract probability distribution? What about an expected value for the amount of rolls that were ""wasted""? So if there was 2 in inventory and you rolled a 5, that would be 3 units ""wasted"" Can we find more details about the distribution, rather than just the expected value?","I just finished reading The Goal by Eliyahu M. Goldratt. It's a good book, and from my understanding, pretty well known. Goldratt is a a physicist who turned his scientific scrutiny to production line management, and his book is about how mathematical thinking can help your business. In it, he describes a game used to illustrate the flow of a production line. It goes like this: There are five people sitting in a line with a few boxes of matches at one end. The goal is to move as many matches as possible to the end of the line. In one turn, the first first person in the line rolls a six sided die and moves that number of matches down the line. The next person then rolls the die and moves that number of matches down the line, and so on. That's one turn. You repeat that process a given number of times and then count the number of matches moved all the way through (""throughput"") and count the matches that are still sitting in between the people waiting to be moved (""inventory""). You want to maximize throughput and minimize inventory build up. To be explicit, if on the first turn the first player rolls a 4 and the second player rolls a 6, they can only move 4 because there's only 4 available to move. But if there are more matches waiting in the inventory (perhaps because the person before them is getting high rolls while they've been getting low rolls), then they take from that pile. So if there are 2 already in inventory, player 1 rolls a 4 and player 2 rolls a 6, there are 6 available matches, so they can move all 6 down the line. Hopefully that's clear. Here is the question, or rather questions: What is the expected value for throughput after $n$ turns? What about the expected inventory waiting for each person after $n$ turns? How does the number of people affect these values? What if the dice are more abstract, like a 17 sided die with four 6s, three 12s, etc. Just an abstract probability distribution? What about an expected value for the amount of rolls that were ""wasted""? So if there was 2 in inventory and you rolled a 5, that would be 3 units ""wasted"" Can we find more details about the distribution, rather than just the expected value?",,"['probability', 'combinatorics', 'statistics', 'probability-distributions', 'dice']"
24,Birthday problem among k people,Birthday problem among k people,,"Consider a group of $n$ people. Assume that each person's birthday is drawn uniformly at random from the $365$ possibilities. What is the smallest value of such that the expected number of pairs of distinct people with the same birthday is at least one?. My approach using indicator random variable: $X_{\bf i, j, i \neq j} = \begin{cases}  &1 \qquad \text{ if ith and jth person having same birthday} \\ &0 \qquad \text{ if ith and jth person NOT having same birthday } \ \end{cases} \\\\$ $ \begin{align*}  & E(X_{i,j}) = 1*P(X_{i,j}) + 0*\left ( 1 - P(X_{i,j}) \right ) \\ & \Rightarrow E(X_{i,j}) = P(X_{i,j}) \\ & \Rightarrow \text{Overall E} = \sum E_{i,j} \\ \\ \hline \\  &\text{ We need } E \geq 1 \\ &\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}E_{i,j} \right ] \geq 1 \\ &\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}P_{i,j} \right ] \geq 1 \\ &\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}\left ( \frac{1}{365} \right ) \right ] \geq 1 \\  &\Rightarrow \left ( \frac{1}{365} \right ) \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}1 \right ] \geq 1 \\ & \Rightarrow \left ( \frac{1}{365} \right )\left [ \sum_{i=1}^{k-1}1 \right ] \geq 1\\ & \Rightarrow \left ( \frac{1}{365} \right )\left [ \frac{k.(k-1)}{2} \right ] \geq 1\\ & \Rightarrow k^2 - k - 730 \geq 0\\ & \Rightarrow k = \left \lceil \frac{1+ \sqrt{1+4*730}}{2} \right \rceil = \left \lceil 27.52 \right \rceil = 28 \\ \\ \end{align*}$ I hope there may be other ways to do this problem and there are other variations to this problem as well (a few are in Kenneth Rosen Book). Please help if there exist other methods. Thanks!","Consider a group of $n$ people. Assume that each person's birthday is drawn uniformly at random from the $365$ possibilities. What is the smallest value of such that the expected number of pairs of distinct people with the same birthday is at least one?. My approach using indicator random variable: $X_{\bf i, j, i \neq j} = \begin{cases}  &1 \qquad \text{ if ith and jth person having same birthday} \\ &0 \qquad \text{ if ith and jth person NOT having same birthday } \ \end{cases} \\\\$ $ \begin{align*}  & E(X_{i,j}) = 1*P(X_{i,j}) + 0*\left ( 1 - P(X_{i,j}) \right ) \\ & \Rightarrow E(X_{i,j}) = P(X_{i,j}) \\ & \Rightarrow \text{Overall E} = \sum E_{i,j} \\ \\ \hline \\  &\text{ We need } E \geq 1 \\ &\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}E_{i,j} \right ] \geq 1 \\ &\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}P_{i,j} \right ] \geq 1 \\ &\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}\left ( \frac{1}{365} \right ) \right ] \geq 1 \\  &\Rightarrow \left ( \frac{1}{365} \right ) \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}1 \right ] \geq 1 \\ & \Rightarrow \left ( \frac{1}{365} \right )\left [ \sum_{i=1}^{k-1}1 \right ] \geq 1\\ & \Rightarrow \left ( \frac{1}{365} \right )\left [ \frac{k.(k-1)}{2} \right ] \geq 1\\ & \Rightarrow k^2 - k - 730 \geq 0\\ & \Rightarrow k = \left \lceil \frac{1+ \sqrt{1+4*730}}{2} \right \rceil = \left \lceil 27.52 \right \rceil = 28 \\ \\ \end{align*}$ I hope there may be other ways to do this problem and there are other variations to this problem as well (a few are in Kenneth Rosen Book). Please help if there exist other methods. Thanks!",,"['probability', 'random-variables', 'birthday']"
25,"Should I pick entirely different numbers on each of the multiple tickets, for the same lottery draw?","Should I pick entirely different numbers on each of the multiple tickets, for the same lottery draw?",,"I was discussing optimal lottery ticket purchasing strategies with a friend, and an interesting question came up. Suppose you: purchase multiple tickets for one and the same draw. select the option to pick the numbers at random for all tickets. It occurred to me that if the numbers are selected at random, then it would be possible - indeed quite likely if you buy several tickets - that the same number(s) may be repeated on multiple tickets. A quick Google confirms what I expected - that the random number selection process for my local lottery is independent for each ticket even when you buy them together and for the same draw, so this would be entirely possible. This had me wondering, does this factor decrease your odds at all? If it does, could one improve upon the process of randomly selecting each ticket independently to improve things? Perhaps this is just a more specific version of the general question - should you avoid repeatedly selecting the same number across multiple tickets on the same draw? The parameters of the draw are: Numbers are 1-59. Six numbers are drawn. Prizes start at three numbers, increasing in size up to all six. Having not studied maths in any depth since my college days, I'm unsure how to frame the problem mathematically, so I'm interested both from a mathematical point of view and practically.","I was discussing optimal lottery ticket purchasing strategies with a friend, and an interesting question came up. Suppose you: purchase multiple tickets for one and the same draw. select the option to pick the numbers at random for all tickets. It occurred to me that if the numbers are selected at random, then it would be possible - indeed quite likely if you buy several tickets - that the same number(s) may be repeated on multiple tickets. A quick Google confirms what I expected - that the random number selection process for my local lottery is independent for each ticket even when you buy them together and for the same draw, so this would be entirely possible. This had me wondering, does this factor decrease your odds at all? If it does, could one improve upon the process of randomly selecting each ticket independently to improve things? Perhaps this is just a more specific version of the general question - should you avoid repeatedly selecting the same number across multiple tickets on the same draw? The parameters of the draw are: Numbers are 1-59. Six numbers are drawn. Prizes start at three numbers, increasing in size up to all six. Having not studied maths in any depth since my college days, I'm unsure how to frame the problem mathematically, so I'm interested both from a mathematical point of view and practically.",,"['probability', 'lotteries']"
26,Upper Bound on Difference of Expected Values of Poisson Binomial Distributions,Upper Bound on Difference of Expected Values of Poisson Binomial Distributions,,"Let $X,Y$ be $2$ Poisson Binomial Distributions supported on $[n] = \{i | i \in \mathbb{Z}, 0\leq i\leq n \}$. Denote by $d(X,Y)$ their total variation distance . I would like to find an upper bound on the absolute value of the difference of their expected values, assuming that $d(X,Y) \leq \epsilon$, where $0<\epsilon<1$. After some experimenting in R it seems that  \begin{equation} |\mathbb{E}[X] - \mathbb{E}[Y]| \leq \epsilon \log n \end{equation} holds with probability at least $9/10$, which maybe means that the correct bound lies in  $\mathcal{O}(\epsilon \log n)$. References to such bounds or ideas on how to prove this bound (or a similar one) would be very helpfull.","Let $X,Y$ be $2$ Poisson Binomial Distributions supported on $[n] = \{i | i \in \mathbb{Z}, 0\leq i\leq n \}$. Denote by $d(X,Y)$ their total variation distance . I would like to find an upper bound on the absolute value of the difference of their expected values, assuming that $d(X,Y) \leq \epsilon$, where $0<\epsilon<1$. After some experimenting in R it seems that  \begin{equation} |\mathbb{E}[X] - \mathbb{E}[Y]| \leq \epsilon \log n \end{equation} holds with probability at least $9/10$, which maybe means that the correct bound lies in  $\mathcal{O}(\epsilon \log n)$. References to such bounds or ideas on how to prove this bound (or a similar one) would be very helpfull.",,"['probability', 'probability-distributions', 'reference-request', 'expectation']"
27,Distribution of the maximum of a large number of normally distributed random variables,Distribution of the maximum of a large number of normally distributed random variables,,"Let $X_i\sim \text{iid}\, \mathcal{N}(\mu,\sigma)$ for $i\in\{1,\dots,n\}$. I am interested in the random variable $Y=\max_i{X_i}$ when $n$ is large. From Extreme value theory it seems that $Y$ would follow a Gumbel distribution but I would like to know the parameters of this distribution as a function of $\mu$ and $\sigma$. Also, would the result holds if $\mu$ and $\sigma$ differ across $i$ or if the $X_i$ are not independent?","Let $X_i\sim \text{iid}\, \mathcal{N}(\mu,\sigma)$ for $i\in\{1,\dots,n\}$. I am interested in the random variable $Y=\max_i{X_i}$ when $n$ is large. From Extreme value theory it seems that $Y$ would follow a Gumbel distribution but I would like to know the parameters of this distribution as a function of $\mu$ and $\sigma$. Also, would the result holds if $\mu$ and $\sigma$ differ across $i$ or if the $X_i$ are not independent?",,"['probability', 'probability-distributions', 'probability-limit-theorems']"
28,Inequality for Binomial Tail Probabilities,Inequality for Binomial Tail Probabilities,,"Let $B(k,n,p)$ be the CDF of a binomial distribution. The following inequality appears to be true from numerical tests. $$B\left(k-1,n,\frac{k-1}{n-1}\right)>B\left(k,n,\frac{k}{n-1}\right)$$ I have looked through the relevant results summarized in section one of Xu, Balakrishnan (2011) to prove the result, but I have not found anything which can be applied easily. Guidance or helpful references are very welcome. Update: I think the following may be helpful. I notice that $B\left(k-1,n,\frac{k-1}{n-1}\right)$ can be expressed as the probability of having no more than $k$ successes among $n+1$ Bernoulli variables where one has $p=1$ and the other have $p=\frac{k-1}{n-1}$. $B\left(k,n,\frac{k}{n-1}\right)$ can be expressed as the probability of having no more than $k$ successes among $n+1$ Bernoulli variables where one has $p=0$ and the other have $p=\frac{k}{n-1}$.","Let $B(k,n,p)$ be the CDF of a binomial distribution. The following inequality appears to be true from numerical tests. $$B\left(k-1,n,\frac{k-1}{n-1}\right)>B\left(k,n,\frac{k}{n-1}\right)$$ I have looked through the relevant results summarized in section one of Xu, Balakrishnan (2011) to prove the result, but I have not found anything which can be applied easily. Guidance or helpful references are very welcome. Update: I think the following may be helpful. I notice that $B\left(k-1,n,\frac{k-1}{n-1}\right)$ can be expressed as the probability of having no more than $k$ successes among $n+1$ Bernoulli variables where one has $p=1$ and the other have $p=\frac{k-1}{n-1}$. $B\left(k,n,\frac{k}{n-1}\right)$ can be expressed as the probability of having no more than $k$ successes among $n+1$ Bernoulli variables where one has $p=0$ and the other have $p=\frac{k}{n-1}$.",,"['probability', 'reference-request', 'binomial-distribution']"
29,Version of Conditional Expectation,Version of Conditional Expectation,,"I would like to proof the following theorem. Let $(X,Y)$ be a random variable with values in $\mathbb{R}^2$. Supposte that $\mathcal{L}(X,Y)$ has density $f(.,.)$ with respect to Lebesgue measure $\lambda^2$ on $\mathbb{R}^2$. If $E[|X|]<\infty$ holds, then $$E[X|Y]=\frac{\int_\mathbb{R}xf(x,Y)dx}{\int_\mathbb{R}f(x,Y)dx}$$ I started like this: Let $A=Y^{-1}(B)$ for $B\in\mathcal{B}(\mathbb{R})$. Then $$ \int_A\frac{\int_\mathbb{R}xf(x,Y)dx}{\int_\mathbb{R}f(x,Y)dx}dP \\=\int_B\frac{\int_\mathbb{R}xf(x,y)dx}{\int_\mathbb{R}f(x,y)dx} P\circ Y^{-1}(dy) \\=\int_B(\frac{\int_\mathbb{R}xf(x,y)dx}{\int_\mathbb{R}f(x,y)dx}\int_\mathbb{R}f(x,y)dx)\ dy \\=\int_B\int_\mathbb{R}xf(x,y)dx\ dy $$ But i am not able to show that the last term is equal to $E[X1_{Y^{-1}(B)}]$.","I would like to proof the following theorem. Let $(X,Y)$ be a random variable with values in $\mathbb{R}^2$. Supposte that $\mathcal{L}(X,Y)$ has density $f(.,.)$ with respect to Lebesgue measure $\lambda^2$ on $\mathbb{R}^2$. If $E[|X|]<\infty$ holds, then $$E[X|Y]=\frac{\int_\mathbb{R}xf(x,Y)dx}{\int_\mathbb{R}f(x,Y)dx}$$ I started like this: Let $A=Y^{-1}(B)$ for $B\in\mathcal{B}(\mathbb{R})$. Then $$ \int_A\frac{\int_\mathbb{R}xf(x,Y)dx}{\int_\mathbb{R}f(x,Y)dx}dP \\=\int_B\frac{\int_\mathbb{R}xf(x,y)dx}{\int_\mathbb{R}f(x,y)dx} P\circ Y^{-1}(dy) \\=\int_B(\frac{\int_\mathbb{R}xf(x,y)dx}{\int_\mathbb{R}f(x,y)dx}\int_\mathbb{R}f(x,y)dx)\ dy \\=\int_B\int_\mathbb{R}xf(x,y)dx\ dy $$ But i am not able to show that the last term is equal to $E[X1_{Y^{-1}(B)}]$.",,"['probability', 'probability-theory', 'statistics', 'conditional-expectation']"
30,"Compute the conditional expectation $E(Y|X)$ for a measurable function $Y$ and a random variable $X$ taking values on $[0,1)$",Compute the conditional expectation  for a measurable function  and a random variable  taking values on,"E(Y|X) Y X [0,1)","Good day, Currently I am working with ""Probability: Theory and Examples"" by Durrett and while getting familiar with conditional expectations I got to this problem: Consider the Lebesgue probability space on the interval $[0,1)$. (I.e. the state space is $Ω = [0, 1)$, the $\sigma$-field is the set of Lebesgue measurable sets and the measure is the Lebesgue measure.) We define the random variable $X$ as:   $$X(w)=\begin{cases} 2w &, 0\leq w < 1/2 \\ 2w−1 &, 1/2\leq w<1 \end{cases}$$   Compute the conditional expectation $E(Y |X)$ where $Y : [0, 1) \to \mathbb{R}$ is a measurable function. First off $Y$ is not defined further. I am a bit confused about the term ""measurable function"". Of what? A measurable function of $X$? But then it would just be $E(Y|X)=Y$. So I assume $Y$ to be a random variable not necessarily independent of $X$. Second let's define conditional expectation: $E(Y|X):=E(Y|\sigma(X))$ is a random variable $Z$ such that $Z$ is measurable w.r.t. $\sigma(X)$ and $E(1_A Y)=E(1_A Z)$ for all $A \in \sigma(X)$. Okay, let's pick a $A \in \sigma(X)$ then there exists a $B \in \mathcal{B}(\mathbb{\mathbb{R}})$ such that $A=X^{-1}(B)$. As Graham Kemp helpfully hinted, the correct inverse of $X$ is $$X^{-1}\{x\}~=~\{w\in[0;1):x=X(w)\}~=~\begin{cases}\{x/2, (1+x)/2\}&:& 0\leq x<1\\ \{\}&:&\text{otherwise}\end{cases}$$ Now I am not sure to do. Normally I would begin from $$E(1_A Y)= \int_A Y dP=\int_B y P_Y(dy)$$ but now I am at my end. Can someone take it from here and show me what to do? I am thankful for every help/hint.","Good day, Currently I am working with ""Probability: Theory and Examples"" by Durrett and while getting familiar with conditional expectations I got to this problem: Consider the Lebesgue probability space on the interval $[0,1)$. (I.e. the state space is $Ω = [0, 1)$, the $\sigma$-field is the set of Lebesgue measurable sets and the measure is the Lebesgue measure.) We define the random variable $X$ as:   $$X(w)=\begin{cases} 2w &, 0\leq w < 1/2 \\ 2w−1 &, 1/2\leq w<1 \end{cases}$$   Compute the conditional expectation $E(Y |X)$ where $Y : [0, 1) \to \mathbb{R}$ is a measurable function. First off $Y$ is not defined further. I am a bit confused about the term ""measurable function"". Of what? A measurable function of $X$? But then it would just be $E(Y|X)=Y$. So I assume $Y$ to be a random variable not necessarily independent of $X$. Second let's define conditional expectation: $E(Y|X):=E(Y|\sigma(X))$ is a random variable $Z$ such that $Z$ is measurable w.r.t. $\sigma(X)$ and $E(1_A Y)=E(1_A Z)$ for all $A \in \sigma(X)$. Okay, let's pick a $A \in \sigma(X)$ then there exists a $B \in \mathcal{B}(\mathbb{\mathbb{R}})$ such that $A=X^{-1}(B)$. As Graham Kemp helpfully hinted, the correct inverse of $X$ is $$X^{-1}\{x\}~=~\{w\in[0;1):x=X(w)\}~=~\begin{cases}\{x/2, (1+x)/2\}&:& 0\leq x<1\\ \{\}&:&\text{otherwise}\end{cases}$$ Now I am not sure to do. Normally I would begin from $$E(1_A Y)= \int_A Y dP=\int_B y P_Y(dy)$$ but now I am at my end. Can someone take it from here and show me what to do? I am thankful for every help/hint.",,"['probability', 'probability-theory', 'random-variables', 'conditional-expectation']"
31,Probability for Fighting Fantasy! What if I have the same skill but more life?,Probability for Fighting Fantasy! What if I have the same skill but more life?,,"so I've been rereading my old fighting fantasy books and I thought of a problem I'm unsure of how to solve. In the book you fight various opponents by rolling two 6 sided dice and adding your skill (just a number), then you roll the dice for them and add their skill. If your total is higher than theirs you take off 2 of their stamina and visa versa if they beat you. You keep fighting rounds until one of you runs out of stamina and dies. Its easy to see the probability of winning an individual round if you have more, less or the same skill as your opponent. But how does having more or less stamina affect the outcome of the entire fight? Obviously having more stamina than your opponent means you will have a better chance of winning but how do you do the sum? If you need any clarification please ask! Thanks","so I've been rereading my old fighting fantasy books and I thought of a problem I'm unsure of how to solve. In the book you fight various opponents by rolling two 6 sided dice and adding your skill (just a number), then you roll the dice for them and add their skill. If your total is higher than theirs you take off 2 of their stamina and visa versa if they beat you. You keep fighting rounds until one of you runs out of stamina and dies. Its easy to see the probability of winning an individual round if you have more, less or the same skill as your opponent. But how does having more or less stamina affect the outcome of the entire fight? Obviously having more stamina than your opponent means you will have a better chance of winning but how do you do the sum? If you need any clarification please ask! Thanks",,['probability']
32,In layman's terms what is the difference between a model and a distribution?,In layman's terms what is the difference between a model and a distribution?,,"The answers (definitions) defined on Wikipedia are arguably a bit cryptic to those unfamiliar with higher mathematics/statistics. I am a high school student very interested in this field as a hobby and am currently struggling with the differences between what is a statistical model and a probability distribution My current, and very rudimentary, understanding is this: statistical models are mathematical attempts to approximate measured distributions (some equation) probability distributions are measured descriptions from experiments that assigns probabilities to each possible outcome of a random event (the actual desired abstract concept itself) confusion is further compounded by the tendency in literature to see the words ""distribution"" and ""model"" used interchangeably - or at least in very similar situations (e.g. binomial distribution vs binomial model) Can someone verify/correct my definitions, and perhaps offer a more formalized (albeit still in terms of simple english) approach to these concepts?","The answers (definitions) defined on Wikipedia are arguably a bit cryptic to those unfamiliar with higher mathematics/statistics. I am a high school student very interested in this field as a hobby and am currently struggling with the differences between what is a statistical model and a probability distribution My current, and very rudimentary, understanding is this: statistical models are mathematical attempts to approximate measured distributions (some equation) probability distributions are measured descriptions from experiments that assigns probabilities to each possible outcome of a random event (the actual desired abstract concept itself) confusion is further compounded by the tendency in literature to see the words ""distribution"" and ""model"" used interchangeably - or at least in very similar situations (e.g. binomial distribution vs binomial model) Can someone verify/correct my definitions, and perhaps offer a more formalized (albeit still in terms of simple english) approach to these concepts?",,"['probability', 'statistics', 'terminology']"
33,"For each pair of events A and B, find P(A|B) and P(B|A).","For each pair of events A and B, find P(A|B) and P(B|A).",,"I've got a simple problem here, but I just want to ensure that I'm not losing a simple concept. Relevant equations: $$P(A|B) = \frac{P(A \cap B)}{P(B)},$$ $$P(A \cap B) = P(A) + P(B) - P(A \cup B)$$ Let $(S,P)$ be a sample space with $S = \{1, 2, 3, 4, 5\}$, and, $P(1) = P(2) = 0.1$ $P(3) = P(4) = 0.2$ $P(5) = 0.4$ For each pair of events $A$ and $B$, find $P(A|B)$ and $P(B|A)$. a. $A = \{1, 2, 3\}$; $B = \{2, 3, 4\}$ b. $A = \{1, 2, 3\}$; $B = \{4, 5\}$ c. $A = \emptyset$; $B = \{2, 3, 4\}$ d. $A = \{1, 2, 3, 4, 5\}; B = \{4, 5\}$ If I am asked to find the probability of one of these sets, do I just add the values together? Is there any instance I would multiply them; such as when I'm finding $P(A \cap B)$ vs. just $P(A)$ or $P(B)$? Do I need to use Inclusion-Exclusion? Here's what I found. a. $P(A|B) = \frac{0.3}{0.5} = \frac{3}{5}$, $P(B|A) = \frac{0.3}{0.4} = \frac{3}{4}$ b. $P(A|B) = 0$, $P(B|A) = 0$ c. $P(A|B) = 0$, $P(B|A) = undefined$ d. $P(A|B) = \frac{0.3}{0.3} = 1$, $P(B|A) = \frac{0.3}{1} = \frac{3}{5}$","I've got a simple problem here, but I just want to ensure that I'm not losing a simple concept. Relevant equations: $$P(A|B) = \frac{P(A \cap B)}{P(B)},$$ $$P(A \cap B) = P(A) + P(B) - P(A \cup B)$$ Let $(S,P)$ be a sample space with $S = \{1, 2, 3, 4, 5\}$, and, $P(1) = P(2) = 0.1$ $P(3) = P(4) = 0.2$ $P(5) = 0.4$ For each pair of events $A$ and $B$, find $P(A|B)$ and $P(B|A)$. a. $A = \{1, 2, 3\}$; $B = \{2, 3, 4\}$ b. $A = \{1, 2, 3\}$; $B = \{4, 5\}$ c. $A = \emptyset$; $B = \{2, 3, 4\}$ d. $A = \{1, 2, 3, 4, 5\}; B = \{4, 5\}$ If I am asked to find the probability of one of these sets, do I just add the values together? Is there any instance I would multiply them; such as when I'm finding $P(A \cap B)$ vs. just $P(A)$ or $P(B)$? Do I need to use Inclusion-Exclusion? Here's what I found. a. $P(A|B) = \frac{0.3}{0.5} = \frac{3}{5}$, $P(B|A) = \frac{0.3}{0.4} = \frac{3}{4}$ b. $P(A|B) = 0$, $P(B|A) = 0$ c. $P(A|B) = 0$, $P(B|A) = undefined$ d. $P(A|B) = \frac{0.3}{0.3} = 1$, $P(B|A) = \frac{0.3}{1} = \frac{3}{5}$",,"['probability', 'discrete-mathematics', 'proof-verification']"
34,Maximum Likelihood of single observation,Maximum Likelihood of single observation,,"I'm stumped on this problem... I keep getting an undefined answer of having to solve -20 = 0. The likelihood function I get is $e^{-20\alpha}$. So I have $y_i=$ $ \begin{cases}        1& w/probability \ p_i \\       0& w/probability \ 1-p_i     \end{cases}$ And $p_i=1-e^{-\alpha x_i}$, i=1,2,... $\alpha>=0$   and $x_i>=0$ If I have a sample of a single observation $(y_1,x_1)=(0,20)$, I am looking for the maximum likelihood of this sample. Thank you for any help :)","I'm stumped on this problem... I keep getting an undefined answer of having to solve -20 = 0. The likelihood function I get is $e^{-20\alpha}$. So I have $y_i=$ $ \begin{cases}        1& w/probability \ p_i \\       0& w/probability \ 1-p_i     \end{cases}$ And $p_i=1-e^{-\alpha x_i}$, i=1,2,... $\alpha>=0$   and $x_i>=0$ If I have a sample of a single observation $(y_1,x_1)=(0,20)$, I am looking for the maximum likelihood of this sample. Thank you for any help :)",,"['probability', 'statistics', 'statistical-inference', 'parameter-estimation', 'maximum-likelihood']"
35,probability question about coins flipping,probability question about coins flipping,,Assume there are $n$ coins in a circle. They show Heads with probability $1/2$ and Tails with probability $1/2$. --Iterative step--- One of the coins that shows Heads is randomly chosen and this coin and its two neighbors (the coin on the right and the one on the left from it) are flipped again. The probability of showing Heads for any coin from now on is $p$. This procedure repeats. We need to find the function of the expected number of iterations to get all Tails in the circle. Can you help me with this? Is there any elegant way to proceed?,Assume there are $n$ coins in a circle. They show Heads with probability $1/2$ and Tails with probability $1/2$. --Iterative step--- One of the coins that shows Heads is randomly chosen and this coin and its two neighbors (the coin on the right and the one on the left from it) are flipped again. The probability of showing Heads for any coin from now on is $p$. This procedure repeats. We need to find the function of the expected number of iterations to get all Tails in the circle. Can you help me with this? Is there any elegant way to proceed?,,"['probability', 'combinatorics']"
36,What is the probability of getting $3$ triples before a single quad in a $52$ card deck?,What is the probability of getting  triples before a single quad in a  card deck?,3 52,"Suppose I have a well shuffled standard deck of $52$ cards.  I draw them one at a time (without replacement) and sort the chosen cards by rank so that it is easy for me to see pairs, triples, quads....  I want to know what is the probability of seeing exactly three triples (such as $5,5,5$, $3,3,3$, $K,K,K$) before seeing a quad (such as $10,10,10,10$).  Note that the triples and quad need not be in any order, they can have other ""irrelevant"" cards drawn in between them. Just to clarify, the triple and quads do not need to be consecutive cards.  For example, if the first $6$ cards drawn are $3,5,6,5,K,5$, then that is a triple for the $5$s. Note that when we either see $3$ triples or one quad, we are done with that hand.  No other cards will be drawn.  So for example, if you have $3,3,3,5,5,7,7,7$ so far (and all the other drawn cards are singles, then another $3$ or $5$ draw will immediately stop the hand but for different reasons.  We will either have quad $3$s at that point or $3$ triples.  A drawn $7$ would also stop this sample hand. A quad winner would be something like $K,K,K,7,7,7,3,3,K$ with any ""irrelevant"" single or double (paired) cards interspersed such as $2,J,9...$. Just for ""extra"" clarity, a quad does NOT also count as a triple.  A triple becomes a quad and loses its triple status if the $4$th card of that same rank is drawn in the same hand. For even more clarity (I didn't know this question would be ambiguous), I am $NOT$ asking for $3$ triples followed by a quad before seeing the $4$th triple.  I am saying all you have to see is $3$ triples without seeing a quad and you can stop that hand and it is counted as a winner.  Sorry for any confusion. I thought it was clearly stated but now that I reread the title it is a little confusing but not if you read the examples it shouldn't be.","Suppose I have a well shuffled standard deck of $52$ cards.  I draw them one at a time (without replacement) and sort the chosen cards by rank so that it is easy for me to see pairs, triples, quads....  I want to know what is the probability of seeing exactly three triples (such as $5,5,5$, $3,3,3$, $K,K,K$) before seeing a quad (such as $10,10,10,10$).  Note that the triples and quad need not be in any order, they can have other ""irrelevant"" cards drawn in between them. Just to clarify, the triple and quads do not need to be consecutive cards.  For example, if the first $6$ cards drawn are $3,5,6,5,K,5$, then that is a triple for the $5$s. Note that when we either see $3$ triples or one quad, we are done with that hand.  No other cards will be drawn.  So for example, if you have $3,3,3,5,5,7,7,7$ so far (and all the other drawn cards are singles, then another $3$ or $5$ draw will immediately stop the hand but for different reasons.  We will either have quad $3$s at that point or $3$ triples.  A drawn $7$ would also stop this sample hand. A quad winner would be something like $K,K,K,7,7,7,3,3,K$ with any ""irrelevant"" single or double (paired) cards interspersed such as $2,J,9...$. Just for ""extra"" clarity, a quad does NOT also count as a triple.  A triple becomes a quad and loses its triple status if the $4$th card of that same rank is drawn in the same hand. For even more clarity (I didn't know this question would be ambiguous), I am $NOT$ asking for $3$ triples followed by a quad before seeing the $4$th triple.  I am saying all you have to see is $3$ triples without seeing a quad and you can stop that hand and it is counted as a winner.  Sorry for any confusion. I thought it was clearly stated but now that I reread the title it is a little confusing but not if you read the examples it shouldn't be.",,['probability']
37,Probability of multiple independent events occurring after repeated attempts,Probability of multiple independent events occurring after repeated attempts,,"Suppose there is a bag of 10 identical octahedrons, one of which is a fair eight-sided die numbered 1-8. Randomly draw the one of the octahedrons out of the bag. If you draw the die, you must roll it. Put the octahedron back into the bag before drawing again. What is the probability of you getting rolls of each number at least once in $n$ tries? I realize this question wasn't very elegantly put, and that's because this was a question I asked myself when I was playing a game. The principle is the same but the question was changed so that game-specific vocabulary don't confuse people. I first tried $(0.1^8) (8!/8^8) \,{_n}C_8$ but then quickly realized my mistake as $n<8$ didn't give $P=0$ and it was also possible for $P$ to be $>1$. After a few more failed attempts and some research I realized that this question might be beyond my current knowledge and that this rabbit hole might be deeper than I initially thought. It is a rather weird question, but I was hoping if I can get some answers here. Edit: It would seem that my question ended up being confusing after all, so let me clarify. The octahedrons are shaped the exact same but only one of them is actually a die. Or really, the point was that every time there's only a 0.1 chance that you get to roll the die.","Suppose there is a bag of 10 identical octahedrons, one of which is a fair eight-sided die numbered 1-8. Randomly draw the one of the octahedrons out of the bag. If you draw the die, you must roll it. Put the octahedron back into the bag before drawing again. What is the probability of you getting rolls of each number at least once in $n$ tries? I realize this question wasn't very elegantly put, and that's because this was a question I asked myself when I was playing a game. The principle is the same but the question was changed so that game-specific vocabulary don't confuse people. I first tried $(0.1^8) (8!/8^8) \,{_n}C_8$ but then quickly realized my mistake as $n<8$ didn't give $P=0$ and it was also possible for $P$ to be $>1$. After a few more failed attempts and some research I realized that this question might be beyond my current knowledge and that this rabbit hole might be deeper than I initially thought. It is a rather weird question, but I was hoping if I can get some answers here. Edit: It would seem that my question ended up being confusing after all, so let me clarify. The octahedrons are shaped the exact same but only one of them is actually a die. Or really, the point was that every time there's only a 0.1 chance that you get to roll the die.",,['probability']
38,Central limit theorem and Poisson distribution,Central limit theorem and Poisson distribution,,"$X$ is the sum of $n$ independent Poisson random variables with parameter 1. Therefore $X$ has a Poisson distribution with parameter $n$. Use the central limit theorem to show that $P(X≤n)→(1/2)$. I was able to prove that $X$ has a Poisson distribution with parameter $n$, but I'm not sure how to use this and the central limit theorem to show the converge of the probability above. Any help/guidance would be wonderdul!","$X$ is the sum of $n$ independent Poisson random variables with parameter 1. Therefore $X$ has a Poisson distribution with parameter $n$. Use the central limit theorem to show that $P(X≤n)→(1/2)$. I was able to prove that $X$ has a Poisson distribution with parameter $n$, but I'm not sure how to use this and the central limit theorem to show the converge of the probability above. Any help/guidance would be wonderdul!",,"['probability', 'probability-theory', 'central-limit-theorem']"
39,Crossing a lane of traffic,Crossing a lane of traffic,,"A pedestrian wishes to cross a single lane of fast-moving tra c. Suppose the number of vehicles that have passed by time t is a Poisson process of rate , and suppose it takes time a to walk across the lane. Assuming that the pedestrian can foresee correctly the times at which vehicles will pass by, Question: 1 how long on average does it take to cross over safely? [Consider the time at which the 1st car passes.] Question 2: How long on average does it take to cross two similar lanes (a) when one must walk straight across (assuming that the pedestrian will not cross if, at any time whilst crossing, a car would pass in either direction), (b) when an island in the middle of the road makes it safe to stop half-way? Attempt: Question 1: It can be calculated by conditioning the first arrival. $E[X]=\int E[X|Y=y]f_Y(y)dy$, where $Y$ is the time of the first traffic. The answer is $(e^{\lambda a}-1)\lambda^{-1}$. Question 2:  a) I think this is two indepedent poisson process each with parameter $\lambda$. Therefore, the sum of the two poisson process = $2\lambda$. So $E[X]=(e^{2\lambda a}-1)(2\lambda)^{-1}$. b)I think the answer is $2*(e^{\lambda a}-1)\lambda^{-1}$","A pedestrian wishes to cross a single lane of fast-moving tra c. Suppose the number of vehicles that have passed by time t is a Poisson process of rate , and suppose it takes time a to walk across the lane. Assuming that the pedestrian can foresee correctly the times at which vehicles will pass by, Question: 1 how long on average does it take to cross over safely? [Consider the time at which the 1st car passes.] Question 2: How long on average does it take to cross two similar lanes (a) when one must walk straight across (assuming that the pedestrian will not cross if, at any time whilst crossing, a car would pass in either direction), (b) when an island in the middle of the road makes it safe to stop half-way? Attempt: Question 1: It can be calculated by conditioning the first arrival. $E[X]=\int E[X|Y=y]f_Y(y)dy$, where $Y$ is the time of the first traffic. The answer is $(e^{\lambda a}-1)\lambda^{-1}$. Question 2:  a) I think this is two indepedent poisson process each with parameter $\lambda$. Therefore, the sum of the two poisson process = $2\lambda$. So $E[X]=(e^{2\lambda a}-1)(2\lambda)^{-1}$. b)I think the answer is $2*(e^{\lambda a}-1)\lambda^{-1}$",,"['probability', 'probability-theory', 'random-variables', 'poisson-process']"
40,Find the conditional probability of 6 appearing exactly once in $3$ rolls of a die given that it appeared at least once.,Find the conditional probability of 6 appearing exactly once in  rolls of a die given that it appeared at least once.,3,"Did I find the correct probability? A fair die is rolled $3$ times. The conditional probability of 6 appearing exactly once, given that it appeared at least once. So,the combined probability that 6 appeared exactly once and it appeared at least once is $$3\left(\frac{1}{6}\right)\left(\frac{5}{6}\right)^{2}$$ since, the case is that the 6 appears only once in the $3$ throws and it can appear at any throw: 1, 2 or 3. And the probability that 6 appeared at least once is $$1-\left(\frac{5}{6}\right)^3$$ So the required probability is $$\frac{3\left(\frac{1}{6}\right)\left(\frac{5}{6}\right)^{2}}{1-\left(\frac{5}{6}\right)^3}$$ P.S.I don't have anything to check the answer, so I posted it here to verify. Please don't mind.","Did I find the correct probability? A fair die is rolled $3$ times. The conditional probability of 6 appearing exactly once, given that it appeared at least once. So,the combined probability that 6 appeared exactly once and it appeared at least once is $$3\left(\frac{1}{6}\right)\left(\frac{5}{6}\right)^{2}$$ since, the case is that the 6 appears only once in the $3$ throws and it can appear at any throw: 1, 2 or 3. And the probability that 6 appeared at least once is $$1-\left(\frac{5}{6}\right)^3$$ So the required probability is $$\frac{3\left(\frac{1}{6}\right)\left(\frac{5}{6}\right)^{2}}{1-\left(\frac{5}{6}\right)^3}$$ P.S.I don't have anything to check the answer, so I posted it here to verify. Please don't mind.",,['probability']
41,"All Cdfs have a uniform distribution on [0, 1]?","All Cdfs have a uniform distribution on [0, 1]?",,"Consider the following proposition Proposition C Let $Z = F(X)$ ; where $F$ is the continuous cumulative distribution function of the random variable X, then $Z$ has a uniform distribution on $[0, 1]$ . Proof $$P(Z \leq z) = P(F(X) \leq z) = P(X \leq F^{-1}(z)) = F(F^{-1}(z)) = z$$ This is the uniform cdf. I can follow the proof above, but my interpretation of its meaning isn't making sense to me. This proof seems to imply that the cdf of any random variable has a uniform distribution. Is this correct? Is there an intuitive explanation for why this is? For example, consider the graph of the cdf of some normal distributions from wikipedia How would you map the ideas of this proposition to the graph of the cdf above?","Consider the following proposition Proposition C Let ; where is the continuous cumulative distribution function of the random variable X, then has a uniform distribution on . Proof This is the uniform cdf. I can follow the proof above, but my interpretation of its meaning isn't making sense to me. This proof seems to imply that the cdf of any random variable has a uniform distribution. Is this correct? Is there an intuitive explanation for why this is? For example, consider the graph of the cdf of some normal distributions from wikipedia How would you map the ideas of this proposition to the graph of the cdf above?","Z = F(X) F Z [0, 1] P(Z \leq z) = P(F(X) \leq z) = P(X \leq F^{-1}(z)) = F(F^{-1}(z)) = z","['probability', 'probability-distributions', 'uniform-distribution']"
42,What assumptions did I make when I strengthened my independence criterion across a new random variable?,What assumptions did I make when I strengthened my independence criterion across a new random variable?,,"I have an algorithm which tries to calculate some $\operatorname{Pr(X | Y_1 Y_2 \dots )}$ (where juxtaposition means event intersection, ""given $Y_1$ and $Y_2$ and ... have happened"".) We have some control over the events $Y_1, Y_2, \dots$ that we measure, and we choose them to make the $Y_i$ largely independent. The algorithm works by recursion on the $Y_i.$ The problem is, I made an assumption about the recursively-applied formula and it is not obviously equivalent to independence of the $Y_i$, so I would like to know how bad I've shot myself in the foot. So for the recursion we define $N = Y_k$ and $O = Y_1 \dots Y_{k-1}$ (mnemonic: ""new fact"" and ""old evidence"" respectively) -- then some repeated application of Bayes' theorem proves that you can essentially tack on an extra $|O$ to every term in the normal Bayes Theorem $\operatorname{Pr}(X|N) =  \operatorname{Pr}(N|X) / \operatorname{Pr}(N)$ to get $$\operatorname{Pr}(X|NO) = \frac{\operatorname{Pr}(N|XO)}{\operatorname{Pr}(N|O)}\cdot \operatorname{Pr}(X|O).$$So the rightmost term will recurse down the $Y_i$; the denominator term is easily simplified on the assumption that the $Y_i$ are independent so that $\operatorname{Pr}(N | O) \approx \operatorname{Pr}(Y_k).$ Here's the problem: in my derivation I assumed that you could naively do the same to the numerator simultaneously, essentially adjoining an $|X$ to the expression $\operatorname{Pr}(N|O) \approx \operatorname{Pr}(N)$ to get $\operatorname{Pr}(N|XO) \approx \operatorname{Pr}(N|X).$ This sounds intuitively plausible, because we want to say ""all of the old events don't tell us anything about the new event because they're all independent"" -- but when this $X$ gets in the way the algebra seems to not simplify out the way that the earlier algebra did. Even worse, one of the results I derived trying to examine this looks unexpectedly symmetric:$$\operatorname{Pr}(X~N~O) = \frac{\operatorname{Pr}(X~O)~\operatorname{Pr}(X~N)~\operatorname{Pr}(N~O)}{\operatorname{Pr}(X)~\operatorname{Pr}(N)~\operatorname{Pr}(O)},$$ where here (as above) juxtaposition means event-intersection (i.e. ""the probability of all of these together"" / ""given all of these together""). This scares me somewhat: symmetries in such random variables would seem to indicate that we are in some sort of deeply unusual situation, and the resulting formulas stemming from this approximation are then likely total bunk in the real world! So I need insight on any of the following mostly-equivalent questions: How safe is $\operatorname{Pr}(N|XO) \approx \operatorname{Pr}(N|X)$ when you are already trying to control $N$ to ensure that $\operatorname{Pr}(N | O) \approx \operatorname{Pr}(N)$? Is there a nice interpretation of the above symmetric formula? Does this somehow force any really bad results like $\operatorname{Pr}(X|NO) = \operatorname{Pr}(X)$ when you follow the logic out? There would be other results that might help too, like if $\operatorname{Pr}(N|XO)$ could be phrased as some monotonic function $f\big(\operatorname{Pr}(N|X), \operatorname{Pr(N)}, \operatorname{Pr(O)}\big),$ that might be sufficient to say ""these are in a one-to-one relationship with the true probability, I just don't know what that relationship is"" and save the system.","I have an algorithm which tries to calculate some $\operatorname{Pr(X | Y_1 Y_2 \dots )}$ (where juxtaposition means event intersection, ""given $Y_1$ and $Y_2$ and ... have happened"".) We have some control over the events $Y_1, Y_2, \dots$ that we measure, and we choose them to make the $Y_i$ largely independent. The algorithm works by recursion on the $Y_i.$ The problem is, I made an assumption about the recursively-applied formula and it is not obviously equivalent to independence of the $Y_i$, so I would like to know how bad I've shot myself in the foot. So for the recursion we define $N = Y_k$ and $O = Y_1 \dots Y_{k-1}$ (mnemonic: ""new fact"" and ""old evidence"" respectively) -- then some repeated application of Bayes' theorem proves that you can essentially tack on an extra $|O$ to every term in the normal Bayes Theorem $\operatorname{Pr}(X|N) =  \operatorname{Pr}(N|X) / \operatorname{Pr}(N)$ to get $$\operatorname{Pr}(X|NO) = \frac{\operatorname{Pr}(N|XO)}{\operatorname{Pr}(N|O)}\cdot \operatorname{Pr}(X|O).$$So the rightmost term will recurse down the $Y_i$; the denominator term is easily simplified on the assumption that the $Y_i$ are independent so that $\operatorname{Pr}(N | O) \approx \operatorname{Pr}(Y_k).$ Here's the problem: in my derivation I assumed that you could naively do the same to the numerator simultaneously, essentially adjoining an $|X$ to the expression $\operatorname{Pr}(N|O) \approx \operatorname{Pr}(N)$ to get $\operatorname{Pr}(N|XO) \approx \operatorname{Pr}(N|X).$ This sounds intuitively plausible, because we want to say ""all of the old events don't tell us anything about the new event because they're all independent"" -- but when this $X$ gets in the way the algebra seems to not simplify out the way that the earlier algebra did. Even worse, one of the results I derived trying to examine this looks unexpectedly symmetric:$$\operatorname{Pr}(X~N~O) = \frac{\operatorname{Pr}(X~O)~\operatorname{Pr}(X~N)~\operatorname{Pr}(N~O)}{\operatorname{Pr}(X)~\operatorname{Pr}(N)~\operatorname{Pr}(O)},$$ where here (as above) juxtaposition means event-intersection (i.e. ""the probability of all of these together"" / ""given all of these together""). This scares me somewhat: symmetries in such random variables would seem to indicate that we are in some sort of deeply unusual situation, and the resulting formulas stemming from this approximation are then likely total bunk in the real world! So I need insight on any of the following mostly-equivalent questions: How safe is $\operatorname{Pr}(N|XO) \approx \operatorname{Pr}(N|X)$ when you are already trying to control $N$ to ensure that $\operatorname{Pr}(N | O) \approx \operatorname{Pr}(N)$? Is there a nice interpretation of the above symmetric formula? Does this somehow force any really bad results like $\operatorname{Pr}(X|NO) = \operatorname{Pr}(X)$ when you follow the logic out? There would be other results that might help too, like if $\operatorname{Pr}(N|XO)$ could be phrased as some monotonic function $f\big(\operatorname{Pr}(N|X), \operatorname{Pr(N)}, \operatorname{Pr(O)}\big),$ that might be sufficient to say ""these are in a one-to-one relationship with the true probability, I just don't know what that relationship is"" and save the system.",,"['probability', 'random-variables', 'bayesian', 'independence', 'naive-bayes']"
43,"What are general sets of conditions in which the inequality, $E\left(\frac{X}{Y}\right) \geq 1$ holds for positive r.v.'s $X$ and $Y$?","What are general sets of conditions in which the inequality,  holds for positive r.v.'s  and ?",E\left(\frac{X}{Y}\right) \geq 1 X Y,"I am currently trying to determine what sorts of general conditions will allow the inequality, $E\left(\frac{X}{Y}\right) \geq 1$ to hold for positive r.v.'s $X$ and $Y$. One condition is to let $X$ and $Y$ be exchangeable, that is, the joint distribution of $(X,Y)$ is the same as the joint distribution of $(Y,X)$. However, I read in a book that an even more general condition than exchangeability holds. The hint given was to determine a concave function and to use Jensen's Inequality. One idea I had was to define the function $g(x,y) = \frac{x}{y}$. If this function is convex, then we have that: $$E\left(g(X,Y)\right) = E\left(\frac{X}{Y}\right) \geq g(E(X,Y)) = g(E(X), E(Y)) \geq \frac{E(X)}{E(Y)}$$ which then implies that the condition is the the means are equal. However, $g(x,y) = \frac{x}{y}$ is not convex and I am not able to think of another example that works. Would anyone have any ideas on whether I am approaching this problem correctly?","I am currently trying to determine what sorts of general conditions will allow the inequality, $E\left(\frac{X}{Y}\right) \geq 1$ to hold for positive r.v.'s $X$ and $Y$. One condition is to let $X$ and $Y$ be exchangeable, that is, the joint distribution of $(X,Y)$ is the same as the joint distribution of $(Y,X)$. However, I read in a book that an even more general condition than exchangeability holds. The hint given was to determine a concave function and to use Jensen's Inequality. One idea I had was to define the function $g(x,y) = \frac{x}{y}$. If this function is convex, then we have that: $$E\left(g(X,Y)\right) = E\left(\frac{X}{Y}\right) \geq g(E(X,Y)) = g(E(X), E(Y)) \geq \frac{E(X)}{E(Y)}$$ which then implies that the condition is the the means are equal. However, $g(x,y) = \frac{x}{y}$ is not convex and I am not able to think of another example that works. Would anyone have any ideas on whether I am approaching this problem correctly?",,"['probability', 'statistics', 'inequality', 'random-variables', 'expectation']"
44,"Solving $X+Y\stackrel{d}{=}2Y$ with $X$ uniform on $[-1,1]$",Solving  with  uniform on,"X+Y\stackrel{d}{=}2Y X [-1,1]","I have problems with the following question: Let $X$ be the random variable such that $X\sim U[-1,1]$. Does there exist a random variable $Y$, independent to $X$, such that $X+Y\sim 2Y$? I thought that uniqueness of characteristic function would help. So, we ask if there exists a variable Y with characteristic function $\phi(t)$, such that $\frac{\sin(t)}{t}\phi(t)=\phi(2t)$.  (And, of course $\phi(0)=1)$ I would be thankful for help. Edit : Proof by contradiction. I will show that zeros of $\phi$ have $0$ as their accumulation point: Notice that if $t\in(-\pi,\pi)$ we have: if $\phi(2t)=0$ then $\phi(t)=0 (*) $. We just have to know if there exists any zero of $\phi$ in $(-\pi,\pi)$. $\phi(\pi)=\frac{2}{\pi}\phi(\frac{\pi}{2})$ and $\phi(-\pi)=\frac{-2}{\pi}\phi(\frac{-\pi}{2})$. So if $\phi(\frac{\pi}{2})\neq0$ and $\phi(-\frac{\pi}{2})\neq0$, then either $\phi(\pi)$ and $\phi(-\pi)$ or $\phi(\frac{\pi}{2})$ and $\phi(-\frac{\pi}{2})$ have opposite signs, so there exists zero of $\phi$ in $(-\pi,\pi)$. We know that $\phi(0)=1$, hence from $(*)$ there is a sequence of zeros of $\phi$ which converges to 0. Then, because $\phi$ is continuous $\phi(0)=0$. Is it correct?","I have problems with the following question: Let $X$ be the random variable such that $X\sim U[-1,1]$. Does there exist a random variable $Y$, independent to $X$, such that $X+Y\sim 2Y$? I thought that uniqueness of characteristic function would help. So, we ask if there exists a variable Y with characteristic function $\phi(t)$, such that $\frac{\sin(t)}{t}\phi(t)=\phi(2t)$.  (And, of course $\phi(0)=1)$ I would be thankful for help. Edit : Proof by contradiction. I will show that zeros of $\phi$ have $0$ as their accumulation point: Notice that if $t\in(-\pi,\pi)$ we have: if $\phi(2t)=0$ then $\phi(t)=0 (*) $. We just have to know if there exists any zero of $\phi$ in $(-\pi,\pi)$. $\phi(\pi)=\frac{2}{\pi}\phi(\frac{\pi}{2})$ and $\phi(-\pi)=\frac{-2}{\pi}\phi(\frac{-\pi}{2})$. So if $\phi(\frac{\pi}{2})\neq0$ and $\phi(-\frac{\pi}{2})\neq0$, then either $\phi(\pi)$ and $\phi(-\pi)$ or $\phi(\frac{\pi}{2})$ and $\phi(-\frac{\pi}{2})$ have opposite signs, so there exists zero of $\phi$ in $(-\pi,\pi)$. We know that $\phi(0)=1$, hence from $(*)$ there is a sequence of zeros of $\phi$ which converges to 0. Then, because $\phi$ is continuous $\phi(0)=0$. Is it correct?",,"['probability', 'random-variables', 'characteristic-functions', 'independence']"
45,"If X is uniformly distributed over $(-1, 1)$, find $P(|X| \gt \frac12)$","If X is uniformly distributed over , find","(-1, 1) P(|X| \gt \frac12)","If X is uniformly distributed over $(-1, 1)$, find $P(|X| \gt \frac12 )$ I know what the pdf looks like, it is $0$ when $x \gt 1$ and $x \lt -1$, and when $-1 \lt x \lt 1$ it is a constant $\frac12$. if the question was asking for $P(X \gt \frac12)$ I would do $\int_\frac12^1 \frac12 dx$ and get the answer $\frac14$, but because there is an absolute value around the X in the question I don't know what to do? Do I have to calculate two integrals and add them? $\int_\frac12^1 \frac12 dx$ and $\int_{-1}^{-\frac12} \frac12 dx$?","If X is uniformly distributed over $(-1, 1)$, find $P(|X| \gt \frac12 )$ I know what the pdf looks like, it is $0$ when $x \gt 1$ and $x \lt -1$, and when $-1 \lt x \lt 1$ it is a constant $\frac12$. if the question was asking for $P(X \gt \frac12)$ I would do $\int_\frac12^1 \frac12 dx$ and get the answer $\frac14$, but because there is an absolute value around the X in the question I don't know what to do? Do I have to calculate two integrals and add them? $\int_\frac12^1 \frac12 dx$ and $\int_{-1}^{-\frac12} \frac12 dx$?",,"['probability', 'random-variables']"
46,Soundness and Completeness of the d-separation,Soundness and Completeness of the d-separation,,"I was reading Koller's book on Probabilistic Graphical Models and was wondering how to prove soundness and completeness of the d-separation ? Let me explain what is d-separation and it's properties soundness and completeness which needs to be proved in order to prove d-separation. d-separation has been based on intuitions regarding flow of influence in Bayesian Networks (BN). In other words there is no grantee that d-separation is ""correct."" Perhaps there is a distribution over the BN where X can influence Y despite the fact that all trails between them are blocked. Hence, the first property we want to ensure for d-separation as a method for determining independence is soundness : if we find that two nodes X and Y are d-separated given some Z, then we are guaranteed that they are, in fact, conditionally independent given Z. Theorem : If a distribution P factorizes according to G, then I(G) ⊆ I(P). In other words, any independence reported by d-separation is satisfied by the underlying distribution. A second desirable property is the complementary one — completeness : d-separation detects all possible independencies.  More precisely, if we have that two variables X and Y are independent given Z, then they are d-separated. A careful examination of the completeness property reveals that it is ill defined, inasmuch as it does not specify the distribution in which X and Y are independent. To formalize this property, we first define the following notion: A distribution P is faithful to G if, whenever (X ⊥ Y | Z) ∈ I(P), then d-sepG(X; Y | Z). In other words, any independence in P is reflected in the d-separation properties of the graph. We can now provide one candidate formalization of the completeness property is as follows: For any distribution P that factorizes over G, we have that P is faithful to G; that is, if X and Y are not d-separated given Z in G, then X and Y are dependent in all distributions P that factorize over G. Thank you.","I was reading Koller's book on Probabilistic Graphical Models and was wondering how to prove soundness and completeness of the d-separation ? Let me explain what is d-separation and it's properties soundness and completeness which needs to be proved in order to prove d-separation. d-separation has been based on intuitions regarding flow of influence in Bayesian Networks (BN). In other words there is no grantee that d-separation is ""correct."" Perhaps there is a distribution over the BN where X can influence Y despite the fact that all trails between them are blocked. Hence, the first property we want to ensure for d-separation as a method for determining independence is soundness : if we find that two nodes X and Y are d-separated given some Z, then we are guaranteed that they are, in fact, conditionally independent given Z. Theorem : If a distribution P factorizes according to G, then I(G) ⊆ I(P). In other words, any independence reported by d-separation is satisfied by the underlying distribution. A second desirable property is the complementary one — completeness : d-separation detects all possible independencies.  More precisely, if we have that two variables X and Y are independent given Z, then they are d-separated. A careful examination of the completeness property reveals that it is ill defined, inasmuch as it does not specify the distribution in which X and Y are independent. To formalize this property, we first define the following notion: A distribution P is faithful to G if, whenever (X ⊥ Y | Z) ∈ I(P), then d-sepG(X; Y | Z). In other words, any independence in P is reflected in the d-separation properties of the graph. We can now provide one candidate formalization of the completeness property is as follows: For any distribution P that factorizes over G, we have that P is faithful to G; that is, if X and Y are not d-separated given Z in G, then X and Y are dependent in all distributions P that factorize over G. Thank you.",,"['probability', 'graph-theory', 'bayesian-network']"
47,Set of n dice are thrown...,Set of n dice are thrown...,,"I need help with this question: A set of n dice is thrown. All those that land on six are put aside and the others are again thrown. This is repeated until all the dice have landed on six. Let N denote the number of throws needed. Let $m_{n} = E[N]$. Let $X_{i}$ denote the number of dice rolled on the ith throw. Find $E[\sum_ {i=1}^{N} X_{i}]$. Here is a solution I was provided with but do not understand the reasoning behind it: $E[X_{i}] = E[E[X_{i}|X_{i-1}]] = E[X_{i-1} - (X_{i-1}*(1/6))] = (5/6)*E[X_{i-1}] = n(5/6)^{i-1}$ Then, $E[\sum_ {i=1}^{N} X_{i}] = \sum_ {k=1}^{n} ([1-(5/6)^{k}]/(1/6))(k)P(N=k)]$. Where, $P(N=1)=(5/6)^{n}$ and $P(N=2) = \sum_ {X=0}^{n-1} \binom {n}{x} (1/6)^{n} (25/36)^{n-x} = (31/36)^{n} - (1/6)^{n}$. Could someone please explain this too me? I appreciate any help. Thanks","I need help with this question: A set of n dice is thrown. All those that land on six are put aside and the others are again thrown. This is repeated until all the dice have landed on six. Let N denote the number of throws needed. Let $m_{n} = E[N]$. Let $X_{i}$ denote the number of dice rolled on the ith throw. Find $E[\sum_ {i=1}^{N} X_{i}]$. Here is a solution I was provided with but do not understand the reasoning behind it: $E[X_{i}] = E[E[X_{i}|X_{i-1}]] = E[X_{i-1} - (X_{i-1}*(1/6))] = (5/6)*E[X_{i-1}] = n(5/6)^{i-1}$ Then, $E[\sum_ {i=1}^{N} X_{i}] = \sum_ {k=1}^{n} ([1-(5/6)^{k}]/(1/6))(k)P(N=k)]$. Where, $P(N=1)=(5/6)^{n}$ and $P(N=2) = \sum_ {X=0}^{n-1} \binom {n}{x} (1/6)^{n} (25/36)^{n-x} = (31/36)^{n} - (1/6)^{n}$. Could someone please explain this too me? I appreciate any help. Thanks",,"['probability', 'probability-theory', 'dice', 'conditional-expectation']"
48,Monty Hall problem again (from Grimmett and Stirzaker),Monty Hall problem again (from Grimmett and Stirzaker),,"Grimmett and Stirzaker Exercise 1.4.5.2 In a game show you have to choose one of three doors. One conceals a car, 2 conceal goats. You choose a door but the door is not opened immediately. Instead the presenter opens another door, which reveals a goat. He offers you the opportunity to change your choice to the third door (unopened and so far unchosen ). Let $p$ be the conditional probability that the third door conceals the car. The presenter's protocol is: (i) he is determined to show you a goat; with a choice of two, he picks one at random. Show that $p=2/3$ (ii)he is determined to show you a goat; with a choice of two goats (Billy and Nan), he shows Billy with probability b. Show that $p=\frac{1}{1+b}$ (iii) he opens a door at random irrespective of what is behind. Show that $p=1/2$ I understand (i) but not (ii). For (i) my answer is: Label the doors D1,D2,D3, the car C, the goats G1 and G2, a goat G then $P(D3=C|D2=G)=\frac {P(D3=C \  \cap\ D2=G)} {P(D2=G)}=\frac{P(D3=C\ \cap D2=G | D1=C)  P(D1=C) + P(D3=C\ \cap\ D2=G | D1 \neq C) P(D1 \neq C) }{P(D2=G |D1=C)P(D1=C)+P(D2=G|D1 \neq C)P(D1\neq C)}=\frac{0*{1\over3}+1 * {2\over3}}{1*{1\over3}+1*{2\over3}}={2\over3}$ however similarly for (ii) my answer would be (calling Billy G1): $P(D3=C|D2=G1)=\frac {P(D3=C \  \cap \ D2=G1)} {P(D2=G1)}=\frac{P(D3=C\ \cap D2=G1 | D1=C)  P(D1=C) + P(D3=C \ \cap D2=G1 | D1 \neq C) P(D1 \neq C) }{P(D2=G1 |D1=C)P(D1=C)+P(D2=G1|D1 \neq C)P(D1\neq C)}=\frac{0*{1\over3}+{1\over2}*{2\over3}}{b*{1\over3}+1*{2\over3}}=\frac{1}{b+2}$ where is my mistake ? [Note: this question has undergone some changes in wording over successive editions of the book, in an attempt at clarifying the problem statement, as seen in the comments below. I attempted to answer what I believe was the problem intended by the authors.]","Grimmett and Stirzaker Exercise 1.4.5.2 In a game show you have to choose one of three doors. One conceals a car, 2 conceal goats. You choose a door but the door is not opened immediately. Instead the presenter opens another door, which reveals a goat. He offers you the opportunity to change your choice to the third door (unopened and so far unchosen ). Let be the conditional probability that the third door conceals the car. The presenter's protocol is: (i) he is determined to show you a goat; with a choice of two, he picks one at random. Show that (ii)he is determined to show you a goat; with a choice of two goats (Billy and Nan), he shows Billy with probability b. Show that (iii) he opens a door at random irrespective of what is behind. Show that I understand (i) but not (ii). For (i) my answer is: Label the doors D1,D2,D3, the car C, the goats G1 and G2, a goat G then however similarly for (ii) my answer would be (calling Billy G1): where is my mistake ? [Note: this question has undergone some changes in wording over successive editions of the book, in an attempt at clarifying the problem statement, as seen in the comments below. I attempted to answer what I believe was the problem intended by the authors.]",p p=2/3 p=\frac{1}{1+b} p=1/2 P(D3=C|D2=G)=\frac {P(D3=C \  \cap\ D2=G)} {P(D2=G)}=\frac{P(D3=C\ \cap D2=G | D1=C)  P(D1=C) + P(D3=C\ \cap\ D2=G | D1 \neq C) P(D1 \neq C) }{P(D2=G |D1=C)P(D1=C)+P(D2=G|D1 \neq C)P(D1\neq C)}=\frac{0*{1\over3}+1 * {2\over3}}{1*{1\over3}+1*{2\over3}}={2\over3} P(D3=C|D2=G1)=\frac {P(D3=C \  \cap \ D2=G1)} {P(D2=G1)}=\frac{P(D3=C\ \cap D2=G1 | D1=C)  P(D1=C) + P(D3=C \ \cap D2=G1 | D1 \neq C) P(D1 \neq C) }{P(D2=G1 |D1=C)P(D1=C)+P(D2=G1|D1 \neq C)P(D1\neq C)}=\frac{0*{1\over3}+{1\over2}*{2\over3}}{b*{1\over3}+1*{2\over3}}=\frac{1}{b+2},"['probability', 'probability-theory', 'recreational-mathematics', 'monty-hall']"
49,Expected norm of a random Gaussian vector,Expected norm of a random Gaussian vector,,"Let $X$ be a random vector in $\mathbb{R}^n$ whose entries are joint Gaussian with zero mean and covariance matrix $K.$ Is there a closed form expression for $\mathbb{E}||X||_2,$ as there is for the absolute deviation of a standard Gaussian in a 1-dimensional space?","Let $X$ be a random vector in $\mathbb{R}^n$ whose entries are joint Gaussian with zero mean and covariance matrix $K.$ Is there a closed form expression for $\mathbb{E}||X||_2,$ as there is for the absolute deviation of a standard Gaussian in a 1-dimensional space?",,['probability']
50,Using Ito theory to decide whether $M^f$ is martingale or a local martingale,Using Ito theory to decide whether  is martingale or a local martingale,M^f,"I came across the following while reading Ikeda & Watanabe book Stochastic differential equations and Diffusion processes , in page 163-164 At first the sentence  $$f(X_t)- f(X_0) - \int_0^t Af(s,X)\, ds \in \mathcal{M}^{c,loc}_2 $$ seems strange, since $f \in C^2_b$ implies that $f, \partial_i f, \partial_i \partial_j f $  are bounded functions, so in principle the local martingale must be bounded (for each $t$) wich gives us that it is a true martingale and we should have $$f(X_t)- f(X_0) - \int_0^t Af(s,X)\, ds \in \mathcal{M}^{c}_2 $$ But then, on second thought, we don't know if the terms $\alpha^i_k(s,X)$ are bounded so we must recognize that the first sentence was true. Now when we move to  the other expression, we read that (after correcting some typos) $$M^{(l)}_i(t) = X^i(t\wedge \sigma_l) - X^i(0) - \int_0^{t \wedge \sigma_l} \beta^i(s,X)\, ds \in \mathcal{M}^c_2$$ But the only thing we know is that $X_{s \wedge \sigma_l}$  is on a bounded set, the functions $\alpha^i_k(s,X), \beta^i(s,X)$ might still be unbounded. So it seems that  $$M^{(l)}_i(t) = X^i(t\wedge \sigma_l) - X^i(0) - \int_0^{t \wedge \sigma_l} \beta^i(s,X)\, ds \in \mathcal{M}^{c,loc}_2$$ What is going wrong?","I came across the following while reading Ikeda & Watanabe book Stochastic differential equations and Diffusion processes , in page 163-164 At first the sentence  $$f(X_t)- f(X_0) - \int_0^t Af(s,X)\, ds \in \mathcal{M}^{c,loc}_2 $$ seems strange, since $f \in C^2_b$ implies that $f, \partial_i f, \partial_i \partial_j f $  are bounded functions, so in principle the local martingale must be bounded (for each $t$) wich gives us that it is a true martingale and we should have $$f(X_t)- f(X_0) - \int_0^t Af(s,X)\, ds \in \mathcal{M}^{c}_2 $$ But then, on second thought, we don't know if the terms $\alpha^i_k(s,X)$ are bounded so we must recognize that the first sentence was true. Now when we move to  the other expression, we read that (after correcting some typos) $$M^{(l)}_i(t) = X^i(t\wedge \sigma_l) - X^i(0) - \int_0^{t \wedge \sigma_l} \beta^i(s,X)\, ds \in \mathcal{M}^c_2$$ But the only thing we know is that $X_{s \wedge \sigma_l}$  is on a bounded set, the functions $\alpha^i_k(s,X), \beta^i(s,X)$ might still be unbounded. So it seems that  $$M^{(l)}_i(t) = X^i(t\wedge \sigma_l) - X^i(0) - \int_0^{t \wedge \sigma_l} \beta^i(s,X)\, ds \in \mathcal{M}^{c,loc}_2$$ What is going wrong?",,"['martingales', 'stochastic-integrals', 'stochastic-differential-equations', 'probability']"
51,How biased is this biased coin,How biased is this biased coin,,"Suppose that we have a coin that we suspect is biased, but that we don't know precisely how biased it is: all we know is that its probability p of landing heads is some fixed value between .4 and .6, inclusive. We flip the coin 100 times, and it lands heads 70 times. I'm curious how to find the probability that .4 ≤ p ≤ .55. My approach was to find $$\frac{\int_{.4}^{.55}\binom{100}{70}p^{70}(1-p)^{30} dp}{\int_{.4}^{.6}\binom{100}{70}p^{70}(1-p)^{30} dp} ≈ .057$$ but this seems too simplistic. Where am I going wrong? EDIT: Apologies, I meant to say that p is uniformly distributed on [.4, .6], though I'm now curious how we would solve if we knew that p is normally distributed on [.4, .6].","Suppose that we have a coin that we suspect is biased, but that we don't know precisely how biased it is: all we know is that its probability p of landing heads is some fixed value between .4 and .6, inclusive. We flip the coin 100 times, and it lands heads 70 times. I'm curious how to find the probability that .4 ≤ p ≤ .55. My approach was to find $$\frac{\int_{.4}^{.55}\binom{100}{70}p^{70}(1-p)^{30} dp}{\int_{.4}^{.6}\binom{100}{70}p^{70}(1-p)^{30} dp} ≈ .057$$ but this seems too simplistic. Where am I going wrong? EDIT: Apologies, I meant to say that p is uniformly distributed on [.4, .6], though I'm now curious how we would solve if we knew that p is normally distributed on [.4, .6].",,['probability']
52,Reversing results for sums of independent variables,Reversing results for sums of independent variables,,"Please let me use a specific example to illustrate the general title above. (1) It is well known that if $X$ and $Y$ are independent and $X,Y\sim N(0,1)$ then $$ Z\equiv X^2+Y^2\sim\chi_2^2 $$ where $\chi_n^2$ denotes the $\chi^2$ distribution with $n\in\mathbb{R}_{++}$ degrees of freedom which is defined via its PDF (or, equivalently, CDF, MGF, etc.) without any mentioning of the normal distributions. I'd like to say something like: (2) If $Z\sim\chi_2^2$, then $\exists X,Y$ independent, $X,Y\sim N(0,1)$ such that $Z=X^2+Y^2$. Are there some general techniques that lead from (1) to (2)? If not, are there some specific techniques that are applicable for this particular case? Thank you.","Please let me use a specific example to illustrate the general title above. (1) It is well known that if $X$ and $Y$ are independent and $X,Y\sim N(0,1)$ then $$ Z\equiv X^2+Y^2\sim\chi_2^2 $$ where $\chi_n^2$ denotes the $\chi^2$ distribution with $n\in\mathbb{R}_{++}$ degrees of freedom which is defined via its PDF (or, equivalently, CDF, MGF, etc.) without any mentioning of the normal distributions. I'd like to say something like: (2) If $Z\sim\chi_2^2$, then $\exists X,Y$ independent, $X,Y\sim N(0,1)$ such that $Z=X^2+Y^2$. Are there some general techniques that lead from (1) to (2)? If not, are there some specific techniques that are applicable for this particular case? Thank you.",,"['probability', 'probability-theory', 'statistics', 'normal-distribution', 'convolution']"
53,"What is the probability of winning a best of $1, 3, 5, \cdots$ to infinity?",What is the probability of winning a best of  to infinity?,"1, 3, 5, \cdots","A shady casino organizes a simple game with rules that follow: 1 die is rolled. If it lands on an even, the house wins. If it lands on an odd, the player wins. However, if the player loses he may take the game to a best of 3. If he wins the best of three, he wins overall. If he loses the best of three, he may take the game to a best of 5 to try and win then. If he loses the best of five, he may take the game to a best of 7, then best of 9, 11, 13 and so on. (In other words, its the kind of gambling trap that is depicted in movies, with some unfortunate person begging for another chance as he gets dragged away by some thugs.) Let $n$ be the total number of games played. If you keep taking the game to a best of the next odd number until you win, all the way to a best of (an odd) infinity, what is the total chance of you winning overall? And for the sake of calculations, let the chance of the player winning be $\dfrac{1}{4}$, and losing be $\dfrac{3}{4}$ due to the house using a weighted die. Is there an actual answer to the question? If so, how? I've started off by looking at infinite series's and permutations (listing the outcomes out as binary numbers, 1=win 0=loss), but I only got so far before getting completely stuck. I thought of splitting it up into the chances of winning the B o $N$ (best of $n$), such that the number of wins is always larger than losses by exactly $1$. This would make it so that I can ignore results with excess wins, and ones with excess losses (as they would eventually be looked at as n increases). (For the sake of clarity, $W$=win $L$=loss) For example: $LWWWW$ (best of 5), can be ignored because it is already accounted for in $LWW$ (best of 3) which results in an overall win and an end to the sequence of games. This would yield: $\displaystyle \binom{n}{\frac{n+1}{2}} \cdot P(W)^\frac{n+1}{2} \cdot P(L)^\frac{n-1}{2}%$ However this only deals with redundant combinations of results, and leaves many redundant permutations of the game results still in, such as any sequence that starts with a win (eg. $WLW$ is also counted even though $W$ (best of $1$) should end the sequence, $LWWLW$ is counted even though $LWW$ (best of 3) should end the sequence). This leads to some tricky permutation maths (I think) that I have scarce ideas on how to do, all of which are beyond me. UPDATE I put together some code to figure out the different ways of winning and a bunch of other related stuff. Unfortunately it starts to take a while after reaching best of 13. Regardless, the total cumulative probability of winning up to a best of 13 (using the weighted die) goes (rounded to 3 d.p.): 0.250 0.297 0.314 0.323 0.327 0.329 0.331 It definitely looks like its tending to a number, but I cant be sure looking at this from a statistical standpoint. I also made the program output the number of useful permutations (ie. not starting with a win nor a sequence that leads to an overall win of a smaller 'best of' round) for each 'best of' up to 13. They go: 1 1 2 5 14 42 132 These numbers are consistent with the permutations I wrote down and checked by hand (well, okay I gave up after best of 9, 42 11-letter-long sequences is a bit crazy). All of these statistics aside, i'm still looking for some logical way to do this. Maybe these numbers would help?","A shady casino organizes a simple game with rules that follow: 1 die is rolled. If it lands on an even, the house wins. If it lands on an odd, the player wins. However, if the player loses he may take the game to a best of 3. If he wins the best of three, he wins overall. If he loses the best of three, he may take the game to a best of 5 to try and win then. If he loses the best of five, he may take the game to a best of 7, then best of 9, 11, 13 and so on. (In other words, its the kind of gambling trap that is depicted in movies, with some unfortunate person begging for another chance as he gets dragged away by some thugs.) Let $n$ be the total number of games played. If you keep taking the game to a best of the next odd number until you win, all the way to a best of (an odd) infinity, what is the total chance of you winning overall? And for the sake of calculations, let the chance of the player winning be $\dfrac{1}{4}$, and losing be $\dfrac{3}{4}$ due to the house using a weighted die. Is there an actual answer to the question? If so, how? I've started off by looking at infinite series's and permutations (listing the outcomes out as binary numbers, 1=win 0=loss), but I only got so far before getting completely stuck. I thought of splitting it up into the chances of winning the B o $N$ (best of $n$), such that the number of wins is always larger than losses by exactly $1$. This would make it so that I can ignore results with excess wins, and ones with excess losses (as they would eventually be looked at as n increases). (For the sake of clarity, $W$=win $L$=loss) For example: $LWWWW$ (best of 5), can be ignored because it is already accounted for in $LWW$ (best of 3) which results in an overall win and an end to the sequence of games. This would yield: $\displaystyle \binom{n}{\frac{n+1}{2}} \cdot P(W)^\frac{n+1}{2} \cdot P(L)^\frac{n-1}{2}%$ However this only deals with redundant combinations of results, and leaves many redundant permutations of the game results still in, such as any sequence that starts with a win (eg. $WLW$ is also counted even though $W$ (best of $1$) should end the sequence, $LWWLW$ is counted even though $LWW$ (best of 3) should end the sequence). This leads to some tricky permutation maths (I think) that I have scarce ideas on how to do, all of which are beyond me. UPDATE I put together some code to figure out the different ways of winning and a bunch of other related stuff. Unfortunately it starts to take a while after reaching best of 13. Regardless, the total cumulative probability of winning up to a best of 13 (using the weighted die) goes (rounded to 3 d.p.): 0.250 0.297 0.314 0.323 0.327 0.329 0.331 It definitely looks like its tending to a number, but I cant be sure looking at this from a statistical standpoint. I also made the program output the number of useful permutations (ie. not starting with a win nor a sequence that leads to an overall win of a smaller 'best of' round) for each 'best of' up to 13. They go: 1 1 2 5 14 42 132 These numbers are consistent with the permutations I wrote down and checked by hand (well, okay I gave up after best of 9, 42 11-letter-long sequences is a bit crazy). All of these statistics aside, i'm still looking for some logical way to do this. Maybe these numbers would help?",,"['probability', 'catalan-numbers']"
54,"Show $\int_{-\infty}^{\infty}\,f(u,t)dG(u)$ is a ch.f. where $G$ is a d.f. ; $f(u,\cdot)$ is a ch.f. and $f(\cdot,t)$ is continuous.",Show  is a ch.f. where  is a d.f. ;  is a ch.f. and  is continuous.,"\int_{-\infty}^{\infty}\,f(u,t)dG(u) G f(u,\cdot) f(\cdot,t)","Show $$\int_{-\infty}^{\infty}\,f(u,t)dG(u)$$ is a ch.f. where $G$ is a   d.f. ; and $f(u,\cdot)$ is a ch.f. for each $u$ and $f(\cdot,t)$is   continuous for each $t$. Note that ch.f. means ""characteristic function"" and d.f. means ""distribution function"". It's a exercise from Kai Lai Chung's probability theory book. My idea is that: in the special case $G$ is discrete, the problem is reduced to the following easy problem: If $f_n$ are ch.f.'s and $\alpha_n \ge 0$,   $\sum_{n=1}^{\infty}\alpha_n=1$, then $$\sum_{n=1}^{\infty}\alpha_nf_n$$   is a ch.f. I think the crucial point is how to use""$f(\cdot,t)$ is  continuous for each $t$""","Show $$\int_{-\infty}^{\infty}\,f(u,t)dG(u)$$ is a ch.f. where $G$ is a   d.f. ; and $f(u,\cdot)$ is a ch.f. for each $u$ and $f(\cdot,t)$is   continuous for each $t$. Note that ch.f. means ""characteristic function"" and d.f. means ""distribution function"". It's a exercise from Kai Lai Chung's probability theory book. My idea is that: in the special case $G$ is discrete, the problem is reduced to the following easy problem: If $f_n$ are ch.f.'s and $\alpha_n \ge 0$,   $\sum_{n=1}^{\infty}\alpha_n=1$, then $$\sum_{n=1}^{\infty}\alpha_nf_n$$   is a ch.f. I think the crucial point is how to use""$f(\cdot,t)$ is  continuous for each $t$""",,"['probability', 'probability-theory', 'probability-distributions', 'characteristic-functions']"
55,Pulling balls out of a box,Pulling balls out of a box,,A box has $b$ blue balls and $r$ red balls. We pull the balls without returning them. What is the probability that the $k$th pull is the first red ball and what is the probability that the last ball is red? Also: do you know a site which fully explains these kinds of problems and all the variation you can have?,A box has $b$ blue balls and $r$ red balls. We pull the balls without returning them. What is the probability that the $k$th pull is the first red ball and what is the probability that the last ball is red? Also: do you know a site which fully explains these kinds of problems and all the variation you can have?,,['probability']
56,empirical estimation of Bernoulli distribution (lower bound),empirical estimation of Bernoulli distribution (lower bound),,"Let $X_i$ be an i.i.d. Bernoulli distributed sequence, with probability $p$ being 1. Now consider an empirical estimation of $p$ with $l$ samples and I am looking for a lower bound for following probability with assumption of $lp>1$ $$ \mathbb{P}\left\{ \frac{1}{l} \sum_{i=1}^l X_i \geq p \right\} $$ The desired lower bound should be independent of $l$ and $p$. My guess is $1/4$. Note : It's $\geq$, not $>$. Some background : I am reading Vapnik's ""Statistical Learning Theory"". Proof of the lemma 4.1 claims that for $lp > 1$, $$ \mathbb{P}\left\{ \frac{1}{l} \sum_{i=1}^l X_i > p \right\} \leq 1/4 $$ However, note that here it is an upper bound and it breaks the proof. I think we should seek for a lower bound the bias probability instead. Thanks","Let $X_i$ be an i.i.d. Bernoulli distributed sequence, with probability $p$ being 1. Now consider an empirical estimation of $p$ with $l$ samples and I am looking for a lower bound for following probability with assumption of $lp>1$ $$ \mathbb{P}\left\{ \frac{1}{l} \sum_{i=1}^l X_i \geq p \right\} $$ The desired lower bound should be independent of $l$ and $p$. My guess is $1/4$. Note : It's $\geq$, not $>$. Some background : I am reading Vapnik's ""Statistical Learning Theory"". Proof of the lemma 4.1 claims that for $lp > 1$, $$ \mathbb{P}\left\{ \frac{1}{l} \sum_{i=1}^l X_i > p \right\} \leq 1/4 $$ However, note that here it is an upper bound and it breaks the proof. I think we should seek for a lower bound the bias probability instead. Thanks",,"['probability', 'law-of-large-numbers']"
57,what is the probability that the circumcircle of 3 point,what is the probability that the circumcircle of 3 point,,"Mary  picks any three non-collinear points inside a given circle, what is the probability that the circumcircle of these 3 points will be covered by the original circle? This is from a  test question a few months ago.I got the result is $\frac{1}{\pi}$,I don't know my result right.What approaches do you think I could take to solving the step?","Mary  picks any three non-collinear points inside a given circle, what is the probability that the circumcircle of these 3 points will be covered by the original circle? This is from a  test question a few months ago.I got the result is $\frac{1}{\pi}$,I don't know my result right.What approaches do you think I could take to solving the step?",,[]
58,Interchange of expectation and summation,Interchange of expectation and summation,,"Assume $(\Omega,\mathscr{F},P)$ is a probability space and $\{X_n\}_{n\geq 1}$ is a sequence of random variables. Let $\{A_n\}_{n\geq 1}$ be a measurable partition of $\Omega$. My question is when the following equality holds:$$E\Big(\sum_{n=1}^\infty X_n1_{A_n}\Big)=\sum_{n=1}^\infty E\big(X_n1_{A_n}\big).$$ Of course, if $\sup_n|X_n|\leq X$ for some integrable $X$, then this is just an implication of dominated convergence theorem. My question is whether this is still true if $\sup_n X_n\leq X$ for some $X$ with $E(X)<+\infty$ if we allow $-\infty$ for expectation? Thanks!","Assume $(\Omega,\mathscr{F},P)$ is a probability space and $\{X_n\}_{n\geq 1}$ is a sequence of random variables. Let $\{A_n\}_{n\geq 1}$ be a measurable partition of $\Omega$. My question is when the following equality holds:$$E\Big(\sum_{n=1}^\infty X_n1_{A_n}\Big)=\sum_{n=1}^\infty E\big(X_n1_{A_n}\big).$$ Of course, if $\sup_n|X_n|\leq X$ for some integrable $X$, then this is just an implication of dominated convergence theorem. My question is whether this is still true if $\sup_n X_n\leq X$ for some $X$ with $E(X)<+\infty$ if we allow $-\infty$ for expectation? Thanks!",,"['probability', 'probability-theory', 'expectation']"
59,Probability Generating Function of a Negative Multinomial Distribution,Probability Generating Function of a Negative Multinomial Distribution,,"Derive the probability generating function ( pfg ) of a negative multinomial distribution with parameters $(k; p_{0}, p_{1}, ..., p_{r})$ where the k-th occurrence of the event with the probability $p_{0}$ stops the trials. My approach : Find the pgf of the event that is stopped by the first occurrence of the event associated with $p_{0}$ then raise that expression to the k-th power. This elementary event is a collection of multinomial event (excluding the stopping event) sequence of length $0 \rightarrow \infty$ , followed by the stopping event: $g_{elementary}(s_{1},...,s_{r}) = p_{0}(\sum_{j=0}^\infty (g_{multinomial}(s_{1},...,s_{r}))^j =\\ p_{0} / (1-g_{multinomial}(s_{1},...,s_{r}))$ where $g_{multinomial}(s_{1},...,s_{r})$ is the pgf of the multinomial event sequence of length $1$ with r possible outcomes, i.e. $\sum_{i=1}^r p_{i}s_{i}$ Raising $g_{elementary}(s_{1},...,s_{r})$ to the k-th power results in: $g(s_{1},...,s_{r}) = p_{0}^k (1-\sum_{i=1}^r p_{i}s_{i})^{-k}$ While this result is correct, I am not sure about my reasoning.","Derive the probability generating function ( pfg ) of a negative multinomial distribution with parameters where the k-th occurrence of the event with the probability stops the trials. My approach : Find the pgf of the event that is stopped by the first occurrence of the event associated with then raise that expression to the k-th power. This elementary event is a collection of multinomial event (excluding the stopping event) sequence of length , followed by the stopping event: where is the pgf of the multinomial event sequence of length with r possible outcomes, i.e. Raising to the k-th power results in: While this result is correct, I am not sure about my reasoning.","(k; p_{0}, p_{1}, ..., p_{r}) p_{0} p_{0} 0 \rightarrow \infty g_{elementary}(s_{1},...,s_{r}) = p_{0}(\sum_{j=0}^\infty (g_{multinomial}(s_{1},...,s_{r}))^j =\\ p_{0} / (1-g_{multinomial}(s_{1},...,s_{r})) g_{multinomial}(s_{1},...,s_{r}) 1 \sum_{i=1}^r p_{i}s_{i} g_{elementary}(s_{1},...,s_{r}) g(s_{1},...,s_{r}) = p_{0}^k (1-\sum_{i=1}^r p_{i}s_{i})^{-k}","['probability', 'probability-distributions', 'generating-functions', 'multinomial-coefficients', 'negative-binomial']"
60,"Distribution of occurrences of ""pairs of heads"" in $N$ coin tosses","Distribution of occurrences of ""pairs of heads"" in  coin tosses",N,"Let's say we toss a weighted coin $N$ times, each with probability $p$ of landing heads up. What's the distribution of the number of times we'll see $k$ pairs of heads ? For example, HTHHHTHH would count as three pairs, as would HHHH, while HHTHH would count as two. I hope that makes sense. More formally, let $X_i$ be an indicator random variable which is 1 if there is a pair of heads starting at position $i$ and 0 otherwise. What I'm looking for is the distribution of the sum $X=\sum_{i=1}^{N-1}X_i$. At first I thought it would be a simple binomial, with the number of trials being $N-1$, each with success probability $p^2$. But I've since come to the conclusion that it's more complicated than that (from some simple simulations in Matlab). This isn't for homework, just a problem I came across that has been bugging me a bit. Thanks! Edit: I'm thinking perhaps the approach used on this website that I came across could be adapted for this, if you fix $h$ and sum over the possibilities for $t$. Thoughts?","Let's say we toss a weighted coin $N$ times, each with probability $p$ of landing heads up. What's the distribution of the number of times we'll see $k$ pairs of heads ? For example, HTHHHTHH would count as three pairs, as would HHHH, while HHTHH would count as two. I hope that makes sense. More formally, let $X_i$ be an indicator random variable which is 1 if there is a pair of heads starting at position $i$ and 0 otherwise. What I'm looking for is the distribution of the sum $X=\sum_{i=1}^{N-1}X_i$. At first I thought it would be a simple binomial, with the number of trials being $N-1$, each with success probability $p^2$. But I've since come to the conclusion that it's more complicated than that (from some simple simulations in Matlab). This isn't for homework, just a problem I came across that has been bugging me a bit. Thanks! Edit: I'm thinking perhaps the approach used on this website that I came across could be adapted for this, if you fix $h$ and sum over the possibilities for $t$. Thoughts?",,"['probability', 'probability-distributions']"
61,Expected number of turns for SPROUT,Expected number of turns for SPROUT,,"As a mathematical father (and with apparently plenty of time on my hands) I long ago computed the expected number of turns for a number of children's games that are effectively Markov maps. ( Chutes and Ladders , Hi Ho! Cherry-O , Candy Land , etc.) And I've seen this and similar posts. (The TLDR version for this technique is that you have to diagonalize a matrix.) My, now older, son has introduced me to a new game and I was wondering about its expected number of turns. The game is SPROUT and it's rules are as follows: $n$ players play a game similar to every-man-for-himself dodge ball. Initally a ball is put into play and all players are free to run around the playing field. Free players can pick up the ball, take up to three steps with the ball, and throw it at another free player--if they hit the target that player is frozen and must sit down. If the target instead catches the ball then the Thrower is frozen and must sit. A frozen player is freed if the player that froze them becomes frozen. The freed player ""sprouts"" back up. The game ends when all players but one are frozen, this can only happen if that single free player has managed to freeze every every player. Apparently with 30 kids or so this game almost never ends. It's a great game to play I guess because the kids get exercise, but even if you get ""out"" or frozen, it's usually not long until you are back in the game. And you have a sweet sense of retribution at the moment of your freedom. Assuming that a turn of this game consists of one random free player freezing another random free player (and simultaneously freeing all the players that the newly frozen player had previously frozen), how many turns do we expect a game of $n$ players to take? This is harder to analyze because the state of the game is not just the number of free players and the number of frozen players, we must remember who froze whom so we can free the captives if their opressor ever becomes frozen. I can run numerical simulations for this but I'd be much more satisfied with an analytical understanding. Here's what I've done so far: We can keep track of the state of the game by an $n$ long vector that tracks the state of each player. Let a zero in position $i$ denote that player $i$ is free and a number from $1$ to $n$ represents the freezor of the frozen player $i$. Initialize the state to be all zeros. $$\{0,0,0,0,0,0,0,\ldots,0\}$$ At any later turn the state will be a combination of zeros and integers from $1$ to $n$ (e.g. $\{0,1,5,5,0\}$ ) but we also have the property that any non-zero integers appearing in the state vector imply that there are zeros in those positions of the state vector as well (due to property 4 above). This means that there are $$\sum_{k=0}^{n-1}{n \choose k}(n-k)^k$$ total states, including the initial state (which is never returned to) and the $n$ final states (one for each possible winning player). This number is crazy big but I imagine that these states are sparsely connected since I have seen a game of ten boys completed. (Maybe one boy was just really superior at the game??) I'd appreciate any feedback on my analysis. Am I thinking about this correctly? Is this just gonna be a hard problem? Is it really an easy problem?? Thanks Update: Upon further inspection I realize that there are actually far fewer states. If I do not care about player identity, only the total number of turns, I can relable my players as needed so that they are ordered with the free player indices lower than the the frozen players and each group further ordered as follows. For the free players let player 1 be the player in the ""lead"" i.e. the one who has frozen the most, let player 2 be the next according to this order and so on for $k$ free players. For the frozen players (beginning at index $k+1$) let them be ordered by the index of their Freezor. e.g. $$\{0,0,0,0,1,1,1,2,2,3\}$$ Then the states are just ordered lists of non-negative integers with the only properties that The last element is not greater in value than the number (count) of zeros. The non-zero integers are monotonically non-decreasing in count. (Never fewer ones than twos, etc.) This drastically reduces the number of states but I do not yet have a good count of this.","As a mathematical father (and with apparently plenty of time on my hands) I long ago computed the expected number of turns for a number of children's games that are effectively Markov maps. ( Chutes and Ladders , Hi Ho! Cherry-O , Candy Land , etc.) And I've seen this and similar posts. (The TLDR version for this technique is that you have to diagonalize a matrix.) My, now older, son has introduced me to a new game and I was wondering about its expected number of turns. The game is SPROUT and it's rules are as follows: $n$ players play a game similar to every-man-for-himself dodge ball. Initally a ball is put into play and all players are free to run around the playing field. Free players can pick up the ball, take up to three steps with the ball, and throw it at another free player--if they hit the target that player is frozen and must sit down. If the target instead catches the ball then the Thrower is frozen and must sit. A frozen player is freed if the player that froze them becomes frozen. The freed player ""sprouts"" back up. The game ends when all players but one are frozen, this can only happen if that single free player has managed to freeze every every player. Apparently with 30 kids or so this game almost never ends. It's a great game to play I guess because the kids get exercise, but even if you get ""out"" or frozen, it's usually not long until you are back in the game. And you have a sweet sense of retribution at the moment of your freedom. Assuming that a turn of this game consists of one random free player freezing another random free player (and simultaneously freeing all the players that the newly frozen player had previously frozen), how many turns do we expect a game of $n$ players to take? This is harder to analyze because the state of the game is not just the number of free players and the number of frozen players, we must remember who froze whom so we can free the captives if their opressor ever becomes frozen. I can run numerical simulations for this but I'd be much more satisfied with an analytical understanding. Here's what I've done so far: We can keep track of the state of the game by an $n$ long vector that tracks the state of each player. Let a zero in position $i$ denote that player $i$ is free and a number from $1$ to $n$ represents the freezor of the frozen player $i$. Initialize the state to be all zeros. $$\{0,0,0,0,0,0,0,\ldots,0\}$$ At any later turn the state will be a combination of zeros and integers from $1$ to $n$ (e.g. $\{0,1,5,5,0\}$ ) but we also have the property that any non-zero integers appearing in the state vector imply that there are zeros in those positions of the state vector as well (due to property 4 above). This means that there are $$\sum_{k=0}^{n-1}{n \choose k}(n-k)^k$$ total states, including the initial state (which is never returned to) and the $n$ final states (one for each possible winning player). This number is crazy big but I imagine that these states are sparsely connected since I have seen a game of ten boys completed. (Maybe one boy was just really superior at the game??) I'd appreciate any feedback on my analysis. Am I thinking about this correctly? Is this just gonna be a hard problem? Is it really an easy problem?? Thanks Update: Upon further inspection I realize that there are actually far fewer states. If I do not care about player identity, only the total number of turns, I can relable my players as needed so that they are ordered with the free player indices lower than the the frozen players and each group further ordered as follows. For the free players let player 1 be the player in the ""lead"" i.e. the one who has frozen the most, let player 2 be the next according to this order and so on for $k$ free players. For the frozen players (beginning at index $k+1$) let them be ordered by the index of their Freezor. e.g. $$\{0,0,0,0,1,1,1,2,2,3\}$$ Then the states are just ordered lists of non-negative integers with the only properties that The last element is not greater in value than the number (count) of zeros. The non-zero integers are monotonically non-decreasing in count. (Never fewer ones than twos, etc.) This drastically reduces the number of states but I do not yet have a good count of this.",,"['probability', 'markov-chains']"
62,"A fun card game involving probability, getting all 13 ranks (any suit(s)) vs. 5 in a row of red or black.","A fun card game involving probability, getting all 13 ranks (any suit(s)) vs. 5 in a row of red or black.",,"Two people, (call them C and D), decide to play a card game for fun.  They use an ordinary fair deck of $52$ cards, shuffled well before each hand is drawn, and randomly draw cards from it one a time without replacement, both using (sharing) the same drawn cards to determine who wins.  A win is defined as follows: C wins if he gets at least one of all $13$ ranks of the cards (regardless of suit as they can be mixed suit or even all the same suit) in a hand. D wins if he gets either $5$ reds or $5$ blacks in a row (consecutive) for a particular hand.  Each new hand starts with $0$ in a row so far so there is no ""carryover"" from a previous hand. It is possible that C and D can both ""win"" on the same card draw so normally that would be a tie but a ""twist"" in the game is that ties are awarded to C but not just as a single win.  Since ties are likely rare, C gets a triple win for ties.  That is, if C and D bet even money and they ""tied"", C would then win $3$ to $1$ odds of whatever D bet him for that particular hand.  So let's take an example run so there is no confusion.  Suppose they both bet $1$ dollar per hand and the following happens: D wins game $1$ so he is then up by $1$ dollar. C wins game $2$ so they are both back to even money. D wins the next $2$ games so he is then up $2$ dollars over C (C is down $2$ dollars). The next game is a tie so C is awarded $3$ dollars so is then ahead by $1$ dollar. Another way to think about it is to not think about money but just count up the number of wins.  If there is a tie, C gets awarded $3$ wins for that hand. So the question is who has the mathematical advantage here and by how much?  For example, if it was a rainy day and they played this game for many hands, who would likely be ahead as far as net money gained as a result of playing this game? Some interesting things to consider are: D can immediately win with only $5$ card draws while C requires $13$ minimum. It is possible that D will not win even if all the cards are drawn, never getting $5$ in a row of either color. A decision can take anywhere from $5$ to $49$ cards. $49$ is the max because imagine if $12$ of each rank (of all $4$ suits) have been chosen but D hasn't won yet for that hand, the next card will complete one of those set of ranks.  For example, if the last $4$ cards in the deck are all Kings (K), the $49$th card will give the win to C (assuming D doesn't win or tie). $$UPDATE$$ I ran a simulation of 1 billion decisions (ties included) and the results are as follows: C won : $469,102,581$ times.  (excluding triple wins for ties). D won : $514,835,119$ times. C,D tied :  $16,062,300$ times.  (C awarded triple win). C won : $517,289,481$ times.  (including triple wins for ties). Advantage for C: about $0.48$% Average # of cards drawn to make a decision is $20.579$. So the triple win award for ties gives C a very slight edge over D but without that D has a decent advantage.  So in theory, if they played this game for many hands, they would about break even.  However, in the shortrun, someone could take a sizable lead.  Sometime I may try about $10$ hands with actual cards and see what I get. I would like to know how to set this problem up mathematically or if it is even possible.  Perhaps we could first solve a simpler variation where we draw exactly $21$ random cards then check for a winner.  Perhaps that will give us some insight into how to solve the more general question with a variable # of cards (from $5$ to $49$ is possible.). Also, can someone tell me how to plot a graph on here because I have data for the # of wins of each # of cards drawn from $1$ to $52$.  The numbers show some interesting patterns.  Out of $1,000,000$ decisions, $5$ cards drawn accounts for the most wins at about $5$%.  Next is very close between $23, 24,$ and $25$ cards which account for about $4.4$% each.","Two people, (call them C and D), decide to play a card game for fun.  They use an ordinary fair deck of $52$ cards, shuffled well before each hand is drawn, and randomly draw cards from it one a time without replacement, both using (sharing) the same drawn cards to determine who wins.  A win is defined as follows: C wins if he gets at least one of all $13$ ranks of the cards (regardless of suit as they can be mixed suit or even all the same suit) in a hand. D wins if he gets either $5$ reds or $5$ blacks in a row (consecutive) for a particular hand.  Each new hand starts with $0$ in a row so far so there is no ""carryover"" from a previous hand. It is possible that C and D can both ""win"" on the same card draw so normally that would be a tie but a ""twist"" in the game is that ties are awarded to C but not just as a single win.  Since ties are likely rare, C gets a triple win for ties.  That is, if C and D bet even money and they ""tied"", C would then win $3$ to $1$ odds of whatever D bet him for that particular hand.  So let's take an example run so there is no confusion.  Suppose they both bet $1$ dollar per hand and the following happens: D wins game $1$ so he is then up by $1$ dollar. C wins game $2$ so they are both back to even money. D wins the next $2$ games so he is then up $2$ dollars over C (C is down $2$ dollars). The next game is a tie so C is awarded $3$ dollars so is then ahead by $1$ dollar. Another way to think about it is to not think about money but just count up the number of wins.  If there is a tie, C gets awarded $3$ wins for that hand. So the question is who has the mathematical advantage here and by how much?  For example, if it was a rainy day and they played this game for many hands, who would likely be ahead as far as net money gained as a result of playing this game? Some interesting things to consider are: D can immediately win with only $5$ card draws while C requires $13$ minimum. It is possible that D will not win even if all the cards are drawn, never getting $5$ in a row of either color. A decision can take anywhere from $5$ to $49$ cards. $49$ is the max because imagine if $12$ of each rank (of all $4$ suits) have been chosen but D hasn't won yet for that hand, the next card will complete one of those set of ranks.  For example, if the last $4$ cards in the deck are all Kings (K), the $49$th card will give the win to C (assuming D doesn't win or tie). $$UPDATE$$ I ran a simulation of 1 billion decisions (ties included) and the results are as follows: C won : $469,102,581$ times.  (excluding triple wins for ties). D won : $514,835,119$ times. C,D tied :  $16,062,300$ times.  (C awarded triple win). C won : $517,289,481$ times.  (including triple wins for ties). Advantage for C: about $0.48$% Average # of cards drawn to make a decision is $20.579$. So the triple win award for ties gives C a very slight edge over D but without that D has a decent advantage.  So in theory, if they played this game for many hands, they would about break even.  However, in the shortrun, someone could take a sizable lead.  Sometime I may try about $10$ hands with actual cards and see what I get. I would like to know how to set this problem up mathematically or if it is even possible.  Perhaps we could first solve a simpler variation where we draw exactly $21$ random cards then check for a winner.  Perhaps that will give us some insight into how to solve the more general question with a variable # of cards (from $5$ to $49$ is possible.). Also, can someone tell me how to plot a graph on here because I have data for the # of wins of each # of cards drawn from $1$ to $52$.  The numbers show some interesting patterns.  Out of $1,000,000$ decisions, $5$ cards drawn accounts for the most wins at about $5$%.  Next is very close between $23, 24,$ and $25$ cards which account for about $4.4$% each.",,['probability']
63,Expected value of the minimum with limited independence,Expected value of the minimum with limited independence,,"Imagine you sample $n$ number with replacement uniformly from the integers $1,\dots, n$.  Let $X$ be the minimum of these samples.  I am interested in $\mathbb{E}(X)$ but with a twist. All I know is that the samples are uniform and pairwise independent. What bounds can one give for $\mathbb{E}(X)$? If we generalize this to $k$-wise independence, for $k \geq 2$, what can we say? We can assume $n$ is large.","Imagine you sample $n$ number with replacement uniformly from the integers $1,\dots, n$.  Let $X$ be the minimum of these samples.  I am interested in $\mathbb{E}(X)$ but with a twist. All I know is that the samples are uniform and pairwise independent. What bounds can one give for $\mathbb{E}(X)$? If we generalize this to $k$-wise independence, for $k \geq 2$, what can we say? We can assume $n$ is large.",,[]
64,How do you calculate the odds that the odds will be right?,How do you calculate the odds that the odds will be right?,,"So in this instance I have a standard deck of 52 cards and am playing a high/low game with it (ie turn over the top card, guess if the next card is higher or lower) and maintain a record of all the cards used. Each guess has an easily calculable chance of being either higher or lower. IE if you draw an 8 for a first cards it's 50% chance that it's higher, and 50% chance that it's lower and a ~5% chance it's another 8 which counts as a ""win"" regardless of your choice of high or low. What I don't know how to calculate: The odds that you will successfully win this game getting all 51 guesses correct strictly guessing the most probable choice. Any solution I come up with would be different for every game and relies on the cards already drawn. I want to know this probability before even starting a game. Edit: Additional info: Suits don't matter Ties are wins. Aces are high","So in this instance I have a standard deck of 52 cards and am playing a high/low game with it (ie turn over the top card, guess if the next card is higher or lower) and maintain a record of all the cards used. Each guess has an easily calculable chance of being either higher or lower. IE if you draw an 8 for a first cards it's 50% chance that it's higher, and 50% chance that it's lower and a ~5% chance it's another 8 which counts as a ""win"" regardless of your choice of high or low. What I don't know how to calculate: The odds that you will successfully win this game getting all 51 guesses correct strictly guessing the most probable choice. Any solution I come up with would be different for every game and relies on the cards already drawn. I want to know this probability before even starting a game. Edit: Additional info: Suits don't matter Ties are wins. Aces are high",,"['probability', 'statistics', 'card-games']"
65,Is p(x)dx equal to dp(x)?,Is p(x)dx equal to dp(x)?,,"I'm confused with the definition of the expectation operator.  Assume a random variable $X$ having a probability distribution $p(x)$. Then the expected value of $X$ can be computed as $\int xp(x)dx$. It is noted in 1 that, given a probability space $(\Omega, \Sigma,  P)$ as defined in 2 , the general definition of the expected value is $\int_{\Omega} X dP = \int_{\Omega} X(w)P(dw) $ where $P$ is the probability measure returning an events probability in $\Sigma$. Is this probability measure the same as the distribution $p(x)$. Additionaly. what does $X(w)$ and $P(dw)$ mean? Also, the Eq. 1 in http://leon.bottou.org/publications/pdf/online-1998.pdf states that  $E[f(x)] = \int f(x)p(x) = \int f(x)dp(x)$, is this correct or simply there is a notation error?","I'm confused with the definition of the expectation operator.  Assume a random variable $X$ having a probability distribution $p(x)$. Then the expected value of $X$ can be computed as $\int xp(x)dx$. It is noted in 1 that, given a probability space $(\Omega, \Sigma,  P)$ as defined in 2 , the general definition of the expected value is $\int_{\Omega} X dP = \int_{\Omega} X(w)P(dw) $ where $P$ is the probability measure returning an events probability in $\Sigma$. Is this probability measure the same as the distribution $p(x)$. Additionaly. what does $X(w)$ and $P(dw)$ mean? Also, the Eq. 1 in http://leon.bottou.org/publications/pdf/online-1998.pdf states that  $E[f(x)] = \int f(x)p(x) = \int f(x)dp(x)$, is this correct or simply there is a notation error?",,"['probability', 'probability-theory']"
66,Marbles in a bag (Combinatorics),Marbles in a bag (Combinatorics),,"There are 10 numbered from 1 to 10 marbles. The marbles are placed in an opaque bag and shuffled. One random marble is taken out, its number is written on a piece of paper, marble is then returned to the bag, marbles are shuffled again. Procedure is repeated, until 25 records are accumulated on the paper. Question №1: what is the probability that paper now contains all numbers from 1 to 10, at least once? Q №2: what is the average amount of numbers to be written in such a manner, until all numbers from 1 to 10 are recorded at least once? P.S. I found correct numbers by using the Monte Carlo method, but interested in purely mathematical solution. Update Since asking this, I've questioned friends and collegues, tried to receive correct solution for #1 at different websites, but it all failed for me. The Emperor of Ice Cream's answer, simply doesn't seem to be entirely correct, as it's outcome is fairly far from my simulation results (which was conducted again on rewired algorithm, only to see the same outcome).","There are 10 numbered from 1 to 10 marbles. The marbles are placed in an opaque bag and shuffled. One random marble is taken out, its number is written on a piece of paper, marble is then returned to the bag, marbles are shuffled again. Procedure is repeated, until 25 records are accumulated on the paper. Question №1: what is the probability that paper now contains all numbers from 1 to 10, at least once? Q №2: what is the average amount of numbers to be written in such a manner, until all numbers from 1 to 10 are recorded at least once? P.S. I found correct numbers by using the Monte Carlo method, but interested in purely mathematical solution. Update Since asking this, I've questioned friends and collegues, tried to receive correct solution for #1 at different websites, but it all failed for me. The Emperor of Ice Cream's answer, simply doesn't seem to be entirely correct, as it's outcome is fairly far from my simulation results (which was conducted again on rewired algorithm, only to see the same outcome).",,"['probability', 'combinatorics']"
67,An irreducible Markov chain is a martingale,An irreducible Markov chain is a martingale,,"Let $\{X_n\}$ be an irreducible Markov chain. Does exist example of such $\{X_n\}$ which is also a martingale given that: a. $\{X_n\}$ is recurrent with finite number of states (but bigger than $1$)? b. $\{X_n\}$ is recurrent with infinite states ? c. $\{X_n\}$ is transient with infinite states ? (If not give a proof why it cannot be) In another question I saw that exists examples for Martingales which are not Markov chains and I know that given harmonic function $h$ on the markov chain, then $h(X_n)$ is indeed a martingale. About c: I think about a random walk on $\mathbb{Z}$ defined by $$X_n=\cases{0 \quad p=\frac 1 2\\X_n+1\quad p=\frac 1 2}$$ which is Markov as a random walk but I don't know how to prove it's a martingle (I'm even pretty sure it's not). About A I thought taking a series of absorbent states, e.g. $\left(\begin{array}{cc} 1 & 0\\ 0 & 1 \end{array}\right)  $ but again I don't know how to prove it's martingle. About the second example (means b.) I'm clueless. Are my examples correct? If so: How I prove marginality and find example for b.? If they are incorrect: Which examples can I find for these questions?","Let $\{X_n\}$ be an irreducible Markov chain. Does exist example of such $\{X_n\}$ which is also a martingale given that: a. $\{X_n\}$ is recurrent with finite number of states (but bigger than $1$)? b. $\{X_n\}$ is recurrent with infinite states ? c. $\{X_n\}$ is transient with infinite states ? (If not give a proof why it cannot be) In another question I saw that exists examples for Martingales which are not Markov chains and I know that given harmonic function $h$ on the markov chain, then $h(X_n)$ is indeed a martingale. About c: I think about a random walk on $\mathbb{Z}$ defined by $$X_n=\cases{0 \quad p=\frac 1 2\\X_n+1\quad p=\frac 1 2}$$ which is Markov as a random walk but I don't know how to prove it's a martingle (I'm even pretty sure it's not). About A I thought taking a series of absorbent states, e.g. $\left(\begin{array}{cc} 1 & 0\\ 0 & 1 \end{array}\right)  $ but again I don't know how to prove it's martingle. About the second example (means b.) I'm clueless. Are my examples correct? If so: How I prove marginality and find example for b.? If they are incorrect: Which examples can I find for these questions?",,"['probability', 'probability-theory']"
68,Conditioning on a continuous random variable,Conditioning on a continuous random variable,,"I have a random variable $N(a)$, which depends on a number $a$, having the property that for all $a \in \mathbb{R}$, $$P(N(a) \geq 1) = p $$ The example I have in mind is $N(a)$ is $T-a$ where $T$ the time of first arrival in a Poisson process after $a$, which is why there is no dependence of $P(N(a) \geq 1)$ on $a$. However, let us not assume anything like this - $N(a)$ is just a random variable for each $a$. Let $Z$ be a continuous random variable independent of all $N(a)$. I would like to assert that  $$P(N(Z) \geq 1) = p.$$  My question is how I might justify this. It is natural to try to justify it by writing $$P(N(Z) \geq 1) = \int_{-\infty}^{+\infty} P(N(a) \geq 1) f_Z(a) ~ da = p$$ but what I don't know is how the first equality can be justified. If the variables were discrete, this would follow by conditioning, but how does one condition on the event $Z=a$ of probability $0$?","I have a random variable $N(a)$, which depends on a number $a$, having the property that for all $a \in \mathbb{R}$, $$P(N(a) \geq 1) = p $$ The example I have in mind is $N(a)$ is $T-a$ where $T$ the time of first arrival in a Poisson process after $a$, which is why there is no dependence of $P(N(a) \geq 1)$ on $a$. However, let us not assume anything like this - $N(a)$ is just a random variable for each $a$. Let $Z$ be a continuous random variable independent of all $N(a)$. I would like to assert that  $$P(N(Z) \geq 1) = p.$$  My question is how I might justify this. It is natural to try to justify it by writing $$P(N(Z) \geq 1) = \int_{-\infty}^{+\infty} P(N(a) \geq 1) f_Z(a) ~ da = p$$ but what I don't know is how the first equality can be justified. If the variables were discrete, this would follow by conditioning, but how does one condition on the event $Z=a$ of probability $0$?",,['probability']
69,Prove that the probability of two event sets are equal,Prove that the probability of two event sets are equal,,"Consider this problem: Let $A_1, A_2,...$ be an arbitrary finite sequence of events. Let $B_1, B_2,...$ be another finite sequence of events defined as follows: $B_1 = A_1, B_2 = A^c_1 >\cap A_2, B_3 = A^c_1 \cap A^c_2 \cap A_3,.. $ Prove: $P(\bigcup^n_{i=1} A_i) = \sum^n_{i=1}P(B_i)$ Proof using Induction: For $\mathbf{n=1}$ $$P(\bigcup^1_{i=1} A_i) = P(A_1) \ \text{and} \ \sum^1_{i=1}P(B_i) = P(B_1) $$ $$ \text{Given} \ A_1 = B_1 \ \text{it follows that} \ P(A_1) = P(B_1)$$ Inductive step: Assumption: $$\forall n \in N \ | \ P(\bigcup^n_{i=1} A_i) = \sum^n_{i=1}P(B_i)$$ prove that: $$P(\bigcup^{n+1}_{i=1} A_i) = \sum^{n+1}_{i=1}P(B_i)$$ Prove: $$P(\bigcup^{n+1}_{i=1} A_i)$$ $$ \iff P(\bigcup^{n}_{i=1} A_i \cup A_{n+1})$$ $$\iff P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1}) - P(\bigcup^{n}_{i=1} A_i \cap A_{n+1})$$ $$ \iff P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1} \cap (\bigcup_{i=1}^n A_1)^c)$$ Applying De Morgan Law $$\iff  P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1} \cap (\bigcap_{i=1}^n A_1^c))$$ Due to preexistence of  $B_n = \bigcap_{i=1}^{n-1} A_i^c \cap A_{n} \ \text{for} \ n > 1 $ and therefore  $B_{n+1} = \bigcap_{i=1}^n A_i^c \cap A_{n+1} $ it follows that $$ \iff P(\bigcup^{n}_{i=1} A_i) + P(B_{n+1})$$ Employing our inductive assumption for $\forall n \in N$ it follows: $$\iff \sum^n_{i=1} P(B_i) + P(B_{n+1}) \iff \sum^{n+1}_{i=1} B_i$$ The proof at some stages does make sense in my head. Could someone please tell me  whether those steps are consistent? Thank you.","Consider this problem: Let $A_1, A_2,...$ be an arbitrary finite sequence of events. Let $B_1, B_2,...$ be another finite sequence of events defined as follows: $B_1 = A_1, B_2 = A^c_1 >\cap A_2, B_3 = A^c_1 \cap A^c_2 \cap A_3,.. $ Prove: $P(\bigcup^n_{i=1} A_i) = \sum^n_{i=1}P(B_i)$ Proof using Induction: For $\mathbf{n=1}$ $$P(\bigcup^1_{i=1} A_i) = P(A_1) \ \text{and} \ \sum^1_{i=1}P(B_i) = P(B_1) $$ $$ \text{Given} \ A_1 = B_1 \ \text{it follows that} \ P(A_1) = P(B_1)$$ Inductive step: Assumption: $$\forall n \in N \ | \ P(\bigcup^n_{i=1} A_i) = \sum^n_{i=1}P(B_i)$$ prove that: $$P(\bigcup^{n+1}_{i=1} A_i) = \sum^{n+1}_{i=1}P(B_i)$$ Prove: $$P(\bigcup^{n+1}_{i=1} A_i)$$ $$ \iff P(\bigcup^{n}_{i=1} A_i \cup A_{n+1})$$ $$\iff P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1}) - P(\bigcup^{n}_{i=1} A_i \cap A_{n+1})$$ $$ \iff P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1} \cap (\bigcup_{i=1}^n A_1)^c)$$ Applying De Morgan Law $$\iff  P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1} \cap (\bigcap_{i=1}^n A_1^c))$$ Due to preexistence of  $B_n = \bigcap_{i=1}^{n-1} A_i^c \cap A_{n} \ \text{for} \ n > 1 $ and therefore  $B_{n+1} = \bigcap_{i=1}^n A_i^c \cap A_{n+1} $ it follows that $$ \iff P(\bigcup^{n}_{i=1} A_i) + P(B_{n+1})$$ Employing our inductive assumption for $\forall n \in N$ it follows: $$\iff \sum^n_{i=1} P(B_i) + P(B_{n+1}) \iff \sum^{n+1}_{i=1} B_i$$ The proof at some stages does make sense in my head. Could someone please tell me  whether those steps are consistent? Thank you.",,['probability']
70,$n$ players throw a die and get score for each pair who throw the same number,players throw a die and get score for each pair who throw the same number,n,"Each member of a group and $n$ players roll a fair die. For every pair of players who throw the same number, the group scores 1 point. Find the mean and variance of the total score of the group. Here is what I tried: Let $S_i$ denote the score obtained by the players who throw $i, i=1,2,\ldots,6$, and let $X_i$ be the number of people who throw $i$, and $1_{ij}$ be the indicator function which is 1 only if the $j^{th}$ person throws $i$. So, we have $X_i=\sum_{j=1}^n 1_{ij}$. I computed $E[S_i|X_i]=\frac{X_i(X_i-1)}{2}$ and so $E[S_i]=\frac{n^2-n}{72}$ and therefore $E[S]=\frac{n^2-n}{12}$, where $S=\sum_{i=1}^6 S_i$ is the total score. In the same manner, by using variance-covariance expansion and conditional variance, I tried to compute $\mathrm{var}(S)$, but at some point I got $\mathrm{var}(\sum_{j<k}1_{ij}1_{ik})$ and I can't compute this variance because of dependence of summands. Also, I'm not sure if my solution so far is correct. Appreciate any help!","Each member of a group and $n$ players roll a fair die. For every pair of players who throw the same number, the group scores 1 point. Find the mean and variance of the total score of the group. Here is what I tried: Let $S_i$ denote the score obtained by the players who throw $i, i=1,2,\ldots,6$, and let $X_i$ be the number of people who throw $i$, and $1_{ij}$ be the indicator function which is 1 only if the $j^{th}$ person throws $i$. So, we have $X_i=\sum_{j=1}^n 1_{ij}$. I computed $E[S_i|X_i]=\frac{X_i(X_i-1)}{2}$ and so $E[S_i]=\frac{n^2-n}{72}$ and therefore $E[S]=\frac{n^2-n}{12}$, where $S=\sum_{i=1}^6 S_i$ is the total score. In the same manner, by using variance-covariance expansion and conditional variance, I tried to compute $\mathrm{var}(S)$, but at some point I got $\mathrm{var}(\sum_{j<k}1_{ij}1_{ik})$ and I can't compute this variance because of dependence of summands. Also, I'm not sure if my solution so far is correct. Appreciate any help!",,['probability']
71,"Probability of $m$ out of $n$ rolls of a die being among the numbers $1,2,\ldots,m-1$, for some $m$.","Probability of  out of  rolls of a die being among the numbers , for some .","m n 1,2,\ldots,m-1 m","Suppose I have a $k$ sided die with the numbers $1,2,\ldots,k$ on each side, and that I roll it $n$ times ($n<k$). What is the probability that there exists an $m\leq n$, so that $m$ of the $n$ rolls lie in the set $\{1,2,\ldots,m-1\}$? If a closed form in terms of $k,n$ cannot be easily found, a recursion would be equally useful, so it can be more easily calculated. I have tried calculating this for specific values of $n$ and $k$, but it is difficult, because the two events corresponding to distinct values of $m$ are not mutually exclusive, so you can't just calculate the probability of the event occurring for each value of $m\leq n$, and add them up. This means that copious use of the Principle of Inclusion-Exclusion is required, and it gets messy very quickly.","Suppose I have a $k$ sided die with the numbers $1,2,\ldots,k$ on each side, and that I roll it $n$ times ($n<k$). What is the probability that there exists an $m\leq n$, so that $m$ of the $n$ rolls lie in the set $\{1,2,\ldots,m-1\}$? If a closed form in terms of $k,n$ cannot be easily found, a recursion would be equally useful, so it can be more easily calculated. I have tried calculating this for specific values of $n$ and $k$, but it is difficult, because the two events corresponding to distinct values of $m$ are not mutually exclusive, so you can't just calculate the probability of the event occurring for each value of $m\leq n$, and add them up. This means that copious use of the Principle of Inclusion-Exclusion is required, and it gets messy very quickly.",,"['probability', 'combinatorics', 'inclusion-exclusion']"
72,Probability of last person taking his own card,Probability of last person taking his own card,,"I was asked this question this time at lunch and could not stop thinking about it since then. I could not find the answer, so that's why I am asking here. The story is as following: n people write their name on a card and put it in a box. After everyone has put their card with their name into the box, people will, one by one, grab a card. If a person takes a card with his/her own name, before that person puts his/her own card back in, that person takes another card (guaranteeing that he/she takes a different card now). After taking a different card, that person puts their own card back into the box. So, the question is: what is the chance that the last person who grabs a card, is left with his own card? We could, for example, take 31 persons in total, so n = 31 .","I was asked this question this time at lunch and could not stop thinking about it since then. I could not find the answer, so that's why I am asking here. The story is as following: n people write their name on a card and put it in a box. After everyone has put their card with their name into the box, people will, one by one, grab a card. If a person takes a card with his/her own name, before that person puts his/her own card back in, that person takes another card (guaranteeing that he/she takes a different card now). After taking a different card, that person puts their own card back into the box. So, the question is: what is the chance that the last person who grabs a card, is left with his own card? We could, for example, take 31 persons in total, so n = 31 .",,['probability']
73,Showing that $p^n(1-p) \leq \frac{1}{en}$,Showing that,p^n(1-p) \leq \frac{1}{en},"I am reading a paper and found the following Lemma without a proof. Let $X_1, \ldots, X_{n+1}$ be independent Bernoulli random variables, where $\Pr[X_i = 1] = p$. Let $E$ be the event that the first $n$ variables are all $1$, but the $X_{n+1}$ is $0$. Then $\Pr[E] \leq \frac{1}{en}$. I understand that $\Pr[E] = p^n(1-p)$. How is it that $p^n(1-p) \leq \frac{1}{en}$?","I am reading a paper and found the following Lemma without a proof. Let $X_1, \ldots, X_{n+1}$ be independent Bernoulli random variables, where $\Pr[X_i = 1] = p$. Let $E$ be the event that the first $n$ variables are all $1$, but the $X_{n+1}$ is $0$. Then $\Pr[E] \leq \frac{1}{en}$. I understand that $\Pr[E] = p^n(1-p)$. How is it that $p^n(1-p) \leq \frac{1}{en}$?",,['probability']
74,Permutation order statistics integral,Permutation order statistics integral,,"Let $U_i$ be $[0,1]$ i.i.d. uniform random variables, for $i=1,\ldots,n$. As an example, let $n=3$. Now pick an ordering, say $x_1>x_2<x_3$. and consider the order statistics integral $$3!\int\cdots\int_{x_1>x_2<x_3;\ \ 1>x_i>0} dx_1\,dx_2\,dx_3=2. $$ We get that this integral equals the number of permutations $\pi=(\pi_1,\pi_2,\pi_3)$  in $S_3$ with $\pi_1>\pi_2<\pi_3$. The only ones are $(3,1,2)$ and $(2,1,3)$ for a total of 2 as expected. In general, we have for a given fixed ordering $x_1?x_2\cdots?x_n$, where the question-marks correspond to $<$ or $>$: $$|\{\pi: \pi_1?\cdots?\pi_n\}|=n!\int\cdots\int_{x_1?x_2\cdots?x_n;\ \ 1>x_i>0} dx_1\,dx_2\,dx_3.$$ Question: is there a sensible meaning for the integral: $$n!\int_{x_1?x_2\cdots?x_n;\ \ 1>x_i>0} \,x_1\,dx_1\,dx_2\,dx_3\cdots dx_n.$$ I want to conclude that it's (related to) the expected value of the first element $\pi_1$ of a uniformly random permutation drawn from the set $\{\pi: \pi_1?\cdots?\pi_n\}$. Unfortunately, this does not seem to be the case. Is there a way to remedy this?","Let $U_i$ be $[0,1]$ i.i.d. uniform random variables, for $i=1,\ldots,n$. As an example, let $n=3$. Now pick an ordering, say $x_1>x_2<x_3$. and consider the order statistics integral $$3!\int\cdots\int_{x_1>x_2<x_3;\ \ 1>x_i>0} dx_1\,dx_2\,dx_3=2. $$ We get that this integral equals the number of permutations $\pi=(\pi_1,\pi_2,\pi_3)$  in $S_3$ with $\pi_1>\pi_2<\pi_3$. The only ones are $(3,1,2)$ and $(2,1,3)$ for a total of 2 as expected. In general, we have for a given fixed ordering $x_1?x_2\cdots?x_n$, where the question-marks correspond to $<$ or $>$: $$|\{\pi: \pi_1?\cdots?\pi_n\}|=n!\int\cdots\int_{x_1?x_2\cdots?x_n;\ \ 1>x_i>0} dx_1\,dx_2\,dx_3.$$ Question: is there a sensible meaning for the integral: $$n!\int_{x_1?x_2\cdots?x_n;\ \ 1>x_i>0} \,x_1\,dx_1\,dx_2\,dx_3\cdots dx_n.$$ I want to conclude that it's (related to) the expected value of the first element $\pi_1$ of a uniformly random permutation drawn from the set $\{\pi: \pi_1?\cdots?\pi_n\}$. Unfortunately, this does not seem to be the case. Is there a way to remedy this?",,"['probability', 'probability-theory', 'permutations']"
75,How to understand the exchangeable $\sigma$-algebra?,How to understand the exchangeable -algebra?,\sigma,"Suppose there are $(\Omega,\mathcal F,\mathbb P)$ and r.v. $\xi_i$(i$\ge$1) $\xi_i:(\Omega,\mathcal F,\mathbb P)\to(\mathbb R,\mathcal B,\mu)$ $A\in$ the exchangeable  $\sigma$-algebra $\mathcal E $ What does $\mathcal E$ mean? In my textbook ,there is a descriptive definition:the occurrence of $A$ is not affected by rearranging finitely many of $\xi_i$. I don't quite understand and I want a mathematical description: Does it mean: if $\omega\in A$,then $(\xi_1,\xi_2,\xi_3)(\omega)=(\xi_2,\xi_1,\xi_3)(\omega)$? (just an example) but this understanding has nothing to do with $A$,only the property of $\omega\in\Omega$.. In another textbook,the author first define a finite permutation $p$ in $\mathbb N$ then define a permutation $T_p$ in $\mathbb R^\infty$ by $(x_1,x_2,\dots)\to(x_{p(1)},x_{p(2)},\dots)$ $C\in\mathcal B^\infty$ is called a symmetry set if $C$ is  $T_p$  invariant for all $p$,the collection of all symmetry sets is called the exchangeable $\sigma$-algebra. What's the relationship of two exchangeable  $\sigma$-algebra? One in $\Omega$, one in $\mathbb R^\infty$.","Suppose there are $(\Omega,\mathcal F,\mathbb P)$ and r.v. $\xi_i$(i$\ge$1) $\xi_i:(\Omega,\mathcal F,\mathbb P)\to(\mathbb R,\mathcal B,\mu)$ $A\in$ the exchangeable  $\sigma$-algebra $\mathcal E $ What does $\mathcal E$ mean? In my textbook ,there is a descriptive definition:the occurrence of $A$ is not affected by rearranging finitely many of $\xi_i$. I don't quite understand and I want a mathematical description: Does it mean: if $\omega\in A$,then $(\xi_1,\xi_2,\xi_3)(\omega)=(\xi_2,\xi_1,\xi_3)(\omega)$? (just an example) but this understanding has nothing to do with $A$,only the property of $\omega\in\Omega$.. In another textbook,the author first define a finite permutation $p$ in $\mathbb N$ then define a permutation $T_p$ in $\mathbb R^\infty$ by $(x_1,x_2,\dots)\to(x_{p(1)},x_{p(2)},\dots)$ $C\in\mathcal B^\infty$ is called a symmetry set if $C$ is  $T_p$  invariant for all $p$,the collection of all symmetry sets is called the exchangeable $\sigma$-algebra. What's the relationship of two exchangeable  $\sigma$-algebra? One in $\Omega$, one in $\mathbb R^\infty$.",,"['real-analysis', 'probability', 'measure-theory']"
76,What is the probability that both roots of the equation $Ax^2 + Bx + C = 0$ are real?,What is the probability that both roots of the equation  are real?,Ax^2 + Bx + C = 0,"Given this problem as part of prep for a test.  We've done the same problem without A being a random variable, but I am completely stumped as to how to accomplish this one with three r.v.s I know the joint is $1/288$ and that $B^2>4AC$ but cannot convert this to a happy integral. Let $A$, $B$, and $C$ be independent random variables, uniformly distributed over $[0,4], [0,8]$, and $[0,9]$ respectively. What is the probability that both roots of the equation $Ax^2 + Bx + C = 0$ are real? Thanks,","Given this problem as part of prep for a test.  We've done the same problem without A being a random variable, but I am completely stumped as to how to accomplish this one with three r.v.s I know the joint is $1/288$ and that $B^2>4AC$ but cannot convert this to a happy integral. Let $A$, $B$, and $C$ be independent random variables, uniformly distributed over $[0,4], [0,8]$, and $[0,9]$ respectively. What is the probability that both roots of the equation $Ax^2 + Bx + C = 0$ are real? Thanks,",,['probability']
77,My data is not normally distributed: what can I do to estimate a tail probability?,My data is not normally distributed: what can I do to estimate a tail probability?,,"Continuing on from my earlier question , I'm attempting to analyse the data qualitatively. In the following plot, I make $10000$ samples where I count ""the number of clashes"".  I plot $n$ vs. the number of times $n$ clashes occurred. (The number of clashes is a measure of ""how wrong"" an attempted attack was [on the secret sharing scheme I'm looking at]). (Drawn using tikzDevice for R , then edited manually.) In R, it fails the shapiro.test , so it's not normally distributed: > shapiro.test(z[1:5000])      Shapiro-Wilk normality test  data:  z[1:5000] W = 0.9947, p-value = 1.597e-12 So: Q: How can I estimate the probability $p$ of $0$ clashes from the above distribution? It should be very small, around $10^{-14}$: I have a theoretical lower bound of $1.046 \times 10^{-14}$, and I expect it to be close to the actual value. I have made $10^{11}$ samples, and all had at least one clash. I attempted to fit an exponential curve to the left hand side (drawn above):  the curve is $$3.29 \times 10^{-12} \exp(0.56n)$$ which, when $n=0$ gives the estimate $\hat{p}=3.29 \times 10^{-16}$.  But I know that this estimate is off by around a factor of $100$, which makes me think this is not the best approach.  (Or maybe I should fit some other curve, or use more samples.  Or maybe this level of confidence is to be expected.) Addendum : I'm trying to show that $\mathrm{Pr}[0 \text{ clashes}]$ is small (say less than $10^{-8}$ or $10^{-9}$).  So the estimate doesn't need to be precise, but I need to have confidence in the estimate. The theoretical maximum number of clashes is $220$ (this number can be achieved). ""Do you know the statistical power of the Shapiro-Wilk test for such a large sample size?""  In short, no, I don't.  But we can compare the results to random data from a normal distribution: > shapiro.test(rnorm(5000, mean = mean(z), sd = sd(z)))      Shapiro-Wilk normality test  data:  rnorm(5000, mean = mean(z), sd = sd(z)) W = 0.9996, p-value = 0.4053 While the results fluctuate between runs, they don't seem comparable to my data. I also tried with fewer samples included and it didn't seem to ""help"". > shapiro.test(z[1:100])      Shapiro-Wilk normality test  data:  z[1:100] W = 0.9757, p-value = 0.06116 compared to > shapiro.test(rnorm(100, mean = mean(z), sd = sd(z)))      Shapiro-Wilk normality test  data:  rnorm(100, mean = mean(z), sd = sd(z)) W = 0.9845, p-value = 0.2932 (Here, it fluctuates quite a lot.) I'm capable of making around $10^{10}$ samples, if it would help.","Continuing on from my earlier question , I'm attempting to analyse the data qualitatively. In the following plot, I make $10000$ samples where I count ""the number of clashes"".  I plot $n$ vs. the number of times $n$ clashes occurred. (The number of clashes is a measure of ""how wrong"" an attempted attack was [on the secret sharing scheme I'm looking at]). (Drawn using tikzDevice for R , then edited manually.) In R, it fails the shapiro.test , so it's not normally distributed: > shapiro.test(z[1:5000])      Shapiro-Wilk normality test  data:  z[1:5000] W = 0.9947, p-value = 1.597e-12 So: Q: How can I estimate the probability $p$ of $0$ clashes from the above distribution? It should be very small, around $10^{-14}$: I have a theoretical lower bound of $1.046 \times 10^{-14}$, and I expect it to be close to the actual value. I have made $10^{11}$ samples, and all had at least one clash. I attempted to fit an exponential curve to the left hand side (drawn above):  the curve is $$3.29 \times 10^{-12} \exp(0.56n)$$ which, when $n=0$ gives the estimate $\hat{p}=3.29 \times 10^{-16}$.  But I know that this estimate is off by around a factor of $100$, which makes me think this is not the best approach.  (Or maybe I should fit some other curve, or use more samples.  Or maybe this level of confidence is to be expected.) Addendum : I'm trying to show that $\mathrm{Pr}[0 \text{ clashes}]$ is small (say less than $10^{-8}$ or $10^{-9}$).  So the estimate doesn't need to be precise, but I need to have confidence in the estimate. The theoretical maximum number of clashes is $220$ (this number can be achieved). ""Do you know the statistical power of the Shapiro-Wilk test for such a large sample size?""  In short, no, I don't.  But we can compare the results to random data from a normal distribution: > shapiro.test(rnorm(5000, mean = mean(z), sd = sd(z)))      Shapiro-Wilk normality test  data:  rnorm(5000, mean = mean(z), sd = sd(z)) W = 0.9996, p-value = 0.4053 While the results fluctuate between runs, they don't seem comparable to my data. I also tried with fewer samples included and it didn't seem to ""help"". > shapiro.test(z[1:100])      Shapiro-Wilk normality test  data:  z[1:100] W = 0.9757, p-value = 0.06116 compared to > shapiro.test(rnorm(100, mean = mean(z), sd = sd(z)))      Shapiro-Wilk normality test  data:  rnorm(100, mean = mean(z), sd = sd(z)) W = 0.9845, p-value = 0.2932 (Here, it fluctuates quite a lot.) I'm capable of making around $10^{10}$ samples, if it would help.",,"['probability', 'statistics', 'estimation', 'experimental-mathematics', 'distribution-tails']"
78,Probability of winning a baseball game,Probability of winning a baseball game,,Ok so here is my question.  If the Tigers (team A) win 66% of the games they play on Tuesdays and the Sharks (team B) win 55% of the games they play on Tuesdays.  Now when they play each other on a Tuesday what are the true chances of each team winning since they  both cannot win? Are these events considered disjoint events even though they are playing each other on a Tuesday?,Ok so here is my question.  If the Tigers (team A) win 66% of the games they play on Tuesdays and the Sharks (team B) win 55% of the games they play on Tuesdays.  Now when they play each other on a Tuesday what are the true chances of each team winning since they  both cannot win? Are these events considered disjoint events even though they are playing each other on a Tuesday?,,['probability']
79,"Biology: How to find the probability of randomly generating multiple, sequentially identical sets","Biology: How to find the probability of randomly generating multiple, sequentially identical sets",,"If I randomly generate a substring (example ""ATGCAGC"") with equal probability (1/X where X=4) for each digit with length (L) digits: What is the formula for finding the probability (P) of randomly generating that sequence (T) times, given a total string length (N)? Example: Given ""ATGCAGC"" string length L=7, number of possible characters X=4 with equal probability of being randomly generated 1/X. In a case where N characters are generated, what is the probability that an exact substring with length L will occur T times? If I have randomly, sequentially generated N=7000 characters, what is the probability that any exact substring length L=7 ""ATGCAGC"" will occur T=2,3,4... times? P is my dependent variable. L, T, N, X are independent. In terms of dice: Example: If I sequentially roll a X=6 sided die N=7000 times: What is the P=probability I will roll the die sequentially the same (1,4,6,5,3,2,3) with sequence length L=7 for T=2 sequentially identical occurrences in the N=7000 sequential rolls of a single die? What is the probability in 7000 rolls I will have any 2 runs of 7 throws that have an exact sequential match? Example: (1,4,6,5,3,2,3 on rolls 201-207)  and (1,4,6,5,3,2,3) on rolls 5001-5007. It could be any number of (T) occurrences, on any roll numbers in (N) total die rolls. I am specifically solving for the probability, given any values for the independent variables. Overlapping or non-overlapping substrings or both are great. My question is related to ( How many times will a consecutive sequence of throws randomly appear if I throw a four-sided die N times? )","If I randomly generate a substring (example ""ATGCAGC"") with equal probability (1/X where X=4) for each digit with length (L) digits: What is the formula for finding the probability (P) of randomly generating that sequence (T) times, given a total string length (N)? Example: Given ""ATGCAGC"" string length L=7, number of possible characters X=4 with equal probability of being randomly generated 1/X. In a case where N characters are generated, what is the probability that an exact substring with length L will occur T times? If I have randomly, sequentially generated N=7000 characters, what is the probability that any exact substring length L=7 ""ATGCAGC"" will occur T=2,3,4... times? P is my dependent variable. L, T, N, X are independent. In terms of dice: Example: If I sequentially roll a X=6 sided die N=7000 times: What is the P=probability I will roll the die sequentially the same (1,4,6,5,3,2,3) with sequence length L=7 for T=2 sequentially identical occurrences in the N=7000 sequential rolls of a single die? What is the probability in 7000 rolls I will have any 2 runs of 7 throws that have an exact sequential match? Example: (1,4,6,5,3,2,3 on rolls 201-207)  and (1,4,6,5,3,2,3) on rolls 5001-5007. It could be any number of (T) occurrences, on any roll numbers in (N) total die rolls. I am specifically solving for the probability, given any values for the independent variables. Overlapping or non-overlapping substrings or both are great. My question is related to ( How many times will a consecutive sequence of throws randomly appear if I throw a four-sided die N times? )",,"['probability', 'dice', 'biology']"
80,"At what point discrepancy, in the NBA, does it make sense to milk the shot clock?","At what point discrepancy, in the NBA, does it make sense to milk the shot clock?",,"I am admittedly not great with probabilities, so I am soliciting the help of the community. I am watching game 3 of the NBA Finals and I am trying to work out when it makes sense to milk the shot clock. I started by trying to work out Miami's possible attempts given different possession times. e.g. If San Antonio is able to maintain an average of 21 seconds per possession, how many attempts does that leave Miami? So I took, Time Remaining/21 + Miami's Average Possession. That is where I got lost. How can I model situations with multiple variables? What sort of insight is there on this problem. I realize it is harder than can be explained in a few paragraphs, but any resources would be great.","I am admittedly not great with probabilities, so I am soliciting the help of the community. I am watching game 3 of the NBA Finals and I am trying to work out when it makes sense to milk the shot clock. I started by trying to work out Miami's possible attempts given different possession times. e.g. If San Antonio is able to maintain an average of 21 seconds per possession, how many attempts does that leave Miami? So I took, Time Remaining/21 + Miami's Average Possession. That is where I got lost. How can I model situations with multiple variables? What sort of insight is there on this problem. I realize it is harder than can be explained in a few paragraphs, but any resources would be great.",,"['probability', 'recreational-mathematics', 'mathematical-modeling']"
81,The Last Man Standing,The Last Man Standing,,"This is my second question following this post . Three players are playing a game. They all have small amounts of   money, let say: player 1 has $\$a$, player 2 has $\$b$, and player 3   has $\$c$, where $a<b<c$. The probability of each player wins each   turn of the game is $p$ for player 1, $q$ for player 2, $r$ for player   3, and $s$ for having draw, where $p+q+r+s=1$. The losers will transfer a dollar ($\$1$) to the winner for each turn. The game ends until one   player has all the money. What is the probability of each player going   bankrupt? What is the expected number of turns so that only one player   left as the winner? Suppose that they play blackjack, if player 1 gets 20 points, player 2 gets 19 points, and player 3 gets 18 points, then the winner of that turn is player 1, so the other two players must pay a dollar to the player 1. If there are two players get, for example, 19 points and the another player gets 18 points, then that turn is considered draw. If they all get 19 points, this is also considered draw. If one player loses all the money, then he will stop playing and only two player will continue the game with probability of winning for each player is $x$ and $y$, also the probability of draw is $z$ . Each turn will be repeated until one player has all the money. To be honest, I can't answer this question and I really don't get it. I left my answer sheet totally empty for this one. (─‿‿─) Please help me to answer this question and provide a simple explanation about the answer you submit. Every answer would be greatly appreciated.","This is my second question following this post . Three players are playing a game. They all have small amounts of   money, let say: player 1 has $\$a$, player 2 has $\$b$, and player 3   has $\$c$, where $a<b<c$. The probability of each player wins each   turn of the game is $p$ for player 1, $q$ for player 2, $r$ for player   3, and $s$ for having draw, where $p+q+r+s=1$. The losers will transfer a dollar ($\$1$) to the winner for each turn. The game ends until one   player has all the money. What is the probability of each player going   bankrupt? What is the expected number of turns so that only one player   left as the winner? Suppose that they play blackjack, if player 1 gets 20 points, player 2 gets 19 points, and player 3 gets 18 points, then the winner of that turn is player 1, so the other two players must pay a dollar to the player 1. If there are two players get, for example, 19 points and the another player gets 18 points, then that turn is considered draw. If they all get 19 points, this is also considered draw. If one player loses all the money, then he will stop playing and only two player will continue the game with probability of winning for each player is $x$ and $y$, also the probability of draw is $z$ . Each turn will be repeated until one player has all the money. To be honest, I can't answer this question and I really don't get it. I left my answer sheet totally empty for this one. (─‿‿─) Please help me to answer this question and provide a simple explanation about the answer you submit. Every answer would be greatly appreciated.",,"['probability', 'combinatorics', 'game-theory']"
82,Closed formula for mean,Closed formula for mean,,"Suppose we have the i.i.d. random variables $X_{11}, X_{12},\ldots, X_{nn}$, such that each $X_{ij}$ has standard normal distribution $N(0,1)$, with mean $0$ and variance $1$. Given some integer $k>0$, is there some closed formula for the mean $$E\Big(\sum_{i_1,i_2,\ldots,i_k=1}^nX_{i_1i_2}X_{i_2i_3}\ldots X_{i_{k-1}i_k}X_{i_ki_1}\Big)$$ ? I worked the cases for $k=1,2,3,4$, which gave, respectively, $0,n,0,8n^2+3n$. I'm not certain about the last one, but I know the mean is $0$ if $k$ is odd. Just for clarification, this is the mean of the trace of $X^k$, where $X$ is a random matrix (it's a square matrix) with entries $X_{ij}$, i.e.,  $$X = \left[ \begin{array}{ccc} X_{11} & \ldots & X_{1n}\\ \vdots & \ddots & \vdots\\ X_{n1} & \ldots & X_{nn}\\ \end{array} \right]. $$ Any insight will be helpful, thanks.","Suppose we have the i.i.d. random variables $X_{11}, X_{12},\ldots, X_{nn}$, such that each $X_{ij}$ has standard normal distribution $N(0,1)$, with mean $0$ and variance $1$. Given some integer $k>0$, is there some closed formula for the mean $$E\Big(\sum_{i_1,i_2,\ldots,i_k=1}^nX_{i_1i_2}X_{i_2i_3}\ldots X_{i_{k-1}i_k}X_{i_ki_1}\Big)$$ ? I worked the cases for $k=1,2,3,4$, which gave, respectively, $0,n,0,8n^2+3n$. I'm not certain about the last one, but I know the mean is $0$ if $k$ is odd. Just for clarification, this is the mean of the trace of $X^k$, where $X$ is a random matrix (it's a square matrix) with entries $X_{ij}$, i.e.,  $$X = \left[ \begin{array}{ccc} X_{11} & \ldots & X_{1n}\\ \vdots & \ddots & \vdots\\ X_{n1} & \ldots & X_{nn}\\ \end{array} \right]. $$ Any insight will be helpful, thanks.",,"['probability', 'random-variables', 'random-matrices']"
83,Maximum Entropy / Principle of Insufficient Reason,Maximum Entropy / Principle of Insufficient Reason,,"I have a question about the maximum entropy principle and its implications.  Here's the problem that motivates my question: Suppose, for instance, I have a random variable $X$ which takes on the value +1 with probability p and -1 with probability 1-p.  Knowing nothing else about the distribution, we might decide to maximize $H(p)=-\sum p_i \log p_i = -(p \log(p) + (1-p) \log (1-p))$ to determine p, which is pretty easy to do with basic calculus- we wind up with $p^*=\frac12$, which is the same result dictated by the Principle of Insufficient Reason.  It seems intuitive to me (this is where I think things start to get somewhat un-rigorous), that another way to think about this is to imagine that $p$ is itself a random variable drawn from $P  \approx \text{Uniform(0,1)}$, and so $p^*$ is simply the ""most likely"" value of $P$, $\mathbb{E}[P]=\frac12$, which agrees with our prior result. Now, here's my actual question.  Suppose I have some solid theoretical reason to assume that $X$ is more likely to assume +1 than -1, i.e. $p>1-p$.  When I try to maximize $H(P)$ under the constraint that $p>1/2$, the problem becomes ill-posed- the function approaches its maximum at the boundary condition, which it can never reach- the ""answer"" is $p^* = \frac12 + \epsilon$.  But, under the other interpretation holding p as a random variable, this problem can be posed as $p^* = \mathbb{E}[\max(P,1-P)]=\frac34$, which is a well-defined answer and seems like a ""reasonable"" solution: if we know that $p^*$ is between 1/2 and 1, then the midpoint of the two can't be an unreasonable guess. Why does this seeming paradox occur?  Is there any theoretical answer that allows us to assign a ""nice"" probability like $\frac23$ or $\frac34$ to the question, or are we stuck with stating that the BC $p>1-p$ adds no new information, since the optimal entropy is still essentially the same?","I have a question about the maximum entropy principle and its implications.  Here's the problem that motivates my question: Suppose, for instance, I have a random variable $X$ which takes on the value +1 with probability p and -1 with probability 1-p.  Knowing nothing else about the distribution, we might decide to maximize $H(p)=-\sum p_i \log p_i = -(p \log(p) + (1-p) \log (1-p))$ to determine p, which is pretty easy to do with basic calculus- we wind up with $p^*=\frac12$, which is the same result dictated by the Principle of Insufficient Reason.  It seems intuitive to me (this is where I think things start to get somewhat un-rigorous), that another way to think about this is to imagine that $p$ is itself a random variable drawn from $P  \approx \text{Uniform(0,1)}$, and so $p^*$ is simply the ""most likely"" value of $P$, $\mathbb{E}[P]=\frac12$, which agrees with our prior result. Now, here's my actual question.  Suppose I have some solid theoretical reason to assume that $X$ is more likely to assume +1 than -1, i.e. $p>1-p$.  When I try to maximize $H(P)$ under the constraint that $p>1/2$, the problem becomes ill-posed- the function approaches its maximum at the boundary condition, which it can never reach- the ""answer"" is $p^* = \frac12 + \epsilon$.  But, under the other interpretation holding p as a random variable, this problem can be posed as $p^* = \mathbb{E}[\max(P,1-P)]=\frac34$, which is a well-defined answer and seems like a ""reasonable"" solution: if we know that $p^*$ is between 1/2 and 1, then the midpoint of the two can't be an unreasonable guess. Why does this seeming paradox occur?  Is there any theoretical answer that allows us to assign a ""nice"" probability like $\frac23$ or $\frac34$ to the question, or are we stuck with stating that the BC $p>1-p$ adds no new information, since the optimal entropy is still essentially the same?",,"['probability', 'probability-theory']"
84,Random Variable Vs. Probability Function Intuition?,Random Variable Vs. Probability Function Intuition?,,"In a book on probability I'm reading they begin by defining random experiment, outcome, sample space & event, then using these notions they define & a probability space in terms of the sample space, a sigma field & a probability function. After about 80 pages of working with this theory, i.e. Bayes theorem, conditional probability etc... they introduce the notion of a random variable & the distribution function of a random variable. They give the impression that a random variable is a function of the outcomes, & that it is defined independently of the notion of a probability function, which this stack answer seems to imply: Probability measures assign values (probabilities) to sets in the $\sigma$-algebra $\mathcal{A}$. On the other hand, random variables are functions $f\colon \Omega\to E$ that are measurable in this sense: If $B \in \mathcal{E}$, then $f^{-1}(B) \in \mathcal{A}$. https://math.stackexchange.com/a/124504 yet other sources I've seen seem to conflate the two notions or even imply they mean the same thing :( What is a random variable a) intuitively, b) mathematically & c) in a way that distinguishes it from a probability function, i.e. a nice intuitive example of a situation where you can't just use a probability function you need a random variable. I can't believe I got through a course on probability without understanding this :( Thanks!","In a book on probability I'm reading they begin by defining random experiment, outcome, sample space & event, then using these notions they define & a probability space in terms of the sample space, a sigma field & a probability function. After about 80 pages of working with this theory, i.e. Bayes theorem, conditional probability etc... they introduce the notion of a random variable & the distribution function of a random variable. They give the impression that a random variable is a function of the outcomes, & that it is defined independently of the notion of a probability function, which this stack answer seems to imply: Probability measures assign values (probabilities) to sets in the $\sigma$-algebra $\mathcal{A}$. On the other hand, random variables are functions $f\colon \Omega\to E$ that are measurable in this sense: If $B \in \mathcal{E}$, then $f^{-1}(B) \in \mathcal{A}$. https://math.stackexchange.com/a/124504 yet other sources I've seen seem to conflate the two notions or even imply they mean the same thing :( What is a random variable a) intuitively, b) mathematically & c) in a way that distinguishes it from a probability function, i.e. a nice intuitive example of a situation where you can't just use a probability function you need a random variable. I can't believe I got through a course on probability without understanding this :( Thanks!",,['probability']
85,How many times do you have to toss a coin so that the probability that #heads = #tails is 0.01?,How many times do you have to toss a coin so that the probability that #heads = #tails is 0.01?,,"I thought it would be something like: $Binomial(n, \frac{1}{2})$. So $0.01 = \binom{n}{\frac{n}{2}}(\frac{1}{2})^{\frac{n}{2}}(\frac{1}{2})^{\frac{n}{2}}$, because half of $n$ should be heads and the other half should be tails.","I thought it would be something like: $Binomial(n, \frac{1}{2})$. So $0.01 = \binom{n}{\frac{n}{2}}(\frac{1}{2})^{\frac{n}{2}}(\frac{1}{2})^{\frac{n}{2}}$, because half of $n$ should be heads and the other half should be tails.",,"['probability', 'probability-distributions', 'binomial-theorem']"
86,Stationary Distribution of Doubly Stochastic Markov Chain [duplicate],Stationary Distribution of Doubly Stochastic Markov Chain [duplicate],,"This question already has answers here : Doubly stochastic matrix proof (2 answers) Closed 4 years ago . For a doubly stochastic markov process defined by a n by n transition matrix, does the stationary distribution go to p = 1/n for each state?  If so, why?","This question already has answers here : Doubly stochastic matrix proof (2 answers) Closed 4 years ago . For a doubly stochastic markov process defined by a n by n transition matrix, does the stationary distribution go to p = 1/n for each state?  If so, why?",,['probability']
87,Random algebraic numbers are linearly disjoint almost surely?,Random algebraic numbers are linearly disjoint almost surely?,,"It is well-known that if one considers a “random” monic polynomial of fixed degree, say $X^n+\sum_{k=0}^{n-1}a_kX^k$ where $(a_0,a_1,\ldots, a_n)$ is drawn from the discrete uniform distribution on $[-N,N]^{n+1}$, then this polynomial will be irreducible and have Galois group $S_n$ “almost surely”, i.e. the  probability of this event tends to $1$ when $N\to \infty$. Now, suppose one considers two random monic polynomials  $P=X^n+\sum_{k=0}^{n-1}a_kX^k$ and $Q=X^m+\sum_{k=0}^{n-1}b_kX^k$ where $(a_0,a_1,\ldots, a_n,b_0,\ldots,b_m)$ is drawn from the discrete uniform distribution on $[-N,N]^{n+m+2}$. Is it also true that for any root $\alpha$ of $P$ and any root $\beta$ of $\mathbb Q$, the extensions ${\mathbb Q}(\alpha)$ and ${\mathbb Q}(\beta)$ will be linearly disjoint over $\mathbb Q$ “almost surely” in the sense above ?","It is well-known that if one considers a “random” monic polynomial of fixed degree, say $X^n+\sum_{k=0}^{n-1}a_kX^k$ where $(a_0,a_1,\ldots, a_n)$ is drawn from the discrete uniform distribution on $[-N,N]^{n+1}$, then this polynomial will be irreducible and have Galois group $S_n$ “almost surely”, i.e. the  probability of this event tends to $1$ when $N\to \infty$. Now, suppose one considers two random monic polynomials  $P=X^n+\sum_{k=0}^{n-1}a_kX^k$ and $Q=X^m+\sum_{k=0}^{n-1}b_kX^k$ where $(a_0,a_1,\ldots, a_n,b_0,\ldots,b_m)$ is drawn from the discrete uniform distribution on $[-N,N]^{n+m+2}$. Is it also true that for any root $\alpha$ of $P$ and any root $\beta$ of $\mathbb Q$, the extensions ${\mathbb Q}(\alpha)$ and ${\mathbb Q}(\beta)$ will be linearly disjoint over $\mathbb Q$ “almost surely” in the sense above ?",,"['probability', 'polynomials', 'commutative-algebra']"
88,Uniform and Chi-square distributions,Uniform and Chi-square distributions,,"I am trying to solve this problem: Let $X \sim U[0,1]$. Then $Y = -2\log X$ is $\chi$-square distribution with parameter $2$. I proceeded this way, $$P(Y \leq y) = P(-2\log X \leq y) = P(X \leq \exp(-y/2))$$ $$F_X(x) = \frac{x-a}{b-a},\quad a \leq x <b$$ $$\Rightarrow F_X(\exp(-y/2)) = \exp(-y/2),\quad 0 \leq x <1.$$ Now I found the PDF: $$f(y) = -1/2\exp(-y/2)$$ But the $\chi$-square PDF with parameter $2$ is given by $$f(y) = 1/2\exp(-y/2)$$ I am not sure why I get the negative sign. Any thoughts? Thanks","I am trying to solve this problem: Let $X \sim U[0,1]$. Then $Y = -2\log X$ is $\chi$-square distribution with parameter $2$. I proceeded this way, $$P(Y \leq y) = P(-2\log X \leq y) = P(X \leq \exp(-y/2))$$ $$F_X(x) = \frac{x-a}{b-a},\quad a \leq x <b$$ $$\Rightarrow F_X(\exp(-y/2)) = \exp(-y/2),\quad 0 \leq x <1.$$ Now I found the PDF: $$f(y) = -1/2\exp(-y/2)$$ But the $\chi$-square PDF with parameter $2$ is given by $$f(y) = 1/2\exp(-y/2)$$ I am not sure why I get the negative sign. Any thoughts? Thanks",,"['probability', 'random-variables']"
89,Sum of Wishart matrices,Sum of Wishart matrices,,"Considering two matrices, $H_1$ and $H_2$, that are independent of each other and follows complex wishart distributions as $\mathcal{CW} _m(n_1,\Sigma_1)$ and $\mathcal{CW} _m(n_2,\Sigma_2)$ respectively. Now considering the sum \begin{equation}  Z=H_1+H_2. \end{equation} Will $Z$ also follow a Wishart distribution? I have only been able to find one example of something like this, in this paper , where the two matrices only differ in degrees of freedom. Is there a similar expression for when the degrees of freedom, $n $, but also the covariance matrix, $\Sigma$, differ?","Considering two matrices, $H_1$ and $H_2$, that are independent of each other and follows complex wishart distributions as $\mathcal{CW} _m(n_1,\Sigma_1)$ and $\mathcal{CW} _m(n_2,\Sigma_2)$ respectively. Now considering the sum \begin{equation}  Z=H_1+H_2. \end{equation} Will $Z$ also follow a Wishart distribution? I have only been able to find one example of something like this, in this paper , where the two matrices only differ in degrees of freedom. Is there a similar expression for when the degrees of freedom, $n $, but also the covariance matrix, $\Sigma$, differ?",,"['probability', 'probability-theory', 'probability-distributions', 'random-matrices']"
90,Rumors told between $n+1$ people,Rumors told between  people,n+1,"In a town of $(n + 1)$ inhabitants, a person tells a rumor to a second person, who in turn repeats it to a third person, etc. At each step the recipient of the rumor is chosen at random from the $n$ people available. (a) Find the probability that the rumor will be told $r$ times without: (i.) returning to the originator; (ii.) being repeated to any person. Here's what I did: (i.) For the first person, the probability is $1$ because they are the originator and can not tell to themselves. For the second, we can tell it to one of the $(n-1)$ people because they can't tell it to themselves nor to the originator, and so for the third. Thus: $1 * {(\frac{n-1}{n})}^{r-1}$ . Note that considering that a person can not tell it to themselves then I devided the fraction by $n$ and not $n+1$ . (ii.) For the first person, again, we have probability of $1$ . Then $n-1$ options for the second (not to themselves, and not to the orignator: $n+1 - 1 -1 = n-1$ ), then $n-2$ for the third (not to themselves, not to the first, and not to the previous: $n+1 - 1 - 1 -1 = n-2$ . etc r times. Is this good?","In a town of inhabitants, a person tells a rumor to a second person, who in turn repeats it to a third person, etc. At each step the recipient of the rumor is chosen at random from the people available. (a) Find the probability that the rumor will be told times without: (i.) returning to the originator; (ii.) being repeated to any person. Here's what I did: (i.) For the first person, the probability is because they are the originator and can not tell to themselves. For the second, we can tell it to one of the people because they can't tell it to themselves nor to the originator, and so for the third. Thus: . Note that considering that a person can not tell it to themselves then I devided the fraction by and not . (ii.) For the first person, again, we have probability of . Then options for the second (not to themselves, and not to the orignator: ), then for the third (not to themselves, not to the first, and not to the previous: . etc r times. Is this good?",(n + 1) n r 1 (n-1) 1 * {(\frac{n-1}{n})}^{r-1} n n+1 1 n-1 n+1 - 1 -1 = n-1 n-2 n+1 - 1 - 1 -1 = n-2,['probability']
91,Dynamic programming problem,Dynamic programming problem,,"A man is in a room, with $n$ passages leading out. For passage $i$, $i = 1,...,n$, there is probability $p_i$ of escaping, $q_i$ of being killed and $r_i$ of returning to the room, where $p_i + q_i + r_i = 1$. In which order should the man try the passages so as to maximise his chances of eventual escape? I am trying to formulate this as a dynamic programming problem, but am not sure how to associate costs with it. I am also not sure if I need to use discounting for the ""death"" scenario. Any help would be greatly appreciated.","A man is in a room, with $n$ passages leading out. For passage $i$, $i = 1,...,n$, there is probability $p_i$ of escaping, $q_i$ of being killed and $r_i$ of returning to the room, where $p_i + q_i + r_i = 1$. In which order should the man try the passages so as to maximise his chances of eventual escape? I am trying to formulate this as a dynamic programming problem, but am not sure how to associate costs with it. I am also not sure if I need to use discounting for the ""death"" scenario. Any help would be greatly appreciated.",,"['probability', 'dynamic-programming']"
92,When does infinite inclusion-exclusion work if $\sum_n P(A_n) < \infty$?,When does infinite inclusion-exclusion work if ?,\sum_n P(A_n) < \infty,"If $\sum_n P(A_n) = \infty$ then obviously we can't try to apply inclusion-exclusion directly to evaluate $P\left(\bigcup_n A_n\right)$, without taking limits. But what if $\sum_n P(A_n) < \infty$? Can we define $$P\left(\bigcup_n A_n\right) = \sum_{n_1 \in {\mathbb N}} P(A_{n_1}) - \sum_{\{n_1,n_2\} \in {\mathbb{N} \choose 2}} P(A_{n_1} \cap A_{n_2}) + \ldots $$ It seems that first all inner series must converge, and then perhaps the outer infinite sum must converge absolutely.  At any rate, when is the expression convergent and valid? In particular, what if the $A_n$ are independent?","If $\sum_n P(A_n) = \infty$ then obviously we can't try to apply inclusion-exclusion directly to evaluate $P\left(\bigcup_n A_n\right)$, without taking limits. But what if $\sum_n P(A_n) < \infty$? Can we define $$P\left(\bigcup_n A_n\right) = \sum_{n_1 \in {\mathbb N}} P(A_{n_1}) - \sum_{\{n_1,n_2\} \in {\mathbb{N} \choose 2}} P(A_{n_1} \cap A_{n_2}) + \ldots $$ It seems that first all inner series must converge, and then perhaps the outer infinite sum must converge absolutely.  At any rate, when is the expression convergent and valid? In particular, what if the $A_n$ are independent?",,"['probability', 'sequences-and-series']"
93,Surprising limit (probability of no two coinciding pairs),Surprising limit (probability of no two coinciding pairs),,"I stumbled upon this question by random chance. The motivation is kind of long, the question is pretty short; if you're just here for the limits, feel free to skip to the break. I'm taking five courses this semester, all of which meet on two days, and I happened to notice that all of my days seemed a little bit different. So I took a closer look at my schedule, and sure enough, none of my classes share the same two days. This struck me as very unlikely, so I decided to work out the probability of this occurring. Of course, in reality, there are all sorts of complicating factors that make certain distributions more favorable than others, but I decided to ignore that and just assume that the schedules were independent identically distributed variables. It was sort of convenient that there are also five days in a week, so the motivating question was this: In an $n$ day week, what is the probability that $n$ classes meeting twice each, do not have any pair that meets on the same two days? So I looked at the combinatorics, and I'm pretty sure the answer is the obnoxiously vertical formula $$\frac{ \displaystyle  { {n \choose 2} \choose n} n!}{ {n \choose 2}^n}$$ The idea here is that there are ${n \choose 2}$ possible schedules, so the list of all possible outcomes includes $n$ choices with repetition from this pool, considering the classes distinguishable. The list of desired outcomes chooses $n$ choices without repetition from this pool, and then assigns the schedules to the classes. [ Perhaps this is not right; if not I'd be interested in that, too, but my question for you all is really about this expression, not my class situation :) ] Now I knew by working out by hand that $n=3$ gives about 22% and $n=4$ gives about 28%, and I computed my actual situation at about 30%. Monotone increasing is what I expected. After all, you have dramatically more ability to separate the classes during longer weeks. I also expected that this effect would quickly dominate the complication that more classes are being added in. But the picture that arises for (larger) small $n$ made it pretty clear that I was wrong . When I was playing around in WolframAlpha, I found the limit $$\lim_{n\to\infty}\frac{ \displaystyle  { {n \choose 2} \choose n} n!}{ {n \choose 2}^n} = \frac{1}{e}$$ That caught me off guard. I immediately thought of Stirling's approximation, but I can't make it fit, since in Stirling $e$ is raised to the $n^\text{th}$. Admittedly I don't know a lot of special limits, but writing it out in terms of factorials seems to get nowhere near the definition of $e$. Is there an elementary explanation for this limit? Bonus question: ""choose $2$"" seems to be a pretty special circumstance: if the twos are replaced by ones, the limit becomes $0$, and if the twos are replaced by threes or fours, the limit becomes $1$. My guess is that with the right explanation of the interesting case, the reason for these will become pretty obvious.","I stumbled upon this question by random chance. The motivation is kind of long, the question is pretty short; if you're just here for the limits, feel free to skip to the break. I'm taking five courses this semester, all of which meet on two days, and I happened to notice that all of my days seemed a little bit different. So I took a closer look at my schedule, and sure enough, none of my classes share the same two days. This struck me as very unlikely, so I decided to work out the probability of this occurring. Of course, in reality, there are all sorts of complicating factors that make certain distributions more favorable than others, but I decided to ignore that and just assume that the schedules were independent identically distributed variables. It was sort of convenient that there are also five days in a week, so the motivating question was this: In an $n$ day week, what is the probability that $n$ classes meeting twice each, do not have any pair that meets on the same two days? So I looked at the combinatorics, and I'm pretty sure the answer is the obnoxiously vertical formula $$\frac{ \displaystyle  { {n \choose 2} \choose n} n!}{ {n \choose 2}^n}$$ The idea here is that there are ${n \choose 2}$ possible schedules, so the list of all possible outcomes includes $n$ choices with repetition from this pool, considering the classes distinguishable. The list of desired outcomes chooses $n$ choices without repetition from this pool, and then assigns the schedules to the classes. [ Perhaps this is not right; if not I'd be interested in that, too, but my question for you all is really about this expression, not my class situation :) ] Now I knew by working out by hand that $n=3$ gives about 22% and $n=4$ gives about 28%, and I computed my actual situation at about 30%. Monotone increasing is what I expected. After all, you have dramatically more ability to separate the classes during longer weeks. I also expected that this effect would quickly dominate the complication that more classes are being added in. But the picture that arises for (larger) small $n$ made it pretty clear that I was wrong . When I was playing around in WolframAlpha, I found the limit $$\lim_{n\to\infty}\frac{ \displaystyle  { {n \choose 2} \choose n} n!}{ {n \choose 2}^n} = \frac{1}{e}$$ That caught me off guard. I immediately thought of Stirling's approximation, but I can't make it fit, since in Stirling $e$ is raised to the $n^\text{th}$. Admittedly I don't know a lot of special limits, but writing it out in terms of factorials seems to get nowhere near the definition of $e$. Is there an elementary explanation for this limit? Bonus question: ""choose $2$"" seems to be a pretty special circumstance: if the twos are replaced by ones, the limit becomes $0$, and if the twos are replaced by threes or fours, the limit becomes $1$. My guess is that with the right explanation of the interesting case, the reason for these will become pretty obvious.",,"['probability', 'combinatorics', 'limits', 'recreational-mathematics']"
94,Probability of student getting 100 in a test given some conditions,Probability of student getting 100 in a test given some conditions,,"A student which knows nothing, went to a test includes 6 questions with answers 'yes' or 'no' only. Find the probability that: a.The student got 100 b.The student got 100 if he knew there are 3 question with answer yes and 3 with answer no. c.The student got 100 if he knew (I) there are 3 question with answer yes and 3 with answer no (II) doesn't exist sequence of 3 question with same answer (e.g answers for 3,4,5 are no and for 1,2,6 yes). Let's define the following events: $A-\text{student got 100},B-\text{student knows there are 3 yes asnwers and 3 no's},C-\text{Doesn't exist sequence of 3 same answers}$ about a: It seems clear that probability for a correct answer is $\frac 1 2$ ,and the answers are independent 'bernouli tests' so the probability is $\frac 1 {64}$ . About B: I think I need to use definition of conditioned probability ( $P(A\mid B)=\frac{P(A\cap B)}{P(B)}$ ) but I don't $P(B)$ . I assume that $P(A\cap B)$ is binomial, means choosing 3 of 6 questions and multiplying by $(\frac 1 2)^3\cdot (\frac 1 2)^3$ getting $P(A\cap B)=\frac 5 {16}$ . About C: I think its almost the same but here I don't know both $P(C)$ and $P((A\cap B)\cap C)$ . I'll be glad for help finding $P(B),P(C),P(A\cap B\cap C)$ .","A student which knows nothing, went to a test includes 6 questions with answers 'yes' or 'no' only. Find the probability that: a.The student got 100 b.The student got 100 if he knew there are 3 question with answer yes and 3 with answer no. c.The student got 100 if he knew (I) there are 3 question with answer yes and 3 with answer no (II) doesn't exist sequence of 3 question with same answer (e.g answers for 3,4,5 are no and for 1,2,6 yes). Let's define the following events: about a: It seems clear that probability for a correct answer is ,and the answers are independent 'bernouli tests' so the probability is . About B: I think I need to use definition of conditioned probability ( ) but I don't . I assume that is binomial, means choosing 3 of 6 questions and multiplying by getting . About C: I think its almost the same but here I don't know both and . I'll be glad for help finding .","A-\text{student got 100},B-\text{student knows there are 3 yes asnwers and 3 no's},C-\text{Doesn't exist sequence of 3 same answers} \frac 1 2 \frac 1 {64} P(A\mid B)=\frac{P(A\cap B)}{P(B)} P(B) P(A\cap B) (\frac 1 2)^3\cdot (\frac 1 2)^3 P(A\cap B)=\frac 5 {16} P(C) P((A\cap B)\cap C) P(B),P(C),P(A\cap B\cap C)",[]
95,Suggestions for learning probability and statistics,Suggestions for learning probability and statistics,,"The Short question: Where can I find a book for probability and statistics book that teaches them  from  scratch in a rigorous (very important condition)  way ? The book must not be elementary, but it has to start from scratch.( For example, I think Lang/Hungerford algebra begin by defining what a group is, in that sense they start from scratch.) The long question: I only took an engineering course in probability and statistics. In my opinion, it is very louzy/non-rigorous. You may assume, I have no knowledge of probability and statistics. I have to take an independent study statistics course this year. I am allowed to choose a book for the course. It has to be a statistics course. My instructor assumes I know probability because I took the course mentioned above.( I admit I  have a poor understanding of probability and this irritates me a lot) . I'd like ato have a book that is: 1) Rigorous 2) It has a significant statistics part 3)It teaches the amount of probability needed to to do statistics","The Short question: Where can I find a book for probability and statistics book that teaches them  from  scratch in a rigorous (very important condition)  way ? The book must not be elementary, but it has to start from scratch.( For example, I think Lang/Hungerford algebra begin by defining what a group is, in that sense they start from scratch.) The long question: I only took an engineering course in probability and statistics. In my opinion, it is very louzy/non-rigorous. You may assume, I have no knowledge of probability and statistics. I have to take an independent study statistics course this year. I am allowed to choose a book for the course. It has to be a statistics course. My instructor assumes I know probability because I took the course mentioned above.( I admit I  have a poor understanding of probability and this irritates me a lot) . I'd like ato have a book that is: 1) Rigorous 2) It has a significant statistics part 3)It teaches the amount of probability needed to to do statistics",,"['probability', 'statistics', 'reference-request']"
96,"5 cars, 4 parking places. Derangements and permutations with fixed points","5 cars, 4 parking places. Derangements and permutations with fixed points",,"I found an exercise in combinatorics: In the parking of a building, there a re five parking spots, with their owner cars assigned   to them. One day only four cars arrived. In how many ways can they park so that not one cars    parks on their corresponding spot? So I think the following way: consider the missing car. It may arrive and park on its own parking spot, there are $5\cdot D_4$ ways of doing that, where $D_n$ is the number of derangements of $n$-element set, or it may arrive and find that his place is already taken. Then it takes someone other's place, thus making a complete derangement of 5 element set. So the total number is $5\cdot D_4+D_5$. Am I thinking correctly? The real problem I have with this is that I found it in some early pop-quiz some teacher gave during the introduction to probability class. Isn't there an easier way?","I found an exercise in combinatorics: In the parking of a building, there a re five parking spots, with their owner cars assigned   to them. One day only four cars arrived. In how many ways can they park so that not one cars    parks on their corresponding spot? So I think the following way: consider the missing car. It may arrive and park on its own parking spot, there are $5\cdot D_4$ ways of doing that, where $D_n$ is the number of derangements of $n$-element set, or it may arrive and find that his place is already taken. Then it takes someone other's place, thus making a complete derangement of 5 element set. So the total number is $5\cdot D_4+D_5$. Am I thinking correctly? The real problem I have with this is that I found it in some early pop-quiz some teacher gave during the introduction to probability class. Isn't there an easier way?",,"['probability', 'combinatorics', 'permutations', 'derangements']"
97,"Evaluation of ""concentration of measure function"" at zero.","Evaluation of ""concentration of measure function"" at zero.",,"Let $(X,d)$ be a metric space equipped with a probability measure $\mu$ (defined on the Borel $\sigma$-algebra on the topology induced by the metric $d$). We define the concentration function of the triple $X,d$ and $\mu$ as follows: $\alpha_{(X,d,\mu)}(r)=\sup\{1-\mu(A_r):A\subset X\text{ is measurable and }\mu(A)\geq 1/2\}$, $r\geq0$, where we define $A_r=\{x\in X:d(x,A)<r\}$ (EDIT: I adopt the convention $A_0=A$). I am interested in the value of the following (sparing you the elementary details that leads to the equality below): $\alpha_{(X,d,\mu)}(0)=\sup\{\mu(B):B\subset X\text{ is measurable and }\mu(B)\leq 1/2\}$ If there exists a measurable set $A\subset X$ such that $\mu(A)=1/2$, then it clearly is the case that $\alpha_{(X,d,\mu)}(0)=1/2$. If there is no set with measure $1/2$, then the situation is not so clear. I can easily find examples where there is no set of measure $1/2$ and $\alpha_{(X,d,\mu)}(0)$ is not $1/2$ (Dirac probability measure comes to mind), but I am unable to either prove (by finding an example ideally) or disprove that there exists a probability measure on some metric space such that no set has a measure of $1/2$ but $\alpha_{(X,d,\mu)}(0)=1/2$.","Let $(X,d)$ be a metric space equipped with a probability measure $\mu$ (defined on the Borel $\sigma$-algebra on the topology induced by the metric $d$). We define the concentration function of the triple $X,d$ and $\mu$ as follows: $\alpha_{(X,d,\mu)}(r)=\sup\{1-\mu(A_r):A\subset X\text{ is measurable and }\mu(A)\geq 1/2\}$, $r\geq0$, where we define $A_r=\{x\in X:d(x,A)<r\}$ (EDIT: I adopt the convention $A_0=A$). I am interested in the value of the following (sparing you the elementary details that leads to the equality below): $\alpha_{(X,d,\mu)}(0)=\sup\{\mu(B):B\subset X\text{ is measurable and }\mu(B)\leq 1/2\}$ If there exists a measurable set $A\subset X$ such that $\mu(A)=1/2$, then it clearly is the case that $\alpha_{(X,d,\mu)}(0)=1/2$. If there is no set with measure $1/2$, then the situation is not so clear. I can easily find examples where there is no set of measure $1/2$ and $\alpha_{(X,d,\mu)}(0)$ is not $1/2$ (Dirac probability measure comes to mind), but I am unable to either prove (by finding an example ideally) or disprove that there exists a probability measure on some metric space such that no set has a measure of $1/2$ but $\alpha_{(X,d,\mu)}(0)=1/2$.",,['probability']
98,Pick the highest of two (or $n$) independent uniformly distributed random numbers - average value?,Pick the highest of two (or ) independent uniformly distributed random numbers - average value?,n,"With ""random number"" I mean an independent uniformly distributed random number. One Picking one random number is easy: When I pick a random number from $x$ to $y$, the average value is $(x+y)/2$. Two I'm no maths expert, nevertheless I was able to work out a solution for whole numbers : When I pick the highest of two random whole numbers from $x$ to $y$ ... Let $n$ be the count of possible results $n = y - x + 1$. I looked at the probability of every single possible outcome and noticed an arithmetic sequence. I knew the sequence had to start with the rarest possibility: Rolling two times in a row the lowest value. $$p_1 = \frac{1}{n^2}$$ And I knew the sequence had to have a sum of 100 %. This made it possible to calculate the last, the $n$th, element: $$p_n = \frac{2}{n} - p_1$$ Based on that it was easy to calculate the difference between elements and subsequently the formula for the sequence. $$p_i = \frac{2in-2i-n+1}{n^3-n^2}$$ All I had to do now, was multiplying the probabilities with their respective values and sum this. $$ \sum_{i=1}^{n} \frac{2in-2i-n+1}{n^3-n^2}(x+i-1) $$ Questions What sort of distribution is this, how is it called? I can't name it and I can hardly search for it. What is the solution for picking the highest of two random real numbers from $x$ to $y$? I feel a little bit lost, because my approach fails, because there are infinite real numbers. What is the solution for picking the highest of $c$ random real numbers from $x$ to $y$?","With ""random number"" I mean an independent uniformly distributed random number. One Picking one random number is easy: When I pick a random number from $x$ to $y$, the average value is $(x+y)/2$. Two I'm no maths expert, nevertheless I was able to work out a solution for whole numbers : When I pick the highest of two random whole numbers from $x$ to $y$ ... Let $n$ be the count of possible results $n = y - x + 1$. I looked at the probability of every single possible outcome and noticed an arithmetic sequence. I knew the sequence had to start with the rarest possibility: Rolling two times in a row the lowest value. $$p_1 = \frac{1}{n^2}$$ And I knew the sequence had to have a sum of 100 %. This made it possible to calculate the last, the $n$th, element: $$p_n = \frac{2}{n} - p_1$$ Based on that it was easy to calculate the difference between elements and subsequently the formula for the sequence. $$p_i = \frac{2in-2i-n+1}{n^3-n^2}$$ All I had to do now, was multiplying the probabilities with their respective values and sum this. $$ \sum_{i=1}^{n} \frac{2in-2i-n+1}{n^3-n^2}(x+i-1) $$ Questions What sort of distribution is this, how is it called? I can't name it and I can hardly search for it. What is the solution for picking the highest of two random real numbers from $x$ to $y$? I feel a little bit lost, because my approach fails, because there are infinite real numbers. What is the solution for picking the highest of $c$ random real numbers from $x$ to $y$?",,"['probability', 'sequences-and-series', 'random']"
99,How far to look before line-of-sight will intersect a star,How far to look before line-of-sight will intersect a star,,"I was told this sort-of riddle by someone, having to do with the proof for the finite age of the universe, and I'm not sure how to approach the answer. Assuming that the entire universe is uniformly filled with sun-like stars (let the sun-radius be $R$) with a density of $N$ stars per cubic Mpc, how far out into space one would have to look, on average, before the line of sight intersects a star It seems like a simple calculation, but I can't seem to wrap my head around it.","I was told this sort-of riddle by someone, having to do with the proof for the finite age of the universe, and I'm not sure how to approach the answer. Assuming that the entire universe is uniformly filled with sun-like stars (let the sun-radius be $R$) with a density of $N$ stars per cubic Mpc, how far out into space one would have to look, on average, before the line of sight intersects a star It seems like a simple calculation, but I can't seem to wrap my head around it.",,['probability']
