,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Infinite product of infinite sums of formal power series: proof?,Infinite product of infinite sums of formal power series: proof?,,"Teaching a course on algebraic combinatorics has made me aware of a technical fact about formal power series that is used throughout the subject, but that I have never seen formally stated, let alone proved. Here is a representative particular case of the fact (see below for the general case): Infinite distributive law (positive integers version). An infinite product of infinite sums of formal power series -- e.g., of the form $\prod\limits_{i=1}^\infty \left( p_{i,0} + p_{i,1} + p_{i,2} + \cdots \right)$ , where each $p_{i,j}$ is a formal power series -- can be expanded into an infinite sum as long as certain reasonable conditions hold. Namely, if we assume that $p_{i,0} = 1$ for each $i$ , and if we assume that the family $\left(p_{i,k}\right)_{i\geq 1,\ k\geq 1}$ is summable (i.e., each monomial appears in only finitely many entries of this family), then the product $\prod\limits_{i=1}^\infty \left( p_{i,0} + p_{i,1} + p_{i,2} + \cdots \right)$ converges (in the coefficientwise topology on our ring of formal power series) and equals the sum of the products $p_{1, k_1} p_{2, k_2} p_{3, k_3} \cdots$ over all essentially finite sequences $\left(k_1, k_2, k_3, \ldots\right)$ of nonnegative integers. (""Essentially finite"" means that all but finitely many $i$ satisfy $k_i = 0$ . This is used for proving various standard generating function identities, such as \begin{align} \prod_{i=1}^\infty \dfrac{1}{1-x^i} = \prod_{i=1}^\infty \left(1 + x^i + x^{2i} + x^{3i} + \cdots\right) = \sum_{\lambda\text{ is a partition}} x^{\left|\lambda\right|} \end{align} or \begin{align} \prod_{i=1}^\infty \dfrac{1}{1-x_it} = \prod_{i=1}^\infty \left(1 + x_it + x_i^2t^2 + x_i^3t^3 + \cdots\right) = \sum_{n \in \mathbb{N}} h_n t^n \end{align} (where the latter equality is playing out in the ring of formal power series over the ring of symmetric functions in $x_1, x_2, x_3, \ldots$ , with $h_n$ standing for the $n$ -th complete homogeneous symmetric function). In most simple situations (including the two I just mentioned), it is not hard to forego the use of the infinite distributive law for a limiting argument that reduces the problem to finite products (for which a distributive law isn't too hard to show). However, as one dives deeper into partitions and symmetric functions, these epicycles start getting exhausting. It is clear that the infinite distributive law belongs into the textbooks; yet I have never seen it there. Thus I started writing out a proof for my lecture notes , but so far I have not had much success. Question. Is there a citeable source or a teachable proof for the infinite distributive law? Note that I am looking for a proof that isn't specific to single-variable power series; at least it needs to cover the case of symmetric functions. Ideally, the proof shouldn't be spread over multiple chapters of a treatise or use heavy topological lingo. That said, so far I haven't even found such a proof. Another complication is the fact that not all infinite products are indexed by positive integers. For example, the Cauchy formula in symmetric functions theory is about expanding $\prod\limits_{\left(i,j\right)\in\left\{1,2,3,\ldots\right\}^2} \dfrac{1}{1-x_iy_j}$ . While convergence of nets can make this general case not much harder than the integer-indexed one, I'd prefer not to rely on it too much. Here is the general version of infinite distributivity that I'm really aiming for (of course, there are even more general facts, but this one seems to suffice for my combinatorial needs): Infinite distributive law (general version). Let $K$ be a commutative ring. Let $L$ be the ring of formal power series over $K$ in some set of variables. We equip $L$ with the usual coefficientwise topology. A family $\left(f_j\right)_{j \in J}$ is said to be multipliable if the product $\prod\limits_{j\in J} f_j$ is well-defined, i.e., if for each monomial $\mathfrak{m}$ , there exists a finite subset $K$ of $J$ such that the $\mathfrak{m}$ -coefficient of $\prod\limits_{j\in K} f_j$ does not change if we increase $K$ (that is, the $\mathfrak{m}$ -coefficient of $\prod\limits_{j\in K} f_j$ equals the $\mathfrak{m}$ -coefficient of $\prod\limits_{j\in K'} f_j$ for any finite subset $K'$ of $J$ with $K \subseteq K'$ ). The notion of a summable family is defined similarly (but can also be characterized in a simpler way: a family $\left(f_j\right)_{j \in J}$ is summable if and only if each monomial $\mathfrak{m}$ occurs in only finitely many of its entries). Let $I$ be a set. For any $i\in I$ , let $S_i$ be a set that contains the number $0$ . Set \begin{align} \overline{S} = \left\{  \left(  i,k\right)  \ \mid\ i\in I\text{ and }k\in S_i\text{ and }k\neq0\right\}  . \end{align} For any $i\in I$ and any $k\in S_i$ , let $p_{i,k}$ be an element of $L$ . Assume that \begin{equation} p_{i,0}=1\ \ \ \ \ \ \ \ \ \ \text{for any }i\in I. \end{equation} Assume further that the family $\left(  p_{i,k}\right)  _{\left(  i,k\right) \in\overline{S}}$ is summable. Then, the product $\prod\limits_{i\in I}\ \ \sum\limits_{k\in S_i}p_{i,k}$ is well-defined (i.e., the family $\left(  p_{i,k}\right)_{k\in S_i}$ is summable for each $i\in I$ , and the family $\left( \sum\limits_{k\in S_i}p_{i,k}\right)  _{i\in I}$ is multipliable), and we have \begin{equation} \prod\limits_{i\in I}\ \ \sum\limits_{k\in S_i}p_{i,k}=\sum\limits_{\substack{\left( k_{i}\right)  _{i\in I}\in\prod\limits_{i\in I}S_i\\\text{is essentially finite} }}\ \ \prod\limits_{i\in I}p_{i,k_{i}}. \end{equation} Here, a family $\left(k_{i}\right)  _{i\in I}\in\prod\limits_{i\in I}S_i$ is said to be essentially finite if all but finitely many $i \in I$ satisfy $k_i = 0$ . In particular, the family $\left(  \prod\limits_{i\in I}p_{i,k_{i}}\right)  _{\left( k_{i}\right)  _{i\in I}\in\prod\limits_{i\in I}S_i\text{ is essentially finite}}$ is summable.","Teaching a course on algebraic combinatorics has made me aware of a technical fact about formal power series that is used throughout the subject, but that I have never seen formally stated, let alone proved. Here is a representative particular case of the fact (see below for the general case): Infinite distributive law (positive integers version). An infinite product of infinite sums of formal power series -- e.g., of the form , where each is a formal power series -- can be expanded into an infinite sum as long as certain reasonable conditions hold. Namely, if we assume that for each , and if we assume that the family is summable (i.e., each monomial appears in only finitely many entries of this family), then the product converges (in the coefficientwise topology on our ring of formal power series) and equals the sum of the products over all essentially finite sequences of nonnegative integers. (""Essentially finite"" means that all but finitely many satisfy . This is used for proving various standard generating function identities, such as or (where the latter equality is playing out in the ring of formal power series over the ring of symmetric functions in , with standing for the -th complete homogeneous symmetric function). In most simple situations (including the two I just mentioned), it is not hard to forego the use of the infinite distributive law for a limiting argument that reduces the problem to finite products (for which a distributive law isn't too hard to show). However, as one dives deeper into partitions and symmetric functions, these epicycles start getting exhausting. It is clear that the infinite distributive law belongs into the textbooks; yet I have never seen it there. Thus I started writing out a proof for my lecture notes , but so far I have not had much success. Question. Is there a citeable source or a teachable proof for the infinite distributive law? Note that I am looking for a proof that isn't specific to single-variable power series; at least it needs to cover the case of symmetric functions. Ideally, the proof shouldn't be spread over multiple chapters of a treatise or use heavy topological lingo. That said, so far I haven't even found such a proof. Another complication is the fact that not all infinite products are indexed by positive integers. For example, the Cauchy formula in symmetric functions theory is about expanding . While convergence of nets can make this general case not much harder than the integer-indexed one, I'd prefer not to rely on it too much. Here is the general version of infinite distributivity that I'm really aiming for (of course, there are even more general facts, but this one seems to suffice for my combinatorial needs): Infinite distributive law (general version). Let be a commutative ring. Let be the ring of formal power series over in some set of variables. We equip with the usual coefficientwise topology. A family is said to be multipliable if the product is well-defined, i.e., if for each monomial , there exists a finite subset of such that the -coefficient of does not change if we increase (that is, the -coefficient of equals the -coefficient of for any finite subset of with ). The notion of a summable family is defined similarly (but can also be characterized in a simpler way: a family is summable if and only if each monomial occurs in only finitely many of its entries). Let be a set. For any , let be a set that contains the number . Set For any and any , let be an element of . Assume that Assume further that the family is summable. Then, the product is well-defined (i.e., the family is summable for each , and the family is multipliable), and we have Here, a family is said to be essentially finite if all but finitely many satisfy . In particular, the family is summable.","\prod\limits_{i=1}^\infty \left( p_{i,0} + p_{i,1} + p_{i,2} + \cdots \right) p_{i,j} p_{i,0} = 1 i \left(p_{i,k}\right)_{i\geq 1,\ k\geq 1} \prod\limits_{i=1}^\infty \left( p_{i,0} + p_{i,1} + p_{i,2} + \cdots \right) p_{1, k_1} p_{2, k_2} p_{3, k_3} \cdots \left(k_1, k_2, k_3, \ldots\right) i k_i = 0 \begin{align}
\prod_{i=1}^\infty \dfrac{1}{1-x^i} = \prod_{i=1}^\infty \left(1 + x^i + x^{2i} + x^{3i} + \cdots\right)
= \sum_{\lambda\text{ is a partition}} x^{\left|\lambda\right|}
\end{align} \begin{align}
\prod_{i=1}^\infty \dfrac{1}{1-x_it} = \prod_{i=1}^\infty \left(1 + x_it + x_i^2t^2 + x_i^3t^3 + \cdots\right)
= \sum_{n \in \mathbb{N}} h_n t^n
\end{align} x_1, x_2, x_3, \ldots h_n n \prod\limits_{\left(i,j\right)\in\left\{1,2,3,\ldots\right\}^2} \dfrac{1}{1-x_iy_j} K L K L \left(f_j\right)_{j \in J} \prod\limits_{j\in J} f_j \mathfrak{m} K J \mathfrak{m} \prod\limits_{j\in K} f_j K \mathfrak{m} \prod\limits_{j\in K} f_j \mathfrak{m} \prod\limits_{j\in K'} f_j K' J K \subseteq K' \left(f_j\right)_{j \in J} \mathfrak{m} I i\in I S_i 0 \begin{align}
\overline{S} = \left\{  \left(  i,k\right)  \ \mid\ i\in I\text{ and }k\in S_i\text{ and }k\neq0\right\}  .
\end{align} i\in I k\in S_i p_{i,k} L \begin{equation}
p_{i,0}=1\ \ \ \ \ \ \ \ \ \ \text{for any }i\in I.
\end{equation} \left(  p_{i,k}\right)  _{\left(  i,k\right) \in\overline{S}} \prod\limits_{i\in I}\ \ \sum\limits_{k\in S_i}p_{i,k} \left(  p_{i,k}\right)_{k\in S_i} i\in I \left( \sum\limits_{k\in S_i}p_{i,k}\right)  _{i\in I} \begin{equation}
\prod\limits_{i\in I}\ \ \sum\limits_{k\in S_i}p_{i,k}=\sum\limits_{\substack{\left(
k_{i}\right)  _{i\in I}\in\prod\limits_{i\in I}S_i\\\text{is essentially finite}
}}\ \ \prod\limits_{i\in I}p_{i,k_{i}}.
\end{equation} \left(k_{i}\right)  _{i\in I}\in\prod\limits_{i\in I}S_i i \in I k_i = 0 \left(  \prod\limits_{i\in I}p_{i,k_{i}}\right)  _{\left(
k_{i}\right)  _{i\in I}\in\prod\limits_{i\in I}S_i\text{ is essentially finite}}","['sequences-and-series', 'topological-vector-spaces', 'formal-power-series', 'algebraic-combinatorics']"
1,Using $|\sin\theta|=\frac{2}{\pi}-\frac4\pi\sum_{m=1}^\infty\frac{\cos(2m\theta)}{4m^2-1}$ to calculate $\sum_{m=1}^\infty\frac1{16m^2-1}$ [duplicate],Using  to calculate  [duplicate],|\sin\theta|=\frac{2}{\pi}-\frac4\pi\sum_{m=1}^\infty\frac{\cos(2m\theta)}{4m^2-1} \sum_{m=1}^\infty\frac1{16m^2-1},"This question already has answers here : Solve $\sum_{k=0}^{\infty}\frac{1}{1-16k^2}$ (3 answers) Closed last month . By the equation $|\sin(\theta)|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(2m\theta)}{4m^2-1}$ , how can I get the value of $\sum_{m=1}^{\infty}\frac{1}{16m^2-1}$ ? If I substitute $\theta=\frac{\pi}{2}$ , $|\sin(\frac{\pi}{2})|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(m.\pi)}{4m^2-1}=1$ . For odd $m$ , $\cos(m.\pi)=-1$ and, for even $m$ , $\cos(m.\pi)=1$ . The sum of even $m$ is $\sum_{m=1}^{\infty}\frac{1}{4.(2.n)^2-1}=\sum_{m=1}^{\infty}\frac{1}{16.n^2-1}$ , the sum that I want to know the value, but how can I represent the sum of odd $m$ ? Solution, after receiving @OlivierOloa's answer below : If I substitute $\theta=\frac{\pi}{2}$ , $|\sin(\frac{\pi}{2})|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(m.\pi)}{4m^2-1}=1$ . For odd $m$ , $\cos(m\pi)=-1$ and, for even $m$ , $\cos(m\pi)=1$ . If I substitute $\theta=0$ , $|\sin(0)|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{1}{4m^2-1}=0$ . $$\begin{align}\left|\sin\frac\pi2\right|+|\sin0|&=\frac4\pi-\frac4\pi\sum_{m=1}^{\infty}\frac{1+\cos(m\pi)}{4m^2-1}=1\\&\Rightarrow\frac4\pi\left(1-2\sum_{n=1}^\infty\frac1{4(2n)^2-1}\right)=1\\&\Rightarrow1-2\sum_{n=1}^{\infty}\frac1{16n^2-1}=\frac\pi4\\&\Rightarrow -2\sum_{n=1}^\infty\frac1{16n^2-1}=\frac{\pi-4}4\\&\Rightarrow\sum_{n=1}^\infty\frac1{16n^2-1}=\frac{4-\pi}8.\end{align}$$","This question already has answers here : Solve $\sum_{k=0}^{\infty}\frac{1}{1-16k^2}$ (3 answers) Closed last month . By the equation , how can I get the value of ? If I substitute , . For odd , and, for even , . The sum of even is , the sum that I want to know the value, but how can I represent the sum of odd ? Solution, after receiving @OlivierOloa's answer below : If I substitute , . For odd , and, for even , . If I substitute , .",|\sin(\theta)|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(2m\theta)}{4m^2-1} \sum_{m=1}^{\infty}\frac{1}{16m^2-1} \theta=\frac{\pi}{2} |\sin(\frac{\pi}{2})|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(m.\pi)}{4m^2-1}=1 m \cos(m.\pi)=-1 m \cos(m.\pi)=1 m \sum_{m=1}^{\infty}\frac{1}{4.(2.n)^2-1}=\sum_{m=1}^{\infty}\frac{1}{16.n^2-1} m \theta=\frac{\pi}{2} |\sin(\frac{\pi}{2})|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(m.\pi)}{4m^2-1}=1 m \cos(m\pi)=-1 m \cos(m\pi)=1 \theta=0 |\sin(0)|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{1}{4m^2-1}=0 \begin{align}\left|\sin\frac\pi2\right|+|\sin0|&=\frac4\pi-\frac4\pi\sum_{m=1}^{\infty}\frac{1+\cos(m\pi)}{4m^2-1}=1\\&\Rightarrow\frac4\pi\left(1-2\sum_{n=1}^\infty\frac1{4(2n)^2-1}\right)=1\\&\Rightarrow1-2\sum_{n=1}^{\infty}\frac1{16n^2-1}=\frac\pi4\\&\Rightarrow -2\sum_{n=1}^\infty\frac1{16n^2-1}=\frac{\pi-4}4\\&\Rightarrow\sum_{n=1}^\infty\frac1{16n^2-1}=\frac{4-\pi}8.\end{align},"['sequences-and-series', 'fourier-series']"
2,Any chances to find the following sum analytically?,Any chances to find the following sum analytically?,,"Consider the following sum: \begin{equation} S(x, k, N, \alpha_1, \alpha_2) = \sum\limits_{m=1}^{N} \dfrac{ e^{i \phi_m k}}{x - \Omega(m, \alpha_1, \alpha_2, N)}, \end{equation} where $x$ - complex valued parameter, $k, N$ - positive integers ( $k<N$ ), $\phi_m = \dfrac{2 \pi (m-1)}{N}$ , $\Omega (m, \alpha_1, \alpha_2, N) = i \alpha_1 \dfrac{\xi + \xi^{1/N} e^{-i \phi_m}}{1 + \xi^{1/N} e^{-i \phi_m}} - i \alpha_2$ , and $\alpha_1, \alpha_2$ - real-valued constants, and $0<\xi<1$ . I really doubt that for any $N$ this can be written as a simple formula in terms of several known functions, but may there be any possible way to simplify it in certain limits? Like $N \to \infty$ , or saying that $\alpha_2 \gg \alpha_1$ .","Consider the following sum: where - complex valued parameter, - positive integers ( ), , , and - real-valued constants, and . I really doubt that for any this can be written as a simple formula in terms of several known functions, but may there be any possible way to simplify it in certain limits? Like , or saying that .","\begin{equation}
S(x, k, N, \alpha_1, \alpha_2) = \sum\limits_{m=1}^{N} \dfrac{ e^{i \phi_m k}}{x - \Omega(m, \alpha_1, \alpha_2, N)},
\end{equation} x k, N k<N \phi_m = \dfrac{2 \pi (m-1)}{N} \Omega (m, \alpha_1, \alpha_2, N) = i \alpha_1 \dfrac{\xi + \xi^{1/N} e^{-i \phi_m}}{1 + \xi^{1/N} e^{-i \phi_m}} - i \alpha_2 \alpha_1, \alpha_2 0<\xi<1 N N \to \infty \alpha_2 \gg \alpha_1","['calculus', 'sequences-and-series', 'summation']"
3,How can I evaluate $ \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}} $ where $k$ is a natural number? [duplicate],How can I evaluate  where  is a natural number? [duplicate], \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}}  k,"This question already has answers here : Find the sum of series $\sum_{n=0}^{\infty}\frac{z^{kn}}{(kn)!}$ (1 answer) Exponential Taylor series with $k$ step (2 answers) Closed 3 years ago . I suddenly interested in the differential equation $$ f^{(k)}(x)=f(x) $$ So I tried to calculate for some $n$ . When $ k=1 $ , we know the solution $$ f(x)=A_0e^x=\sum_{n=0}^{\infty}{\frac{A_0x^n}{n!}} $$ Also, for $ k=2 $ , $$ f(x)=Ae^x-Be^{-x}=\sum_{n=0}^{\infty}{(\frac{A_0x^{2n}}{(2n)!}+\frac{A_1x^{2n+1}}{(2n+1)!})} $$ where $ A_0=A+B $ and $ A_1=A-B $ . Inductively, I could guess that the solution of the differential equation would be in the form $$ f(x)=\sum_{n=0}^{\infty}{\sum_{i=0}^{k-1}{\frac{A_ix^{kn+i}}{(kn+i)!}}} $$ But I could neither prove that it is the only solution nor get the explicit formula. How should I evaluate $ \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}} $ , cause if we know the answer for it, we can evaluate the original expression by differentiating it. Thanks to WolframAlpha, I know the answer for $ k=3 $ , $$ \sum_{n=0}^{\infty}{\frac{x^{3n}}{(3n)!}}=\frac{1}{3}(2e^{-\frac {x}{2}}\cos{(\frac {\sqrt{3}}{2}x)}+e^{x}) $$ I think the answer might related to $ \sin $ and $ \cos $ of $ \frac {2\pi}{k} $ .","This question already has answers here : Find the sum of series $\sum_{n=0}^{\infty}\frac{z^{kn}}{(kn)!}$ (1 answer) Exponential Taylor series with $k$ step (2 answers) Closed 3 years ago . I suddenly interested in the differential equation So I tried to calculate for some . When , we know the solution Also, for , where and . Inductively, I could guess that the solution of the differential equation would be in the form But I could neither prove that it is the only solution nor get the explicit formula. How should I evaluate , cause if we know the answer for it, we can evaluate the original expression by differentiating it. Thanks to WolframAlpha, I know the answer for , I think the answer might related to and of .", f^{(k)}(x)=f(x)  n  k=1   f(x)=A_0e^x=\sum_{n=0}^{\infty}{\frac{A_0x^n}{n!}}   k=2   f(x)=Ae^x-Be^{-x}=\sum_{n=0}^{\infty}{(\frac{A_0x^{2n}}{(2n)!}+\frac{A_1x^{2n+1}}{(2n+1)!})}   A_0=A+B   A_1=A-B   f(x)=\sum_{n=0}^{\infty}{\sum_{i=0}^{k-1}{\frac{A_ix^{kn+i}}{(kn+i)!}}}   \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}}   k=3   \sum_{n=0}^{\infty}{\frac{x^{3n}}{(3n)!}}=\frac{1}{3}(2e^{-\frac {x}{2}}\cos{(\frac {\sqrt{3}}{2}x)}+e^{x})   \sin   \cos   \frac {2\pi}{k} ,"['sequences-and-series', 'ordinary-differential-equations', 'power-series', 'functional-equations']"
4,"If $S_{n,m}=\sum_{k=1}^{n} k^m =\sum_{j=0}^{m-1} A_{n,j}(m) S_{n,j},$ what are $A_{n,j}(m)$",If  what are,"S_{n,m}=\sum_{k=1}^{n} k^m =\sum_{j=0}^{m-1} A_{n,j}(m) S_{n,j}, A_{n,j}(m)","We know the sum of first $n$ natural numbers, their squares and cubes. sum of higher powers can be worked out using the differences: $k^m-(k-1)^{m}$ . However, these formulas are not remembered well. Recently, Dr. Mythili Subramanian and I  have started wondering if one can write $$S_{n,m}=\sum_{k=1}^{n} k^m =\sum_{j=0}^{m-1} A_{n,j}(m)~ S_{n,j} $$ then what are the expression/name for the coefficients: $A_{n,j}(m)?$ Interestingly, we know the asymptotic result that $$\sum_{k=1}^{n} k^m \sim \frac{n^{m+1}}{m+1}, ~\text{when $n$ is large}.$$ Any suggestion, information or help is welcome here. We are also trying to get it.","We know the sum of first natural numbers, their squares and cubes. sum of higher powers can be worked out using the differences: . However, these formulas are not remembered well. Recently, Dr. Mythili Subramanian and I  have started wondering if one can write then what are the expression/name for the coefficients: Interestingly, we know the asymptotic result that Any suggestion, information or help is welcome here. We are also trying to get it.","n k^m-(k-1)^{m} S_{n,m}=\sum_{k=1}^{n} k^m =\sum_{j=0}^{m-1} A_{n,j}(m)~ S_{n,j}  A_{n,j}(m)? \sum_{k=1}^{n} k^m \sim \frac{n^{m+1}}{m+1}, ~\text{when n is large}.","['sequences-and-series', 'summation', 'summation-method']"
5,Showing $\sum_{k=0}^{\infty} \sum_{i+j=k}a_i b_j = \sum_{k=0}^{\infty} a_k \sum_{k=0}^{\infty} b_k$,Showing,\sum_{k=0}^{\infty} \sum_{i+j=k}a_i b_j = \sum_{k=0}^{\infty} a_k \sum_{k=0}^{\infty} b_k,"I want to show $\sum_{k=0}^{\infty} \sum_{i+j=k}a_i b_j = \sum_{k=0}^{\infty} a_k \sum_{k=0}^{\infty} b_k$ rigoursly. How I can prove rigorously? (Of course suppose $\sum_{k=0}^{\infty}a_k < \infty$ , $\sum_{k=0}^{\infty}b_k < \infty$ condition is required)","I want to show rigoursly. How I can prove rigorously? (Of course suppose , condition is required)",\sum_{k=0}^{\infty} \sum_{i+j=k}a_i b_j = \sum_{k=0}^{\infty} a_k \sum_{k=0}^{\infty} b_k \sum_{k=0}^{\infty}a_k < \infty \sum_{k=0}^{\infty}b_k < \infty,"['sequences-and-series', 'power-series']"
6,Show that $\sum_{n\geq 1} \frac{a_n}{n^z}$ defines a holomorphic function in $\{ \operatorname{Re}z > 1\}$,Show that  defines a holomorphic function in,\sum_{n\geq 1} \frac{a_n}{n^z} \{ \operatorname{Re}z > 1\},"I am trying to make the following demonstration: let $(a_n)_n\subset \mathbb{C}$ be a sequence fulfilling that for all $\delta>0$ , $$\sup_n \dfrac{|a_n|}{n^\delta}<+\infty. $$ Show that the series $\displaystyle \sum_{n\geq 1} \dfrac{a_n}{n^z}$ , $\textrm{Re}\, z>1 $ , defines a holomorphic function on the half-plane $\textrm{Re}\, z> 1 $ . What I have done is: I first show that $\displaystyle \sum_{n\geq 1} \dfrac{a_n}{n^z}$ converges uniformly in every compact rectangle $R=[a, b] \times [c, d] \subset \mathbb {C} $ with $ a> 1 $ . For this I will see that the sequence of partial sums is a uniformly Cauchy sequence. Let $ \beta> \alpha $ , and $ z = x + iy \in R $ with $ x> 1 $ \begin{align*} 		    \left| \sum_{n=1}^\beta \dfrac{a_n}{n^z}-\sum_{n=1}^\alpha \dfrac{a_n}{n^z}\right| &=\left| \sum_{n=\alpha +1}^\beta \dfrac{a_n}{n^z}\right|\leq \sum_{n=\alpha+1}^\beta \dfrac{|a_n|}{|n^z|}=\sum_{n=\alpha+1}^\beta \dfrac{|a_n|}{n^x} \\ 		    & \leq \sum_{n=\alpha+1}^\beta \dfrac{|a_n|}{n^a} \leq \sum_{n=\alpha+1}^\beta M=M(\beta -\alpha) 		\end{align*} where $M=\displaystyle \sup_{n\in \{ \alpha+1,\ldots, \beta\}} \dfrac{|a_n|}{n^a}$ . If we see that there exists an integer $m$ such that if $m$ exists, then $m\to 0$ then we will have that the succession of partial sums is Cauchy uniform. This is true because as we increase $n$ , $n^a$ will increase. Therefore $\displaystyle \sum_{n \geq 1} \dfrac{a_n}{n^z}$ converges uniformly on every compact subset in the interior of the half-plane of convergence $\textrm{Re} \, z> 1 $ . Then, $ f (z) = \displaystyle \sum_ {n \geq 1} \dfrac{a_n}{n ^ z} $ is holomorphic in the half-plane $ \textrm {Re} \, z> 1 $ and the sequence of derivatives $ (f'_n) _n $ where $ f_n (z) = \dfrac {a_n} {n ^ z} $ converges uniformly on each compact subset of the half-plane of convergence to the derivative $ f '$ obtained in deriving term by term . I don't know if it is well resolved. What I don't know how to justify very well is the step that $M$ goes to $0$ for a sufficiently large $N$ .","I am trying to make the following demonstration: let be a sequence fulfilling that for all , Show that the series , , defines a holomorphic function on the half-plane . What I have done is: I first show that converges uniformly in every compact rectangle with . For this I will see that the sequence of partial sums is a uniformly Cauchy sequence. Let , and with where . If we see that there exists an integer such that if exists, then then we will have that the succession of partial sums is Cauchy uniform. This is true because as we increase , will increase. Therefore converges uniformly on every compact subset in the interior of the half-plane of convergence . Then, is holomorphic in the half-plane and the sequence of derivatives where converges uniformly on each compact subset of the half-plane of convergence to the derivative obtained in deriving term by term . I don't know if it is well resolved. What I don't know how to justify very well is the step that goes to for a sufficiently large .","(a_n)_n\subset \mathbb{C} \delta>0 \sup_n \dfrac{|a_n|}{n^\delta}<+\infty.  \displaystyle \sum_{n\geq 1} \dfrac{a_n}{n^z} \textrm{Re}\, z>1  \textrm{Re}\, z> 1  \displaystyle \sum_{n\geq 1} \dfrac{a_n}{n^z} R=[a, b] \times [c, d] \subset \mathbb {C}   a> 1   \beta> \alpha   z = x + iy \in R   x> 1  \begin{align*}
		    \left| \sum_{n=1}^\beta \dfrac{a_n}{n^z}-\sum_{n=1}^\alpha \dfrac{a_n}{n^z}\right| &=\left| \sum_{n=\alpha +1}^\beta \dfrac{a_n}{n^z}\right|\leq \sum_{n=\alpha+1}^\beta \dfrac{|a_n|}{|n^z|}=\sum_{n=\alpha+1}^\beta \dfrac{|a_n|}{n^x} \\
		    & \leq \sum_{n=\alpha+1}^\beta \dfrac{|a_n|}{n^a} \leq \sum_{n=\alpha+1}^\beta M=M(\beta -\alpha)
		\end{align*} M=\displaystyle \sup_{n\in \{ \alpha+1,\ldots, \beta\}} \dfrac{|a_n|}{n^a} m m m\to 0 n n^a \displaystyle \sum_{n \geq 1} \dfrac{a_n}{n^z} \textrm{Re} \, z> 1   f (z) = \displaystyle \sum_ {n \geq 1} \dfrac{a_n}{n ^ z}   \textrm {Re} \, z> 1   (f'_n) _n   f_n (z) = \dfrac {a_n} {n ^ z}   f ' M 0 N","['sequences-and-series', 'complex-analysis', 'dirichlet-series']"
7,Metric for sequences proof,Metric for sequences proof,,"Suppose $X = \{\{x_n\}_{n \in \mathbb{N}} : x_n \in \mathbb{R}$ $\forall n\geq 1\}$ . Prove that $d: X \times X \rightarrow \mathbb{R}$ such that $d(\{x_n\}_{n \in \mathbb{N}}, \{y_n\}_{n \in \mathbb{N}}) = \sum_{n = 1}^{\infty} 2^{-n}\frac{|x_n - y_n|}{1 + |x_n - y_n|}$ is a metric on $X$ . My attempt: I was given the hint that I should check each of the following: (1) a function $f(x) = \frac{x}{x+1}$ is montone increasing, (2) the triangle inequality applies to $\frac{|x_n - y_n|}{(1 + |x_n - y_n|)}$ and (3) the metric itself satisfies the inequality. (1) $f$ is monotone increasing: If $x \geq 0$ , $f'(x) = \frac{1}{(1 + x)^2} > 0$ . So $f$ is increasing. (2) Triangle inequality applies: We have $|x_n-y_n|≤|x_n-z_n|+|z_n-y_n|$ and so $\frac {|x_n-y_n|}{1+|x_n-y_n|}≤ \frac {|x_n-z_n|+|z_n-y_n|}{1+|x_n-z_n|+|z_n-y_n|}=\frac {|x_n-z_n|}{1+|x_n-z_n|+|z_n-y_n|} + \frac {|z_n-y_n|}{1+|x_n-z_n|+|z_n-y_n|}≤\frac{|x_n-z_n|}{1+|x_n-z_n|}+\frac {|z_n-y_n|}{1+|z_n-y_n|}$ Therefore $\frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|} \geq \frac{|x_n-y_n|}{1 + |x_n-y_n|}$ . (3) Metric satisfies triangle inequality: We know $\frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|} \geq \frac{|x_n-y_n|}{1 + |x_n-y_n|}$ . So $$2^{-n}(\frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|}) \geq 2^{-n}\frac{|x_n-y_n|}{1 + |x_n-y_n|}$$ and $$\sum_{n = 1}^{\infty} 2^{-n}(\frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|}) \geq \sum_{n = 1}^{\infty} 2^{-n}\frac{|x_n-y_n|}{1 + |x_n-y_n|}$$ QED. First of all, is this correct? If so, is that it? Is that sufficient to show that $d$ is a metric on $X$ ? Although I understood how to prove the hints, I still am not sure how these hints actually show that $d$ is a metric on $X$ , presuming they are sufficient to show this. Any insight is much appreciated.","Suppose . Prove that such that is a metric on . My attempt: I was given the hint that I should check each of the following: (1) a function is montone increasing, (2) the triangle inequality applies to and (3) the metric itself satisfies the inequality. (1) is monotone increasing: If , . So is increasing. (2) Triangle inequality applies: We have and so Therefore . (3) Metric satisfies triangle inequality: We know . So and QED. First of all, is this correct? If so, is that it? Is that sufficient to show that is a metric on ? Although I understood how to prove the hints, I still am not sure how these hints actually show that is a metric on , presuming they are sufficient to show this. Any insight is much appreciated.","X = \{\{x_n\}_{n \in \mathbb{N}} : x_n \in \mathbb{R} \forall n\geq 1\} d: X \times X \rightarrow \mathbb{R} d(\{x_n\}_{n \in \mathbb{N}}, \{y_n\}_{n \in \mathbb{N}}) = \sum_{n = 1}^{\infty} 2^{-n}\frac{|x_n - y_n|}{1 + |x_n - y_n|} X f(x) = \frac{x}{x+1} \frac{|x_n - y_n|}{(1 + |x_n - y_n|)} f x \geq 0 f'(x) = \frac{1}{(1 + x)^2} > 0 f |x_n-y_n|≤|x_n-z_n|+|z_n-y_n| \frac {|x_n-y_n|}{1+|x_n-y_n|}≤ \frac {|x_n-z_n|+|z_n-y_n|}{1+|x_n-z_n|+|z_n-y_n|}=\frac {|x_n-z_n|}{1+|x_n-z_n|+|z_n-y_n|} + \frac {|z_n-y_n|}{1+|x_n-z_n|+|z_n-y_n|}≤\frac{|x_n-z_n|}{1+|x_n-z_n|}+\frac {|z_n-y_n|}{1+|z_n-y_n|} \frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|} \geq \frac{|x_n-y_n|}{1 + |x_n-y_n|} \frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|} \geq \frac{|x_n-y_n|}{1 + |x_n-y_n|} 2^{-n}(\frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|}) \geq 2^{-n}\frac{|x_n-y_n|}{1 + |x_n-y_n|} \sum_{n = 1}^{\infty} 2^{-n}(\frac{|x_n - z_n|}{1 + |x_n - z_n|}+\frac{|z_n-y_n|}{1 + |z_n-y_n|}) \geq \sum_{n = 1}^{\infty} 2^{-n}\frac{|x_n-y_n|}{1 + |x_n-y_n|} d X d X","['sequences-and-series', 'proof-writing', 'metric-spaces', 'solution-verification']"
8,Claiming that $\int_c^\infty I(y)dy = \int_a^\infty J(x)dx$,Claiming that,\int_c^\infty I(y)dy = \int_a^\infty J(x)dx,"Claim: Let a real-valued function $f(x,y)$ be definied on $D = [a,+\infty)\times [c,+\infty)$ . If $I(y) = \int_a^\infty f(x,y)dx$ and $J(x) = \int_c^\infty f(x,y)dy$ are continuous and at least one of the following $$\int_c^\infty I(y)dy = \int_c^\infty dy \int_a^\infty f(x,y)dx \\ \int_a^\infty J(x)dx = \int_a^\infty dx \int_c^\infty f(x,y)dy$$ improper integrals conveverges, then so does the other and $$\int_c^\infty I(y)dy = \int_a^\infty J(x)dx$$ I haven't found anything very related to this theorem in my textbooks. I was thinking of taking two arbitrary sequences $(a_n)$ and $(c_n)$ such that $a_n \to +\infty$ and $c_n \to +\infty$ and defining $$I_n(y) = \int_a^{a_n} f(x,y) dy$$ and $$J_n(x) = \int_c^{c_n} f(x,y)dy$$ Then, obviously $I_n(y)_\rightarrow^\rightarrow I(y)$ and $J_n(x)_\rightarrow^\rightarrow J(x)$ . However, it seems I cannot go any further. I wonder if after the definition of the functional sequence above, one could use the ready results from that section.","Claim: Let a real-valued function be definied on . If and are continuous and at least one of the following improper integrals conveverges, then so does the other and I haven't found anything very related to this theorem in my textbooks. I was thinking of taking two arbitrary sequences and such that and and defining and Then, obviously and . However, it seems I cannot go any further. I wonder if after the definition of the functional sequence above, one could use the ready results from that section.","f(x,y) D = [a,+\infty)\times [c,+\infty) I(y) = \int_a^\infty f(x,y)dx J(x) = \int_c^\infty f(x,y)dy \int_c^\infty I(y)dy = \int_c^\infty dy \int_a^\infty f(x,y)dx \\ \int_a^\infty J(x)dx = \int_a^\infty dx \int_c^\infty f(x,y)dy \int_c^\infty I(y)dy = \int_a^\infty J(x)dx (a_n) (c_n) a_n \to +\infty c_n \to +\infty I_n(y) = \int_a^{a_n} f(x,y) dy J_n(x) = \int_c^{c_n} f(x,y)dy I_n(y)_\rightarrow^\rightarrow I(y) J_n(x)_\rightarrow^\rightarrow J(x)","['real-analysis', 'calculus', 'integration', 'sequences-and-series', 'improper-integrals']"
9,Convergence/divergence of $\sum\limits_{k=0}^{\infty}\sum\limits_{i=0}^k\left(\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}}\right)$,Convergence/divergence of,\sum\limits_{k=0}^{\infty}\sum\limits_{i=0}^k\left(\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}}\right),"Is the series $C:=\sum\limits_{k=0}^{\infty}\sum\limits_{i=0}^k\left(\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}}\right)$ convergent? I would say no, because: Let be $c_k:=\sum\limits_{i=0}^k\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}}$ , then we get $c_k=\sum\limits_{i=0}^k\frac{(-1)^{k}}{\sqrt{i+1}\sqrt{k-i+1}}=(-1)^k\sum\limits_{i=0}^k\frac{1}{\sqrt{i+1}\sqrt{k-i+1}}$ . As $(c_k)$ is not a null sequence the limit of the partial sums $\lim\limits_{n\to\infty}C_n=\sum\limits_{k=0}^{n}\sum\limits_{i=0}^k\left(\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}}\right)=\sum\limits_{k=0}^{n}(-1)^kc_k$ doesn't exist/ $C$ doesn't converge. Did I miss something?","Is the series convergent? I would say no, because: Let be , then we get . As is not a null sequence the limit of the partial sums doesn't exist/ doesn't converge. Did I miss something?",C:=\sum\limits_{k=0}^{\infty}\sum\limits_{i=0}^k\left(\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}}\right) c_k:=\sum\limits_{i=0}^k\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}} c_k=\sum\limits_{i=0}^k\frac{(-1)^{k}}{\sqrt{i+1}\sqrt{k-i+1}}=(-1)^k\sum\limits_{i=0}^k\frac{1}{\sqrt{i+1}\sqrt{k-i+1}} (c_k) \lim\limits_{n\to\infty}C_n=\sum\limits_{k=0}^{n}\sum\limits_{i=0}^k\left(\frac{(-1)^i}{\sqrt{i+1}}\frac{(-1)^{k-i}}{\sqrt{k-i+1}}\right)=\sum\limits_{k=0}^{n}(-1)^kc_k C,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
10,"Prove that for all bijective functions $\pi:\mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N}$, $\sum_{n=1}^{\infty} a_{\pi (n)}$ is convergent.","Prove that for all bijective functions ,  is convergent.",\pi:\mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N} \sum_{n=1}^{\infty} a_{\pi (n)},"I am tasked with this question: Let $$\sum_{n=1}^{\infty} a_{(i, n)} = a_{(i, 1)}+a_{(i, 2)}+a_{(i, 3)}+\dots$$ Such that $\sum_{n=1}^{\infty} a_{(i, n)}$ is absolutely convergent for each $i$ , and $\sum_{n=1}^{\infty} |a_{(i, n)}| = b_i.$ Furthermore, $\sum_{n=1}^{\infty} b_i$ is also convergent. Prove that for all bijective functions $\pi:\mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N}$ , $\sum_{n=1}^{\infty} a_{\pi (n)}$ is convergent. My attempt: Since $\pi$ is bijective, every $a_{(i,n)}$ is represented in $\sum a_{\pi (n)}$ . Thus $\sum a_{\pi (n)} = \sum a_{(i,n)}$ . We take $\sum |a_{\pi (n)}| = \sum b_i$ , which is convergent. Since every absolutely convergent series is also just convergent, it follows that $\sum a_{(i,n)} = \sum a_{\pi (n)}$ is convergent. Is that just it? The weightage of the question is rather high, and I can't help but feel that I've made a mistake in reasoning. Anyway I can further 'flesh out' the proof in case something is missing?","I am tasked with this question: Let Such that is absolutely convergent for each , and Furthermore, is also convergent. Prove that for all bijective functions , is convergent. My attempt: Since is bijective, every is represented in . Thus . We take , which is convergent. Since every absolutely convergent series is also just convergent, it follows that is convergent. Is that just it? The weightage of the question is rather high, and I can't help but feel that I've made a mistake in reasoning. Anyway I can further 'flesh out' the proof in case something is missing?","\sum_{n=1}^{\infty} a_{(i, n)} = a_{(i, 1)}+a_{(i, 2)}+a_{(i, 3)}+\dots \sum_{n=1}^{\infty} a_{(i, n)} i \sum_{n=1}^{\infty} |a_{(i, n)}| = b_i. \sum_{n=1}^{\infty} b_i \pi:\mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N} \sum_{n=1}^{\infty} a_{\pi (n)} \pi a_{(i,n)} \sum a_{\pi (n)} \sum a_{\pi (n)} = \sum a_{(i,n)} \sum |a_{\pi (n)}| = \sum b_i \sum a_{(i,n)} = \sum a_{\pi (n)}","['real-analysis', 'sequences-and-series', 'solution-verification']"
11,coefficient $[q^n]\sum_{m\ge1}\frac{q^{\alpha m}}{1-q^{\beta m}}$ where $0<\alpha<\beta$,coefficient  where,[q^n]\sum_{m\ge1}\frac{q^{\alpha m}}{1-q^{\beta m}} 0<\alpha<\beta,"Problem: I am looking for a finite-sum expression for the coefficient $c_n=c_n(\alpha,\beta)$ , where $$C(\alpha,\beta;q)=\sum_{m\ge1}\frac{q^{\alpha m}}{1-q^{\beta m}}=\sum_{n\ge1}c_n(\alpha,\beta)q^n,$$ with $\alpha,\beta\in\Bbb Z$ , $0<\alpha<\beta$ , and $|q|<1$ . Context: I know such $c_n$ exist, because $|q|<1$ ensures that $\frac{q^{\alpha m}}{1-q^{\beta m}}$ is analytic about $q=0$ for $m\ge1$ . I was motivated to attempt this because of the well-known $$\begin{align} \vartheta_3^2(q)&=1+4\sum_{m\ge1}\frac{q^m}{1+q^{2m}}\\ &=1+4\left(C(3,4;q)-C(1,4;q)\right), \end{align}$$ which implies that $r_2(n)=4c_n(3,4)-4c_n(1,4)$ for $n\ge1$ . I know that finite-sum expressions for $c_n(3,4)$ and $c_n(1,4)$ , along with $c_n(\alpha,\beta)$ exist because the following (more general) result is true: $$A(a,b;q)=\sum_{m\ge1}\frac{(aq)^m}{1-bq^m}=\sum_{n\ge1}q^n\sum_{d|n}a^db^{n/d-1}.\tag1$$ My Attempts: Let $i(n,m)=1$ when $n|m$ and $i(n,m)=0$ otherwise, and note that for positive integer $v$ , $$\frac{x^v}{1-x^v}=\sum_{r\ge v}x^ri(v,r).$$ Then let $u=\beta-\alpha$ so that $$\begin{align} C(q)&=\sum_{m\ge1}\frac{q^{\alpha m}}{1-q^{\beta m}}\\ &=\sum_{m\ge1}q^{-um}\frac{q^{\beta m}}{1-q^{\beta m}}\\ &=\sum_{m\ge1}q^{-um}\sum_{r\ge\beta}q^{mr}i(\beta,r)\\ &=\sum_{r\ge\beta}i(\beta,r)\sum_{m\ge1}q^{(r-u)m}\\ &=\sum_{t\ge\alpha}i(\beta,t+u)\sum_{m\ge1}q^{tm}\\ &=\sum_{t\ge\alpha}i(\beta,t+u)\sum_{s\ge t}q^{s}i(t,s)\\ &=\sum_{t\ge\alpha}\sum_{s\ge t}q^{s}i(\beta,t+u)i(t,s)\\ &=\sum_{t\ge\alpha}\sum_{j\ge 0}q^{j+t}i(\beta,t+u)i(t,j+t)\\ &=\sum_{j\ge0}\sum_{t\ge \alpha}q^{j+t}i(\beta,t+u)i(t,j+t)\\ &=\sum_{j\ge0}\sum_{l\ge 0}q^{j+l+\alpha}i(\beta,l+\beta)i(l+\alpha,j+l+\alpha). \end{align}$$ Then write $n=j+l+\alpha$ . Since $C(0)=0$ we know that $n\ge1$ . Thus $$\begin{align} C(q)&=\sum_{n\ge1}\sum_{\,\,\,j,l\ge0\\ j+l=n-\alpha}q^{j+l+\alpha}i(\beta,l+\beta)i(l+\alpha,j+l+\alpha)\\ &=\sum_{n\ge1}\sum_{\,\,\,j,l\ge0\\ j+l=n-\alpha}q^{n}i(\beta,l+\beta)i(l+\alpha,n)\\ &=\sum_{n\ge1}q^n\sum_{\,\,\,j,l\ge0\\ j+l=n-\alpha}i(\beta,l+\beta)i(l+\alpha,n). \end{align}$$ Since $j,l\ge0$ and $j+l=n-\alpha$ , we have $0\le l\le n-\alpha$ . Then upon writing $d=l+\alpha$ , we have $$\begin{align} C(q)&=\sum_{n\ge1}q^n\sum_{l=0}^{n-\alpha}i(\beta,l+\beta)i(l+\alpha,n)\\ &=\sum_{n\ge1}q^n\sum_{d=\alpha}^{n}i(\beta,d+u)i(d,n)\\ &=\sum_{n\ge1}q^n\sum_{d|n,\,d\ge\alpha}i(\beta,d+u).\tag{*} \end{align}$$ This would imply that $$c_n(\alpha,\beta)=\sum_{d|n,\,d\ge\alpha}i(\beta,d+u).$$ Question: Is $(*)$ correct? If not, what is the expression for $c_n$ that I'm looking for? Thanks :)","Problem: I am looking for a finite-sum expression for the coefficient , where with , , and . Context: I know such exist, because ensures that is analytic about for . I was motivated to attempt this because of the well-known which implies that for . I know that finite-sum expressions for and , along with exist because the following (more general) result is true: My Attempts: Let when and otherwise, and note that for positive integer , Then let so that Then write . Since we know that . Thus Since and , we have . Then upon writing , we have This would imply that Question: Is correct? If not, what is the expression for that I'm looking for? Thanks :)","c_n=c_n(\alpha,\beta) C(\alpha,\beta;q)=\sum_{m\ge1}\frac{q^{\alpha m}}{1-q^{\beta m}}=\sum_{n\ge1}c_n(\alpha,\beta)q^n, \alpha,\beta\in\Bbb Z 0<\alpha<\beta |q|<1 c_n |q|<1 \frac{q^{\alpha m}}{1-q^{\beta m}} q=0 m\ge1 \begin{align}
\vartheta_3^2(q)&=1+4\sum_{m\ge1}\frac{q^m}{1+q^{2m}}\\
&=1+4\left(C(3,4;q)-C(1,4;q)\right),
\end{align} r_2(n)=4c_n(3,4)-4c_n(1,4) n\ge1 c_n(3,4) c_n(1,4) c_n(\alpha,\beta) A(a,b;q)=\sum_{m\ge1}\frac{(aq)^m}{1-bq^m}=\sum_{n\ge1}q^n\sum_{d|n}a^db^{n/d-1}.\tag1 i(n,m)=1 n|m i(n,m)=0 v \frac{x^v}{1-x^v}=\sum_{r\ge v}x^ri(v,r). u=\beta-\alpha \begin{align}
C(q)&=\sum_{m\ge1}\frac{q^{\alpha m}}{1-q^{\beta m}}\\
&=\sum_{m\ge1}q^{-um}\frac{q^{\beta m}}{1-q^{\beta m}}\\
&=\sum_{m\ge1}q^{-um}\sum_{r\ge\beta}q^{mr}i(\beta,r)\\
&=\sum_{r\ge\beta}i(\beta,r)\sum_{m\ge1}q^{(r-u)m}\\
&=\sum_{t\ge\alpha}i(\beta,t+u)\sum_{m\ge1}q^{tm}\\
&=\sum_{t\ge\alpha}i(\beta,t+u)\sum_{s\ge t}q^{s}i(t,s)\\
&=\sum_{t\ge\alpha}\sum_{s\ge t}q^{s}i(\beta,t+u)i(t,s)\\
&=\sum_{t\ge\alpha}\sum_{j\ge 0}q^{j+t}i(\beta,t+u)i(t,j+t)\\
&=\sum_{j\ge0}\sum_{t\ge \alpha}q^{j+t}i(\beta,t+u)i(t,j+t)\\
&=\sum_{j\ge0}\sum_{l\ge 0}q^{j+l+\alpha}i(\beta,l+\beta)i(l+\alpha,j+l+\alpha).
\end{align} n=j+l+\alpha C(0)=0 n\ge1 \begin{align}
C(q)&=\sum_{n\ge1}\sum_{\,\,\,j,l\ge0\\ j+l=n-\alpha}q^{j+l+\alpha}i(\beta,l+\beta)i(l+\alpha,j+l+\alpha)\\
&=\sum_{n\ge1}\sum_{\,\,\,j,l\ge0\\ j+l=n-\alpha}q^{n}i(\beta,l+\beta)i(l+\alpha,n)\\
&=\sum_{n\ge1}q^n\sum_{\,\,\,j,l\ge0\\ j+l=n-\alpha}i(\beta,l+\beta)i(l+\alpha,n).
\end{align} j,l\ge0 j+l=n-\alpha 0\le l\le n-\alpha d=l+\alpha \begin{align}
C(q)&=\sum_{n\ge1}q^n\sum_{l=0}^{n-\alpha}i(\beta,l+\beta)i(l+\alpha,n)\\
&=\sum_{n\ge1}q^n\sum_{d=\alpha}^{n}i(\beta,d+u)i(d,n)\\
&=\sum_{n\ge1}q^n\sum_{d|n,\,d\ge\alpha}i(\beta,d+u).\tag{*}
\end{align} c_n(\alpha,\beta)=\sum_{d|n,\,d\ge\alpha}i(\beta,d+u). (*) c_n","['sequences-and-series', 'number-theory', 'analytic-number-theory', 'divisor-sum', 'q-series']"
12,"Proof that $\sum_{p=0}^\infty \frac{(Ct)^p (\sqrt{p})^p}{p!} \leq Ae^{Bt^2}$ for some constants $A, B > 0$",Proof that  for some constants,"\sum_{p=0}^\infty \frac{(Ct)^p (\sqrt{p})^p}{p!} \leq Ae^{Bt^2} A, B > 0","Fix $C > 0.$ I need to prove that there are constants $A, B> 0$ (depending on $C$ ) such that $$\sum_{p=0}^\infty \frac{(Ct)^p (\sqrt{p})^p}{p!} \leq Ae^{Bt^2}$$ for every $t>0.$ Sorry for not showing any work, but I don't really know how to tackle this. Thanks.","Fix I need to prove that there are constants (depending on ) such that for every Sorry for not showing any work, but I don't really know how to tackle this. Thanks.","C > 0. A, B> 0 C \sum_{p=0}^\infty \frac{(Ct)^p (\sqrt{p})^p}{p!} \leq Ae^{Bt^2} t>0.","['real-analysis', 'sequences-and-series']"
13,Is convergence itself necessary for Riemann´s rearrangement theorem?,Is convergence itself necessary for Riemann´s rearrangement theorem?,,"I have been studying series recently and I´ve gone through the proof of Riemann´s rearrangement theorem among other things. I was given the following related but different statement to prove as an exercise: A divergent series $\sum{a_k}$ has a convergent rearrangement if and only if the sum of the positive and negative terms diverge to $+\infty$ and $-\infty$ respectively and $\lim_{k\to \infty}{a_k}=0$ While trying to prove that the condition was sufficient I wondered: ""Can I not just appeal to Riemann´s rearrangement theorem?"" However it states that any conditionally convergent series can be rearranaged to converge to any real number or diverge. The statement I´m trying to prove assumes $\sum{a_k}$ diverges. From what I can tell however, in the proof of Riemann´s rearrangement theorem, the convergence itself of the series doesnt seem to be used to prove the theorem, but rather the fact that the sum of the positive and negative terms diverge to $+\infty/-\infty$ and that $\lim_{k\to \infty}{a_k}=0$ . So my question is: Is the convergence itself necessary to prove Riemann´s theorem?","I have been studying series recently and I´ve gone through the proof of Riemann´s rearrangement theorem among other things. I was given the following related but different statement to prove as an exercise: A divergent series has a convergent rearrangement if and only if the sum of the positive and negative terms diverge to and respectively and While trying to prove that the condition was sufficient I wondered: ""Can I not just appeal to Riemann´s rearrangement theorem?"" However it states that any conditionally convergent series can be rearranaged to converge to any real number or diverge. The statement I´m trying to prove assumes diverges. From what I can tell however, in the proof of Riemann´s rearrangement theorem, the convergence itself of the series doesnt seem to be used to prove the theorem, but rather the fact that the sum of the positive and negative terms diverge to and that . So my question is: Is the convergence itself necessary to prove Riemann´s theorem?",\sum{a_k} +\infty -\infty \lim_{k\to \infty}{a_k}=0 \sum{a_k} +\infty/-\infty \lim_{k\to \infty}{a_k}=0,"['real-analysis', 'sequences-and-series']"
14,"Prove that $\sum a_n$ converges iff $\sum 2^n a_{2^n}$ converges, but with another function instead of $2^{n}$.","Prove that  converges iff  converges, but with another function instead of .",\sum a_n \sum 2^n a_{2^n} 2^{n},"Let $\{a_n\}$ be a positive, decreasing sequence of real numbers. I know how to prove that $\sum_{n=1}^\infty a_n$ converges iff $\sum_{n=1}^\infty 2^n a_{2^n}$ converges, but is it possible that this is true for another function from naturals to naturals instead of $2^n$ ? In case there is no function why is it?","Let be a positive, decreasing sequence of real numbers. I know how to prove that converges iff converges, but is it possible that this is true for another function from naturals to naturals instead of ? In case there is no function why is it?",\{a_n\} \sum_{n=1}^\infty a_n \sum_{n=1}^\infty 2^n a_{2^n} 2^n,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'soft-question']"
15,"If there exsits a constant M such that $ \forall x\in [a,b], \forall n\geq 1,|S'_n(x)|\leq M, $ then $\sum_{n=1}^\infty a_n(x)$ converges uniformly.",If there exsits a constant M such that  then  converges uniformly.," \forall x\in [a,b], \forall n\geq 1,|S'_n(x)|\leq M,  \sum_{n=1}^\infty a_n(x)","Let series of functions $\sum_{n=1}^\infty a_n(x)$ converges on $[a, b]$ , its partial sum are $S_n(x)$ . If there exsits a constant M such that $$ \forall x\in [a,b], \forall n\geq 1,|S'_n(x)|\leq M, $$ then $\sum_{n=1}^\infty a_n(x)$ converges uniformly. I tried to prove the problem by Cauchy criterion. $$ S_{n+p}(x)-S_n(x)=S_{n+p}'(\xi_1)(x-a)+S_{n+p}(a)-S_{n}'(\xi_2)(x-a)-S_{n}(a) $$ But it seems we are unable to to control $|S'_{n+p}-S'_n|$ , so I  amstuck here. Is my way wrong, if so, please suggest a correct way. Appreciate any help!","Let series of functions converges on , its partial sum are . If there exsits a constant M such that then converges uniformly. I tried to prove the problem by Cauchy criterion. But it seems we are unable to to control , so I  amstuck here. Is my way wrong, if so, please suggest a correct way. Appreciate any help!","\sum_{n=1}^\infty a_n(x) [a, b] S_n(x) 
\forall x\in [a,b], \forall n\geq 1,|S'_n(x)|\leq M,
 \sum_{n=1}^\infty a_n(x) 
S_{n+p}(x)-S_n(x)=S_{n+p}'(\xi_1)(x-a)+S_{n+p}(a)-S_{n}'(\xi_2)(x-a)-S_{n}(a)
 |S'_{n+p}-S'_n|","['real-analysis', 'sequences-and-series', 'analysis', 'uniform-convergence']"
16,"On $\mathbb{R}^\omega$ are these metrics equivalent $\sum_{n=1}^\infty \frac{1}{2^n}\min(1,|a_n-b_n|)$ vs with $\frac{|a_n-b_n|}{n^2(1+|a_n-b_n|)}$",On  are these metrics equivalent  vs with,"\mathbb{R}^\omega \sum_{n=1}^\infty \frac{1}{2^n}\min(1,|a_n-b_n|) \frac{|a_n-b_n|}{n^2(1+|a_n-b_n|)}","How can I show that on $\mathbb{R}^\omega$ these two metrics are equivalent $\sum_{n=1}^\infty \frac{1}{2^n}\min(1,|a_n-b_n|)$ and $\sum_{n=1}^\infty \frac{1}{n^2}\frac{|a_n-b_n|}{1+|a_n-b_n|}$ ? Actually I'm not even sure whether they're equivalent but my intuition is that since as $a_n$ and $b_n$ get closer $\min(1,|a_n-b_n|)$ and $\frac{|a_n-b_n|}{1+|a_n-b_n|}$ will be nearly the same, and I assume that the $\frac{1}{2^n}$ and $1/n^2$ terms wont make a difference. However I don't know how to proceed with the proof. I'd love any kind of hint!","How can I show that on these two metrics are equivalent and ? Actually I'm not even sure whether they're equivalent but my intuition is that since as and get closer and will be nearly the same, and I assume that the and terms wont make a difference. However I don't know how to proceed with the proof. I'd love any kind of hint!","\mathbb{R}^\omega \sum_{n=1}^\infty \frac{1}{2^n}\min(1,|a_n-b_n|) \sum_{n=1}^\infty \frac{1}{n^2}\frac{|a_n-b_n|}{1+|a_n-b_n|} a_n b_n \min(1,|a_n-b_n|) \frac{|a_n-b_n|}{1+|a_n-b_n|} \frac{1}{2^n} 1/n^2","['real-analysis', 'sequences-and-series', 'functional-analysis']"
17,"To show a sequence is bounded, monotone and to find its limit","To show a sequence is bounded, monotone and to find its limit",,"I am new to analysis and following is the question: Show that the sequence $\frac{n+1}{n}$ is monotone, bounded and find its limit. The way I approached it is the following: To show that it is monotone, We can write the sequence as $a_n = 1 + \frac{1}{n}$ . Since $n_{2} > n_{1}$ , we have that $\frac{1}{n_2}<\frac{1}{n_1} $ . And hence $1 + \frac{1}{n_{1}} > 1 + \frac{1}{n_{2}}$ . So this shows that the sequence is monotonically decreasing. Question 1: With analysis I never know if my argument is complete, so is it complete here? Am I missing something? To show that it is bounded, We know that since $n\in \mathbb{N}$ , we have that $0 < \frac{1}{n} \le 1$ , and so $1 < 1+\frac{1}{n} \le 2$ . Hence it is bounded. Question 2: Another analysis question, how do I even know that I am not using things that have not been defined yet? Like, have I taken things for granted in my proof above? Finally, to find the limit, Can we just say that since this is a monotonically decreasing sequence, that is also bounded we can say that: $\lim_{n\rightarrow \infty} x_{n} = inf$ ${x_{n} : n \in \mathbb{N}}$ , we can say that the limit in this case would be 1? Question 3: I feel like this is not enough, and we would still have to show officially that 1 is the infimum of this sequence, which I am not sure how I can prove without saying that it makes intuitive sense for me? So if someone could tell me what the official proof of this part would be that would be great. Final Question: Is what I have so far correct or have I made any assumptions that one should not make while solving analysis questions?!","I am new to analysis and following is the question: Show that the sequence is monotone, bounded and find its limit. The way I approached it is the following: To show that it is monotone, We can write the sequence as . Since , we have that . And hence . So this shows that the sequence is monotonically decreasing. Question 1: With analysis I never know if my argument is complete, so is it complete here? Am I missing something? To show that it is bounded, We know that since , we have that , and so . Hence it is bounded. Question 2: Another analysis question, how do I even know that I am not using things that have not been defined yet? Like, have I taken things for granted in my proof above? Finally, to find the limit, Can we just say that since this is a monotonically decreasing sequence, that is also bounded we can say that: , we can say that the limit in this case would be 1? Question 3: I feel like this is not enough, and we would still have to show officially that 1 is the infimum of this sequence, which I am not sure how I can prove without saying that it makes intuitive sense for me? So if someone could tell me what the official proof of this part would be that would be great. Final Question: Is what I have so far correct or have I made any assumptions that one should not make while solving analysis questions?!",\frac{n+1}{n} a_n = 1 + \frac{1}{n} n_{2} > n_{1} \frac{1}{n_2}<\frac{1}{n_1}  1 + \frac{1}{n_{1}} > 1 + \frac{1}{n_{2}} n\in \mathbb{N} 0 < \frac{1}{n} \le 1 1 < 1+\frac{1}{n} \le 2 \lim_{n\rightarrow \infty} x_{n} = inf {x_{n} : n \in \mathbb{N}},"['real-analysis', 'sequences-and-series']"
18,series sum of sigmoid functions,series sum of sigmoid functions,,"This is apparently true (from a paper on Restricted Boltzmann Machines): $${\sum}_{i=1}^{\infty}1/(1+e^{i-(x+0.5)})\approx \ln(1+e^x)$$ (according to the author an ""extremely close"" approximation)  If you just do an integral, you get: $${\int}^{\infty}_1dy/(1+e^{y-(x+0.5)})=(y-\ln(1+e^ye^{-(x+0.5)})){\vert}^{\infty}_1=-\ln(e^{-y}+e^{-(x+0.5)}){\vert}^{\infty}_1=\ln(1+e^{x-0.5})$$ I also tried the expansion (with a resulting double sum): $$1/(1+x)={\sum}_{j=0}^{\infty}(-1)^jx^j$$ I'm missing a trick. Anyone have any clue how to derive this?  Thank you much.","This is apparently true (from a paper on Restricted Boltzmann Machines): (according to the author an ""extremely close"" approximation)  If you just do an integral, you get: I also tried the expansion (with a resulting double sum): I'm missing a trick. Anyone have any clue how to derive this?  Thank you much.",{\sum}_{i=1}^{\infty}1/(1+e^{i-(x+0.5)})\approx \ln(1+e^x) {\int}^{\infty}_1dy/(1+e^{y-(x+0.5)})=(y-\ln(1+e^ye^{-(x+0.5)})){\vert}^{\infty}_1=-\ln(e^{-y}+e^{-(x+0.5)}){\vert}^{\infty}_1=\ln(1+e^{x-0.5}) 1/(1+x)={\sum}_{j=0}^{\infty}(-1)^jx^j,"['sequences-and-series', 'summation']"
19,Show that inner product on $\ell^2$ is well-defined,Show that inner product on  is well-defined,\ell^2,"Define $$ \ell^2 = \{(z_n)\in \mathbb{C}^{\mathbb{N}}: \sum_{j=1}^{\infty}|z_j|^2<+\infty\}.$$ One can show that $\ell^2$ is a $\mathbb{C}$ -vector space and, moreover, that $\ell^2$ is an inner product space for $$ \langle(z_n),(u_n)\rangle=\sum_{j=1}^{\infty}z_j\overline{u_j}.$$ It's not too challenging to show that this map is indeed an inner product, but I'm also trying to show that it is well-defined; i.e. that $$ |\langle(z_n),(u_n)\rangle|<+\infty,\quad \forall(z_n),(u_n)\in \ell^2.$$ I want to show something like this $$|\langle(z_n),(u_n)\rangle|^2 = \left| \sum_j z_j\overline{u_j}\right|^2\le \dots\le \left(\sum_j |z_j|^2\right)\left( \sum_j|u_j|^2\right) < +\infty.$$ I can't use Cauchy-Schwarz' inequality since I have yet to show that $\ell^2$ is an inner product space. Any hints?","Define One can show that is a -vector space and, moreover, that is an inner product space for It's not too challenging to show that this map is indeed an inner product, but I'm also trying to show that it is well-defined; i.e. that I want to show something like this I can't use Cauchy-Schwarz' inequality since I have yet to show that is an inner product space. Any hints?"," \ell^2 = \{(z_n)\in \mathbb{C}^{\mathbb{N}}: \sum_{j=1}^{\infty}|z_j|^2<+\infty\}. \ell^2 \mathbb{C} \ell^2  \langle(z_n),(u_n)\rangle=\sum_{j=1}^{\infty}z_j\overline{u_j}.  |\langle(z_n),(u_n)\rangle|<+\infty,\quad \forall(z_n),(u_n)\in \ell^2. |\langle(z_n),(u_n)\rangle|^2 = \left| \sum_j z_j\overline{u_j}\right|^2\le \dots\le \left(\sum_j |z_j|^2\right)\left( \sum_j|u_j|^2\right) < +\infty. \ell^2","['sequences-and-series', 'inner-products', 'cauchy-schwarz-inequality']"
20,Show that the limit of $u_{n+d} = \frac{u_n + \cdots + u_{n+d-1}}{d}$ is $\frac{2}{d(d+1)}(u_0 + 2u_1 +\dots + du_{d-1})$,Show that the limit of  is,u_{n+d} = \frac{u_n + \cdots + u_{n+d-1}}{d} \frac{2}{d(d+1)}(u_0 + 2u_1 +\dots + du_{d-1}),"Let $u_0,\ldots,u_{d-1} \in \Bbb R$ . We define $(u_n)$ by the recursive relation: $$ u_{n+d} = \frac{u_n + \cdots + u_{n+d-1}}{d} $$ Show that $$\lim_{n\to +\infty} u_n = \frac{2}{d(d+1)}(u_0 + 2u_1 + \cdots + du_{d-1})$$ I solved it for $d=2$ by looking at $u_{n+2}-u_{n+1}$ but I think the generalization is trickier. I don't really know where to start. Edit: I read the solution proposed by the first comment. But I'm looking for another type of solution. I found this question in an exam for students that ask as a preliminary question to prove Gauss-Lucas theorem. I really wonder where is the link between both questions? Edit 2: Edit 3: Since: $$ |u_{n+d}| \leq \frac{|u_n| + \cdots + |u_{n+d-1}|}{d} \leq \max\{|u_n|;\cdots |u_{n+d-1}|\} $$ it is easy to show by recurrence that $\forall n, |u_n|\leq \max \{|u_0|;\cdots |u_{d-1}|\}$ . Thus, $u_n$ is bounded. However, if $P$ denotes the characteristic polynomial, $d \times P = d X^d - X^{d-1} - ... - 1$ . And $P(z) = 0 \implies |z|^d \leq (1/d) (|z|^0 + ... + |z|^{d-1}$ . Thus, we easily get that $|z|\leq 1$ and $|z| = 1 \iff z = 1$ (since $-1$ cannot be a root). Thus, if $u_n = \sum_{\lambda ; P(\lambda)=0} \alpha_{\lambda,n}\lambda^n$ is the solution of the reccurence, as $n\to \infty$ , $u_n \sim \alpha_{1,n}$ . But $\alpha_{1,n}$ is polynomial in $n$ and $u_n$ is bounded. Thus $\alpha_{1,n}$ is a constant and is the limit.","Let . We define by the recursive relation: Show that I solved it for by looking at but I think the generalization is trickier. I don't really know where to start. Edit: I read the solution proposed by the first comment. But I'm looking for another type of solution. I found this question in an exam for students that ask as a preliminary question to prove Gauss-Lucas theorem. I really wonder where is the link between both questions? Edit 2: Edit 3: Since: it is easy to show by recurrence that . Thus, is bounded. However, if denotes the characteristic polynomial, . And . Thus, we easily get that and (since cannot be a root). Thus, if is the solution of the reccurence, as , . But is polynomial in and is bounded. Thus is a constant and is the limit.","u_0,\ldots,u_{d-1} \in \Bbb R (u_n) 
u_{n+d} = \frac{u_n + \cdots + u_{n+d-1}}{d}
 \lim_{n\to +\infty} u_n = \frac{2}{d(d+1)}(u_0 + 2u_1 + \cdots + du_{d-1}) d=2 u_{n+2}-u_{n+1} 
|u_{n+d}| \leq \frac{|u_n| + \cdots + |u_{n+d-1}|}{d} \leq \max\{|u_n|;\cdots |u_{n+d-1}|\}
 \forall n, |u_n|\leq \max \{|u_0|;\cdots |u_{d-1}|\} u_n P d \times P = d X^d - X^{d-1} - ... - 1 P(z) = 0 \implies |z|^d \leq (1/d) (|z|^0 + ... + |z|^{d-1} |z|\leq 1 |z| = 1 \iff z = 1 -1 u_n = \sum_{\lambda ; P(\lambda)=0} \alpha_{\lambda,n}\lambda^n n\to \infty u_n \sim \alpha_{1,n} \alpha_{1,n} n u_n \alpha_{1,n}","['real-analysis', 'sequences-and-series', 'limits']"
21,Proving that the function $f(x)=\sum_n\frac{1}{10^n}\{10^nx\}$ is everywhere continuous but nowhere differentiable.,Proving that the function  is everywhere continuous but nowhere differentiable.,f(x)=\sum_n\frac{1}{10^n}\{10^nx\},"Theorem: The function $f(x)=\sum_{n=1}^{\infty}\frac{1}{10^n}\{10^nx\}$ is everywhere continuous but nowhere differentiable, where $\{.\} $ represents distance from nearest integer. This theorem has been taken from chapter $23$ of Spivak's Calculus book. By Weirstrauss M test, $f$ is uniformly continuous. In the book, the theorem is proven by showing that the limit $L=\lim_{m\to \infty}\frac{f(a+h_m)-f(a)}{h_m}=\lim_{m\to \infty}\sum_{n=1}^{\infty}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}$ does not exist when $h_m\to 0$ , where $a\in (0,1]$ . Let $a=0.a_1a_2\cdots$ Let $h_m=10^{-m}$ if $a_m\ne 4,9$ and $h_m=-10^{-m}$ if $a_m=4,9$ . $\tag{1}$ No. of terms in summation in the above limit $L$ is finite as if $n\ge m, 10^nh_m$ is integer and hence numerator of the summations becomes zero. So for $n\lt m$ , $\{10^na\}=\text{integer}+0.a_{n+1}a_{n+2}\cdots a_m\cdots $ and $10^n \{a+h_m\}=\text{integer}+0.a_{n+1}a_{n+2}\cdots (a_m\pm1)\cdots$ and this representation into decimals is correct as $h_m=-10^{-m}$ if $m=9$ . ** Then, Spivak makes a statement that if $0.a_{n+1}a_{n+2}\cdots  a_m\cdots \le 0.5$ , then we also have $0.a_{n+1}a_{n+2}\cdots (a_m\pm  1)\cdots \le 0.5$ as $h_m=-10^{-m}$ if $a_m=4$ . ** And I think that this is not true at all because in the special case $m=n+1$ , if $a_m=5$ then clearly $0.a_m\le 0.5$ but $0.(a_m\pm 1)\le 0.5$ is not true! and hence condition on $h_m$ should be $h_m=-10^{-m}$ when $a_m=5,9$ and $h_m=10^{-m}$ when $a_m\ne 5,9$ . Is my understanding correct? Another doubt that I have is: Is the following alternative way correct? Let's choose $h_m=10^{-m}$ if $a_m\ne 9$ and $h_m=-10^{-m}$ if $a_m=9$ . Then it's clear by writing decimal representation that, $\{10^n(a+h_m)\}-\{10^na\}=\pm 10^{n-m}$ and then $L=\lim_{m\to \infty}\frac{f(a+h_m)-f(a)}{h_m}=\lim_{m\to \infty}\sum_{n=1}^{\infty}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}=\lim_{m\to \infty}\sum_{n=1}^{m-1}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}\lim_{m\to \infty}\sum_{n=1}^{m-1}\pm 1=\lim_{m\to \infty}\pm (m-1)$ , which doesn't exist. Hence proved. Please help. Thanks.","Theorem: The function is everywhere continuous but nowhere differentiable, where represents distance from nearest integer. This theorem has been taken from chapter of Spivak's Calculus book. By Weirstrauss M test, is uniformly continuous. In the book, the theorem is proven by showing that the limit does not exist when , where . Let Let if and if . No. of terms in summation in the above limit is finite as if is integer and hence numerator of the summations becomes zero. So for , and and this representation into decimals is correct as if . ** Then, Spivak makes a statement that if , then we also have as if . ** And I think that this is not true at all because in the special case , if then clearly but is not true! and hence condition on should be when and when . Is my understanding correct? Another doubt that I have is: Is the following alternative way correct? Let's choose if and if . Then it's clear by writing decimal representation that, and then , which doesn't exist. Hence proved. Please help. Thanks.","f(x)=\sum_{n=1}^{\infty}\frac{1}{10^n}\{10^nx\} \{.\}  23 f L=\lim_{m\to \infty}\frac{f(a+h_m)-f(a)}{h_m}=\lim_{m\to \infty}\sum_{n=1}^{\infty}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m} h_m\to 0 a\in (0,1] a=0.a_1a_2\cdots h_m=10^{-m} a_m\ne 4,9 h_m=-10^{-m} a_m=4,9 \tag{1} L n\ge m, 10^nh_m n\lt m \{10^na\}=\text{integer}+0.a_{n+1}a_{n+2}\cdots a_m\cdots  10^n \{a+h_m\}=\text{integer}+0.a_{n+1}a_{n+2}\cdots (a_m\pm1)\cdots h_m=-10^{-m} m=9 0.a_{n+1}a_{n+2}\cdots
 a_m\cdots \le 0.5 0.a_{n+1}a_{n+2}\cdots (a_m\pm
 1)\cdots \le 0.5 h_m=-10^{-m} a_m=4 m=n+1 a_m=5 0.a_m\le 0.5 0.(a_m\pm 1)\le 0.5 h_m h_m=-10^{-m} a_m=5,9 h_m=10^{-m} a_m\ne 5,9 h_m=10^{-m} a_m\ne 9 h_m=-10^{-m} a_m=9 \{10^n(a+h_m)\}-\{10^na\}=\pm 10^{n-m} L=\lim_{m\to \infty}\frac{f(a+h_m)-f(a)}{h_m}=\lim_{m\to \infty}\sum_{n=1}^{\infty}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}=\lim_{m\to \infty}\sum_{n=1}^{m-1}\frac{\{10^n(a+h_m)\}-\{10^na\}}{10^nh_m}\lim_{m\to \infty}\sum_{n=1}^{m-1}\pm 1=\lim_{m\to \infty}\pm (m-1)","['real-analysis', 'calculus', 'sequences-and-series', 'solution-verification']"
22,Does it make sense to relax the definition of convergent sequence?,Does it make sense to relax the definition of convergent sequence?,,"The usual definition of a convergent sequence is: A sequence $\{a_n\}_{n=1}^\infty$ converges to $c \iff \forall \epsilon \gt 0$ there exists an $N_\epsilon$ such that $|a_n - c| \le \epsilon$ for all $n \ge N_\epsilon$ The intuitive idea is that a sequence converges to $c$ , if after a certain point all $a_n$ stay within a given distance $\epsilon$ of $c$ . Now consider the following sequence: $$ \{a_n\}_{n=1}^\infty = \begin{cases}  1 \quad \text{if } n = 2^k \text{ for some } k \in \mathbb{N} \\  \frac{1}{n} \quad \text{otherwise} \end{cases}$$ This sequence obviously doesn't converge to 0 according to the usual definition because there's always a large $N$ for which $a_N = 1$ . However, these $N$ s are very sparse: There's only one for each doubling of $a_n$ . In particular, as $n \to \infty$ , these outliers become ""infinitely sparse"". If "" $n = \infty$ "", then we'd need to wait for ""another $\infty$ "" elements until convergence is violated again. (I took this idea from slowly varying functions where, intuitively speaking, a function is slowly varying if it ""converges at $\infty$ "". Intuitively, $ln(x)$ is slowly varying because as $x \to \infty$ it takes larger and larger $x$ to produce a relevant increase in $ln(x)$ .) Has there been research using a relaxed definition of convergence, such that the above (and similar) sequences $\{a_n\}_{n=1}^\infty$ are convergent in this sense? If yes, are there interesting insights from this?","The usual definition of a convergent sequence is: A sequence converges to there exists an such that for all The intuitive idea is that a sequence converges to , if after a certain point all stay within a given distance of . Now consider the following sequence: This sequence obviously doesn't converge to 0 according to the usual definition because there's always a large for which . However, these s are very sparse: There's only one for each doubling of . In particular, as , these outliers become ""infinitely sparse"". If "" "", then we'd need to wait for ""another "" elements until convergence is violated again. (I took this idea from slowly varying functions where, intuitively speaking, a function is slowly varying if it ""converges at "". Intuitively, is slowly varying because as it takes larger and larger to produce a relevant increase in .) Has there been research using a relaxed definition of convergence, such that the above (and similar) sequences are convergent in this sense? If yes, are there interesting insights from this?","\{a_n\}_{n=1}^\infty c \iff \forall \epsilon \gt 0 N_\epsilon |a_n - c| \le \epsilon n \ge N_\epsilon c a_n \epsilon c 
\{a_n\}_{n=1}^\infty = \begin{cases}
 1 \quad \text{if } n = 2^k \text{ for some } k \in \mathbb{N} \\
 \frac{1}{n} \quad \text{otherwise}
\end{cases} N a_N = 1 N a_n n \to \infty n = \infty \infty \infty ln(x) x \to \infty x ln(x) \{a_n\}_{n=1}^\infty","['sequences-and-series', 'convergence-divergence']"
23,Is there a different way of splitting numbers into digits?,Is there a different way of splitting numbers into digits?,,"I was looking at a graph visualizing the Euler–Mascheroni constant ( $\gamma$ ), like that below, and an interesting question emerged. Background: The Euler-Mascheroni constant, to take the definition directly from the above-linked Wikipedia page, is the limiting difference between the harmonic series and the natural logarithm . Basically, the ""natural log of infinity"" (not quite so rigorous), or $\lim_{x \to \infty} \ln(x)$ , is infinite, and so is the harmonic series, or $\sum_{n=1}^{\infty} \frac{1}{n}$ . But if you subtract this infinite natural log from the harmonic series, you get a finite number around $0.57721$ , called the Euler-Mascheroni constant. Question: As the harmonic series is a step function , $\gamma$ is the sum of ""contributions"" from infinitely many sections, shown below as the first purple section covering $x \in [1, 2)$ , the second purple section covering $x \in [2, 3)$ , the third covering $x \in [3, 4)$ , etc. It occurred to me that this is fairly similar to the notion of a number being the sum of its digits, like the number 123 expressed as follows: It could be really useful to be able to express, operate on, and reason about a number with each ""digit"" representing a different term of a series, beyond the one canonical series in which we currently express all numbers: $$\textrm{number}=\textrm{digit}_1*\textrm{base}^{n-1}\ +\ \textrm{digit}_2*\textrm{base}^{n-2}\ +\ \textrm{digit}_3*\textrm{base}^{n-3}\ +\ ...\ +\ \textrm{digit}_n*\textrm{base}^0$$ TL;DR: Does there exist an area of study within mathematics that generalizes the notion of ""digits of a number"", allowing for them to be defined by something other than the series directly above, and with its own rules and operations for manipulating such a number? What are its rules and operations?","I was looking at a graph visualizing the Euler–Mascheroni constant ( ), like that below, and an interesting question emerged. Background: The Euler-Mascheroni constant, to take the definition directly from the above-linked Wikipedia page, is the limiting difference between the harmonic series and the natural logarithm . Basically, the ""natural log of infinity"" (not quite so rigorous), or , is infinite, and so is the harmonic series, or . But if you subtract this infinite natural log from the harmonic series, you get a finite number around , called the Euler-Mascheroni constant. Question: As the harmonic series is a step function , is the sum of ""contributions"" from infinitely many sections, shown below as the first purple section covering , the second purple section covering , the third covering , etc. It occurred to me that this is fairly similar to the notion of a number being the sum of its digits, like the number 123 expressed as follows: It could be really useful to be able to express, operate on, and reason about a number with each ""digit"" representing a different term of a series, beyond the one canonical series in which we currently express all numbers: TL;DR: Does there exist an area of study within mathematics that generalizes the notion of ""digits of a number"", allowing for them to be defined by something other than the series directly above, and with its own rules and operations for manipulating such a number? What are its rules and operations?","\gamma \lim_{x \to \infty} \ln(x) \sum_{n=1}^{\infty} \frac{1}{n} 0.57721 \gamma x \in [1, 2) x \in [2, 3) x \in [3, 4) \textrm{number}=\textrm{digit}_1*\textrm{base}^{n-1}\ +\ \textrm{digit}_2*\textrm{base}^{n-2}\ +\ \textrm{digit}_3*\textrm{base}^{n-3}\ +\ ...\ +\ \textrm{digit}_n*\textrm{base}^0","['real-analysis', 'sequences-and-series', 'number-theory', 'reference-request', 'soft-question']"
24,Prove a recursive relation,Prove a recursive relation,,"Suppose one has the following recursive relation : $$ a_{n+1} = a_n + \dfrac{1}{a_n} $$ Where: $$a_n > 0$$ Is there any way to find a closed form formula for something like this? I tried looking at the local factors by looking at how it develops, but it seems very chaotic. I found an inverse formula for this relation: $$ a_{n-1} = \dfrac{a_n+ \sqrt{{a_n}^2 - 4}}{2} $$ A bit odd is the fact that the inverse function is undefined ( in the reals) for $a_n < 2$ even though the regular function is defined for values lower than 2. Also, since the original function is increasing and monotonic, we know that the inverse is decreasing and monotonic - which means that for very large values of $a_0$ we always expect that the limit as n goes to infinity to be undefined, as it is guaranteed to go lower than 2 at some point in the sequence. Thats all I got basically, Would love to hear if you have any ideas or know anything about these types of recursive relations, because I noticed  for example: $$ a_{n+1} = a_n + \dfrac{1}{2a_n} $$ has a very similar inverse: $$ a_{n-1} = \dfrac{a_n+ \sqrt{{a_n}^2 - 2}}{2} $$","Suppose one has the following recursive relation : Where: Is there any way to find a closed form formula for something like this? I tried looking at the local factors by looking at how it develops, but it seems very chaotic. I found an inverse formula for this relation: A bit odd is the fact that the inverse function is undefined ( in the reals) for even though the regular function is defined for values lower than 2. Also, since the original function is increasing and monotonic, we know that the inverse is decreasing and monotonic - which means that for very large values of we always expect that the limit as n goes to infinity to be undefined, as it is guaranteed to go lower than 2 at some point in the sequence. Thats all I got basically, Would love to hear if you have any ideas or know anything about these types of recursive relations, because I noticed  for example: has a very similar inverse:","
a_{n+1} = a_n + \dfrac{1}{a_n}
 a_n > 0 
a_{n-1} = \dfrac{a_n+ \sqrt{{a_n}^2 - 4}}{2}
 a_n < 2 a_0 
a_{n+1} = a_n + \dfrac{1}{2a_n}
 
a_{n-1} = \dfrac{a_n+ \sqrt{{a_n}^2 - 2}}{2}
","['sequences-and-series', 'recurrence-relations', 'inverse-function']"
25,Prove $\sum_{k=1}^{\infty} \frac{{(-1)}^n}{k^2} \sum_{j=0}^{\infty} \frac{{(-1)}^j}{2k+j+1}=-\frac{\pi^2}{12}\ln{2}+\pi C-\frac{33}{16} \zeta(3)$,Prove,\sum_{k=1}^{\infty} \frac{{(-1)}^n}{k^2} \sum_{j=0}^{\infty} \frac{{(-1)}^j}{2k+j+1}=-\frac{\pi^2}{12}\ln{2}+\pi C-\frac{33}{16} \zeta(3),Prove $$\sum_{k=1}^{\infty} \frac{{(-1)}^k}{k^2} \sum_{j=0}^{\infty} \frac{{(-1)}^j}{2k+j+1}=-\frac{\pi^2}{12}\ln{2}+\pi C-\frac{33}{16} \zeta(3)$$ where C is catalan's constant. Wolfram Alpha confirms that the sums converge to approximately the right side.  Wolfram Alpha also evaluates the first sum in terms of Hurwitz lerch transcendent or digamma function but how do I then evaluate the outer sum with either of these functions. Original question is $$\int_0^1 \frac{\text{Li}_2(-x^2)}{1+x} \; \mathrm{d}x$$ and I've got it to the double sum here by writing Li as its series form and forming a geometric series with $\frac{1}{1+x}$ . Any tips or suggestions?  maybe other approach to the integral? Edit: Integration by parts may work better? $$\ln{(1+x)}\text{Li}_2(-x^2) \bigg \rvert_0^1 + 2\int_0^1 \frac{\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x$$ Wolfram says that second integral is $\pi C -\frac{33 \zeta(3)}{16}$ which is very good here but I don't know how to evaluate that integral. $$\int_0^1 \frac{2\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x=\int_0^1 \frac{\ln^2{(1+x)(1+x^2)}}{x} \; \mathrm{d}x-\int_0^1 \frac{\ln^2{(1+x)}}{x} \; \mathrm{d}x - \int_0^1 \frac{\ln^2{(1+x^2)}}{x} \; \mathrm{d}x$$ Last integral is 0 $$\int_0^1 \frac{2\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x=\int_0^1 \frac{\ln^2{(1+x)(1+x^2)}}{x} \; \mathrm{d}x-\int_0^1 \frac{\ln^2{(1+x)}}{x} \; \mathrm{d}x$$,Prove where C is catalan's constant. Wolfram Alpha confirms that the sums converge to approximately the right side.  Wolfram Alpha also evaluates the first sum in terms of Hurwitz lerch transcendent or digamma function but how do I then evaluate the outer sum with either of these functions. Original question is and I've got it to the double sum here by writing Li as its series form and forming a geometric series with . Any tips or suggestions?  maybe other approach to the integral? Edit: Integration by parts may work better? Wolfram says that second integral is which is very good here but I don't know how to evaluate that integral. Last integral is 0,\sum_{k=1}^{\infty} \frac{{(-1)}^k}{k^2} \sum_{j=0}^{\infty} \frac{{(-1)}^j}{2k+j+1}=-\frac{\pi^2}{12}\ln{2}+\pi C-\frac{33}{16} \zeta(3) \int_0^1 \frac{\text{Li}_2(-x^2)}{1+x} \; \mathrm{d}x \frac{1}{1+x} \ln{(1+x)}\text{Li}_2(-x^2) \bigg \rvert_0^1 + 2\int_0^1 \frac{\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x \pi C -\frac{33 \zeta(3)}{16} \int_0^1 \frac{2\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x=\int_0^1 \frac{\ln^2{(1+x)(1+x^2)}}{x} \; \mathrm{d}x-\int_0^1 \frac{\ln^2{(1+x)}}{x} \; \mathrm{d}x - \int_0^1 \frac{\ln^2{(1+x^2)}}{x} \; \mathrm{d}x \int_0^1 \frac{2\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x=\int_0^1 \frac{\ln^2{(1+x)(1+x^2)}}{x} \; \mathrm{d}x-\int_0^1 \frac{\ln^2{(1+x)}}{x} \; \mathrm{d}x,"['real-analysis', 'calculus']"
26,Conjecturing that all AP-GP mixed sequences are the first derivatives of a pure GP,Conjecturing that all AP-GP mixed sequences are the first derivatives of a pure GP,,"I was studying some series which are mix of AP and GP as $$(a+d)+(a+2d)r+(a+3d)r^2+......$$ An example could be, $1+2x+3x^2+4x^3+.....$ If i took ${|x|}\lt1$ , and while calculating the sum of the series upto $\infty$ terms by multiplying the series with $x$ and getting the answer as $$\frac {1}{(1-x)^2}$$ I just realised this series is the first derivative of the following series, $$1+x+x^2+x^3+x^4+.......$$ I tried this with all the examples in my book, all of them could be somehow reduced to the derivative of some GP. So my final question is weather all AP-GP mixed sequences can be expressed as derivative of some GP. If so, how can we prove it?","I was studying some series which are mix of AP and GP as An example could be, If i took , and while calculating the sum of the series upto terms by multiplying the series with and getting the answer as I just realised this series is the first derivative of the following series, I tried this with all the examples in my book, all of them could be somehow reduced to the derivative of some GP. So my final question is weather all AP-GP mixed sequences can be expressed as derivative of some GP. If so, how can we prove it?",(a+d)+(a+2d)r+(a+3d)r^2+...... 1+2x+3x^2+4x^3+..... {|x|}\lt1 \infty x \frac {1}{(1-x)^2} 1+x+x^2+x^3+x^4+.......,"['sequences-and-series', 'derivatives']"
27,Inverse Laplace transform of $\frac{\sqrt{2s}}{\sinh\sqrt{2s}}$ and $\frac{1}{\cosh\sqrt{2s}}$ (related to Brownian motion),Inverse Laplace transform of  and  (related to Brownian motion),\frac{\sqrt{2s}}{\sinh\sqrt{2s}} \frac{1}{\cosh\sqrt{2s}},"I was reading ""2018The computation of the probability density and distribution functions for some families of random variables by means of the Wynn-p accelerated Post-Widder formula"" and run into the following question. The paper gives two Laplace transforms: $$L_{X_S}(s)=\frac{\sqrt{2s}}{\sinh\sqrt{2s}}\ \text{and} \ L_{X_C}(s)=\frac{1}{\cosh\sqrt{2s}},$$ where $X_S$ and $X_C$ can be interpreted as the hitting time of a Brownian motion in $\mathbb{R}$ and $\mathbb{R}^3$ . The paper also says that the densities are: $$f_{X_S}(x)=\pi^2\sum_{k=1}^\infty(-1)^{k+1}k^2e^{-\frac{1}{2}k^2\pi^2x}\ \text{and} \ f_{X_C}(s)=\pi \sum_{k=0}^{\infty}(-1)^k\left(k+\frac{1}{2}\right)e^{-\frac{1}{2}(k+\frac{1}{2})^2\pi^2x}.$$ I am interested in the density functions, i.e., the inverse of Laplace transforms. There is one way in ""2001Probability laws related to the Jacobi theta and Riemann zeta functions, and Brownian excursions"", through $L_{X_C}$ . However, that paper mentions reciprocal property between $X_C$ and $X_C$ and between $X_S$ and $X_C$ , which I do not understand. In particular, since $\int_0^\infty e^{-sx}e^{-ax}dx=\frac{1}{s+a}$ for $a>0$ , directly applying Laplace transform to densities may lead to divergent series, e.g., $\sum_{k=1}^\infty(-1)^{k+1}\frac{k^2 \pi^2 }{s+\frac{1}{2}k^2\pi^2}$ . A similar expression $\sum_{n=-\infty}^{\infty}\frac{1}{n^2+b^2}=\frac{\pi}{b}\coth\pi b$ is also noticed, but I cannot see how to apply it so far. Any help would be appreciated.","I was reading ""2018The computation of the probability density and distribution functions for some families of random variables by means of the Wynn-p accelerated Post-Widder formula"" and run into the following question. The paper gives two Laplace transforms: where and can be interpreted as the hitting time of a Brownian motion in and . The paper also says that the densities are: I am interested in the density functions, i.e., the inverse of Laplace transforms. There is one way in ""2001Probability laws related to the Jacobi theta and Riemann zeta functions, and Brownian excursions"", through . However, that paper mentions reciprocal property between and and between and , which I do not understand. In particular, since for , directly applying Laplace transform to densities may lead to divergent series, e.g., . A similar expression is also noticed, but I cannot see how to apply it so far. Any help would be appreciated.","L_{X_S}(s)=\frac{\sqrt{2s}}{\sinh\sqrt{2s}}\ \text{and} \ L_{X_C}(s)=\frac{1}{\cosh\sqrt{2s}}, X_S X_C \mathbb{R} \mathbb{R}^3 f_{X_S}(x)=\pi^2\sum_{k=1}^\infty(-1)^{k+1}k^2e^{-\frac{1}{2}k^2\pi^2x}\ \text{and} \ f_{X_C}(s)=\pi \sum_{k=0}^{\infty}(-1)^k\left(k+\frac{1}{2}\right)e^{-\frac{1}{2}(k+\frac{1}{2})^2\pi^2x}. L_{X_C} X_C X_C X_S X_C \int_0^\infty e^{-sx}e^{-ax}dx=\frac{1}{s+a} a>0 \sum_{k=1}^\infty(-1)^{k+1}\frac{k^2 \pi^2 }{s+\frac{1}{2}k^2\pi^2} \sum_{n=-\infty}^{\infty}\frac{1}{n^2+b^2}=\frac{\pi}{b}\coth\pi b","['sequences-and-series', 'probability-theory', 'stochastic-calculus', 'laplace-transform']"
28,A summation identity,A summation identity,,"I have encountered this identity in Page 616 of Mathematical Methods for Students of Physics and Related Fields (Second Edition) by Sadri Hassani: $$ \sum_{m = 0}^{n}\left(-1\right)^{m}\, {\left(\,{2n + 2m}\,\right)! \over \left(\,{n + m}\,\right)!\,\left(\,{n - m}\,\right)!\, \left(\,{2m}\,\right)!} = \left(\,{-4}\,\right)^n $$ . I don't know how one can obtain it directly, however, I tried to prove it by induction. Thus, for $n = 1$ , the identity is valid. If we assume its validity for $n$ , we have to show that $\sum_{m = 0}^{n + 1} (-1)^m \frac{(2n + 2m + 2)!}{(n + m + 1)! (n - m + 1)! (2 m)!} = (-4)^{n + 1}$ . The thing that comes to one's mind is that to separate the ( $n + 1$ )th term in the left-hand side of the above, and write it as $(-1)^{n + 1} \frac{(4n + 4)!}{(2n + 2)! (2n + 2)!} + \sum_{m = 0}^{n} (-1)^m \frac{(2n + 2m + 2)!}{(n + m + 1)! (n - m + 1)! (2 m)!}$ , which with a little simplification, it becomes $(-1)^{n + 1} \frac{(4n + 4)!}{(2n + 2)! (2n + 2)!} + 2 \sum_{m = 0}^{n} (-1)^m \frac{(2n + 2m + 1) (2n + 2m)!}{(n - m + 1) (n + m)! (n - m)! (2 m)!}$ . It seems to me that one cannot simplify it more in order to be able to use the assumption; one could divide $\frac{2n + 2m + 1}{n - m + 1}$ but it doesn't seem to lead anywhere. Any help to proceed from here is appreciated!","I have encountered this identity in Page 616 of Mathematical Methods for Students of Physics and Related Fields (Second Edition) by Sadri Hassani: . I don't know how one can obtain it directly, however, I tried to prove it by induction. Thus, for , the identity is valid. If we assume its validity for , we have to show that . The thing that comes to one's mind is that to separate the ( )th term in the left-hand side of the above, and write it as , which with a little simplification, it becomes . It seems to me that one cannot simplify it more in order to be able to use the assumption; one could divide but it doesn't seem to lead anywhere. Any help to proceed from here is appreciated!","
\sum_{m = 0}^{n}\left(-1\right)^{m}\,
{\left(\,{2n + 2m}\,\right)!
\over \left(\,{n + m}\,\right)!\,\left(\,{n - m}\,\right)!\,
\left(\,{2m}\,\right)!} = \left(\,{-4}\,\right)^n
 n = 1 n \sum_{m = 0}^{n + 1} (-1)^m \frac{(2n + 2m + 2)!}{(n + m + 1)! (n - m + 1)! (2 m)!} = (-4)^{n + 1} n + 1 (-1)^{n + 1} \frac{(4n + 4)!}{(2n + 2)! (2n + 2)!} + \sum_{m = 0}^{n} (-1)^m \frac{(2n + 2m + 2)!}{(n + m + 1)! (n - m + 1)! (2 m)!} (-1)^{n + 1} \frac{(4n + 4)!}{(2n + 2)! (2n + 2)!} + 2 \sum_{m = 0}^{n} (-1)^m \frac{(2n + 2m + 1) (2n + 2m)!}{(n - m + 1) (n + m)! (n - m)! (2 m)!} \frac{2n + 2m + 1}{n - m + 1}","['sequences-and-series', 'summation']"
29,calculate $\sum_{n=0}^\infty \frac{3^n}{n!(n+3)}$ using power series,calculate  using power series,\sum_{n=0}^\infty \frac{3^n}{n!(n+3)},"let $f(x)=\frac{e^x-1-x-\frac{x^2}{2}}{x}$ , because $e^x = \sum_{n=0}^\infty \frac{x^n}{n!}$ , $f$ can be expressed as $$f(x) = \frac{\sum_{n=0}^\infty \frac{x^n}{n!}-1-x-\frac{x^2}{2}}{x}=\frac{\sum_{n=3}^\infty \frac{x^n}{n!}}{x}=\sum_{n=0}^\infty \frac{x^{n+2}}{(n+3)!}$$ the power series converge in $(-\infty, \infty)$ because $\lim_{n\to\infty} \sqrt[n]{\frac{1}{(n+3)!}}=0$ and let $f_n(x) = \frac{x^{n+2}}{(n+3)!} \Longrightarrow f'_n(x) = \frac{x^{n+1}}{(n+1)!(n+3)}$ , $\sum_{n=0}^\infty \frac{x^{n+1}}{(n+1)!(n+3)}= \sum_{n=0}^\infty f'_n(x)$ also converge in $(-\infty, \infty)$ (for the same reason), hence $$f'(x) = \sum_{n=0}^\infty \frac{x^{n+1}}{(n+1)!(n+3)}$$ by repeating this process once more I get $$f''(x) = \sum_{n=0}^\infty \frac{x^n}{n!(n+3)}$$ and if $x=3$ I get $$\sum_{n=0}^\infty \frac{3^n}{n!(n+3)} = f''(3)$$ which is what was looking for. my problem is that $f$ isn't defined for $x=0$ yet the series does converge for it as $\sum_{n=0}^\infty \frac{0^n}{n!(n+3)}=0$ , so was the function $f$ I used wrong? or could it be that I can't differentiate $f$ the way I did?","let , because , can be expressed as the power series converge in because and let , also converge in (for the same reason), hence by repeating this process once more I get and if I get which is what was looking for. my problem is that isn't defined for yet the series does converge for it as , so was the function I used wrong? or could it be that I can't differentiate the way I did?","f(x)=\frac{e^x-1-x-\frac{x^2}{2}}{x} e^x = \sum_{n=0}^\infty \frac{x^n}{n!} f f(x) = \frac{\sum_{n=0}^\infty \frac{x^n}{n!}-1-x-\frac{x^2}{2}}{x}=\frac{\sum_{n=3}^\infty \frac{x^n}{n!}}{x}=\sum_{n=0}^\infty \frac{x^{n+2}}{(n+3)!} (-\infty, \infty) \lim_{n\to\infty} \sqrt[n]{\frac{1}{(n+3)!}}=0 f_n(x) = \frac{x^{n+2}}{(n+3)!} \Longrightarrow f'_n(x) = \frac{x^{n+1}}{(n+1)!(n+3)} \sum_{n=0}^\infty \frac{x^{n+1}}{(n+1)!(n+3)}= \sum_{n=0}^\infty f'_n(x) (-\infty, \infty) f'(x) = \sum_{n=0}^\infty \frac{x^{n+1}}{(n+1)!(n+3)} f''(x) = \sum_{n=0}^\infty \frac{x^n}{n!(n+3)} x=3 \sum_{n=0}^\infty \frac{3^n}{n!(n+3)} = f''(3) f x=0 \sum_{n=0}^\infty \frac{0^n}{n!(n+3)}=0 f f","['sequences-and-series', 'power-series']"
30,Solving $\int_1^2 \sum_{m = -\infty}^{\infty} \left(2^m x \cdot e^{- 2^m x} \right)dx$,Solving,\int_1^2 \sum_{m = -\infty}^{\infty} \left(2^m x \cdot e^{- 2^m x} \right)dx,"In this answer to another question, the following equation comes up $$g(x)=\sum_{m = -\infty}^{\infty} 2^m x \cdot e^{- 2^m x}$$ I am interested in the average value of $g(x)$ in the interval of $1 < x < 2$ , which would be $$\frac{1}{2-1} \int_1^2 \sum_{m = -\infty}^{\infty} \left(2^m x \cdot e^{- 2^m x}\right) dx = \sum_{m=-\infty}^{\infty}\left( \int_1^2 2^mx\cdot e^{-2^mx}dx\right)$$ Mathematica gives the inner integral as $(-2-2^{-m}) e^{-2^{m+1}}+(1+2^{-m})e^{-2^m}$ , so this can be simplified to $$\sum_{m=-\infty}^{\infty} \left((-2-2^{-m}) e^{-2^{m+1}}+(1+2^{-m})e^{-2^m}\right) \approx 1.4427$$ This is very close to $\frac{1}{\ln(2)}$ , which leads me to believe that that is the closed form (although I am not sure). This is as far as I managed to get. How can I find the exact value of $\int_1^2 g(x)dx$ ? Edit: I managed to rewrite the sum as $$\lim_{N \to \infty}\left( 2^N-\sum_{m=-N+1}^{N}\left(1+2^{-m}\right)e^{-2^{m}}\right)$$ However, this form is much worse for numerical calculations.","In this answer to another question, the following equation comes up I am interested in the average value of in the interval of , which would be Mathematica gives the inner integral as , so this can be simplified to This is very close to , which leads me to believe that that is the closed form (although I am not sure). This is as far as I managed to get. How can I find the exact value of ? Edit: I managed to rewrite the sum as However, this form is much worse for numerical calculations.",g(x)=\sum_{m = -\infty}^{\infty} 2^m x \cdot e^{- 2^m x} g(x) 1 < x < 2 \frac{1}{2-1} \int_1^2 \sum_{m = -\infty}^{\infty} \left(2^m x \cdot e^{- 2^m x}\right) dx = \sum_{m=-\infty}^{\infty}\left( \int_1^2 2^mx\cdot e^{-2^mx}dx\right) (-2-2^{-m}) e^{-2^{m+1}}+(1+2^{-m})e^{-2^m} \sum_{m=-\infty}^{\infty} \left((-2-2^{-m}) e^{-2^{m+1}}+(1+2^{-m})e^{-2^m}\right) \approx 1.4427 \frac{1}{\ln(2)} \int_1^2 g(x)dx \lim_{N \to \infty}\left( 2^N-\sum_{m=-N+1}^{N}\left(1+2^{-m}\right)e^{-2^{m}}\right),"['real-analysis', 'integration', 'sequences-and-series', 'definite-integrals', 'exponential-function']"
31,Expressing continued fractions through $e$,Expressing continued fractions through,e,"The following are some conjectures of mine that I have discovered empirically. The last three conjectures are true if the first four are true, and vice versa. i. $$e=3-\cfrac{1}{4-\cfrac{2}{5-\cfrac{3}{6-\ddots}}}$$ ii. $$\cfrac{e}{e-2}=4-\cfrac{1}{5-\cfrac{2}{6-\cfrac{3}{7-\ddots}}}$$ iii. $$\cfrac{e}{2(3-e)}=5-\cfrac{1}{6-\cfrac{2}{7-\cfrac{3}{8-\ddots}}}$$ iv. $$\cfrac{e}{3(3e-8)}=6-\cfrac{1}{7-\cfrac{2}{8-\cfrac{3}{9-\ddots}}}$$ v. Let $c_1(x)=5-\cfrac{1}{6-\cfrac{2}{7-\ddots}}$ and $c_2(x)=4-\cfrac{2}{5-\cfrac{3}{6-\ddots}}$ . Then, $$\cfrac{c_1(x)}{c_2(x)}=\cfrac e2$$ vi. Let $c_3(x)=6-\cfrac{1}{7-\cfrac{2}{8-\ddots}}$ and $c_4(x)=5-\cfrac{2}{6-\cfrac{3}{7-\ddots}}$ . Then, $$\cfrac{c_3(x)}{c_4(x)}=\cfrac e{3(e-2)}$$ vii. $$\cfrac{c_1(x)c_4(x)}{c_2(x)c_3(x)}=3\bigg(\cfrac e2-1\bigg)$$ Can these conjectures be proven/disproven, particularly either the first four or last three? If they are true, it appears the function $$f(n)=n-\cfrac{1}{n+1-\cfrac{2}{n+2-\cfrac{3}{n+3-\ddots}}}$$ is expressed through $e$ , at least seemingly for natural $n\geq 3$ .","The following are some conjectures of mine that I have discovered empirically. The last three conjectures are true if the first four are true, and vice versa. i. ii. iii. iv. v. Let and . Then, vi. Let and . Then, vii. Can these conjectures be proven/disproven, particularly either the first four or last three? If they are true, it appears the function is expressed through , at least seemingly for natural .",e=3-\cfrac{1}{4-\cfrac{2}{5-\cfrac{3}{6-\ddots}}} \cfrac{e}{e-2}=4-\cfrac{1}{5-\cfrac{2}{6-\cfrac{3}{7-\ddots}}} \cfrac{e}{2(3-e)}=5-\cfrac{1}{6-\cfrac{2}{7-\cfrac{3}{8-\ddots}}} \cfrac{e}{3(3e-8)}=6-\cfrac{1}{7-\cfrac{2}{8-\cfrac{3}{9-\ddots}}} c_1(x)=5-\cfrac{1}{6-\cfrac{2}{7-\ddots}} c_2(x)=4-\cfrac{2}{5-\cfrac{3}{6-\ddots}} \cfrac{c_1(x)}{c_2(x)}=\cfrac e2 c_3(x)=6-\cfrac{1}{7-\cfrac{2}{8-\ddots}} c_4(x)=5-\cfrac{2}{6-\cfrac{3}{7-\ddots}} \cfrac{c_3(x)}{c_4(x)}=\cfrac e{3(e-2)} \cfrac{c_1(x)c_4(x)}{c_2(x)c_3(x)}=3\bigg(\cfrac e2-1\bigg) f(n)=n-\cfrac{1}{n+1-\cfrac{2}{n+2-\cfrac{3}{n+3-\ddots}}} e n\geq 3,"['sequences-and-series', 'elementary-number-theory', 'continued-fractions']"
32,Finding a multiple of a given number which can be expressed as 1+2+...+x,Finding a multiple of a given number which can be expressed as 1+2+...+x,,"An unrelated problem I came across in the domain of computer science reduced to the following mathematical problem: For a given number $ n\in \mathbb{N} $ , I need to find if any multiple of that number can be expressed as a series of the first $x$ natural numbers. Further, if such multiples exist, I need to find the least such multiple. That is, for a given $n$ , I need the lowest values for $k, x$ that satisfy the equation: $$ n \times k = \frac{x\times \left(x+1  \right)}{2}, n\in \mathbb{N}, k\in \mathbb{N}, x\in \mathbb{N} $$ I understand that this is a diophantine equation, and while I could find ways to solve linear and quadratic diophantine equations, I could not find a general form that could be applied to the problem above, especially since there are two unknowns in the equation. I also considered that one way to solve the problem would be to try and factorize $2 \times n$ into two consecutive numbers as indicated by the rearranged equation: $$ k = \frac{x\times \left(x+1  \right)}{2 \times n}, n\in \mathbb{N}, k\in \mathbb{N}, x\in \mathbb{N} $$ Finally, since the problem originated in the context of computer programs, I figured that if I couldn't find a mathematical approach to solve this equation, I could simply try for all values of x till I found an appropriate value. The problem with that approach (apart from the less than ideal computational time needed) is that I do not know if the $n$ I'm solving this for has such a multiple or not, hence I have no way of knowing if the brute-force algorithm would terminate. So I also tried (unsuccessfully) to find a method to determine if such a value for $k, x$ exists for a given $n$ . Does such a method exist? I would appreciate any help in trying to solve this problem.","An unrelated problem I came across in the domain of computer science reduced to the following mathematical problem: For a given number , I need to find if any multiple of that number can be expressed as a series of the first natural numbers. Further, if such multiples exist, I need to find the least such multiple. That is, for a given , I need the lowest values for that satisfy the equation: I understand that this is a diophantine equation, and while I could find ways to solve linear and quadratic diophantine equations, I could not find a general form that could be applied to the problem above, especially since there are two unknowns in the equation. I also considered that one way to solve the problem would be to try and factorize into two consecutive numbers as indicated by the rearranged equation: Finally, since the problem originated in the context of computer programs, I figured that if I couldn't find a mathematical approach to solve this equation, I could simply try for all values of x till I found an appropriate value. The problem with that approach (apart from the less than ideal computational time needed) is that I do not know if the I'm solving this for has such a multiple or not, hence I have no way of knowing if the brute-force algorithm would terminate. So I also tried (unsuccessfully) to find a method to determine if such a value for exists for a given . Does such a method exist? I would appreciate any help in trying to solve this problem."," n\in \mathbb{N}  x n k, x 
n \times k = \frac{x\times \left(x+1  \right)}{2}, n\in \mathbb{N}, k\in \mathbb{N}, x\in \mathbb{N}
 2 \times n 
k = \frac{x\times \left(x+1  \right)}{2 \times n}, n\in \mathbb{N}, k\in \mathbb{N}, x\in \mathbb{N}
 n k, x n","['sequences-and-series', 'number-theory', 'diophantine-equations', 'factoring', 'gcd-and-lcm']"
33,Prove or disprove that the sum is bounded by a constant,Prove or disprove that the sum is bounded by a constant,,"Given $p\in[0,1]$ , prove or disprove that the sum $$\sum_{n=k}^\infty\sum_{j=0}^k\left(\matrix{n\\j}\right)p^j(1-p)^{n-j}$$ is bounded by a constant that does not depend on $k$ . The terms $\left(\matrix{n\\j}\right)p^j(1-p)^{n-j}$ do remind me of the binomial expansion. But using that, the most naive estimate is $$\sum_{j=0}^k\left(\matrix{n\\j}\right)p^j(1-p)^{n-j}\leq\sum_{j=0}^n\left(\matrix{n\\j}\right)p^j(1-p)^{n-j}=1$$ And then summing over $n$ still gives $\infty$ . How should I make the correct estimate? p.s. I am not absolutely sure that this holds . There is a proof that I was reading where such an estimate could yield the final result. I am a bit confused now because one comment says this is wrong while an answer seems to have proved this.","Given , prove or disprove that the sum is bounded by a constant that does not depend on . The terms do remind me of the binomial expansion. But using that, the most naive estimate is And then summing over still gives . How should I make the correct estimate? p.s. I am not absolutely sure that this holds . There is a proof that I was reading where such an estimate could yield the final result. I am a bit confused now because one comment says this is wrong while an answer seems to have proved this.","p\in[0,1] \sum_{n=k}^\infty\sum_{j=0}^k\left(\matrix{n\\j}\right)p^j(1-p)^{n-j} k \left(\matrix{n\\j}\right)p^j(1-p)^{n-j} \sum_{j=0}^k\left(\matrix{n\\j}\right)p^j(1-p)^{n-j}\leq\sum_{j=0}^n\left(\matrix{n\\j}\right)p^j(1-p)^{n-j}=1 n \infty","['real-analysis', 'sequences-and-series', 'estimation']"
34,Proving $\prod\limits_{k=1}^{n-1}\left(1-\frac{\sin^2(x/2n)}{\sin^2(k\pi/2n)}\right)=\frac{\sin{x}}{n\sin(x/n)}$ and related tangent formula,Proving  and related tangent formula,\prod\limits_{k=1}^{n-1}\left(1-\frac{\sin^2(x/2n)}{\sin^2(k\pi/2n)}\right)=\frac{\sin{x}}{n\sin(x/n)},"Let $ n\geq 2 $ , and $ x\in\left]0,\pi\right[ $ , prove the following formulas : $$\begin{align} \prod_{k=1}^{n-1}{\left(1-\frac{\sin^{2}{\left(\frac{x}{2n}\right)}}{\sin^{2}{\left(\frac{k\pi}{2n}\right)}}\right)}&=\frac{\sin{x}}{n\sin{\left(\frac{x}{n}\right)}} \\[8pt] \prod_{k=1}^{n-1}{\left(1-\frac{\tan^{2}{\left(\frac{x}{2n}\right)}}{\tan^{2}{\left(\frac{k\pi}{2n}\right)}}\right)}&=\frac{\sin{x}}{n\sin{\left(\frac{x}{n}\right)}\cos^{2n-2}{\left(\frac{x}{2n}\right)}} \end{align}$$ These beautiful formulas have served me to build a rigourous proof (Using squeezing theorem and the fact that if $ 0< x\leq y<\frac{\pi}{2} $ then $ \frac{\tan{x}}{\tan{y}}\leq\frac{x}{y}\leq\frac{\sin{x}}{\sin{y}} $ ) for Euler's well-known formula : $$ \left(\forall x\in\left]-\pi,\pi\right[\right),\ \sin{x}=x\prod_{n=1}^{+\infty}{\left(1-\frac{x^{2}}{n^{2}\pi^{2}}\right)} $$","Let , and , prove the following formulas : These beautiful formulas have served me to build a rigourous proof (Using squeezing theorem and the fact that if then ) for Euler's well-known formula :"," n\geq 2   x\in\left]0,\pi\right[  \begin{align}
\prod_{k=1}^{n-1}{\left(1-\frac{\sin^{2}{\left(\frac{x}{2n}\right)}}{\sin^{2}{\left(\frac{k\pi}{2n}\right)}}\right)}&=\frac{\sin{x}}{n\sin{\left(\frac{x}{n}\right)}} \\[8pt]
\prod_{k=1}^{n-1}{\left(1-\frac{\tan^{2}{\left(\frac{x}{2n}\right)}}{\tan^{2}{\left(\frac{k\pi}{2n}\right)}}\right)}&=\frac{\sin{x}}{n\sin{\left(\frac{x}{n}\right)}\cos^{2n-2}{\left(\frac{x}{2n}\right)}}
\end{align}  0< x\leq y<\frac{\pi}{2}   \frac{\tan{x}}{\tan{y}}\leq\frac{x}{y}\leq\frac{\sin{x}}{\sin{y}}   \left(\forall x\in\left]-\pi,\pi\right[\right),\ \sin{x}=x\prod_{n=1}^{+\infty}{\left(1-\frac{x^{2}}{n^{2}\pi^{2}}\right)} ","['sequences-and-series', 'trigonometry', 'products']"
35,"Convergence of $\frac{a_{n+1}}{a_n}$, where $|a_{n+1}a_{n-1} - a_n^2| = 1 $","Convergence of , where",\frac{a_{n+1}}{a_n} |a_{n+1}a_{n-1} - a_n^2| = 1 ,Let $(a_n)$ a non-decreasing sequence of positive real numbers such that $\lim a_n = \infty$ and $|a_{n+1}a_{n-1} - a_n^2| = 1 $ . Prove that the sequence $(\frac{a_{n+1}}{a_n})$ converges. My little ´´progress´´: $|a_{n+1}a_{n-1} - a_n^2| = 1 $ . $\left|\dfrac{a_{n+1}a_{n-1}}{a_n^2} - 1\right| = \dfrac{1}{a_n^2} \to 0$ $\dfrac{a_{n+1}a_{n-1}}{a_n^2} \to 1$ $\dfrac{a_{n+1}}{a_n}\dfrac{a_{n-1}}{a_n} \to 1$,Let a non-decreasing sequence of positive real numbers such that and . Prove that the sequence converges. My little ´´progress´´: .,(a_n) \lim a_n = \infty |a_{n+1}a_{n-1} - a_n^2| = 1  (\frac{a_{n+1}}{a_n}) |a_{n+1}a_{n-1} - a_n^2| = 1  \left|\dfrac{a_{n+1}a_{n-1}}{a_n^2} - 1\right| = \dfrac{1}{a_n^2} \to 0 \dfrac{a_{n+1}a_{n-1}}{a_n^2} \to 1 \dfrac{a_{n+1}}{a_n}\dfrac{a_{n-1}}{a_n} \to 1,['real-analysis']
36,Alternating power sequence,Alternating power sequence,,"I quite randomly stumbled upon the following phenomenon: Let $ f:\mathbb R^+\to\mathbb R^+, x\mapsto x^{-2^{3^{-4^{\cdot^{\cdot^{\cdot}}}}}} $ , then in the interval of $[1,20)$ the plot of $f$ looks like the following: This looks surprisingly similar to the plot of $\frac{1}{x}$ , plotted in red: Why is that? And why is $f$ even well defined (i.e. why does the sequence converge)? It seems as if there exists some $\xi\in[1,2]$ for which $$\forall x\in\mathbb R^+:f(x)=x^{-\xi}\qquad\xi\simeq 1.2$$ $f$ is undefined for negative values and diverges at $0$ : $$\lim\limits_{x\searrow0}f(x)\to\infty $$ Can anyone explain those properties / link to some proof? I'd be quite curious about the exact value of $\xi$ too. Also, if you're interested or don't trust me, I've created the plots with this program. So to clarify this a bit, the problem can be formulated the following way: Show that $$\xi:=-\lim\limits_{n\to\infty}-2^{3^{-4^{\cdot^{\cdot^{\cdot^{\sigma(n)\cdot n}}}}}}\simeq1.1982330602188767$$ $$\sigma:\mathbb N\to\{-1,1\},\ n\mapsto\begin{cases}-1& n\mod2=0\\1&n\mod2=1\end{cases}$$ We can formulate this mathematically precisely: Let $\sigma$ be as defined previously, then define $$e:\mathbb N^2\to\mathbb R,\ (m,n)\mapsto\begin{cases}\sigma(m)\cdot m^{e(m+1,n)}&m<n\\\sigma(m)\cdot m&m=n\end{cases}$$ then $\xi$ is defined as $$\xi:=\lim\limits_{n\to\infty}e(2,n)$$ For this we can proof that $\xi\in(-2,-1)$ by something like the following: $$\forall n\in\mathbb N:\ e(4,n)=-4^{r(n)}\quad r(n)>0\implies e(4,n)<-1$$ $$\implies e(3,n)=3^{e(4,n)}=\left|3^{e(4,n)}\right|<1$$ $$\implies e(2,n)=-2^{e(3,n)}\in(-2,-1)$$ However, this is not a full proof of convergence (but merely of limitedness). I feel like the proof of convergence should contain the value it converges to. But if the value of $\xi$ only appears by this construction, that's rather difficult. It would also suffice to proof the monotony of $e(2,\cdot)$ - however, it clearly isn't monotonous. Maybe, similarly to the proof I presented, the interval for $\xi$ can be minimized bit by bit, but I don't quite know how I'd proceed there. The above proof can easily be generified to the following ( $\forall n\in\mathbb N$ ): $$\forall m\in 2\mathbb N:\ e(m,n)<-1$$ $$\implies\forall o\in\mathbb N\setminus2\mathbb N:\ e(o,n)=|e(o,n)|<1$$ $$\implies\forall p\in2\mathbb N:\ e(p,n)\in(-m,-1)$$ However, a quick computer program indicates that $$\forall m\in2\mathbb N,\ n\gg m:\ e(m,n)\in(-2,-1)$$ I don't know if that's of any use though.","I quite randomly stumbled upon the following phenomenon: Let , then in the interval of the plot of looks like the following: This looks surprisingly similar to the plot of , plotted in red: Why is that? And why is even well defined (i.e. why does the sequence converge)? It seems as if there exists some for which is undefined for negative values and diverges at : Can anyone explain those properties / link to some proof? I'd be quite curious about the exact value of too. Also, if you're interested or don't trust me, I've created the plots with this program. So to clarify this a bit, the problem can be formulated the following way: Show that We can formulate this mathematically precisely: Let be as defined previously, then define then is defined as For this we can proof that by something like the following: However, this is not a full proof of convergence (but merely of limitedness). I feel like the proof of convergence should contain the value it converges to. But if the value of only appears by this construction, that's rather difficult. It would also suffice to proof the monotony of - however, it clearly isn't monotonous. Maybe, similarly to the proof I presented, the interval for can be minimized bit by bit, but I don't quite know how I'd proceed there. The above proof can easily be generified to the following ( ): However, a quick computer program indicates that I don't know if that's of any use though."," f:\mathbb R^+\to\mathbb R^+, x\mapsto x^{-2^{3^{-4^{\cdot^{\cdot^{\cdot}}}}}}  [1,20) f \frac{1}{x} f \xi\in[1,2] \forall x\in\mathbb R^+:f(x)=x^{-\xi}\qquad\xi\simeq 1.2 f 0 \lim\limits_{x\searrow0}f(x)\to\infty  \xi \xi:=-\lim\limits_{n\to\infty}-2^{3^{-4^{\cdot^{\cdot^{\cdot^{\sigma(n)\cdot n}}}}}}\simeq1.1982330602188767 \sigma:\mathbb N\to\{-1,1\},\ n\mapsto\begin{cases}-1& n\mod2=0\\1&n\mod2=1\end{cases} \sigma e:\mathbb N^2\to\mathbb R,\ (m,n)\mapsto\begin{cases}\sigma(m)\cdot m^{e(m+1,n)}&m<n\\\sigma(m)\cdot m&m=n\end{cases} \xi \xi:=\lim\limits_{n\to\infty}e(2,n) \xi\in(-2,-1) \forall n\in\mathbb N:\ e(4,n)=-4^{r(n)}\quad r(n)>0\implies e(4,n)<-1 \implies e(3,n)=3^{e(4,n)}=\left|3^{e(4,n)}\right|<1 \implies e(2,n)=-2^{e(3,n)}\in(-2,-1) \xi e(2,\cdot) \xi \forall n\in\mathbb N \forall m\in 2\mathbb N:\ e(m,n)<-1 \implies\forall o\in\mathbb N\setminus2\mathbb N:\ e(o,n)=|e(o,n)|<1 \implies\forall p\in2\mathbb N:\ e(p,n)\in(-m,-1) \forall m\in2\mathbb N,\ n\gg m:\ e(m,n)\in(-2,-1)","['sequences-and-series', 'power-towers']"
37,How to get the ordinary generating function for this series,How to get the ordinary generating function for this series,,"I came across the following sum: $$ \sum_{k \geq 0} \frac{2^k}{2^k+1} $$ Is there a way to derive the ordinary generating function (OGF) for this sum?, i.e. given the series: $$ A(z) = a_0 + a_1z^1 + a_2z^2 + ... +a^kz^k + ... $$ if we have for instance $a_k=1$ for all $k \geq 0$ , we have OGF $A(z)=1/(1-z)$ , or if the $a_k$ 's represent the harmonic numbers $H_k$ for $k \geq 0$ , we have the OGF $\frac{1}{1-z}\ln{(\frac{z}{1-z})}$ . So is there a way to get the OGF where $a_k=\frac{2^k}{2^k+1}$ ?","I came across the following sum: Is there a way to derive the ordinary generating function (OGF) for this sum?, i.e. given the series: if we have for instance for all , we have OGF , or if the 's represent the harmonic numbers for , we have the OGF . So is there a way to get the OGF where ?","
\sum_{k \geq 0} \frac{2^k}{2^k+1}
 
A(z) = a_0 + a_1z^1 + a_2z^2 + ... +a^kz^k + ...
 a_k=1 k \geq 0 A(z)=1/(1-z) a_k H_k k \geq 0 \frac{1}{1-z}\ln{(\frac{z}{1-z})} a_k=\frac{2^k}{2^k+1}","['sequences-and-series', 'summation', 'algorithms', 'generating-functions']"
38,‎prove that the sequence ‎$‎\{F(n)\}‎$ ‎converges.‎,‎prove that the sequence ‎ ‎converges.‎,‎\{F(n)\}‎,"‎‎‎‎Let ‎‎ $‎g:‎\mathbb{R^+}‎‎‎\rightarrow‎‎\mathbb{R^+}‎$ ‎be a function such that $\log g(x)‎$ ‎is ‎concave, and‎ ‎ $‎‎‎‎\displaystyle{\lim_{x\to\infty}}‎\frac{g(x+w)}{g(x)} = 1‎$ ‎‎‎‎‎‎‎‎‎for each ‎ $‎w>0‎$ . ‎‎‎Then‎:‎ Fact 1: ‎‎ $‎g(x)‎$ ‎is ‎increasing‎;‎ ‎‎ Fact 2: ‎‎ $\log g(x)‎$ ‎‎‎‎‎ has derivative ‎‎ $‎‎\frac{g^\prime_{-}(x) + g^\prime_{+}(x) ‎}{2g(x)}‎$ ‎except, possibly, on a countable set, where ‎ $‎g^\prime_{+}(x‏)‎$ ‎and ‎‎ $‎g^\prime_{-}(x)‎$ ‎are ‎right ‎and ‎left ‎derivatives, ‎respectively; ‎ Fact  ‎3:‎‎ $‎‎\frac{g^‎\prime_{-}(x) + g^‎\prime_{+}(x) ‎}{2g(x)}‎$ is ‎decreasing ‎and ‎non-negative on ‎ $‎‎\mathbb{R}‎^+‎$ ‎.‎ ‎‎ My question ‎is:‎ ‎‎Let ‎‎ ‎‎ \begin{align*}‎‎ ‎F(n) = \sum_{i=1}^n ‎‎\frac{g^\prime_{-}(i) + g^\prime_{+}(i) ‎}{2g(i)} - \log g(n), ‎\end{align*} ‎‎‎ ‎prove that the sequence ‎ $‎\{F(n)\}‎$ ‎converges.‎‎ ‎Thanks‎ in advance.","‎‎‎‎Let ‎‎ ‎be a function such that ‎is ‎concave, and‎ ‎ ‎‎‎‎‎‎‎‎‎for each ‎ . ‎‎‎Then‎:‎ Fact 1: ‎‎ ‎is ‎increasing‎;‎ ‎‎ Fact 2: ‎‎ ‎‎‎‎‎ has derivative ‎‎ ‎except, possibly, on a countable set, where ‎ ‎and ‎‎ ‎are ‎right ‎and ‎left ‎derivatives, ‎respectively; ‎ Fact  ‎3:‎‎ is ‎decreasing ‎and ‎non-negative on ‎ ‎.‎ ‎‎ My question ‎is:‎ ‎‎Let ‎‎ ‎‎ ‎‎‎ ‎prove that the sequence ‎ ‎converges.‎‎ ‎Thanks‎ in advance.","‎g:‎\mathbb{R^+}‎‎‎\rightarrow‎‎\mathbb{R^+}‎ \log g(x)‎ ‎‎‎‎\displaystyle{\lim_{x\to\infty}}‎\frac{g(x+w)}{g(x)} = 1‎ ‎w>0‎ ‎g(x)‎ \log g(x)‎ ‎‎\frac{g^\prime_{-}(x) + g^\prime_{+}(x) ‎}{2g(x)}‎ ‎g^\prime_{+}(x‏)‎ ‎g^\prime_{-}(x)‎ ‎‎\frac{g^‎\prime_{-}(x) + g^‎\prime_{+}(x) ‎}{2g(x)}‎ ‎‎\mathbb{R}‎^+‎ \begin{align*}‎‎
‎F(n) = \sum_{i=1}^n ‎‎\frac{g^\prime_{-}(i) + g^\prime_{+}(i) ‎}{2g(i)} - \log g(n),
‎\end{align*} ‎\{F(n)\}‎","['real-analysis', 'sequences-and-series', 'derivatives', 'convergence-divergence', 'convex-analysis']"
39,any real number between $0$ and $1$ is expressible as an (infinite) sum of particular fractions,any real number between  and  is expressible as an (infinite) sum of particular fractions,0 1,"If $0 < x \le 1$ then there is one and only one sequence of positive integers $(k_v)$ , with $$1 < k_1 \le k_2\le k_3\le\cdots,$$ for which $$x={1\over k_1}+{1\over k_1k_2}+\cdots+{1\over k_1k_2\cdots k_n}+\cdots$$ $x$ is rational if and only if the $k_v$ are all equal after some index $v_0$ . As far as the last statement is concerned, the if part is easy. I don't know how to build such a sequence. If I knew how to generate the $k_v$ I could probably show also the only if part. Hints? I found that for $x \ne 1$ , $\lfloor{xk_1}\rfloor = 1$ and also $\lfloor{k_2(xk_1-1)\rfloor} = 1$ and so on, so if I can determine $k_1$ from the first equation, I can determine also $k_2$ from the second, provided $(xk_1-1)$ kind of satisfy the same conditions as $x$ . I don't know if this pattern is correct however, for I need to establish uniqueness. Also it doesn't seem so obvious at first glance how to prove that such a sequence gives $x$ . Obviously I can't determine $k_1$ from just the first equation, since for example, if $x = 1/2$ then both $k_1 = 2$ and $k_1 = 3$ can be chosen. Also for $x = 1$ one has $x = {1\over2} + {1\over2\cdot2}+\cdots$ and that's why $\lfloor k_1x\rfloor \ne 1$ Uniqueness is easy as well to prove. For let there exist two such sequences $a_n$ and $b_n$ , and let $m \ge 1$ be the first integer such that w.l.o.g. $b_m > a_m$ . Then $0 = ({1\over a_m}+{1\over a_ma_{m+1}}+\cdots)-({1\over b_m}+{1\over b_mb_{m+1}}+\cdots)$ . We see that the first sum is strictly greater than ${1\over a_m}$ , whereas the second sum is $\le {1\over a_m}$ , because from $b_m \ge a_m+1$ we obtain that the $n$ -th term for $n \ge 1$ is $\le \left({1\over 1+a_m}\right)^n$ . Thus the difference cannot be $0$ .","If then there is one and only one sequence of positive integers , with for which is rational if and only if the are all equal after some index . As far as the last statement is concerned, the if part is easy. I don't know how to build such a sequence. If I knew how to generate the I could probably show also the only if part. Hints? I found that for , and also and so on, so if I can determine from the first equation, I can determine also from the second, provided kind of satisfy the same conditions as . I don't know if this pattern is correct however, for I need to establish uniqueness. Also it doesn't seem so obvious at first glance how to prove that such a sequence gives . Obviously I can't determine from just the first equation, since for example, if then both and can be chosen. Also for one has and that's why Uniqueness is easy as well to prove. For let there exist two such sequences and , and let be the first integer such that w.l.o.g. . Then . We see that the first sum is strictly greater than , whereas the second sum is , because from we obtain that the -th term for is . Thus the difference cannot be .","0 < x \le 1 (k_v) 1 < k_1 \le k_2\le k_3\le\cdots, x={1\over k_1}+{1\over k_1k_2}+\cdots+{1\over k_1k_2\cdots k_n}+\cdots x k_v v_0 k_v x \ne 1 \lfloor{xk_1}\rfloor = 1 \lfloor{k_2(xk_1-1)\rfloor} = 1 k_1 k_2 (xk_1-1) x x k_1 x = 1/2 k_1 = 2 k_1 = 3 x = 1 x = {1\over2} + {1\over2\cdot2}+\cdots \lfloor k_1x\rfloor \ne 1 a_n b_n m \ge 1 b_m > a_m 0 = ({1\over a_m}+{1\over a_ma_{m+1}}+\cdots)-({1\over b_m}+{1\over b_mb_{m+1}}+\cdots) {1\over a_m} \le {1\over a_m} b_m \ge a_m+1 n n \ge 1 \le \left({1\over 1+a_m}\right)^n 0","['real-analysis', 'sequences-and-series']"
40,Convergence of positive sequence in which each term is less than the average of preceding 2 terms [duplicate],Convergence of positive sequence in which each term is less than the average of preceding 2 terms [duplicate],,This question already has answers here : $x_{n+m}\le \frac{x_n+x_{n+1}+\cdots+x_{n+m-1}}{m}$. Prove that this sequence has a limit. (3 answers) Closed 4 years ago . It is easy to prove any sequence generated by $$ x_{n+1}:=\frac{x_n+x_{n-1}}{2} $$ is convergent. But how about if the sequence only satisfies $$ 0\leq x_{n+1}\leq\frac{x_n+x_{n-1}}{2} $$ with positive $x_0$ and $x_1$ ? @Martin R gives a proof. Could this result be extended to $n$ preceding terms?,This question already has answers here : $x_{n+m}\le \frac{x_n+x_{n+1}+\cdots+x_{n+m-1}}{m}$. Prove that this sequence has a limit. (3 answers) Closed 4 years ago . It is easy to prove any sequence generated by is convergent. But how about if the sequence only satisfies with positive and ? @Martin R gives a proof. Could this result be extended to preceding terms?,"
x_{n+1}:=\frac{x_n+x_{n-1}}{2}
 
0\leq x_{n+1}\leq\frac{x_n+x_{n-1}}{2}
 x_0 x_1 n","['sequences-and-series', 'convergence-divergence']"
41,Why is $\sum_{k=1}^\infty \frac{1}{(b+1)^k}=\frac{1}{b}$?,Why is ?,\sum_{k=1}^\infty \frac{1}{(b+1)^k}=\frac{1}{b},"I was looking through in stack math and got this answer: Prove that $e$ is irrational by Yiorgos S. Smyrlis . (This answer is copied below). Since I cannot comment I can only ask here. Here is the information provided. Hints. We first show that $2<\mathrm{e}<3$ (see below), and hence $\mathrm{e}$ is not an integer. Next, following up OP's thought, assuming $\mathrm{e}=a/b$ , we multiply by $b!$ and we obtain $$ \sum_{k=0}^\infty \frac{b!}{k!}=a\cdot (b-1)! \tag{1} $$ The right hand side of $(1)$ is an integer. The left hand side of $(1)$ is of the form $$ \sum_{k=0}^b \frac{b!}{k!}+\sum_{k=b+1}^\infty \frac{b!}{k!}= p+r. $$ Note that $p=\sum_{k=0}^b \frac{b!}{k!}$ is an integer, while $$ 0<r=\sum_{k=b+1}^\infty \frac{b!}{k!}=\frac{1}{b+1}+\frac{1}{(b+1)(b+2)}+\cdots<\sum_{k=1}^\infty \frac{1}{(b+1)^k}=\frac{1}{b}<1. $$ Note. The fact that $\mathrm{e}\in (2,3)$ can be derived from the inequalities $$  \left(1+\frac{1}{n}\right)^{\!n}<\mathrm{e}<\left(1+\frac{1}{n}\right)^{\!n+1}, $$ for $n=1$ for the left inequality and $n=5$ for the right inequality.","I was looking through in stack math and got this answer: Prove that is irrational by Yiorgos S. Smyrlis . (This answer is copied below). Since I cannot comment I can only ask here. Here is the information provided. Hints. We first show that (see below), and hence is not an integer. Next, following up OP's thought, assuming , we multiply by and we obtain The right hand side of is an integer. The left hand side of is of the form Note that is an integer, while Note. The fact that can be derived from the inequalities for for the left inequality and for the right inequality.","e 2<\mathrm{e}<3 \mathrm{e} \mathrm{e}=a/b b! 
\sum_{k=0}^\infty \frac{b!}{k!}=a\cdot (b-1)! \tag{1}
 (1) (1) 
\sum_{k=0}^b \frac{b!}{k!}+\sum_{k=b+1}^\infty \frac{b!}{k!}= p+r.
 p=\sum_{k=0}^b \frac{b!}{k!} 
0<r=\sum_{k=b+1}^\infty \frac{b!}{k!}=\frac{1}{b+1}+\frac{1}{(b+1)(b+2)}+\cdots<\sum_{k=1}^\infty \frac{1}{(b+1)^k}=\frac{1}{b}<1.
 \mathrm{e}\in (2,3)  
\left(1+\frac{1}{n}\right)^{\!n}<\mathrm{e}<\left(1+\frac{1}{n}\right)^{\!n+1},
 n=1 n=5","['real-analysis', 'sequences-and-series']"
42,Using the limit comparison test,Using the limit comparison test,,"Given the infinite series: $$\sum^{\infty}_{n=1}\frac{1}{2n+3}$$ Determine whether this series converges. The answer key used the integral test to determine that no, this series does not converge. I came at this problem differently. I first tried using the comparison test with $\frac1n$ which was inconclusive. I then tried the limit comparison test - again with $\frac1n$ . I got a limit of $\frac12$ . Because this is a finite, positive number - the limit diverges. As a beginner, I am simply unsure that my method was legitimate - after all - its a fifty fifty chance of getting it right:) So, I am asking here- did I find the answer using a legitimate method?","Given the infinite series: Determine whether this series converges. The answer key used the integral test to determine that no, this series does not converge. I came at this problem differently. I first tried using the comparison test with which was inconclusive. I then tried the limit comparison test - again with . I got a limit of . Because this is a finite, positive number - the limit diverges. As a beginner, I am simply unsure that my method was legitimate - after all - its a fifty fifty chance of getting it right:) So, I am asking here- did I find the answer using a legitimate method?",\sum^{\infty}_{n=1}\frac{1}{2n+3} \frac1n \frac1n \frac12,"['calculus', 'sequences-and-series', 'convergence-divergence']"
43,Infinite sign switching 1/prime series,Infinite sign switching 1/prime series,,"Given the following series \begin{equation} \sum _{p{\text{ prime}} \atop p{\text{ is the i'th prime}}}{ \frac {(-1)^i}{p}} \end{equation} (sry maybe there is a better way to describe this series)  so the first n steps would look like this: \begin{equation} \frac{1}{2} - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{11} - ... \end{equation} My Questions: Does this series converge? It seems to me that it should but i would like to see a proof. Here is what the first 500 steps look like plotted: The number it seems to converges to (gained from a simulation) is round about 0.2696... Is there anything special about this number? Does it have some name? What is the exact number this series converges to (if it does), and if this is possible to say is this number irrational (I would guess yes)?","Given the following series (sry maybe there is a better way to describe this series)  so the first n steps would look like this: My Questions: Does this series converge? It seems to me that it should but i would like to see a proof. Here is what the first 500 steps look like plotted: The number it seems to converges to (gained from a simulation) is round about 0.2696... Is there anything special about this number? Does it have some name? What is the exact number this series converges to (if it does), and if this is possible to say is this number irrational (I would guess yes)?","\begin{equation}
\sum _{p{\text{ prime}} \atop p{\text{ is the i'th prime}}}{ \frac {(-1)^i}{p}}
\end{equation} \begin{equation}
\frac{1}{2} - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{11} - ...
\end{equation}","['sequences-and-series', 'number-theory', 'prime-numbers']"
44,"Convergence of $\prod_{k=1}^n \left( I_d + \frac{1}{n} A\left(\frac{k}{n}\right) \right)$ for $A : [0, 1] \rightarrow \mathcal{M}_d(\mathbf{R})$",Convergence of  for,"\prod_{k=1}^n \left( I_d + \frac{1}{n} A\left(\frac{k}{n}\right) \right) A : [0, 1] \rightarrow \mathcal{M}_d(\mathbf{R})","The problem Let $d \geq 1$ and $A : [0, 1] \rightarrow \mathcal{M}_d(\mathbf{R})$ be a continuous function. For $n \geq 1$ , define: $$ E_n := \prod_{k=1}^n \left( I_d + \frac{1}{n} A \left( \frac{k}{n} \right)  \right) $$ The goal is to study the convergence of $(E_n)_{n \geq 1}$ . I would like to find when (under which conditions on $A$ ) this sequence converges, to which limit, and when it does not converge. My try My first idea is to show that: $$ E_n \underset{n \to +\infty}{\longrightarrow} \exp \left( \int_0^1 A  \right) $$ I have succeeded to prove it for $d = 1$ . It consists in taking the logarithm of $E_n$ , use the inequalities $x - \frac{x^2}{2} \leq \ln(1+x) \leq x$ for $x \in [0, 1]$ and finally the squeeze theorem and Riemann sums. The result is also true when $A$ is a constant matrix. But I have a hard time to generalize the proof with logarithms. I know one can define the logarithm of matrices not too far from $I_d$ , but nothing about the additivity of this logarithm.","The problem Let and be a continuous function. For , define: The goal is to study the convergence of . I would like to find when (under which conditions on ) this sequence converges, to which limit, and when it does not converge. My try My first idea is to show that: I have succeeded to prove it for . It consists in taking the logarithm of , use the inequalities for and finally the squeeze theorem and Riemann sums. The result is also true when is a constant matrix. But I have a hard time to generalize the proof with logarithms. I know one can define the logarithm of matrices not too far from , but nothing about the additivity of this logarithm.","d \geq 1 A : [0, 1] \rightarrow \mathcal{M}_d(\mathbf{R}) n \geq 1 
E_n := \prod_{k=1}^n \left( I_d + \frac{1}{n} A \left( \frac{k}{n} \right)  \right)
 (E_n)_{n \geq 1} A 
E_n \underset{n \to +\infty}{\longrightarrow} \exp \left( \int_0^1 A  \right)
 d = 1 E_n x - \frac{x^2}{2} \leq \ln(1+x) \leq x x \in [0, 1] A I_d","['linear-algebra', 'integration', 'sequences-and-series', 'matrices', 'matrix-exponential']"
45,Prove that the following series converges to $1 - \frac{\pi}{4}$.,Prove that the following series converges to .,1 - \frac{\pi}{4},"We got the following identity by solving a problem in two different ways, but we don't know how to prove it. $$\sum_{n=0}^{\infty} [Si((4n+1)\pi)-Si((4n+3)\pi)] = 1 - \frac{\pi}{4}$$ where $$Si(x)=\int_0^x \frac{\sin(t)}{t}dt$$ We were able to verify that the first few thousand partial sums are very close to the RHS. Is there a way to prove this identity?","We got the following identity by solving a problem in two different ways, but we don't know how to prove it. where We were able to verify that the first few thousand partial sums are very close to the RHS. Is there a way to prove this identity?",\sum_{n=0}^{\infty} [Si((4n+1)\pi)-Si((4n+3)\pi)] = 1 - \frac{\pi}{4} Si(x)=\int_0^x \frac{\sin(t)}{t}dt,"['sequences-and-series', 'definite-integrals', 'fourier-analysis']"
46,Infinite prime cylinders?,Infinite prime cylinders?,,"Define a prime $n$ -circle as a circular sequence of $n$ distinct natural numbers such that adjacent elements sum to a prime (including $n^{\textrm{th}}$ $+$ $1^{\textrm{st}}$ ). For example: $$6, 1, 2, 5, 8, 9, 4, 7 \;.$$ This is a variation on the prime circles counted in the integer sequence A051252 , in that I am not insisting that the numbers be drawn from $\{1,2,\ldots,n\}$ . (The above circle misses $3$ .) Define a prime $n$ -cylinder as an aligned stacking of prime circles, such that adjacent numbers vertically also sum to a prime. (However, no wrap-around requirement from top to bottom.) Further, every circular rung of the cyclinder should be a distinct permutation—no repeats allowed (also disallowing reversals). For example, here is a prime octagonal-cylinder consisting of  four prime circles: And here displayed as a matrix: $$ \left( \begin{array}{cccccccc}  7 & 4 & 3 & 8 & 9 & 2 & 5 & 6    \\  16 & 15 & 8 & 9 & 4 & 3 & 2 &    1 \\  7 & 4 & 9 & 8 & 3 & 2 & 15 &    16 \\  6 & 1 & 2 & 5 & 8 & 9 & 4 & 7    \\ \end{array} \right) $$ Q . Do there exist infinitely tall prime $n$ -cylinders,   for each $n$ ? The answer should be the same whether the cyclinder is infinite just in one direction, or bi-infinite, extending infinitely in both directions. Although it seems relatively easy to add rungs in a greedy fashion, I don't see how to prove that this approach can extend infinitely. For example, here is how one might get ""stuck."" Suppose you are adding the last number $x$ to the top prime circle. The three numbers adjacent to $x$ (left, right, below) could be $1$ , $3$ , and $5$ . But the only number $x$ such that each of $\{x+1, x+3, x+5 \}$ is prime is $x=2$ , which may already have been used in that top circle.","Define a prime -circle as a circular sequence of distinct natural numbers such that adjacent elements sum to a prime (including ). For example: This is a variation on the prime circles counted in the integer sequence A051252 , in that I am not insisting that the numbers be drawn from . (The above circle misses .) Define a prime -cylinder as an aligned stacking of prime circles, such that adjacent numbers vertically also sum to a prime. (However, no wrap-around requirement from top to bottom.) Further, every circular rung of the cyclinder should be a distinct permutation—no repeats allowed (also disallowing reversals). For example, here is a prime octagonal-cylinder consisting of  four prime circles: And here displayed as a matrix: Q . Do there exist infinitely tall prime -cylinders,   for each ? The answer should be the same whether the cyclinder is infinite just in one direction, or bi-infinite, extending infinitely in both directions. Although it seems relatively easy to add rungs in a greedy fashion, I don't see how to prove that this approach can extend infinitely. For example, here is how one might get ""stuck."" Suppose you are adding the last number to the top prime circle. The three numbers adjacent to (left, right, below) could be , , and . But the only number such that each of is prime is , which may already have been used in that top circle.","n n n^{\textrm{th}} + 1^{\textrm{st}} 6, 1, 2, 5, 8, 9, 4, 7 \;. \{1,2,\ldots,n\} 3 n 
\left(
\begin{array}{cccccccc}
 7 & 4 & 3 & 8 & 9 & 2 & 5 & 6
   \\
 16 & 15 & 8 & 9 & 4 & 3 & 2 &
   1 \\
 7 & 4 & 9 & 8 & 3 & 2 & 15 &
   16 \\
 6 & 1 & 2 & 5 & 8 & 9 & 4 & 7
   \\
\end{array}
\right)
 n n x x 1 3 5 x \{x+1, x+3, x+5 \} x=2","['sequences-and-series', 'number-theory', 'prime-numbers']"
47,Exercise of integration and sum [duplicate],Exercise of integration and sum [duplicate],,"This question already has answers here : A curious integral (4 answers) Closed 4 years ago . Show that $$\int_0^\infty \frac{\sin x}{e^x-1}\,dx=\sum_{n=1}^\infty \frac{1}{n^2+1}.$$ Thoughts: I think I have to use the dominated convergence theorem, but I don't see how.. I tried expanding $\frac{1}{1-e^x}=1+e^x+e^{2x}+\ldots$ but then realised this works only $|e^x|<1$ .","This question already has answers here : A curious integral (4 answers) Closed 4 years ago . Show that Thoughts: I think I have to use the dominated convergence theorem, but I don't see how.. I tried expanding but then realised this works only .","\int_0^\infty \frac{\sin x}{e^x-1}\,dx=\sum_{n=1}^\infty \frac{1}{n^2+1}. \frac{1}{1-e^x}=1+e^x+e^{2x}+\ldots |e^x|<1","['calculus', 'integration', 'sequences-and-series']"
48,Converse of 0/0 Type Stolz Theorem,Converse of 0/0 Type Stolz Theorem,,"One version of Stolz Theorem is that Given two sequences $\{a_n\},\{b_n\}$ , with $\lim_{n\to\infty}a_n=0$ and $\{b_n\}$ is strictly decreasing and its limit is also $0$ . Then $$\lim_{n\to\infty}\dfrac{a_n-a_{n+1}}{b_n-b_{n+1}}=L<\infty$$ implies $$\lim_{n\to\infty}\dfrac{a_n}{b_n}=L.$$ I want to find a counterexample for the converse statement, although I'm not so sure is there any counterexample. I first assume $a_n/b_n$ has a limit and its limit is $L$ , then $$\dfrac{a_n-a_{n+1}}{b_n-b_{n+1}}-\dfrac{a_n}{b_n}=\dfrac{a_n/b_n-a_{n+1}/b_{n+1}}{b_n/b_{n+1}-1}$$ If $\lim b_n/b_{n+1}\neq 1$ , then it is easy to see that the inverse is also true. But if $b_n/b_{n+1}\to 1$ , we have $$\lim_{n\to\infty}\dfrac{a_n}{a_{n+1}}=\lim_{n\to\infty}\dfrac{a_n}{a_{n+1}}\cdot\dfrac{b_{n+1}}{b_n}=\dfrac LL=1$$ so if there is a counterexample, it must satisfy both $b_n/b_{n+1}\to 1$ and $a_n/a_{n+1}\to 1$ . Being stricted the search domain, I'm still not able to work out a counterexample. Hence is there really a counterexample or the converse is indeed true?","One version of Stolz Theorem is that Given two sequences , with and is strictly decreasing and its limit is also . Then implies I want to find a counterexample for the converse statement, although I'm not so sure is there any counterexample. I first assume has a limit and its limit is , then If , then it is easy to see that the inverse is also true. But if , we have so if there is a counterexample, it must satisfy both and . Being stricted the search domain, I'm still not able to work out a counterexample. Hence is there really a counterexample or the converse is indeed true?","\{a_n\},\{b_n\} \lim_{n\to\infty}a_n=0 \{b_n\} 0 \lim_{n\to\infty}\dfrac{a_n-a_{n+1}}{b_n-b_{n+1}}=L<\infty \lim_{n\to\infty}\dfrac{a_n}{b_n}=L. a_n/b_n L \dfrac{a_n-a_{n+1}}{b_n-b_{n+1}}-\dfrac{a_n}{b_n}=\dfrac{a_n/b_n-a_{n+1}/b_{n+1}}{b_n/b_{n+1}-1} \lim b_n/b_{n+1}\neq 1 b_n/b_{n+1}\to 1 \lim_{n\to\infty}\dfrac{a_n}{a_{n+1}}=\lim_{n\to\infty}\dfrac{a_n}{a_{n+1}}\cdot\dfrac{b_{n+1}}{b_n}=\dfrac LL=1 b_n/b_{n+1}\to 1 a_n/a_{n+1}\to 1","['real-analysis', 'calculus', 'sequences-and-series', 'limits']"
49,Proving Convergence Using Cauchy Sequences,Proving Convergence Using Cauchy Sequences,,"Today I learned about Cauchy Sequences, defined as the following: A sequence $(x_n)$ is a Cauchy Sequence if $\forall\varepsilon>0,\exists N\in\mathbb{N}\ \forall n,m\geq N: |x_n-x_m|<\varepsilon$ . Assuming we are dealing with a complete metric space, all Cauchy Sequences converge, right? If so, for what sequences is it easier to show they are Cauchy in order to show they converge (as opposed to the limit definition of a convergent sequence)? My professor said they tend to be sequences whose limit is not immediately clear but I can't think of any such examples. Could someone please share an example of a convergent sequence whose limit and perhaps bounds are non-trivial but can be proven to be convergent by proving they are Cauchy? Thank you!","Today I learned about Cauchy Sequences, defined as the following: A sequence is a Cauchy Sequence if . Assuming we are dealing with a complete metric space, all Cauchy Sequences converge, right? If so, for what sequences is it easier to show they are Cauchy in order to show they converge (as opposed to the limit definition of a convergent sequence)? My professor said they tend to be sequences whose limit is not immediately clear but I can't think of any such examples. Could someone please share an example of a convergent sequence whose limit and perhaps bounds are non-trivial but can be proven to be convergent by proving they are Cauchy? Thank you!","(x_n) \forall\varepsilon>0,\exists N\in\mathbb{N}\ \forall n,m\geq N: |x_n-x_m|<\varepsilon","['sequences-and-series', 'cauchy-sequences']"
50,How to study this sequence $u_n=\sum_{k=1}^{n}\frac{1}{n+2k}$,How to study this sequence,u_n=\sum_{k=1}^{n}\frac{1}{n+2k},Please is there any way to prove that sequence is increasing ? I do: $u_{n+1}-u_n=\sum_{k=1}^{n+1}\frac{1}{(n+1)+2k}-\sum_{k=1}^{n}\frac{1}{n+2k}=\left[\frac{1}{n+3}+\frac{1}{n+5}+\ldots+\frac{1}{3n+1}+\frac{1}{3n+3}\right]-\left[\frac{1}{n+2}+\frac{1}{n+4}+\ldots+\frac{1}{3n}\right]$ i don't know how to continue,Please is there any way to prove that sequence is increasing ? I do: i don't know how to continue,u_{n+1}-u_n=\sum_{k=1}^{n+1}\frac{1}{(n+1)+2k}-\sum_{k=1}^{n}\frac{1}{n+2k}=\left[\frac{1}{n+3}+\frac{1}{n+5}+\ldots+\frac{1}{3n+1}+\frac{1}{3n+3}\right]-\left[\frac{1}{n+2}+\frac{1}{n+4}+\ldots+\frac{1}{3n}\right],"['real-analysis', 'sequences-and-series']"
51,Prove the equality (Taylor series).,Prove the equality (Taylor series).,,"Prove the equality: $$ \frac{1}{3}\left(e^x+2e^{-x/2}\cos\frac{x\sqrt{3}}{2}\right)= \sum_{n=0}^{\infty}\frac{x^{3n}}{(3n)!},\ \ -\infty<x<+\infty $$ I tried to apply Euler's formula ( $e^{ix}=\cos x+i\sin x$ ) to this problem but it went rather unsuccessful. Here is what I did: $$ e^{-x/2}=e^{i(ix/2)}=\cos\frac{ix}{2}+i\sin\frac{ix}{2}\Rightarrow\\ \Rightarrow 2e^{-x/2}\cos\frac{x\sqrt{3}}{2}=2\cos\frac{ix}{2}\cos\frac{x\sqrt{3}}{2}+ 2i\sin\frac{ix}{2}\cos\frac{x\sqrt{3}}{2}=\\ =\cos\frac{x(i+\sqrt{3})}{2}+\cos\frac{x(i-\sqrt{3})}{2}+ i\sin\frac{x(i+\sqrt{3})}{2}+i\sin\frac{x(i-\sqrt{3})}{2}=\\ =e^{ix(i+\sqrt{3})/2}+e^{ix(i-\sqrt{3})/2}= e^{x(-1+i\sqrt{3})/2}+e^{x(-1-i\sqrt{3})/2} $$ Then I tried to use Maclaurin series for $e^{x(-1+i\sqrt{3})/2}$ and $e^{x(-1-i\sqrt{3})/2}$ after which I got completely befuddled because it seemed to me that I had only complicated the initial problem. So, if anyone could help me, I would appreciate it.","Prove the equality: I tried to apply Euler's formula ( ) to this problem but it went rather unsuccessful. Here is what I did: Then I tried to use Maclaurin series for and after which I got completely befuddled because it seemed to me that I had only complicated the initial problem. So, if anyone could help me, I would appreciate it.","
\frac{1}{3}\left(e^x+2e^{-x/2}\cos\frac{x\sqrt{3}}{2}\right)=
\sum_{n=0}^{\infty}\frac{x^{3n}}{(3n)!},\ \ -\infty<x<+\infty
 e^{ix}=\cos x+i\sin x 
e^{-x/2}=e^{i(ix/2)}=\cos\frac{ix}{2}+i\sin\frac{ix}{2}\Rightarrow\\
\Rightarrow 2e^{-x/2}\cos\frac{x\sqrt{3}}{2}=2\cos\frac{ix}{2}\cos\frac{x\sqrt{3}}{2}+
2i\sin\frac{ix}{2}\cos\frac{x\sqrt{3}}{2}=\\
=\cos\frac{x(i+\sqrt{3})}{2}+\cos\frac{x(i-\sqrt{3})}{2}+
i\sin\frac{x(i+\sqrt{3})}{2}+i\sin\frac{x(i-\sqrt{3})}{2}=\\
=e^{ix(i+\sqrt{3})/2}+e^{ix(i-\sqrt{3})/2}=
e^{x(-1+i\sqrt{3})/2}+e^{x(-1-i\sqrt{3})/2}
 e^{x(-1+i\sqrt{3})/2} e^{x(-1-i\sqrt{3})/2}","['calculus', 'sequences-and-series', 'taylor-expansion']"
52,Which is the proper taylor series?,Which is the proper taylor series?,,"My friend and I are trying to tackle the following problem: Write the Taylor series around a = 1 for $xe^{x}$ I approached the problem the following way: We know that Taylor series for $e^x$ around 1 are: $f(x) = e^{x} = \Sigma \frac{e^{1}}{n!}(x-1)^{n}$ so if we do g(x) = $xe^{x}$ , $g(x) = x(f(x))$ and $ g(x) = x(\Sigma \frac{e}{n!}(x-1)^{n}) = \Sigma x\frac{e}{n!}(x-1)^{n}$ from n = 0 to infinty Which, according to WolframAlpha, leads back to $xe^{x}$ . Now, my friend did it the following way:  he found f(x) of $xe^{x}$ , and then f'(x)= $xe^{x}+e^{x}$ , and then f''(x) = $xe^{x} + e^{x} + e^{x}$ , and so forth (each iteration added another $e^{x}$ ). He came up with the following expression: $\Sigma (n+1)\frac{e(x-1)^{n}}{n!}$ from n=0 to infinity. I put both equations on a graph and they both seem to approximate $xe^{x}$ fairly well around a=1. So my question is, who has the most acceptable Taylor Series? Is the other answer wrong?","My friend and I are trying to tackle the following problem: Write the Taylor series around a = 1 for I approached the problem the following way: We know that Taylor series for around 1 are: so if we do g(x) = , and from n = 0 to infinty Which, according to WolframAlpha, leads back to . Now, my friend did it the following way:  he found f(x) of , and then f'(x)= , and then f''(x) = , and so forth (each iteration added another ). He came up with the following expression: from n=0 to infinity. I put both equations on a graph and they both seem to approximate fairly well around a=1. So my question is, who has the most acceptable Taylor Series? Is the other answer wrong?",xe^{x} e^x f(x) = e^{x} = \Sigma \frac{e^{1}}{n!}(x-1)^{n} xe^{x} g(x) = x(f(x))  g(x) = x(\Sigma \frac{e}{n!}(x-1)^{n}) = \Sigma x\frac{e}{n!}(x-1)^{n} xe^{x} xe^{x} xe^{x}+e^{x} xe^{x} + e^{x} + e^{x} e^{x} \Sigma (n+1)\frac{e(x-1)^{n}}{n!} xe^{x},"['sequences-and-series', 'power-series', 'taylor-expansion']"
53,Evaluate product $\prod_{i=1}^{n}(\frac{i}{i+x})^{i}$,Evaluate product,\prod_{i=1}^{n}(\frac{i}{i+x})^{i},Is there a way to evaluate this product so that the answer is in closed form? $$\prod_{i=1}^{n}\left(\frac{i}{i+x}\right)^{i}=\left(\frac{1}{1+x}\right)\left(\frac{2}{2+x}\right)^{2}\cdots\left(\frac{n}{n+x}\right)^{n}$$ It can of course be written as $$\prod_{i=1}^{n}\left(\frac{1}{1+\frac{x}{i}}\right)^{i}$$ but I don't know if that helps. Thank you!,Is there a way to evaluate this product so that the answer is in closed form? It can of course be written as but I don't know if that helps. Thank you!,\prod_{i=1}^{n}\left(\frac{i}{i+x}\right)^{i}=\left(\frac{1}{1+x}\right)\left(\frac{2}{2+x}\right)^{2}\cdots\left(\frac{n}{n+x}\right)^{n} \prod_{i=1}^{n}\left(\frac{1}{1+\frac{x}{i}}\right)^{i},"['sequences-and-series', 'products']"
54,Has this series for $\ln(2)$ been discovered yet?,Has this series for  been discovered yet?,\ln(2),"$$\ln(2)=\frac{1}{2}+\frac{1}{4}-\frac{1}{5}+\frac{1}{6}-\frac{1}{9}+\frac{1}{10}-\frac{1}{11}+\frac{1}{12}-\frac{1}{13}+...$$ This is something I came up with and was intrigued, and no this isn't random; there's a pattern to this. Since you guys are asking for a relation, here it is; $$\ln(2)=1+\sum_{n=1}^∞ \frac{(-1)^{S_n-1}}{S_n-1} $$ Where $S_n$ is the $n$ -th number that is not a perfect power ( A007916 , and $S_1$ is $2$ ). Proof to this is also somewhat easy to derive.","This is something I came up with and was intrigued, and no this isn't random; there's a pattern to this. Since you guys are asking for a relation, here it is; Where is the -th number that is not a perfect power ( A007916 , and is ). Proof to this is also somewhat easy to derive.",\ln(2)=\frac{1}{2}+\frac{1}{4}-\frac{1}{5}+\frac{1}{6}-\frac{1}{9}+\frac{1}{10}-\frac{1}{11}+\frac{1}{12}-\frac{1}{13}+... \ln(2)=1+\sum_{n=1}^∞ \frac{(-1)^{S_n-1}}{S_n-1}  S_n n S_1 2,"['sequences-and-series', 'number-theory', 'logarithms', 'math-history']"
55,Limit Of A Sequence Formal Proof,Limit Of A Sequence Formal Proof,,"Let $\left (x_n \right )_{n=1}^{\infty}$ be a convergent sequence in $\mathbb{R}$ with limit $x$ . Show that $\lim_{x\rightarrow \infty}\frac{1}{n}\sum_{k=1}^{n}x_k = x$ . I had been working at it for awhile and was completely lost upon looking at the solution I had many questions even after staring at it for awhile, the solution states: Let $\varepsilon > 0$ . As $\lim_{x\rightarrow \infty}x_n = x$ , there is $n_1  \in \mathbb{N}$ s.t. $|x_n -x| < \frac{\varepsilon}{2}$ for $n \ge n_1$ . Choose $n_2 \in \mathbb{N}$ s.t. $$\frac{1}{n_2}\left|\sum_{k=1}^{n_1 - 1}(x_k-x)\right| < \frac{\varepsilon}{2}. \tag{1}$$ Set $n_\varepsilon := \max\{n_1,n_2\}$ . For $n \ge n_\epsilon$ , we have: \begin{align*} \left|\sum_{k=1}^{n}x_k-x\right| &= \left|\sum_{k=1}^{n_1 -1}(x_k-x)\right| \\ &\le \frac{1}{n}\left|\sum_{k=1}^{n}x_k-x\right| + \frac{1}{n}\sum_{k=n_1}^{n}|x_k-x| \\ &\le \frac{1}{n_2}\left|\sum_{k=1}^{n}x_k-x\right| + \frac{1}{n}\sum_{k=n_1}^{n}|x_k-x| \\ &< \frac{\varepsilon}{2} + \frac{n + 1 -n_1}{n} \max_{k=n_1,\ldots, n} |x_k - x| \\ &< \frac{\epsilon}{2} + \frac{\epsilon}{2} \\ &< \epsilon. \end{align*} The thing I don't understand is how we get: 1) I don't quite get the thought process that goes into determining (1) before we start the proof. 2) $\frac{1}{n}\sum_{k=n_1}^{n}|x_k-x| < \frac{n + 1 -n_1}{n} \max_{k=n_1,\ldots, n} |x_k - x|$ Clarification on either of these steps would be greatly appreciated thank you.","Let be a convergent sequence in with limit . Show that . I had been working at it for awhile and was completely lost upon looking at the solution I had many questions even after staring at it for awhile, the solution states: Let . As , there is s.t. for . Choose s.t. Set . For , we have: The thing I don't understand is how we get: 1) I don't quite get the thought process that goes into determining (1) before we start the proof. 2) Clarification on either of these steps would be greatly appreciated thank you.","\left (x_n \right )_{n=1}^{\infty} \mathbb{R} x \lim_{x\rightarrow \infty}\frac{1}{n}\sum_{k=1}^{n}x_k = x \varepsilon > 0 \lim_{x\rightarrow \infty}x_n = x n_1 
\in \mathbb{N} |x_n -x| < \frac{\varepsilon}{2} n \ge n_1 n_2 \in \mathbb{N} \frac{1}{n_2}\left|\sum_{k=1}^{n_1 - 1}(x_k-x)\right| < \frac{\varepsilon}{2}. \tag{1} n_\varepsilon := \max\{n_1,n_2\} n \ge n_\epsilon \begin{align*}
\left|\sum_{k=1}^{n}x_k-x\right| &= \left|\sum_{k=1}^{n_1 -1}(x_k-x)\right| \\
&\le \frac{1}{n}\left|\sum_{k=1}^{n}x_k-x\right| + \frac{1}{n}\sum_{k=n_1}^{n}|x_k-x| \\
&\le \frac{1}{n_2}\left|\sum_{k=1}^{n}x_k-x\right| + \frac{1}{n}\sum_{k=n_1}^{n}|x_k-x| \\
&< \frac{\varepsilon}{2} + \frac{n + 1 -n_1}{n} \max_{k=n_1,\ldots, n} |x_k - x| \\
&< \frac{\epsilon}{2} + \frac{\epsilon}{2} \\
&< \epsilon.
\end{align*} \frac{1}{n}\sum_{k=n_1}^{n}|x_k-x| < \frac{n + 1 -n_1}{n} \max_{k=n_1,\ldots, n} |x_k - x|","['real-analysis', 'sequences-and-series', 'proof-explanation']"
56,Advanced Sum: Compute $\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2}$,Advanced Sum: Compute,\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2},"How to prove $$\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2}= \\ \small{\frac43\ln^32\zeta(2)-\frac72\ln^22\zeta(3)-\frac{21}{16}\zeta(2)\zeta(3)+\frac{713}{64}\zeta(5)-\frac4{15}\ln^52-8\ln2\operatorname{Li}_4\left(\frac12\right)-8\operatorname{Li}_5\left(\frac12\right)}$$ where $H_n^{(q)}=\sum_{k=1}^n\frac{1}{n^q}$ is the harmonic number, $\operatorname{Li}_r(x)=\sum_{n=1}^\infty\frac{x^n}{n^r}$ is the polylogarithm function and $\zeta$ is the Riemann zeta function. This problem is proposed by Cornel with no solution submitted. My trial By applying integration by parts we have $$\int_0^1 x^{2n}(\operatorname{Li}_2(x)-\zeta(2))\ dx=-\frac{H_{2n}}{(2n+1)^2}-\frac{1}{(2n+1)^3}$$ now multiply both sides by $H_n^{(2)}$ then sum both sides from $n=1$ to $\infty$ we get $$\int_0^1(\operatorname{Li}_2(x)-\zeta(2))\sum_{n=1}^\infty H_n^{(2)}x^{2n}\ dx=-\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2}-\sum_{n=1}^\infty\frac{H_n^{(2)}}{(2n+1)^3}$$ $$\int_0^1\frac{(\operatorname{Li}_2(x)-\zeta(2))\operatorname{Li}_2(x^2)}{1-x^2}\ dx=-\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2}-\color{blue}{\sum_{n=1}^\infty\frac{H_n^{(2)}}{(2n+1)^3}}$$ I managed to find the blue sum using Abel's summation. As for the integral, I tried integration by parts but still resistant. QUESTION Any idea how to crack the integral or a different approach to find the target sum? Thanks.","How to prove where is the harmonic number, is the polylogarithm function and is the Riemann zeta function. This problem is proposed by Cornel with no solution submitted. My trial By applying integration by parts we have now multiply both sides by then sum both sides from to we get I managed to find the blue sum using Abel's summation. As for the integral, I tried integration by parts but still resistant. QUESTION Any idea how to crack the integral or a different approach to find the target sum? Thanks.","\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2}=
\\ \small{\frac43\ln^32\zeta(2)-\frac72\ln^22\zeta(3)-\frac{21}{16}\zeta(2)\zeta(3)+\frac{713}{64}\zeta(5)-\frac4{15}\ln^52-8\ln2\operatorname{Li}_4\left(\frac12\right)-8\operatorname{Li}_5\left(\frac12\right)} H_n^{(q)}=\sum_{k=1}^n\frac{1}{n^q} \operatorname{Li}_r(x)=\sum_{n=1}^\infty\frac{x^n}{n^r} \zeta \int_0^1 x^{2n}(\operatorname{Li}_2(x)-\zeta(2))\ dx=-\frac{H_{2n}}{(2n+1)^2}-\frac{1}{(2n+1)^3} H_n^{(2)} n=1 \infty \int_0^1(\operatorname{Li}_2(x)-\zeta(2))\sum_{n=1}^\infty H_n^{(2)}x^{2n}\ dx=-\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2}-\sum_{n=1}^\infty\frac{H_n^{(2)}}{(2n+1)^3} \int_0^1\frac{(\operatorname{Li}_2(x)-\zeta(2))\operatorname{Li}_2(x^2)}{1-x^2}\ dx=-\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n+1)^2}-\color{blue}{\sum_{n=1}^\infty\frac{H_n^{(2)}}{(2n+1)^3}}","['real-analysis', 'integration', 'sequences-and-series', 'harmonic-numbers', 'polylogarithm']"
57,Coefficients of polynomial $f_n(q)=\prod_{k=1}^{n}(1+q^k)$,Coefficients of polynomial,f_n(q)=\prod_{k=1}^{n}(1+q^k),"What is the general formula for the coefficient $c_n(k)$ where $$f_n(q)=\prod_{j=1}^{n}(1+q^j)=\sum_{k=0}^{n(n+1)/2}c_n(k)q^k?$$ I came across this problem while researching $q$ -analogs. Indeed, the polynomial in question is trivially given by $$f_n(q)=(-q;q)_n$$ where $(a;q)_n=\prod_{k=0}^{n-1}(1-aq^k)$ is the $q$ -Pochhammer symbol. From Wikipedia, I read that $$f_n(q)=\sum_{j=0}^{n}\left[{{n}\atop{j}}\right]_{q^2}q^j\tag{1}$$ where $$\left[{{n}\atop{j}}\right]_{q}=\frac{(q;q)_n}{(q;q)_j(q;q)_{n-j}}.$$ While $(1)$ is a cool identity nonetheless, it does not provide me with what I'm looking for, as $\left[{{n}\atop{j}}\right]_{q^2}$ is still dependent on $q$ . I worked out the first few polynomials by hand: $$\begin{align} f_1(q)&=1+q\\ f_2(q)&=1+q+q^2+q^3\\ f_3(q)&=1+q+q^2+2q^3+q^4+q^5+q^6\\ f_4(q)&=1+q+q^2+2q^3+2q^4+2q^5+2q^6+2q^7+q^8+q^9+q^{10}\\ f_5(q)&=1+q+q^2+2q^3+2q^4+3q^5+3q^6+3q^7+3q^8+3q^9+3q^{10}+2q^{11}+2q^{12}\\ &+q^{13}+q^{14}+q^{15}. \end{align}$$ It seems as if, in general, $$c_n(k)=c_n(n(n+1)/2-k).$$ I started trying to find recurrence relations. I saw that $$c_3(k)=\begin{cases} c_2(k) & 0\le k\le 2 \\ c_2(k)+c_2(k-3) & k=3 \\ c_2(k-3) & 4\le k \le 6 \end{cases}$$ and similarly $$c_4(k)=\begin{cases} c_3(k) & 0\le k\le 3 \\ c_3(k)+c_3(k-4) & 4\le k\le 6 \\ c_3(k-4) & 7\le k\le 10 \end{cases}$$ as well as $$c_5(k)=\begin{cases} c_4(k) & 0\le k\le 4 \\ c_4(k)+c_4(k-5) & 5\le k\le 10 \\ c_4(k-5) & 11\le k\le 15  \end{cases}$$ which hints at the general expression $$c_n(k)=\begin{cases} c_{n-1}(k) & 0\le k\le n-1 \\ c_{n-1}(k)+c_{n-1}(k-n) & n\le k\le n(n-1)/2 \\ c_{n-1}(k-n) & 1+n(n-1)/2\le k\le n(n+1)/2 \end{cases} .\tag{2}$$ This looks promising, but I am not sure if it is correct, because I just found it from basically guessing/recognizing a pattern which is not the most rigorous approach. Could someone verify $(2)$ and/or provide a simpler form of it? I ask this because I want to eventually find the coefficients $C(k)$ in $$(-q;q)_\infty=\sum_{k\ge0}C(k)q^k$$ by taking $\lim_{n\to\infty}c_n(k)$ . Edit: It may or may not help to note that, since $f_n(1)=\prod_{k=1}^{n}2=2^n$ , we have the interesting identity $$\sum_{k=0}^{n}c_n(k)=2^n.$$","What is the general formula for the coefficient where I came across this problem while researching -analogs. Indeed, the polynomial in question is trivially given by where is the -Pochhammer symbol. From Wikipedia, I read that where While is a cool identity nonetheless, it does not provide me with what I'm looking for, as is still dependent on . I worked out the first few polynomials by hand: It seems as if, in general, I started trying to find recurrence relations. I saw that and similarly as well as which hints at the general expression This looks promising, but I am not sure if it is correct, because I just found it from basically guessing/recognizing a pattern which is not the most rigorous approach. Could someone verify and/or provide a simpler form of it? I ask this because I want to eventually find the coefficients in by taking . Edit: It may or may not help to note that, since , we have the interesting identity","c_n(k) f_n(q)=\prod_{j=1}^{n}(1+q^j)=\sum_{k=0}^{n(n+1)/2}c_n(k)q^k? q f_n(q)=(-q;q)_n (a;q)_n=\prod_{k=0}^{n-1}(1-aq^k) q f_n(q)=\sum_{j=0}^{n}\left[{{n}\atop{j}}\right]_{q^2}q^j\tag{1} \left[{{n}\atop{j}}\right]_{q}=\frac{(q;q)_n}{(q;q)_j(q;q)_{n-j}}. (1) \left[{{n}\atop{j}}\right]_{q^2} q \begin{align}
f_1(q)&=1+q\\
f_2(q)&=1+q+q^2+q^3\\
f_3(q)&=1+q+q^2+2q^3+q^4+q^5+q^6\\
f_4(q)&=1+q+q^2+2q^3+2q^4+2q^5+2q^6+2q^7+q^8+q^9+q^{10}\\
f_5(q)&=1+q+q^2+2q^3+2q^4+3q^5+3q^6+3q^7+3q^8+3q^9+3q^{10}+2q^{11}+2q^{12}\\
&+q^{13}+q^{14}+q^{15}.
\end{align} c_n(k)=c_n(n(n+1)/2-k). c_3(k)=\begin{cases} c_2(k) & 0\le k\le 2 \\ c_2(k)+c_2(k-3) & k=3 \\ c_2(k-3) & 4\le k \le 6 \end{cases} c_4(k)=\begin{cases} c_3(k) & 0\le k\le 3 \\ c_3(k)+c_3(k-4) & 4\le k\le 6 \\ c_3(k-4) & 7\le k\le 10 \end{cases} c_5(k)=\begin{cases} c_4(k) & 0\le k\le 4 \\ c_4(k)+c_4(k-5) & 5\le k\le 10 \\ c_4(k-5) & 11\le k\le 15  \end{cases} c_n(k)=\begin{cases} c_{n-1}(k) & 0\le k\le n-1 \\ c_{n-1}(k)+c_{n-1}(k-n) & n\le k\le n(n-1)/2 \\ c_{n-1}(k-n) & 1+n(n-1)/2\le k\le n(n+1)/2 \end{cases} .\tag{2} (2) C(k) (-q;q)_\infty=\sum_{k\ge0}C(k)q^k \lim_{n\to\infty}c_n(k) f_n(1)=\prod_{k=1}^{n}2=2^n \sum_{k=0}^{n}c_n(k)=2^n.","['sequences-and-series', 'analytic-number-theory', 'products', 'infinite-product', 'q-analogs']"
58,Is it possible to utilize the convergence of the sequence $z_{n+1}=a/(1+z_n)$ to prove that the sequence $x_{n+2} = \sqrt{x_{n+1} x_n}$ is convergent?,Is it possible to utilize the convergence of the sequence  to prove that the sequence  is convergent?,z_{n+1}=a/(1+z_n) x_{n+2} = \sqrt{x_{n+1} x_n},"I'm doing Problem II.4.6 in textbook Analysis I by Amann/Escher. For $x_0,x_1 \in \mathbb R^+$ , the sequence $(x_n)_{n \in \mathbb N}$ defined recursively by $x_{n+2} = \sqrt{x_{n+1} x_n}$ is convergent. My questions: I'm not sure if my attempt (the parts from Lemma 4 to the end) is fine or contains logical gaps/errors. Could you please verify these parts? Any suggestion is greatly appreciated. Particularly, I'm not sure if my induction in case $m > n$ in the part ""... $\color{blue}{\text{vacuously true}}$ ...""  and the proof that there exists $0 < \beta < 1$ such that $y_{n+1} \le \beta y_n$ are correct or not. There is Problem II.4.5 as follows: For $z_0,a \in \mathbb R^+$ , the sequence $(z_n)_{n \in \mathbb N}$ defined recursively by $z_{n+1}=a/(1+z_n)$ is convergent. Using Mathematica, I found that both of the sequences $(x_n)_{n \in \mathbb N}$ and $(z_n)_{n \in \mathbb N}$ share the same plot as follows. I would like to ask whether it is possible to utilize the convergence of $(z_n)_{n \in \mathbb N}$ to prove the convergence of $(x_n)_{n \in \mathbb N}$ . Thank you so much for your help! My attempt: First we consider the case $x_0 < x_1$ . Lemma 1: $x_{2n} < x_{2n+1}$ for all $n$ . Proof: The statement trivially holds for $n=0$ . Let it hold for some $n$ . We have $$\begin{aligned} x_{2(n+1)} < x_{2(n+1)+1} & \iff x_{2n+2} < x_{2n+3} \\ &\iff \sqrt{x_{2n+1} x_{2n}} < \sqrt{x_{2n+2} x_{2n+1}} \\ &\iff  x_{2n} < x_{2n+2}  \\ &\iff x_{2n} < \sqrt{x_{2n+1} x_{2n}} \\&\iff x_{2n} < x_{2n+1}\quad (\star) \end{aligned}$$ in which $(\star)$ follows from inductive hypothesis. As such, the statement holds for $n+1$ . Lemma 2: $x_{2n} < x_{2n+2}$ for all $n$ . Proof: We have $x_{2n} < x_{2n+2} \iff x_{2n} < \sqrt{x_{2n+1} x_{2n}} \iff x_{2n} < x_{2n+1}$ , which is true by Lemma 1 . As a consequence, $(x_{2n})_{n \in \mathbb N}$ is increasing. Lemma 3: $x_{2n+3} < x_{2n+1}$ for all $n$ . Proof: We have $x_{2n+3} < x_{2n+1} \iff \sqrt{x_{2n+2} x_{2n+1}} < x_{2n+1} \iff x_{2n+2} < x_{2n+1} \iff$ $\sqrt{x_{2n+1} x_{2n}} < x_{2n+1} \iff x_{2n} < x_{2n+1}$ , which is true by Lemma 1 . As a consequence, $(x_{2n+1})_{n \in \mathbb N}$ is decreasing. Lemma 4: $x_{2m} < x_{2n+1}$ for all $m,n$ . Proof: In case $m \le n$ , we have $x_{2m} \overset{(\star)}{\le} x_{2n} \overset{(\star\star)}{<} x_{2n+1}$ in which $(\star)$ follows from the fact that $(x_{2n})_{n \in \mathbb N}$ is increasing, and $(\star\star)$ follows from Lemma 1 . We prove the statement in case $m > n$ by induction on $m$ . It's $\color{blue}{\text{vacuously true}}$ for $m=0$ . Let it hold for some $m$ . We have $$\begin{aligned} x_{2(m+1)} < x_{2n+1} & \iff x_{2m+2} < x_{2n+1} \\ &\iff \sqrt{x_{2m+1} x_{2m}} < x_{2n+1} \\ &\iff  x_{2m+1} x_{2m} < x^2_{2n+1} \quad (\star) \end{aligned}$$ in which $(\star)$ follows from $x_{2m} < x_{2n+1}$ (by inductive hypothesis) and from $x_{2m+1} < x_{2n+1}$ (by $m > n$ and $(x_{2n+1})_{n \in \mathbb N}$ is decreasing). As such, the statement holds for $n+1$ . We define the sequence $(y_n)$ by $y_n := x_{2n+1} - x_{2n}$ . We next prove that there exists $0 < \beta < 1$ such that $y_{n+1} \le \beta y_n$ for all $n$ . $$\begin{aligned} y_{n+1} < \beta y_n &\iff x_{2(n+1)+1} - x_{2(n+1)} < \beta (x_{2n+1} - x_{2n}) \\ &\iff x_{2n+3} - x_{2n+2} < \beta (x_{2n+1} - x_{2n}) \\&\iff \sqrt{x_{2n+2} x_{2n+1}} - x_{2n+2} < \beta (x_{2n+1} - x_{2n}) \\ &\iff \sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n+2}}) < \beta (x_{2n+1} - x_{2n})\end{aligned}$$ Since $x_{2n+2} > x_{2n}$ , $\sqrt{x_{2n+1}} - \sqrt{x_{2n+2}} < \sqrt{x_{2n+1}} - \sqrt{x_{2n}}$ . As such, it suffices to prove that there exists $0 < \beta < 1$ such that $\sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n}}) < \beta (x_{2n+1} - x_{2n})$ . We have $$\begin{aligned} &\sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n}}) < \beta (x_{2n+1} - x_{2n}) \\ &\iff \sqrt{x_{2n+2}} < \beta (\sqrt{x_{2n+1}} + \sqrt{x_{2n}}) \\ &\iff \dfrac{\sqrt{x_{2n+2}}}{\sqrt{x_{2n+1}} + \sqrt{x_{2n}}} < \beta \\&\iff \left( \dfrac{\sqrt{x_{2n+2}}}{\sqrt{x_{2n+1}} + \sqrt{x_{2n}}}\right)^2 < \beta^2  \\ &\iff \dfrac{x_{2n+2}}{x_{2n+1} + 2\sqrt{x_{2n+1} x_{2n}} + x_{2n}} < \beta^2 \\ &\iff \dfrac{x_{2n+2}}{x_{2n+1} + 2x_{2n+2} + x_{2n}} < \beta^2\\ &\iff \dfrac{1}{2+ x_{2n+1}/x_{2n+2} + x_{2n}/x_{2n+2}} < \beta^2  \end{aligned}$$ As a result, we are done if we choose $1/\sqrt{2} <\beta < 1$ . Then $y_{n+1} \le \beta y_n$ and thus $y_{n} \le \beta^n y_0$ for all $n$ . We have $0 \le \lim_{n \to \infty} y_n \le \lim_{n \to \infty} \beta^n y_0 = 0$ . As such, $\lim_{n \to \infty} y_n = 0$ and so $\lim_{n \to \infty}x_{2n} = \lim_{n \to \infty}x_{2n+1} = \alpha$ . From Lemmas 2 , 3 , and 4 , our sequence $(x_n)_{n \in \mathbb N}$ looks like $$x_0 < x_2 < x_4 < \cdots < x_{2n}< \cdots <x_{2n+1} < \cdots <x_5<x_3<x_1$$ By Nested Intervals Theorem, we have $$\lim_{n \to \infty}x_{2n} = \lim_{n \to \infty}x_{2n+1}$$ Next we prove that $$\lim_{n \to \infty}x_{n} = \alpha$$ Approach 1: For $\varepsilon > 0$ , there exists $N \in \mathbb N$ such that $|x_{2n} - \alpha| < \varepsilon$ and $|x_{2n+1} - \alpha| < \varepsilon$ for all $n > N$ . Thus $|x_{n} - \alpha| < \varepsilon$ for all $n > 2N$ . As a result, $\lim_{n \to \infty}x_{n} = \alpha$ . Approach 2: Given $n \in \mathbb N$ , we have $A := \{2k+1 \in \mathbb N \mid k \ge n\} \subseteq B := \{k \in \mathbb N \mid k \ge n\}$ and, for each $k \in B$ , there exists $k' \in A$ such that $x_k \le x_{k'}$ . As such, $\sup_{k \ge n} x_{k} = \sup_{k \ge n} x_{2k+1}$ and thus $\inf_{n \ge 0} \sup_{k \ge n} x_{k} = \inf_{n \ge 0} \sup_{k \ge n} x_{2k+1}$ . Similarly, we have $\sup_{n \ge 0} \inf_{k \ge n} x_{2k} =$ $\sup_{n \ge 0} \inf_{k \ge n} x_{k}$ . It follows that $$\alpha = \sup_{n \ge 0} \inf_{k \ge n} x_{2k} = \sup_{n \ge 0} \inf_{k \ge n} x_{k} \le \inf_{n \ge 0} \sup_{k \ge n} x_{k} = \inf_{n \ge 0} \sup_{k \ge n} x_{2k+1} = \alpha$$ and thus $\lim_{n \to \infty} x_{n} = \alpha$ . The case $x_0 > x_1$ is similar, while the case $x_0 = x_1$ is trivial.","I'm doing Problem II.4.6 in textbook Analysis I by Amann/Escher. For , the sequence defined recursively by is convergent. My questions: I'm not sure if my attempt (the parts from Lemma 4 to the end) is fine or contains logical gaps/errors. Could you please verify these parts? Any suggestion is greatly appreciated. Particularly, I'm not sure if my induction in case in the part ""... ...""  and the proof that there exists such that are correct or not. There is Problem II.4.5 as follows: For , the sequence defined recursively by is convergent. Using Mathematica, I found that both of the sequences and share the same plot as follows. I would like to ask whether it is possible to utilize the convergence of to prove the convergence of . Thank you so much for your help! My attempt: First we consider the case . Lemma 1: for all . Proof: The statement trivially holds for . Let it hold for some . We have in which follows from inductive hypothesis. As such, the statement holds for . Lemma 2: for all . Proof: We have , which is true by Lemma 1 . As a consequence, is increasing. Lemma 3: for all . Proof: We have , which is true by Lemma 1 . As a consequence, is decreasing. Lemma 4: for all . Proof: In case , we have in which follows from the fact that is increasing, and follows from Lemma 1 . We prove the statement in case by induction on . It's for . Let it hold for some . We have in which follows from (by inductive hypothesis) and from (by and is decreasing). As such, the statement holds for . We define the sequence by . We next prove that there exists such that for all . Since , . As such, it suffices to prove that there exists such that . We have As a result, we are done if we choose . Then and thus for all . We have . As such, and so . From Lemmas 2 , 3 , and 4 , our sequence looks like By Nested Intervals Theorem, we have Next we prove that Approach 1: For , there exists such that and for all . Thus for all . As a result, . Approach 2: Given , we have and, for each , there exists such that . As such, and thus . Similarly, we have . It follows that and thus . The case is similar, while the case is trivial.","x_0,x_1 \in \mathbb R^+ (x_n)_{n \in \mathbb N} x_{n+2} = \sqrt{x_{n+1} x_n} m > n \color{blue}{\text{vacuously true}} 0 < \beta < 1 y_{n+1} \le \beta y_n z_0,a \in \mathbb R^+ (z_n)_{n \in \mathbb N} z_{n+1}=a/(1+z_n) (x_n)_{n \in \mathbb N} (z_n)_{n \in \mathbb N} (z_n)_{n \in \mathbb N} (x_n)_{n \in \mathbb N} x_0 < x_1 x_{2n} < x_{2n+1} n n=0 n \begin{aligned} x_{2(n+1)} < x_{2(n+1)+1} & \iff x_{2n+2} < x_{2n+3} \\ &\iff \sqrt{x_{2n+1} x_{2n}} < \sqrt{x_{2n+2} x_{2n+1}} \\ &\iff  x_{2n} < x_{2n+2}  \\ &\iff x_{2n} < \sqrt{x_{2n+1} x_{2n}} \\&\iff x_{2n} < x_{2n+1}\quad (\star) \end{aligned} (\star) n+1 x_{2n} < x_{2n+2} n x_{2n} < x_{2n+2} \iff x_{2n} < \sqrt{x_{2n+1} x_{2n}} \iff x_{2n} < x_{2n+1} (x_{2n})_{n \in \mathbb N} x_{2n+3} < x_{2n+1} n x_{2n+3} < x_{2n+1} \iff \sqrt{x_{2n+2} x_{2n+1}} < x_{2n+1} \iff x_{2n+2} < x_{2n+1} \iff \sqrt{x_{2n+1} x_{2n}} < x_{2n+1} \iff x_{2n} < x_{2n+1} (x_{2n+1})_{n \in \mathbb N} x_{2m} < x_{2n+1} m,n m \le n x_{2m} \overset{(\star)}{\le} x_{2n} \overset{(\star\star)}{<} x_{2n+1} (\star) (x_{2n})_{n \in \mathbb N} (\star\star) m > n m \color{blue}{\text{vacuously true}} m=0 m \begin{aligned} x_{2(m+1)} < x_{2n+1} & \iff x_{2m+2} < x_{2n+1} \\ &\iff \sqrt{x_{2m+1} x_{2m}} < x_{2n+1} \\ &\iff  x_{2m+1} x_{2m} < x^2_{2n+1} \quad (\star) \end{aligned} (\star) x_{2m} < x_{2n+1} x_{2m+1} < x_{2n+1} m > n (x_{2n+1})_{n \in \mathbb N} n+1 (y_n) y_n := x_{2n+1} - x_{2n} 0 < \beta < 1 y_{n+1} \le \beta y_n n \begin{aligned} y_{n+1} < \beta y_n &\iff x_{2(n+1)+1} - x_{2(n+1)} < \beta (x_{2n+1} - x_{2n}) \\ &\iff x_{2n+3} - x_{2n+2} < \beta (x_{2n+1} - x_{2n}) \\&\iff \sqrt{x_{2n+2} x_{2n+1}} - x_{2n+2} < \beta (x_{2n+1} - x_{2n}) \\ &\iff \sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n+2}}) < \beta (x_{2n+1} - x_{2n})\end{aligned} x_{2n+2} > x_{2n} \sqrt{x_{2n+1}} - \sqrt{x_{2n+2}} < \sqrt{x_{2n+1}} - \sqrt{x_{2n}} 0 < \beta < 1 \sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n}}) < \beta (x_{2n+1} - x_{2n}) \begin{aligned} &\sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n}}) < \beta (x_{2n+1} - x_{2n}) \\ &\iff \sqrt{x_{2n+2}} < \beta (\sqrt{x_{2n+1}} + \sqrt{x_{2n}}) \\ &\iff \dfrac{\sqrt{x_{2n+2}}}{\sqrt{x_{2n+1}} + \sqrt{x_{2n}}} < \beta \\&\iff \left( \dfrac{\sqrt{x_{2n+2}}}{\sqrt{x_{2n+1}} + \sqrt{x_{2n}}}\right)^2 < \beta^2  \\ &\iff \dfrac{x_{2n+2}}{x_{2n+1} + 2\sqrt{x_{2n+1} x_{2n}} + x_{2n}} < \beta^2 \\ &\iff \dfrac{x_{2n+2}}{x_{2n+1} + 2x_{2n+2} + x_{2n}} < \beta^2\\ &\iff \dfrac{1}{2+ x_{2n+1}/x_{2n+2} + x_{2n}/x_{2n+2}} < \beta^2  \end{aligned} 1/\sqrt{2} <\beta < 1 y_{n+1} \le \beta y_n y_{n} \le \beta^n y_0 n 0 \le \lim_{n \to \infty} y_n \le \lim_{n \to \infty} \beta^n y_0 = 0 \lim_{n \to \infty} y_n = 0 \lim_{n \to \infty}x_{2n} = \lim_{n \to \infty}x_{2n+1} = \alpha (x_n)_{n \in \mathbb N} x_0 < x_2 < x_4 < \cdots < x_{2n}< \cdots <x_{2n+1} < \cdots <x_5<x_3<x_1 \lim_{n \to \infty}x_{2n} = \lim_{n \to \infty}x_{2n+1} \lim_{n \to \infty}x_{n} = \alpha \varepsilon > 0 N \in \mathbb N |x_{2n} - \alpha| < \varepsilon |x_{2n+1} - \alpha| < \varepsilon n > N |x_{n} - \alpha| < \varepsilon n > 2N \lim_{n \to \infty}x_{n} = \alpha n \in \mathbb N A := \{2k+1 \in \mathbb N \mid k \ge n\} \subseteq B := \{k \in \mathbb N \mid k \ge n\} k \in B k' \in A x_k \le x_{k'} \sup_{k \ge n} x_{k} = \sup_{k \ge n} x_{2k+1} \inf_{n \ge 0} \sup_{k \ge n} x_{k} = \inf_{n \ge 0} \sup_{k \ge n} x_{2k+1} \sup_{n \ge 0} \inf_{k \ge n} x_{2k} = \sup_{n \ge 0} \inf_{k \ge n} x_{k} \alpha = \sup_{n \ge 0} \inf_{k \ge n} x_{2k} = \sup_{n \ge 0} \inf_{k \ge n} x_{k} \le \inf_{n \ge 0} \sup_{k \ge n} x_{k} = \inf_{n \ge 0} \sup_{k \ge n} x_{2k+1} = \alpha \lim_{n \to \infty} x_{n} = \alpha x_0 > x_1 x_0 = x_1","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'alternative-proof']"
59,Are these new series formulae for $\zeta(2)$?,Are these new series formulae for ?,\zeta(2),"Let $\zeta(n)$ denote the Riemann zeta function defined for positive integers greater than $1$ by its usual infinite series. Thus, $\zeta(2)=\sum_{k=1}^\infty\frac{1}{k^2}$ . Many formulae exist involving $\zeta(2)$ , including the Apéry-like fast-converging series: $$ \zeta (2)=3\sum _{{n=1}}^{{\infty }}{\frac  {1}{n^{{2}}{\binom  {2n}{n}}}}. $$ Recently I have found the following similar-looking series: $$ \zeta (2)=\frac83\sum _{{n=1}}^{{\infty }}{\frac  {2^{n-1}}{n^{{2}}{\binom  {2n}{n}}}}, $$ $$ \zeta (2)=\frac94\sum _{{n=1}}^{{\infty }}{\frac  {3^{n-1}}{n^{{2}}{\binom  {2n}{n}}}} $$ and $$ \zeta (2)=\frac43\sum _{{n=1}}^{{\infty }}{\frac  {4^{n-1}}{n^{{2}}{\binom  {2n}{n}}}}. $$ Are these series already known? A quick internet search yields no such results. EDIT forgot to add the second series.","Let denote the Riemann zeta function defined for positive integers greater than by its usual infinite series. Thus, . Many formulae exist involving , including the Apéry-like fast-converging series: Recently I have found the following similar-looking series: and Are these series already known? A quick internet search yields no such results. EDIT forgot to add the second series.","\zeta(n) 1 \zeta(2)=\sum_{k=1}^\infty\frac{1}{k^2} \zeta(2) 
\zeta (2)=3\sum _{{n=1}}^{{\infty }}{\frac  {1}{n^{{2}}{\binom  {2n}{n}}}}.
 
\zeta (2)=\frac83\sum _{{n=1}}^{{\infty }}{\frac  {2^{n-1}}{n^{{2}}{\binom  {2n}{n}}}},
 
\zeta (2)=\frac94\sum _{{n=1}}^{{\infty }}{\frac  {3^{n-1}}{n^{{2}}{\binom  {2n}{n}}}}
 
\zeta (2)=\frac43\sum _{{n=1}}^{{\infty }}{\frac  {4^{n-1}}{n^{{2}}{\binom  {2n}{n}}}}.
","['sequences-and-series', 'riemann-zeta']"
60,Compute $2\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^4}+\sum_{n=1}^\infty\frac{H_nH_n^{(3)}}{n^3}$,Compute,2\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^4}+\sum_{n=1}^\infty\frac{H_nH_n^{(3)}}{n^3},"How to prove that $$2\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^4}+\sum_{n=1}^\infty\frac{H_nH_n^{(3)}}{n^3}=7\zeta(7)+\frac{7}{4}\zeta(3)\zeta(4)-\frac32\zeta(2)\zeta(5)\tag{1}$$ where $H_n^{(p)}=1+\frac1{2^p}+\cdots+\frac1{n^p}$ is the $n$ th generalized harmonic number of order $p$ . You can find the proof of the equality above in the book (Almost) Impossible Integrals, Sums and Series page 297 using pure series manipulations but is it possible to prove it using integration or any other way? All approaches are appreciated. In case you are curious about the result of each sum, you can find them also in the book $$\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^4}=2\zeta(2)\zeta(5)+\frac34\zeta(3)\zeta(4)-\frac{51}{16}\zeta(7)$$ $$\sum_{n=1}^\infty\frac{H_nH_n^{(3)}}{n^3}=\frac{81}{8}\zeta(7)-\frac{11}{2}\zeta(2)\zeta(5)+\frac14\zeta(3)\zeta(4)$$ but again, our main problem here is to prove the equality in (1) in different ways. Thanks","How to prove that where is the th generalized harmonic number of order . You can find the proof of the equality above in the book (Almost) Impossible Integrals, Sums and Series page 297 using pure series manipulations but is it possible to prove it using integration or any other way? All approaches are appreciated. In case you are curious about the result of each sum, you can find them also in the book but again, our main problem here is to prove the equality in (1) in different ways. Thanks",2\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^4}+\sum_{n=1}^\infty\frac{H_nH_n^{(3)}}{n^3}=7\zeta(7)+\frac{7}{4}\zeta(3)\zeta(4)-\frac32\zeta(2)\zeta(5)\tag{1} H_n^{(p)}=1+\frac1{2^p}+\cdots+\frac1{n^p} n p \sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^4}=2\zeta(2)\zeta(5)+\frac34\zeta(3)\zeta(4)-\frac{51}{16}\zeta(7) \sum_{n=1}^\infty\frac{H_nH_n^{(3)}}{n^3}=\frac{81}{8}\zeta(7)-\frac{11}{2}\zeta(2)\zeta(5)+\frac14\zeta(3)\zeta(4),"['calculus', 'integration', 'sequences-and-series', 'harmonic-numbers', 'polylogarithm']"
61,Prove that $\sum_{k=1}^\infty \left(\frac{\sqrt{k}-1}{\sqrt{k}}\right)^k$ converges using a comparison,Prove that  converges using a comparison,\sum_{k=1}^\infty \left(\frac{\sqrt{k}-1}{\sqrt{k}}\right)^k,"I have been asked to prove that \begin{align*} \sum_{k=1}^\infty \left(\frac{\sqrt{k}-1}{\sqrt{k}}\right)^k \end{align*} converges. I beleive that I was able to do it using a logarithm test with two applications of L'Hopital, but I have been given a hint that it can be done easily with a comparison. However, I am at a loss for which what I can compare it to. Any help would be greatly appreciated.","I have been asked to prove that converges. I beleive that I was able to do it using a logarithm test with two applications of L'Hopital, but I have been given a hint that it can be done easily with a comparison. However, I am at a loss for which what I can compare it to. Any help would be greatly appreciated.","\begin{align*}
\sum_{k=1}^\infty \left(\frac{\sqrt{k}-1}{\sqrt{k}}\right)^k
\end{align*}","['real-analysis', 'sequences-and-series']"
62,Convergence of Sequences: Confusion in definition,Convergence of Sequences: Confusion in definition,,"This is the definition of convergence we've been taught - $(x_{n}) \rightarrow L$ if for every $\epsilon>0 , \exists N \in \mathbb{N}$ such that for all $n \geq N$ it follows that $|x_{n}-L|< \epsilon$ I don't understand the importance of the part in bold, i.e. why is it necessary for all n ? Please provide a counterexample (a case which shows the necessity of the text in bold) if possible! Thank you! P.S. I feel it should be okay if for certain values of n the terms of the sequence don't lie in the designated interval, most other terms can converge to L. What am I missing? P.P.S. I guess my question boils down to the necessity of monotonicity for convergence. Here's an example to provide more clarity into what I'm thinking: $(x_{n})= 1/2^n$ for all $n$ , except $n=4$ . I separately define $x_{4}= 5$ . For very large $n$ , this sequence approaches $0$ .","This is the definition of convergence we've been taught - if for every such that for all it follows that I don't understand the importance of the part in bold, i.e. why is it necessary for all n ? Please provide a counterexample (a case which shows the necessity of the text in bold) if possible! Thank you! P.S. I feel it should be okay if for certain values of n the terms of the sequence don't lie in the designated interval, most other terms can converge to L. What am I missing? P.P.S. I guess my question boils down to the necessity of monotonicity for convergence. Here's an example to provide more clarity into what I'm thinking: for all , except . I separately define . For very large , this sequence approaches .","(x_{n}) \rightarrow L \epsilon>0 , \exists N \in \mathbb{N} n \geq N |x_{n}-L|< \epsilon (x_{n})= 1/2^n n n=4 x_{4}= 5 n 0","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
63,Compute $\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^7}$ and $\sum_{n=1}^\infty\frac{H_n^2}{n^7}$,Compute  and,\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^7} \sum_{n=1}^\infty\frac{H_n^2}{n^7},"How to prove that $$S_1=\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^7}=7\zeta(2)\zeta(7)+2\zeta(3)\zeta(6)+4\zeta(4)\zeta(5)-\frac{35}{2}\zeta(9)\ ?$$ $$S_2=\sum_{n=1}^\infty\frac{H_n^2}{n^7}=-\zeta(2)\zeta(7)-\frac72\zeta(3)\zeta(6)+\frac13\zeta^3(3)-\frac{5}{2}\zeta(4)\zeta(5)+\frac{55}{6}\zeta(9)\ ?$$ where $H_n^{(p)}=1+\frac1{2^p}+\cdots+\frac1{n^p}$ is the $n$ th generalized harmonic number of order $p$ . I came across these two sums while working on an tough one of wight 9 and I managed to find these two results but I don't think my solution is a good approach as it's pretty long and involves tedious calculations, so I am seeking different methods if possible. I am much into new ideas. All approaches are appreciated though. By the way, do we have a generalization for $\displaystyle\sum_{n=1}^\infty \frac{H_n^{(2)}}{n^a}$ , for odd $a$ ? Note that  there is no closed form for even $a>4$ . Thanks in advance. Note: You can find these two results on Wolfram Alpha here and here respectively but I modified it a little bit as I like it expressed in terms of $\zeta(a)$ instead of $\pi^a$ .","How to prove that where is the th generalized harmonic number of order . I came across these two sums while working on an tough one of wight 9 and I managed to find these two results but I don't think my solution is a good approach as it's pretty long and involves tedious calculations, so I am seeking different methods if possible. I am much into new ideas. All approaches are appreciated though. By the way, do we have a generalization for , for odd ? Note that  there is no closed form for even . Thanks in advance. Note: You can find these two results on Wolfram Alpha here and here respectively but I modified it a little bit as I like it expressed in terms of instead of .",S_1=\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^7}=7\zeta(2)\zeta(7)+2\zeta(3)\zeta(6)+4\zeta(4)\zeta(5)-\frac{35}{2}\zeta(9)\ ? S_2=\sum_{n=1}^\infty\frac{H_n^2}{n^7}=-\zeta(2)\zeta(7)-\frac72\zeta(3)\zeta(6)+\frac13\zeta^3(3)-\frac{5}{2}\zeta(4)\zeta(5)+\frac{55}{6}\zeta(9)\ ? H_n^{(p)}=1+\frac1{2^p}+\cdots+\frac1{n^p} n p \displaystyle\sum_{n=1}^\infty \frac{H_n^{(2)}}{n^a} a a>4 \zeta(a) \pi^a,"['integration', 'sequences-and-series', 'closed-form', 'riemann-zeta', 'harmonic-numbers']"
64,"Determining a sequence's $n$-th term from its first and second differences, when latter is in arithmetic or geometric progression","Determining a sequence's -th term from its first and second differences, when latter is in arithmetic or geometric progression",n,"For the series, $3, 7, 14, 24, 37, \ldots$ , the $1$ st successive differences are $4,7,10,13,\ldots$ , and the $2$ nd successive differences are $3,3,3,\ldots$ . So, the book says, the $nth$ term $T_n$ of the given series will be $an^2+bn+c$ . And for the series, $3,8,22,72,266,1036,\ldots$ , the $1$ st successive differences are $5,14,50,194,770,\ldots$ , and the $2$ nd successive differences are $9,36,144,576,\ldots$ , which are in geometric progression with common ratio being $4$ . So, the book says $T_n$ will be $a4^{n-1}+bn+c$ . I have verified in both cases that it's true with $a,b,c$ in first case coming out to be $\frac32,-\frac12,2$ , and in second case $1,2,0$ , respectively. My question is why is this so? Why is $T_n$ the way it is? How to approach this method in a fresh question?","For the series, , the st successive differences are , and the nd successive differences are . So, the book says, the term of the given series will be . And for the series, , the st successive differences are , and the nd successive differences are , which are in geometric progression with common ratio being . So, the book says will be . I have verified in both cases that it's true with in first case coming out to be , and in second case , respectively. My question is why is this so? Why is the way it is? How to approach this method in a fresh question?","3, 7, 14, 24, 37, \ldots 1 4,7,10,13,\ldots 2 3,3,3,\ldots nth T_n an^2+bn+c 3,8,22,72,266,1036,\ldots 1 5,14,50,194,770,\ldots 2 9,36,144,576,\ldots 4 T_n a4^{n-1}+bn+c a,b,c \frac32,-\frac12,2 1,2,0 T_n",['sequences-and-series']
65,"How many different sums can you get when you ""add up all the integers""?","How many different sums can you get when you ""add up all the integers""?",,"Suppose you want to ""add up all the integers"" naively, by devising some way of arranging the integers in sequence and finding the limit of the partial sums of that sequence, possibly grouping up and pre-summing groups of integers. You could represent this formally by defining a function $f : \mathbb{N} \to \{\mathbb{Z}\}$ subject to $\forall n \in \mathbb{Z}. \exists i \in \mathbb{N}. n \in f(i)$ $\forall i, j, n \text{ with } i \not= j. n \in f(i) \implies n \not\in f(j)$ Every $f(i)$ is a finite set and taking the following limit: $$\lim_{n\to\infty}\sum_{i=1}^{n} \Sigma f(i)$$ There are at least 3 different limits you can obtain with different choices of $f$ : $f(i) = \{i, -i\}$ produces the sequence $0, 1 + -1, 2 + -2, \ldots$ . Since every term is 0, the limit is 0 as well. $f(i) = \{1 + i, 1 - i\}$ produces the sequence $1, 2 + 0, 3 + -1, 4 + -2, \ldots$ . Since each term after the first sums to 2 the limit is $+\infty$ . $f(i) = \{-1 + i, -1 - i\}$ produces the sequence $-1, 0 + -2, 1 + -3, 2 + -4, \ldots$ . Since each term after the first sums to -2, the limit is $-\infty$ . My question is: Are 0, $+\infty$ , and $-\infty$ the only possible limits? Is it possible with a clever choice of $f$ to get a limit of, say, 10, or any other number? (It's clearly also true that there are plenty of legal $f$ s that lead to the limit not existing; I'm not interested in that here.) Fun note: This question is inspired by a discussion I had with a roommate long ago, who wrote a poem with the line ""the sum of all the numbers is zero"" based on the reasoning I gave above. I pointed out that infinite series are weird and immediately came up with the two other ""sums"" I've listed here. Ever since then, and I've been wondering if there are other ""sums."" I can't find any but also can't prove that none exist. You'll be happy to know that the roommate discussed the issue with his poetry professor, who allowed the line even though the mathematics turned out to be dubious.","Suppose you want to ""add up all the integers"" naively, by devising some way of arranging the integers in sequence and finding the limit of the partial sums of that sequence, possibly grouping up and pre-summing groups of integers. You could represent this formally by defining a function subject to Every is a finite set and taking the following limit: There are at least 3 different limits you can obtain with different choices of : produces the sequence . Since every term is 0, the limit is 0 as well. produces the sequence . Since each term after the first sums to 2 the limit is . produces the sequence . Since each term after the first sums to -2, the limit is . My question is: Are 0, , and the only possible limits? Is it possible with a clever choice of to get a limit of, say, 10, or any other number? (It's clearly also true that there are plenty of legal s that lead to the limit not existing; I'm not interested in that here.) Fun note: This question is inspired by a discussion I had with a roommate long ago, who wrote a poem with the line ""the sum of all the numbers is zero"" based on the reasoning I gave above. I pointed out that infinite series are weird and immediately came up with the two other ""sums"" I've listed here. Ever since then, and I've been wondering if there are other ""sums."" I can't find any but also can't prove that none exist. You'll be happy to know that the roommate discussed the issue with his poetry professor, who allowed the line even though the mathematics turned out to be dubious.","f : \mathbb{N} \to \{\mathbb{Z}\} \forall n \in \mathbb{Z}. \exists i \in \mathbb{N}. n \in f(i) \forall i, j, n \text{ with } i \not= j. n \in f(i) \implies n \not\in f(j) f(i) \lim_{n\to\infty}\sum_{i=1}^{n} \Sigma f(i) f f(i) = \{i, -i\} 0, 1 + -1, 2 + -2, \ldots f(i) = \{1 + i, 1 - i\} 1, 2 + 0, 3 + -1, 4 + -2, \ldots +\infty f(i) = \{-1 + i, -1 - i\} -1, 0 + -2, 1 + -3, 2 + -4, \ldots -\infty +\infty -\infty f f",['sequences-and-series']
66,Let $f:\mathbb{N} \rightarrow \mathbb{N}$ such that $f(1)=2011$ and $f(n)= \frac{1}{n^2 -1}(f(1)+f(2)+...+f(n-1))$ for $n \ge 2$. Calculate $f(2011)$ [duplicate],Let  such that  and  for . Calculate  [duplicate],f:\mathbb{N} \rightarrow \mathbb{N} f(1)=2011 f(n)= \frac{1}{n^2 -1}(f(1)+f(2)+...+f(n-1)) n \ge 2 f(2011),"This question already has answers here : Solving for $f(2004)$ in a given functional equation (4 answers) Closed 4 years ago . Being $f:\mathbb{N} \rightarrow \mathbb{N}$ such that $f(1)=2011$ and $f(n)=  \frac{1}{n^2 -1}(f(1)+f(2)+...+f(n-1))$ for $n \ge 2$ . Calculate $f(2011)$ When calculating $f(n)$ I need to consider the sum of the previous elements, from $2011$ to $f(n-1)$ . But when considering each of these, I need again the the sum of the previous $f(n)$ . I've never met a problem like this. It seems like a sequence  by recursion: are there any rules when approaching problems like this?","This question already has answers here : Solving for $f(2004)$ in a given functional equation (4 answers) Closed 4 years ago . Being such that and for . Calculate When calculating I need to consider the sum of the previous elements, from to . But when considering each of these, I need again the the sum of the previous . I've never met a problem like this. It seems like a sequence  by recursion: are there any rules when approaching problems like this?",f:\mathbb{N} \rightarrow \mathbb{N} f(1)=2011 f(n)=  \frac{1}{n^2 -1}(f(1)+f(2)+...+f(n-1)) n \ge 2 f(2011) f(n) 2011 f(n-1) f(n),"['sequences-and-series', 'recurrence-relations']"
67,"How to find the growth rates of $n$ bacteria, knowing the sizes of bacteria from $m$ observations?","How to find the growth rates of  bacteria, knowing the sizes of bacteria from  observations?",n m,"Each bacterium grows at a some constant rate, i.e. every minute the size of the bacteria increases by some constant value. Different bacteria can grow at different rate (they can also grow at same rate). Scientists observe $n$ bacteria under the microscope. Bacteria differ only in size and growth rate (in all other they are indistinguishable). Every minute, scientists identify the sizes of all $n$ bacteria and write down $n$ numbers - the sizes of bacteria (Scientists do not know which particular bacterium is of this or that size, because the bacteria move all the time). Prove that there is a number $m$ such that after $m$ minutes of observations, scientists will be able to unequivocally find a set of the growth rates of $n$ bacteria (The number $m$ should not depend on the sizes of the bacteria and their growth rates. The number $m$ may depend on the number $n$ .). My work . Scientists have numbers of $n$ arithmetic progressions. They need to find a set of common difference of arithmetic progressions. I proved that: a) if $n=1$ then $m=2$ ; b) if $n=2$ then $m=3$ ; c) if $n \ge 3$ then $m \ne 3$ (I do not know how to prove of the problem in the case when $n \ge 3$ ).","Each bacterium grows at a some constant rate, i.e. every minute the size of the bacteria increases by some constant value. Different bacteria can grow at different rate (they can also grow at same rate). Scientists observe bacteria under the microscope. Bacteria differ only in size and growth rate (in all other they are indistinguishable). Every minute, scientists identify the sizes of all bacteria and write down numbers - the sizes of bacteria (Scientists do not know which particular bacterium is of this or that size, because the bacteria move all the time). Prove that there is a number such that after minutes of observations, scientists will be able to unequivocally find a set of the growth rates of bacteria (The number should not depend on the sizes of the bacteria and their growth rates. The number may depend on the number .). My work . Scientists have numbers of arithmetic progressions. They need to find a set of common difference of arithmetic progressions. I proved that: a) if then ; b) if then ; c) if then (I do not know how to prove of the problem in the case when ).",n n n m m n m m n n n=1 m=2 n=2 m=3 n \ge 3 m \ne 3 n \ge 3,"['sequences-and-series', 'combinatorics', 'contest-math']"
68,challenging sum $\sum_{k=1}^\infty\frac{H_k^{(2)}}{(2k+1)^2}$,challenging sum,\sum_{k=1}^\infty\frac{H_k^{(2)}}{(2k+1)^2},How to prove that \begin{align} \sum_{k=1}^\infty\frac{H_k^{(2)}}{(2k+1)^2}=\frac13\ln^42-2\ln^22\zeta(2)+7\ln2\zeta(3)-\frac{121}{16}\zeta(4)+8\operatorname{Li}_4\left(\frac12\right) \end{align} where $H_n^{(m)}=1+\frac1{2^m}+\frac1{3^m}+...+\frac1{n^m}$ is the $n$ th harmonic number of order $m$ . This problem was proposed by Cornel Valean. Here is integral expression of the sum $\displaystyle -\int_0^1\frac{\ln x\operatorname{Li}_2(x^2)}{1-x^2}\ dx\quad $ .,How to prove that where is the th harmonic number of order . This problem was proposed by Cornel Valean. Here is integral expression of the sum .,"\begin{align}
\sum_{k=1}^\infty\frac{H_k^{(2)}}{(2k+1)^2}=\frac13\ln^42-2\ln^22\zeta(2)+7\ln2\zeta(3)-\frac{121}{16}\zeta(4)+8\operatorname{Li}_4\left(\frac12\right)
\end{align} H_n^{(m)}=1+\frac1{2^m}+\frac1{3^m}+...+\frac1{n^m} n m \displaystyle -\int_0^1\frac{\ln x\operatorname{Li}_2(x^2)}{1-x^2}\ dx\quad ","['integration', 'sequences-and-series', 'harmonic-numbers', 'polylogarithm', 'summation-by-parts']"
69,Convergence of $\sum_{k=1}^{\infty}\frac{\cos(\theta k)}{\sqrt{k}}$,Convergence of,\sum_{k=1}^{\infty}\frac{\cos(\theta k)}{\sqrt{k}},Say if the following series $$ \sum_{k=1}^{\infty} \frac{\cos(\theta k)}{\sqrt{k}} $$ for $θ \in \mathbb{R}$ is convergent. Is it absolutely convergent? I don't know how to approach this problem. Any hint will be very appreciated. Thanks!,Say if the following series for is convergent. Is it absolutely convergent? I don't know how to approach this problem. Any hint will be very appreciated. Thanks!, \sum_{k=1}^{\infty} \frac{\cos(\theta k)}{\sqrt{k}}  θ \in \mathbb{R},"['calculus', 'sequences-and-series', 'convergence-divergence', 'divergent-series', 'absolute-convergence']"
70,Is there any mathematical significance of this sequence?,Is there any mathematical significance of this sequence?,,"Let's say I sum up all of the numbers from 1 to $n$ (we'll say $n$ is 6 for this example). In this case, I'd get a total of 21 ( $1+2+3+4+5+6=21$ ). Now let us pose the following question: if I replaced the $+$ s with $\times$ s, what would I have to divide/multiply each element in the sequence by to get the same answer as with addition? As in, if $$f_1(x)=1+2+3+...+x$$ then what would $y$ be at each point in $$f_2(x)=\frac{1}{y_1}\times\frac{2}{y_2}\times\frac{3}{y_3}...\times\frac{x}{y_x}$$ I started calculating some of the elements of $y$ , and (if I didn't make a mistake), I got: $$\begin{array}{c|c|c|c|}  n & \text{Total ($f_1$)} & \text{Fraction of $y_n$} & \text{Decimal of $y_n$} \\ \hline \text{1} & 1 & 1 & 1\\ \hline \text{2} & 3 & \frac{2}{3} & 0.66\dot6\\ \hline \text{3} & 6 & \frac{3}{2} & 1.5\\ \hline \text{4} & 10 & \frac{12}{5} & 2.4 \\ \hline \text{5} & 15 & \frac{10}{3} & 3.33\dot3 \\ \hline \text{6} & 21 & \frac{30}{7} & 4.286... \\ \hline \end{array}$$ Rather, we could get the value of $y_n$ at any point using the following formula (provided a positive integer $n$ , $1<n$ ): $$y_n=\frac{(\sum_{i=0}^{n-1} i)\times n}{\sum_{i=0}^{n} i}$$ The question is, is there a more effective way to calculate this - the above formula is essentially doing the same as I did by hand (adding up all of the numbers, dividing, etc.), but... as a formula. I'm also aware of Gauss's method of summing numbers, but I'm curious to find out if there's some deeper mathematical link between these numbers - possible a connection to some sequence on OEIS?","Let's say I sum up all of the numbers from 1 to (we'll say is 6 for this example). In this case, I'd get a total of 21 ( ). Now let us pose the following question: if I replaced the s with s, what would I have to divide/multiply each element in the sequence by to get the same answer as with addition? As in, if then what would be at each point in I started calculating some of the elements of , and (if I didn't make a mistake), I got: Rather, we could get the value of at any point using the following formula (provided a positive integer , ): The question is, is there a more effective way to calculate this - the above formula is essentially doing the same as I did by hand (adding up all of the numbers, dividing, etc.), but... as a formula. I'm also aware of Gauss's method of summing numbers, but I'm curious to find out if there's some deeper mathematical link between these numbers - possible a connection to some sequence on OEIS?","n n 1+2+3+4+5+6=21 + \times f_1(x)=1+2+3+...+x y f_2(x)=\frac{1}{y_1}\times\frac{2}{y_2}\times\frac{3}{y_3}...\times\frac{x}{y_x} y \begin{array}{c|c|c|c|} 
n & \text{Total (f_1)} & \text{Fraction of y_n} & \text{Decimal of y_n} \\ \hline
\text{1} & 1 & 1 & 1\\ \hline
\text{2} & 3 & \frac{2}{3} & 0.66\dot6\\ \hline
\text{3} & 6 & \frac{3}{2} & 1.5\\ \hline
\text{4} & 10 & \frac{12}{5} & 2.4 \\ \hline
\text{5} & 15 & \frac{10}{3} & 3.33\dot3 \\ \hline
\text{6} & 21 & \frac{30}{7} & 4.286... \\ \hline
\end{array} y_n n 1<n y_n=\frac{(\sum_{i=0}^{n-1} i)\times n}{\sum_{i=0}^{n} i}","['sequences-and-series', 'summation']"
71,Find the value of $\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n\vert f(a_{k+1})-f(a_k) \vert$,Find the value of,\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n\vert f(a_{k+1})-f(a_k) \vert,Define sequence $a_n=\cos(2n) \quad (n\geq1)$ and $f(x)=\frac{x}{\vert x \vert}$ . Find the value of $$\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n\vert f(a_{k+1})-f(a_k) \vert$$ I don't know how to approach. I couldn't find any regulation of numerator (I mean the sum part.).,Define sequence and . Find the value of I don't know how to approach. I couldn't find any regulation of numerator (I mean the sum part.).,a_n=\cos(2n) \quad (n\geq1) f(x)=\frac{x}{\vert x \vert} \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n\vert f(a_{k+1})-f(a_k) \vert,"['calculus', 'sequences-and-series', 'limits']"
72,Continuity and differentiability of $f(x) = \frac{x}{1+x} + \frac{x}{(x+1)(2x+1)} + \frac{x}{(2x+1)(3x+1)}+...$,Continuity and differentiability of,f(x) = \frac{x}{1+x} + \frac{x}{(x+1)(2x+1)} + \frac{x}{(2x+1)(3x+1)}+...,"Here's the given function: $$f(x) = \dfrac{x}{1+x} + \dfrac{x}{(x+1)(2x+1)} + \dfrac{x}{(2x+1)(3x+1)}+...$$ My question regarding this function: is this function considered a continuous and a differenciable function? Is it not continuous or differenciable at any specific points? According to a question about this function, $f(x)$ is non-continuous. They haven't mentioned anything about it being differenciable or not. My working: Simplyfing the series on the right hand side of the equation is quite straightforward- $$f(x) = \dfrac{x}{1+x} + \dfrac{x}{(x+1)(2x+1)} + \dfrac{x}{(2x+1)(3x+1)}+...$$ $$\implies f(x) = \dfrac{1+x-1}{1+x} + \dfrac{(2x+1)-(x+1)}{(x+1)(2x+1)} + \dfrac{(3x+1)-(2x+1)}{(2x+1)(3x+1)}+...$$ $$\implies f(x) = 1 -\dfrac{1}{1+x}+\dfrac{1}{1+x} -\dfrac{1}{2x+1} +\dfrac{1}{2x+1}-\dfrac{1}{3x+1}...$$ $$\implies f(x) =1 $$ Since $f(x)$ is a constant function, it appears to be both continuous and differenciable $\forall x \in \mathbb R$ . This is clearly incorrect, what am I doing wrong? EDIT: Is there a way to graph a function like $f(x)$ ?","Here's the given function: My question regarding this function: is this function considered a continuous and a differenciable function? Is it not continuous or differenciable at any specific points? According to a question about this function, is non-continuous. They haven't mentioned anything about it being differenciable or not. My working: Simplyfing the series on the right hand side of the equation is quite straightforward- Since is a constant function, it appears to be both continuous and differenciable . This is clearly incorrect, what am I doing wrong? EDIT: Is there a way to graph a function like ?",f(x) = \dfrac{x}{1+x} + \dfrac{x}{(x+1)(2x+1)} + \dfrac{x}{(2x+1)(3x+1)}+... f(x) f(x) = \dfrac{x}{1+x} + \dfrac{x}{(x+1)(2x+1)} + \dfrac{x}{(2x+1)(3x+1)}+... \implies f(x) = \dfrac{1+x-1}{1+x} + \dfrac{(2x+1)-(x+1)}{(x+1)(2x+1)} + \dfrac{(3x+1)-(2x+1)}{(2x+1)(3x+1)}+... \implies f(x) = 1 -\dfrac{1}{1+x}+\dfrac{1}{1+x} -\dfrac{1}{2x+1} +\dfrac{1}{2x+1}-\dfrac{1}{3x+1}... \implies f(x) =1  f(x) \forall x \in \mathbb R f(x),"['calculus', 'sequences-and-series', 'limits', 'continuity']"
73,Simplifying product of two modified Bessel functions,Simplifying product of two modified Bessel functions,,"Is it possible to simplify the product of two modified Bessel functions of the first kind with order zero, \begin{align} \Bigg( \sum_{n=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{n} }{n! \cdot n!} \Bigg) \cdot \Bigg( \sum_{k=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{k} }{k! \cdot k!} \Bigg) \text{?} \end{align} I have gotten as far as \begin{align} & \Bigg( \sum_{n=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{n} }{n! \cdot n!} \Bigg) \cdot \Bigg( \sum_{k=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{k} }{k! \cdot k!} \Bigg) \\ &= \sum_{n=0}^{\infty} \Big( \frac{x^{2}}{4} \Big)^{n} \sum_{k=0}^{n} \frac{1}{k! \cdot k!} \cdot \frac{1}{(n-k)! \cdot (n-k)!} \\ &= \sum_{n=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{n} }{n! \cdot n!} \sum_{k=0}^{n} \binom{n}{k}^{2} \\ &= \sum_{n=0}^{\infty} \binom{2n}{n}^{2} \cdot \dfrac{ \Big( \frac{x}{2} \Big)^{2n}}{(2n)!} \text{;} \end{align} however, I cannot see a way forward. If possible, I'd like to represent the product in terms of another modified Bessel function, beyond the very obvious definition already given above. Perhaps the exponential generating function of the central binomial coefficients could be useful.","Is it possible to simplify the product of two modified Bessel functions of the first kind with order zero, I have gotten as far as however, I cannot see a way forward. If possible, I'd like to represent the product in terms of another modified Bessel function, beyond the very obvious definition already given above. Perhaps the exponential generating function of the central binomial coefficients could be useful.","\begin{align}
\Bigg( \sum_{n=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{n} }{n! \cdot n!} \Bigg) \cdot \Bigg( \sum_{k=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{k} }{k! \cdot k!} \Bigg) \text{?}
\end{align} \begin{align}
& \Bigg( \sum_{n=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{n} }{n! \cdot n!} \Bigg) \cdot \Bigg( \sum_{k=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{k} }{k! \cdot k!} \Bigg) \\
&= \sum_{n=0}^{\infty} \Big( \frac{x^{2}}{4} \Big)^{n} \sum_{k=0}^{n} \frac{1}{k! \cdot k!} \cdot \frac{1}{(n-k)! \cdot (n-k)!} \\
&= \sum_{n=0}^{\infty} \dfrac{ \Big( \frac{x^{2}}{4} \Big)^{n} }{n! \cdot n!} \sum_{k=0}^{n} \binom{n}{k}^{2} \\
&= \sum_{n=0}^{\infty} \binom{2n}{n}^{2} \cdot \dfrac{ \Big( \frac{x}{2} \Big)^{2n}}{(2n)!} \text{;}
\end{align}","['sequences-and-series', 'combinatorics', 'binomial-coefficients', 'bessel-functions']"
74,Find $\lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}} \sum_{k=0}^\infty \frac{\sqrt{k+ n }}{k!} (n+a)^k$,Find,\lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}} \sum_{k=0}^\infty \frac{\sqrt{k+ n }}{k!} (n+a)^k,I am trying to find the following limit: \begin{align} \lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}  \sum_{k=0}^\infty  \frac{\sqrt{k+ n }}{k!} (n+a)^k \end{align} for some fixed $a>0$ . Things that tired.  We can come up with the following bound: \begin{align} \lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}  \sum_{k=0}^\infty  \frac{\sqrt{k+ n }}{k!} (n+a)^k \le  \lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}  \sum_{k=0}^\infty \left(  \frac{\sqrt{k }}{k!} (n+a)^k + \frac{\sqrt{ n }}{k!} (n+a)^k\right)\\  \le  \lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}     \sum_{k=0}^\infty \frac{\sqrt{k }}{k!} (n+a)^k + e^{a} \end{align},I am trying to find the following limit: for some fixed . Things that tired.  We can come up with the following bound:,"\begin{align}
\lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}  \sum_{k=0}^\infty  \frac{\sqrt{k+ n }}{k!} (n+a)^k
\end{align} a>0 \begin{align}
\lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}  \sum_{k=0}^\infty  \frac{\sqrt{k+ n }}{k!} (n+a)^k \le  \lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}  \sum_{k=0}^\infty \left(  \frac{\sqrt{k }}{k!} (n+a)^k + \frac{\sqrt{ n }}{k!} (n+a)^k\right)\\
 \le  \lim_{ n \to \infty} \frac{e^{-n}}{\sqrt{n}}     \sum_{k=0}^\infty \frac{\sqrt{k }}{k!} (n+a)^k + e^{a}
\end{align}","['sequences-and-series', 'limits']"
75,"Prove that $\sum\limits_{n=1}(-1)^n\frac{x^2+n}{n^2}$ uniformly convergent on $[a,b]$",Prove that  uniformly convergent on,"\sum\limits_{n=1}(-1)^n\frac{x^2+n}{n^2} [a,b]","I used the cauchy criteria, for $p>q$ $$\sup\limits_{x\in [a,b]}\left | S_p(x) -S_q(x)\right |= \sup\limits_{x}\left | \sum\limits_{k=q+1}^{p}(-1)^n\frac{x^2+n}{n^2} \right |\leq \\  \sup\limits_{x}\sum\limits_{k=q+1}^{p}\left | \frac{x^2+n}{n^2} \right |\leq  \sup\limits_{x}\frac{x^2+q+1}{(q+1)^2}(p-q)=\\ \frac{b^2+q+1}{(q+1)^2}(p-q)$$ Is what I am doing right till now ?","I used the cauchy criteria, for Is what I am doing right till now ?","p>q \sup\limits_{x\in [a,b]}\left | S_p(x) -S_q(x)\right |=
\sup\limits_{x}\left | \sum\limits_{k=q+1}^{p}(-1)^n\frac{x^2+n}{n^2} \right |\leq \\ 
\sup\limits_{x}\sum\limits_{k=q+1}^{p}\left | \frac{x^2+n}{n^2} \right |\leq 
\sup\limits_{x}\frac{x^2+q+1}{(q+1)^2}(p-q)=\\
\frac{b^2+q+1}{(q+1)^2}(p-q)","['real-analysis', 'sequences-and-series', 'uniform-convergence']"
76,"On the functions $\mathrm{Gi}_{s}^{p,q}(x)=\sum\limits_{n\geq0}\frac{x^{pn+q}}{(pn+q)^s}$",On the functions,"\mathrm{Gi}_{s}^{p,q}(x)=\sum\limits_{n\geq0}\frac{x^{pn+q}}{(pn+q)^s}","I have stumbled across the functions $$\mathrm{Gi}_s^{p,q}(x)=\sum_{n\geq0}\frac{x^{pn+q}}{(pn+q)^s}$$ And I would like to know where I can learn more about them. These functions are interesting because they include certain other special functions as special cases. For example, the polylogarithms: $$\mathrm{Li}_s(x)=\mathrm{Gi}_s^{1,1}(x)$$ and the inverse tangent integrals: $$\mathrm{Ti}_s(x)=-i\cdot\mathrm{Gi}_s^{2,1}(ix)$$ and the interesting relation $$\mathrm{Gi}_s^{p,p}(x)=\frac1{p^s}\mathrm{Li}_s(x^p)$$ As well as the Hurwitz zeta function: $$\mathrm{Gi}_s^{1,q}(1)=\zeta(s,q)$$ And similarily, a relation to the Lerch Transcendent: $$\Phi(z,s,\alpha)=\frac1{z^\alpha}\mathrm{Gi}_s^{1,\alpha}(z)$$ What I've found out so far is detailed below. A hyper-geometric representation We may note that $$\mathrm{Gi}_s^{p,q}(x)=x^q\sum_{n\geq0}\frac{\Gamma(n+1)}{(pn+q)^s}\frac{x^{pn}}{n!}$$ Setting $$t_n=\frac{\Gamma(n+1)}{(pn+q)^s}$$ We have that $$\frac{t_{n+1}}{t_n}=\frac{(n+1)(n+q/p)^s}{(n+q/p+1)^s}$$ so we have that $$\mathrm{Gi}_s^{p,q}(x)=x^q\,_{s+1}F_{s}\left(1,\frac{q}{p},...,\frac{q}{p};1+\frac{q}{p},...,1+\frac{q}{p};x^p\right)$$ A recurrence We may notice that $$\begin{align} \frac{\partial}{\partial x}\mathrm{Gi}_s^{p,q}(x)&=\sum_{n\geq0}\frac{x^{pn+q-1}}{(pn+q)^{s-1}}\\ &=\frac1x\sum_{n\geq0}\frac{x^{pn+q}}{(pn+q)^{s-1}}\\ &=\frac1x\mathrm{Gi}_{s-1}^{p,q}(x)\\ \end{align}$$ So we of course have the $\mathrm{Li}$ -style recurrence $$\mathrm{Gi}_s^{p,q}(x)=\int_0^x \frac{\mathrm{Gi}_{s-1}^{p,q}(t)}{t}\mathrm dt$$ With the easily shown base case of $$\mathrm{Gi}_0^{p,q}(x)=\frac{x^q}{1-x^p}$$ from which the recursive definitions of $\mathrm{Ti}$ and $\mathrm{Li}$ follow. We may also consider the function $$\mathrm{Fi}_s^{p,q}(x)=\sum_{n\geq0}(-1)^n\frac{x^{pn+q}}{(pn+q)^s}$$ And by defining $\lambda_p=\exp\frac{i\pi}{p}$ , we have $$\mathrm{Gi}_s^{p,q}(\lambda_p x)=\lambda_{p}^{q}\mathrm{Fi}_s^{p,q}(x)$$","I have stumbled across the functions And I would like to know where I can learn more about them. These functions are interesting because they include certain other special functions as special cases. For example, the polylogarithms: and the inverse tangent integrals: and the interesting relation As well as the Hurwitz zeta function: And similarily, a relation to the Lerch Transcendent: What I've found out so far is detailed below. A hyper-geometric representation We may note that Setting We have that so we have that A recurrence We may notice that So we of course have the -style recurrence With the easily shown base case of from which the recursive definitions of and follow. We may also consider the function And by defining , we have","\mathrm{Gi}_s^{p,q}(x)=\sum_{n\geq0}\frac{x^{pn+q}}{(pn+q)^s} \mathrm{Li}_s(x)=\mathrm{Gi}_s^{1,1}(x) \mathrm{Ti}_s(x)=-i\cdot\mathrm{Gi}_s^{2,1}(ix) \mathrm{Gi}_s^{p,p}(x)=\frac1{p^s}\mathrm{Li}_s(x^p) \mathrm{Gi}_s^{1,q}(1)=\zeta(s,q) \Phi(z,s,\alpha)=\frac1{z^\alpha}\mathrm{Gi}_s^{1,\alpha}(z) \mathrm{Gi}_s^{p,q}(x)=x^q\sum_{n\geq0}\frac{\Gamma(n+1)}{(pn+q)^s}\frac{x^{pn}}{n!} t_n=\frac{\Gamma(n+1)}{(pn+q)^s} \frac{t_{n+1}}{t_n}=\frac{(n+1)(n+q/p)^s}{(n+q/p+1)^s} \mathrm{Gi}_s^{p,q}(x)=x^q\,_{s+1}F_{s}\left(1,\frac{q}{p},...,\frac{q}{p};1+\frac{q}{p},...,1+\frac{q}{p};x^p\right) \begin{align}
\frac{\partial}{\partial x}\mathrm{Gi}_s^{p,q}(x)&=\sum_{n\geq0}\frac{x^{pn+q-1}}{(pn+q)^{s-1}}\\
&=\frac1x\sum_{n\geq0}\frac{x^{pn+q}}{(pn+q)^{s-1}}\\
&=\frac1x\mathrm{Gi}_{s-1}^{p,q}(x)\\
\end{align} \mathrm{Li} \mathrm{Gi}_s^{p,q}(x)=\int_0^x \frac{\mathrm{Gi}_{s-1}^{p,q}(t)}{t}\mathrm dt \mathrm{Gi}_0^{p,q}(x)=\frac{x^q}{1-x^p} \mathrm{Ti} \mathrm{Li} \mathrm{Fi}_s^{p,q}(x)=\sum_{n\geq0}(-1)^n\frac{x^{pn+q}}{(pn+q)^s} \lambda_p=\exp\frac{i\pi}{p} \mathrm{Gi}_s^{p,q}(\lambda_p x)=\lambda_{p}^{q}\mathrm{Fi}_s^{p,q}(x)","['sequences-and-series', 'power-series', 'special-functions', 'zeta-functions']"
77,Constructing an arithmetic progression so that $\sum_{i=1}^n f(x_i) =0$,Constructing an arithmetic progression so that,\sum_{i=1}^n f(x_i) =0,"Let $f: \mathbb{R} \to \mathbb{R} $ be a continuous function so that $ \exists a, b \in \mathbb{R} $ with $f(a) f(b) <0$ . Prove that $\forall n>2 \exists$ an arithmetic progression $x_1<x_2<...<x_n$ so that $\sum_{i=1}^n f(x_i) =0$ . What I have observed is that there $\exists c \in (a, b) $ so that $f(c) =0$ . I think this is what we need to use to construct that arithmetic progression, but I can't manage to do it.","Let be a continuous function so that with . Prove that an arithmetic progression so that . What I have observed is that there so that . I think this is what we need to use to construct that arithmetic progression, but I can't manage to do it.","f: \mathbb{R} \to \mathbb{R}   \exists a, b \in \mathbb{R}  f(a) f(b) <0 \forall n>2 \exists x_1<x_2<...<x_n \sum_{i=1}^n f(x_i) =0 \exists c \in (a, b)  f(c) =0","['real-analysis', 'sequences-and-series', 'functions']"
78,On a mistake in a derivation regarding a recurrence relation.,On a mistake in a derivation regarding a recurrence relation.,,"Suppose we have a sequence $\{u_t \}_{t \in \mathbb{N}}$ given by the recurrence relation $$u_{t+1} = q_0 u_t + q_1 u_{t-1} + \dots + q_p u_{t-p} + \epsilon, \quad  \epsilon >0$$ where $p \in \mathbb{N}$ and $q_1, \dots, q_p$ are such that the roots $r_0,r_1, \dots, r_p$ of the associated homogeneous characteristic equation $$r^{p+1} - q_0 r^p - q_1 r^{p-1}- \dots - q_p = 0 $$ lie inside the unit circle and the sequence is strictly positive. We can render the sequence homogeneous by settting $u^* = \epsilon / (1 - q_0 - q_1 - \dots -q_p) $ and noticing that $$(u_{t+1} -u^*)  = q_0 (u_t - u^*) + q_1 (u_{t-1} - u^*) + \dots + q_p (u_{t-p} - u^*) $$ It is known that the solution to this recurrence will have the form $$u_{t+1} - u^* = a_0 r_0^{t+1}+a_1 r_1^{t+1}+ \dots + a_p r_p^{t+1}$$ where $a_0,a_1, \dots, a_p$ are real numbers and $r_0, r_1, \dots , r_p$ are the roots of the characteristic equation. Taking the limit for $t \rightarrow \infty$ and recalling that the roots where assumed inside the unit circle we obtain that $$\lim_{t \rightarrow \infty} u_{t+1 } = u^*$$ but (it seems to me) $u^*$ can be negative and the sequence was taken strictly positive. Where is the mistake? Edit: The Eneström–Kakeya theorem (see this link) seems to imply that we can construct a polynomial with all roots inside the unit circle and such that $u^* = \epsilon / (1 - q_0 - q_1 - \dots -q_p) $ is negative. So I still have a doubt if this derivation is correct, thus I am putting a bounty on the question.","Suppose we have a sequence given by the recurrence relation where and are such that the roots of the associated homogeneous characteristic equation lie inside the unit circle and the sequence is strictly positive. We can render the sequence homogeneous by settting and noticing that It is known that the solution to this recurrence will have the form where are real numbers and are the roots of the characteristic equation. Taking the limit for and recalling that the roots where assumed inside the unit circle we obtain that but (it seems to me) can be negative and the sequence was taken strictly positive. Where is the mistake? Edit: The Eneström–Kakeya theorem (see this link) seems to imply that we can construct a polynomial with all roots inside the unit circle and such that is negative. So I still have a doubt if this derivation is correct, thus I am putting a bounty on the question.","\{u_t \}_{t \in \mathbb{N}} u_{t+1} = q_0 u_t + q_1 u_{t-1} + \dots + q_p u_{t-p} + \epsilon, \quad  \epsilon >0 p \in \mathbb{N} q_1, \dots, q_p r_0,r_1, \dots, r_p r^{p+1} - q_0 r^p - q_1 r^{p-1}- \dots - q_p = 0  u^* = \epsilon / (1 - q_0 - q_1 - \dots -q_p)  (u_{t+1} -u^*)  = q_0 (u_t - u^*) + q_1 (u_{t-1} - u^*) + \dots + q_p (u_{t-p} - u^*)  u_{t+1} - u^* = a_0 r_0^{t+1}+a_1 r_1^{t+1}+ \dots + a_p r_p^{t+1} a_0,a_1, \dots, a_p r_0, r_1, \dots , r_p t \rightarrow \infty \lim_{t \rightarrow \infty} u_{t+1 } = u^* u^* u^* = \epsilon / (1 - q_0 - q_1 - \dots -q_p) ","['real-analysis', 'sequences-and-series', 'recurrence-relations']"
79,Why do these two sequences end in an increasing number of zeroes?,Why do these two sequences end in an increasing number of zeroes?,,"The trimorphic numbers are integers whose cubes end in the digits of the integers themselves, such as ${\sf{49}}^3=1176\sf{49}$ , and I have discovered something interesting about such integers that end in $9$ and $1$ . The OEIS sequence A224473 is a sequence of trimorphic numbers congruent to $9\pmod{10}$ and has formula $a_1(n)=2\cdot5^{2^n}-1\pmod{10^n}$ for a natural number $n$ . The sequence is $\{9,49,249,1249,\cdots\}$ . If we denote $b_1(n)=a_1(n)^2-1$ , we see the following. $$b_1(1)=80\\b_1(2)=2400\\b_1(3)=62000\\b_1(4)=12560000\\\cdots$$ That is, $b_1(n)\equiv0\pmod{10^n}$ . Furthermore, A224474 is a sequence of trimorphic numbers congruent to $1\pmod{10}$ with formula $a_2(n)=2\cdot16^{5^n}-1\pmod{10^n}$ , and the first few values are $\{1,51,751,8751,\cdots\}$ . If we denote $b_2(n)=a_2(n)^2-1$ , we observe a similar thing. $$b_2(1)=0\\b_2(2)=2600\\b_2(3)=564000\\b_2(4)=76580000\\\cdots$$ That is, $b_2(n)\equiv0\pmod{10^n}$ . Questions . How can it be proved that $b_1(n)$ and $b_2(n)$ are divisible by $10^n$ ? Is the fact that they are all trimorphic numbers just a coincidence, or does this behaviour occur due to that property?","The trimorphic numbers are integers whose cubes end in the digits of the integers themselves, such as , and I have discovered something interesting about such integers that end in and . The OEIS sequence A224473 is a sequence of trimorphic numbers congruent to and has formula for a natural number . The sequence is . If we denote , we see the following. That is, . Furthermore, A224474 is a sequence of trimorphic numbers congruent to with formula , and the first few values are . If we denote , we observe a similar thing. That is, . Questions . How can it be proved that and are divisible by ? Is the fact that they are all trimorphic numbers just a coincidence, or does this behaviour occur due to that property?","{\sf{49}}^3=1176\sf{49} 9 1 9\pmod{10} a_1(n)=2\cdot5^{2^n}-1\pmod{10^n} n \{9,49,249,1249,\cdots\} b_1(n)=a_1(n)^2-1 b_1(1)=80\\b_1(2)=2400\\b_1(3)=62000\\b_1(4)=12560000\\\cdots b_1(n)\equiv0\pmod{10^n} 1\pmod{10} a_2(n)=2\cdot16^{5^n}-1\pmod{10^n} \{1,51,751,8751,\cdots\} b_2(n)=a_2(n)^2-1 b_2(1)=0\\b_2(2)=2600\\b_2(3)=564000\\b_2(4)=76580000\\\cdots b_2(n)\equiv0\pmod{10^n} b_1(n) b_2(n) 10^n","['sequences-and-series', 'elementary-number-theory', 'modular-arithmetic', 'divisibility', 'oeis']"
80,A sequence of $rs + 1$ real numbers has an increasing subsequence of length $r + 1$ or a decreasing subsequence of length $s + 1$.,A sequence of  real numbers has an increasing subsequence of length  or a decreasing subsequence of length .,rs + 1 r + 1 s + 1,"Problem : Prove the following: a sequence of $rs + 1$ real numbers has an increasing subsequence of length $r + 1$ or a decreasing subsequence of length $s + 1$ . Solution : Define a partial ordering on the sequence $a _ { 1 } , \ldots , a _ { r s + 1 }$ by $a _ { i } \preceq a _ { j }$ iff, $a _ { i } \leq a _ { j }$ and $i \leq j$ A chain is an increasing subsequence, an antichain is a decreasing subsequence. Now I would like to apply Dilworth theorem. Suppose that the maximum size of a chain is $r+1$ , the poset can be partitioned into $r+1$ antichain. However from there I don't now how to continue, what would be size of those antichains?","Problem : Prove the following: a sequence of real numbers has an increasing subsequence of length or a decreasing subsequence of length . Solution : Define a partial ordering on the sequence by iff, and A chain is an increasing subsequence, an antichain is a decreasing subsequence. Now I would like to apply Dilworth theorem. Suppose that the maximum size of a chain is , the poset can be partitioned into antichain. However from there I don't now how to continue, what would be size of those antichains?","rs + 1 r + 1 s + 1 a _ { 1 } , \ldots , a _ { r s + 1 } a _ { i } \preceq a _ { j } a _ { i } \leq a _ { j } i \leq j r+1 r+1","['sequences-and-series', 'combinatorics', 'discrete-mathematics', 'elementary-set-theory']"
81,"Have these ""calculus-based"" consecutive summations been discovered yet?","Have these ""calculus-based"" consecutive summations been discovered yet?",,"Consider the sum-of-powers series $$S_i(n) = 1^i + 2^i + \cdots + n^i = \sum_{k=1}^n y_i(k) \quad\text{with}\; y_i(x)=x^i \tag{1}$$ For $i=1, 2, 3$ , it turns out that we can write $$\begin{align} S_1(n) &= \frac{n+1}{n}\cdot\int_0^{n}y_1(x)\,dx \tag{2a}\\[4pt] S_2(n) &= \frac{n+1}{n}\cdot\int_0^{n}y_2(x)\,dx \cdot \frac{y_2^\prime(n)+1}{y_2^\prime(n)} \tag{2b}\\[4pt] S_3(n) &= \left(\frac{n+1}{n}\right)^2\cdot\int_0^{n}y_3(x)\,dx \tag{2c}\\[4pt] \end{align}$$ which simplify to the well-known formulas $$\begin{align} S_1(n) &= \frac12 n(n+1) \tag{3a}\\[4pt] S_2(n) &= \frac16 n(n+1)(2n+1) \tag{3b}\\[4pt] S_3(n) &= \frac14 n^2 (n + 1)^2 \tag{3c}\\[4pt] \end{align}$$ The only thing is that I'm not quite sure why these relations can include derivatives and integrals and somehow even work at all - they were simply a result of an extremely tiresome trial and error process. And can this ""template"" be extended to any $S_i(n)$ series or even more unorthodox variants? Credits for the condensation and formatting of my answer goes to Blue (in the comments)","Consider the sum-of-powers series For , it turns out that we can write which simplify to the well-known formulas The only thing is that I'm not quite sure why these relations can include derivatives and integrals and somehow even work at all - they were simply a result of an extremely tiresome trial and error process. And can this ""template"" be extended to any series or even more unorthodox variants? Credits for the condensation and formatting of my answer goes to Blue (in the comments)","S_i(n) = 1^i + 2^i + \cdots + n^i = \sum_{k=1}^n y_i(k) \quad\text{with}\; y_i(x)=x^i \tag{1} i=1, 2, 3 \begin{align}
S_1(n) &= \frac{n+1}{n}\cdot\int_0^{n}y_1(x)\,dx \tag{2a}\\[4pt]
S_2(n) &= \frac{n+1}{n}\cdot\int_0^{n}y_2(x)\,dx \cdot \frac{y_2^\prime(n)+1}{y_2^\prime(n)} \tag{2b}\\[4pt]
S_3(n) &= \left(\frac{n+1}{n}\right)^2\cdot\int_0^{n}y_3(x)\,dx \tag{2c}\\[4pt]
\end{align} \begin{align}
S_1(n) &= \frac12 n(n+1) \tag{3a}\\[4pt]
S_2(n) &= \frac16 n(n+1)(2n+1) \tag{3b}\\[4pt]
S_3(n) &= \frac14 n^2 (n + 1)^2 \tag{3c}\\[4pt]
\end{align} S_i(n)","['calculus', 'sequences-and-series']"
82,Evaluating the Cauchy product of $\sum_{n=0}^{\infty}\frac{(-1)^{n+1}}{n+1}$ and $\sum_{n=0}^{\infty}\frac{1}{3^n} $,Evaluating the Cauchy product of  and,\sum_{n=0}^{\infty}\frac{(-1)^{n+1}}{n+1} \sum_{n=0}^{\infty}\frac{1}{3^n} ,Using the Mertens' theorem for Cauchy products we know that the Cauchy product of series $$ \sum_{n=0}^{\infty}\frac{(-1)^{n+1}}{n+1}\qquad\text{and}\qquad\sum_{n=0}^{\infty}\frac{1}{3^n} $$ does converge. But how can we try to find the value of this sum? What I only know is that we can write that this sum equals to $$ S=\sum_{n=0}^{\infty}c_n\qquad\text{where}\qquad c_n=\sum_{k=0}^{n}\frac{1}{3^{n-k}}\frac{(-1)^{k+1}}{k+1} $$ but I'm not able to find any way to calculate the sum. Any hints?,Using the Mertens' theorem for Cauchy products we know that the Cauchy product of series does converge. But how can we try to find the value of this sum? What I only know is that we can write that this sum equals to but I'm not able to find any way to calculate the sum. Any hints?,"
\sum_{n=0}^{\infty}\frac{(-1)^{n+1}}{n+1}\qquad\text{and}\qquad\sum_{n=0}^{\infty}\frac{1}{3^n}
 
S=\sum_{n=0}^{\infty}c_n\qquad\text{where}\qquad c_n=\sum_{k=0}^{n}\frac{1}{3^{n-k}}\frac{(-1)^{k+1}}{k+1}
","['sequences-and-series', 'summation']"
83,Finding $p$ such that $\sum\limits_{n=1}^\infty n(1+n^2)^p$ converges. Check my work.,Finding  such that  converges. Check my work.,p \sum\limits_{n=1}^\infty n(1+n^2)^p,"Given series $$ \sum\limits_{n=1}^\infty n(1+n^2)^p $$ Find the values of $p$ , such that the series is convergent. To find $p$ , I use integral test, assume $f(x)=x(1+x^2)^p$ , \begin{eqnarray} \int\limits_1^\infty x(1+x^2)^pdx &=& \lim\limits_{b\to\infty} \int\limits_1^b x(1+x^2)^pdx\\ &=& \lim\limits_{b\to\infty} \left[\dfrac{1}{2(p+1)}\left((1+b^2)^{p+1}-2^{p+1}\right)\right] \end{eqnarray} If $p=1$ , the integral is divergent, If $p>-1$ , the integral is divergent, If $p<-1$ , the integral is convergent to $-\dfrac{1}{p+1}2^p$ , So, I conclude the series is convergent while $p<-1$ . This answer is correct or incorrect?","Given series Find the values of , such that the series is convergent. To find , I use integral test, assume , If , the integral is divergent, If , the integral is divergent, If , the integral is convergent to , So, I conclude the series is convergent while . This answer is correct or incorrect?","
\sum\limits_{n=1}^\infty n(1+n^2)^p
 p p f(x)=x(1+x^2)^p \begin{eqnarray}
\int\limits_1^\infty x(1+x^2)^pdx &=& \lim\limits_{b\to\infty} \int\limits_1^b x(1+x^2)^pdx\\
&=& \lim\limits_{b\to\infty} \left[\dfrac{1}{2(p+1)}\left((1+b^2)^{p+1}-2^{p+1}\right)\right]
\end{eqnarray} p=1 p>-1 p<-1 -\dfrac{1}{p+1}2^p p<-1","['sequences-and-series', 'convergence-divergence']"
84,Using Wallis' product to derive $\sqrt\pi$,Using Wallis' product to derive,\sqrt\pi,"Recall Wallis' product: $$\lim_{n\to\infty}\Big(\frac{2}{1}\cdot\frac{2}{3}\cdot\frac{4}{3}\cdot\frac{4}{5}\cdot\frac{6}{5}\cdots\frac{2n}{2n-1}\cdot\frac{2n}{2n+1}\Big)=\frac{\pi}{2}$$ We have to show that $$\lim_{n\to\infty}\frac{(n!)^22^{2n}}{(2n)!\sqrt n}=\sqrt\pi$$ The hint I got was to use $$P_n=\frac{(n!)^42^{4n}}{[(2n)!]^2(2n+1)}$$ which is just simply the inside of the limit in Wallis' product, multiplied and divided by $2\cdot2\cdot4\cdot4\cdots(2n)\cdot(2n)$ alternatively. How do I use $P_n$ to derive $\sqrt\pi\:$ ?","Recall Wallis' product: We have to show that The hint I got was to use which is just simply the inside of the limit in Wallis' product, multiplied and divided by alternatively. How do I use to derive ?",\lim_{n\to\infty}\Big(\frac{2}{1}\cdot\frac{2}{3}\cdot\frac{4}{3}\cdot\frac{4}{5}\cdot\frac{6}{5}\cdots\frac{2n}{2n-1}\cdot\frac{2n}{2n+1}\Big)=\frac{\pi}{2} \lim_{n\to\infty}\frac{(n!)^22^{2n}}{(2n)!\sqrt n}=\sqrt\pi P_n=\frac{(n!)^42^{4n}}{[(2n)!]^2(2n+1)} 2\cdot2\cdot4\cdot4\cdots(2n)\cdot(2n) P_n \sqrt\pi\:,['sequences-and-series']
85,Prove that $\prod_{r=1}^m \sin \left( \frac {r\pi}{2m+1}\right) =\frac {\sqrt {2m+1}}{2^m}$,Prove that,\prod_{r=1}^m \sin \left( \frac {r\pi}{2m+1}\right) =\frac {\sqrt {2m+1}}{2^m},"Prove that $$\prod_{r=1}^m  \sin \left( \frac {r\pi}{2m+1}\right) =\frac {\sqrt {2m+1}}{2^m}$$ My try: $$\prod_{r=1}^m  \sin \left( \frac {r\pi}{2m+1}\right) =\prod_{r=1}^m \left(\frac {e^{\frac {ir\pi}{2m+1}} -e^{\frac {-ir\pi}{2m+1}}}{2i}\right) =\frac {1}{2^mi^m}\left(\prod_{r=1}^m e^{\frac {-ir\pi}{2m+1}}\right) \prod_{r=1}^m \left(e^{\frac {2ir\pi}{2m+1}} -1\right)$$ But I can't get a clue to tackle $$\prod_{r=1}^m \left(e^{\frac {2ir\pi}{2m+1}} -1\right)$$ . I tried to use it's relation with roots of unity but couldn't proceed much. I also tried writing the $\sin$ using Euler's reflection formula that for $z\in (0,1)$ $$\sin (\pi z)=\frac {\pi}{\Gamma(z)\Gamma(1-z)}$$ where in our case $z=\frac {r}{2m+1}$ . But that too didn't last long. Any help is greatly appreciated. Thanks.",Prove that My try: But I can't get a clue to tackle . I tried to use it's relation with roots of unity but couldn't proceed much. I also tried writing the using Euler's reflection formula that for where in our case . But that too didn't last long. Any help is greatly appreciated. Thanks.,"\prod_{r=1}^m  \sin \left( \frac {r\pi}{2m+1}\right) =\frac {\sqrt {2m+1}}{2^m} \prod_{r=1}^m  \sin \left( \frac {r\pi}{2m+1}\right) =\prod_{r=1}^m \left(\frac {e^{\frac {ir\pi}{2m+1}} -e^{\frac {-ir\pi}{2m+1}}}{2i}\right) =\frac {1}{2^mi^m}\left(\prod_{r=1}^m e^{\frac {-ir\pi}{2m+1}}\right) \prod_{r=1}^m \left(e^{\frac {2ir\pi}{2m+1}} -1\right) \prod_{r=1}^m \left(e^{\frac {2ir\pi}{2m+1}} -1\right) \sin z\in (0,1) \sin (\pi z)=\frac {\pi}{\Gamma(z)\Gamma(1-z)} z=\frac {r}{2m+1}","['calculus', 'sequences-and-series', 'trigonometry', 'complex-numbers', 'gamma-function']"
86,The last digit of pi (in terms of Banach limits),The last digit of pi (in terms of Banach limits),,"Let $\phi : l^\infty \to \mathbb C$ be a Banach limit , and define the sequence $\{x_k\}_{k\geq 0}$ to be the digits in the 10-base decimal expansion of $\pi$ . Note that $$\{x_k\}_{k\geq 0} \in l^\infty$$ and so we can talk about $\phi(\{x_k\}_{k\geq 0})$ . What it is? Note that Banach limits don't have to be unique. Now consider the real number $\sqrt 2$ . What is its last number? Finally, consider any element $x\in \mathbb R$ . Can we say about the last digit of $x$ , in the sense of Banach limits as considered above?","Let be a Banach limit , and define the sequence to be the digits in the 10-base decimal expansion of . Note that and so we can talk about . What it is? Note that Banach limits don't have to be unique. Now consider the real number . What is its last number? Finally, consider any element . Can we say about the last digit of , in the sense of Banach limits as considered above?",\phi : l^\infty \to \mathbb C \{x_k\}_{k\geq 0} \pi \{x_k\}_{k\geq 0} \in l^\infty \phi(\{x_k\}_{k\geq 0}) \sqrt 2 x\in \mathbb R x,"['sequences-and-series', 'functional-analysis', 'limits', 'banach-spaces']"
87,Show the series $\sum\limits^{\infty}_{n=1}{\frac{a_n}{n}}$ converges,Show the series  converges,\sum\limits^{\infty}_{n=1}{\frac{a_n}{n}},"Suppose the sequence $\{a_n\}_{n=1}^{\infty}$ satisfies $$\mid\sum\limits^{n}_{k=1}{a_{k}}\mid\leq C\sqrt{n} \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space n=1, 2, 3, \cdots$$ where $C$ is a fixed (but arbitrary) number. Prove that the series $$\sum\limits^{\infty}_{n=1}{\frac{a_n}{n}}$$ converges. My attempt: Suppose $b_n:= \frac{1}{n}$ ; Abel's lemma on summation by parts gives $$\sum\limits^{k}_{n=1}{\frac{a_n}{n}}=\sum\limits^{k-1}_{n=1}{[\sum\limits_{i=1}^{n}{a_i}\cdot(b_n-b_{n+1})] + \sum\limits_{i=1}^{k}{a_i}\cdot b_k}$$ $$<\sum\limits^{k-1}_{n=1}{\mid\sum\limits_{i=1}^{n}{a_i}\mid\cdot(b_n-b_{n+1}) +\mid \sum\limits_{i=1}^{k}{a_i}\mid \cdot b_k}$$ $$\le\sum\limits_{n=1}^{k}[C\sqrt{n}\cdot{(\frac{1}{n}-\frac{1}{n+1}})]+C\sqrt{k}\cdot \frac{1}{k+1}$$ $$=\sum\limits_{n=1}^{k}{\frac{C\sqrt{n}}{n(n+1)}}+\frac{C\sqrt{k}}{k+1}.$$ Since $k\rightarrow\infty$ , therefore $$\frac{C\sqrt{k}}{k+1}\rightarrow 0.$$ Moreover, for the sigma notation, since $$\frac{C\sqrt{n}}{n(n+1)}<\frac{C\sqrt{n}}{n^2}=\frac{C}{n^\frac{3}{2}}$$ Above is a $p$ -series with $p=\frac{3}{2}>1$ , hence the series $\sum\limits_{n=1}^{k}{\frac{C\sqrt{n}}{n(n+1)}}$ converges. Even though $\sum\limits_{n=1}^{k}{\frac{C\sqrt{n}}{n(n+1)}}$ converges and $\frac{C\sqrt{k}}{k+1}$ approaches to $0$ for $k\rightarrow\infty$ , but they do not imply the series $\sum\limits^{\infty}_{n=1}{\frac{a_n}{n}}$ converges. My proof seems not yet completed. How do I continue it?","Suppose the sequence satisfies where is a fixed (but arbitrary) number. Prove that the series converges. My attempt: Suppose ; Abel's lemma on summation by parts gives Since , therefore Moreover, for the sigma notation, since Above is a -series with , hence the series converges. Even though converges and approaches to for , but they do not imply the series converges. My proof seems not yet completed. How do I continue it?","\{a_n\}_{n=1}^{\infty} \mid\sum\limits^{n}_{k=1}{a_{k}}\mid\leq C\sqrt{n} \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space n=1, 2, 3, \cdots C \sum\limits^{\infty}_{n=1}{\frac{a_n}{n}} b_n:= \frac{1}{n} \sum\limits^{k}_{n=1}{\frac{a_n}{n}}=\sum\limits^{k-1}_{n=1}{[\sum\limits_{i=1}^{n}{a_i}\cdot(b_n-b_{n+1})] + \sum\limits_{i=1}^{k}{a_i}\cdot b_k} <\sum\limits^{k-1}_{n=1}{\mid\sum\limits_{i=1}^{n}{a_i}\mid\cdot(b_n-b_{n+1}) +\mid \sum\limits_{i=1}^{k}{a_i}\mid \cdot b_k} \le\sum\limits_{n=1}^{k}[C\sqrt{n}\cdot{(\frac{1}{n}-\frac{1}{n+1}})]+C\sqrt{k}\cdot \frac{1}{k+1} =\sum\limits_{n=1}^{k}{\frac{C\sqrt{n}}{n(n+1)}}+\frac{C\sqrt{k}}{k+1}. k\rightarrow\infty \frac{C\sqrt{k}}{k+1}\rightarrow 0. \frac{C\sqrt{n}}{n(n+1)}<\frac{C\sqrt{n}}{n^2}=\frac{C}{n^\frac{3}{2}} p p=\frac{3}{2}>1 \sum\limits_{n=1}^{k}{\frac{C\sqrt{n}}{n(n+1)}} \sum\limits_{n=1}^{k}{\frac{C\sqrt{n}}{n(n+1)}} \frac{C\sqrt{k}}{k+1} 0 k\rightarrow\infty \sum\limits^{\infty}_{n=1}{\frac{a_n}{n}}","['sequences-and-series', 'proof-verification', 'convergence-divergence']"
88,The result of $n$ iterations of $x_{\text{output}}=\arctan\left(c\tan(x_{\text{input}})\right)$ [closed],The result of  iterations of  [closed],n x_{\text{output}}=\arctan\left(c\tan(x_{\text{input}})\right),"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question The function is given by: $$x_{\text{output}}=\arctan\left(c\tan(x_{\text{input}})\right)$$ where $c$ is a constant between $0$ and $1$ . After an output is found, the output becomes the input for the next iteration. I would like to know how to find the angle (or $x_{\text{output}}$ ) after $n$ iterations. I could make a table, but if $n$ is large this is tedious... Thanks!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question The function is given by: where is a constant between and . After an output is found, the output becomes the input for the next iteration. I would like to know how to find the angle (or ) after iterations. I could make a table, but if is large this is tedious... Thanks!",x_{\text{output}}=\arctan\left(c\tan(x_{\text{input}})\right) c 0 1 x_{\text{output}} n n,"['calculus', 'sequences-and-series']"
89,Existence of derivative of series at $x = 0$,Existence of derivative of series at,x = 0,"I want to determine if the following function is differentiable for $x \in [0,\infty)$ $$F(x) = \sum_{j=0}^\infty \frac{e^{-jx}}{j^2 +1}$$ The series is uniformly convergent on $[0,\infty$ ) by the M-test since $\displaystyle \left|\frac{e^{-jx}}{j^2 +1} \right| < \frac{1}{j^2}$ and the series of termwise derivatives has uniform convergence on any interval $[\alpha,\infty)$ since $\displaystyle \left|\frac{je^{-jx}}{j^2 +1}\right|< \frac{e^{-\alpha j}}{j^2}.$ This proves that $F$ is differentiable for any point $x \in (0,\infty)$ . I know that the series of termwise derivatives does not converge  for $x = 0$ , so the derivative $F'(0)$ may not exist, but I would like to know how to show this directly. There are examples where a derivative of a series may exist even though it can't be obtained by termwise differentiation.","I want to determine if the following function is differentiable for The series is uniformly convergent on ) by the M-test since and the series of termwise derivatives has uniform convergence on any interval since This proves that is differentiable for any point . I know that the series of termwise derivatives does not converge  for , so the derivative may not exist, but I would like to know how to show this directly. There are examples where a derivative of a series may exist even though it can't be obtained by termwise differentiation.","x \in [0,\infty) F(x) = \sum_{j=0}^\infty \frac{e^{-jx}}{j^2 +1} [0,\infty \displaystyle \left|\frac{e^{-jx}}{j^2 +1} \right| < \frac{1}{j^2} [\alpha,\infty) \displaystyle \left|\frac{je^{-jx}}{j^2 +1}\right|< \frac{e^{-\alpha j}}{j^2}. F x \in (0,\infty) x = 0 F'(0)","['sequences-and-series', 'derivatives']"
90,How to obtain the lower bound of $\dfrac{n}{\sqrt[n]{n!}}$ by Taylor's series?,How to obtain the lower bound of  by Taylor's series?,\dfrac{n}{\sqrt[n]{n!}},"We want to prove $$\lim_{n \to \infty}a_n=\lim_{n \to \infty}\frac{n}{\sqrt[n]{n!}}=e.$$ I have some solutions for this, but I want to find another method applying the squeeze theorem. Thus, a natrual thought is to find the upper bound and the lower bound of $a_n$ . Notice that $$e^x=1+x+\frac{x^2}{2!}+\cdots+\frac{x^n}{n!}+\cdots.$$ If we substitute $x$ for $n$ , then $$e^n=1+n+\frac{n^2}{2!}+\cdots+\frac{n^n}{n!}+\cdots>\frac{n^n}{n!}.\tag1$$ Thus, we obtain $$e>\frac{n}{\sqrt[n]{n!}},$$ which shows $e$ is a upper bound of $a_n$ . But how to obtain the lower bound by $(1)$ ? Say it again. I have other methods to deal with it. I just wonder whether there is some method depending on $(1)$ only or not.","We want to prove I have some solutions for this, but I want to find another method applying the squeeze theorem. Thus, a natrual thought is to find the upper bound and the lower bound of . Notice that If we substitute for , then Thus, we obtain which shows is a upper bound of . But how to obtain the lower bound by ? Say it again. I have other methods to deal with it. I just wonder whether there is some method depending on only or not.","\lim_{n \to \infty}a_n=\lim_{n \to \infty}\frac{n}{\sqrt[n]{n!}}=e. a_n e^x=1+x+\frac{x^2}{2!}+\cdots+\frac{x^n}{n!}+\cdots. x n e^n=1+n+\frac{n^2}{2!}+\cdots+\frac{n^n}{n!}+\cdots>\frac{n^n}{n!}.\tag1 e>\frac{n}{\sqrt[n]{n!}}, e a_n (1) (1)","['sequences-and-series', 'limits']"
91,"I found another pattern in the Fibonacci sequence, can anyone explain why?","I found another pattern in the Fibonacci sequence, can anyone explain why?",,"I think I stumbled on something and I just wanted to ask why this pattern occurs. I’m not a mathematician I put the sequence in excel (if anyone wants it here’s a link https://oeis.org/A000045/b000045.txt ) and from 20th number onwards a pattern emerges with the largest digit. 6765 so the 6 10946 the 1 17711 the 1 28657 the 2 46368 the 4 75025 the 7 121393 the 1 196418 the 1 317811 the 3 514229 th 5 832040 the 8 1346269 the 1 2178309 the 2 3524578 the 3 5702887 the 5 9227465 the 9 14930352 the 1 24157817 the 2 39088169 the 3 The number 6 then begins again on the 39th number, , and the 40th begins with 1 , and the 41st begins with 1 , and the 42nd begins with 2 , and the 43rd begins with 4 , and the 44th begins with 7 , and the 45th begins with 1 so again the 6112471.... begins to appear. I thought I'd write out everytime I see this 6 in the sequence begins again. List of line where the 6 sequence repeats. 20 (as shown with first example), 39, 63, 87, 106, 130, 154, 173, 197, 221, 240, 264, 288, 307, 331, 355, 374, 398, 422, 441, 465, 484, 508 ,532 , 551, 575, 599, 618, 642, 666, 685, 709, 733, 752, 776, 800, 819, 843, 867, 886, 910, 934, 953, 977, 996, 1020, 1044, 1063, 1087, 1111, 1130, 1154, 1178, 1197, 1221, 1245, 1264, 1288, 1312, 1331, 1355, 1379, 1398, 1422, 1441, 1465 As you will see below this pattern repeats (0r the 6 1 1 2 4 7 1) begins again every 19, 24, 24 times respectively 6 times. 39 - 20 = 19 63 - 39 = 24 87 - 63 = 24 106 - 87 = 19 130 - 106 = 24 154 - 130 = 24 173 - 154 = 19 197 - 173 = 24 221 - 197 = 24 240 - 221 = 19 264 - 240 = 24 288 - 264 = 24 307 - 288 = 19 331 - 307 = 24 355 - 331 = 24 374 - 355 = 19 398 - 374 = 24 422 - 398 = 24 441 - 422 = 19 465 - 441 = 24 484 - 465 = 19 508 - 484 = 24 532 - 508 = 24 551 - 532 = 19 575 - 551 = 24 599 - 575 = 24 618 - 599 = 19 642 - 618 = 24 666 - 642 = 24 685 - 666 = 19 709 - 685 = 24 733 - 709 = 24 752 - 733 = 19 776 - 752 = 24 800 - 776 = 24 819 - 800 = 19 843 - 819 = 24 867 - 843 = 24 886 - 867 = 19 910 - 886 = 24 934 - 910 = 24 953 - 934 = 19 977 - 953 = 24 996 - 977 = 19 1020 - 996 = 24 1044 - 1020 = 24 1063 - 1044 = 19 1087 - 1063 = 24 1111 - 1087 = 24 1130 - 1111 = 19 1154 - 1130 = 24 1178 - 1154 = 24 1197 - 1178 = 19 1221 - 1197 = 24 1245 - 1221 = 24 1264 - 1245 = 19 1288 - 1264 = 24 1312 - 1288 = 24 1331 - 1312 = 19 1355 - 1331 = 24 1379 - 1355 = 24 1398 - 1379 = 19 1422 - 1398 = 24 1441 - 1422 = 19 1465 - 1441 = 24 (excel reached limit after this, could not continue) The 6 sequence repeats 19, 24, 24 interval 6 times respectively for 19 cosecutive times. Does anyone have an explanation? Also I know numbers shouldn’t be looked at from it’s largest number alone but as a whole, but it’s just something I noticed Thanks in advance","I think I stumbled on something and I just wanted to ask why this pattern occurs. I’m not a mathematician I put the sequence in excel (if anyone wants it here’s a link https://oeis.org/A000045/b000045.txt ) and from 20th number onwards a pattern emerges with the largest digit. 6765 so the 6 10946 the 1 17711 the 1 28657 the 2 46368 the 4 75025 the 7 121393 the 1 196418 the 1 317811 the 3 514229 th 5 832040 the 8 1346269 the 1 2178309 the 2 3524578 the 3 5702887 the 5 9227465 the 9 14930352 the 1 24157817 the 2 39088169 the 3 The number 6 then begins again on the 39th number, , and the 40th begins with 1 , and the 41st begins with 1 , and the 42nd begins with 2 , and the 43rd begins with 4 , and the 44th begins with 7 , and the 45th begins with 1 so again the 6112471.... begins to appear. I thought I'd write out everytime I see this 6 in the sequence begins again. List of line where the 6 sequence repeats. 20 (as shown with first example), 39, 63, 87, 106, 130, 154, 173, 197, 221, 240, 264, 288, 307, 331, 355, 374, 398, 422, 441, 465, 484, 508 ,532 , 551, 575, 599, 618, 642, 666, 685, 709, 733, 752, 776, 800, 819, 843, 867, 886, 910, 934, 953, 977, 996, 1020, 1044, 1063, 1087, 1111, 1130, 1154, 1178, 1197, 1221, 1245, 1264, 1288, 1312, 1331, 1355, 1379, 1398, 1422, 1441, 1465 As you will see below this pattern repeats (0r the 6 1 1 2 4 7 1) begins again every 19, 24, 24 times respectively 6 times. 39 - 20 = 19 63 - 39 = 24 87 - 63 = 24 106 - 87 = 19 130 - 106 = 24 154 - 130 = 24 173 - 154 = 19 197 - 173 = 24 221 - 197 = 24 240 - 221 = 19 264 - 240 = 24 288 - 264 = 24 307 - 288 = 19 331 - 307 = 24 355 - 331 = 24 374 - 355 = 19 398 - 374 = 24 422 - 398 = 24 441 - 422 = 19 465 - 441 = 24 484 - 465 = 19 508 - 484 = 24 532 - 508 = 24 551 - 532 = 19 575 - 551 = 24 599 - 575 = 24 618 - 599 = 19 642 - 618 = 24 666 - 642 = 24 685 - 666 = 19 709 - 685 = 24 733 - 709 = 24 752 - 733 = 19 776 - 752 = 24 800 - 776 = 24 819 - 800 = 19 843 - 819 = 24 867 - 843 = 24 886 - 867 = 19 910 - 886 = 24 934 - 910 = 24 953 - 934 = 19 977 - 953 = 24 996 - 977 = 19 1020 - 996 = 24 1044 - 1020 = 24 1063 - 1044 = 19 1087 - 1063 = 24 1111 - 1087 = 24 1130 - 1111 = 19 1154 - 1130 = 24 1178 - 1154 = 24 1197 - 1178 = 19 1221 - 1197 = 24 1245 - 1221 = 24 1264 - 1245 = 19 1288 - 1264 = 24 1312 - 1288 = 24 1331 - 1312 = 19 1355 - 1331 = 24 1379 - 1355 = 24 1398 - 1379 = 19 1422 - 1398 = 24 1441 - 1422 = 19 1465 - 1441 = 24 (excel reached limit after this, could not continue) The 6 sequence repeats 19, 24, 24 interval 6 times respectively for 19 cosecutive times. Does anyone have an explanation? Also I know numbers shouldn’t be looked at from it’s largest number alone but as a whole, but it’s just something I noticed Thanks in advance",,"['sequences-and-series', 'integers']"
92,$ \lim_{n \to \infty} \frac{(-1)^n(3-n)}{(3n-5)}$ and ...,and ..., \lim_{n \to \infty} \frac{(-1)^n(3-n)}{(3n-5)},"To find limits: $(a) \lim_{n \to \infty} \frac{(-1)^n(3-n)}{(3n-5)}$ $(b) \lim_{n \to \infty} \frac{n^3}{n!}$ For the first one the sequence is oscillating so it does not converge. For the 2nd one I used ratio test: Let $a_n = \frac{n^3}{n!} $ , then $\frac{a_{n+1}}{a_n} = \frac{n! \times (n+1)^3}{n^3 \times (n+1)!} = (1+ \frac1n)^3 \times \frac{1}{1+n}$ . Thus, $|\frac{a_{n+1}}{a_n}| < 1$ , by ratio test limit is $0$ . Is the solutions correct?","To find limits: For the first one the sequence is oscillating so it does not converge. For the 2nd one I used ratio test: Let , then . Thus, , by ratio test limit is . Is the solutions correct?",(a) \lim_{n \to \infty} \frac{(-1)^n(3-n)}{(3n-5)} (b) \lim_{n \to \infty} \frac{n^3}{n!} a_n = \frac{n^3}{n!}  \frac{a_{n+1}}{a_n} = \frac{n! \times (n+1)^3}{n^3 \times (n+1)!} = (1+ \frac1n)^3 \times \frac{1}{1+n} |\frac{a_{n+1}}{a_n}| < 1 0,"['real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
93,Showing that the sum of two sets of sequences is dense in the sequence space $\ell^1$,Showing that the sum of two sets of sequences is dense in the sequence space,\ell^1,"I'm trying to solve the following problem. It's a part of problem 1.14 in Brezies' book on functional analysis. Let $E=\ell^1$ . Consider $$X=\{x=(x_n)_{n\geq1}\in E:x_{2n}=0\ \forall n\geq1\}$$ and $$Y=\{y=(y_n)_{n\geq1}\in E:y_{2n}=\frac{1}{2^n}y_{2n-1}\ \forall n\geq1\}.$$ Show that $\overline{X+Y}=E$ . Here, $\ell^1=\{x:\|x\|_1<\infty\}$ and $$\|x\|_1:=\sum_{k=1}^\infty|x_k|.$$ We have that $\overline{X+Y}\subseteq E$ as $E$ is the ambient space of $X+Y$ , but I'm unsure on how to prove that $E\subseteq\overline{X+Y}$ . Maybe an argument by contradiction would be useful. That is, assume that there exists a $z\in E$ such that $z\notin\overline{X+Y}$ and then arrive to some contradiction. The problem to continue here is that I don't really know what the closure $\overline{X+Y}$ would be. Thus, I don't really know how to proceed with the other part either. I know that we're working in a sequence space, so every element is a sequence. The sequences may have infinitely many elements, so we're in an infinite dimensional space. I know how the norm $$\|(x_n)_{n\in\Bbb{N}}-(y_n)_{n\in\Bbb{N}}\|:=\sum_{k=1}^\infty|x_k-y_k|$$ works, but not really what the sets of the intersection of closed sets would look like, or how they would influence the outcome of the closure. Here, both $X$ and $Y$ are closed. I'm also a bit curious on how addition of sets consisting of sequences works. Is the resulting set such that every sequence point in every sequence is the sum of the sequences in the initial sets $X$ and $Y$ ?","I'm trying to solve the following problem. It's a part of problem 1.14 in Brezies' book on functional analysis. Let . Consider and Show that . Here, and We have that as is the ambient space of , but I'm unsure on how to prove that . Maybe an argument by contradiction would be useful. That is, assume that there exists a such that and then arrive to some contradiction. The problem to continue here is that I don't really know what the closure would be. Thus, I don't really know how to proceed with the other part either. I know that we're working in a sequence space, so every element is a sequence. The sequences may have infinitely many elements, so we're in an infinite dimensional space. I know how the norm works, but not really what the sets of the intersection of closed sets would look like, or how they would influence the outcome of the closure. Here, both and are closed. I'm also a bit curious on how addition of sets consisting of sequences works. Is the resulting set such that every sequence point in every sequence is the sum of the sequences in the initial sets and ?",E=\ell^1 X=\{x=(x_n)_{n\geq1}\in E:x_{2n}=0\ \forall n\geq1\} Y=\{y=(y_n)_{n\geq1}\in E:y_{2n}=\frac{1}{2^n}y_{2n-1}\ \forall n\geq1\}. \overline{X+Y}=E \ell^1=\{x:\|x\|_1<\infty\} \|x\|_1:=\sum_{k=1}^\infty|x_k|. \overline{X+Y}\subseteq E E X+Y E\subseteq\overline{X+Y} z\in E z\notin\overline{X+Y} \overline{X+Y} \|(x_n)_{n\in\Bbb{N}}-(y_n)_{n\in\Bbb{N}}\|:=\sum_{k=1}^\infty|x_k-y_k| X Y X Y,"['sequences-and-series', 'general-topology', 'functional-analysis']"
94,Does the sequence lemma hold for Hausdorff?,Does the sequence lemma hold for Hausdorff?,,"Munkres Topology: Sequence Lemma Let $X$ be a topological space; let $A \subset X$ . If there is a sequence of points of $A$ converging to $x$ , then $x \in \overline{A}$ ; the converse holds if $X$ is metrizable. This lemma has been asked about before. Lemma 21.2 in Munkres' TOPOLOGY, 2nd ed: The Sequence Lemma My question is about changing ""metrizable"" with ""Hausdorff"". I found a class where in a homework problem set , it says ""This is an example of a non-Hausdorff space in which the sequence lemma holds."" The saying says to me that the class has a version of the sequence lemma that holds for Hausdorff and then there's an example where the sequence lemma holds for something they would not expect, which is non-Hausdorff. (Another explanation is that the example is non-metrizable and then it is additionally pointed out that the example is also non-Hausdorff.) I hope that the version is exactly the same as the one above except for changing ""metrizable"" with ""Hausdorff"". (I cannot find anything of the sort in Week 4 or Notes for whole class.) I have attempted a proof but it has some resemblance to the proof for metrizable spaces. I am choosing to not type up this proof fearing it is wrong because I have somehow assumed metrization.","Munkres Topology: Sequence Lemma Let be a topological space; let . If there is a sequence of points of converging to , then ; the converse holds if is metrizable. This lemma has been asked about before. Lemma 21.2 in Munkres' TOPOLOGY, 2nd ed: The Sequence Lemma My question is about changing ""metrizable"" with ""Hausdorff"". I found a class where in a homework problem set , it says ""This is an example of a non-Hausdorff space in which the sequence lemma holds."" The saying says to me that the class has a version of the sequence lemma that holds for Hausdorff and then there's an example where the sequence lemma holds for something they would not expect, which is non-Hausdorff. (Another explanation is that the example is non-metrizable and then it is additionally pointed out that the example is also non-Hausdorff.) I hope that the version is exactly the same as the one above except for changing ""metrizable"" with ""Hausdorff"". (I cannot find anything of the sort in Week 4 or Notes for whole class.) I have attempted a proof but it has some resemblance to the proof for metrizable spaces. I am choosing to not type up this proof fearing it is wrong because I have somehow assumed metrization.",X A \subset X A x x \in \overline{A} X,"['sequences-and-series', 'general-topology']"
95,Weak convergence of measures implying almost sure convergence of random variables,Weak convergence of measures implying almost sure convergence of random variables,,"Suppose $\mu,\mu_n$ are Borel probability measures on $\mathbb{R}$ with $\mu_n$ converging weakly to $\mu$ . I am asked to find some probability space $(\Omega,\mathcal{F},\mathbb{P})$ and random variables $X,X_n$ such that $X$ has law $\mu$ , $X_n$ has law $\mu_n$ and $X_n \to X$ almost surely as $n \to \infty$ . So far I tried to let $(\Omega,\mathcal{F},\mathbb{P}) = ((0,1),\mathcal{B}_{0,1},\text{Lebesgue})$ and defined $X_n$ as for $\omega \in (0,1)$ we let $X_n(\omega) = \inf\{x \in \mathbb{R}: \omega \in \mu_n((-\infty,x])\}$ . Then $\mathbb{P}(X_n \in (-\infty,x]) = \mathbb{P}(X_n^{-1}((-\infty,x])) = \mu_n((-\infty,x])$ so $X_n$ has law $\mu_n$ and similarly for $X$ . However I am not able to prove that $X_n \to X$ almost surely. I have tried using contradiction, if $X_n \not\to X$ almost surely then we have that $|X_n-X| \geq 0$ and this does not converge to 0 almost surely. So the integral of this does not converge to $0$ as $n \to \infty$ . However at this point I get stuck. I can't see where I should bring in the fact that $\mu_n \to \mu$ weakly. How should I proceed?","Suppose are Borel probability measures on with converging weakly to . I am asked to find some probability space and random variables such that has law , has law and almost surely as . So far I tried to let and defined as for we let . Then so has law and similarly for . However I am not able to prove that almost surely. I have tried using contradiction, if almost surely then we have that and this does not converge to 0 almost surely. So the integral of this does not converge to as . However at this point I get stuck. I can't see where I should bring in the fact that weakly. How should I proceed?","\mu,\mu_n \mathbb{R} \mu_n \mu (\Omega,\mathcal{F},\mathbb{P}) X,X_n X \mu X_n \mu_n X_n \to X n \to \infty (\Omega,\mathcal{F},\mathbb{P}) = ((0,1),\mathcal{B}_{0,1},\text{Lebesgue}) X_n \omega \in (0,1) X_n(\omega) = \inf\{x \in \mathbb{R}: \omega \in \mu_n((-\infty,x])\} \mathbb{P}(X_n \in (-\infty,x]) = \mathbb{P}(X_n^{-1}((-\infty,x])) = \mu_n((-\infty,x]) X_n \mu_n X X_n \to X X_n \not\to X |X_n-X| \geq 0 0 n \to \infty \mu_n \to \mu","['sequences-and-series', 'measure-theory', 'convergence-divergence', 'weak-convergence', 'almost-everywhere']"
96,about limit of exponential function [duplicate],about limit of exponential function [duplicate],,This question already has answers here : Limit of $\lim\limits_{n\to\infty} (1 + \frac{x_n}{n})^n$ (2 answers) Closed 5 years ago . Maybe the answer is obvious. I'm sorry for this I know for all $x \in \mathbb{R}$ that $$ \lim_\limits{n \to \infty}\left(1 + \frac{x}{n} \right)^{n} = \exp(x). $$ Now suppose I have a sequence $\{x_{n}\}_{n \in \mathbb{N}}$ such that $$ \lim_\limits{n \to \infty} x_{n} = x \in \mathbb{R}. $$ Can I also conclude that $$ \lim_\limits{n \to \infty}\left(1 + \frac{x_{n}}{n} \right)^{n} = \exp(x)? $$,This question already has answers here : Limit of $\lim\limits_{n\to\infty} (1 + \frac{x_n}{n})^n$ (2 answers) Closed 5 years ago . Maybe the answer is obvious. I'm sorry for this I know for all $x \in \mathbb{R}$ that $$ \lim_\limits{n \to \infty}\left(1 + \frac{x}{n} \right)^{n} = \exp(x). $$ Now suppose I have a sequence $\{x_{n}\}_{n \in \mathbb{N}}$ such that $$ \lim_\limits{n \to \infty} x_{n} = x \in \mathbb{R}. $$ Can I also conclude that $$ \lim_\limits{n \to \infty}\left(1 + \frac{x_{n}}{n} \right)^{n} = \exp(x)? $$,,['real-analysis']
97,How to prove that if $a_n=o(n) $ then $\sum_{k=0}^n\frac{a_n^k}{k!}\sim e^{a_n} $,How to prove that if  then,a_n=o(n)  \sum_{k=0}^n\frac{a_n^k}{k!}\sim e^{a_n} ,"I recall a question where it was proved that $$\lim_{n\to\infty}e^{-n}\sum_{k=0}^n\frac{n^k}{k!}=\frac12.$$This seems to remain true when $n$ is replaced by $n+c $ where $c$ is some constant, while apparently, if $a_n=o(n)$, $$\sum_{k=0}^n\frac{a_n^k}{k!}\sim e^{a_n}.$$How to prove it? Maybe the method used in the related question is also useful here, but I couldn't find it","I recall a question where it was proved that $$\lim_{n\to\infty}e^{-n}\sum_{k=0}^n\frac{n^k}{k!}=\frac12.$$This seems to remain true when $n$ is replaced by $n+c $ where $c$ is some constant, while apparently, if $a_n=o(n)$, $$\sum_{k=0}^n\frac{a_n^k}{k!}\sim e^{a_n}.$$How to prove it? Maybe the method used in the related question is also useful here, but I couldn't find it",,"['calculus', 'real-analysis', 'sequences-and-series', 'limits', 'asymptotics']"
98,Convergent sequence in Hilbert space,Convergent sequence in Hilbert space,,"Let $H$ be a Hilbert space with orthonormal basis $(e_n)_n$ and $(a_n)_n \in \ell^2(\mathbb{N})$, so $$\sum_{n=0}^{\infty} |a_n|^2 < \infty$$ Now, define the sequence $(\xi_n)_n$ in $H$ as $$\xi_n= \sum_{k=0}^{n} a_ke_k $$ I now have to proof that this sequence is convergent in $H$ or, if not, give a counterexample. I think that it's true because $a_n \to 0$ when $n \to \infty$ but I don't know how I can proof this.","Let $H$ be a Hilbert space with orthonormal basis $(e_n)_n$ and $(a_n)_n \in \ell^2(\mathbb{N})$, so $$\sum_{n=0}^{\infty} |a_n|^2 < \infty$$ Now, define the sequence $(\xi_n)_n$ in $H$ as $$\xi_n= \sum_{k=0}^{n} a_ke_k $$ I now have to proof that this sequence is convergent in $H$ or, if not, give a counterexample. I think that it's true because $a_n \to 0$ when $n \to \infty$ but I don't know how I can proof this.",,"['sequences-and-series', 'convergence-divergence', 'hilbert-spaces']"
99,Double fractional part integral,Double fractional part integral,,"Let $\{\}$ denote the fractional part, does the following integral have a closed form ?  $$\int_{0}^{1}\int_{0}^{1}\bigg\{\frac{1}{x\,y}\bigg\}^2dx\,dy$$","Let $\{\}$ denote the fractional part, does the following integral have a closed form ?  $$\int_{0}^{1}\int_{0}^{1}\bigg\{\frac{1}{x\,y}\bigg\}^2dx\,dy$$",,"['integration', 'sequences-and-series', 'definite-integrals', 'fractional-part']"
