,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Computing eigenfunction of expectational operator,Computing eigenfunction of expectational operator,,"Let $A$ be an operator from $\textbf{L}^2$ to itself defined by $$Af(x) = \mathbb{E}[e^{-W \gamma}\cdot f(x\cdot e^W)]$$ where $W$ is a $\mathbb{N}(0,1)$ distributed random variable and $\gamma \in [3,10]$ is a parameter.  I believe there is no analytical method to compute the principal eigenfunction and eigenvalue of this operator. By principal eigenfunction, I mean the positive function $f(x)$ such that $$Af(x) = \kappa f(x)$$ $\forall x \in \mathbb{R}$. What kind of numerical methods are used for problems of this sort? Also, if anyone can recommend some textbook covering this kind of problems that would be amazing. Thank you! Edit: the source for this kind of problem is an Economics publication on long run risk exposure (Hansen and Scheinkman (2009)) Edit2: Uranix gave great tips to approach this specific problem but also made me realize that there is not much hope of solving this analytically in general (when the factor multiplying $f(x\cdot e^W)$ is a general function of $W$). Does anyone know which numerical techniques can be used in this context?","Let $A$ be an operator from $\textbf{L}^2$ to itself defined by $$Af(x) = \mathbb{E}[e^{-W \gamma}\cdot f(x\cdot e^W)]$$ where $W$ is a $\mathbb{N}(0,1)$ distributed random variable and $\gamma \in [3,10]$ is a parameter.  I believe there is no analytical method to compute the principal eigenfunction and eigenvalue of this operator. By principal eigenfunction, I mean the positive function $f(x)$ such that $$Af(x) = \kappa f(x)$$ $\forall x \in \mathbb{R}$. What kind of numerical methods are used for problems of this sort? Also, if anyone can recommend some textbook covering this kind of problems that would be amazing. Thank you! Edit: the source for this kind of problem is an Economics publication on long run risk exposure (Hansen and Scheinkman (2009)) Edit2: Uranix gave great tips to approach this specific problem but also made me realize that there is not much hope of solving this analytically in general (when the factor multiplying $f(x\cdot e^W)$ is a general function of $W$). Does anyone know which numerical techniques can be used in this context?",,"['functional-analysis', 'numerical-methods', 'operator-theory', 'eigenfunctions']"
1,L^1 convergence and limsup of convergent sequence,L^1 convergence and limsup of convergent sequence,,"I have to solve this exercise: let $f_n$ be a sequence of positive real function defined on a measure space $(X,M,\mu)$ such that $f_n\in L^1(\mu)$ $\forall n\in \mathbb{N}$ and $f_n$ is convergent in $L^1$-norm. Is it true that $\limsup_{n\to\infty}f_n$ is a.e. finite? If so, does it have to be Lebesgue-integrable? I know that if $f_n\to f\in L^1(\mu)$ in $L^1$-norm there exists a subsequence $f_{n_k}$ pointwise convergent to the $L^1$-limit of $f_n$, but this does not exclude the existence of a divergent subsequence on a positive measure set, even if I think that the answer to the first question is yes. How can I prove it? I thought about using Reverse Fatou's Lemma but it doesn't seem to help...","I have to solve this exercise: let $f_n$ be a sequence of positive real function defined on a measure space $(X,M,\mu)$ such that $f_n\in L^1(\mu)$ $\forall n\in \mathbb{N}$ and $f_n$ is convergent in $L^1$-norm. Is it true that $\limsup_{n\to\infty}f_n$ is a.e. finite? If so, does it have to be Lebesgue-integrable? I know that if $f_n\to f\in L^1(\mu)$ in $L^1$-norm there exists a subsequence $f_{n_k}$ pointwise convergent to the $L^1$-limit of $f_n$, but this does not exclude the existence of a divergent subsequence on a positive measure set, even if I think that the answer to the first question is yes. How can I prove it? I thought about using Reverse Fatou's Lemma but it doesn't seem to help...",,"['integration', 'functional-analysis', 'measure-theory', 'lp-spaces', 'limsup-and-liminf']"
2,"Find all $\alpha$ such that $n^\alpha\chi_{[n,n+1]}$ converges weakly to 0 in $L^p$.",Find all  such that  converges weakly to 0 in .,"\alpha n^\alpha\chi_{[n,n+1]} L^p","Edit: $1 < p < \infty$ Let $f_n(x) = n^\alpha \chi_{[n,n+1]}.$ Then $$ \begin{align} \left|\int_{-\infty}^{\infty} n^\alpha \chi_{[n,n+1]}g(x)dx\right| &\le n^\alpha \lvert\lvert\chi_{[n,n+1]}g(x)\rvert\rvert_1\\ &\le n^\alpha \lvert\lvert\chi_{[n,n+1]}\rvert\rvert_p \lvert\lvert g(x)\rvert\rvert_q\\ &= n^\alpha \lvert\lvert g(x)\rvert\rvert_q \end{align} $$ which goes to 0 if $\alpha < 0$. Suppose $\alpha \ge 0$ and let $g(x) = \chi_{[n,n+1]}$. Then $g\in L^q$, and $$\left|\int_{-\infty}^{\infty} n^\alpha \chi_{[n,n+1]}g(x)dx\right| = n^\alpha \to \infty.$$ Did I miss anything here? Thanks.","Edit: $1 < p < \infty$ Let $f_n(x) = n^\alpha \chi_{[n,n+1]}.$ Then $$ \begin{align} \left|\int_{-\infty}^{\infty} n^\alpha \chi_{[n,n+1]}g(x)dx\right| &\le n^\alpha \lvert\lvert\chi_{[n,n+1]}g(x)\rvert\rvert_1\\ &\le n^\alpha \lvert\lvert\chi_{[n,n+1]}\rvert\rvert_p \lvert\lvert g(x)\rvert\rvert_q\\ &= n^\alpha \lvert\lvert g(x)\rvert\rvert_q \end{align} $$ which goes to 0 if $\alpha < 0$. Suppose $\alpha \ge 0$ and let $g(x) = \chi_{[n,n+1]}$. Then $g\in L^q$, and $$\left|\int_{-\infty}^{\infty} n^\alpha \chi_{[n,n+1]}g(x)dx\right| = n^\alpha \to \infty.$$ Did I miss anything here? Thanks.",,"['real-analysis', 'functional-analysis', 'proof-verification', 'lp-spaces', 'weak-convergence']"
3,Stone-Weierstrass theorem of $\mathbb{S}^2$,Stone-Weierstrass theorem of,\mathbb{S}^2,Someone told me that every continuous function on $\mathbb{S}^2$ could be expressed as a uniform limit of restrictions to $\mathbb{S}^2$ of polynomials. Does this result come from the Stone-Weierstrass theorem? Could anyone be able to explain to me what it means formally? Thanks for your help!,Someone told me that every continuous function on $\mathbb{S}^2$ could be expressed as a uniform limit of restrictions to $\mathbb{S}^2$ of polynomials. Does this result come from the Stone-Weierstrass theorem? Could anyone be able to explain to me what it means formally? Thanks for your help!,,[]
4,the proof of variational principal for the principal eigenvalue (checking orthonormal subset),the proof of variational principal for the principal eigenvalue (checking orthonormal subset),,"Hi I am looking at part 3 of the proof in Evans Chapter 6.  I have difficulty understanding  ""Furthermore from (6) and (7) we see that $(\lambda_k^{-1/2} w_k)$ is an orthonormal subset of $H_0^1(U)$. It is known, from the previous results of the chapter, $(w_k)_{k=1}^{\infty}$ is an orthonormal basis of $L^2(U)$, $w_k\in H_0^1(U)$ is an eigenfunction corresponding to $\lambda_k.$ The bilinear form is defined as  $$ B[u,v]:=\int_{U} a^{ij} D^j u D^i v+b^i D^i u v+cuv .$$ Given $u$ is a weak solution, the following also holds for the eigenvalue problem $$ B[u,v]=(\lambda u,v)\,\,\,\forall\,\,\,v\in H_0^1(U)$$ I understand this is really a matter of checking definition. My confusions two-fold. I do not see, by diving $w_k$ by $\lambda_k^{1/2},$ 1) Why we get an orthonormal subset? This means?? 2) Why this orthonormal subset is in $H_0^1(U)?$ Now the most important questions of mine. A . It is true that $(w_k)_{k=1}^{\infty}$ forms an orthogonal basis of $H_0^1(U)$, in view of the Galerkin approximation of weak solutions in Chapt 7. How to verify this? B . In view of the proof below, $(w_k)_{k=1}^{\infty}$ cannot be orthonormal basis of $H_0^1(U).$ (Though the scaled version does.) Can someone give a proof, perhaps a contradictory argument? I am looking for a proof that make use of the definition of $H_0^1$ inner product and integration by parts, rather than inferring from (6) and (7).","Hi I am looking at part 3 of the proof in Evans Chapter 6.  I have difficulty understanding  ""Furthermore from (6) and (7) we see that $(\lambda_k^{-1/2} w_k)$ is an orthonormal subset of $H_0^1(U)$. It is known, from the previous results of the chapter, $(w_k)_{k=1}^{\infty}$ is an orthonormal basis of $L^2(U)$, $w_k\in H_0^1(U)$ is an eigenfunction corresponding to $\lambda_k.$ The bilinear form is defined as  $$ B[u,v]:=\int_{U} a^{ij} D^j u D^i v+b^i D^i u v+cuv .$$ Given $u$ is a weak solution, the following also holds for the eigenvalue problem $$ B[u,v]=(\lambda u,v)\,\,\,\forall\,\,\,v\in H_0^1(U)$$ I understand this is really a matter of checking definition. My confusions two-fold. I do not see, by diving $w_k$ by $\lambda_k^{1/2},$ 1) Why we get an orthonormal subset? This means?? 2) Why this orthonormal subset is in $H_0^1(U)?$ Now the most important questions of mine. A . It is true that $(w_k)_{k=1}^{\infty}$ forms an orthogonal basis of $H_0^1(U)$, in view of the Galerkin approximation of weak solutions in Chapt 7. How to verify this? B . In view of the proof below, $(w_k)_{k=1}^{\infty}$ cannot be orthonormal basis of $H_0^1(U).$ (Though the scaled version does.) Can someone give a proof, perhaps a contradictory argument? I am looking for a proof that make use of the definition of $H_0^1$ inner product and integration by parts, rather than inferring from (6) and (7).",,"['linear-algebra', 'functional-analysis', 'partial-differential-equations', 'orthonormal', 'regularity-theory-of-pdes']"
5,About equivalent norms on a vector space,About equivalent norms on a vector space,,"Definition. A norm $\|\cdot\|$ in a vector space $X$ is said to be equivalent to a norm $\|\cdot\|_0$ on $X$ if there are positive numbers $a$ and $b$ such that for all $x \in X$ we have $$ a\| x \|_0 \leq \|x\| \leq b\|x\|_0 $$ My question . If two norms $\|\cdot\|$ and $\|\cdot\|_{0}$ on a vector space $X$ are equivalent, then $\|x_{n} - x\| \rightarrow 0$ if and only if $\|x_n - x\|_0 \rightarrow 0$. I know that two equivalents norms induce same the topology. How can I use it to prove the sentence. Ref: (Kreyszig) Introductory Functional Analysis with Applications.","Definition. A norm $\|\cdot\|$ in a vector space $X$ is said to be equivalent to a norm $\|\cdot\|_0$ on $X$ if there are positive numbers $a$ and $b$ such that for all $x \in X$ we have $$ a\| x \|_0 \leq \|x\| \leq b\|x\|_0 $$ My question . If two norms $\|\cdot\|$ and $\|\cdot\|_{0}$ on a vector space $X$ are equivalent, then $\|x_{n} - x\| \rightarrow 0$ if and only if $\|x_n - x\|_0 \rightarrow 0$. I know that two equivalents norms induce same the topology. How can I use it to prove the sentence. Ref: (Kreyszig) Introductory Functional Analysis with Applications.",,['functional-analysis']
6,Proving linearity of an operator using boundedness.,Proving linearity of an operator using boundedness.,,"I am considering an operator $K\colon \ell^2 \to \ell^2$ given by $$Kx = \sum_{n=1}^\infty e^{-n} \langle x , e_n\rangle e_n $$ where $e_n = (\delta_{k,n})_{k\in \mathrm{N}}$ is the standard basis on the sequence space $\ell^2$ and $ \langle \cdot , \cdot \rangle$ denotes the usual inner product. I know that this operator is bounded with $ \Vert K \Vert = e^{-1}$. Now my textbook tells me that linearity of $K$ is easily shown using boundedness, yet I am not  sure whether boundedness is strictly necessary to prove this.  \begin{align*} K(x+y) &= \sum_{n=1}^\infty e^{-n} \langle x + y, e_n\rangle e_n\\ &= \sum_{n=1}^\infty e^{-n} (\langle x, e_n\rangle + \langle y, e_n\rangle) e_n\\ &= \sum_{n=1}^\infty e^{-n} \langle x, e_n\rangle e_n + \sum_{n=1}^\infty e^{-n} \langle y, e_n\rangle e_n \quad (*)\\ &= Kx + Ky. \end{align*} I suspect boundedness is used in $(*)$, so making it more precise I get  $$ \left\Vert \sum_{n=1}^N e^{-n} \langle x + y, e_n\rangle e_n - Kx - Ky \right\Vert \leq \left\Vert \sum_{n=N+1}^\infty e^{-n} \langle x, e_n\rangle e_n \right\Vert + \left\Vert \sum_{n=N+1}^\infty e^{-n} \langle y, e_n\rangle e_n \right\Vert$$ by the triangle inequality. Now boundedness of $K$ shows that the right hand side converges to zero as $N \to \infty$. It seems to me that boundedness is unnecessary here, and that the only thing needed is that $Kx \in \ell^2$ for all $x \in\ell^2$. Is this correct? If so, I have a follow-up question: are there examples of unbounded operators where the above argument may be used to prove linearity? I was thinking of the defining $Tx = \sum_{n=1}^\infty n \langle x , e_n \rangle e_n$ as an example of such an operator, but I am not sure if this operator is well-defined on $\ell^2$","I am considering an operator $K\colon \ell^2 \to \ell^2$ given by $$Kx = \sum_{n=1}^\infty e^{-n} \langle x , e_n\rangle e_n $$ where $e_n = (\delta_{k,n})_{k\in \mathrm{N}}$ is the standard basis on the sequence space $\ell^2$ and $ \langle \cdot , \cdot \rangle$ denotes the usual inner product. I know that this operator is bounded with $ \Vert K \Vert = e^{-1}$. Now my textbook tells me that linearity of $K$ is easily shown using boundedness, yet I am not  sure whether boundedness is strictly necessary to prove this.  \begin{align*} K(x+y) &= \sum_{n=1}^\infty e^{-n} \langle x + y, e_n\rangle e_n\\ &= \sum_{n=1}^\infty e^{-n} (\langle x, e_n\rangle + \langle y, e_n\rangle) e_n\\ &= \sum_{n=1}^\infty e^{-n} \langle x, e_n\rangle e_n + \sum_{n=1}^\infty e^{-n} \langle y, e_n\rangle e_n \quad (*)\\ &= Kx + Ky. \end{align*} I suspect boundedness is used in $(*)$, so making it more precise I get  $$ \left\Vert \sum_{n=1}^N e^{-n} \langle x + y, e_n\rangle e_n - Kx - Ky \right\Vert \leq \left\Vert \sum_{n=N+1}^\infty e^{-n} \langle x, e_n\rangle e_n \right\Vert + \left\Vert \sum_{n=N+1}^\infty e^{-n} \langle y, e_n\rangle e_n \right\Vert$$ by the triangle inequality. Now boundedness of $K$ shows that the right hand side converges to zero as $N \to \infty$. It seems to me that boundedness is unnecessary here, and that the only thing needed is that $Kx \in \ell^2$ for all $x \in\ell^2$. Is this correct? If so, I have a follow-up question: are there examples of unbounded operators where the above argument may be used to prove linearity? I was thinking of the defining $Tx = \sum_{n=1}^\infty n \langle x , e_n \rangle e_n$ as an example of such an operator, but I am not sure if this operator is well-defined on $\ell^2$",,['functional-analysis']
7,Prove that $f\in L^2$ and $\lim_{n\rightarrow\infty} \int_A f_n = \int_Af$,Prove that  and,f\in L^2 \lim_{n\rightarrow\infty} \int_A f_n = \int_Af,"Let $A$ be a bounded, measurable susbset of $\mathbb{R}$. Prove that if $(f_n) \subset L^2 (A)$ converges uniformly to $f$ on $A$, then $f\in L^2(A)$ and $\lim_{n\rightarrow\infty} \int_A f_n = \int_Af$. Clearly $f$ is measurable. We have to show that $\int_A f^2 < \infty$. Choose $\epsilon>0$. From uniform convergence we can find $N\in\mathbb{N}$ such that $|f_{n_0}(x)-f(x)|<\epsilon$ for all $x\in A$ and some $n_0>N$. Now denote by $A^-$ the part of $A$ where $f$ is negative and by $A^+$ the part of $A$ where $f$ is positive. Since $f$ is measurable, both sets are measurable. We have $-f(x)<\epsilon - f_{n_0}(x)$ thus $\int_{A^-} f^2< \int_{A^{-}}(\epsilon-f_{n_0})^2<\infty$ (since A is bounded). Similarly, since $f(x)<\epsilon + f_{n_0}(x)$, we get $\int_{A^+} f^2< \int_{A^{+}}(\epsilon+f_{n_0})^2<\infty$ and we can conclude that $f\in L^2 (A)$. It remains to show that $\lim_{n\rightarrow\infty} \int_A f_n = \int_Af$. First we establish convergence in $L^2$ on $A$: $$\|f_n-f\|_2^2=\int_A |f_n(x)-f(x)|^2\,dx \leq m(A) \left(\sup_{x \in A}|f_n(x)-f(x)|\right)^2 \to 0$$ Now we can use CS inequality and conclude that $\lim_{n\rightarrow\infty} \int_A f_n = \int_Af$. Is my derivation correct?","Let $A$ be a bounded, measurable susbset of $\mathbb{R}$. Prove that if $(f_n) \subset L^2 (A)$ converges uniformly to $f$ on $A$, then $f\in L^2(A)$ and $\lim_{n\rightarrow\infty} \int_A f_n = \int_Af$. Clearly $f$ is measurable. We have to show that $\int_A f^2 < \infty$. Choose $\epsilon>0$. From uniform convergence we can find $N\in\mathbb{N}$ such that $|f_{n_0}(x)-f(x)|<\epsilon$ for all $x\in A$ and some $n_0>N$. Now denote by $A^-$ the part of $A$ where $f$ is negative and by $A^+$ the part of $A$ where $f$ is positive. Since $f$ is measurable, both sets are measurable. We have $-f(x)<\epsilon - f_{n_0}(x)$ thus $\int_{A^-} f^2< \int_{A^{-}}(\epsilon-f_{n_0})^2<\infty$ (since A is bounded). Similarly, since $f(x)<\epsilon + f_{n_0}(x)$, we get $\int_{A^+} f^2< \int_{A^{+}}(\epsilon+f_{n_0})^2<\infty$ and we can conclude that $f\in L^2 (A)$. It remains to show that $\lim_{n\rightarrow\infty} \int_A f_n = \int_Af$. First we establish convergence in $L^2$ on $A$: $$\|f_n-f\|_2^2=\int_A |f_n(x)-f(x)|^2\,dx \leq m(A) \left(\sup_{x \in A}|f_n(x)-f(x)|\right)^2 \to 0$$ Now we can use CS inequality and conclude that $\lim_{n\rightarrow\infty} \int_A f_n = \int_Af$. Is my derivation correct?",,"['functional-analysis', 'lebesgue-integral', 'lebesgue-measure']"
8,"What's an example of a function in $L^1(0,1)$ but not $L^p(0,1)$ for $p>1$?",What's an example of a function in  but not  for ?,"L^1(0,1) L^p(0,1) p>1","What's an example of a function in $L^1(0,1)$ but not $L^p(0,1)$ for $p>1$? I've seen this answer but this is on an infinite domain. I'm interested only in $(0,1)$. I tried playing around with $\int_0^1 \frac{1}{x^a\log^b(x)}dx$ but haven't found success. I was trying to think of some transformation of the given answer to the domain $(0,1)$ but it can get messy. If possible, I would prefer a hint to an outright answer.","What's an example of a function in $L^1(0,1)$ but not $L^p(0,1)$ for $p>1$? I've seen this answer but this is on an infinite domain. I'm interested only in $(0,1)$. I tried playing around with $\int_0^1 \frac{1}{x^a\log^b(x)}dx$ but haven't found success. I was trying to think of some transformation of the given answer to the domain $(0,1)$ but it can get messy. If possible, I would prefer a hint to an outright answer.",,['functional-analysis']
9,"Is $C^\omega([0,1])$ normable? (And about the growth of coefficients of infinitely differentiable functions)",Is  normable? (And about the growth of coefficients of infinitely differentiable functions),"C^\omega([0,1])","This question arised to me when trying to prove that the space of infinitely differentiable functions defined in a compact space $K\subset\mathbb{C}$ taking values in $\mathbb{C}$, that is $C^\infty(K)$, is a Banach space. It is well known that $C^n(K)$ (the space of n-times continuously diferentiable functions) is a Banach space with the norm $$||f||:=||f||_\infty+...+||f^{n)}||_\infty$$ When I try to define an analogous norm for $C^\infty(K)$, I have the problem that I dont know how fast is allowed to grow the sequence $$(||f^{n)}||_\infty)_n$$ I've read from several sources that $C^\infty(K)$ is a Frechet space so I'm guessing that there is no restriction about the growth of that sequence. Its that true? Any help would be appreciated. (Update) [$\approx$ Solved] I've read that the space of analytic functions $C^\omega([0,1])$ is not normable (nor $C^\infty([0,1])$ either then), so my question must have a negative answer: If it were true that $||f^{n)}||_\infty\leq M_n$ for some absolute (i.e. holding for every $f\in C^\omega([0,1])$) sequence $(M_n)_n$ of positive numbers, then we could define $$||f||_\omega:=\sum_{n=0}^\infty2^{-n}\frac{||f^{n)}||_\infty}{M_n}$$ for $f\in C^\omega([0,1])$. It is inmediate to verify that $||\cdot||_\omega$ (would) define a norm over $C^\omega([0,1])$. As this can't happen, there is not such sequence $(M_n)_n$. [I guess that saying that $C^\omega([0,1])$ is not normable means with respect to the topology ""where $f$ and $g$ are close if $f^{n)}$ and $g^{n)}$ are close for every $n\geq0$"". That is, with respect to the topology $\tau$ generated by $\{B(\varepsilon,f)\}_{\varepsilon>0,f\in C^\omega([0,1])}$, where $B(\varepsilon,f)=\{g\in C^\omega([0,1]):||g^{n)}-f^{n)}||_\infty<\varepsilon\ \forall n\geq0\}$] As proving that $C^\omega([0,1])$ is  not normable with respect to $\tau$ is the only remaining question, I've changed the tittle. Again, any help would be appreciated :)","This question arised to me when trying to prove that the space of infinitely differentiable functions defined in a compact space $K\subset\mathbb{C}$ taking values in $\mathbb{C}$, that is $C^\infty(K)$, is a Banach space. It is well known that $C^n(K)$ (the space of n-times continuously diferentiable functions) is a Banach space with the norm $$||f||:=||f||_\infty+...+||f^{n)}||_\infty$$ When I try to define an analogous norm for $C^\infty(K)$, I have the problem that I dont know how fast is allowed to grow the sequence $$(||f^{n)}||_\infty)_n$$ I've read from several sources that $C^\infty(K)$ is a Frechet space so I'm guessing that there is no restriction about the growth of that sequence. Its that true? Any help would be appreciated. (Update) [$\approx$ Solved] I've read that the space of analytic functions $C^\omega([0,1])$ is not normable (nor $C^\infty([0,1])$ either then), so my question must have a negative answer: If it were true that $||f^{n)}||_\infty\leq M_n$ for some absolute (i.e. holding for every $f\in C^\omega([0,1])$) sequence $(M_n)_n$ of positive numbers, then we could define $$||f||_\omega:=\sum_{n=0}^\infty2^{-n}\frac{||f^{n)}||_\infty}{M_n}$$ for $f\in C^\omega([0,1])$. It is inmediate to verify that $||\cdot||_\omega$ (would) define a norm over $C^\omega([0,1])$. As this can't happen, there is not such sequence $(M_n)_n$. [I guess that saying that $C^\omega([0,1])$ is not normable means with respect to the topology ""where $f$ and $g$ are close if $f^{n)}$ and $g^{n)}$ are close for every $n\geq0$"". That is, with respect to the topology $\tau$ generated by $\{B(\varepsilon,f)\}_{\varepsilon>0,f\in C^\omega([0,1])}$, where $B(\varepsilon,f)=\{g\in C^\omega([0,1]):||g^{n)}-f^{n)}||_\infty<\varepsilon\ \forall n\geq0\}$] As proving that $C^\omega([0,1])$ is  not normable with respect to $\tau$ is the only remaining question, I've changed the tittle. Again, any help would be appreciated :)",,['functional-analysis']
10,To Show Closedness of a Graph in an Application of Closed Graph Theorem,To Show Closedness of a Graph in an Application of Closed Graph Theorem,,"Here's an old exam question I am struggling with: Let E be a Banach space and $ (x_n)_{n \in N} \subset E $ such that $  \sum_{n=1} ^{\infty} | \langle x_n , x^* \rangle |  < \infty $ for all   continuous linear functionals $ x^* \in E^* $. Show that then there exists a constant $ C < \infty $ such that $$  \sum_{n=1} ^{\infty} | \langle x_n , x^* \rangle |  \leq C||x^*|| .$$ What I know is that I should show that the graph of a linear map $ T: E^* \rightarrow l^1 $ is closed and then the continuity of $ T $ would follow from the closed graph theorem. But the problem here is that I don't have any idea where to start showing closedness of the graph.","Here's an old exam question I am struggling with: Let E be a Banach space and $ (x_n)_{n \in N} \subset E $ such that $  \sum_{n=1} ^{\infty} | \langle x_n , x^* \rangle |  < \infty $ for all   continuous linear functionals $ x^* \in E^* $. Show that then there exists a constant $ C < \infty $ such that $$  \sum_{n=1} ^{\infty} | \langle x_n , x^* \rangle |  \leq C||x^*|| .$$ What I know is that I should show that the graph of a linear map $ T: E^* \rightarrow l^1 $ is closed and then the continuity of $ T $ would follow from the closed graph theorem. But the problem here is that I don't have any idea where to start showing closedness of the graph.",,['functional-analysis']
11,Applying equivalence of norms on $\mathbb R^n$ .,Applying equivalence of norms on  .,\mathbb R^n,"Let $\|\cdot\|$ be any norm on $\mathbb R^n$. Prove that a sequance on $\mathbb R^n$ converges  to an element $x \in \mathbb R^n$ under the $\|\cdot\|_2$ norm if and only if the sequance converges to $x$ under the $\|\cdot\|$ norm. I want to say that $c\|\cdot\| \leq \|\cdot\|_2 \leq d\|\cdot\|$ given $c,d \in \mathbb R$ since $\mathbb R^n$ is a closed space and than to show c=d. is that a correct way? how can i show d=c?","Let $\|\cdot\|$ be any norm on $\mathbb R^n$. Prove that a sequance on $\mathbb R^n$ converges  to an element $x \in \mathbb R^n$ under the $\|\cdot\|_2$ norm if and only if the sequance converges to $x$ under the $\|\cdot\|$ norm. I want to say that $c\|\cdot\| \leq \|\cdot\|_2 \leq d\|\cdot\|$ given $c,d \in \mathbb R$ since $\mathbb R^n$ is a closed space and than to show c=d. is that a correct way? how can i show d=c?",,"['functional-analysis', 'notation', 'normed-spaces']"
12,"isomorphism between $C[0,1]$ and $C^1[0,1]$",isomorphism between  and,"C[0,1] C^1[0,1]","Is space $C[0,1]$ with norm $\parallel f \parallel=\max|f(x)|$ (space of continuous functions on $[0,1]$) isomorphic to space $C^1[0,1]$ with norm $\parallel f \parallel=\max|f(x)|+\max|f'(x)|$ (space of continuously differentiable functions on $[0,1]$) ? Under isomorphism I mean continuous linear bijective operator between these two spaces (and also the inverse is continuous). If yes, is there any explicit example of such isomorphism ? Thank you very much for Your answers.","Is space $C[0,1]$ with norm $\parallel f \parallel=\max|f(x)|$ (space of continuous functions on $[0,1]$) isomorphic to space $C^1[0,1]$ with norm $\parallel f \parallel=\max|f(x)|+\max|f'(x)|$ (space of continuously differentiable functions on $[0,1]$) ? Under isomorphism I mean continuous linear bijective operator between these two spaces (and also the inverse is continuous). If yes, is there any explicit example of such isomorphism ? Thank you very much for Your answers.",,"['functional-analysis', 'banach-spaces']"
13,Intuition behind Contraction Mapping Theorem,Intuition behind Contraction Mapping Theorem,,"I understand that this theorem works for complete metric spaces, but I have been studying this purely for normed vector spaces. I want to check my heuristic understanding of the theorem and proof: Statement of theorem: Let $(V, ||.||)$ be a complete normed vector space and $U \subset V$ a closed subset of the space. Let $f: U \rightarrow U$ be a contraction mapping such that $\exists K \in (0,1)$ such that $\forall u, v \in V, ||f(u) - f(v)|| \leq K||u-v||$ . Then there is a unique $w \in U$ such that $f(w) = w$ The proof constructs a sequence by taking any $u_0 \in U$ and doing $f(u_n) = u_{n+1}$. My understanding: Since $K <1$ and we are mapping each time between $U$, we are mapping a 'smaller' and 'smaller' such that eventually $f(u_n)$ will just map to itself thus reaching a fixed point. And this limit exists because this sequence $u_n$ is Cauchy and in a Banach space all Cauchy sequences will converge to some limit. My questions Why are we free to take any $u_0 \in U$? Does our choice of $u_0$ affect the convergence rate? Why is it necessarily the case that the limit is unique? And how is this affected by the map $f?$ Does the theorem still apply for $K =1?$ What applications are there to this theorem?","I understand that this theorem works for complete metric spaces, but I have been studying this purely for normed vector spaces. I want to check my heuristic understanding of the theorem and proof: Statement of theorem: Let $(V, ||.||)$ be a complete normed vector space and $U \subset V$ a closed subset of the space. Let $f: U \rightarrow U$ be a contraction mapping such that $\exists K \in (0,1)$ such that $\forall u, v \in V, ||f(u) - f(v)|| \leq K||u-v||$ . Then there is a unique $w \in U$ such that $f(w) = w$ The proof constructs a sequence by taking any $u_0 \in U$ and doing $f(u_n) = u_{n+1}$. My understanding: Since $K <1$ and we are mapping each time between $U$, we are mapping a 'smaller' and 'smaller' such that eventually $f(u_n)$ will just map to itself thus reaching a fixed point. And this limit exists because this sequence $u_n$ is Cauchy and in a Banach space all Cauchy sequences will converge to some limit. My questions Why are we free to take any $u_0 \in U$? Does our choice of $u_0$ affect the convergence rate? Why is it necessarily the case that the limit is unique? And how is this affected by the map $f?$ Does the theorem still apply for $K =1?$ What applications are there to this theorem?",,"['analysis', 'functional-analysis']"
14,$fg\in L^1$ for every $g\in L^1$ prove $f\in L^{\infty}$,for every  prove,fg\in L^1 g\in L^1 f\in L^{\infty},"Let $(X,\mathcal{A}, \mu)$ be an arbitrary measure space. Let $f$ be an extended complex-valued $\mathcal{A}-$measurable function on $X$ such that $|f|<\infty$ $\mu$-a.e. on $X$. Suppose that $fg\in L^1(X,\mathcal{A}, \mu)$ for every $g\in L^1(X,\mathcal{A}, \mu)$. Show that $f\in L^{\infty}(X,\mathcal{A}, \mu)$. Can anyone verify my answer? Does anyone know a better elementary approach? (It'll be great if similar approach can be generalized to the case of $L^p$ and $L^q$) Related question: On $\sigma-$ finite space $fg\in L^1$ for every $g\in L^q$ prove $f\in L^p$ My answer: For any given $f\notin L^{\infty}$, define $E_n=\{x\in X|n-1<f(x)\leq n\}$, there is a subsequence $E_{n_1}$,...$E_{n_j}$ such that $\mu(E_{n_j})>0$ for each $j$. Define $\displaystyle g=\sum_{j=1}^{\infty}\frac{1}{j^2\mu(E_{n_j})}\mathbb{1}_{E_{n_j}}$, we have $\displaystyle \int_{X}|g|d\mu=\sum_{j=1}^{\infty}\frac{1}{j^2}<\infty$ so $g\in L^1$. However $$\int_{X}|fg|d\mu=\int_{X} \sum_{j=1}^{\infty} \frac{|f|\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}$$ because $f$ is finite almost everywhere and the last expression $$\int_{X} \sum_{j=1}^{\infty} \frac{|f|\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}>\int_{X} \sum_{j=1}^{\infty} \frac{(n_j-1)\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}>\int_{X} \sum_{j=1}^{\infty} \frac{(j-1)\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}=\sum_{j=1}^{\infty}\frac{j-1}{j^2}=\infty$$ by limit comparison with harmonic series. Therefore $fg\notin L^1$","Let $(X,\mathcal{A}, \mu)$ be an arbitrary measure space. Let $f$ be an extended complex-valued $\mathcal{A}-$measurable function on $X$ such that $|f|<\infty$ $\mu$-a.e. on $X$. Suppose that $fg\in L^1(X,\mathcal{A}, \mu)$ for every $g\in L^1(X,\mathcal{A}, \mu)$. Show that $f\in L^{\infty}(X,\mathcal{A}, \mu)$. Can anyone verify my answer? Does anyone know a better elementary approach? (It'll be great if similar approach can be generalized to the case of $L^p$ and $L^q$) Related question: On $\sigma-$ finite space $fg\in L^1$ for every $g\in L^q$ prove $f\in L^p$ My answer: For any given $f\notin L^{\infty}$, define $E_n=\{x\in X|n-1<f(x)\leq n\}$, there is a subsequence $E_{n_1}$,...$E_{n_j}$ such that $\mu(E_{n_j})>0$ for each $j$. Define $\displaystyle g=\sum_{j=1}^{\infty}\frac{1}{j^2\mu(E_{n_j})}\mathbb{1}_{E_{n_j}}$, we have $\displaystyle \int_{X}|g|d\mu=\sum_{j=1}^{\infty}\frac{1}{j^2}<\infty$ so $g\in L^1$. However $$\int_{X}|fg|d\mu=\int_{X} \sum_{j=1}^{\infty} \frac{|f|\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}$$ because $f$ is finite almost everywhere and the last expression $$\int_{X} \sum_{j=1}^{\infty} \frac{|f|\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}>\int_{X} \sum_{j=1}^{\infty} \frac{(n_j-1)\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}>\int_{X} \sum_{j=1}^{\infty} \frac{(j-1)\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}=\sum_{j=1}^{\infty}\frac{j-1}{j^2}=\infty$$ by limit comparison with harmonic series. Therefore $fg\notin L^1$",,"['real-analysis', 'functional-analysis']"
15,Nonlinear elliptic PDE - passing to the limit,Nonlinear elliptic PDE - passing to the limit,,"In the notes I am trying to follow one can find the following argument (part of a longer proof on existence of a weak solution to a certain type of nonlinear elliptic pde): Let $V = H^1_0(\Omega)$ and  consider $(u_m) \subset V$ such that $||u_m||_V \leq C$ for all m. It follows that (after some abuse in labelling) $u_{m_k} \to u$ weakly in V, $u_{m_k} \to u$ in $L^2(\Omega)$ and $u_{m_k} \to u$ a.e. in $\Omega$. Furthermore, let $v \in V$ with $v_m \to v$ in $V$. Finally, $a(x,u)$ is a Caratheodory function (so in particular continuous w.r.t to the second variable) with uniform bounds $A_1 \leq a \leq A_2$. Then, apparently, we use Dominated Convergence Theorem (DCT) to conclude that  $$ a(\cdot,u_{m_k})\nabla v_{m_k} \to a(\cdot,u)\nabla v \text{ in } L^2(\Omega), $$ which also apparently allows us to conclude that $$ \int_{\Omega} a(x,u_{m_k})\nabla u_{m_k} \cdot \nabla v_{m_k} \to \int_{\Omega} a(x,u)\nabla u \cdot \nabla v. $$ First of all, I reckon that in the first line there is a typo and we have $u_{m_k}$ instead of $v_{m_k}$, as the way it is I suppose we do not need DCT to show $L^2$ convergence (adding zero cleverly seems to be enough). If there indeed is a typo there, then how can we apply DCT? In its form stated in the notes, we would need a.e. convergence of LHS to RHS but for that we would need a.e. convergence of $\nabla u_{m_k}$ - does it follow from a.e. convergence of $u_{m_k}$? If there is no typo, then how can we go from first line to the second? Many thanks for any insight you might have!","In the notes I am trying to follow one can find the following argument (part of a longer proof on existence of a weak solution to a certain type of nonlinear elliptic pde): Let $V = H^1_0(\Omega)$ and  consider $(u_m) \subset V$ such that $||u_m||_V \leq C$ for all m. It follows that (after some abuse in labelling) $u_{m_k} \to u$ weakly in V, $u_{m_k} \to u$ in $L^2(\Omega)$ and $u_{m_k} \to u$ a.e. in $\Omega$. Furthermore, let $v \in V$ with $v_m \to v$ in $V$. Finally, $a(x,u)$ is a Caratheodory function (so in particular continuous w.r.t to the second variable) with uniform bounds $A_1 \leq a \leq A_2$. Then, apparently, we use Dominated Convergence Theorem (DCT) to conclude that  $$ a(\cdot,u_{m_k})\nabla v_{m_k} \to a(\cdot,u)\nabla v \text{ in } L^2(\Omega), $$ which also apparently allows us to conclude that $$ \int_{\Omega} a(x,u_{m_k})\nabla u_{m_k} \cdot \nabla v_{m_k} \to \int_{\Omega} a(x,u)\nabla u \cdot \nabla v. $$ First of all, I reckon that in the first line there is a typo and we have $u_{m_k}$ instead of $v_{m_k}$, as the way it is I suppose we do not need DCT to show $L^2$ convergence (adding zero cleverly seems to be enough). If there indeed is a typo there, then how can we apply DCT? In its form stated in the notes, we would need a.e. convergence of LHS to RHS but for that we would need a.e. convergence of $\nabla u_{m_k}$ - does it follow from a.e. convergence of $u_{m_k}$? If there is no typo, then how can we go from first line to the second? Many thanks for any insight you might have!",,"['real-analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'lp-spaces']"
16,The existence of minimizer in Sobolev space,The existence of minimizer in Sobolev space,,"Let $B\subset \mathbb R^2$ be a unit ball. let $v\in W^{1,2}(B)$ be given. We know that $0\leq v\leq 1$ and it is possible that $v=0$ on some positive $\mathcal L^2$ measurable set in $B$. Let $w\in W^{1,2}(B)$ be given as well. Define $$ \bar u:=\operatorname{argmin}\left\{\int_B|\nabla u|^2v^2,\,u\in W^{1,2}(B),\,\, T[u]=T[w]\right\} $$ where $T$ denote the standard trace operator. My question: do we have $\bar u\in W^{1,2}(B)$ exist? (I do not care about uniqueness)","Let $B\subset \mathbb R^2$ be a unit ball. let $v\in W^{1,2}(B)$ be given. We know that $0\leq v\leq 1$ and it is possible that $v=0$ on some positive $\mathcal L^2$ measurable set in $B$. Let $w\in W^{1,2}(B)$ be given as well. Define $$ \bar u:=\operatorname{argmin}\left\{\int_B|\nabla u|^2v^2,\,u\in W^{1,2}(B),\,\, T[u]=T[w]\right\} $$ where $T$ denote the standard trace operator. My question: do we have $\bar u\in W^{1,2}(B)$ exist? (I do not care about uniqueness)",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
17,Density of sets whose image is dense.,Density of sets whose image is dense.,,"This is probably easy, but I can't think of an answer. Assume $X$ is a Banach space and $A$ is a (not assumed closed) subspace of $X$. Let $T:X \to X$ be a bounded operator, which is also injective. If $T(A)$ is dense in $X$, does it follow that $A$ is dense in $X$?","This is probably easy, but I can't think of an answer. Assume $X$ is a Banach space and $A$ is a (not assumed closed) subspace of $X$. Let $T:X \to X$ be a bounded operator, which is also injective. If $T(A)$ is dense in $X$, does it follow that $A$ is dense in $X$?",,"['functional-analysis', 'operator-theory']"
18,How to find the intersection of level curves?,How to find the intersection of level curves?,,"For two functions $f,g:\mathbb{R}^2\rightarrow\mathbb{R}$, how would I show that the level curves of these two different functions intersect at right angles? I can give the specific functions, but I would like to know in a more general way.","For two functions $f,g:\mathbb{R}^2\rightarrow\mathbb{R}$, how would I show that the level curves of these two different functions intersect at right angles? I can give the specific functions, but I would like to know in a more general way.",,"['real-analysis', 'functional-analysis', 'intersection-theory']"
19,Universal property of topology of uniform convergence,Universal property of topology of uniform convergence,,"What kind of universal property does the strong dual topology on $X'$ have, for $X$ being a locally convex space. Is it possible to define $X'$ as the projective limit of the normed spaces $\mathcal{L}(B,\mathbb{C})$ where $B\in \mathfrak{B}_X$ an element of the directed set of bounded subsets of X? What kind of universal property does the uniform norm have? EDIT: What I actually want to know is, in which sense the (bounded) uniform convergence topologies are categorical EDIT: It is known that there is an adjoint pair of functors $(F,G)$ between the symmetric monoidal categories of locally convex spaces and convex bornological spaces. The latter is closed, i.e. for $X,Y \in \mathsf{cbs}$ there is an internal hom object $[X,Y] \in \mathsf{cbs}$, which is just the set of bounded maps together with the bornology of equibounded sets of linear maps. For $A,B \in \mathsf{lcs}$ we obtain a topological space $G(F(A),F(B))$ and since the adjoint pair is the identity on set level, we have $G(F(A),F(B))=B(A,B)$. Moreover, we know that $\mathcal{L}(A,B) \subseteq B(A,B)$. Thus, we can endow $\mathcal{L}(A,B)$ with the initial topology with respect to this inclusion. My guess is, that this coincides with the bounded uniform convergence topology.","What kind of universal property does the strong dual topology on $X'$ have, for $X$ being a locally convex space. Is it possible to define $X'$ as the projective limit of the normed spaces $\mathcal{L}(B,\mathbb{C})$ where $B\in \mathfrak{B}_X$ an element of the directed set of bounded subsets of X? What kind of universal property does the uniform norm have? EDIT: What I actually want to know is, in which sense the (bounded) uniform convergence topologies are categorical EDIT: It is known that there is an adjoint pair of functors $(F,G)$ between the symmetric monoidal categories of locally convex spaces and convex bornological spaces. The latter is closed, i.e. for $X,Y \in \mathsf{cbs}$ there is an internal hom object $[X,Y] \in \mathsf{cbs}$, which is just the set of bounded maps together with the bornology of equibounded sets of linear maps. For $A,B \in \mathsf{lcs}$ we obtain a topological space $G(F(A),F(B))$ and since the adjoint pair is the identity on set level, we have $G(F(A),F(B))=B(A,B)$. Moreover, we know that $\mathcal{L}(A,B) \subseteq B(A,B)$. Thus, we can endow $\mathcal{L}(A,B)$ with the initial topology with respect to this inclusion. My guess is, that this coincides with the bounded uniform convergence topology.",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces', 'universal-property']"
20,How do I get $\|x\|\le C\|y\|$ in this case?,How do I get  in this case?,\|x\|\le C\|y\|,"I feel that the title is a bit uninformative, please feel free to edit it. This is a problem related to the Open Mapping Theorem. Let $T:X\to Y$ be a bounded linear operator from a Banach space X to a Banach space Y. Suppose that there exist a constant $C>0$ such that for any $y\in D\subset Y$, $D$ is dense in $Y$, these conditions are satisfied $\exists x\in X$ such that $Tx=y$. $\|x\|\le C\|y\|$. I am trying to show that the result holds for any $y\in Y$, the closure of $D$. Let $y\in Y$ be an arbitrary element, then we can write $y$ as  $$ y=\sum_{n=1}^{\infty}y_n $$ where $y_n\in D$ for each $n\in \Bbb N$. We can chose $(y_n)$ so that  $$ \sum_{n=1}^{\infty}\|y_n\|<\infty $$ since $Y$ is Banach. For each $n$, we let $x_n\in X$ be an element such that $Tx_n=y_n$ and $\|x_n\|\le C\|y_n\|$. Then  $$ \sum_{n=1}^{\infty}\|x_n\|\le \sum_{n=1}^{\infty}C\|y_n\|<\infty $$ by our assumption, thus $x=\sum_{n=1}^{\infty}x_n\in X$ since $X$ is Banach. It's not hard to see that  $$ Tx=T(\sum_{n=1}^{\infty}x_n)=\sum_{n=1}^{\infty}y_n=y $$ but this is where I got stuck. I can't show that $\|x\|\le C\|y\|$. Can  anyone please suggest me an idea on how to proceed? An alternative proof would be fine too if you can explain how my method is doomed to fail.","I feel that the title is a bit uninformative, please feel free to edit it. This is a problem related to the Open Mapping Theorem. Let $T:X\to Y$ be a bounded linear operator from a Banach space X to a Banach space Y. Suppose that there exist a constant $C>0$ such that for any $y\in D\subset Y$, $D$ is dense in $Y$, these conditions are satisfied $\exists x\in X$ such that $Tx=y$. $\|x\|\le C\|y\|$. I am trying to show that the result holds for any $y\in Y$, the closure of $D$. Let $y\in Y$ be an arbitrary element, then we can write $y$ as  $$ y=\sum_{n=1}^{\infty}y_n $$ where $y_n\in D$ for each $n\in \Bbb N$. We can chose $(y_n)$ so that  $$ \sum_{n=1}^{\infty}\|y_n\|<\infty $$ since $Y$ is Banach. For each $n$, we let $x_n\in X$ be an element such that $Tx_n=y_n$ and $\|x_n\|\le C\|y_n\|$. Then  $$ \sum_{n=1}^{\infty}\|x_n\|\le \sum_{n=1}^{\infty}C\|y_n\|<\infty $$ by our assumption, thus $x=\sum_{n=1}^{\infty}x_n\in X$ since $X$ is Banach. It's not hard to see that  $$ Tx=T(\sum_{n=1}^{\infty}x_n)=\sum_{n=1}^{\infty}y_n=y $$ but this is where I got stuck. I can't show that $\|x\|\le C\|y\|$. Can  anyone please suggest me an idea on how to proceed? An alternative proof would be fine too if you can explain how my method is doomed to fail.",,"['linear-algebra', 'functional-analysis', 'operator-theory', 'banach-spaces']"
21,Biharmonic Equation in a Rectangle with Some Uncommon Boundary Conditions,Biharmonic Equation in a Rectangle with Some Uncommon Boundary Conditions,,"Consider the following boundary value problem (BVP) $$\matrix{    {{\Delta ^2}H = 0,} \hfill & {} \hfill & {{\rm{in}}\,} \hfill & \Omega  \hfill  \cr     {\partial _y^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_1}} \hfill  \cr     {\partial _y^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_2}} \hfill  \cr     {\partial _x^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_3}} \hfill  \cr     {\partial _x^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_4}} \hfill  \cr   } \tag{1}$$ where $$\eqalign{    & \Delta^2 = \partial_{x}^{4}+2\partial_{x}^{2}\partial_{y}^{2}+\partial_{y}^{4} \cr   & \Omega  = \left\{ {\left( {x,y} \right): - a < x < a, - b < y < b} \right\}  \cr    & {S_1} = \left\{ {\left( {x,y} \right):x = a, - b \le y \le b} \right\}  \cr    & {S_2} = \left\{ {\left( {x,y} \right):x =  - a, - b \le y \le b} \right\}  \cr    & {S_3} = \left\{ {\left( {x,y} \right): - a \le x \le a,y = b} \right\}  \cr    & {S_4} = \left\{ {\left( {x,y} \right): - a \le x \le a,y =  - b} \right\}  \cr    & \partial \Omega  = \bigcup\limits_{i = 1}^4 {{S_i}}  \cr} \tag{2}$$ The function $H:\mathbb{R^2} \to \mathbb{R}$ is considered to belong to $C^{\infty}(\mathbb{R}^2)$. Then I want to show that $$\begin{align} \partial_{x}^{2}H&=0 \qquad \text{in} \qquad \Omega\\ \partial_{y}^{2}H&=0 \qquad \text{in} \qquad \Omega\\ {\partial _x}{\partial _y}H&=0 \qquad \text{in} \qquad \Omega \end{align}  \tag{3}$$ But I don't have any idea on how to proceed! Any hints or help is appreciated. :)","Consider the following boundary value problem (BVP) $$\matrix{    {{\Delta ^2}H = 0,} \hfill & {} \hfill & {{\rm{in}}\,} \hfill & \Omega  \hfill  \cr     {\partial _y^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_1}} \hfill  \cr     {\partial _y^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_2}} \hfill  \cr     {\partial _x^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_3}} \hfill  \cr     {\partial _x^2H = 0} \hfill & {{\partial _x}{\partial _y}H = 0} \hfill & {{\rm{on}}} \hfill & {{S_4}} \hfill  \cr   } \tag{1}$$ where $$\eqalign{    & \Delta^2 = \partial_{x}^{4}+2\partial_{x}^{2}\partial_{y}^{2}+\partial_{y}^{4} \cr   & \Omega  = \left\{ {\left( {x,y} \right): - a < x < a, - b < y < b} \right\}  \cr    & {S_1} = \left\{ {\left( {x,y} \right):x = a, - b \le y \le b} \right\}  \cr    & {S_2} = \left\{ {\left( {x,y} \right):x =  - a, - b \le y \le b} \right\}  \cr    & {S_3} = \left\{ {\left( {x,y} \right): - a \le x \le a,y = b} \right\}  \cr    & {S_4} = \left\{ {\left( {x,y} \right): - a \le x \le a,y =  - b} \right\}  \cr    & \partial \Omega  = \bigcup\limits_{i = 1}^4 {{S_i}}  \cr} \tag{2}$$ The function $H:\mathbb{R^2} \to \mathbb{R}$ is considered to belong to $C^{\infty}(\mathbb{R}^2)$. Then I want to show that $$\begin{align} \partial_{x}^{2}H&=0 \qquad \text{in} \qquad \Omega\\ \partial_{y}^{2}H&=0 \qquad \text{in} \qquad \Omega\\ {\partial _x}{\partial _y}H&=0 \qquad \text{in} \qquad \Omega \end{align}  \tag{3}$$ But I don't have any idea on how to proceed! Any hints or help is appreciated. :)",,"['functional-analysis', 'ordinary-differential-equations', 'multivariable-calculus', 'partial-differential-equations', 'regularity-theory-of-pdes']"
22,Spectrum of right shift operator in weighted $l2$ sequence space,Spectrum of right shift operator in weighted  sequence space,l2,"Let $l_2(a)$ be a hilbert space defined with following inner product: $\langle x_n,y_n\rangle = \sum a^k x_k y_k$. (It's a weighted sequence space with the weights  $\omega_i = a^i$). It's elements are the sequences for which the norm is defined and finite. ( $\langle x_n,x_n \rangle = c ).$ The left and right shift operators are defined as usual: $S_r(({x_0 , x_1, x_2, ... x_n , ...})) = (0, x_0, ...)$  $S_l(({x_0 , x_1, x_2, ... x_n , ...})) = (x_1, x_2, ...)$ Now, I was asked to find $\sigma(S_r), \sigma(S_l)$. My attempt was this: I found the operator norm of both operators. $\lvert S_r\rvert = a$, $\lvert S_l\rvert = 1/a$. Then, I figured that $S_l$ has eigenvalues for every $\lambda$ satisfying $\lvert \lambda \rvert < 1/a$. Because the specturm is closed and bounded by the operator norm, i figured that $\sigma(S_l)$ is the closed ball with radius $1/a$. Additionaly, i found that $S_r ^ * = aS_l$, and therefore $Im(S_r - \lambda I)^\bot = Ker(aS_l - \bar{\lambda} I) = Ker(a(S_l - (\bar{\lambda}/a) I)) = Ker(S_l - (\bar{\lambda} / a) I) \neq 0 \Longleftrightarrow \bar{\lambda} / a < 1/a$. So i deduced that if $\lvert\lambda\rvert < 1$ so $\lambda \in \sigma(S_r)$. which doesn't make sense to me if $a < 1$ and then the spectrum has to be bounded by $\lvert S_r \rvert = a$. Thanks alot.","Let $l_2(a)$ be a hilbert space defined with following inner product: $\langle x_n,y_n\rangle = \sum a^k x_k y_k$. (It's a weighted sequence space with the weights  $\omega_i = a^i$). It's elements are the sequences for which the norm is defined and finite. ( $\langle x_n,x_n \rangle = c ).$ The left and right shift operators are defined as usual: $S_r(({x_0 , x_1, x_2, ... x_n , ...})) = (0, x_0, ...)$  $S_l(({x_0 , x_1, x_2, ... x_n , ...})) = (x_1, x_2, ...)$ Now, I was asked to find $\sigma(S_r), \sigma(S_l)$. My attempt was this: I found the operator norm of both operators. $\lvert S_r\rvert = a$, $\lvert S_l\rvert = 1/a$. Then, I figured that $S_l$ has eigenvalues for every $\lambda$ satisfying $\lvert \lambda \rvert < 1/a$. Because the specturm is closed and bounded by the operator norm, i figured that $\sigma(S_l)$ is the closed ball with radius $1/a$. Additionaly, i found that $S_r ^ * = aS_l$, and therefore $Im(S_r - \lambda I)^\bot = Ker(aS_l - \bar{\lambda} I) = Ker(a(S_l - (\bar{\lambda}/a) I)) = Ker(S_l - (\bar{\lambda} / a) I) \neq 0 \Longleftrightarrow \bar{\lambda} / a < 1/a$. So i deduced that if $\lvert\lambda\rvert < 1$ so $\lambda \in \sigma(S_r)$. which doesn't make sense to me if $a < 1$ and then the spectrum has to be bounded by $\lvert S_r \rvert = a$. Thanks alot.",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory']"
23,optimal monotonic transform: $\min_f (f(x)-y)^2$,optimal monotonic transform:,\min_f (f(x)-y)^2,"Given two vectors of length $N$ denoted by $x_i$ and $y_i$, $1\leq i\leq N$, what is the monotonic transformation $f(x)$ that minimizes the overall distance $D=\sum_{i=1}^{N}{(f(x_i) - y_i)^2}$.  Does there exist either a closed form solution or fast algorithm for computing it?","Given two vectors of length $N$ denoted by $x_i$ and $y_i$, $1\leq i\leq N$, what is the monotonic transformation $f(x)$ that minimizes the overall distance $D=\sum_{i=1}^{N}{(f(x_i) - y_i)^2}$.  Does there exist either a closed form solution or fast algorithm for computing it?",,"['linear-algebra', 'functional-analysis', 'optimization', 'transformation', 'monotone-functions']"
24,How to show $ \sup\limits_{k}||u_k||_{W^{1.q}(U)}<\infty $?,How to show ?, \sup\limits_{k}||u_k||_{W^{1.q}(U)}<\infty ,"If $u_k\rightharpoonup u$  weakly in $W^{1,q}(U)$, how can I show  $$ \sup\limits_{k}||u_k||_{W^{1.q}(U)}<\infty? $$","If $u_k\rightharpoonup u$  weakly in $W^{1,q}(U)$, how can I show  $$ \sup\limits_{k}||u_k||_{W^{1.q}(U)}<\infty? $$",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
25,Find the eigenvalues of the operator T.,Find the eigenvalues of the operator T.,,"I have the following problem, ""Suppose that $X=\ell^1$ and define the operator $T\in B(X)$ as follows: $$Tx=\left(\frac12x_2,\frac13x_3,\frac14x_4,...\right)\,,\textit{where,}\,\,\, x=(x_1,x_2,x_3,...)$$ Find the eigenvalues of $T.$"" Here is my attempt so far: Let $\lambda$ be an eigenvalue of $T$, then, $$\implies\exists x\in \ell^1:Tx=\lambda x,\lambda\in\mathbb C$$ $$\implies\frac12x_2=\lambda x_1,\,\frac13x_3=\lambda x_2,\,\frac14x_4=\lambda x_3,...$$ We can write this in an equivalent manner as follows: $$\implies \frac12x_2=\lambda x_1,\,\frac13x_3=2!\lambda^2x_1,\,\frac14x_4=3!\lambda^3x_1,\,...\,,\frac1nx_n=(n-1)!\lambda^{n-1}x_1,\,...$$ For $n\in\mathbb N/\{1\}$. In order for the eigenvalue problem to be satisfied we require $x\ne1$, and so, if we have that $x_1=0\implies x=0$, which yields a contradiction. Thus, $x_1\neq0.$ This means that we then have, $$x=(x_1,\lambda x_1,2!\lambda^2x_1,...)$$ We must also ensure that $x\in X=\ell^1$, so we consider, $$x\in\ell^1\iff\sum_{k=1}^\infty|x_k|\lt \infty$$ $$\iff\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}x_1|\lt \infty$$ $$\iff|x_1|\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}|\lt \infty$$ And we know that $x_1\neq0$, so, $$\iff\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}|\lt \infty$$ I am unsure how to move on from here. I had thought to argue along the lines that if $(k-1)!$ grows at a rate faster than the $\lambda^{k-1}$ tends to zero, then the sum will not be finite. I think I have to try and show that $|\lambda|\lt1$, but am not sure how to get rid of the $(k-1)!$ in the above. Is the aforementioned line of thought the right way to go about this? Cheers!","I have the following problem, ""Suppose that $X=\ell^1$ and define the operator $T\in B(X)$ as follows: $$Tx=\left(\frac12x_2,\frac13x_3,\frac14x_4,...\right)\,,\textit{where,}\,\,\, x=(x_1,x_2,x_3,...)$$ Find the eigenvalues of $T.$"" Here is my attempt so far: Let $\lambda$ be an eigenvalue of $T$, then, $$\implies\exists x\in \ell^1:Tx=\lambda x,\lambda\in\mathbb C$$ $$\implies\frac12x_2=\lambda x_1,\,\frac13x_3=\lambda x_2,\,\frac14x_4=\lambda x_3,...$$ We can write this in an equivalent manner as follows: $$\implies \frac12x_2=\lambda x_1,\,\frac13x_3=2!\lambda^2x_1,\,\frac14x_4=3!\lambda^3x_1,\,...\,,\frac1nx_n=(n-1)!\lambda^{n-1}x_1,\,...$$ For $n\in\mathbb N/\{1\}$. In order for the eigenvalue problem to be satisfied we require $x\ne1$, and so, if we have that $x_1=0\implies x=0$, which yields a contradiction. Thus, $x_1\neq0.$ This means that we then have, $$x=(x_1,\lambda x_1,2!\lambda^2x_1,...)$$ We must also ensure that $x\in X=\ell^1$, so we consider, $$x\in\ell^1\iff\sum_{k=1}^\infty|x_k|\lt \infty$$ $$\iff\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}x_1|\lt \infty$$ $$\iff|x_1|\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}|\lt \infty$$ And we know that $x_1\neq0$, so, $$\iff\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}|\lt \infty$$ I am unsure how to move on from here. I had thought to argue along the lines that if $(k-1)!$ grows at a rate faster than the $\lambda^{k-1}$ tends to zero, then the sum will not be finite. I think I have to try and show that $|\lambda|\lt1$, but am not sure how to get rid of the $(k-1)!$ in the above. Is the aforementioned line of thought the right way to go about this? Cheers!",,"['real-analysis', 'functional-analysis', 'eigenvalues-eigenvectors', 'operator-theory', 'spectral-theory']"
26,Normalize a function and a measure so that the $L^p$ norm is $1$ for two values of $p$,Normalize a function and a measure so that the  norm is  for two values of,L^p 1 p,"I'm reading Tao's book on the interpolation of $l^p $ spaces and one part writes ""if $\|f\| _{ L^{p _ 0} } = \|f \|_ {L ^{ p _ 1 }} =1 $ then we are done. To obtain the general case, one can multiply the function $f$ and the measure $\mu$ by appropriately chosen constants to obtain the above normalization."" I have no idea how can I get this normalization since I feel if I'm given a functions $f$ and a measure $\mu$, no matter how I normalize them, $\|f\| _{L^{ p _ 0 }} \neq \|f \|_{L^{ p _ 1 }}$ in general.","I'm reading Tao's book on the interpolation of $l^p $ spaces and one part writes ""if $\|f\| _{ L^{p _ 0} } = \|f \|_ {L ^{ p _ 1 }} =1 $ then we are done. To obtain the general case, one can multiply the function $f$ and the measure $\mu$ by appropriately chosen constants to obtain the above normalization."" I have no idea how can I get this normalization since I feel if I'm given a functions $f$ and a measure $\mu$, no matter how I normalize them, $\|f\| _{L^{ p _ 0 }} \neq \|f \|_{L^{ p _ 1 }}$ in general.",,"['functional-analysis', 'lp-spaces']"
27,Ranges of projection operators,Ranges of projection operators,,"Suppose that $X$ is a Banach space and $P$ and $Q$ be bounded linear projections on $X$ such that $PQ$ and $QP$ are compact. Does it follow that $PQ$ and $QP$ are finite-rank operators? My attempt: I claim that both $PQ$ and $QP$ have closed range so if the range of one of them were not finite-dimensional, we would find a bounded sequence in it without a convergent subsequence. Is it fine? If so, can we find a projection $R$ with finite-dimensional range such that $PQ$ and $QP$ commute on the image of $I-R$?","Suppose that $X$ is a Banach space and $P$ and $Q$ be bounded linear projections on $X$ such that $PQ$ and $QP$ are compact. Does it follow that $PQ$ and $QP$ are finite-rank operators? My attempt: I claim that both $PQ$ and $QP$ have closed range so if the range of one of them were not finite-dimensional, we would find a bounded sequence in it without a convergent subsequence. Is it fine? If so, can we find a projection $R$ with finite-dimensional range such that $PQ$ and $QP$ commute on the image of $I-R$?",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
28,Does weak convergence in $L^2$ imply almost everywhere convergence of Cesaro averages?,Does weak convergence in  imply almost everywhere convergence of Cesaro averages?,L^2,"Consider a bounded sequence $f_n\in L^2(X,\mu)$, $\|f_n\|_{L^2}\leq C$. Is the following true: if $f_n \to f$ weakly (that is $\langle f_n,g \rangle \to \langle f,g \rangle$ for every $g\in L^2(X,\mu)$), then Cesaro averages $\frac{1}{n} \sum_{k=1}^n f_k$ converge to $f$ almost everywhere? What about other relations between convergence of a sequence and convergence of its Cesaro averages? Added afterwards: The first statement is false. Consider $f_n(x) = \sin kx$ for $10^{k-1}\leq n < 10^k$. Obviously, $f_n\to^w 0$, while $| \frac{1}{10^n} \sum_{k=1}^{10^n} f_k - \sin nx|\leq \frac{1}{10}$, meaning that $\limsup_n |\frac{1}{n} \sum_{k=1}^n f_k(x)| > 0$ for a.e. $x\in X$. Question about other types of convergence remains open: Assuming that a sequence $f_n\in L^2$ converges weakly, can we say anything about the sequence of Cesaro averages $\frac{1}{n} \sum_{k=1}^n f_k$? Does it converge strongly, in measure?.. In fact , the question is motivated by the following problem: Fix $\varepsilon >0$. Is it true that $$ \mu(\{ x\in X : \limsup_n |\frac{1}{n} \sum_{k=1}^n f_k(x)| > \varepsilon \}) < \varepsilon $$ whenever $\|f_n\|_{L^2}< \delta$ for small enough $\delta = \delta(\varepsilon)$? I will be grateful for any useful comments, suggestions or references!","Consider a bounded sequence $f_n\in L^2(X,\mu)$, $\|f_n\|_{L^2}\leq C$. Is the following true: if $f_n \to f$ weakly (that is $\langle f_n,g \rangle \to \langle f,g \rangle$ for every $g\in L^2(X,\mu)$), then Cesaro averages $\frac{1}{n} \sum_{k=1}^n f_k$ converge to $f$ almost everywhere? What about other relations between convergence of a sequence and convergence of its Cesaro averages? Added afterwards: The first statement is false. Consider $f_n(x) = \sin kx$ for $10^{k-1}\leq n < 10^k$. Obviously, $f_n\to^w 0$, while $| \frac{1}{10^n} \sum_{k=1}^{10^n} f_k - \sin nx|\leq \frac{1}{10}$, meaning that $\limsup_n |\frac{1}{n} \sum_{k=1}^n f_k(x)| > 0$ for a.e. $x\in X$. Question about other types of convergence remains open: Assuming that a sequence $f_n\in L^2$ converges weakly, can we say anything about the sequence of Cesaro averages $\frac{1}{n} \sum_{k=1}^n f_k$? Does it converge strongly, in measure?.. In fact , the question is motivated by the following problem: Fix $\varepsilon >0$. Is it true that $$ \mu(\{ x\in X : \limsup_n |\frac{1}{n} \sum_{k=1}^n f_k(x)| > \varepsilon \}) < \varepsilon $$ whenever $\|f_n\|_{L^2}< \delta$ for small enough $\delta = \delta(\varepsilon)$? I will be grateful for any useful comments, suggestions or references!",,"['functional-analysis', 'measure-theory', 'random-variables', 'weak-convergence', 'almost-everywhere']"
29,Norm on reduced crossed product - $C^*$ version v.s. $L^p$ version,Norm on reduced crossed product -  version v.s.  version,C^* L^p,"Let $(G,A,\alpha)$ be a $C^*$-dynamical system where $G$ is a countable discrete group. When defining the reduced crossed product, one can proceed as follows: Let $\pi$ be a faithful representation of $A$ on a Hilbert space $H$. Then we get a representation $\tilde{\pi}$ of $A$ on $\ell^2(G,H)$ such that $(\tilde{\pi}(a)\xi)(t)=\pi(\alpha_{t^{-1}}(a))\xi(t)$ for all $a\in A$, $t\in G$, and $\xi\in\ell^2(G,H)$. Let $\lambda$ be the representation of $G$ on $\ell^2(G,H)$ such that $\lambda_s\xi(t)=\xi(s^{-1}t)$ for $s,t\in G$ and $\xi\in\ell^2(G,H)$. Then $(\tilde{\pi},\lambda)$ is a covariant representation,  called a regular covariant representation, and its integrated form $\tilde{\pi}\rtimes\lambda$ is a faithful representation of $AG$ on $\ell^2(G,H)$. Define the reduced norm on $AG$ by $||f||_r=||(\tilde{\pi}\rtimes\lambda)(f)||$. The completion is the reduced crossed product. It can be shown that $||f||_r=\sup ||\sigma(f)||$ for $f\in AG$, where the supremum is taken over all regular covariant representations $\sigma$ obtained from (not necessarily faithful) representations of $A$. Therefore, one could have used either one of these as the definition of $||f||_r$. My question has to do with the $L^p$ analog of the reduced $C^*$-crossed product, which has been studied by Chris Phillips. In this case, $A$ is isometrically isomorphic to a norm-closed subalgebra of $B(L^p(X,\mu))$ for some measure space $(X,\mu)$ and $p\in[1,\infty)$. In Phillips's setup, he uses the supremum definition (following earlier work by Dirksen-de Jeu-Wortel) but the supremum is now taken over all regular covariant representations obtained from nondegenerate $\sigma$-finite contractive representations of $A$, and this gives a seminorm, so one mods out by the kernel of this seminorm and takes completion in the induced norm to get the reduced $L^p$ crossed product. I have also seen a talk by Kasparov where he uses the first definition of the reduced norm. I suppose he is thinking of $A$ as already coming with a faithful representation given by the isometric embedding. So my question is: Are the two norms the same? Or what can we say about the resulting algebras?","Let $(G,A,\alpha)$ be a $C^*$-dynamical system where $G$ is a countable discrete group. When defining the reduced crossed product, one can proceed as follows: Let $\pi$ be a faithful representation of $A$ on a Hilbert space $H$. Then we get a representation $\tilde{\pi}$ of $A$ on $\ell^2(G,H)$ such that $(\tilde{\pi}(a)\xi)(t)=\pi(\alpha_{t^{-1}}(a))\xi(t)$ for all $a\in A$, $t\in G$, and $\xi\in\ell^2(G,H)$. Let $\lambda$ be the representation of $G$ on $\ell^2(G,H)$ such that $\lambda_s\xi(t)=\xi(s^{-1}t)$ for $s,t\in G$ and $\xi\in\ell^2(G,H)$. Then $(\tilde{\pi},\lambda)$ is a covariant representation,  called a regular covariant representation, and its integrated form $\tilde{\pi}\rtimes\lambda$ is a faithful representation of $AG$ on $\ell^2(G,H)$. Define the reduced norm on $AG$ by $||f||_r=||(\tilde{\pi}\rtimes\lambda)(f)||$. The completion is the reduced crossed product. It can be shown that $||f||_r=\sup ||\sigma(f)||$ for $f\in AG$, where the supremum is taken over all regular covariant representations $\sigma$ obtained from (not necessarily faithful) representations of $A$. Therefore, one could have used either one of these as the definition of $||f||_r$. My question has to do with the $L^p$ analog of the reduced $C^*$-crossed product, which has been studied by Chris Phillips. In this case, $A$ is isometrically isomorphic to a norm-closed subalgebra of $B(L^p(X,\mu))$ for some measure space $(X,\mu)$ and $p\in[1,\infty)$. In Phillips's setup, he uses the supremum definition (following earlier work by Dirksen-de Jeu-Wortel) but the supremum is now taken over all regular covariant representations obtained from nondegenerate $\sigma$-finite contractive representations of $A$, and this gives a seminorm, so one mods out by the kernel of this seminorm and takes completion in the induced norm to get the reduced $L^p$ crossed product. I have also seen a talk by Kasparov where he uses the first definition of the reduced norm. I suppose he is thinking of $A$ as already coming with a faithful representation given by the isometric embedding. So my question is: Are the two norms the same? Or what can we say about the resulting algebras?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'banach-algebras']"
30,Surjectivity of Derivatives in infinite dimensional spaces,Surjectivity of Derivatives in infinite dimensional spaces,,"I have a trouble about an exercise in Techniques of Variational Analysis, Borwein, J.M., Zhu, Q.J (Ex. 2.1.2): Let $X$ be a Banach space and let $f: X \to \mathbb{R}$ be a Frchet differentiable function ( https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative Frchet_derivative ). Suppose that $f$ is bounded from below on any bounded set and satisfies $$\lim_{\left \| x \right \| \to \infty} \frac{f\left (x \right )}{\left \| x \right \|}=+\infty$$ Then the range of $f'$ is dense in $X^*$. By the similar method in $\mathbb{R}$, for $\gamma \in X^*$, letting $g\left ( x \right ) = f \left ( x \right ) -\langle \gamma , x \rangle $. I proved $g \to \infty$ as $x \to \infty$. However, I have no idea to continue or construct a sequence in the range of $f'$ converging to $\gamma$. I also don't know how to use the hypothesis that $f$ is bounded from below on any bounded set.","I have a trouble about an exercise in Techniques of Variational Analysis, Borwein, J.M., Zhu, Q.J (Ex. 2.1.2): Let $X$ be a Banach space and let $f: X \to \mathbb{R}$ be a Frchet differentiable function ( https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative Frchet_derivative ). Suppose that $f$ is bounded from below on any bounded set and satisfies $$\lim_{\left \| x \right \| \to \infty} \frac{f\left (x \right )}{\left \| x \right \|}=+\infty$$ Then the range of $f'$ is dense in $X^*$. By the similar method in $\mathbb{R}$, for $\gamma \in X^*$, letting $g\left ( x \right ) = f \left ( x \right ) -\langle \gamma , x \rangle $. I proved $g \to \infty$ as $x \to \infty$. However, I have no idea to continue or construct a sequence in the range of $f'$ converging to $\gamma$. I also don't know how to use the hypothesis that $f$ is bounded from below on any bounded set.",,"['analysis', 'functional-analysis', 'calculus-of-variations']"
31,"Hermite Functions and Multiplication Operators: Why is the ""obvious"" equation correct?","Hermite Functions and Multiplication Operators: Why is the ""obvious"" equation correct?",,"Question: Let $T$ be the unbounded operator on $L^2(\mathbb{R})$ defined by $$Tf(x) = \frac{1}{\sqrt{2}} \left( x f(x) - f^{\prime}(x) \right), $$ with domain $\mathfrak{D}(T)$ restricted to the set where $xf(x)$ and $f^{\prime}(x)$ are each, separately, in $L^2(\mathbb{R})$ (and we permit $f^{\prime}(x)$ to be a distributional derivative). It is known (e.g., Folland's Real Analysis , Exercise 8.23 (a -- c)) that $T h_k(x) = \sqrt{k + 1} h_{k + 1}(x)$, where $h_k(x)$ is the $k$th Hermite function (precise definition below). Of course, the Hermite functions form an orthonormal basis of $L^2(\mathbb{R})$, so for any $f \in \mathfrak{D}(T)$, we may write $$f(x) = \sum_{k = 0}^{\infty} c_k h_k(x).$$ I would like to write then that for any $f \in \mathfrak{D}(T)$, $$Tf(x) = \sum_{k = 0}^{\infty} c_k T h_k(x) = \sum_{k = 0}^{\infty} c_k \sqrt{k + 1} h_{k + 1}(x);$$ certainly, this would be true for finite sums. How do I justify the linearity across the infinite sum? Motivation: Let the (physicist's) Hermite functions be defined by $$h_k(x) = \frac{(-1)^k}{\sqrt{\sqrt{\pi} 2^k k!}} e^{x^2/2} \left( \frac{d}{dx} \right)^k e^{-x^2}, \quad k \in \mathbb{N} \cup \left\lbrace 0 \right\rbrace;$$ they form an orthonormal basis of $L^2(\mathbb{R})$. We define $\ell^2$ to be the space of square-summable sequences, where we let the sequences be indexed starting at $0$ for convenience.  Then by $h_k(x)$ an orthonormal basis of $L^2(\mathbb{R})$, we know that the map $\iota: \ell^2 \to L^2(\mathbb{R})$ given by \begin{equation} \iota \left( (c_k)_{k = 0}^{\infty} \right) := \sum_{k = 0}^{\infty} c_k h_k(x) \end{equation} is an isomorphism of Hilbert spaces. I wish to relate conditions on the decay of the coefficients to the integrability of the resulting functions.  Let $$\mathfrak{L}_1 = \left\lbrace (c_k)_{k = 0}^{\infty} \in \ell^2: (\sqrt{k + 1} c_k)_{k = 0}^{\infty} \in \ell^2 \right\rbrace$$ and  $$\mathfrak{D}_1 = \left\lbrace f(x) \in L^2(\mathbb{R}): xf(x) \in L^2(\mathbb{R}), s \widehat{f}(s) \in L^2(\mathbb{R}) \right\rbrace,$$ where $\widehat{f}(s)$ is the Fourier transform of $f$, under the convention \begin{equation}  \widehat{f}(s) = \frac{1}{\sqrt{2\pi}} \int\limits_{\mathbb{R}} f(x) e^{- i \pi x \cdot s} \, dx, \quad f \in L^1(\mathbb{R}). \end{equation} I wish to show that $\iota (\mathfrak{L}_1) = \mathfrak{D}_1$. I can handle the inclusion $\iota (\mathfrak{L}_1) \subseteq \mathfrak{D}_1$. We know that \begin{equation} \tag{1} x h_k(x) = \sqrt{\frac{k + 1}{2}} h_{k + 1}(x) + \sqrt{\frac{k}{2}}h_{k-1}(x), \end{equation} so again, for finite linear combinations of Hermite functions there is no issue.  Moreover, for any $(c_k) \in \mathfrak{L}_1$, let $f = \iota (c_k)$, and let $P_n$ be the orthogonal projection onto $\text{span} \langle h_0, h_1, \dotsc , h_n \rangle$. By (1), for all $n \in \mathbb{N}$, $P_n f$ is in the domain of the multiplication-by-$x$ operator, hereafter denoted $M_x$.  Moreover, we discern the loose bound that for $m \leq n$, $m, n \in \mathbb{N}$, $$ \Vert M_x P_n f - M_x P_m f \Vert_{L^2}^2 \leq 2 \sum_{k = m - 1}^{n + 1} (k + 1) \vert c_k \vert^2, $$ so by $f = \iota(c_k)$ and $( \sqrt{k + 1} c_k) \in \ell^2$, we see that the sequence $( M_x P_n f)_{n = 1}^{\infty}$ is Cauchy in $L^2(\mathbb{R})$, hence convergent.  Obviously $P_n f \to f$ in $L^2(\mathbb{R})$, and $M_x P_n f \to g$ for some $g \in L^2(\mathbb{R})$; by closedness of $M_x$, we have that $f$ is in the domain of $M_x$ and $M_x f = \lim_{n \to \infty} M_x P_n f$.  In other words, $x f(x) \in L^2(\mathbb{R})$. By our convention on the Fourier transform, we have that (e.g., Folland, Real Analysis , Exercise 23h) that \begin{equation} \tag{2} \widehat{h}_k(s) = (-i)^k h_k(s); \end{equation} Hence, showing $s \widehat{f}(s) \in L^2(\mathbb{R})$ follows in essentially the same way. In my attempt to show $\mathfrak{D}_1 \subseteq \iota(\mathfrak{L}_1)$, I note first that for all $f \in \mathfrak{D}_1$, $f \in L^2(\mathbb{R})$ and $s \widehat{f}(s) \in L^2(\mathbb{R})$, then $f \in \mathcal{H}^1(\mathbb{R})$, the $L^2$-Sobolev space of first order, so in particular, the distributional derivative $f^{\prime}(x)$ is in $L^2(\mathbb{R})$. Since for $f \in \mathfrak{D}_1$, we also have that $x f(x) \in L^2(\mathbb{R})$, we see that $f \in \mathfrak{D}(T)$.  If the linearity holds, then by $Tf \in L^2(\mathbb{R})$, it will follow that $(\sqrt{k + 1} c_k) \in \ell^2$, and we will be done. Perhaps (probably!) it is just a mental block, but I am not as certain how the infinite limit holds in this direction.  Certainly $$ \langle T h_j, T h_k \rangle = (k + 1) \delta_{j, k}, $$ so we have some orthogonality to work with, but I do not see the passage to infinite sums, even under the hypothesis that $f \in \mathfrak{D}(T)$.","Question: Let $T$ be the unbounded operator on $L^2(\mathbb{R})$ defined by $$Tf(x) = \frac{1}{\sqrt{2}} \left( x f(x) - f^{\prime}(x) \right), $$ with domain $\mathfrak{D}(T)$ restricted to the set where $xf(x)$ and $f^{\prime}(x)$ are each, separately, in $L^2(\mathbb{R})$ (and we permit $f^{\prime}(x)$ to be a distributional derivative). It is known (e.g., Folland's Real Analysis , Exercise 8.23 (a -- c)) that $T h_k(x) = \sqrt{k + 1} h_{k + 1}(x)$, where $h_k(x)$ is the $k$th Hermite function (precise definition below). Of course, the Hermite functions form an orthonormal basis of $L^2(\mathbb{R})$, so for any $f \in \mathfrak{D}(T)$, we may write $$f(x) = \sum_{k = 0}^{\infty} c_k h_k(x).$$ I would like to write then that for any $f \in \mathfrak{D}(T)$, $$Tf(x) = \sum_{k = 0}^{\infty} c_k T h_k(x) = \sum_{k = 0}^{\infty} c_k \sqrt{k + 1} h_{k + 1}(x);$$ certainly, this would be true for finite sums. How do I justify the linearity across the infinite sum? Motivation: Let the (physicist's) Hermite functions be defined by $$h_k(x) = \frac{(-1)^k}{\sqrt{\sqrt{\pi} 2^k k!}} e^{x^2/2} \left( \frac{d}{dx} \right)^k e^{-x^2}, \quad k \in \mathbb{N} \cup \left\lbrace 0 \right\rbrace;$$ they form an orthonormal basis of $L^2(\mathbb{R})$. We define $\ell^2$ to be the space of square-summable sequences, where we let the sequences be indexed starting at $0$ for convenience.  Then by $h_k(x)$ an orthonormal basis of $L^2(\mathbb{R})$, we know that the map $\iota: \ell^2 \to L^2(\mathbb{R})$ given by \begin{equation} \iota \left( (c_k)_{k = 0}^{\infty} \right) := \sum_{k = 0}^{\infty} c_k h_k(x) \end{equation} is an isomorphism of Hilbert spaces. I wish to relate conditions on the decay of the coefficients to the integrability of the resulting functions.  Let $$\mathfrak{L}_1 = \left\lbrace (c_k)_{k = 0}^{\infty} \in \ell^2: (\sqrt{k + 1} c_k)_{k = 0}^{\infty} \in \ell^2 \right\rbrace$$ and  $$\mathfrak{D}_1 = \left\lbrace f(x) \in L^2(\mathbb{R}): xf(x) \in L^2(\mathbb{R}), s \widehat{f}(s) \in L^2(\mathbb{R}) \right\rbrace,$$ where $\widehat{f}(s)$ is the Fourier transform of $f$, under the convention \begin{equation}  \widehat{f}(s) = \frac{1}{\sqrt{2\pi}} \int\limits_{\mathbb{R}} f(x) e^{- i \pi x \cdot s} \, dx, \quad f \in L^1(\mathbb{R}). \end{equation} I wish to show that $\iota (\mathfrak{L}_1) = \mathfrak{D}_1$. I can handle the inclusion $\iota (\mathfrak{L}_1) \subseteq \mathfrak{D}_1$. We know that \begin{equation} \tag{1} x h_k(x) = \sqrt{\frac{k + 1}{2}} h_{k + 1}(x) + \sqrt{\frac{k}{2}}h_{k-1}(x), \end{equation} so again, for finite linear combinations of Hermite functions there is no issue.  Moreover, for any $(c_k) \in \mathfrak{L}_1$, let $f = \iota (c_k)$, and let $P_n$ be the orthogonal projection onto $\text{span} \langle h_0, h_1, \dotsc , h_n \rangle$. By (1), for all $n \in \mathbb{N}$, $P_n f$ is in the domain of the multiplication-by-$x$ operator, hereafter denoted $M_x$.  Moreover, we discern the loose bound that for $m \leq n$, $m, n \in \mathbb{N}$, $$ \Vert M_x P_n f - M_x P_m f \Vert_{L^2}^2 \leq 2 \sum_{k = m - 1}^{n + 1} (k + 1) \vert c_k \vert^2, $$ so by $f = \iota(c_k)$ and $( \sqrt{k + 1} c_k) \in \ell^2$, we see that the sequence $( M_x P_n f)_{n = 1}^{\infty}$ is Cauchy in $L^2(\mathbb{R})$, hence convergent.  Obviously $P_n f \to f$ in $L^2(\mathbb{R})$, and $M_x P_n f \to g$ for some $g \in L^2(\mathbb{R})$; by closedness of $M_x$, we have that $f$ is in the domain of $M_x$ and $M_x f = \lim_{n \to \infty} M_x P_n f$.  In other words, $x f(x) \in L^2(\mathbb{R})$. By our convention on the Fourier transform, we have that (e.g., Folland, Real Analysis , Exercise 23h) that \begin{equation} \tag{2} \widehat{h}_k(s) = (-i)^k h_k(s); \end{equation} Hence, showing $s \widehat{f}(s) \in L^2(\mathbb{R})$ follows in essentially the same way. In my attempt to show $\mathfrak{D}_1 \subseteq \iota(\mathfrak{L}_1)$, I note first that for all $f \in \mathfrak{D}_1$, $f \in L^2(\mathbb{R})$ and $s \widehat{f}(s) \in L^2(\mathbb{R})$, then $f \in \mathcal{H}^1(\mathbb{R})$, the $L^2$-Sobolev space of first order, so in particular, the distributional derivative $f^{\prime}(x)$ is in $L^2(\mathbb{R})$. Since for $f \in \mathfrak{D}_1$, we also have that $x f(x) \in L^2(\mathbb{R})$, we see that $f \in \mathfrak{D}(T)$.  If the linearity holds, then by $Tf \in L^2(\mathbb{R})$, it will follow that $(\sqrt{k + 1} c_k) \in \ell^2$, and we will be done. Perhaps (probably!) it is just a mental block, but I am not as certain how the infinite limit holds in this direction.  Certainly $$ \langle T h_j, T h_k \rangle = (k + 1) \delta_{j, k}, $$ so we have some orthogonality to work with, but I do not see the passage to infinite sums, even under the hypothesis that $f \in \mathfrak{D}(T)$.",,"['functional-analysis', 'sobolev-spaces']"
32,show that closure of $c_{00}$ is $c_{0}$ in $\ell$-infinity [duplicate],show that closure of  is  in -infinity [duplicate],c_{00} c_{0} \ell,"This question already has answers here : The closure of $c_{00}$ is $c_{0}$ in $\ell^\infty$ (2 answers) Closed 8 years ago . Let $x=(x(1),x(2),,x(n),) \in c_0$. So for any $\varepsilon>0$ there exists a $n_0 \in \mathbb{N}$ such that $|x(n)| \to 0$ as $n \to \infty$ for all $n \geq n_0$. Now for all $n \geq n_0$ , $||x_n  x||_\infty = \sup \{|x(m)|: m \geq n_0 \} \to 0$ as $m \to \infty$. I have a doubt that regarding the last line. That is, how can we say that $$\sup \{ |x(n+1)|, |x(n+2)|, ......... \} = \sup \{ |x(m)|:m > n \} \to 0$$ as $m \to \infty$ ? (because we dont know the supremum of this set (i.e. $\sup \{ |x(m)|:m>n \}$ ), it can                                                                         be infinity also). So how can we say that $\sup \{ |x(m)|:m>n \} \to 0$ ? What makes it possible?","This question already has answers here : The closure of $c_{00}$ is $c_{0}$ in $\ell^\infty$ (2 answers) Closed 8 years ago . Let $x=(x(1),x(2),,x(n),) \in c_0$. So for any $\varepsilon>0$ there exists a $n_0 \in \mathbb{N}$ such that $|x(n)| \to 0$ as $n \to \infty$ for all $n \geq n_0$. Now for all $n \geq n_0$ , $||x_n  x||_\infty = \sup \{|x(m)|: m \geq n_0 \} \to 0$ as $m \to \infty$. I have a doubt that regarding the last line. That is, how can we say that $$\sup \{ |x(n+1)|, |x(n+2)|, ......... \} = \sup \{ |x(m)|:m > n \} \to 0$$ as $m \to \infty$ ? (because we dont know the supremum of this set (i.e. $\sup \{ |x(m)|:m>n \}$ ), it can                                                                         be infinity also). So how can we say that $\sup \{ |x(m)|:m>n \} \to 0$ ? What makes it possible?",,['functional-analysis']
33,Absolute Convergence of a Series defined as a Cauchy Sequence,Absolute Convergence of a Series defined as a Cauchy Sequence,,"So the question I'm answering is ""Suppose (X, || ||) is a normed space. Show that X is complete iff every absolutely convergent series in X converges on an element of X."" The first half was simple (show that every absolutely convergent series can be expressed as a Cauchy sequence of partial sums, and thus converges because X is complete), but the second half I'm having trouble with. So, in my quest to show that ""Every absolutely convergent series in X converges to an element in X implies X is complete,"" I'm trying to find a way to show that, given a Cauchy sequence $(a_n)_{n \epsilon \Bbb N}$, the series $\Sigma_{k=1}^\infty x_k$, where $x_k := a_k-a_{k-1}$ (with $a_0 = 0$) is absolutely convergent. So far I have: For given $\varepsilon > 0, \exists N \epsilon \Bbb N$ such that $m, n \epsilon \Bbb N, m>n>N  \Rightarrow\\ ||a_m - a_n|| = ||\Sigma_{k=1}^m x_k -\Sigma_{k=1}^nx_k|| = ||\Sigma_{k=n+1}^mx_k||<\varepsilon\\$ and $||a_m-a_n||\ge|||a_m||-||a_n|||=|||\Sigma_{k=1}^m x_k|| -||\Sigma_{k=1}^nx_k|||$ and now I'm lost.","So the question I'm answering is ""Suppose (X, || ||) is a normed space. Show that X is complete iff every absolutely convergent series in X converges on an element of X."" The first half was simple (show that every absolutely convergent series can be expressed as a Cauchy sequence of partial sums, and thus converges because X is complete), but the second half I'm having trouble with. So, in my quest to show that ""Every absolutely convergent series in X converges to an element in X implies X is complete,"" I'm trying to find a way to show that, given a Cauchy sequence $(a_n)_{n \epsilon \Bbb N}$, the series $\Sigma_{k=1}^\infty x_k$, where $x_k := a_k-a_{k-1}$ (with $a_0 = 0$) is absolutely convergent. So far I have: For given $\varepsilon > 0, \exists N \epsilon \Bbb N$ such that $m, n \epsilon \Bbb N, m>n>N  \Rightarrow\\ ||a_m - a_n|| = ||\Sigma_{k=1}^m x_k -\Sigma_{k=1}^nx_k|| = ||\Sigma_{k=n+1}^mx_k||<\varepsilon\\$ and $||a_m-a_n||\ge|||a_m||-||a_n|||=|||\Sigma_{k=1}^m x_k|| -||\Sigma_{k=1}^nx_k|||$ and now I'm lost.",,['functional-analysis']
34,To show a dense subspace of lp(Z)?,To show a dense subspace of lp(Z)?,,"Exercise: My proposal Recall that \begin{equation} 	\|u\|_p 	:=  \left( \sum\limits_{j \in \mathbb{Z}} | u_{j} |^{p} \right)^{1/p},  	\,\,\,  	j \in \mathbb{Z},  	\forall u = \left( u_{j} \right) \in l_{p}, 	\,   	u_{j} \neq 0  	\, \text{ if } 1 \leq p < \infty, \end{equation} Let $u \in l^{p}(\mathbb{Z})$, $V \subset l^{p}(\mathbb{Z})$, and let $\{v_{j}\}_{j}$ be a sequence in $V$ which converges to $u$. The countable union of closed set is closed in $\mathbb{Z}$ when $u_{j} \neq 0$. (unsure about this step!) Because $V$ has finite dimension, we have a basis $\{ u_{1}, ..., u_{k} \}$ of $V$. Also, $u \in$ Span$(u_{1}, ..., u_{k}, u)$. But, we have that $V$ is closed in Span$(u_{1}, ..., u_{k}, u)$ with $v_{n} \to u$, and then $u \in V. \square$ Svetoslav's answer rewritten Recall that $$ V=\left\{u\in l^p(\mathbb Z): \left\{j\in\mathbb Z:u_j\neq 0\right\} \text{is finite}\right\}\subset l^p(\mathbb Z)$$ where  $$\|u\|_p 	:=  \left( \sum\limits_{j \in \mathbb{Z}} | u_{j} |^{p} \right)^{1/p},  	\,\,\,  	\forall \,u = \left\{ u_{j} \right\}_{j\in\mathbb Z} \in l_{p},\,\, 1 \leq p < \infty. $$ Let an element be $u \in l^{p}(\mathbb{Z})$, and a sequence of elements $(v^{j})_{j=1}^{\infty}\subset V$.  The series  \begin{equation*} ||u||_{p}^{p} = \sum\limits_{j \in \mathbb{Z}} |u_{j}|^{p} < \infty, \end{equation*} is (absolutely) convergent which implies that its tail tends to zero. Indeed,  let $S_n := \sum\limits_{j\in\mathbb Z,j\leq |n|} |u_{j}|^{p}$ be the partial sums of the series and let $A=\sum\limits_{j \in \mathbb{Z}} |u_{j}|^{p} < \infty$ be its sum.  By the definition for convergent series, given $\epsilon >0$, there exists $N\in\mathbb N$ such that for all $n>N$ we have  \begin{equation*} |\sum_{ |j| > n } |u_{j}|^{p} |=|A-S_n| < \epsilon.    \end{equation*} implying $\sum_{ |j| > n } |u_{j}|^{p} \to 0$, when $n \to \infty$.  Take for approximating sequence $\{ v^{j} \}_{j=1}^{\infty} \subset V$:  \begin{equation*} v^{j} = (0,0, ..., 0, u_{-j}, u_{-j+1}, ..., u_{-1}, u_{0}, u_{1}, ..., u_{j-1}, u_{j}, 0, 0, ...) \in V  \end{equation*} and see that this sequence converges to $u$, i.e \begin{equation*} || v^{j} - u ||_{p}=\sum_{ |k| > j } |u_{k}|^{p} \to 0 \, \text{ when } \, j \to \infty.  \end{equation*} Therefore $V$ is a dense subspace of $l^{p}(\mathbb{Z})$ for $1 \leq p < \infty. \square$ How can you show better that V is a dense subspace of $l^{p}(\mathbb{Z})$?","Exercise: My proposal Recall that \begin{equation} 	\|u\|_p 	:=  \left( \sum\limits_{j \in \mathbb{Z}} | u_{j} |^{p} \right)^{1/p},  	\,\,\,  	j \in \mathbb{Z},  	\forall u = \left( u_{j} \right) \in l_{p}, 	\,   	u_{j} \neq 0  	\, \text{ if } 1 \leq p < \infty, \end{equation} Let $u \in l^{p}(\mathbb{Z})$, $V \subset l^{p}(\mathbb{Z})$, and let $\{v_{j}\}_{j}$ be a sequence in $V$ which converges to $u$. The countable union of closed set is closed in $\mathbb{Z}$ when $u_{j} \neq 0$. (unsure about this step!) Because $V$ has finite dimension, we have a basis $\{ u_{1}, ..., u_{k} \}$ of $V$. Also, $u \in$ Span$(u_{1}, ..., u_{k}, u)$. But, we have that $V$ is closed in Span$(u_{1}, ..., u_{k}, u)$ with $v_{n} \to u$, and then $u \in V. \square$ Svetoslav's answer rewritten Recall that $$ V=\left\{u\in l^p(\mathbb Z): \left\{j\in\mathbb Z:u_j\neq 0\right\} \text{is finite}\right\}\subset l^p(\mathbb Z)$$ where  $$\|u\|_p 	:=  \left( \sum\limits_{j \in \mathbb{Z}} | u_{j} |^{p} \right)^{1/p},  	\,\,\,  	\forall \,u = \left\{ u_{j} \right\}_{j\in\mathbb Z} \in l_{p},\,\, 1 \leq p < \infty. $$ Let an element be $u \in l^{p}(\mathbb{Z})$, and a sequence of elements $(v^{j})_{j=1}^{\infty}\subset V$.  The series  \begin{equation*} ||u||_{p}^{p} = \sum\limits_{j \in \mathbb{Z}} |u_{j}|^{p} < \infty, \end{equation*} is (absolutely) convergent which implies that its tail tends to zero. Indeed,  let $S_n := \sum\limits_{j\in\mathbb Z,j\leq |n|} |u_{j}|^{p}$ be the partial sums of the series and let $A=\sum\limits_{j \in \mathbb{Z}} |u_{j}|^{p} < \infty$ be its sum.  By the definition for convergent series, given $\epsilon >0$, there exists $N\in\mathbb N$ such that for all $n>N$ we have  \begin{equation*} |\sum_{ |j| > n } |u_{j}|^{p} |=|A-S_n| < \epsilon.    \end{equation*} implying $\sum_{ |j| > n } |u_{j}|^{p} \to 0$, when $n \to \infty$.  Take for approximating sequence $\{ v^{j} \}_{j=1}^{\infty} \subset V$:  \begin{equation*} v^{j} = (0,0, ..., 0, u_{-j}, u_{-j+1}, ..., u_{-1}, u_{0}, u_{1}, ..., u_{j-1}, u_{j}, 0, 0, ...) \in V  \end{equation*} and see that this sequence converges to $u$, i.e \begin{equation*} || v^{j} - u ||_{p}=\sum_{ |k| > j } |u_{k}|^{p} \to 0 \, \text{ when } \, j \to \infty.  \end{equation*} Therefore $V$ is a dense subspace of $l^{p}(\mathbb{Z})$ for $1 \leq p < \infty. \square$ How can you show better that V is a dense subspace of $l^{p}(\mathbb{Z})$?",,['functional-analysis']
35,Going from composites to individual functions,Going from composites to individual functions,,"$f(g(k(x)))=\sqrt{1+4x^2}$ and $g(k(f(x)))=1+4x$ What is a systematic way to solve for $f$,$g$,and $k$? I never learned anything like this in algebra.","$f(g(k(x)))=\sqrt{1+4x^2}$ and $g(k(f(x)))=1+4x$ What is a systematic way to solve for $f$,$g$,and $k$? I never learned anything like this in algebra.",,"['algebra-precalculus', 'functional-analysis']"
36,How numerical radius help us to conclude an operator is normal and partial isometry?,How numerical radius help us to conclude an operator is normal and partial isometry?,,"In Furuta's book, ""Invitation to Linear Operators"" there is a theorem, theorem 2 in 3.7.3, that says: If $T^k=T$ for some integer $k\ge 2$ and if $w(T)\le 1$, then $T$ is the direct sum of a unitary operator and zero, that is $T$ is normal and partial isometry. I have tried several ways to solve this but unfortunately I couldn't do that. Since I need to proof of this theorem, I will be glad if someone could help me for it.","In Furuta's book, ""Invitation to Linear Operators"" there is a theorem, theorem 2 in 3.7.3, that says: If $T^k=T$ for some integer $k\ge 2$ and if $w(T)\le 1$, then $T$ is the direct sum of a unitary operator and zero, that is $T$ is normal and partial isometry. I have tried several ways to solve this but unfortunately I couldn't do that. Since I need to proof of this theorem, I will be glad if someone could help me for it.",,"['linear-algebra', 'functional-analysis', 'operator-theory']"
37,Elegant way to prove that the space must be infinite dimensional?,Elegant way to prove that the space must be infinite dimensional?,,"Let $F(S,V)$ be the set of all functions from S to a vector space V,   assume that $V\ne\{0\}$, and that S contains infinitely many elements, then we must have that $F(S,V)$ is infinite-dimensional. Is there an easy way to prove this? In order to show this I had to do a lot of work, first reduce the problem to the case where S is countable, and then consider some functions on the countable space etc.. It seems like such a simple fact that there should be a very simple proof?","Let $F(S,V)$ be the set of all functions from S to a vector space V,   assume that $V\ne\{0\}$, and that S contains infinitely many elements, then we must have that $F(S,V)$ is infinite-dimensional. Is there an easy way to prove this? In order to show this I had to do a lot of work, first reduce the problem to the case where S is countable, and then consider some functions on the countable space etc.. It seems like such a simple fact that there should be a very simple proof?",,"['linear-algebra', 'functional-analysis']"
38,Can some help me understand Zeidler's intuitive proof of Brouwer Fixed Point theorem,Can some help me understand Zeidler's intuitive proof of Brouwer Fixed Point theorem,,"On pg53, Zeidler gives the Brouwer's Fixed Point Theorem The continuous operator $A: M \to M$ has a fixed point provided $M$ is   a compact, convex and nonempty set in a finite dimensional normed   space over $\mathbb{K}$ Then he proceed to prove this using ""intuitive proof"" Let $M$ be a closed disk in $\mathbb{R^2}$, and let $A:M\to M$ be a   continuous operator. Suppose $A:M\to M$ is fixed point free such that $Au \neq u$, $\forall u \in M$ Then construct an operator $R: M \to \partial M$ as follows: For each point $u \in M$ follow the directed line segment from $Au$ to   $u$ to intersection with $\partial M$ and let the intersection point   be $Ru$ Obviously $R$ is a so called retraction that is $R$ is continuous and   $Ru = u$, $  \forall u \in \partial M$ Intuitively such a retraction does not exist, hence the desired   contradiction. Why is it intuitive that such retraction does not exist? $Ru =u$ means that for each $u$ in the boundary of $M$, $Ru$ takes the point to the boundary which is still the same $u$, so it makes total sense to say $Ru =u$. Secondly, if $Ru \neq u$, then $RAu \neq u$ hence $Au \neq u$...wouldn't this contradict the theorem? Can someone please guide me through this? Thanks!","On pg53, Zeidler gives the Brouwer's Fixed Point Theorem The continuous operator $A: M \to M$ has a fixed point provided $M$ is   a compact, convex and nonempty set in a finite dimensional normed   space over $\mathbb{K}$ Then he proceed to prove this using ""intuitive proof"" Let $M$ be a closed disk in $\mathbb{R^2}$, and let $A:M\to M$ be a   continuous operator. Suppose $A:M\to M$ is fixed point free such that $Au \neq u$, $\forall u \in M$ Then construct an operator $R: M \to \partial M$ as follows: For each point $u \in M$ follow the directed line segment from $Au$ to   $u$ to intersection with $\partial M$ and let the intersection point   be $Ru$ Obviously $R$ is a so called retraction that is $R$ is continuous and   $Ru = u$, $  \forall u \in \partial M$ Intuitively such a retraction does not exist, hence the desired   contradiction. Why is it intuitive that such retraction does not exist? $Ru =u$ means that for each $u$ in the boundary of $M$, $Ru$ takes the point to the boundary which is still the same $u$, so it makes total sense to say $Ru =u$. Secondly, if $Ru \neq u$, then $RAu \neq u$ hence $Au \neq u$...wouldn't this contradict the theorem? Can someone please guide me through this? Thanks!",,"['functional-analysis', 'proof-verification', 'proof-writing', 'intuition', 'fixed-point-theorems']"
39,"""Occupation time"" nonlinear functional measurable?","""Occupation time"" nonlinear functional measurable?",,"My question is for which functions $f$ the following nonlinear functional $f\rightarrow\int \mathbf{1}_B(f(x))dx$ is Borel measurable; $B\in\mathcal{B}(\mathbb{R})$ and $\mathbf{1}_B(.)$ is a characteristic function. I know that for $f\in (C[0,1],\sup)$ it is the case. How about $f\in L_p[0,1]$? I would be very grateful for help.","My question is for which functions $f$ the following nonlinear functional $f\rightarrow\int \mathbf{1}_B(f(x))dx$ is Borel measurable; $B\in\mathcal{B}(\mathbb{R})$ and $\mathbf{1}_B(.)$ is a characteristic function. I know that for $f\in (C[0,1],\sup)$ it is the case. How about $f\in L_p[0,1]$? I would be very grateful for help.",,"['functional-analysis', 'measure-theory']"
40,$\ell^p$ as a direct summand of $L^p$,as a direct summand of,\ell^p L^p,"I've been struggling with the following problem from a previous year's quals, and I don't know where to look it up (or even if it's supposed to be too obvious to write down). How do we embed $\ell^p$ as a direct summand of $L^p(0,1)$? In other words, how do we find an isomorphism $L^p(0,1)\cong \ell^p\oplus V$ of Banach spaces for some space $V$? (I think it's clear how to get a stupid embedding...just pick countably many functions with disjoint support, but how do we show it is a direct summand?)","I've been struggling with the following problem from a previous year's quals, and I don't know where to look it up (or even if it's supposed to be too obvious to write down). How do we embed $\ell^p$ as a direct summand of $L^p(0,1)$? In other words, how do we find an isomorphism $L^p(0,1)\cong \ell^p\oplus V$ of Banach spaces for some space $V$? (I think it's clear how to get a stupid embedding...just pick countably many functions with disjoint support, but how do we show it is a direct summand?)",,['functional-analysis']
41,The dual function of composite functions,The dual function of composite functions,,"Given $X$ $Y$ are two finite dimensional Hilbert space. Let $K$: $X\to Y$ be linear and $F$: $Y\to \mathbb R^+$ is convex. Let us use $F^\ast$ to denote the dual (conjugate) function of $F$. Recall $$ F^\ast(y^\ast):=\sup\{(y^*,y)-F(y)\} $$ for any $y^\ast\in Y^\ast$. But since Hilbert space, we don't really care $Y^*$ or $Y$... My question is: what is $((F\circ K)(x))^\ast$ in term of $F^\ast$ and $K^\ast$? Is there a such result? Or just simply $((F\circ K)(x))^\ast = F^\ast (y)$? Thank you!","Given $X$ $Y$ are two finite dimensional Hilbert space. Let $K$: $X\to Y$ be linear and $F$: $Y\to \mathbb R^+$ is convex. Let us use $F^\ast$ to denote the dual (conjugate) function of $F$. Recall $$ F^\ast(y^\ast):=\sup\{(y^*,y)-F(y)\} $$ for any $y^\ast\in Y^\ast$. But since Hilbert space, we don't really care $Y^*$ or $Y$... My question is: what is $((F\circ K)(x))^\ast$ in term of $F^\ast$ and $K^\ast$? Is there a such result? Or just simply $((F\circ K)(x))^\ast = F^\ast (y)$? Thank you!",,"['real-analysis', 'functional-analysis', 'optimization', 'duality-theorems']"
42,Is $H^2(\Omega)\cap H_0^1(\Omega)$ compactly embedded on $H_0^1(\Omega)$?,Is  compactly embedded on ?,H^2(\Omega)\cap H_0^1(\Omega) H_0^1(\Omega),"Considering $\Omega$ bounded and $\partial \Omega$ smooth.  I already know that $H^2(\Omega)\cap H_0^1(\Omega)$ is continuously embedded on $H_0^1(\Omega)$, thus if I take a bounded sequence in $H^2(\Omega)\cap H_0^1(\Omega)$ it is also bounded on $H_0^1(\Omega)$, and it has a weakly convergent subsequence, but I didn't succeed with that approach. I also tried to use Rellich Theorem that gives me a strongly convergent subsequence $u_{k_j}$ on $ L^{2}(\Omega)$ when I take $ \{ u_k\}\subset H^2(\Omega)\cap H_0^1(\Omega) : \|u_k\|_{H^2(\Omega)}\leq M $. Because $u_k$ is also bounded on $H_0^1(\Omega)$. But then I don't know how to make  $$\int\limits_\Omega |Du_{k_j}|^2$$ convergent. Can anyone please help me with that?  Thanks in advance.","Considering $\Omega$ bounded and $\partial \Omega$ smooth.  I already know that $H^2(\Omega)\cap H_0^1(\Omega)$ is continuously embedded on $H_0^1(\Omega)$, thus if I take a bounded sequence in $H^2(\Omega)\cap H_0^1(\Omega)$ it is also bounded on $H_0^1(\Omega)$, and it has a weakly convergent subsequence, but I didn't succeed with that approach. I also tried to use Rellich Theorem that gives me a strongly convergent subsequence $u_{k_j}$ on $ L^{2}(\Omega)$ when I take $ \{ u_k\}\subset H^2(\Omega)\cap H_0^1(\Omega) : \|u_k\|_{H^2(\Omega)}\leq M $. Because $u_k$ is also bounded on $H_0^1(\Omega)$. But then I don't know how to make  $$\int\limits_\Omega |Du_{k_j}|^2$$ convergent. Can anyone please help me with that?  Thanks in advance.",,"['functional-analysis', 'regularity-theory-of-pdes']"
43,"First representation theorem for sesquilinear forms - what is the role of the ""core""?","First representation theorem for sesquilinear forms - what is the role of the ""core""?",,"In the first representation theorem , the notion of the core of a sesquilinear form appears. What is the intuition behind this notion, in context of this theorem and in general? I appreciate any comments and answers! ( Here are some relevant definitions and background . All excerpts are from Kato's Perturbation Theory for Linear Operators , pp.308-322.)","In the first representation theorem , the notion of the core of a sesquilinear form appears. What is the intuition behind this notion, in context of this theorem and in general? I appreciate any comments and answers! ( Here are some relevant definitions and background . All excerpts are from Kato's Perturbation Theory for Linear Operators , pp.308-322.)",,"['functional-analysis', 'mathematical-physics', 'spectral-theory']"
44,Equivalent formulations: pure contraction,Equivalent formulations: pure contraction,,I want to prove the following equivalence: let $T$ be a bounded self-adjoint operator on a Hilbert space $H$. TFAE: $\|Tx\|<\|x\|$ for each $x\in H\setminus\{0\}$ $\|T\|\leq1$ and $\pm1\notin\sigma_p(T)$ where $\sigma_p(T)$ is the point spectrum (the set of all eigenvalues of $T$). One implication has to be easy from my point of view. Can someone help me with this proof? Thanks a lot.,I want to prove the following equivalence: let $T$ be a bounded self-adjoint operator on a Hilbert space $H$. TFAE: $\|Tx\|<\|x\|$ for each $x\in H\setminus\{0\}$ $\|T\|\leq1$ and $\pm1\notin\sigma_p(T)$ where $\sigma_p(T)$ is the point spectrum (the set of all eigenvalues of $T$). One implication has to be easy from my point of view. Can someone help me with this proof? Thanks a lot.,,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
45,"For a self-adjoint $T$, if $T^k$ is compact, then so is $T$.","For a self-adjoint , if  is compact, then so is .",T T^k T,"I'm studying functional analysis. Let $T:\mathcal{H}\rightarrow\mathcal{H}$ be a bounded self-adjoint linear operator on a Hilbert space $\mathcal{H}$. The problem is showing if $T^k$ is a compact operator for some $n\in\mathbb{N}$, then $T$ is also compact. Since $T^k$ is compact and self-adjoint, we may choose a countable orthonomal system $\{x_n\}$ and real eigenvalues $\{\lambda_n\}$ such that $T^k=\displaystyle\sum_n \lambda_n x_n\otimes\overline{x_n}.$ Then I guess $T$ should be the form of $S:=\sum_n (\lambda_n)^{1/k} x_n\otimes\overline{x_n}.$ Hm, if $n$ is even, we should consider the sign more carefully. $S^k=T^k$ is trivial. But.. how can I prove the uniqueness?","I'm studying functional analysis. Let $T:\mathcal{H}\rightarrow\mathcal{H}$ be a bounded self-adjoint linear operator on a Hilbert space $\mathcal{H}$. The problem is showing if $T^k$ is a compact operator for some $n\in\mathbb{N}$, then $T$ is also compact. Since $T^k$ is compact and self-adjoint, we may choose a countable orthonomal system $\{x_n\}$ and real eigenvalues $\{\lambda_n\}$ such that $T^k=\displaystyle\sum_n \lambda_n x_n\otimes\overline{x_n}.$ Then I guess $T$ should be the form of $S:=\sum_n (\lambda_n)^{1/k} x_n\otimes\overline{x_n}.$ Hm, if $n$ is even, we should consider the sign more carefully. $S^k=T^k$ is trivial. But.. how can I prove the uniqueness?",,['functional-analysis']
46,Sufficient condition for $0$ to be in a closed convex hull in a Hilbert space.,Sufficient condition for  to be in a closed convex hull in a Hilbert space.,0,"I am working on the following problem: Let $\mathcal{H}$ be a Hilbert space, let $\left\{a_n\right\}_{n=1}^\infty \subset \mathcal{H}$ be a sequence such that $||a_n|| = 1$, and consider the closed convex hull of $\left\{ a_n \right\}$, $$\mathcal{C} = \overline{\left\{ \sum_{i}^{< \infty} c_i a_i \;\colon\; c_i \geq 0 \text{ and } \sum c_i = 1 \right\}}.$$ (a)  If $\mathcal{H} = \text{span}\left\{ a_n \right\}$, then $\mathcal{H}$ is finite-dimensional.   (b)  $$\text{If } \lim_{n \to \infty} \left<a_n, x\right> = 0 \text{ for all } x \in \mathcal{H}, \text{ then } 0 \in \mathcal{C}.$$ I already proved (a).  I presume that (a) might have something to do with proving (b), but I am not sure.  Notice that if $\mathcal{H}$ is finite-dimensional, then the hypotheses of (b) are absurd, for they force $||a_n|| \to 0$.  I thought then maybe I could approach this by contradiction and show that if we assume $0 \notin \mathcal{C}$, then $\mathcal{H} = \text{span}\left\{a_n\right\}$ (or, at least, $\text{span}\left\{a_n\right\}$ is closed and thus a Hilbert space), and we would be done, but I haven't made any progress on this front.  Another thought I had was to just try to write down explicitly a sequence in $\mathcal{C}$ that converges to $0$.  The most obvious thing feels to me something like $$x_n = \frac{1}{n} \sum_{i = 1}^n a_i.$$  Then $$||x_n||^2 \leq \frac{1}{n} + \frac{2}{n^2} \sum_{i \neq j} |\left< a_i, a_j \right>|. $$  We would be done if we could show $|\left< a_i, a_j \right>| < \epsilon$ for all $i \neq j$ and $i$, $j$ sufficiently large, but my question here uniformly convergent subsequence of bounded linear operators on a Hilbert space? seems to preclude this method, even after restricting to subsequences to avoid pathological situations.  So I'm stuck.  Any help would be appreciated. -Thanks. EDIT:  I just caught a mistake, I should have written $$||x_n||^2 \leq \frac{1}{n} + \frac{2}{n^2} \sum_{i < j} |\text{Re}\left< a_i, a_j \right>|. $$  This shouldn't fix anything though, because Martin's answer on the page linked above still gives a nice counterexample.","I am working on the following problem: Let $\mathcal{H}$ be a Hilbert space, let $\left\{a_n\right\}_{n=1}^\infty \subset \mathcal{H}$ be a sequence such that $||a_n|| = 1$, and consider the closed convex hull of $\left\{ a_n \right\}$, $$\mathcal{C} = \overline{\left\{ \sum_{i}^{< \infty} c_i a_i \;\colon\; c_i \geq 0 \text{ and } \sum c_i = 1 \right\}}.$$ (a)  If $\mathcal{H} = \text{span}\left\{ a_n \right\}$, then $\mathcal{H}$ is finite-dimensional.   (b)  $$\text{If } \lim_{n \to \infty} \left<a_n, x\right> = 0 \text{ for all } x \in \mathcal{H}, \text{ then } 0 \in \mathcal{C}.$$ I already proved (a).  I presume that (a) might have something to do with proving (b), but I am not sure.  Notice that if $\mathcal{H}$ is finite-dimensional, then the hypotheses of (b) are absurd, for they force $||a_n|| \to 0$.  I thought then maybe I could approach this by contradiction and show that if we assume $0 \notin \mathcal{C}$, then $\mathcal{H} = \text{span}\left\{a_n\right\}$ (or, at least, $\text{span}\left\{a_n\right\}$ is closed and thus a Hilbert space), and we would be done, but I haven't made any progress on this front.  Another thought I had was to just try to write down explicitly a sequence in $\mathcal{C}$ that converges to $0$.  The most obvious thing feels to me something like $$x_n = \frac{1}{n} \sum_{i = 1}^n a_i.$$  Then $$||x_n||^2 \leq \frac{1}{n} + \frac{2}{n^2} \sum_{i \neq j} |\left< a_i, a_j \right>|. $$  We would be done if we could show $|\left< a_i, a_j \right>| < \epsilon$ for all $i \neq j$ and $i$, $j$ sufficiently large, but my question here uniformly convergent subsequence of bounded linear operators on a Hilbert space? seems to preclude this method, even after restricting to subsequences to avoid pathological situations.  So I'm stuck.  Any help would be appreciated. -Thanks. EDIT:  I just caught a mistake, I should have written $$||x_n||^2 \leq \frac{1}{n} + \frac{2}{n^2} \sum_{i < j} |\text{Re}\left< a_i, a_j \right>|. $$  This shouldn't fix anything though, because Martin's answer on the page linked above still gives a nice counterexample.",,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
47,Positive Elements of $\mathbb{C}G$: as functionals versus as elements of the C*-algebra,Positive Elements of : as functionals versus as elements of the C*-algebra,\mathbb{C}G,"I might have thought about this problem a little longer but am quite confused so said I would put this question to the good people here... Consider a finite group $G$ or rather the algebra of functions on $G$, $\mathbb{C}^G=F(G)$ with multiplication in $F(G)$ defined pointwise. We have an involution on $F(G)$: $$f^*(g)=\overline{f(g)}.$$ If we take the supremum norm on $F(G)$: $$\|f\|_\infty=\max_{g\in G}|f(g)|,$$ we have a C*-algebra. The positive elements of $F(G)$ are those of the form $f^*f$ and so those that have positive coefficients with respect to the basis $\{\delta_s:s\in G\}$ are the positive functions. Denote by $\mathbb{C}G$ the linear functionals on $F(G)$. This set is spanned by elements dual to the $\{\delta^s:s\in G\}$: $$\delta^s(\delta_t)=\delta_{t,s},$$ where the latter $\delta$ is the Kronecker delta. It is not difficult to show that the positive linear functionals of $\mathbb{C}(G)$ are those with positive coefficients with respect to the $\{\delta^s:s\in G\}$ basis. So for example, if $G=\{\mathbb{Z}_3,\,\oplus_3\}$ then $\displaystyle \nu=\frac{\delta^1+\delta^2}{2}\in\mathbb{C}G$ is a positive linear functional . However one can also give $\mathbb{C}G$ the structure of a C*-algebra. Extend by linearity the convolution product $$(\delta^s,\delta^t)\mapsto \delta^{st};\qquad\delta^s\star\delta^t=\delta^{st},$$ to the whole of $\mathbb{C}G$. My understanding is that there are C*-norms on $\mathbb{C}G$ when equipped with the involution: $$\nu^*(\delta_s)=\overline{\nu(\delta_{s^{-1}})}.$$ Now positivity in this C*-algebra is not the same as positivity as a linear functional. In particular it is not difficult to show that there is no $\mu\in\mathbb{C}\mathbb{Z}_3$ such that $$\mu^*\star \mu=\frac{\delta^1+\delta^2}{2}=:\nu.$$ Therefore, as an element of the C*-algebra $\mathbb{C}\mathbb{Z}_3$, $\nu$ is not positive. Is there an easy way of recognising if an element of the C*- algebra $\mathbb{C}G$ is positive? Random thoughts... is it necessary for $\nu(\delta_e)\neq0$, symmetry plays a role? $\nu(\delta_s)=\nu(\delta_{s^{-1}})$... have we any positive elements of the algebra which are not positive functionals . Alternatively I need to look at self-adjoint --- $\nu(\delta_s)=\overline{\nu(\delta_{s^{-1}})}$ --- and positive spectrum... can I find the spectrum of an element of $\mathbb{C}G$? Thank you.","I might have thought about this problem a little longer but am quite confused so said I would put this question to the good people here... Consider a finite group $G$ or rather the algebra of functions on $G$, $\mathbb{C}^G=F(G)$ with multiplication in $F(G)$ defined pointwise. We have an involution on $F(G)$: $$f^*(g)=\overline{f(g)}.$$ If we take the supremum norm on $F(G)$: $$\|f\|_\infty=\max_{g\in G}|f(g)|,$$ we have a C*-algebra. The positive elements of $F(G)$ are those of the form $f^*f$ and so those that have positive coefficients with respect to the basis $\{\delta_s:s\in G\}$ are the positive functions. Denote by $\mathbb{C}G$ the linear functionals on $F(G)$. This set is spanned by elements dual to the $\{\delta^s:s\in G\}$: $$\delta^s(\delta_t)=\delta_{t,s},$$ where the latter $\delta$ is the Kronecker delta. It is not difficult to show that the positive linear functionals of $\mathbb{C}(G)$ are those with positive coefficients with respect to the $\{\delta^s:s\in G\}$ basis. So for example, if $G=\{\mathbb{Z}_3,\,\oplus_3\}$ then $\displaystyle \nu=\frac{\delta^1+\delta^2}{2}\in\mathbb{C}G$ is a positive linear functional . However one can also give $\mathbb{C}G$ the structure of a C*-algebra. Extend by linearity the convolution product $$(\delta^s,\delta^t)\mapsto \delta^{st};\qquad\delta^s\star\delta^t=\delta^{st},$$ to the whole of $\mathbb{C}G$. My understanding is that there are C*-norms on $\mathbb{C}G$ when equipped with the involution: $$\nu^*(\delta_s)=\overline{\nu(\delta_{s^{-1}})}.$$ Now positivity in this C*-algebra is not the same as positivity as a linear functional. In particular it is not difficult to show that there is no $\mu\in\mathbb{C}\mathbb{Z}_3$ such that $$\mu^*\star \mu=\frac{\delta^1+\delta^2}{2}=:\nu.$$ Therefore, as an element of the C*-algebra $\mathbb{C}\mathbb{Z}_3$, $\nu$ is not positive. Is there an easy way of recognising if an element of the C*- algebra $\mathbb{C}G$ is positive? Random thoughts... is it necessary for $\nu(\delta_e)\neq0$, symmetry plays a role? $\nu(\delta_s)=\nu(\delta_{s^{-1}})$... have we any positive elements of the algebra which are not positive functionals . Alternatively I need to look at self-adjoint --- $\nu(\delta_s)=\overline{\nu(\delta_{s^{-1}})}$ --- and positive spectrum... can I find the spectrum of an element of $\mathbb{C}G$? Thank you.",,"['linear-algebra', 'functional-analysis', 'finite-groups', 'group-rings']"
48,Self-adjoint extension of the Laplacian,Self-adjoint extension of the Laplacian,,"Let $M$ be a complete Riemannian manifold and $-\Delta$ denote the Laplace-Beltrami operator on $M$. We can prove that $(-\Delta f, g) = (\nabla f, \nabla g) = (f, -\Delta g)$, when $f, g \in C^\infty_0(M)$. My question is, when one extends the Laplace-Beltrami operator as a self-adjoint operator, what is the domain of the extension? Edit: As Jack Lee points out, here we are thinking of $-\Delta$ as an unbounded operator on $L^2(M)$.","Let $M$ be a complete Riemannian manifold and $-\Delta$ denote the Laplace-Beltrami operator on $M$. We can prove that $(-\Delta f, g) = (\nabla f, \nabla g) = (f, -\Delta g)$, when $f, g \in C^\infty_0(M)$. My question is, when one extends the Laplace-Beltrami operator as a self-adjoint operator, what is the domain of the extension? Edit: As Jack Lee points out, here we are thinking of $-\Delta$ as an unbounded operator on $L^2(M)$.",,"['functional-analysis', 'differential-geometry', 'reference-request', 'sobolev-spaces']"
49,$\overline{\mathrm{Im} (T^*T)} = \overline{\mathrm{Im} T^*}$,,\overline{\mathrm{Im} (T^*T)} = \overline{\mathrm{Im} T^*},"I need to prove that in a Hilbert space, $\overline{\mathrm{Im}(T^*T)} = \overline{\mathrm{Im}T^*}$. I have already shown that $\ker (T^*) = (\mathrm{Im} T)^\perp$ and have so far concluded that $[\mathrm{Im}(T^*T)]^{\perp \perp} = [\mathrm{Im} T^*]^{\perp \perp}$ by proving $\ker (T^*T) =\ker (T)$. How do I obtain the final step? Can I just use the fact that for any subspace $A$, $A^{\perp \perp}= \overline{ \mathrm{Sp} (A)}$ but since the image is always a linear subspace, it is equal to its span?","I need to prove that in a Hilbert space, $\overline{\mathrm{Im}(T^*T)} = \overline{\mathrm{Im}T^*}$. I have already shown that $\ker (T^*) = (\mathrm{Im} T)^\perp$ and have so far concluded that $[\mathrm{Im}(T^*T)]^{\perp \perp} = [\mathrm{Im} T^*]^{\perp \perp}$ by proving $\ker (T^*T) =\ker (T)$. How do I obtain the final step? Can I just use the fact that for any subspace $A$, $A^{\perp \perp}= \overline{ \mathrm{Sp} (A)}$ but since the image is always a linear subspace, it is equal to its span?",,"['linear-algebra', 'functional-analysis', 'operator-theory', 'hilbert-spaces']"
50,$\overline{L^2(\mathbb R)\cap L^1(\mathbb R)}^{L^2(\mathbb R)}=L^2(\mathbb R)$,,\overline{L^2(\mathbb R)\cap L^1(\mathbb R)}^{L^2(\mathbb R)}=L^2(\mathbb R),While reading a proof in a book they used the following  result: $$ \overline{L^2(\mathbb R)\cap L^1(\mathbb R)}^{L^2(\mathbb R)}=L^2(\mathbb R) $$  saying that it's well known !! But all I can see is only one inclusion $\overline{L^2(\mathbb R)\cap L^1(\mathbb R)}^{L^2(\mathbb R)}\subset L^2(\mathbb R)$ which is trivial. Am I missing something because I can't see where the other inclusion comes from ? any help will be great thank you for your time.,While reading a proof in a book they used the following  result: $$ \overline{L^2(\mathbb R)\cap L^1(\mathbb R)}^{L^2(\mathbb R)}=L^2(\mathbb R) $$  saying that it's well known !! But all I can see is only one inclusion $\overline{L^2(\mathbb R)\cap L^1(\mathbb R)}^{L^2(\mathbb R)}\subset L^2(\mathbb R)$ which is trivial. Am I missing something because I can't see where the other inclusion comes from ? any help will be great thank you for your time.,,"['functional-analysis', 'lebesgue-integral', 'lp-spaces']"
51,Theorem about irreducible representation of $C^*$-algebra,Theorem about irreducible representation of -algebra,C^*,"I have been told, that there is a theorem about irreducible representation of $C^*$-algebras, but I have troubles finding it. It is also possible, that this theorem is consequence of some theorem I've already come across, but I did not realize that. From what I have understand, the theorem should state something like this: Let $\pi: A \to B(\mathscr{H})$ be a representation. If this representation is irreducible, than for every two points in $\mathscr{H}$ there is a path from one to the other. If needed I can provide the definitions of irreducible representations or some equivalent theorems.","I have been told, that there is a theorem about irreducible representation of $C^*$-algebras, but I have troubles finding it. It is also possible, that this theorem is consequence of some theorem I've already come across, but I did not realize that. From what I have understand, the theorem should state something like this: Let $\pi: A \to B(\mathscr{H})$ be a representation. If this representation is irreducible, than for every two points in $\mathscr{H}$ there is a path from one to the other. If needed I can provide the definitions of irreducible representations or some equivalent theorems.",,"['functional-analysis', 'representation-theory', 'operator-algebras', 'c-star-algebras']"
52,I need help understanding the proof of Lemma 2.4-1 from Kreyszig's Functional Analysis.,I need help understanding the proof of Lemma 2.4-1 from Kreyszig's Functional Analysis.,,"Lemma: Let $\{x_1, \ldots, x_n \}$ be a linearly independent set of vectors in a normed space $X$ (of any dimension). Then there is a number $c > 0$ such that for every choice of scalars $\alpha_1, \ldots, \alpha_n$, we have  $$\Vert \alpha_1 x_1 + \ldots + \alpha_n x_n \Vert \geq c (\lvert\alpha_1\rvert + \ldots + \lvert\alpha_n\rvert).$$ I have understood the proof until the second page where the author writes each sequence $(\beta_j^{(m)})$ is bounded. I don't understand next exactly how $(y_{n, m})$ is a subsequence and how we obtain the subsequence $(y_{n,m})=(y_{n, 1}, y_{n, 2}, \cdots)$ of $(y_m)$","Lemma: Let $\{x_1, \ldots, x_n \}$ be a linearly independent set of vectors in a normed space $X$ (of any dimension). Then there is a number $c > 0$ such that for every choice of scalars $\alpha_1, \ldots, \alpha_n$, we have  $$\Vert \alpha_1 x_1 + \ldots + \alpha_n x_n \Vert \geq c (\lvert\alpha_1\rvert + \ldots + \lvert\alpha_n\rvert).$$ I have understood the proof until the second page where the author writes each sequence $(\beta_j^{(m)})$ is bounded. I don't understand next exactly how $(y_{n, m})$ is a subsequence and how we obtain the subsequence $(y_{n,m})=(y_{n, 1}, y_{n, 2}, \cdots)$ of $(y_m)$",,['functional-analysis']
53,Functions so that image of min (resp. max) is a positive definite kernel,Functions so that image of min (resp. max) is a positive definite kernel,,"I am trying to determine the functions $\phi : \mathbb{R}^+ \to \mathbb{R}$ such that: Pb 1: $K(s, t) = \phi( \mathrm{min} (s,t))$ is a positive definite kernel on $\mathbb{R}^+$. Pb 2: $K(s, t) = \phi( \mathrm{max} (s,t))$ is a positive definite kernel on $\mathbb{R}^+$. (NB: The 2 problems are independent, I am not trying to find functions statisfying BOTH conditions) For Pb1, since min is a p.d. kernel, I have found that all $\phi$ admitting a power series expansion on  $\mathbb{R}^+$ with positive coefficients will work (e.g. polynoms with positive coeffs, exponential).  By Cauchy-Schwarz inequality, I also found that $\phi$ must be increasing. For Pb2, Cauchy-Schwarz gives that $\phi$ must be decreasing. It must also take positive values. I have found that positive constant functions work, and I wonder if they are the only ones. Any hints?","I am trying to determine the functions $\phi : \mathbb{R}^+ \to \mathbb{R}$ such that: Pb 1: $K(s, t) = \phi( \mathrm{min} (s,t))$ is a positive definite kernel on $\mathbb{R}^+$. Pb 2: $K(s, t) = \phi( \mathrm{max} (s,t))$ is a positive definite kernel on $\mathbb{R}^+$. (NB: The 2 problems are independent, I am not trying to find functions statisfying BOTH conditions) For Pb1, since min is a p.d. kernel, I have found that all $\phi$ admitting a power series expansion on  $\mathbb{R}^+$ with positive coefficients will work (e.g. polynoms with positive coeffs, exponential).  By Cauchy-Schwarz inequality, I also found that $\phi$ must be increasing. For Pb2, Cauchy-Schwarz gives that $\phi$ must be decreasing. It must also take positive values. I have found that positive constant functions work, and I wonder if they are the only ones. Any hints?",,"['analysis', 'functional-analysis', 'statistics', 'hilbert-spaces']"
54,Strictly convex iff norm is strictly sub additive,Strictly convex iff norm is strictly sub additive,,"Show that the closed unit ball in a normed linear space is strictly convex   iff the norm is strictly sub additive. One part is easy strictly sub additive implies strictly convex, but I'm not able to prove the other way.","Show that the closed unit ball in a normed linear space is strictly convex   iff the norm is strictly sub additive. One part is easy strictly sub additive implies strictly convex, but I'm not able to prove the other way.",,"['functional-analysis', 'convex-analysis']"
55,is the pullback operator associated to a flow bounded in L^2?,is the pullback operator associated to a flow bounded in L^2?,,"Let $M$ be a smooth compact manifold with a finite Borel measure $m$. Let $\{f_t\}_{t\in\mathbb R}$ be a $C^1$ flow on $M$. That is, a $C^1$ function $$ \mathbb R\times M\ni(t,x)\mapsto f_t(x)\in M $$ such that $f_0(x)=x$ for all $x\in M$, and $f_{t_1}\circ f_{t_2}=f_{t_1+t_2}$ for all $t_1,t_2\in\mathbb R$. Then, the pullback operator $f_t^*$ on $C(M)$ (with the sup-norm), $$ f_t^*\;\!\psi=\psi\circ f_t,\quad t\in\mathbb R,~\psi\in C(M), $$ is a bounded operator. I am wondering if $\;\!f_t^*$ could be extended to a bounded operator in $L^2(M,m)$ (with the $L^2$-norm), for instance when $|t|$ is small$\;\!$? The problem is we cannot use the tools of differential calculus such as the Jacobian, integration by parts, and so on, to estimate the norm of $f_t^*$ in $L^2(M,m)$ because (1) the measure $m$ is not given by a volume form on $M$ and (2) the flow $\{f_t\}_{t\in\mathbb R}$ does not preserve the measure $m$.","Let $M$ be a smooth compact manifold with a finite Borel measure $m$. Let $\{f_t\}_{t\in\mathbb R}$ be a $C^1$ flow on $M$. That is, a $C^1$ function $$ \mathbb R\times M\ni(t,x)\mapsto f_t(x)\in M $$ such that $f_0(x)=x$ for all $x\in M$, and $f_{t_1}\circ f_{t_2}=f_{t_1+t_2}$ for all $t_1,t_2\in\mathbb R$. Then, the pullback operator $f_t^*$ on $C(M)$ (with the sup-norm), $$ f_t^*\;\!\psi=\psi\circ f_t,\quad t\in\mathbb R,~\psi\in C(M), $$ is a bounded operator. I am wondering if $\;\!f_t^*$ could be extended to a bounded operator in $L^2(M,m)$ (with the $L^2$-norm), for instance when $|t|$ is small$\;\!$? The problem is we cannot use the tools of differential calculus such as the Jacobian, integration by parts, and so on, to estimate the norm of $f_t^*$ in $L^2(M,m)$ because (1) the measure $m$ is not given by a volume form on $M$ and (2) the flow $\{f_t\}_{t\in\mathbb R}$ does not preserve the measure $m$.",,"['functional-analysis', 'measure-theory', 'differential-geometry', 'operator-theory']"
56,How to determine convexity of functional,How to determine convexity of functional,,"I am a rookie to functional and calculus of variation. I want to know whether there exists any   sufficient condition for convexity of a functional besides the definition. Actually for function, one sufficient condition for convexity is that its Hessian matrix is positive definite. Can this conclusion be extended to the functional case? In addition, are there any books involving these? Thanks.","I am a rookie to functional and calculus of variation. I want to know whether there exists any   sufficient condition for convexity of a functional besides the definition. Actually for function, one sufficient condition for convexity is that its Hessian matrix is positive definite. Can this conclusion be extended to the functional case? In addition, are there any books involving these? Thanks.",,"['functional-analysis', 'calculus-of-variations']"
57,Question about computing a Complicated integral,Question about computing a Complicated integral,,"where $\beta$ is defined like this: I'm trying to prove (2.18) but i don't know how to do, i calculated the integral but i don't find anything EDIT1: $\beta(\phi_{\lambda,p,\rho}(y))=\displaystyle\frac{\int_{\mathbb{R}^N} x |\nabla(\phi_{\lambda,p,\rho}(y))(x)|^2 dx}{\int_{\mathbb{R}^N}|\nabla(\phi_{\lambda,p,\rho}(y))(x)|^2 dx}$ By definition of $\phi_{\lambda,p,\rho}$ we obtain: $\beta(\phi_{\lambda,p,\rho}(y))=\displaystyle\frac{\int_{B_{\rho}(y)} x |\nabla u_{\lambda,p,\rho}(|x-y|)|^2 dx}{\int_{B_{\rho}(y)}|\nabla u_{\lambda,p,\rho}(|x-y|)|^2 dx}$ We have that $x\in B_{\rho}(y)$, $u_{\lambda,p,\rho}$ is radial so $u_{\lambda,p,\rho}(|x-y|)=u_{\lambda,p,\rho}(x-y)$ But how to obtain that $\beta(\phi_{\lambda,p,\rho}(y))=y$ ? please help me Thank you.","where $\beta$ is defined like this: I'm trying to prove (2.18) but i don't know how to do, i calculated the integral but i don't find anything EDIT1: $\beta(\phi_{\lambda,p,\rho}(y))=\displaystyle\frac{\int_{\mathbb{R}^N} x |\nabla(\phi_{\lambda,p,\rho}(y))(x)|^2 dx}{\int_{\mathbb{R}^N}|\nabla(\phi_{\lambda,p,\rho}(y))(x)|^2 dx}$ By definition of $\phi_{\lambda,p,\rho}$ we obtain: $\beta(\phi_{\lambda,p,\rho}(y))=\displaystyle\frac{\int_{B_{\rho}(y)} x |\nabla u_{\lambda,p,\rho}(|x-y|)|^2 dx}{\int_{B_{\rho}(y)}|\nabla u_{\lambda,p,\rho}(|x-y|)|^2 dx}$ We have that $x\in B_{\rho}(y)$, $u_{\lambda,p,\rho}$ is radial so $u_{\lambda,p,\rho}(|x-y|)=u_{\lambda,p,\rho}(x-y)$ But how to obtain that $\beta(\phi_{\lambda,p,\rho}(y))=y$ ? please help me Thank you.",,"['analysis', 'functional-analysis', 'partial-differential-equations', 'improper-integrals']"
58,Is $x\mapsto \|Tx\|$ lower semi-continuous?,Is  lower semi-continuous?,x\mapsto \|Tx\|,"Suppose $T:\mathcal D(T)\rightarrow \mathcal Y$ is a closed operator from a Banach space $\mathcal X$ to a Banach space $\mathcal Y$. Is it true that $$ \|Tx\|\leq \liminf_{n\rightarrow\infty} \|T x_n\| $$ whenever $\|x-x_n\|\rightarrow 0$, i.e. is $x\mapsto \| Tx\|$ lower semi-continuous? (here it is implicit that $x_n,x\in \mathcal D(T)$). When $T$ is a multiplication operator in some $L^ p$ space, the inequality reduces to Fatou's Lemma. More generally, I would like to know if $x\mapsto \| Tx+y\|$ is lower semi-continuous for all $y\in\mathcal Y$. Any help in either direction will be much appreciated!","Suppose $T:\mathcal D(T)\rightarrow \mathcal Y$ is a closed operator from a Banach space $\mathcal X$ to a Banach space $\mathcal Y$. Is it true that $$ \|Tx\|\leq \liminf_{n\rightarrow\infty} \|T x_n\| $$ whenever $\|x-x_n\|\rightarrow 0$, i.e. is $x\mapsto \| Tx\|$ lower semi-continuous? (here it is implicit that $x_n,x\in \mathcal D(T)$). When $T$ is a multiplication operator in some $L^ p$ space, the inequality reduces to Fatou's Lemma. More generally, I would like to know if $x\mapsto \| Tx+y\|$ is lower semi-continuous for all $y\in\mathcal Y$. Any help in either direction will be much appreciated!",,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'semicontinuous-functions']"
59,Closed unit ball of $B(H)$ with wot topology is compact,Closed unit ball of  with wot topology is compact,B(H),"The following is a Theorem of Conway's operator theory: I can not understand how he proves it. I think $\phi(\text{ ball B(H)})$ is compact if $\phi(\text{ ball B(H)})$ is closed subset of compact set $X$, but why is $X$ compact?","The following is a Theorem of Conway's operator theory: I can not understand how he proves it. I think $\phi(\text{ ball B(H)})$ is compact if $\phi(\text{ ball B(H)})$ is closed subset of compact set $X$, but why is $X$ compact?",,"['functional-analysis', 'operator-theory', 'c-star-algebras', 'topological-vector-spaces']"
60,How to prove that an existence statement cannot be constructive,How to prove that an existence statement cannot be constructive,,"Given the well known spaces of sequences:  $$ l_\infty =\{(x_n), n\in \mathbb{N}, x_n \in \mathbb{R} : \sup_n |x_n|<\infty\} $$ $$ l_1= \{(x_n), n\in \mathbb{N}, x_n \in \mathbb{R} : \sum_n |x_n|<\infty\} $$ we can prove, by Hahn-Banach theorem, that $l_1\subsetneqq( l_\infty)^*$, where $( l_\infty)^*$ is the dual space of $ l_\infty$. But it seems that it's impossible to show explicitly an element of $( l_\infty)^*/l_1$. Here I found that "" it is impossible for an explicit example to be constructed "", but there is not a proof of this statement.  I found the same statement also here , but again without proof. I tried to find a proof but it's too hard for me. Someone can give me a sketch of the proof, or indicate an accessible source where I can find such proof? I'm interested to this question because it's connected with that Do we really need reals? , being an example of a non constructive existence theorem with an explicit proof of the fact that a constructive approach is impossible. Some one know other similar results?","Given the well known spaces of sequences:  $$ l_\infty =\{(x_n), n\in \mathbb{N}, x_n \in \mathbb{R} : \sup_n |x_n|<\infty\} $$ $$ l_1= \{(x_n), n\in \mathbb{N}, x_n \in \mathbb{R} : \sum_n |x_n|<\infty\} $$ we can prove, by Hahn-Banach theorem, that $l_1\subsetneqq( l_\infty)^*$, where $( l_\infty)^*$ is the dual space of $ l_\infty$. But it seems that it's impossible to show explicitly an element of $( l_\infty)^*/l_1$. Here I found that "" it is impossible for an explicit example to be constructed "", but there is not a proof of this statement.  I found the same statement also here , but again without proof. I tried to find a proof but it's too hard for me. Someone can give me a sketch of the proof, or indicate an accessible source where I can find such proof? I'm interested to this question because it's connected with that Do we really need reals? , being an example of a non constructive existence theorem with an explicit proof of the fact that a constructive approach is impossible. Some one know other similar results?",,"['functional-analysis', 'constructive-mathematics']"
61,"Prove a certain property of linear functionals, using the Hahn-Banach-Separation theorems","Prove a certain property of linear functionals, using the Hahn-Banach-Separation theorems",,"I've been trying to solve this question, with no luck so far: Let $X$ be a real linear space, and $\{\|\cdot \|_i\}_{i=1}^{n}$ family of norms on $X$. Let $f$ be a linear functional on $X$ such that for every $x\in X$: $f(x)\leq \max \|x\|_i$. Prove that there are $t_1,...,t_n\geq0$ such that $\sum t_i=1$ and for every $x\in X$: $f(x)\leq\sum t_i \|x\|_i$. I've been told that the best way to look at this questions is by separating $A=\mathop{\rm conv}\{(\|x\|_1-f(x),\ldots,\|x\|_n-f(x)):x\in X\}\subset \mathbb R^n$ with some other set. It didn't do me much good to try this my own. My observations are that $A$ is obviously convex, and every point in $\{(\|x\|_1-f(x),\ldots,\|x|\|_n-f(x)):x\in X\}\$$ has at least one non-negative coordinate. $A$ isn't necessarily closed since $f$ isn't necessarily bounded with one specific norm (therefore not continuous), nor is opened. Don't know what separation theorem would do, and more than that - even if I could separate, all I'd get is $\varphi(A)\geq \gamma \geq \varphi(B)$ which would give me information about $\varphi(a)$ and not on $f$. I thought it might be possible to prove that every point in a has at least one non-negative coordinate (is this even true?) and seperate from $\{(b_1,...,b_n):\forall i\:: b_i<0\}$ I'd love some tips/hints/guide/any thoughts actually. Thanks a lot!","I've been trying to solve this question, with no luck so far: Let $X$ be a real linear space, and $\{\|\cdot \|_i\}_{i=1}^{n}$ family of norms on $X$. Let $f$ be a linear functional on $X$ such that for every $x\in X$: $f(x)\leq \max \|x\|_i$. Prove that there are $t_1,...,t_n\geq0$ such that $\sum t_i=1$ and for every $x\in X$: $f(x)\leq\sum t_i \|x\|_i$. I've been told that the best way to look at this questions is by separating $A=\mathop{\rm conv}\{(\|x\|_1-f(x),\ldots,\|x\|_n-f(x)):x\in X\}\subset \mathbb R^n$ with some other set. It didn't do me much good to try this my own. My observations are that $A$ is obviously convex, and every point in $\{(\|x\|_1-f(x),\ldots,\|x|\|_n-f(x)):x\in X\}\$$ has at least one non-negative coordinate. $A$ isn't necessarily closed since $f$ isn't necessarily bounded with one specific norm (therefore not continuous), nor is opened. Don't know what separation theorem would do, and more than that - even if I could separate, all I'd get is $\varphi(A)\geq \gamma \geq \varphi(B)$ which would give me information about $\varphi(a)$ and not on $f$. I thought it might be possible to prove that every point in a has at least one non-negative coordinate (is this even true?) and seperate from $\{(b_1,...,b_n):\forall i\:: b_i<0\}$ I'd love some tips/hints/guide/any thoughts actually. Thanks a lot!",,"['real-analysis', 'linear-algebra']"
62,Fourier transform inversion formula for $f\in L_1(\mathbb{R}^n)$ and Dini condition,Fourier transform inversion formula for  and Dini condition,f\in L_1(\mathbb{R}^n),"Let us define the Dini condition for a function $f\in L_1(-\infty,\infty)$, i.e. Lebesgue summable on $\mathbb{R}$, as Given an $x\in\mathbb{R}$ there is a $\delta>0$ such that the Lebesgue integral $\int_{[-\delta,\delta]}|\frac{f(x+t)-f(x)}{t}|d\mu_t$ exists. In all the post the integrals are to be intended as Lebesgue integrals. I know (p. 423, here , of Kolmogorov-Fomin's       ) that, if $f\in L_1(-\infty,\infty)$ satisfies the Dini condition in $x\in\mathbb{R}$, then the inversion formula for the Fourier transform holds: $$f(x)=\frac{1}{2\pi}\lim_{N\to+\infty}\int_{[-N,N]}\Bigg(\int_{\mathbb{R}}f(t)e^{-i\lambda t)}d\mu_t\Bigg)e^{i\lambda x} d\mu_\lambda.$$ The same famous text proves ( p. 437-438 ) a similar theorem for functions $f\in L_1(\mathbb{R}^n)$, under conditions that I do not fully understand, stated in the following way: Let function $f(x_1,x_2,\ldots,x_n)$ ne integrable on the whole space $\mathbb{R}^n$ and let it satisfy the conditions:   $$|f(x_1+t_1,x_2,\ldots,x_n)-f(x_1,x_2,\ldots,x_n)|\leq C|t_1|^a,$$ $$|f(x_1,x_2+t_2,\ldots,x_n)-f(x_1,x_2,\ldots,x_n)|\leq C(x_1)|t_2|^a,$$$$\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots$$$$|f(x_1,x_2,\ldots,x_n+t_n)-f(x_1,x_2,\ldots,x_n)|\leq C(x_1,x_2,\ldots,x_{n- > 1})|t_n|^a,$$where $0\le a\le1,\quad\int_{\mathbb{R}}C(x_1)d\mu_{x_1}<\infty,\ldots,\quad\int_{\mathbb{R}}\ldots\int_{\mathbb{R}}C(x_1,\ldots,x_{n-1})d\mu_{x_1}\ldots d\mu_{x_{n-1}}<\infty.$   Then $$(2\pi)^nf(x_1,x_2,\ldots x_n)=$$$$=\lim_{N_1\to\infty}\int_{-N_1}^{N_1}\Big(\ldots\lim_{N_{n-1}\to\infty}\int_{-N_{n-1}}^{N_{n-1}}\Big(\lim_{N_n\to\infty}\int_{-N_n}^{N_n}g(\lambda_1,\ldots,\lambda_n)e^{ix_n\lambda_n }d\mu_{\lambda_n}\Big)e^{ix_{n-1}\lambda_{n-1}}d\mu_{\lambda_{n-1}}...\ldots\Big)e^{ix_1\lambda_1}d\mu_{\lambda_1} $$ where the integrals are Lebesgue integrals and $g(\lambda_1,\ldots,\lambda_n):=\int_{\mathbb{R}}\ldots\int_{\mathbb{R}}f(x_1,\ldots,x_n)e^{-i\sum_{k=1}^nx_k\lambda_k}d\mu_{x_1}\ldots d\mu_{x_n}$. The theorem is precisely stated in this way in the book (I've only changed some notation to clearly show the integrals are Lebesgue integrals), but I am not sure to understand what are $a$ and the $t_k$ in this wording. Does anybody passing by know the theorem and what the inequalities mean: must they hold for some $a\in[0,1]$ or for all $a\in[0,1]$? As to the $t_k$, $k=1,\ldots ,n$ must they satisfy the inequality for some $\delta>0$ such that $t_1,\ldots,t_n\le\delta$? The proof seems to use the fact that the function $f(-,x_2,\ldots ,x_n)$ as a function of $x_1$ satisfies the above defined Dini condition: does it? Why can we see that? In particular, I am not convinced that $a=0$ could guarantee the Dini condition ($\int_{0}^1 x^{-1}dx=+\infty$). I think that my greatest problem is that I do not understand the conditions in the theorem's statement... Thank you so much for any explanation!","Let us define the Dini condition for a function $f\in L_1(-\infty,\infty)$, i.e. Lebesgue summable on $\mathbb{R}$, as Given an $x\in\mathbb{R}$ there is a $\delta>0$ such that the Lebesgue integral $\int_{[-\delta,\delta]}|\frac{f(x+t)-f(x)}{t}|d\mu_t$ exists. In all the post the integrals are to be intended as Lebesgue integrals. I know (p. 423, here , of Kolmogorov-Fomin's       ) that, if $f\in L_1(-\infty,\infty)$ satisfies the Dini condition in $x\in\mathbb{R}$, then the inversion formula for the Fourier transform holds: $$f(x)=\frac{1}{2\pi}\lim_{N\to+\infty}\int_{[-N,N]}\Bigg(\int_{\mathbb{R}}f(t)e^{-i\lambda t)}d\mu_t\Bigg)e^{i\lambda x} d\mu_\lambda.$$ The same famous text proves ( p. 437-438 ) a similar theorem for functions $f\in L_1(\mathbb{R}^n)$, under conditions that I do not fully understand, stated in the following way: Let function $f(x_1,x_2,\ldots,x_n)$ ne integrable on the whole space $\mathbb{R}^n$ and let it satisfy the conditions:   $$|f(x_1+t_1,x_2,\ldots,x_n)-f(x_1,x_2,\ldots,x_n)|\leq C|t_1|^a,$$ $$|f(x_1,x_2+t_2,\ldots,x_n)-f(x_1,x_2,\ldots,x_n)|\leq C(x_1)|t_2|^a,$$$$\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots$$$$|f(x_1,x_2,\ldots,x_n+t_n)-f(x_1,x_2,\ldots,x_n)|\leq C(x_1,x_2,\ldots,x_{n- > 1})|t_n|^a,$$where $0\le a\le1,\quad\int_{\mathbb{R}}C(x_1)d\mu_{x_1}<\infty,\ldots,\quad\int_{\mathbb{R}}\ldots\int_{\mathbb{R}}C(x_1,\ldots,x_{n-1})d\mu_{x_1}\ldots d\mu_{x_{n-1}}<\infty.$   Then $$(2\pi)^nf(x_1,x_2,\ldots x_n)=$$$$=\lim_{N_1\to\infty}\int_{-N_1}^{N_1}\Big(\ldots\lim_{N_{n-1}\to\infty}\int_{-N_{n-1}}^{N_{n-1}}\Big(\lim_{N_n\to\infty}\int_{-N_n}^{N_n}g(\lambda_1,\ldots,\lambda_n)e^{ix_n\lambda_n }d\mu_{\lambda_n}\Big)e^{ix_{n-1}\lambda_{n-1}}d\mu_{\lambda_{n-1}}...\ldots\Big)e^{ix_1\lambda_1}d\mu_{\lambda_1} $$ where the integrals are Lebesgue integrals and $g(\lambda_1,\ldots,\lambda_n):=\int_{\mathbb{R}}\ldots\int_{\mathbb{R}}f(x_1,\ldots,x_n)e^{-i\sum_{k=1}^nx_k\lambda_k}d\mu_{x_1}\ldots d\mu_{x_n}$. The theorem is precisely stated in this way in the book (I've only changed some notation to clearly show the integrals are Lebesgue integrals), but I am not sure to understand what are $a$ and the $t_k$ in this wording. Does anybody passing by know the theorem and what the inequalities mean: must they hold for some $a\in[0,1]$ or for all $a\in[0,1]$? As to the $t_k$, $k=1,\ldots ,n$ must they satisfy the inequality for some $\delta>0$ such that $t_1,\ldots,t_n\le\delta$? The proof seems to use the fact that the function $f(-,x_2,\ldots ,x_n)$ as a function of $x_1$ satisfies the above defined Dini condition: does it? Why can we see that? In particular, I am not convinced that $a=0$ could guarantee the Dini condition ($\int_{0}^1 x^{-1}dx=+\infty$). I think that my greatest problem is that I do not understand the conditions in the theorem's statement... Thank you so much for any explanation!",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'lebesgue-integral']"
63,Typo in Murphy's book: $ \sigma_A(b)= \sigma_B(b) \cup \{0\}$ or $ \sigma_A(b) \cup \{0\}= \sigma_B(b) \cup \{0\}$,Typo in Murphy's book:  or, \sigma_A(b)= \sigma_B(b) \cup \{0\}  \sigma_A(b) \cup \{0\}= \sigma_B(b) \cup \{0\},"On page 45 the book states that for any $\lambda \in \mathbb C \setminus \{0\}$ and any star subalgebra $B$ of a $C^\ast$ algebra $A$ with $1_B \neq 1_A$, $b -\lambda 1_B$ is invertible in $B$ if and only if $b-\lambda 1_A$ is invertible in $A$. Therefore $$ \sigma_A(b)= \sigma_B(b) \cup \{0\}$$ This should be $ \sigma_A(b) \cup \{0\}= \sigma_B(b) \cup \{0\}$, shouldn't it?","On page 45 the book states that for any $\lambda \in \mathbb C \setminus \{0\}$ and any star subalgebra $B$ of a $C^\ast$ algebra $A$ with $1_B \neq 1_A$, $b -\lambda 1_B$ is invertible in $B$ if and only if $b-\lambda 1_A$ is invertible in $A$. Therefore $$ \sigma_A(b)= \sigma_B(b) \cup \{0\}$$ This should be $ \sigma_A(b) \cup \{0\}= \sigma_B(b) \cup \{0\}$, shouldn't it?",,['functional-analysis']
64,Infinite direct sum of Hilbert spaces,Infinite direct sum of Hilbert spaces,,"Let $\{H_i\}_{i \in I}$ be an infinite collection of Hilbert spaces. I am trying to understand their ""direct sum"" . $\bigoplus H_i$ (algebraic sum) is an inner product space in a straightforward way. It is not, however a Hilbert space .  Let $\overline{\,} : \mathbb{N} \to I$ be an injection, and $\{h_k\}_{k \in \mathbb{N}}$ such that $h_k \in H_{\overline{k}}$. Then the sequence $\sum\limits_{k=1}^n h_k$ is Cauchy, but not convergent when $\sum\limits_{k=1}^\infty \|h_k\|_{H_{\overline{k}}}^2 < \infty$. In fact, I would like to argue that these are the only obstructions to $\bigoplus H_i$ being a Hilbert space. Unfortunately, proving it is beyond me. Let $H \subseteq \prod H_i$ be the subset bounded with respect to the norm $$\|h\| := \sqrt{\sum \|\pi_i(h)\|_{H_i}^2}$$ (The sum is considered infinite if more than countably many $\pi_i(h)$ are non-zero.) I would like to prove that $H$ is an inner product space with the above norm $H$ is complete with respect to the above norm $\bigoplus H_i$ is a dense ""subspace"" of $H$ I'm looking for an accessible reference. I'm currently reading ""Linear Analysis"" by Bollobs, which I find very well-written. He even sets this as an exercise, but with a tone that strongly suggests that $H$ isn't complete:","Let $\{H_i\}_{i \in I}$ be an infinite collection of Hilbert spaces. I am trying to understand their ""direct sum"" . $\bigoplus H_i$ (algebraic sum) is an inner product space in a straightforward way. It is not, however a Hilbert space .  Let $\overline{\,} : \mathbb{N} \to I$ be an injection, and $\{h_k\}_{k \in \mathbb{N}}$ such that $h_k \in H_{\overline{k}}$. Then the sequence $\sum\limits_{k=1}^n h_k$ is Cauchy, but not convergent when $\sum\limits_{k=1}^\infty \|h_k\|_{H_{\overline{k}}}^2 < \infty$. In fact, I would like to argue that these are the only obstructions to $\bigoplus H_i$ being a Hilbert space. Unfortunately, proving it is beyond me. Let $H \subseteq \prod H_i$ be the subset bounded with respect to the norm $$\|h\| := \sqrt{\sum \|\pi_i(h)\|_{H_i}^2}$$ (The sum is considered infinite if more than countably many $\pi_i(h)$ are non-zero.) I would like to prove that $H$ is an inner product space with the above norm $H$ is complete with respect to the above norm $\bigoplus H_i$ is a dense ""subspace"" of $H$ I'm looking for an accessible reference. I'm currently reading ""Linear Analysis"" by Bollobs, which I find very well-written. He even sets this as an exercise, but with a tone that strongly suggests that $H$ isn't complete:",,"['functional-analysis', 'reference-request']"
65,Showing that the dual of Banach space $l^1$ is $l^{\infty}$,Showing that the dual of Banach space  is,l^1 l^{\infty},"I'm trying to show that the dual of Banach space $l^1$ is isometrically isomorphic $l^{\infty}$. I've defined a linear map  $F: (l^1)^* \to l^{\infty}$ by $F(y)(x) = \sum x_n y_n$. So far I've shown that this map is well-defined and linear in x and y. Now I'm trying to show that it is norm-preserving. I can easily show that $|F(y)| \le \|y\|_{\infty} \|x\|_1$ as this is immediate from the definition. I'm now trying to show the other direction of the inequality. So far I have: Suppose $M$ is such that $|F(y) (x)| \le M\|x\|_1$. I want to try and choose a particular sequence $x$ so that $M$ must necessarily be greater than $\|y\|_{\infty}$ and then the inf over all $M$ must then be greater than $\|y\|_{\infty}$ and I will have the result. The only thing I have tried so far is the sequence $X = (1,1,...1,0,...)$ with 1's up to the nth place but unfortunately I cannot get this to work. Thanks","I'm trying to show that the dual of Banach space $l^1$ is isometrically isomorphic $l^{\infty}$. I've defined a linear map  $F: (l^1)^* \to l^{\infty}$ by $F(y)(x) = \sum x_n y_n$. So far I've shown that this map is well-defined and linear in x and y. Now I'm trying to show that it is norm-preserving. I can easily show that $|F(y)| \le \|y\|_{\infty} \|x\|_1$ as this is immediate from the definition. I'm now trying to show the other direction of the inequality. So far I have: Suppose $M$ is such that $|F(y) (x)| \le M\|x\|_1$. I want to try and choose a particular sequence $x$ so that $M$ must necessarily be greater than $\|y\|_{\infty}$ and then the inf over all $M$ must then be greater than $\|y\|_{\infty}$ and I will have the result. The only thing I have tried so far is the sequence $X = (1,1,...1,0,...)$ with 1's up to the nth place but unfortunately I cannot get this to work. Thanks",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
66,Is the $\sigma$-finiteness condition necessary to ensure that $L^p(\mu)$ is reflexive?,Is the -finiteness condition necessary to ensure that  is reflexive?,\sigma L^p(\mu),"Suppose $(X,\mu)$ is a measure space, and $p,q>0$ such that $1/p+1/q=1$. We know that if $\mu$ is $\sigma$-finite, then $L^p(\mu)$, $L^q(\mu)$ are reflexive and dual to each other. The proof could be found in Rudin's Real and Complex Analysis or Stein's Real Analysis , based on Radon-Nikodym's theorem. However, I see another proof from Brezis's book, although with assumption that $X=\Omega\subseteq\mathbb R^n$ is open and $\mu$ is the Lebesgue measure, it seems that the proof could be generalized to the case that $(X,\mu)$ is any measure space, no matter whether $\mu$ is $\sigma$-finite. For simplicity, we assume that $p\ge2$ and we only show that $L^p(\mu)$ is reflexive. We know from Rudin's text that $L^p(\mu)$ is a Banach space, no matter whether $\mu$ is $\sigma$-finite. The proof that $L^p(\mu)$ is reflexive is outlined as follows: Clarkson's inequality: $$\left\lVert\frac{f+g}2\right\rVert_{L^p}^p+\left\lVert\frac{f-g}2\right\rVert_{L^p}^p\le\frac12\left(\lVert f\rVert_{L^p}^p+\lVert g\rVert_{L^p}^p\right)$$ $L^p(\mu)$ is uniformly convex, therefore reflexive. I don't know where $\sigma$-finiteness is implicitly used here, or it's applicable to the case that $\mu$ is not $\sigma$-finite. I need some help. Thanks!","Suppose $(X,\mu)$ is a measure space, and $p,q>0$ such that $1/p+1/q=1$. We know that if $\mu$ is $\sigma$-finite, then $L^p(\mu)$, $L^q(\mu)$ are reflexive and dual to each other. The proof could be found in Rudin's Real and Complex Analysis or Stein's Real Analysis , based on Radon-Nikodym's theorem. However, I see another proof from Brezis's book, although with assumption that $X=\Omega\subseteq\mathbb R^n$ is open and $\mu$ is the Lebesgue measure, it seems that the proof could be generalized to the case that $(X,\mu)$ is any measure space, no matter whether $\mu$ is $\sigma$-finite. For simplicity, we assume that $p\ge2$ and we only show that $L^p(\mu)$ is reflexive. We know from Rudin's text that $L^p(\mu)$ is a Banach space, no matter whether $\mu$ is $\sigma$-finite. The proof that $L^p(\mu)$ is reflexive is outlined as follows: Clarkson's inequality: $$\left\lVert\frac{f+g}2\right\rVert_{L^p}^p+\left\lVert\frac{f-g}2\right\rVert_{L^p}^p\le\frac12\left(\lVert f\rVert_{L^p}^p+\lVert g\rVert_{L^p}^p\right)$$ $L^p(\mu)$ is uniformly convex, therefore reflexive. I don't know where $\sigma$-finiteness is implicitly used here, or it's applicable to the case that $\mu$ is not $\sigma$-finite. I need some help. Thanks!",,"['functional-analysis', 'measure-theory', 'lp-spaces']"
67,Bound the norm of the partial trace of an operator on a Hilbert space,Bound the norm of the partial trace of an operator on a Hilbert space,,"Let $H=H_1 \otimes H_2$ a composite Hilbert space and let $A, B$ bounded linear operators on $H$, and we can assume they are trace class. Let $A_2$ we denote the operator on $H_2$ obtained by taking the partial trace on $H_1$, i.e. $A_2 = \mathrm{tr}_1 (A) \in B(H_2)$. Assume that we know there is some $\varepsilon > 0$ so that $$ ||A-B||_{B(H)} < \varepsilon. $$ Can we deduce a similar bound for $$ ||A_2 - B_2 ||_{B(H_2)} ? $$ Notes : 1) The finite dimensional case $\dim (H_1) = n_1$, $\dim (H_2) = n_2$, $\dim (H) = n$ all finite would be fine (but if you have a hint or source for an answer in the general case I'd appreciate!). 2) (My approach) Choose the Frobenius (or Hilbert-Schmidt) norm, $$ ||A||_{B(H)} = \sqrt{\mathrm{tr}(A^\dagger A)}$$ and let $C=A-B$. We know that $ ||I_1 \otimes C_2 ||_{B(H)} = ||I_1||_{B(H_1)} ||C_2||_{B(H_2)}$ (cf. Reed Simon Vol. 1 page 299), then  $$ \begin{array}{rcl} ||C_2||_{B(H_2)} &=& \frac{1}{\sqrt{n_1}} ||I_1 \otimes C_2||_{B(H)} \\ &=& \frac{1}{\sqrt{n_1}} ||C - (I_1 \otimes C_2) - C ||_{B(H)} \\ &\leq& \frac{\varepsilon}{\sqrt{n_1}} + \frac{1}{\sqrt{n_1}} ||C - (I_1 \otimes C_2)||_{B(H)}  \end{array} $$ and expect to bound the term on the right by $\alpha ||C||_{B(H)}$. To see what is going on I put $$ C = C^{(1)}_1 \otimes C^{(2)}_1 + C^{(1)}_2 \otimes C^{(2)}_2  $$ (taking enough terms of these form should be fine to represent an arbitrary $C$). A calculation gives $$ ||C - (I_1 \otimes C_2)||_{B(H)} = ||(C^{(1)}_1 - (\mathrm{tr} C^{(1)}_1) I_1)\otimes C_1^{(2)} + (C^{(1)}_2 - (\mathrm{tr} C^{(1)}_2) I_1)\otimes C_2^{(2)}||_{B(H)} $$ how close this is to $||C||_{B(H)}$?","Let $H=H_1 \otimes H_2$ a composite Hilbert space and let $A, B$ bounded linear operators on $H$, and we can assume they are trace class. Let $A_2$ we denote the operator on $H_2$ obtained by taking the partial trace on $H_1$, i.e. $A_2 = \mathrm{tr}_1 (A) \in B(H_2)$. Assume that we know there is some $\varepsilon > 0$ so that $$ ||A-B||_{B(H)} < \varepsilon. $$ Can we deduce a similar bound for $$ ||A_2 - B_2 ||_{B(H_2)} ? $$ Notes : 1) The finite dimensional case $\dim (H_1) = n_1$, $\dim (H_2) = n_2$, $\dim (H) = n$ all finite would be fine (but if you have a hint or source for an answer in the general case I'd appreciate!). 2) (My approach) Choose the Frobenius (or Hilbert-Schmidt) norm, $$ ||A||_{B(H)} = \sqrt{\mathrm{tr}(A^\dagger A)}$$ and let $C=A-B$. We know that $ ||I_1 \otimes C_2 ||_{B(H)} = ||I_1||_{B(H_1)} ||C_2||_{B(H_2)}$ (cf. Reed Simon Vol. 1 page 299), then  $$ \begin{array}{rcl} ||C_2||_{B(H_2)} &=& \frac{1}{\sqrt{n_1}} ||I_1 \otimes C_2||_{B(H)} \\ &=& \frac{1}{\sqrt{n_1}} ||C - (I_1 \otimes C_2) - C ||_{B(H)} \\ &\leq& \frac{\varepsilon}{\sqrt{n_1}} + \frac{1}{\sqrt{n_1}} ||C - (I_1 \otimes C_2)||_{B(H)}  \end{array} $$ and expect to bound the term on the right by $\alpha ||C||_{B(H)}$. To see what is going on I put $$ C = C^{(1)}_1 \otimes C^{(2)}_1 + C^{(1)}_2 \otimes C^{(2)}_2  $$ (taking enough terms of these form should be fine to represent an arbitrary $C$). A calculation gives $$ ||C - (I_1 \otimes C_2)||_{B(H)} = ||(C^{(1)}_1 - (\mathrm{tr} C^{(1)}_1) I_1)\otimes C_1^{(2)} + (C^{(1)}_2 - (\mathrm{tr} C^{(1)}_2) I_1)\otimes C_2^{(2)}||_{B(H)} $$ how close this is to $||C||_{B(H)}$?",,"['linear-algebra', 'functional-analysis', 'hilbert-spaces']"
68,How to decide completeness of $\ell^\infty$?,How to decide completeness of ?,\ell^\infty,"Let $\ell^\infty$ denote the set of all bounded sequences $x \colon = (\xi_j)_{j=1}^\infty$, $y \colon= (\eta_j)_{j=1}^\infty$ of complex numbers with the metric $d$ defined as follows:  $$ d(x,y) \colon= \sup_{j\in\mathbb{N}} |\xi_j - \eta_j|. $$ Then how to determine if $\ell^\infty$ is complete? My work: Let $(x_n)$, where $x_n \colon= (\xi_j^{(n)})$, be a Cauchy sequence in $\ell^\infty$. Then, given $\epsilon > 0$, there exists an integer $N$ such that $m$, $n > N$ implies that $$d(x_m, x_n) = \sup_{j\in\mathbb{N}} |\xi_j^{(m)} - \xi_j^{(n)}| < \epsilon.$$ So, for each $j \in \mathbb{N}$, we have  $$ |\xi_j^{(m)} - \xi_j^{(n)}| < \epsilon,$$ from which it follows that, for each $j\in \mathbb{N}$, the sequence $(\xi_j^{(n)})_{n=1}^\infty$ is a Cauchy sequence in the complete mertic space $\mathbb{C}$, the set of complex numbers under the usual metric, and hence this sequence is convergent; let  $$\xi_j \colon= \lim_{n\to\infty} \xi_{j}^{(n)} $$ for each $j \in \mathbb{N}$. Let $x \colon= (\xi_j)_{j=1}^\infty$. We now need to show that $x\in \ell^\infty$ and that $x_n \to x$ as $n \to \infty$. In order to show that $x \in \ell^\infty$, we show that $x$ is a bounded sequence. Since $\xi_j^{(n)} \to \xi_j$ as $n \to \infty$, there exists $N_j$ such that $n > N_j$ implies that $$|\xi_j^{(n)} - \xi_j| < \epsilon.$$  And since, for example, $x_{N+1} = (\xi_j^{(N+1)} )_{j=1}^\infty$ is a sequence in $\ell^\infty$, it is a bounded sequence of complex numbers; so there is a non-negative real number $k_{N+1}$ such that  $$ |\xi_j^{(N+1)} | \leq k_{N+1}$$  for each $j \in \mathbb{N}$. Hence, for each $j \in \mathbb{N}$, we have  $$|\xi_j| = | \xi_j - \xi_j^{(N+1)} + \xi_j^{(N+1)} | \leq  | \xi_j - \xi_j^{(N+1)} | + |\xi_j^{(N+1)} | < \epsilon + k_{N+1},$$ which shows that $x \in \ell^\infty$. Am I right so far? Now how to rigorously prove that $(x_n)$ converges to $x$? My effort: Fix $m \in \mathbb{N}$. Then as, for each $j = 1, \ldots, m$, we have  $$ \lim_{n\to\infty} \xi_{j}^{(n)} = \xi_j,$$  so, given $\epsilon > 0$, we can find an integer $M_j$ such that $n > M_j$ implies that  $$|\xi_j^{(n)} - \xi_j| < \frac{\epsilon}{2}. $$ Now let's take $M \colon= \max(M_1, \ldots, M_m)$. Then $n  > M$ implies  $$ |\xi_j^{(n)} - \xi_j| < \frac{\epsilon}{2} $$ for each $j= 1, \ldots, m$. That is, $n > M$ implies that  $$ \sup \{|\xi_j^{(n)} - \xi_j| \colon j = 1, \ldots, m \} \leq \frac{\epsilon}{2}.$$ What next?","Let $\ell^\infty$ denote the set of all bounded sequences $x \colon = (\xi_j)_{j=1}^\infty$, $y \colon= (\eta_j)_{j=1}^\infty$ of complex numbers with the metric $d$ defined as follows:  $$ d(x,y) \colon= \sup_{j\in\mathbb{N}} |\xi_j - \eta_j|. $$ Then how to determine if $\ell^\infty$ is complete? My work: Let $(x_n)$, where $x_n \colon= (\xi_j^{(n)})$, be a Cauchy sequence in $\ell^\infty$. Then, given $\epsilon > 0$, there exists an integer $N$ such that $m$, $n > N$ implies that $$d(x_m, x_n) = \sup_{j\in\mathbb{N}} |\xi_j^{(m)} - \xi_j^{(n)}| < \epsilon.$$ So, for each $j \in \mathbb{N}$, we have  $$ |\xi_j^{(m)} - \xi_j^{(n)}| < \epsilon,$$ from which it follows that, for each $j\in \mathbb{N}$, the sequence $(\xi_j^{(n)})_{n=1}^\infty$ is a Cauchy sequence in the complete mertic space $\mathbb{C}$, the set of complex numbers under the usual metric, and hence this sequence is convergent; let  $$\xi_j \colon= \lim_{n\to\infty} \xi_{j}^{(n)} $$ for each $j \in \mathbb{N}$. Let $x \colon= (\xi_j)_{j=1}^\infty$. We now need to show that $x\in \ell^\infty$ and that $x_n \to x$ as $n \to \infty$. In order to show that $x \in \ell^\infty$, we show that $x$ is a bounded sequence. Since $\xi_j^{(n)} \to \xi_j$ as $n \to \infty$, there exists $N_j$ such that $n > N_j$ implies that $$|\xi_j^{(n)} - \xi_j| < \epsilon.$$  And since, for example, $x_{N+1} = (\xi_j^{(N+1)} )_{j=1}^\infty$ is a sequence in $\ell^\infty$, it is a bounded sequence of complex numbers; so there is a non-negative real number $k_{N+1}$ such that  $$ |\xi_j^{(N+1)} | \leq k_{N+1}$$  for each $j \in \mathbb{N}$. Hence, for each $j \in \mathbb{N}$, we have  $$|\xi_j| = | \xi_j - \xi_j^{(N+1)} + \xi_j^{(N+1)} | \leq  | \xi_j - \xi_j^{(N+1)} | + |\xi_j^{(N+1)} | < \epsilon + k_{N+1},$$ which shows that $x \in \ell^\infty$. Am I right so far? Now how to rigorously prove that $(x_n)$ converges to $x$? My effort: Fix $m \in \mathbb{N}$. Then as, for each $j = 1, \ldots, m$, we have  $$ \lim_{n\to\infty} \xi_{j}^{(n)} = \xi_j,$$  so, given $\epsilon > 0$, we can find an integer $M_j$ such that $n > M_j$ implies that  $$|\xi_j^{(n)} - \xi_j| < \frac{\epsilon}{2}. $$ Now let's take $M \colon= \max(M_1, \ldots, M_m)$. Then $n  > M$ implies  $$ |\xi_j^{(n)} - \xi_j| < \frac{\epsilon}{2} $$ for each $j= 1, \ldots, m$. That is, $n > M$ implies that  $$ \sup \{|\xi_j^{(n)} - \xi_j| \colon j = 1, \ldots, m \} \leq \frac{\epsilon}{2}.$$ What next?",,"['real-analysis', 'analysis', 'functional-analysis', 'metric-spaces', 'cauchy-sequences']"
69,Do $\mathbb{R}^n$ and $\mathbb{C}^n$ valued ordinarily measureable functions form a Banach space under p-norm?,Do  and  valued ordinarily measureable functions form a Banach space under p-norm?,\mathbb{R}^n \mathbb{C}^n,"By measureable function I mean an ""ordinarily"" measureable function, that is measureable in a sense of this definition: a function between measurable spaces is said to be measurable if the preimage of each measurable set is measurable. Let $(X,\ \mathcal{F},\ \mu)$ be a measure space and let $V$ be either $\mathbb{R}^n$ or $\mathbb{C}^n$ with a standard norm $\|v\|=(\sum_{k=1}^n|v_k|^2)^\frac{1}{2}$ for $v=(v_1,\ ...,\ v_n)$ in $V$. Do the measureable functions (where $V$ is equipped with a $\sigma$-algebra of Borel sets of either $\mathbb{R}^n$ or $\mathbb{C}^n$) form a vector space? Let $1\leq p \leq \infty$. For a measureable function $f: X\to V$ we define $$\|f\|_p=(\int\limits_X \|f\|^p\mathrm{d}\mu)^\frac{1}{p}.$$ Do the measureable functions $f$ such that $\|f\|_p<\infty$, after we identify those that are equal almost everywhere, form a Banach space under norm $\|\cdot\|_p$? I ask, because I know this is not true in the case of functions with values in infinite dimensional Banach spaces. There a notion of Bochner measurable function is introduced.","By measureable function I mean an ""ordinarily"" measureable function, that is measureable in a sense of this definition: a function between measurable spaces is said to be measurable if the preimage of each measurable set is measurable. Let $(X,\ \mathcal{F},\ \mu)$ be a measure space and let $V$ be either $\mathbb{R}^n$ or $\mathbb{C}^n$ with a standard norm $\|v\|=(\sum_{k=1}^n|v_k|^2)^\frac{1}{2}$ for $v=(v_1,\ ...,\ v_n)$ in $V$. Do the measureable functions (where $V$ is equipped with a $\sigma$-algebra of Borel sets of either $\mathbb{R}^n$ or $\mathbb{C}^n$) form a vector space? Let $1\leq p \leq \infty$. For a measureable function $f: X\to V$ we define $$\|f\|_p=(\int\limits_X \|f\|^p\mathrm{d}\mu)^\frac{1}{p}.$$ Do the measureable functions $f$ such that $\|f\|_p<\infty$, after we identify those that are equal almost everywhere, form a Banach space under norm $\|\cdot\|_p$? I ask, because I know this is not true in the case of functions with values in infinite dimensional Banach spaces. There a notion of Bochner measurable function is introduced.",,"['functional-analysis', 'measure-theory', 'vector-spaces', 'lp-spaces']"
70,"Example of a function $u\in L^\infty(0,T,H^1)$ such that $u_t\notin L^\infty(0,T,H^1)$",Example of a function  such that,"u\in L^\infty(0,T,H^1) u_t\notin L^\infty(0,T,H^1)","Could someone give me an example of a function $u\in L^\infty(0,T,H^1)$ such that $u_t$ exists (in the distributional sense), $u_t\in L^\infty(0,T,L^2)$ and $u_t\notin L^\infty(0,T,H^1)$? Thanks. EDIT (to add context). Let $f_0\in H^1$. If $u(t)=f_0$ (constant function with respect to $t$) then $u\in L^\infty(0,T,H^1)$ and $u_t\in L^\infty(0,T,H^1)$. If $u(t)=\int_0^t f_0\;dt$, the same occurs. These are simple examples in which I've thought. Essentially, my question is: How to derive $u$ with respect to $t$ affects the regularity of $u(t)$ with respect to $x$? I think that examples can help me to understand it.","Could someone give me an example of a function $u\in L^\infty(0,T,H^1)$ such that $u_t$ exists (in the distributional sense), $u_t\in L^\infty(0,T,L^2)$ and $u_t\notin L^\infty(0,T,H^1)$? Thanks. EDIT (to add context). Let $f_0\in H^1$. If $u(t)=f_0$ (constant function with respect to $t$) then $u\in L^\infty(0,T,H^1)$ and $u_t\in L^\infty(0,T,H^1)$. If $u(t)=\int_0^t f_0\;dt$, the same occurs. These are simple examples in which I've thought. Essentially, my question is: How to derive $u$ with respect to $t$ affects the regularity of $u(t)$ with respect to $x$? I think that examples can help me to understand it.",,"['functional-analysis', 'measure-theory', 'sobolev-spaces', 'distribution-theory']"
71,Questions on Fubini's Theorem and $\sigma$-finite measure?,Questions on Fubini's Theorem and -finite measure?,\sigma,"I asked a question about this a several days ago, but I think I have a better formulated question now.  The reason I did not just edit the last question about this is that I feel the answers I got were helpful, and this time around I have more detail to add. So, if $(X \times Y, \overline{\Sigma \times \tau}, \lambda)$ is a complete measure space, with $\lambda = \mu \times \nu$, then, if $f \in L^{1}(d\lambda)$, Fubini's theorem gives us:  $\int \limits_{X \times Y} f \,d\lambda = \int \limits_{X} \left [ \int \limits_{Y} f \,d\nu \right ] \,d\mu$.  We did not need to assume the space was $\sigma$-finite, because $f \geq 0$ being in $L^{1}(d\lambda)$ allowed us to construct a monotonically increasing sequence of simple functions supported on sets of finite measure which converge to $f$. But, my professor said that $\sigma$-finiteness is hidden in the hypothesis of Fubini's theorem.  Specifically, we proved that the following are equivalent: $\exists f > 0$ measurable such that $f \in L^{1}(d\lambda)$ $\iff$ $\lambda$ is $\sigma$-finite This statement was easy to prove.  Then, my professor said that when we are looking at $f \in L^{1}(d\lambda)$, we have $\int \limits_{X \times Y} f \,d\lambda = \int \limits_{X \times Y} f \chi_{ \{x \mid f(x) \neq 0 \} } \,d\lambda$, and the measure given by $\chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda$ is $\sigma$-finite.  This is because the positive part of $f$, $f^{+}$, is in $L^{1}( \chi_{ \{x \mid f(x) \neq 0 \} } \,d\lambda)$. Question 1: Okay, clearly $f^{+}$ is strictly positive, and also measurable with respect to $\lambda$.  How do I know that it is measurable with respect to $\chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda$? Also how would I show that $f^{+} \in L^{1}( \chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda)$?  I need to show that $\int \limits_{X} f^{+} \,d(\chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda) < \infty$.  I'm not sure how. Question 2: Since we have the above equivalence for $\sigma$-finite measures, given any measure space and any measure $\lambda$, if $f\in L^{1}(d\lambda)$, then the map $f \chi_{ \{ x \mid f(x) > 0 \} }$ is a positive measurable function in $L^{1}(d\lambda)$. So any measure space is $\sigma$-finite by this argument... But that can't be true.  What is wrong with the argument? Answer: This function actually takes the value $0$....","I asked a question about this a several days ago, but I think I have a better formulated question now.  The reason I did not just edit the last question about this is that I feel the answers I got were helpful, and this time around I have more detail to add. So, if $(X \times Y, \overline{\Sigma \times \tau}, \lambda)$ is a complete measure space, with $\lambda = \mu \times \nu$, then, if $f \in L^{1}(d\lambda)$, Fubini's theorem gives us:  $\int \limits_{X \times Y} f \,d\lambda = \int \limits_{X} \left [ \int \limits_{Y} f \,d\nu \right ] \,d\mu$.  We did not need to assume the space was $\sigma$-finite, because $f \geq 0$ being in $L^{1}(d\lambda)$ allowed us to construct a monotonically increasing sequence of simple functions supported on sets of finite measure which converge to $f$. But, my professor said that $\sigma$-finiteness is hidden in the hypothesis of Fubini's theorem.  Specifically, we proved that the following are equivalent: $\exists f > 0$ measurable such that $f \in L^{1}(d\lambda)$ $\iff$ $\lambda$ is $\sigma$-finite This statement was easy to prove.  Then, my professor said that when we are looking at $f \in L^{1}(d\lambda)$, we have $\int \limits_{X \times Y} f \,d\lambda = \int \limits_{X \times Y} f \chi_{ \{x \mid f(x) \neq 0 \} } \,d\lambda$, and the measure given by $\chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda$ is $\sigma$-finite.  This is because the positive part of $f$, $f^{+}$, is in $L^{1}( \chi_{ \{x \mid f(x) \neq 0 \} } \,d\lambda)$. Question 1: Okay, clearly $f^{+}$ is strictly positive, and also measurable with respect to $\lambda$.  How do I know that it is measurable with respect to $\chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda$? Also how would I show that $f^{+} \in L^{1}( \chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda)$?  I need to show that $\int \limits_{X} f^{+} \,d(\chi_{ \{x \mid f(x) \neq 0 \} }\,d\lambda) < \infty$.  I'm not sure how. Question 2: Since we have the above equivalence for $\sigma$-finite measures, given any measure space and any measure $\lambda$, if $f\in L^{1}(d\lambda)$, then the map $f \chi_{ \{ x \mid f(x) > 0 \} }$ is a positive measurable function in $L^{1}(d\lambda)$. So any measure space is $\sigma$-finite by this argument... But that can't be true.  What is wrong with the argument? Answer: This function actually takes the value $0$....",,"['real-analysis', 'functional-analysis', 'measure-theory', 'product-space']"
72,Spectrum of a finite rank operator,Spectrum of a finite rank operator,,"If $ T\in B(H)$ is a finite rank operator, then there are orthonormal vectors $e_1,...,e_n$ and vectors $g_1,...,g_n$ such that $Th=\sum_{i=1}^n (h,e_i )g_i$, then we can easily see that $T$ is normal iff $g_i=\lambda_i e_i$ for some scalars $\lambda_1,...,\lambda_n$. Also for every $I=1,...,n$, $e_i\in \ker (T-\lambda_i)$ which shows that $\lambda_i\in \sigma(T)$. For general case, I want to describe what possible subsets of C  could be spectrum of finite rank operators, but   I do not know how should do it. Please hint me.","If $ T\in B(H)$ is a finite rank operator, then there are orthonormal vectors $e_1,...,e_n$ and vectors $g_1,...,g_n$ such that $Th=\sum_{i=1}^n (h,e_i )g_i$, then we can easily see that $T$ is normal iff $g_i=\lambda_i e_i$ for some scalars $\lambda_1,...,\lambda_n$. Also for every $I=1,...,n$, $e_i\in \ker (T-\lambda_i)$ which shows that $\lambda_i\in \sigma(T)$. For general case, I want to describe what possible subsets of C  could be spectrum of finite rank operators, but   I do not know how should do it. Please hint me.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'normed-spaces', 'spectral-theory']"
73,Convergence in $C(X)$ is uniform convergence.,Convergence in  is uniform convergence.,C(X),"I read this the convergence in $C(X)$ is uniform convergence. Where $X$ is compact hausdorff topological space and $$C(X)=\{f:X\to\mathbb{C}\;\mid \; f\ \text{is continuous}\}$$ And  $$\|f\|=\sup\{|f(x)|:x\in X\}$$ What I have done: I suppose $f_n\to f $ pointwise, then for every $\varepsilon>0$ and for every $x\in X$ there exists a positive integer $N$ such that $\forall n\geq N$ we have $$d(f_n(x),f(x))=\|f_n(x)-f(x)\|<\varepsilon$$ then $$\sup_{x\in X}\|f_n(x)-f(x)\|<\varepsilon$$ Then further what I should do? Edited:My question is how to prove that convergence in C(X) is uniform convergence and also  is this because of compactness of $X$ or because of supremum norm?","I read this the convergence in $C(X)$ is uniform convergence. Where $X$ is compact hausdorff topological space and $$C(X)=\{f:X\to\mathbb{C}\;\mid \; f\ \text{is continuous}\}$$ And  $$\|f\|=\sup\{|f(x)|:x\in X\}$$ What I have done: I suppose $f_n\to f $ pointwise, then for every $\varepsilon>0$ and for every $x\in X$ there exists a positive integer $N$ such that $\forall n\geq N$ we have $$d(f_n(x),f(x))=\|f_n(x)-f(x)\|<\varepsilon$$ then $$\sup_{x\in X}\|f_n(x)-f(x)\|<\varepsilon$$ Then further what I should do? Edited:My question is how to prove that convergence in C(X) is uniform convergence and also  is this because of compactness of $X$ or because of supremum norm?",,"['real-analysis', 'functional-analysis', 'uniform-convergence']"
74,*-representations of dense subalgebras,*-representations of dense subalgebras,,Let $H$ be a separable Hilbert space and let $K(H)$ be the C*-algebra of compact operators on $H$. Suppose that $A$ is a *-subalgebra of $K(H)$ which contains all the finite-rank operators. Given a *-representation $\pi\colon A\to B(K)$ on some Hilbert space $K$. Does it follow that $\|\pi(a)\|\leqslant \|a\|_{K(H)}$? I was trying to play with the uniqueness of the *-irreducible representation of $K(H)$ but with no success so far.,Let $H$ be a separable Hilbert space and let $K(H)$ be the C*-algebra of compact operators on $H$. Suppose that $A$ is a *-subalgebra of $K(H)$ which contains all the finite-rank operators. Given a *-representation $\pi\colon A\to B(K)$ on some Hilbert space $K$. Does it follow that $\|\pi(a)\|\leqslant \|a\|_{K(H)}$? I was trying to play with the uniqueness of the *-irreducible representation of $K(H)$ but with no success so far.,,"['functional-analysis', 'operator-algebras']"
75,Unique fixed point of a contraction defined on a closed ball which maps the boundary back into the ball,Unique fixed point of a contraction defined on a closed ball which maps the boundary back into the ball,,"Let $X$ be a Banach space, $r > 0$, $A: K_r(X) \rightarrow X$ a contraction (where $K_r(X)$ is the closed ball of radius $r$ and center $0$ in $X$), with contraction constant $0<q<1$, which also fulfills $A(S_r(X)) \subseteq K_r(X)$ (where $S_r(X)$ is the boundary of $K_r(X)$). Then there exists a unique fixed point of $A$ in $K_r(X)$.","Let $X$ be a Banach space, $r > 0$, $A: K_r(X) \rightarrow X$ a contraction (where $K_r(X)$ is the closed ball of radius $r$ and center $0$ in $X$), with contraction constant $0<q<1$, which also fulfills $A(S_r(X)) \subseteq K_r(X)$ (where $S_r(X)$ is the boundary of $K_r(X)$). Then there exists a unique fixed point of $A$ in $K_r(X)$.",,"['functional-analysis', 'fixed-point-theorems']"
76,Adjoint of sum of two operators,Adjoint of sum of two operators,,Let $A$ be self-adjoint and $B$ symmetric (which means densely defined for me as well) with $A$-bound less than $1$. Does this imply that $(A+iB)^*=A-iB$ ?,Let $A$ be self-adjoint and $B$ symmetric (which means densely defined for me as well) with $A$-bound less than $1$. Does this imply that $(A+iB)^*=A-iB$ ?,,"['functional-analysis', 'operator-theory', 'spectral-theory']"
77,Similarity transformation of a linear operator,Similarity transformation of a linear operator,,I've seen in some books that given a differential operator $$\frac{d}{dx}$$ under a similarity transformation we get $$\frac{d}{dx}\rightarrow T\frac{d}{dx}T^{-1}=\left(\frac{d}{dx}-\frac{\dot{T}}{T}\right)$$ for some function $T(x)$. I'd like to know why this is true. Why are the two operators equivalent?,I've seen in some books that given a differential operator $$\frac{d}{dx}$$ under a similarity transformation we get $$\frac{d}{dx}\rightarrow T\frac{d}{dx}T^{-1}=\left(\frac{d}{dx}-\frac{\dot{T}}{T}\right)$$ for some function $T(x)$. I'd like to know why this is true. Why are the two operators equivalent?,,"['linear-algebra', 'functional-analysis', 'ordinary-differential-equations']"
78,Rudin's 'Principle of Mathematical Analysis' Problem 7.12 [closed],Rudin's 'Principle of Mathematical Analysis' Problem 7.12 [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Suppose $g$ and $f_n$ ($n = 1,2,\ldots$) are defined on $(0,\infty)$, are Riemann-integrable on $[t,T]$ whenever $0 < t < T < \infty$, $|f_n| \leq g$, $f_n \rightarrow f$ uniformly on every compact subset of $(0,\infty)$, and $$ \int_0^{\infty}\,g(x)\,dx < \infty $$ Prove that $$ \lim_{n \rightarrow \infty}\,\int_0^{\infty}\,f_n(x)\,dx = \int_0^{\infty}\,f(x)\,dx $$ I appreciate all your comments, thanks.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Suppose $g$ and $f_n$ ($n = 1,2,\ldots$) are defined on $(0,\infty)$, are Riemann-integrable on $[t,T]$ whenever $0 < t < T < \infty$, $|f_n| \leq g$, $f_n \rightarrow f$ uniformly on every compact subset of $(0,\infty)$, and $$ \int_0^{\infty}\,g(x)\,dx < \infty $$ Prove that $$ \lim_{n \rightarrow \infty}\,\int_0^{\infty}\,f_n(x)\,dx = \int_0^{\infty}\,f(x)\,dx $$ I appreciate all your comments, thanks.",,"['sequences-and-series', 'functional-analysis', 'uniform-convergence']"
79,Does completing a normed space commute with taking quotients?,Does completing a normed space commute with taking quotients?,,"Let $X$ be a normed vector space and $Y \subset X$ a closed subspace. We consider the quotient $X / Y$ and equip it with the quotient norm. Then we may form the completion $\overline{X / Y}$. We compare $\overline{X / Y}$ to the following space: denote by $\overline{X}$ the completion of $X$ and by $\overline{Y} \subset \overline{X}$ the closure of $Y \subset \overline{X}$. Now we form the quotient $\overline{X} / \overline{Y}$ with the quotient norm. Are $\overline{X / Y}$ and $\overline{X} / \overline{Y}$ (naturally) isomorphic, i.e., is there a linear, bijective isometry between them?","Let $X$ be a normed vector space and $Y \subset X$ a closed subspace. We consider the quotient $X / Y$ and equip it with the quotient norm. Then we may form the completion $\overline{X / Y}$. We compare $\overline{X / Y}$ to the following space: denote by $\overline{X}$ the completion of $X$ and by $\overline{Y} \subset \overline{X}$ the closure of $Y \subset \overline{X}$. Now we form the quotient $\overline{X} / \overline{Y}$ with the quotient norm. Are $\overline{X / Y}$ and $\overline{X} / \overline{Y}$ (naturally) isomorphic, i.e., is there a linear, bijective isometry between them?",,"['linear-algebra', 'functional-analysis', 'banach-spaces', 'normed-spaces', 'quotient-spaces']"
80,Sequence spaces,Sequence spaces,,"Suppose the sequence spaces $$d \colon=\left\lbrace \left\lbrace x_n\right\rbrace_{n \in \mathbb{N}} \in \mathbb{K}^{\mathbb{N}} \colon x_n=0 \ \text{for almost all} \ n \right\rbrace$$ and $$\ell^p \colon= \left\lbrace x=\left\lbrace x(n)\right\rbrace_{n \in \mathbb{N}} \in \mathbb{K}^{\mathbb{N}}\colon \sum_{n=1}^{\infty} |x(n)|^p  < \infty \right\rbrace,$$ with $$\|x\|_p \colon = \left( \sum_{n=1}^{\infty} |x(n)|^p \right)^{\frac{1}{p}} \text{for} \ x=\left\lbrace x(n)\right\rbrace_{n \in \mathbb{N}} \in \ell^p.$$ Then it holds that $\overline{d}=\ell^p$. I have constructed and example which confuses me: Let $x_n \colon = \{1,2,3,\ldots,n,0,0, \ldots \} \in d$. Then it follows that  $$ \lim_{n \to \infty} x_n =\{n\}_{n \in \mathbb{N}}$$ and so $\{n\}_{n \in \mathbb{N}} \in \overline{d}$ but $\{n\}_{n \in \mathbb{N}} \notin \ell^p$. Where is my mistake?","Suppose the sequence spaces $$d \colon=\left\lbrace \left\lbrace x_n\right\rbrace_{n \in \mathbb{N}} \in \mathbb{K}^{\mathbb{N}} \colon x_n=0 \ \text{for almost all} \ n \right\rbrace$$ and $$\ell^p \colon= \left\lbrace x=\left\lbrace x(n)\right\rbrace_{n \in \mathbb{N}} \in \mathbb{K}^{\mathbb{N}}\colon \sum_{n=1}^{\infty} |x(n)|^p  < \infty \right\rbrace,$$ with $$\|x\|_p \colon = \left( \sum_{n=1}^{\infty} |x(n)|^p \right)^{\frac{1}{p}} \text{for} \ x=\left\lbrace x(n)\right\rbrace_{n \in \mathbb{N}} \in \ell^p.$$ Then it holds that $\overline{d}=\ell^p$. I have constructed and example which confuses me: Let $x_n \colon = \{1,2,3,\ldots,n,0,0, \ldots \} \in d$. Then it follows that  $$ \lim_{n \to \infty} x_n =\{n\}_{n \in \mathbb{N}}$$ and so $\{n\}_{n \in \mathbb{N}} \in \overline{d}$ but $\{n\}_{n \in \mathbb{N}} \notin \ell^p$. Where is my mistake?",,['sequences-and-series']
81,When is the composition of a function with Dirac delta a valid distribution?,When is the composition of a function with Dirac delta a valid distribution?,,"If $f:\mathbb{R}^k \rightarrow \mathbb{R}$ is nicely behaved, one can view $\delta(f)$ as a distribution (linear functional on $C^{\infty}_c(\mathbb{R}^k)$)- but what if you don't have nicely behaved functions? Is $\delta(xy)$ a valid distribution on $\mathbb{R}^2$? Is it consistent to define $\int f(x,y)\delta(xy)dxdy = \int f(x,0)dx + \int f(0,y)dy$? My motivation is a slightly more sophisticated example: For spinor-helicity variables $\lambda_i,\tilde{\lambda}_i$, $i = 1,2,3$, which are two-component complex vectors, conservation of momentum is enforced by: $$\delta^{2 \times 2}(\lambda_1\tilde{\lambda}_1^{T} + \lambda_2\tilde{\lambda}_2^{T} + \lambda_3\tilde{\lambda}_3^{T})$$ (The expression inside is a $2 \times 2$ matrix with complex entries). However there is a similar 'kink' in this set, comparable to the origin in $xy = 0$ (it occurs when all the $\lambda_i$ are parallel and all the $\tilde{\lambda}_i$ are parallel). Is this a well-defined distribution?","If $f:\mathbb{R}^k \rightarrow \mathbb{R}$ is nicely behaved, one can view $\delta(f)$ as a distribution (linear functional on $C^{\infty}_c(\mathbb{R}^k)$)- but what if you don't have nicely behaved functions? Is $\delta(xy)$ a valid distribution on $\mathbb{R}^2$? Is it consistent to define $\int f(x,y)\delta(xy)dxdy = \int f(x,0)dx + \int f(0,y)dy$? My motivation is a slightly more sophisticated example: For spinor-helicity variables $\lambda_i,\tilde{\lambda}_i$, $i = 1,2,3$, which are two-component complex vectors, conservation of momentum is enforced by: $$\delta^{2 \times 2}(\lambda_1\tilde{\lambda}_1^{T} + \lambda_2\tilde{\lambda}_2^{T} + \lambda_3\tilde{\lambda}_3^{T})$$ (The expression inside is a $2 \times 2$ matrix with complex entries). However there is a similar 'kink' in this set, comparable to the origin in $xy = 0$ (it occurs when all the $\lambda_i$ are parallel and all the $\tilde{\lambda}_i$ are parallel). Is this a well-defined distribution?",,"['functional-analysis', 'measure-theory', 'distribution-theory']"
82,How to show the completeness of the space of Fourier transforms $\mathcal{F}L^{1}$?,How to show the completeness of the space of Fourier transforms ?,\mathcal{F}L^{1},"Consider the space of all Fourier transforms of $L^{1}(\mathbb R),$ that is, $$\mathcal{F}L^{1}=\mathcal{F}L^{1}(\mathbb R):= \{f\in L^{\infty}(\mathbb R):\hat{f}\in L^{1}(\mathbb R)\},$$ with the norm, $\|f\|_{\mathcal{F}(L^{1})}=\|\hat{f}\|_{L^{1}(\mathbb R)}.$ (By uniqueness theorem and using the fact that Fourier transform is a linear, one can deduce that, this is actually a norm) My Question : How to show $\mathcal{F}L^{1}$ is a complete with respect to the above norm ? My attempt : Suppose $\{f_{n}\}_{n\in \mathbb N}$ is a Cauchy sequence in $\mathcal{F}L^{1},$ that is, there is $N\in \mathbb N$, such that, $\|\hat{f_{n}}-\hat{f_{m}}\|_{L^{1}(\mathbb R)}\to 0$, for every $n, m \geq N$; and since $(L^{1}(\mathbb R), \|\cdot\|_{L^{1}(\mathbb R)})$ is complete, there is a $g\in L^{1}(\mathbb R)$, such that, $\|\hat{f_{n}}-g\|_{L^{1}(\mathbb R)}\to 0$ as $n\to \infty.$ We must find,  $h\in \mathcal{F}L^{1}$ such that $\|f_{n}-h\|_{\mathcal{F}L^{1}}\to 0$ as $n\to \infty.$ Now my guess work is that, we should take, $h:=\check{g}$; but then the problem is: can we expect, $\hat{h}=g$ (I know this one can expect, if both $f$ and $\hat{f}$ both are in $L^{1}(\mathbb R)$, by inversion formula); or am I missing some thing ? Thanks,","Consider the space of all Fourier transforms of $L^{1}(\mathbb R),$ that is, $$\mathcal{F}L^{1}=\mathcal{F}L^{1}(\mathbb R):= \{f\in L^{\infty}(\mathbb R):\hat{f}\in L^{1}(\mathbb R)\},$$ with the norm, $\|f\|_{\mathcal{F}(L^{1})}=\|\hat{f}\|_{L^{1}(\mathbb R)}.$ (By uniqueness theorem and using the fact that Fourier transform is a linear, one can deduce that, this is actually a norm) My Question : How to show $\mathcal{F}L^{1}$ is a complete with respect to the above norm ? My attempt : Suppose $\{f_{n}\}_{n\in \mathbb N}$ is a Cauchy sequence in $\mathcal{F}L^{1},$ that is, there is $N\in \mathbb N$, such that, $\|\hat{f_{n}}-\hat{f_{m}}\|_{L^{1}(\mathbb R)}\to 0$, for every $n, m \geq N$; and since $(L^{1}(\mathbb R), \|\cdot\|_{L^{1}(\mathbb R)})$ is complete, there is a $g\in L^{1}(\mathbb R)$, such that, $\|\hat{f_{n}}-g\|_{L^{1}(\mathbb R)}\to 0$ as $n\to \infty.$ We must find,  $h\in \mathcal{F}L^{1}$ such that $\|f_{n}-h\|_{\mathcal{F}L^{1}}\to 0$ as $n\to \infty.$ Now my guess work is that, we should take, $h:=\check{g}$; but then the problem is: can we expect, $\hat{h}=g$ (I know this one can expect, if both $f$ and $\hat{f}$ both are in $L^{1}(\mathbb R)$, by inversion formula); or am I missing some thing ? Thanks,",,"['functional-analysis', 'metric-spaces', 'fourier-analysis', 'lp-spaces', 'harmonic-analysis']"
83,Norm of a functional on square integrable harmonic functions,Norm of a functional on square integrable harmonic functions,,"Let H be the Hilbert space of square integrable (real) harmonic functions on the unit disk of the complex plane. I want to find the norm of the linear functional $$h\mapsto h_x(0)$$ Here is my proof that this functional is bounded. The partial derivative $\frac{\partial h}{\partial x}(z)$ is also harmonic, therefore by the mean value propery and Green's theorem we have $$\frac{\partial h}{\partial x}(0)=\frac{1}{\pi r^2}\int_{D(0,r)} \frac{\partial h}{\partial x}(x,y)dxdy= \frac{1}{\pi r^2} \int_{\partial D(0,r)}hdy  $$ $$= \frac{1}{\pi r^2} \int_0^{2\pi} h(re^{it})r \cos tdt$$ This implies $$ r^2|\frac{\partial h}{\partial x}(0)|\leq \frac{1}{\pi}\int_0^{2\pi} |h(re^{it})|rdt$$ and integrating from $0$ to $R$ yields $$\frac{R^3}{3}|\frac{\partial h}{\partial x}(0)|\leq \frac{1}{\pi}\int_{D(0,R)}|h(w)|dA(w) $$ By Cauchy Schwarz we have $$|\frac{\partial h}{\partial x}(0)|\leq\frac{3}{\pi R^3} (\pi R^2)^{1/2} \int_{D(0,R)} |h(w)|^2dA(w)=\frac{3}{\sqrt{\pi}R^2}\int_{\mathbb D}|h(w)|^2dA(w)$$ Letting $R\to 1$ gives that the operator norm is $\leq  3/\sqrt{\pi}$. However, this is not the best constant. I tried harmonic functions of the form $ax+by$ which have $L^2$ norm $(a^2+b^2)^{1/2} \sqrt{\pi}/2$. In particular, for $h(z)=x$ we get $\|h\|_2= \sqrt\pi/2$ .","Let H be the Hilbert space of square integrable (real) harmonic functions on the unit disk of the complex plane. I want to find the norm of the linear functional $$h\mapsto h_x(0)$$ Here is my proof that this functional is bounded. The partial derivative $\frac{\partial h}{\partial x}(z)$ is also harmonic, therefore by the mean value propery and Green's theorem we have $$\frac{\partial h}{\partial x}(0)=\frac{1}{\pi r^2}\int_{D(0,r)} \frac{\partial h}{\partial x}(x,y)dxdy= \frac{1}{\pi r^2} \int_{\partial D(0,r)}hdy  $$ $$= \frac{1}{\pi r^2} \int_0^{2\pi} h(re^{it})r \cos tdt$$ This implies $$ r^2|\frac{\partial h}{\partial x}(0)|\leq \frac{1}{\pi}\int_0^{2\pi} |h(re^{it})|rdt$$ and integrating from $0$ to $R$ yields $$\frac{R^3}{3}|\frac{\partial h}{\partial x}(0)|\leq \frac{1}{\pi}\int_{D(0,R)}|h(w)|dA(w) $$ By Cauchy Schwarz we have $$|\frac{\partial h}{\partial x}(0)|\leq\frac{3}{\pi R^3} (\pi R^2)^{1/2} \int_{D(0,R)} |h(w)|^2dA(w)=\frac{3}{\sqrt{\pi}R^2}\int_{\mathbb D}|h(w)|^2dA(w)$$ Letting $R\to 1$ gives that the operator norm is $\leq  3/\sqrt{\pi}$. However, this is not the best constant. I tried harmonic functions of the form $ax+by$ which have $L^2$ norm $(a^2+b^2)^{1/2} \sqrt{\pi}/2$. In particular, for $h(z)=x$ we get $\|h\|_2= \sqrt\pi/2$ .",,"['real-analysis', 'complex-analysis', 'functional-analysis']"
84,continuous depence of the spectrum on elements,continuous depence of the spectrum on elements,,"Suppose $a_n \to a$ in a unital $C^*$-algebra $A$. If $\lambda_n \in \sigma(a_n)$ converges to $\lambda \in \mathbb{C}$, then $\lambda \in \sigma(a)$. Does the converse hold? So if $\lambda \in \sigma(a)$, does there exist a sequence $\lambda_n \in \sigma(a_n)$ with $\lambda_n \to \lambda$? I'm positive that it holds if $\dim(A) < \infty$, and if $A$ is commutative, but in the general case I don't see a proof. Perhaps some additional assumptions are necessary?","Suppose $a_n \to a$ in a unital $C^*$-algebra $A$. If $\lambda_n \in \sigma(a_n)$ converges to $\lambda \in \mathbb{C}$, then $\lambda \in \sigma(a)$. Does the converse hold? So if $\lambda \in \sigma(a)$, does there exist a sequence $\lambda_n \in \sigma(a_n)$ with $\lambda_n \to \lambda$? I'm positive that it holds if $\dim(A) < \infty$, and if $A$ is commutative, but in the general case I don't see a proof. Perhaps some additional assumptions are necessary?",,"['functional-analysis', 'operator-algebras']"
85,Positive compact operator has unique square root.,Positive compact operator has unique square root.,,"Let H be a hilbert space and T be a compact positive operator so that by the spectral decomposition theorem,  $T=\sum_{n=1}^{\infty}{\lambda}_{n}\langle x,e_{n}\rangle e_{n}$ where the $e_{n}$ are the eigenvectors of T and form an orthonormal basis. I have shown that T has a positive square root namely $S=\sum_{n=1}^{\infty}{\lambda}_{n}^{0.5}\langle x,e_{n}\rangle e_{n}$. I am trying to show S is unique. My attempt : Suppose that $L$ is positive with $L^2=T$.Then since $L$ commutes with $T$ it is invariant on it's eigenspaces. So given $e_{n}$ there is an $m$ such that $e_{m}$ is associated to the same eigenvalue, ${\lambda}$ as $e_{n}$ and $L(e_{n})={\alpha}e_{m}$ for some ${\alpha}$. Note that since each eigenvalue may be associated to more than one eigenvector, we cannot assume $n=m$. From there I'm stuck Thanks","Let H be a hilbert space and T be a compact positive operator so that by the spectral decomposition theorem,  $T=\sum_{n=1}^{\infty}{\lambda}_{n}\langle x,e_{n}\rangle e_{n}$ where the $e_{n}$ are the eigenvectors of T and form an orthonormal basis. I have shown that T has a positive square root namely $S=\sum_{n=1}^{\infty}{\lambda}_{n}^{0.5}\langle x,e_{n}\rangle e_{n}$. I am trying to show S is unique. My attempt : Suppose that $L$ is positive with $L^2=T$.Then since $L$ commutes with $T$ it is invariant on it's eigenspaces. So given $e_{n}$ there is an $m$ such that $e_{m}$ is associated to the same eigenvalue, ${\lambda}$ as $e_{n}$ and $L(e_{n})={\alpha}e_{m}$ for some ${\alpha}$. Note that since each eigenvalue may be associated to more than one eigenvector, we cannot assume $n=m$. From there I'm stuck Thanks",,"['linear-algebra', 'functional-analysis']"
86,A inequality of calculus [duplicate],A inequality of calculus [duplicate],,"This question already has answers here : How prove this $\int_{a}^{b}[f''(x)]^2dx\ge\dfrac{4}{b-a}$ (4 answers) Closed 10 years ago . Let $f \in C^2[a,b]$ and $f(a) = f(b) = 0$, $f'(a) = 1$,$f'(b) = 0$, prove that $$\int_a^b|f''(x)|^2\,dx \geq \frac{4}{b-a}$$ Remark: This question is in the book functional analysis of Peking University; We have$$u(x) = \int_a^xu'(t)\,dt$$so $|u(x)|^2 \leq (b-a)\int_a^bu'(x)\,dx$ by applying the Cauthy-Schwartz inequality. but I cannot get the number 4 I have construct a function of which satisfies the condition using quadratic functionand the infimum is attained, and $4$ is got from differentiating and squaring.","This question already has answers here : How prove this $\int_{a}^{b}[f''(x)]^2dx\ge\dfrac{4}{b-a}$ (4 answers) Closed 10 years ago . Let $f \in C^2[a,b]$ and $f(a) = f(b) = 0$, $f'(a) = 1$,$f'(b) = 0$, prove that $$\int_a^b|f''(x)|^2\,dx \geq \frac{4}{b-a}$$ Remark: This question is in the book functional analysis of Peking University; We have$$u(x) = \int_a^xu'(t)\,dt$$so $|u(x)|^2 \leq (b-a)\int_a^bu'(x)\,dx$ by applying the Cauthy-Schwartz inequality. but I cannot get the number 4 I have construct a function of which satisfies the condition using quadratic functionand the infimum is attained, and $4$ is got from differentiating and squaring.",,"['calculus', 'functional-analysis', 'inequality']"
87,Hahn-Banach separation theorem for Hilbert spaces,Hahn-Banach separation theorem for Hilbert spaces,,What is the strongest form of the Hahn-Banach separation theorem for Hilbert spaces? Could you please provide a reference?,What is the strongest form of the Hahn-Banach separation theorem for Hilbert spaces? Could you please provide a reference?,,"['functional-analysis', 'convex-analysis', 'hilbert-spaces']"
88,Isometry between $l^p$ and $L^p$.,Isometry between  and .,l^p L^p,"Consider $p\in[1,\infty)$ and the operator $T:l^p\rightarrow L^p([0,\infty))$: $$ Tx=\sum_{n=1}^\infty x_n\chi_{[n-1,n]} \qquad\forall\,x\in(x_1,x_2,\ldots,)\in l^p $$ Prove that $T$ is an isometry. My idea was to start with the definitions of the norms: $$ ||x||_{l^p}^p=\sum_{n\in\mathbb{N}}|x_n|^p=\sum_{n\in\mathbb{N}}\int_0^\infty|\chi_{[n-1,n]}x_n|^p\,d\mu = (\cdots) = \int_0^\infty|\sum_{n\in\mathbb{N}}x_n\chi_{[n-1,n]}|^pd\mu=||Tx||_{L^p}^p $$ I miss the central part and I'm not sure it is possibile to ""connect"" the norms in this way. I tried to think about some theorem about limits-integrals exchange but I didn't find anything. Or is it better to prove both the inequatilities between the norms?","Consider $p\in[1,\infty)$ and the operator $T:l^p\rightarrow L^p([0,\infty))$: $$ Tx=\sum_{n=1}^\infty x_n\chi_{[n-1,n]} \qquad\forall\,x\in(x_1,x_2,\ldots,)\in l^p $$ Prove that $T$ is an isometry. My idea was to start with the definitions of the norms: $$ ||x||_{l^p}^p=\sum_{n\in\mathbb{N}}|x_n|^p=\sum_{n\in\mathbb{N}}\int_0^\infty|\chi_{[n-1,n]}x_n|^p\,d\mu = (\cdots) = \int_0^\infty|\sum_{n\in\mathbb{N}}x_n\chi_{[n-1,n]}|^pd\mu=||Tx||_{L^p}^p $$ I miss the central part and I'm not sure it is possibile to ""connect"" the norms in this way. I tried to think about some theorem about limits-integrals exchange but I didn't find anything. Or is it better to prove both the inequatilities between the norms?",,"['functional-analysis', 'operator-theory']"
89,Unitary Operator bounded?,Unitary Operator bounded?,,"Please read all before giving an answer... Suppose you're given a densely defined not necessarily bounded operator: $\overline{\mathcal{D}(T)}=\mathcal{H}$ Moreover, assume it is injective: $\mathcal{N}(T)=\{0\}$ Now, imagine it has the property: $T^*Tx=x,x\in\mathcal{D}(T^*T)$ My point is now, it might happen that: $\mathcal{D}(T^*)=\{0\}$ So in this case the above equation seems trivially true as: $\mathcal{D}(T^*T)=\mathcal{N}(T)=\{0\}$ It is not clear to me wether this situation in particular can occur, but is it possible that sth. seemingly similar can happen, so that the above property does not apply preservation of the scalar product? ...clearly, such an operator must be unbounded otherwise one could extend the domain to all of the Hilbert Space, the adjoint would then be defined everywhere as well and in return the property above would imply preservation of the scalar oroduct by construction...","Please read all before giving an answer... Suppose you're given a densely defined not necessarily bounded operator: $\overline{\mathcal{D}(T)}=\mathcal{H}$ Moreover, assume it is injective: $\mathcal{N}(T)=\{0\}$ Now, imagine it has the property: $T^*Tx=x,x\in\mathcal{D}(T^*T)$ My point is now, it might happen that: $\mathcal{D}(T^*)=\{0\}$ So in this case the above equation seems trivially true as: $\mathcal{D}(T^*T)=\mathcal{N}(T)=\{0\}$ It is not clear to me wether this situation in particular can occur, but is it possible that sth. seemingly similar can happen, so that the above property does not apply preservation of the scalar product? ...clearly, such an operator must be unbounded otherwise one could extend the domain to all of the Hilbert Space, the adjoint would then be defined everywhere as well and in return the property above would imply preservation of the scalar oroduct by construction...",,"['functional-analysis', 'adjoint-operators']"
90,Riesz Representation Theorem for functions in $C_0(X)$,Riesz Representation Theorem for functions in,C_0(X),"I've been analyzing the proof of Riesz Representation Theorem as presented in Rudin's book for Real and Complex Analysis as Theorem 6.19 and found some steps confusing. First I'd like to know why we can assume that $||\Phi||=1$. It seems to be vital step for proof but it's not fully clear for me why we do so. My first thought was that we can consider functions divided by measure of $X$, since they still belong to $C_0(X)$ and furthermore complex measure can take only finite values. Thus we have $f:=g/\mu(X)$ and $$|\Phi f| \leqslant \int_X |f| d\mu= \frac{1}{|\mu(X)|} \int_X |g| d\mu \leqslant 1$$ for some $g\in C_0(X)$ with sup norm $||g||\leqslant 1$ Is this valid argument? Second thing is why we can write $$\lambda(X)=\sup\{\Lambda f: 0\leqslant f\leqslant 1\; f\in C_c(X)\}?$$ It's obvious that $\sup\{\Lambda f: 0\leqslant f\leqslant 1\; f\in C_c(X)\} \leqslant \lambda(X)$, but how can I prove opposite inequality? These may seem really trivial questions, yet I cannot figure them out. Thanks in advance, K.","I've been analyzing the proof of Riesz Representation Theorem as presented in Rudin's book for Real and Complex Analysis as Theorem 6.19 and found some steps confusing. First I'd like to know why we can assume that $||\Phi||=1$. It seems to be vital step for proof but it's not fully clear for me why we do so. My first thought was that we can consider functions divided by measure of $X$, since they still belong to $C_0(X)$ and furthermore complex measure can take only finite values. Thus we have $f:=g/\mu(X)$ and $$|\Phi f| \leqslant \int_X |f| d\mu= \frac{1}{|\mu(X)|} \int_X |g| d\mu \leqslant 1$$ for some $g\in C_0(X)$ with sup norm $||g||\leqslant 1$ Is this valid argument? Second thing is why we can write $$\lambda(X)=\sup\{\Lambda f: 0\leqslant f\leqslant 1\; f\in C_c(X)\}?$$ It's obvious that $\sup\{\Lambda f: 0\leqslant f\leqslant 1\; f\in C_c(X)\} \leqslant \lambda(X)$, but how can I prove opposite inequality? These may seem really trivial questions, yet I cannot figure them out. Thanks in advance, K.",,"['functional-analysis', 'banach-spaces', 'riesz-representation-theorem']"
91,Relation between $L^1(\partial\Omega)$ and the surface integral on $C^1$ domains,Relation between  and the surface integral on  domains,L^1(\partial\Omega) C^1,"Let $\Omega \subset \mathbb{R}^n$ be a $C^{1}$ bounded domain. It is possible to define the space $L^1(\partial\Omega)$ as the set of functions $u\colon \partial\Omega \to \mathbb{R}$ with the finite norm $$\lVert u \rVert_{L^1(\partial\Omega)} := \sum_i\lVert {\phi_i(u\circ g_i)}\rVert_{L^1(B_i)}$$ where $\phi_i$ partition of unity, $g_i$ is a $C^1$ diffeomorphism and $B_i$ are subsets of $\mathbb{R}^{n}$. There are lots of definitions like this (eg. see Renardy and Rogers, Krylov, James Robinson's Infinite Dimensional Dynamical System) or with small variations. There is also the surface integral of a function $v\colon \partial\Omega \to \mathbb{R}$: $$|u| := \int_{\partial \Omega}fdS$$ where $dS$ is the surface density. To compute this quantity, we need to use a parametrisation. Now my question, is it always the case that $$\lVert u \rVert_{L^1(\partial\Omega)} \qquad\text{and}\qquad |u|$$ are equivalent? Does this hold for all the little variations of the $L^1$ norm in the first equation?? Now when we have a Lipschitz surface, these norms are equivalent (see Necas). BUT their definition of the $L^1$ norm is different so let us not use that result here. Edit : hmm, it seems $C^1$ domains are not a subset of Lipschitz domains.","Let $\Omega \subset \mathbb{R}^n$ be a $C^{1}$ bounded domain. It is possible to define the space $L^1(\partial\Omega)$ as the set of functions $u\colon \partial\Omega \to \mathbb{R}$ with the finite norm $$\lVert u \rVert_{L^1(\partial\Omega)} := \sum_i\lVert {\phi_i(u\circ g_i)}\rVert_{L^1(B_i)}$$ where $\phi_i$ partition of unity, $g_i$ is a $C^1$ diffeomorphism and $B_i$ are subsets of $\mathbb{R}^{n}$. There are lots of definitions like this (eg. see Renardy and Rogers, Krylov, James Robinson's Infinite Dimensional Dynamical System) or with small variations. There is also the surface integral of a function $v\colon \partial\Omega \to \mathbb{R}$: $$|u| := \int_{\partial \Omega}fdS$$ where $dS$ is the surface density. To compute this quantity, we need to use a parametrisation. Now my question, is it always the case that $$\lVert u \rVert_{L^1(\partial\Omega)} \qquad\text{and}\qquad |u|$$ are equivalent? Does this hold for all the little variations of the $L^1$ norm in the first equation?? Now when we have a Lipschitz surface, these norms are equivalent (see Necas). BUT their definition of the $L^1$ norm is different so let us not use that result here. Edit : hmm, it seems $C^1$ domains are not a subset of Lipschitz domains.",,"['functional-analysis', 'differential-geometry', 'partial-differential-equations', 'banach-spaces', 'sobolev-spaces']"
92,Compactness of integral operator,Compactness of integral operator,,"I need some help with this exercise. Let $f\in C^0_b(R^2)$ and consider the operator $[T(v)](x)=\int_0^x f(x,y)v(y)dy$ for every $x\in R$. Is this a compact operator $T:C^0[0,1]\rightarrow C^1[0,1]$? I think Ascoli Arzel theorem might be useful. So, let $(v_n)$ be a bounded sequence in $C^0[0,1]$, $||v_n||<c$ for every $n$. I want to prove that the family of functions $\mathcal F=(Tv_n)\subset C^1[0,1]$ is equibounded and equicontinous. I have proved that it is equibounded, but I have some problems with equicontinuity. Let $x,z\in[0,1]$, and suppose $z>x$, we also know that $|f|<M$. Now $|Tv_n(x)-Tv_n(z)|=|\int_0^x f(x,y)v_n(y)dy-\int_0^z f(z,y)v_n(y)dy|=|\int_0^xf(x,y)v_n(y)dy-\int_0^x f(z,y)v_n(y)dy-\int_x^zf(z,y)v_n(y)dy|<\int_0^x|f(x,y)-f(z,y)||v_n(y)|dy+\int_x^z |f(z,y)||v_n(y)|dy$. Now, from continuity and boundedness of $f$, from boundedness of $(v_n)$, we have that $|Tv_n(x)-Tv_n(z)|<c\epsilon x+Mc(z-x)<c(\epsilon+M)$, which is indipendent from $n$ but it is not proportional to $\epsilon$. Any suggestions?","I need some help with this exercise. Let $f\in C^0_b(R^2)$ and consider the operator $[T(v)](x)=\int_0^x f(x,y)v(y)dy$ for every $x\in R$. Is this a compact operator $T:C^0[0,1]\rightarrow C^1[0,1]$? I think Ascoli Arzel theorem might be useful. So, let $(v_n)$ be a bounded sequence in $C^0[0,1]$, $||v_n||<c$ for every $n$. I want to prove that the family of functions $\mathcal F=(Tv_n)\subset C^1[0,1]$ is equibounded and equicontinous. I have proved that it is equibounded, but I have some problems with equicontinuity. Let $x,z\in[0,1]$, and suppose $z>x$, we also know that $|f|<M$. Now $|Tv_n(x)-Tv_n(z)|=|\int_0^x f(x,y)v_n(y)dy-\int_0^z f(z,y)v_n(y)dy|=|\int_0^xf(x,y)v_n(y)dy-\int_0^x f(z,y)v_n(y)dy-\int_x^zf(z,y)v_n(y)dy|<\int_0^x|f(x,y)-f(z,y)||v_n(y)|dy+\int_x^z |f(z,y)||v_n(y)|dy$. Now, from continuity and boundedness of $f$, from boundedness of $(v_n)$, we have that $|Tv_n(x)-Tv_n(z)|<c\epsilon x+Mc(z-x)<c(\epsilon+M)$, which is indipendent from $n$ but it is not proportional to $\epsilon$. Any suggestions?",,"['real-analysis', 'functional-analysis', 'operator-theory', 'compact-operators']"
93,Solving equations where the solution is an operator,Solving equations where the solution is an operator,,"Ok, so here's some context. Solving regular equations we might have something like this: $2 + x = 5$, solving for $x$ we get 3. We might even have an equation like $x + y = 5$ where there are multiple solutions. But what's in common with all these equations is that the process, or the algorithm, we follow to solve them is determined by the operators that show the relations between variables. Now if you think back to very early elementary school, I'm sure you solved stuff like $5 \_ 2 = 3$ where you would fill in the blank with a minus. I'm wondering if there's a branch or mathematics that studies actual systematical ways to solve ""equations"" like that. It might seem trivial from this example but it obviously would grow in complexity. Perhaps the solutions would be operators AND numbers. The concrete problem I thought up that led me to this was trying to find a way to ""map"" any $\frac{1}{n}$ to $\frac{1}{n+1}$ by just adding/multiplying/something the first fraction by a constant. The ""equation"" would look something like this: $\frac{1}{n}\_C=\frac{1}{n+1}$ I can solve similar problems in my head, like: $n\_C=n+1$ where the obvious solution is $+$ and 1. Or for example, $n\_C=2n$ where the solution is $\times$ and 2. The last one can also have $+$ as a solution but then $C$ would have to be $n$ and would no longer be a constant. (I didn't know what to put as the tag)","Ok, so here's some context. Solving regular equations we might have something like this: $2 + x = 5$, solving for $x$ we get 3. We might even have an equation like $x + y = 5$ where there are multiple solutions. But what's in common with all these equations is that the process, or the algorithm, we follow to solve them is determined by the operators that show the relations between variables. Now if you think back to very early elementary school, I'm sure you solved stuff like $5 \_ 2 = 3$ where you would fill in the blank with a minus. I'm wondering if there's a branch or mathematics that studies actual systematical ways to solve ""equations"" like that. It might seem trivial from this example but it obviously would grow in complexity. Perhaps the solutions would be operators AND numbers. The concrete problem I thought up that led me to this was trying to find a way to ""map"" any $\frac{1}{n}$ to $\frac{1}{n+1}$ by just adding/multiplying/something the first fraction by a constant. The ""equation"" would look something like this: $\frac{1}{n}\_C=\frac{1}{n+1}$ I can solve similar problems in my head, like: $n\_C=n+1$ where the obvious solution is $+$ and 1. Or for example, $n\_C=2n$ where the solution is $\times$ and 2. The last one can also have $+$ as a solution but then $C$ would have to be $n$ and would no longer be a constant. (I didn't know what to put as the tag)",,['functional-analysis']
94,continuity of a map on $M(\mathbb{R}^n)$,continuity of a map on,M(\mathbb{R}^n),"Let $M:=M(\mathbb{R}^n)$ be the space of probability measures on $\mathbb{R}^n$ with respect to the Borel $\sigma$-algebra. Let $K\subset M$ be a compact convex subset. $K$ carries a natural topological structure, i.e. the weak topology induced by the bounded continuous functions. I have a continuous function $f:\mathbb{R}^n\to\mathbb{R}$ given such that $$|f(x_1,\dots,x_n)|\le K(1+\sum_{i=1}^n|x_i|)$$ for some constant $K$. I want to verify the continuity of $F:K\to\mathbb{R}$ on $K$, where $$F(\mu):=\int_{\mathbb{R}^n}f d\mu$$ We know that every $\mu\in K$ has marginals $\rho_1,\dots,\rho_n$ with finite first moments. I have two questions: From the finite first moment it should follow: $\int_{\mathbb{R}^n\backslash[-a,a]^n}fd\mu\to 0$ uniformly in $\mu\in K$. Why is this the case? I've never heard the term finite first moment for a measure (just for r.v.) This should prove the continuity of $F$. How exactly?","Let $M:=M(\mathbb{R}^n)$ be the space of probability measures on $\mathbb{R}^n$ with respect to the Borel $\sigma$-algebra. Let $K\subset M$ be a compact convex subset. $K$ carries a natural topological structure, i.e. the weak topology induced by the bounded continuous functions. I have a continuous function $f:\mathbb{R}^n\to\mathbb{R}$ given such that $$|f(x_1,\dots,x_n)|\le K(1+\sum_{i=1}^n|x_i|)$$ for some constant $K$. I want to verify the continuity of $F:K\to\mathbb{R}$ on $K$, where $$F(\mu):=\int_{\mathbb{R}^n}f d\mu$$ We know that every $\mu\in K$ has marginals $\rho_1,\dots,\rho_n$ with finite first moments. I have two questions: From the finite first moment it should follow: $\int_{\mathbb{R}^n\backslash[-a,a]^n}fd\mu\to 0$ uniformly in $\mu\in K$. Why is this the case? I've never heard the term finite first moment for a measure (just for r.v.) This should prove the continuity of $F$. How exactly?",,['functional-analysis']
95,"If $u$ and $v$ have weak derivatives,what about $uv$?","If  and  have weak derivatives,what about ?",u v uv,"$\Omega$ is a domain in $R^n$, Let $u\in L^1_{\text{loc}}(\Omega)$. If there exists $g_i \in  L^1_{\text{loc}}(\Omega)$ such that  $$\int_\Omega g_i \phi \, dx=-\int_\Omega u \frac{\partial \phi_i}{\partial x},\phi \in C_0^\infty(\Omega)$$ Then we say $u$ has weak partial derivatives $g_i$. If $u$ and $v$ have weak partial derivatives, does $uv$ have  weak partial derivatives? Or what conditions should we add to $u$ and $v$?","$\Omega$ is a domain in $R^n$, Let $u\in L^1_{\text{loc}}(\Omega)$. If there exists $g_i \in  L^1_{\text{loc}}(\Omega)$ such that  $$\int_\Omega g_i \phi \, dx=-\int_\Omega u \frac{\partial \phi_i}{\partial x},\phi \in C_0^\infty(\Omega)$$ Then we say $u$ has weak partial derivatives $g_i$. If $u$ and $v$ have weak partial derivatives, does $uv$ have  weak partial derivatives? Or what conditions should we add to $u$ and $v$?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'distribution-theory']"
96,Existence of a Lagrange multiplier (Euler Lagrange equations + holonomic constraints ),Existence of a Lagrange multiplier (Euler Lagrange equations + holonomic constraints ),,"Let $I=[a,b]\subset \mathbb{R}, G:\mathbb{R}^n\to \mathbb{R}^k$ smooth, $0<k<n, M=G^{-1}(0)$. Assume that $DG(x)$ has full rank for all $x\in M$. Fix $p_1,p_2\in M$ and assume $u\in W^{1,\infty}(I,\mathbb{R}^n)$ minimizes the functional given by $$J(u)=\int_a^bF(t,u(t),\dot{u}(t))dt $$ on the set $$S := \{u\in W^{1,\infty}(I,\mathbb{R}^n): u(a)=p_1,u(b)=p_2, u(t)\in M\}.$$ Show there exists a function $\lambda \in W^{1,\infty}(I,\mathbb{R}^k)$ such that $$\frac{d}{dt}F_p(t,u(t),\dot{u}(t)) -F_u(t,u(t),\dot{u}(t))= DG(u(t))^T\lambda(t).$$ I got as $\textbf{hint}$: Near $p\in M$, there are parameterizations $\psi:V\to U\subset M$ where $V\subset \mathbb{R}^{n-k}$ and $U\subset M$ contains $p$. Assume first $\bigcup_t\{u(t)\}\subset U$. Define $w:I\to\mathbb{R}^{n-k}$ by $$w(t) = (\psi^{-1}\circ u)(t) $$ and find a suitable functional $\tilde{J}$ (on a suitable space) which corresponds to $J$ and is minimized by $w$. Use the Euler-Lagrange equations for $\tilde{J}$ and the fact that $DG(\psi(z))D_z\psi(z)=0.$ (for the general case, cover $\bigcup_t\{u(t)\}$ with coordinate patches and localize by subdividing the set into pieces that lie within thise patches). I'm simply trying to prove the simpler case, but I have hard time finding such $\tilde{J}$. I appreciate all the help and suggestions.","Let $I=[a,b]\subset \mathbb{R}, G:\mathbb{R}^n\to \mathbb{R}^k$ smooth, $0<k<n, M=G^{-1}(0)$. Assume that $DG(x)$ has full rank for all $x\in M$. Fix $p_1,p_2\in M$ and assume $u\in W^{1,\infty}(I,\mathbb{R}^n)$ minimizes the functional given by $$J(u)=\int_a^bF(t,u(t),\dot{u}(t))dt $$ on the set $$S := \{u\in W^{1,\infty}(I,\mathbb{R}^n): u(a)=p_1,u(b)=p_2, u(t)\in M\}.$$ Show there exists a function $\lambda \in W^{1,\infty}(I,\mathbb{R}^k)$ such that $$\frac{d}{dt}F_p(t,u(t),\dot{u}(t)) -F_u(t,u(t),\dot{u}(t))= DG(u(t))^T\lambda(t).$$ I got as $\textbf{hint}$: Near $p\in M$, there are parameterizations $\psi:V\to U\subset M$ where $V\subset \mathbb{R}^{n-k}$ and $U\subset M$ contains $p$. Assume first $\bigcup_t\{u(t)\}\subset U$. Define $w:I\to\mathbb{R}^{n-k}$ by $$w(t) = (\psi^{-1}\circ u)(t) $$ and find a suitable functional $\tilde{J}$ (on a suitable space) which corresponds to $J$ and is minimized by $w$. Use the Euler-Lagrange equations for $\tilde{J}$ and the fact that $DG(\psi(z))D_z\psi(z)=0.$ (for the general case, cover $\bigcup_t\{u(t)\}$ with coordinate patches and localize by subdividing the set into pieces that lie within thise patches). I'm simply trying to prove the simpler case, but I have hard time finding such $\tilde{J}$. I appreciate all the help and suggestions.",,"['real-analysis', 'functional-analysis', 'calculus-of-variations']"
97,Using inequalities,Using inequalities,,"UPDATE: Let $x=(x_{n})$ and $y=(y_{n}) \in A$ with $A:=\{x=(x_{n})\in \ell^{2}| \phantom{x} \|x\|\leq 1\}$. Prove that $d:A\times A \rightarrow \mathbb{R}_{+}$ defined by    $$d(x,y)=\sum_{n=1}^{\infty}(1/3)^{n}|x_{n}-y_{n}|$$   is bounded. Let $x,y\in A$ we get \begin{align*} \sum_{n=1}^{\infty}(1/3)^{n}|x_{n}-y_{n}| &\leq \sum_{n=1}^{\infty}(1/3)^{n}(|x_{n}|+|y_{n}|) \phantom{x} (1) \\ &= \sum_{n=1}^{\infty}(1/3)^{n}|x_{n}|+\sum_{n=1}^{\infty}(1/3)^{n}|y_{n}| \phantom{x} (2)\\ &\leq \sqrt{\sum_{n=1}^{\infty}(1/3)^{n}} \sqrt{\sum_{n=1}^{\infty}|x_{n}|^{2}} + \sqrt{\sum_{n=1}^{\infty}(1/3)^{n}} \sqrt{\sum_{n=1}^{\infty}|y_{n}|^{2}} \phantom{x} (3) \\ &= \left(\frac{1}{1-1/3}\right)^{1/2} \|x_{n}\|_{2}+\left(\frac{1}{1-1/3}\right)^{1/2} \|y_{n}\|_{2} \phantom{x} (4)\\ &= \sqrt{3/2} \|x_{n}\|_{2}+\sqrt{3/2} \|y_{n}\|_{2}.\phantom{x} (5) \end{align*} Thus, $d(x,y)$ is bounded. What is used in these steps: (1) Triangle inequality ? (2) What is used here? (3) Cauchy schwarz? (4) and (5) geometric series and standard calculation.","UPDATE: Let $x=(x_{n})$ and $y=(y_{n}) \in A$ with $A:=\{x=(x_{n})\in \ell^{2}| \phantom{x} \|x\|\leq 1\}$. Prove that $d:A\times A \rightarrow \mathbb{R}_{+}$ defined by    $$d(x,y)=\sum_{n=1}^{\infty}(1/3)^{n}|x_{n}-y_{n}|$$   is bounded. Let $x,y\in A$ we get \begin{align*} \sum_{n=1}^{\infty}(1/3)^{n}|x_{n}-y_{n}| &\leq \sum_{n=1}^{\infty}(1/3)^{n}(|x_{n}|+|y_{n}|) \phantom{x} (1) \\ &= \sum_{n=1}^{\infty}(1/3)^{n}|x_{n}|+\sum_{n=1}^{\infty}(1/3)^{n}|y_{n}| \phantom{x} (2)\\ &\leq \sqrt{\sum_{n=1}^{\infty}(1/3)^{n}} \sqrt{\sum_{n=1}^{\infty}|x_{n}|^{2}} + \sqrt{\sum_{n=1}^{\infty}(1/3)^{n}} \sqrt{\sum_{n=1}^{\infty}|y_{n}|^{2}} \phantom{x} (3) \\ &= \left(\frac{1}{1-1/3}\right)^{1/2} \|x_{n}\|_{2}+\left(\frac{1}{1-1/3}\right)^{1/2} \|y_{n}\|_{2} \phantom{x} (4)\\ &= \sqrt{3/2} \|x_{n}\|_{2}+\sqrt{3/2} \|y_{n}\|_{2}.\phantom{x} (5) \end{align*} Thus, $d(x,y)$ is bounded. What is used in these steps: (1) Triangle inequality ? (2) What is used here? (3) Cauchy schwarz? (4) and (5) geometric series and standard calculation.",,['functional-analysis']
98,Representations of a C*-algebra of bounded Borel functions,Representations of a C*-algebra of bounded Borel functions,,"Let $X$ be a compact Hausdorff space. Let $B(X)$ be the C*-algebra of bounded Borel measureable functions on $X$ (under the supremum norm). I am curious whether the (say unital) $*$-representations of $B(X)$ are completely classified. One way to get these is from spectral measures on $X$. See IX.1.12 in A Course in Functional Analysis by John B. Conway. I'm not sure whether this is all of them, though. What this all boils down to is a question about the following continuity condition. Let $\pi : B(X) \to B(H)$ be a unital $*$-representation of $B(X)$ on a Hilbert space $H$. Suppose that $E_1,E_2,\ldots$ is a countable pairwise disjoint collection of Borel measurable subsets of $X$. Let $E = \bigcup_{n=1}^\infty E_n$. Is it necessarily true that $$\pi(\chi_E) = \sum_{n=1}^\infty \pi(\chi_{E_n})$$ with the sum converging in the strong operator topology?","Let $X$ be a compact Hausdorff space. Let $B(X)$ be the C*-algebra of bounded Borel measureable functions on $X$ (under the supremum norm). I am curious whether the (say unital) $*$-representations of $B(X)$ are completely classified. One way to get these is from spectral measures on $X$. See IX.1.12 in A Course in Functional Analysis by John B. Conway. I'm not sure whether this is all of them, though. What this all boils down to is a question about the following continuity condition. Let $\pi : B(X) \to B(H)$ be a unital $*$-representation of $B(X)$ on a Hilbert space $H$. Suppose that $E_1,E_2,\ldots$ is a countable pairwise disjoint collection of Borel measurable subsets of $X$. Let $E = \bigcup_{n=1}^\infty E_n$. Is it necessarily true that $$\pi(\chi_E) = \sum_{n=1}^\infty \pi(\chi_{E_n})$$ with the sum converging in the strong operator topology?",,"['functional-analysis', 'measure-theory', 'c-star-algebras']"
99,Problem with mapping concerning $c_{0}$,Problem with mapping concerning,c_{0},"Show that the mapping    $$ \Phi: \ell^{1}\rightarrow \mathcal{L}(c_{0};\mathbb{K}), \phantom{x} \Phi_{ x}(y):=\sum_{n=1}^{\infty}x_{n}y_{n}$$   is well-defined and an isometric isomorphism. Updated my answer: The functional $$ x \mapsto \sum_{n=1}^{\infty}x_{n}y_{n} $$ is bounded, since \begin{align*} |\Phi_{x}(y)| &= \left|\sum_{n=1}^{\infty} x_{n}y_{n} \right|\leq \sum_{n=1}^{\infty} |x_{n}y_{n}| = \sum_{n=1}^{\infty} |x_{n}||y_{n}| \\  &\leq \|y\|_{\infty}\|x\|_{1}. \end{align*} Because the functional is bounded by $\|x\|_{\infty}$, the mapping $$ \Phi: \ell^{1}\rightarrow \mathcal{L}(c_{0};\mathbb{K}),$$ defined by $$y\mapsto\left( x \mapsto \sum_{n=1}^{\infty}x_{n}y_{n} \right)$$ is well-defined. (Question 1. Is this correct?) Note that if $|x_{j}|=\|x\|_{\infty}$ and if we take $y_{j}=e_{j}$, where $e_{j}$ is the $j$-th unit vector, then $|\Phi_{x}(e_{j}) |=1$. Thus $$\|\Phi f\|_{\mathcal{L}(c_{0};\mathbb{K})}=\|f\|_{\ell^{1}} \phantom{x}\mathrm{for}\phantom{x}\mathrm{all}\phantom{x}f\in \ell^{1} .$$ (Question 2. Is this correct or am I on the wrong path, is there are a better way to show this? ) We claim that $\Phi$ is also surjective and hence it is an isometric isomorphism. If $\phi$ is a functional on $c_{0}$ let us denote $\phi(e_{j})$ by $x_{j}$. Then $$\phi_{x}(y) = \sum_{n=1}^{\infty}\phi(e_{n})y_{n}=\sum_{n=1}^{\infty}\phi(y_{n}e_{n})=\phi(y),$$ (the last equality holds because $\sum_{n=1}^{\infty}y_{n}e_{n}$ converges to $y$ in $c_{0}$ and $\phi$ is continuous in $c_{0}$) (Question 3. Is this correct and how do I prove my convergence argument?) so $\Phi(x)=\phi$. (Question 4. Struggling the most with this part. Is what I have done correct, have I really showed that $\mathrm{ran}(\Phi)=\mathcal{L}(c_{0};\mathbb{K})$ or is there are a better way to show this? )","Show that the mapping    $$ \Phi: \ell^{1}\rightarrow \mathcal{L}(c_{0};\mathbb{K}), \phantom{x} \Phi_{ x}(y):=\sum_{n=1}^{\infty}x_{n}y_{n}$$   is well-defined and an isometric isomorphism. Updated my answer: The functional $$ x \mapsto \sum_{n=1}^{\infty}x_{n}y_{n} $$ is bounded, since \begin{align*} |\Phi_{x}(y)| &= \left|\sum_{n=1}^{\infty} x_{n}y_{n} \right|\leq \sum_{n=1}^{\infty} |x_{n}y_{n}| = \sum_{n=1}^{\infty} |x_{n}||y_{n}| \\  &\leq \|y\|_{\infty}\|x\|_{1}. \end{align*} Because the functional is bounded by $\|x\|_{\infty}$, the mapping $$ \Phi: \ell^{1}\rightarrow \mathcal{L}(c_{0};\mathbb{K}),$$ defined by $$y\mapsto\left( x \mapsto \sum_{n=1}^{\infty}x_{n}y_{n} \right)$$ is well-defined. (Question 1. Is this correct?) Note that if $|x_{j}|=\|x\|_{\infty}$ and if we take $y_{j}=e_{j}$, where $e_{j}$ is the $j$-th unit vector, then $|\Phi_{x}(e_{j}) |=1$. Thus $$\|\Phi f\|_{\mathcal{L}(c_{0};\mathbb{K})}=\|f\|_{\ell^{1}} \phantom{x}\mathrm{for}\phantom{x}\mathrm{all}\phantom{x}f\in \ell^{1} .$$ (Question 2. Is this correct or am I on the wrong path, is there are a better way to show this? ) We claim that $\Phi$ is also surjective and hence it is an isometric isomorphism. If $\phi$ is a functional on $c_{0}$ let us denote $\phi(e_{j})$ by $x_{j}$. Then $$\phi_{x}(y) = \sum_{n=1}^{\infty}\phi(e_{n})y_{n}=\sum_{n=1}^{\infty}\phi(y_{n}e_{n})=\phi(y),$$ (the last equality holds because $\sum_{n=1}^{\infty}y_{n}e_{n}$ converges to $y$ in $c_{0}$ and $\phi$ is continuous in $c_{0}$) (Question 3. Is this correct and how do I prove my convergence argument?) so $\Phi(x)=\phi$. (Question 4. Struggling the most with this part. Is what I have done correct, have I really showed that $\mathrm{ran}(\Phi)=\mathcal{L}(c_{0};\mathbb{K})$ or is there are a better way to show this? )",,['functional-analysis']
