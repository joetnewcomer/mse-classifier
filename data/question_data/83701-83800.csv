,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Can a subspace have a larger dual?,Can a subspace have a larger dual?,,"I cant manage to figure this out, for instance $L^{1}[0,1]$ has $L^{\infty}[0,1]$ as dual and $C[0,1]$ (a sub space of $L^{1}[0,1]$ have the signed measures of bdd. varitaion as dual. I cant mange to prove anything regarding cardinality realtions between the measures and $L^{\infty}[0,1]$ tho. Intuitively it feels like we have more measures. Hints?","I cant manage to figure this out, for instance $L^{1}[0,1]$ has $L^{\infty}[0,1]$ as dual and $C[0,1]$ (a sub space of $L^{1}[0,1]$ have the signed measures of bdd. varitaion as dual. I cant mange to prove anything regarding cardinality realtions between the measures and $L^{\infty}[0,1]$ tho. Intuitively it feels like we have more measures. Hints?",,['functional-analysis']
1,Show that a positive operator on a complex Hilbert space is self-adjoint,Show that a positive operator on a complex Hilbert space is self-adjoint,,"Let $(\mathcal{H}, (\cdot, \cdot))$ be a complex Hilbert space, and $A :  \mathcal{H} \to \mathcal{H}$ a positive, bounded operator ( $A$ being positive means $(Ax,x) \ge 0$ for all $x \in \mathcal{H}$ ). Prove that $A$ is self-adjoint. That is, prove that $(Ax,y) = (x, Ay)$ for all $x,y \in \mathcal{H}$ . Here's what I have so far. Because $A$ is positive we have $\mathbb{R} \ni (Ax,x) = \overline{(x,Ax)} = (x,Ax)$ , all $x \in \mathcal{H}$ . Next, I have seen some hints that tell me to apply the polarization identity: $$(x,y) = \frac{1}{4}((\lVert x+y \rVert^2 + \lVert x-y \rVert^2) - i(\lVert x + iy \rVert^2 - \lVert x - iy \rVert^2)),$$ where of course the norm is defined by $\lVert \cdot \rVert^2 = (\cdot, \cdot)$ . So my guess is that I need to start with the expressions: $$(Ax,y) = \frac{1}{4}((\lVert Ax+y \rVert^2 + \lVert Ax-y \rVert^2) - i(\lVert Ax + iy \rVert^2 - \lVert Ax - iy \rVert^2)),$$ $$(x,Ay) = \frac{1}{4}((\lVert x+Ay \rVert^2 + \lVert x-Ay \rVert^2) - i(\lVert x + iAy \rVert^2 - \lVert x - iAy \rVert^2)),$$ and somehow show they are equal. But here is where I have gotten stuck. Hints or solutions are greatly appreciated.","Let be a complex Hilbert space, and a positive, bounded operator ( being positive means for all ). Prove that is self-adjoint. That is, prove that for all . Here's what I have so far. Because is positive we have , all . Next, I have seen some hints that tell me to apply the polarization identity: where of course the norm is defined by . So my guess is that I need to start with the expressions: and somehow show they are equal. But here is where I have gotten stuck. Hints or solutions are greatly appreciated.","(\mathcal{H}, (\cdot, \cdot)) A :  \mathcal{H} \to \mathcal{H} A (Ax,x) \ge 0 x \in \mathcal{H} A (Ax,y) = (x, Ay) x,y \in \mathcal{H} A \mathbb{R} \ni (Ax,x) = \overline{(x,Ax)} = (x,Ax) x \in \mathcal{H} (x,y) = \frac{1}{4}((\lVert x+y \rVert^2 + \lVert x-y \rVert^2) - i(\lVert x + iy \rVert^2 - \lVert x - iy \rVert^2)), \lVert \cdot \rVert^2 = (\cdot, \cdot) (Ax,y) = \frac{1}{4}((\lVert Ax+y \rVert^2 + \lVert Ax-y \rVert^2) - i(\lVert Ax + iy \rVert^2 - \lVert Ax - iy \rVert^2)), (x,Ay) = \frac{1}{4}((\lVert x+Ay \rVert^2 + \lVert x-Ay \rVert^2) - i(\lVert x + iAy \rVert^2 - \lVert x - iAy \rVert^2)),","['functional-analysis', 'hilbert-spaces']"
2,"The definition of ""entire function""","The definition of ""entire function""",,"I am reading about the definition of ""entire functions"" : ""If a complex function is analytic at all finite points of the complex plane $\mathbb{C}$, then it is said to be entire ..."" In fact, I'd like to understand this definition. Thus I wish a help to respond my questions. Are all analytic functions on $\mathbb{C}$ entire? Why do we need to use this definition? Thank you very much for all of your answers!","I am reading about the definition of ""entire functions"" : ""If a complex function is analytic at all finite points of the complex plane $\mathbb{C}$, then it is said to be entire ..."" In fact, I'd like to understand this definition. Thus I wish a help to respond my questions. Are all analytic functions on $\mathbb{C}$ entire? Why do we need to use this definition? Thank you very much for all of your answers!",,"['complex-analysis', 'functional-analysis', 'analytic-number-theory']"
3,"Open and closed balls in $C[a,b]$",Open and closed balls in,"C[a,b]","Let $X$ be a non empty set and let $C[a,b]$ denote the set of all real or complex valued continuous functions on $X$ with a metric induced by the supremum norm. How to find open and closed balls in $C[a,b]$? Can we see them geometrically? For example what is an open ball $B(x_0;1)$ i.e. ball centered at $x_0$ with radius $1$ in $C[a,b]$. I can visualize them in $\mathbb R^n$ but when it comes to functional spaces I have no clue how to identify them? Thanks for helping me.","Let $X$ be a non empty set and let $C[a,b]$ denote the set of all real or complex valued continuous functions on $X$ with a metric induced by the supremum norm. How to find open and closed balls in $C[a,b]$? Can we see them geometrically? For example what is an open ball $B(x_0;1)$ i.e. ball centered at $x_0$ with radius $1$ in $C[a,b]$. I can visualize them in $\mathbb R^n$ but when it comes to functional spaces I have no clue how to identify them? Thanks for helping me.",,"['functional-analysis', 'metric-spaces']"
4,Polar decomposition of Bounded Normal Operator on Hilbert Space,Polar decomposition of Bounded Normal Operator on Hilbert Space,,"It is well known that if $T$ is a bounded linear operator on a infinite dimensional Hilbert space $H$ then there exists unique partial isometry $U$ such that $T=U \vert T \vert$,where $\vert T \vert =(T^*T)^{1/2}$.Such a decomposition is called a polar decomposition of $T$.I am trying to solve the following problem: Suppose $T$ is Bounded Normal operator on $H$ ,then there exists unique unitary operator $U$ such that $T=U \vert T \vert$ I don't have any clean way to show the existence of such a unitary operator.Can someone please give me some idea to prove this?","It is well known that if $T$ is a bounded linear operator on a infinite dimensional Hilbert space $H$ then there exists unique partial isometry $U$ such that $T=U \vert T \vert$,where $\vert T \vert =(T^*T)^{1/2}$.Such a decomposition is called a polar decomposition of $T$.I am trying to solve the following problem: Suppose $T$ is Bounded Normal operator on $H$ ,then there exists unique unitary operator $U$ such that $T=U \vert T \vert$ I don't have any clean way to show the existence of such a unitary operator.Can someone please give me some idea to prove this?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
5,Kernel of the Laplacian on a compact manifold,Kernel of the Laplacian on a compact manifold,,"Is there a way to characterise the kernel of the Laplace-Beltrami operator on a compact manifold without boundary? Or is it just ""the set of functions $u$ such that $-\Delta u = 0$?""","Is there a way to characterise the kernel of the Laplace-Beltrami operator on a compact manifold without boundary? Or is it just ""the set of functions $u$ such that $-\Delta u = 0$?""",,"['functional-analysis', 'differential-geometry', 'manifolds']"
6,"Are integrable, essentially bounded functions in L^p?","Are integrable, essentially bounded functions in L^p?",,"Given an arbitrary measure space (of possibly infinite measure), if $f \in L^1 \cap L^\infty$, then by Hölder's inequality, $f^2 \in L^1$, so $f \in L^2$. Intuition suggests that $f \in L^p$ even for any $1 \le p \le \infty$ (since we have eliminated the only two things that can go wrong for $f$ to be in $L^p$; blow-up & non-decay). This does not seem to follow from the common inequalities, hence my question: Is it true that $L^1 \cap L^\infty \subset L^p$ in general, and if so how can I prove it? Many thanks in advance for any hints!","Given an arbitrary measure space (of possibly infinite measure), if $f \in L^1 \cap L^\infty$, then by Hölder's inequality, $f^2 \in L^1$, so $f \in L^2$. Intuition suggests that $f \in L^p$ even for any $1 \le p \le \infty$ (since we have eliminated the only two things that can go wrong for $f$ to be in $L^p$; blow-up & non-decay). This does not seem to follow from the common inequalities, hence my question: Is it true that $L^1 \cap L^\infty \subset L^p$ in general, and if so how can I prove it? Many thanks in advance for any hints!",,"['functional-analysis', 'measure-theory', 'lebesgue-integral', 'lp-spaces', 'integral-inequality']"
7,What makes compact operators special?,What makes compact operators special?,,"I would like to understand why compact operators are considered so special to consider them as an extra class of operators. Over Hilbert spaces these (as far as I know) these are the ones with separable range - limits of finite rank operators. However in general Banach spaces this is not what makes a bounded operator compact. So I'm still wondering what the crucial point is to consider compact operators (something like ""bounded operators are precisely the continuous ones and moreover turns the class of bounded operators into a banach space itself""). Does somebody have a good solid reasoning (some theorem characterizing compact operator)? Everything welcome of course =)","I would like to understand why compact operators are considered so special to consider them as an extra class of operators. Over Hilbert spaces these (as far as I know) these are the ones with separable range - limits of finite rank operators. However in general Banach spaces this is not what makes a bounded operator compact. So I'm still wondering what the crucial point is to consider compact operators (something like ""bounded operators are precisely the continuous ones and moreover turns the class of bounded operators into a banach space itself""). Does somebody have a good solid reasoning (some theorem characterizing compact operator)? Everything welcome of course =)",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'spectral-theory', 'compact-operators']"
8,Linear transformations in infinite dimensional vector spaces,Linear transformations in infinite dimensional vector spaces,,"If we look at an $n$ - dimensional vector space $V$ and a linear transformation  \begin{equation} T : V \to V, \quad x \mapsto Tx \quad \forall \, x \in V \end{equation} then given a choice of basis for $V$ one can represent $T$ in terms of a $n \times n$ matrix $A_T = A_T(i,j)$ Is this also the case for linear transformations on infinite - dimensional vector spaces, where we replace the matrix $A_T$ by an integral ? In particular, since differentiation is a linear map, that would mean differentiation can be written in the form of an integral ... I realize this is either a dumb question (because it is obviously wrong) or it is some classic result I haven't found yet. In both cases it would be great to get some reference where I can learn more about it, many thanks!","If we look at an $n$ - dimensional vector space $V$ and a linear transformation  \begin{equation} T : V \to V, \quad x \mapsto Tx \quad \forall \, x \in V \end{equation} then given a choice of basis for $V$ one can represent $T$ in terms of a $n \times n$ matrix $A_T = A_T(i,j)$ Is this also the case for linear transformations on infinite - dimensional vector spaces, where we replace the matrix $A_T$ by an integral ? In particular, since differentiation is a linear map, that would mean differentiation can be written in the form of an integral ... I realize this is either a dumb question (because it is obviously wrong) or it is some classic result I haven't found yet. In both cases it would be great to get some reference where I can learn more about it, many thanks!",,"['functional-analysis', 'operator-theory', 'differential-operators']"
9,Completeness of Measure spaces,Completeness of Measure spaces,,"A metric space X is called complete if every Cauchy sequence of points in X has a limit that is also in X. It's perfectly clear to me. A measure space $(X, \chi, \mu)$ is complete if the $\sigma$-algebra contains all subsets of sets of measure zero. That is, $(X, \chi, \mu)$ is complete if $N \in \chi$, $\mu (N) = 0$ and $A \subseteq N$ imply $A \in \chi$. Technically, I could understand the definition, but can't get the logic behind it. Questions: 1) Why do we care only about subsets of sets of measure zero to determine completeness? 2) How does the completeness of measure spaces relate to a completeness of metric spaces? 3) Could you suggest a concrete elementary example of a measure space (preferably, with simple sets) that isn't initially complete and then is completed?","A metric space X is called complete if every Cauchy sequence of points in X has a limit that is also in X. It's perfectly clear to me. A measure space $(X, \chi, \mu)$ is complete if the $\sigma$-algebra contains all subsets of sets of measure zero. That is, $(X, \chi, \mu)$ is complete if $N \in \chi$, $\mu (N) = 0$ and $A \subseteq N$ imply $A \in \chi$. Technically, I could understand the definition, but can't get the logic behind it. Questions: 1) Why do we care only about subsets of sets of measure zero to determine completeness? 2) How does the completeness of measure spaces relate to a completeness of metric spaces? 3) Could you suggest a concrete elementary example of a measure space (preferably, with simple sets) that isn't initially complete and then is completed?",,"['functional-analysis', 'measure-theory']"
10,weak* continuous linear functional is in the predual,weak* continuous linear functional is in the predual,,"Let $X$ be a Banach space and $X^*$ its dual. We know that the weak* topology is the least topology that makes every $x \in X$ continuous as an evaluation functional. However, this does not imply that every weak* continuous linear functional is something in $X$ , even though this happens to be true. The question is: how can we prove this? What have I though is: It is enough to show that $\cap_{i=1}^{k} \ker{x_i} \subset \ker{\phi}$ for some $x_i \in X, i=1,2,...,k$ I have shown this for infinitely many $x_i$ s (easy, using the weak* continuity and that 0 is always in the ker) and in order to pass to finitely many I would need some kind of compactness result (probably by using Banach-Alaoglu somehow), but I do not know how to do this. Can anyone help?","Let be a Banach space and its dual. We know that the weak* topology is the least topology that makes every continuous as an evaluation functional. However, this does not imply that every weak* continuous linear functional is something in , even though this happens to be true. The question is: how can we prove this? What have I though is: It is enough to show that for some I have shown this for infinitely many s (easy, using the weak* continuity and that 0 is always in the ker) and in order to pass to finitely many I would need some kind of compactness result (probably by using Banach-Alaoglu somehow), but I do not know how to do this. Can anyone help?","X X^* x \in X X \cap_{i=1}^{k} \ker{x_i} \subset \ker{\phi} x_i \in X, i=1,2,...,k x_i",['functional-analysis']
11,"Proving that $\int_0^1 f(x)e^{nx}\,{\rm d}x = 0$ for all $n\in\mathbb{N}_0$ implies $f(x) = 0$",Proving that  for all  implies,"\int_0^1 f(x)e^{nx}\,{\rm d}x = 0 n\in\mathbb{N}_0 f(x) = 0","I'm trying to show that if $f$ is a continuous function on $[0,1]$ and $\int_0^{1} f(x)e^{nx}\,{\rm d}x = 0$ for all $n = 0, 1, 2, \dots$, then $f(x) = 0$. I'd like to use Weierstrass approximation theorem to find a sequence of polynomials $p_m$ that converge uniformly to $f(x)$. Then we could say $\lim\limits_{m\to \infty} \int p_m(x)e^{nx}\,{\rm d}x = \int f(x)e^{nx}\,{\rm d}x = 0$, but I'm struggling to deduce that then all the $p_m$ are zero which would give the result.","I'm trying to show that if $f$ is a continuous function on $[0,1]$ and $\int_0^{1} f(x)e^{nx}\,{\rm d}x = 0$ for all $n = 0, 1, 2, \dots$, then $f(x) = 0$. I'd like to use Weierstrass approximation theorem to find a sequence of polynomials $p_m$ that converge uniformly to $f(x)$. Then we could say $\lim\limits_{m\to \infty} \int p_m(x)e^{nx}\,{\rm d}x = \int f(x)e^{nx}\,{\rm d}x = 0$, but I'm struggling to deduce that then all the $p_m$ are zero which would give the result.",,"['functional-analysis', 'banach-spaces']"
12,Exact sequence involving the nabla operator,Exact sequence involving the nabla operator,,"Recently I noticed that $$0 \longrightarrow \Bbb R \overset{\text{const.}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R) \overset{\text{grad}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R^3) \overset{\text{rot}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R^3) \overset{\text{div}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R)\longrightarrow 0$$ is an exact sequence of $\Bbb R$-algebras, where the second arrow is given by $\text{const}:c \mapsto f(\vec x)\equiv c$ and grad, rot ,div are the gradient, rotation and divergence operators. Is the existence of such an exact sequence a mere curiosity or does it have its origins from deep results in homological algebra. If so, are there generelizations to $\Bbb R^n$ with higher $n$ or even to other smooth manifolds?","Recently I noticed that $$0 \longrightarrow \Bbb R \overset{\text{const.}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R) \overset{\text{grad}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R^3) \overset{\text{rot}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R^3) \overset{\text{div}}\longrightarrow \mathcal{C}^\infty(\Bbb R^3,\Bbb R)\longrightarrow 0$$ is an exact sequence of $\Bbb R$-algebras, where the second arrow is given by $\text{const}:c \mapsto f(\vec x)\equiv c$ and grad, rot ,div are the gradient, rotation and divergence operators. Is the existence of such an exact sequence a mere curiosity or does it have its origins from deep results in homological algebra. If so, are there generelizations to $\Bbb R^n$ with higher $n$ or even to other smooth manifolds?",,"['functional-analysis', 'differential-geometry', 'multivariable-calculus', 'homological-algebra']"
13,Norm in L2 bounded by norm in H1,Norm in L2 bounded by norm in H1,,"I am studying FEM the very basics. I don't have a very strong background in math nor in functional analysis. Having said that, here's the problem I'm analyzing. $$ -\mu u'' + \sigma u = f ~~~~~ x \in (0,1) $$ $$u(0) = u(1) = 0$$ From that I got the bilinear form of the problem as: $$ a(u, v) = \int_\Omega \mu u'v'dx + \int_\Omega \sigma u vdx $$ $$ F(v) = \int_\Omega fvdx ~~~~~~~~~~\forall v \in V=H_0^1$$ I was trying to understand the proof of continuity of the bilinear form and I found that it could be proven as follows: $$|a(u,v)|= \Big|\int_\Omega \mu u'v'dx + \int_\Omega \sigma u vdx \Big|≤ \Big|\int_\Omega \mu u'v'dx\Big| + \Big|\int_\Omega \sigma u vdx\Big|$$ $$≤ \mu ||u'||_{L^2} ||v'||_{L^2} + \sigma||u||_{L^2}||v||_{L^2}$$ $$≤ \max(\mu, \sigma) (||u'||_{L^2} ||v'||_{L^2} + ||u||_{L^2}||v||_{L^2})$$ As far as I understand the stuff above is using the Cauchy-Schwarz inequality. Then to complete the verification of the continuity I have to ""change"" (I don't know if it's the correct word) from $L^2$ to $H^1$ because there's where I defined my space $V$ to be. So I found two expression that I don't understand how to interpret $$||u||_{L^2} ≤ ||u||_{H^1},~~~~~~~~||u'||_{L^2} ≤ ||u||_{H^1}$$ does it mean that a norm in $L^2$ is bounded by a norm in $H^1$ ?? If so, how can I visualize that (geometrically) ?","I am studying FEM the very basics. I don't have a very strong background in math nor in functional analysis. Having said that, here's the problem I'm analyzing. $$ -\mu u'' + \sigma u = f ~~~~~ x \in (0,1) $$ $$u(0) = u(1) = 0$$ From that I got the bilinear form of the problem as: $$ a(u, v) = \int_\Omega \mu u'v'dx + \int_\Omega \sigma u vdx $$ $$ F(v) = \int_\Omega fvdx ~~~~~~~~~~\forall v \in V=H_0^1$$ I was trying to understand the proof of continuity of the bilinear form and I found that it could be proven as follows: $$|a(u,v)|= \Big|\int_\Omega \mu u'v'dx + \int_\Omega \sigma u vdx \Big|≤ \Big|\int_\Omega \mu u'v'dx\Big| + \Big|\int_\Omega \sigma u vdx\Big|$$ $$≤ \mu ||u'||_{L^2} ||v'||_{L^2} + \sigma||u||_{L^2}||v||_{L^2}$$ $$≤ \max(\mu, \sigma) (||u'||_{L^2} ||v'||_{L^2} + ||u||_{L^2}||v||_{L^2})$$ As far as I understand the stuff above is using the Cauchy-Schwarz inequality. Then to complete the verification of the continuity I have to ""change"" (I don't know if it's the correct word) from $L^2$ to $H^1$ because there's where I defined my space $V$ to be. So I found two expression that I don't understand how to interpret $$||u||_{L^2} ≤ ||u||_{H^1},~~~~~~~~||u'||_{L^2} ≤ ||u||_{H^1}$$ does it mean that a norm in $L^2$ is bounded by a norm in $H^1$ ?? If so, how can I visualize that (geometrically) ?",,"['functional-analysis', 'ordinary-differential-equations']"
14,"Given $T \in L(X,Y)$, show the equivalence between: existence of $S$ such that $S(T(x))=x$, and $T$ being injective with $T(X)$ complemented in $Y$","Given , show the equivalence between: existence of  such that , and  being injective with  complemented in","T \in L(X,Y) S S(T(x))=x T T(X) Y","Given $X,Y$ Banach spaces and $T \in L(X,Y)$ , show that the following sentences are equivalent: A) there exists $S \in L(Y,X)$ such that $S(T(x))=x$ for all $x \in X$ . B) $T$ is injective and $T(X)$ is a complemented space of $Y$ . Context : I was given this exercise in my functional analysis course but I don’t know how to solve this. All I have understood so far in this exercise are the following: I was given the following definition of ""complemented space'': a closed subspace $M$ is complemented in $N$ if exists a topological complement of $M$ in $N$ or equivalently if there exists a linear continuous projection $P$ in $N$ such that $𝑃(N)=M$ ; $L(X,Y)$ means the set of all continuous linear operators from $X$ to $Y$ .","Given Banach spaces and , show that the following sentences are equivalent: A) there exists such that for all . B) is injective and is a complemented space of . Context : I was given this exercise in my functional analysis course but I don’t know how to solve this. All I have understood so far in this exercise are the following: I was given the following definition of ""complemented space'': a closed subspace is complemented in if exists a topological complement of in or equivalently if there exists a linear continuous projection in such that ; means the set of all continuous linear operators from to .","X,Y T \in L(X,Y) S \in L(Y,X) S(T(x))=x x \in X T T(X) Y M N M N P N 𝑃(N)=M L(X,Y) X Y","['functional-analysis', 'linear-transformations', 'banach-spaces', 'normed-spaces', 'complete-spaces']"
15,$e_n \to 0$ weakly in $l^\infty$,weakly in,e_n \to 0 l^\infty,"Given the the sequence $(e_n)_n$ in $l^\infty$, I want to show that that $e_n$ converges weakly to $0$ in $l^\infty$, i.e. $$e_n\rightharpoonup 0 \text{    as   } n\to \infty.$$ By $e_n\in l^\infty$, I mean the sequence $e_n^{(m)}=\delta_{m,n}$. Should I try to show this by looking at the dual of $l^\infty$ which is not trivial, or is there another way?","Given the the sequence $(e_n)_n$ in $l^\infty$, I want to show that that $e_n$ converges weakly to $0$ in $l^\infty$, i.e. $$e_n\rightharpoonup 0 \text{    as   } n\to \infty.$$ By $e_n\in l^\infty$, I mean the sequence $e_n^{(m)}=\delta_{m,n}$. Should I try to show this by looking at the dual of $l^\infty$ which is not trivial, or is there another way?",,"['functional-analysis', 'lp-spaces', 'weak-convergence']"
16,Reproducing kernel Hilbert spaces and the isomorphism theorem,Reproducing kernel Hilbert spaces and the isomorphism theorem,,"A reproducing kernel Hilbert space is a Hilbert space in which the evaluation functional $L_x : f \rightarrow f(x)$ is continuous. By continuity, the Riesz representation theorem says that this functional can be represented as an inner product. I have a feeling there's something fundamental I've misunderstood here. If any two real Hilbert spaces of the same cardinality are isomorphic, then why is it that $l_2$ is a RKHS, but $L^2[0,1]$ is not?","A reproducing kernel Hilbert space is a Hilbert space in which the evaluation functional $L_x : f \rightarrow f(x)$ is continuous. By continuity, the Riesz representation theorem says that this functional can be represented as an inner product. I have a feeling there's something fundamental I've misunderstood here. If any two real Hilbert spaces of the same cardinality are isomorphic, then why is it that $l_2$ is a RKHS, but $L^2[0,1]$ is not?",,"['functional-analysis', 'hilbert-spaces']"
17,Learning functional analysis and measure theory,Learning functional analysis and measure theory,,"I have taken a first course in real analysis and I'm currently studying analysis in $\mathbb{R}^N$ on my own. I want to start functional analysis after this, and I also want to learn measure theory and Lebesgue integration. My question is: should I learn functional analysis first, without Lebesgue integration, using a text such as Kreyszig's introductory functional analysis, and then study Lebesgue integration later, or should I study Lebesgue theory first and then functional analysis, perhaps using using something like Lang's ""Real and Functional Analysis""? If neither of these ways is good in your opinion, what would be the best way to go? I'm a grad student of mechanical engineering, and I ultimately want to understand PDEs properly.","I have taken a first course in real analysis and I'm currently studying analysis in $\mathbb{R}^N$ on my own. I want to start functional analysis after this, and I also want to learn measure theory and Lebesgue integration. My question is: should I learn functional analysis first, without Lebesgue integration, using a text such as Kreyszig's introductory functional analysis, and then study Lebesgue integration later, or should I study Lebesgue theory first and then functional analysis, perhaps using using something like Lang's ""Real and Functional Analysis""? If neither of these ways is good in your opinion, what would be the best way to go? I'm a grad student of mechanical engineering, and I ultimately want to understand PDEs properly.",,"['functional-analysis', 'self-learning']"
18,"If a Banach space $X$ is isometric to its first dual $X^*$, must $X$ be reflexive?","If a Banach space  is isometric to its first dual , must  be reflexive?",X X^* X,"Suppose that $X$ is a Banach space such that there exists a linear isometry $X \rightarrow X^*$. Must $X$ be reflexive? Of course, this implies that $X$ is isometric with its second dual $X^{**}$. But with this alone it is not possible to conclude that $X$ is reflexive, James space is the famous counterexample for this. So a negative answer to my question should be at least as difficult as finding an example like the James space.. so probably not very easy.","Suppose that $X$ is a Banach space such that there exists a linear isometry $X \rightarrow X^*$. Must $X$ be reflexive? Of course, this implies that $X$ is isometric with its second dual $X^{**}$. But with this alone it is not possible to conclude that $X$ is reflexive, James space is the famous counterexample for this. So a negative answer to my question should be at least as difficult as finding an example like the James space.. so probably not very easy.",,"['functional-analysis', 'banach-spaces']"
19,"Maximal ideals in the algebra of continuously differentiable functions on [0,1]","Maximal ideals in the algebra of continuously differentiable functions on [0,1]",,"This is an exercise in Rudin's Functional Analysis, in the chapter on commutative Banach algebras. My (uneducated) guess was that every homomorphism on $C^{1}[0,1]$ is an evaluation at some point of [0,1]. The imitation of the proof for finding the homomorphisms on $C[0,1]$, as in Simmons, fails as taking the moduli of functions does not preserve differentiability. I would be grateful for hints on this.","This is an exercise in Rudin's Functional Analysis, in the chapter on commutative Banach algebras. My (uneducated) guess was that every homomorphism on $C^{1}[0,1]$ is an evaluation at some point of [0,1]. The imitation of the proof for finding the homomorphisms on $C[0,1]$, as in Simmons, fails as taking the moduli of functions does not preserve differentiability. I would be grateful for hints on this.",,"['functional-analysis', 'commutative-algebra', 'banach-algebras']"
20,When to use Closed Graph Theorem vs. Uniform Boundedness Theorem?,When to use Closed Graph Theorem vs. Uniform Boundedness Theorem?,,"I run in to problem that I often know is solvable with either the Closed Graph Theorem or Uniform Boundedness Theorem. I seem to mix up the solutions. Are there any hints on when to use which? Or can they both be used solve the same problem? One example: Let $X$ be a Banach space and let $T_n$ be a sequence of bounded linear maps from $X$ into itself, such that for every $x\in X$ we have $$ \lim_{n\rightarrow \infty} T_nx = x$$ in the norm of $X$. Show that the linear map $T:X\rightarrow X$ is continuous iff the maps $T_nT$ are continuous for each $n\geq 1$. For ($\Leftarrow$), I tried to use the Closed Graph Theorem as follows. Assume $x_n \rightarrow x$ and $Tx\rightarrow y$. Then $$\lim_{m \rightarrow \infty} T_mT\lim_{n \rightarrow \infty}x_n = \lim_{m \rightarrow \infty} T_my = y,$$ and $$\lim_{m \rightarrow \infty} T_mT\lim_{n \rightarrow \infty}x_n = \lim_{m \rightarrow \infty} T_mTx = Tx,$$ and by the Closed Graph Theorem, we are done. However, the solution to the exercise solved it using the Uniformed Boundedness Theorem.","I run in to problem that I often know is solvable with either the Closed Graph Theorem or Uniform Boundedness Theorem. I seem to mix up the solutions. Are there any hints on when to use which? Or can they both be used solve the same problem? One example: Let $X$ be a Banach space and let $T_n$ be a sequence of bounded linear maps from $X$ into itself, such that for every $x\in X$ we have $$ \lim_{n\rightarrow \infty} T_nx = x$$ in the norm of $X$. Show that the linear map $T:X\rightarrow X$ is continuous iff the maps $T_nT$ are continuous for each $n\geq 1$. For ($\Leftarrow$), I tried to use the Closed Graph Theorem as follows. Assume $x_n \rightarrow x$ and $Tx\rightarrow y$. Then $$\lim_{m \rightarrow \infty} T_mT\lim_{n \rightarrow \infty}x_n = \lim_{m \rightarrow \infty} T_my = y,$$ and $$\lim_{m \rightarrow \infty} T_mT\lim_{n \rightarrow \infty}x_n = \lim_{m \rightarrow \infty} T_mTx = Tx,$$ and by the Closed Graph Theorem, we are done. However, the solution to the exercise solved it using the Uniformed Boundedness Theorem.",,"['functional-analysis', 'banach-spaces', 'operator-theory']"
21,Topological vector spaces book recommendation,Topological vector spaces book recommendation,,"I'm currently taking a class covering the theory of topological vector spaces using the book Topological Vector Spaces, Distributions, and Kernels by Francois Treves. I find the subject to be very interesting, but its also been quite difficult for me to understand some of the material or do some of the exercises. The course aims to cover most of the first part of Treves book, basically up to Frechet spaces or LF spaces. Are there any other books that cover roughly the same material as in Treves book that might be a bit easier to go over? I've already checked out other books by H.H. Schaefer and M. P. Wolff, G. Kothe, and Bourbaki, but I've found all these books to be more difficult than the Treves book. My main interests in topological vector spaces are on the theory of distributions, functional analysis, and applications to partial differential equations. Thanks in advance.","I'm currently taking a class covering the theory of topological vector spaces using the book Topological Vector Spaces, Distributions, and Kernels by Francois Treves. I find the subject to be very interesting, but its also been quite difficult for me to understand some of the material or do some of the exercises. The course aims to cover most of the first part of Treves book, basically up to Frechet spaces or LF spaces. Are there any other books that cover roughly the same material as in Treves book that might be a bit easier to go over? I've already checked out other books by H.H. Schaefer and M. P. Wolff, G. Kothe, and Bourbaki, but I've found all these books to be more difficult than the Treves book. My main interests in topological vector spaces are on the theory of distributions, functional analysis, and applications to partial differential equations. Thanks in advance.",,"['functional-analysis', 'book-recommendation', 'topological-vector-spaces']"
22,A Banach Space cannot have a denumerable basis:Why is it true?,A Banach Space cannot have a denumerable basis:Why is it true?,,I came across the following theorem: A Banach Space cannot have a denumerable basis which has been proven in my book. I can't understand why is it true since $\mathbb R$ is a banach space over $\mathbb R$ and it has a countable basis i.e $\{1\}$ Where am I missing the link?,I came across the following theorem: A Banach Space cannot have a denumerable basis which has been proven in my book. I can't understand why is it true since $\mathbb R$ is a banach space over $\mathbb R$ and it has a countable basis i.e $\{1\}$ Where am I missing the link?,,['functional-analysis']
23,Can $ {L^{1}}(G) $ be a $ C^{*} $-algebra?,Can  be a -algebra?, {L^{1}}(G)   C^{*} ,"Let $ G $ be a locally compact abelian group. Then $ {L^{1}}(G) $ is a commutative algebra when equipped with convolution. Is there an involution $ ^{*} $ on $ {L^{1}}(G) $ so that it becomes a $ C^{*} $-algebra? We can show that the map $ f \mapsto \overline{f} $ is an involution, but with this involution, $ {L^{1}}(G) $ is not a $ C^{*} $-algebra. I believe the answer is negative, but I can’t prove it. If this is the case, can we inject $ {L^{1}}(G) $ into a larger algebra which is a $ C^{*} $-algebra?","Let $ G $ be a locally compact abelian group. Then $ {L^{1}}(G) $ is a commutative algebra when equipped with convolution. Is there an involution $ ^{*} $ on $ {L^{1}}(G) $ so that it becomes a $ C^{*} $-algebra? We can show that the map $ f \mapsto \overline{f} $ is an involution, but with this involution, $ {L^{1}}(G) $ is not a $ C^{*} $-algebra. I believe the answer is negative, but I can’t prove it. If this is the case, can we inject $ {L^{1}}(G) $ into a larger algebra which is a $ C^{*} $-algebra?",,"['functional-analysis', 'lp-spaces', 'c-star-algebras', 'banach-algebras']"
24,Riesz Functional Calculus vs. Holomorphic Functional Calculus,Riesz Functional Calculus vs. Holomorphic Functional Calculus,,"""Functional calculus"" is a word used to describe the practice of taking some functions or formulas defined on complex numbers, and apply them in some way to certain kinds of operators, despite that operators are not complex numbers and so they are not in the domain of the function. There are many kinds of functional calculus. (Correct me if I'm wrong about something: I'm studying these topics right now) There is the so called Continuous functional calculus, that applies a continuous function defined on the spectrum of a normal operator in a unital C*algebra to that operator. There is the Borel functional calculus that aims to apply a more general Borel function to a self-adjoint operator. And there are the Riesz and Holomorphic functional calculus, that apply the analytic functions to some kind of operators. I didn't catch the difference between these last two. Can someone please try to explain that to me briefly? Thank you.","""Functional calculus"" is a word used to describe the practice of taking some functions or formulas defined on complex numbers, and apply them in some way to certain kinds of operators, despite that operators are not complex numbers and so they are not in the domain of the function. There are many kinds of functional calculus. (Correct me if I'm wrong about something: I'm studying these topics right now) There is the so called Continuous functional calculus, that applies a continuous function defined on the spectrum of a normal operator in a unital C*algebra to that operator. There is the Borel functional calculus that aims to apply a more general Borel function to a self-adjoint operator. And there are the Riesz and Holomorphic functional calculus, that apply the analytic functions to some kind of operators. I didn't catch the difference between these last two. Can someone please try to explain that to me briefly? Thank you.",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'spectral-theory']"
25,"Why unit open ball is open in norm topology, but not open in weak topology?","Why unit open ball is open in norm topology, but not open in weak topology?",,"Why unit open ball is open in norm topology, but not open in weak topology? I will be grateful for any explanation. Edit: Obviously in infnite dimensional spaces.","Why unit open ball is open in norm topology, but not open in weak topology? I will be grateful for any explanation. Edit: Obviously in infnite dimensional spaces.",,['functional-analysis']
26,Could we write Fourier transform as a matrix?,Could we write Fourier transform as a matrix?,,"I have heard that Fourier transform is a linear transformation. I have also heard that any linear transformation can be written as a matrix multiplication. (probably I'm missing some details in the above two statements) So my guess is, the above two notions are related (may be not). Carrying on with the question, I also know that Fourier transform acts on the space of $L^2$ functions (again correct me please if wrong). So my questions are: How can we write the Fourier transform as a matrix operator say $\mathcal{F}$? What are the elements of that matrix $\mathcal{F}$? What is the dimension of that matrix $\mathcal{F}$? When $\mathcal{F}$ acts on a function $g$, how do we write $g$ as a vector, to apply the matrix $\mathcal{F}$? I know these can be done in DFT, but can it be done in continuous case is my question? I read the following posts and they are related but not the same. Is a Fourier transform a change of basis, or is it a linear transformation? How is the Fourier transform ""linear""? Thanks a lot in advance.","I have heard that Fourier transform is a linear transformation. I have also heard that any linear transformation can be written as a matrix multiplication. (probably I'm missing some details in the above two statements) So my guess is, the above two notions are related (may be not). Carrying on with the question, I also know that Fourier transform acts on the space of $L^2$ functions (again correct me please if wrong). So my questions are: How can we write the Fourier transform as a matrix operator say $\mathcal{F}$? What are the elements of that matrix $\mathcal{F}$? What is the dimension of that matrix $\mathcal{F}$? When $\mathcal{F}$ acts on a function $g$, how do we write $g$ as a vector, to apply the matrix $\mathcal{F}$? I know these can be done in DFT, but can it be done in continuous case is my question? I read the following posts and they are related but not the same. Is a Fourier transform a change of basis, or is it a linear transformation? How is the Fourier transform ""linear""? Thanks a lot in advance.",,"['analysis', 'functional-analysis', 'vector-spaces', 'fourier-analysis']"
27,If a map $C:X\rightarrow U$ maps every weakly convergent sequence into strongly convergent,If a map  maps every weakly convergent sequence into strongly convergent,C:X\rightarrow U,A Linear map between Banach spaces $C:X\rightarrow U$ is compact if it maps if the closure of the image of the unit ball is precompact in U. If a map $C:X\rightarrow U$ maps every weakly convergent sequence into strongly convergent can we say that the map is compact? The converse can be seen here: Compact operator maps weakly convergent sequences into strongly convergent sequences,A Linear map between Banach spaces $C:X\rightarrow U$ is compact if it maps if the closure of the image of the unit ball is precompact in U. If a map $C:X\rightarrow U$ maps every weakly convergent sequence into strongly convergent can we say that the map is compact? The converse can be seen here: Compact operator maps weakly convergent sequences into strongly convergent sequences,,"['functional-analysis', 'operator-theory']"
28,Show that the spectral radius is an upper semi-continuous function,Show that the spectral radius is an upper semi-continuous function,,"I am stuck in a problem of Conway's A course in a Functional Analysis . Can anyone give me a hint to solve the problem? The question is ""If $A$ is a Banach Algebra, then show that the function $r:A\to R$ defined by $r(a)=$ spectral radius of $a,$ is a upper semi-continuous function."" Recall that spectral radius of $a,$ $r(a):=\sup\{|c|:c\in\mbox{ spectrum of } a\}$ .","I am stuck in a problem of Conway's A course in a Functional Analysis . Can anyone give me a hint to solve the problem? The question is ""If $A$ is a Banach Algebra, then show that the function $r:A\to R$ defined by $r(a)=$ spectral radius of $a,$ is a upper semi-continuous function."" Recall that spectral radius of $a,$ $r(a):=\sup\{|c|:c\in\mbox{ spectrum of } a\}$ .",,"['functional-analysis', 'spectral-theory', 'continuity', 'banach-algebras']"
29,Is there a non-reflexive Banach space with every proper closed subspace reflexive?,Is there a non-reflexive Banach space with every proper closed subspace reflexive?,,"Many conditions necessary for reflexivity of a Banach space turn out to be sufficient as well, for example, compactness of the closed unit ball in the weak topology. I am wondering if there is any sort of converse to the fact that every closed subspace of a Banach space is reflexive. Namely, let $X$ be a Banach space such that every proper closed subspace of $X$ is reflexive. Does this imply that $X$ itself is reflexive?","Many conditions necessary for reflexivity of a Banach space turn out to be sufficient as well, for example, compactness of the closed unit ball in the weak topology. I am wondering if there is any sort of converse to the fact that every closed subspace of a Banach space is reflexive. Namely, let $X$ be a Banach space such that every proper closed subspace of $X$ is reflexive. Does this imply that $X$ itself is reflexive?",,"['functional-analysis', 'banach-spaces']"
30,Resolution of the identity (basic questions),Resolution of the identity (basic questions),,"There are a few advanced discussions about the title: Resolution of Identity Resolution of Identity Resolution of identity of a selfadjoint I just want to ask the most fundamental part of it. (I am not a student in math.) From the definition in Wiki: https://en.wikipedia.org/wiki/Borel_functional_calculus Let $T$ be a self-adjoint operator. If $E$ is a Borel subset of $\mathbb{R}$, and $\mathbf{1}_E$ is the indicator function, then $\mathbf{1}_E(T)$ is a self-adjoint projection on $H$. Then mapping $$\Omega: E\mapsto \mathbf{1}_E(T)$$ is a projection-valued measure called the resolution of the identity for the self-adjoint operator $T$ ($H$ is a Hilbert space). I am still confused about how does $\mathbf{1}_E(T)$ really work. $E\subset\mathbb{R}$; however, $T$ is an operator defined on $H$. So $T\notin E$ How does $\mathbf{1}_E(T)$ act on vectors in $H$? ""resolution of the identity"": where does ""resolution"" and ""identity"" come from this definition. Could anyone please let me know these (much better if a concrete example provided)","There are a few advanced discussions about the title: Resolution of Identity Resolution of Identity Resolution of identity of a selfadjoint I just want to ask the most fundamental part of it. (I am not a student in math.) From the definition in Wiki: https://en.wikipedia.org/wiki/Borel_functional_calculus Let $T$ be a self-adjoint operator. If $E$ is a Borel subset of $\mathbb{R}$, and $\mathbf{1}_E$ is the indicator function, then $\mathbf{1}_E(T)$ is a self-adjoint projection on $H$. Then mapping $$\Omega: E\mapsto \mathbf{1}_E(T)$$ is a projection-valued measure called the resolution of the identity for the self-adjoint operator $T$ ($H$ is a Hilbert space). I am still confused about how does $\mathbf{1}_E(T)$ really work. $E\subset\mathbb{R}$; however, $T$ is an operator defined on $H$. So $T\notin E$ How does $\mathbf{1}_E(T)$ act on vectors in $H$? ""resolution of the identity"": where does ""resolution"" and ""identity"" come from this definition. Could anyone please let me know these (much better if a concrete example provided)",,"['functional-analysis', 'spectral-theory', 'banach-algebras']"
31,Example of an operator with purely residual spectrum,Example of an operator with purely residual spectrum,,Do you know an example of a linear bounded operator acting on a Banach (or even Hilbert) space whose residual spectrum is non-empty but the point and continuous spectrum are empty?,Do you know an example of a linear bounded operator acting on a Banach (or even Hilbert) space whose residual spectrum is non-empty but the point and continuous spectrum are empty?,,"['functional-analysis', 'spectral-theory']"
32,"""Clear"" reason why open sets in weak topology is unbounded","""Clear"" reason why open sets in weak topology is unbounded",,"In Lax's Functional Analysis book: The open sets in the weak topology are unions of finite intersections of sets of the form $\{x:a<l(x)<b\}$. Clearly, in an infinite-dimensional space the intersection of a finite number of sets of this form is unbounded. I don't really see the ""clearly"" part. I may be missing something. Do we have to consider $\cap\ker f_i$ like the answer here?: Why unit open ball is open in norm topology, but not open in weak topology?","In Lax's Functional Analysis book: The open sets in the weak topology are unions of finite intersections of sets of the form $\{x:a<l(x)<b\}$. Clearly, in an infinite-dimensional space the intersection of a finite number of sets of this form is unbounded. I don't really see the ""clearly"" part. I may be missing something. Do we have to consider $\cap\ker f_i$ like the answer here?: Why unit open ball is open in norm topology, but not open in weak topology?",,"['functional-analysis', 'analysis']"
33,"Let $T: E \rightarrow E^*$ be a linear operator satisfying $\langle Tx,x \rangle \geq 0 \forall x \in E$. Prove T is bounded.",Let  be a linear operator satisfying . Prove T is bounded.,"T: E \rightarrow E^* \langle Tx,x \rangle \geq 0 \forall x \in E","I'm trying to use the closed graph theorem, i.e, I'm trying to prove that $Graph(T) = \{ (x,Tx) ; ~x \in E \}$ is closed in $E \times $F, but I'm a little bit confused. So, i'd like some help in proving it. Here, given $f$ function, $\langle f,x \rangle = f(x)$. Thanks in advance.","I'm trying to use the closed graph theorem, i.e, I'm trying to prove that $Graph(T) = \{ (x,Tx) ; ~x \in E \}$ is closed in $E \times $F, but I'm a little bit confused. So, i'd like some help in proving it. Here, given $f$ function, $\langle f,x \rangle = f(x)$. Thanks in advance.",,['functional-analysis']
34,Dense subset of Hilbert space has trivial orthogonal complement,Dense subset of Hilbert space has trivial orthogonal complement,,If $D$ is a dense subset (not subspace) of  a Hilbert space then is the orthogonal complement of $D$ equal to $\{ 0 \}$? This is true if $D$ is a subspace but if you only know that $D$ is a subset you cannot apply the decomposition theorem. Any ideas?,If $D$ is a dense subset (not subspace) of  a Hilbert space then is the orthogonal complement of $D$ equal to $\{ 0 \}$? This is true if $D$ is a subspace but if you only know that $D$ is a subset you cannot apply the decomposition theorem. Any ideas?,,"['functional-analysis', 'hilbert-spaces']"
35,Ways to calculate the spectrum of an operator,Ways to calculate the spectrum of an operator,,"Friends, I am learning some very basic stuff of spectral theory and kind of lost, in some sense. I am trying to find ways to compute the spectra of different operators, when they work and don't work. For example, by applying directly the definitions, I am able to compute the spectrum of the orthogonal projection to be the set $\{0,I\}$. But, in order to find the essential spectrum of some differential operators, say $L=\partial_{xx}+c\partial_{x}+F$ where $F$ is some linearized term of a nonlinear function $f(u)$, I would perform a Fourier transform $\mathfrak{F}(L)$ and calculate the eigenvalues of this operator. (I am not even sure if this is the correct way of doing it.) Other ways are taking different kinds of transforms (which I have no idea; but by talking to some people, I sensed that taking a Laplace transform sometimes works, too!). I think applying directly the definitions would not be possible in at lot of the cases. Can someone give me references for techniques of finding spectra of different operators, when they fail and work? At least, when I see some kind of operator, I would like to know that I have a sense of what to do. Best regards,","Friends, I am learning some very basic stuff of spectral theory and kind of lost, in some sense. I am trying to find ways to compute the spectra of different operators, when they work and don't work. For example, by applying directly the definitions, I am able to compute the spectrum of the orthogonal projection to be the set $\{0,I\}$. But, in order to find the essential spectrum of some differential operators, say $L=\partial_{xx}+c\partial_{x}+F$ where $F$ is some linearized term of a nonlinear function $f(u)$, I would perform a Fourier transform $\mathfrak{F}(L)$ and calculate the eigenvalues of this operator. (I am not even sure if this is the correct way of doing it.) Other ways are taking different kinds of transforms (which I have no idea; but by talking to some people, I sensed that taking a Laplace transform sometimes works, too!). I think applying directly the definitions would not be possible in at lot of the cases. Can someone give me references for techniques of finding spectra of different operators, when they fail and work? At least, when I see some kind of operator, I would like to know that I have a sense of what to do. Best regards,",,"['functional-analysis', 'reference-request', 'operator-theory', 'spectral-theory']"
36,Ideals in $B(H)$ are self-adjoint,Ideals in  are self-adjoint,B(H),It is known that every (closed two-sided) ideal in a $C^{*}$-algebra is self-adjoint. The proofs that I've seen involve functional calculus and approximate units. I am wondering whether there is a more direct approach in the particular case of $B(H)$ (for a Hilbert space $H$).,It is known that every (closed two-sided) ideal in a $C^{*}$-algebra is self-adjoint. The proofs that I've seen involve functional calculus and approximate units. I am wondering whether there is a more direct approach in the particular case of $B(H)$ (for a Hilbert space $H$).,,"['functional-analysis', 'operator-theory', 'operator-algebras']"
37,reference for operator algebra,reference for operator algebra,,"I am taking a course on operator algebra this semester. My instructor has suggested a reference ""Kadinson and Ringrose."" Are there any other good/standard references for this subject that I can look up?","I am taking a course on operator algebra this semester. My instructor has suggested a reference ""Kadinson and Ringrose."" Are there any other good/standard references for this subject that I can look up?",,"['functional-analysis', 'reference-request', 'operator-algebras']"
38,Unit ball of a Separable Banach Spaces is metrizable,Unit ball of a Separable Banach Spaces is metrizable,,"Please help me to understand why the unit ball of a separable banach space is metrizable, when it is given the induced topology from the weak topology.  Specifically, my problem is I think I'd be able to do it if I knew the dual was separable, but not with the current given information. (If I had this additional information, I'd use the infinite sum metric tricks that one uses all too often.) The underlying field can be real or complex.","Please help me to understand why the unit ball of a separable banach space is metrizable, when it is given the induced topology from the weak topology.  Specifically, my problem is I think I'd be able to do it if I knew the dual was separable, but not with the current given information. (If I had this additional information, I'd use the infinite sum metric tricks that one uses all too often.) The underlying field can be real or complex.",,"['analysis', 'functional-analysis', 'metric-spaces', 'banach-spaces']"
39,"If a normed space $X$ is reflexive, show that $X'$ is reflexive.","If a normed space  is reflexive, show that  is reflexive.",X X',"If a normed space $X$ is reflexive, show that $X'$ is reflexive. Suppose $X$ is reflexive. Then by definition the Canonical mapping $J : X \to X''$ defined by $x \mapsto g_x$ where $g_x(f) = f(x)$ is an isomorphism. We want to show that the mapping $J' : X' \to X'''$ defined by $f \mapsto h_f$ where $h_f(g_x) = g_x(f)$ is an isomorphism. It will suffice to show that $J'$ is onto. I am unsure about what to do after this. Any help would be greatly appreciated. Some ideas: Choose $h \in X'''$, then by definition $h : X'' \to \mathbb R$ is a linear bounded functional. Try to find $f \in X'$, that is $f$ such that $f : X \to \mathbb R$ (a linear bounded functional) such that the cannonical mapping maps $f \mapsto h$, i.e., $J'(f) = h(f)$.","If a normed space $X$ is reflexive, show that $X'$ is reflexive. Suppose $X$ is reflexive. Then by definition the Canonical mapping $J : X \to X''$ defined by $x \mapsto g_x$ where $g_x(f) = f(x)$ is an isomorphism. We want to show that the mapping $J' : X' \to X'''$ defined by $f \mapsto h_f$ where $h_f(g_x) = g_x(f)$ is an isomorphism. It will suffice to show that $J'$ is onto. I am unsure about what to do after this. Any help would be greatly appreciated. Some ideas: Choose $h \in X'''$, then by definition $h : X'' \to \mathbb R$ is a linear bounded functional. Try to find $f \in X'$, that is $f$ such that $f : X \to \mathbb R$ (a linear bounded functional) such that the cannonical mapping maps $f \mapsto h$, i.e., $J'(f) = h(f)$.",,"['functional-analysis', 'normed-spaces', 'duality-theorems']"
40,"If $A_n$ is a sequence of positive bounded linear operators converging in norm to $A$ on a Hilbert Space, show $\sqrt{A_n}\to\sqrt{A}$ in norm.","If  is a sequence of positive bounded linear operators converging in norm to  on a Hilbert Space, show  in norm.",A_n A \sqrt{A_n}\to\sqrt{A},"If $A_n$ is a sequence of positive bounded linear operators converging in norm to $A$ on a Hilbert Space, show $\sqrt{A_n}\to\sqrt{A}$ in norm. I can show that $A$ would be positive and  thus have a square root, but then I'm mostly stuck. If $A_n=B_n^2$ and $A=B^2$, I have also shown that since $B_n$ is positive it is by definition self adjoint and so $$\|B_n x\| = \sqrt{\langle B_n x, B_n x \rangle} = \sqrt{\langle A_n x, x\rangle} \to \sqrt{\langle Ax,x\rangle} = \|Bx\|2$$ for all $x$ and so therefore $\|B_n\|\to \|B\|$. However, I am completely stuck on the desired result. If I knew $B_n$ and $B$ would commute, then I'd use $$\|A_n^2 - A\| = \|(B_n - B)(B_n + B) \|$$ and play with the inner product, but I don't know this a priori. Thanks for your help. EDIT: For those wondering this question comes from Mathematical Physics I: Functional Analysis by Reed and Simon in chapter 7 question 14.","If $A_n$ is a sequence of positive bounded linear operators converging in norm to $A$ on a Hilbert Space, show $\sqrt{A_n}\to\sqrt{A}$ in norm. I can show that $A$ would be positive and  thus have a square root, but then I'm mostly stuck. If $A_n=B_n^2$ and $A=B^2$, I have also shown that since $B_n$ is positive it is by definition self adjoint and so $$\|B_n x\| = \sqrt{\langle B_n x, B_n x \rangle} = \sqrt{\langle A_n x, x\rangle} \to \sqrt{\langle Ax,x\rangle} = \|Bx\|2$$ for all $x$ and so therefore $\|B_n\|\to \|B\|$. However, I am completely stuck on the desired result. If I knew $B_n$ and $B$ would commute, then I'd use $$\|A_n^2 - A\| = \|(B_n - B)(B_n + B) \|$$ and play with the inner product, but I don't know this a priori. Thanks for your help. EDIT: For those wondering this question comes from Mathematical Physics I: Functional Analysis by Reed and Simon in chapter 7 question 14.",,"['functional-analysis', 'operator-theory']"
41,A few questions about the Hilbert triple/Gelfand triple,A few questions about the Hilbert triple/Gelfand triple,,"I am attempting to fully understand Hilbert triples by reading Brezis' Function Analysis book. Consider $V \subset H \subset V^*$ , where $V$ is Banach and $H$ is Hilbert. $V$ is dense in $H$ . Why do we need density of $V$ ? Assume the injection $V \subset H$ is continuous. There is a canonical map $T:H^* \to V^*$ that just restricts functionals on $H$ to take arguments restricted to $V$ . $T$ has the properties: (1) $|Tf|_{V^*} \leq C|f|_{H^*},$ (2) $T$ is injective, (3) $R(T)$ is dense in $V^*$ if $V$ is reflexive. Why do we need $V \subset H$ to be continuous? What's the need for these three properties? I'm not asking ""why are they true"" but what is the significance of these properties for this discussion? The second one is fine, I suppose. I guess the third property is nice as it says we can get close as want to to an element of $V^*$ by elements on $H^*$ , but so what? Identifying $H^*$ with $H$ and using $T$ as a canonical embedding from $H^*$ into $V^*$ , we write $V \subset H \equiv H^* \subset V^*$ , where all injections are continuous and dense. Why is continuous and dense worth pointing out? The situation is more delicate if $V$ turns out to be a Hilbert space with its own inner product. We could identify $V$ and $V^*$ with this inner product, but then the Hilbert triple becomes absurd. We cannot simulataneously identify both $V$ and $H$ with their dual spaces. Here is a very instructive example. Let $H = \ell^2$ , with $(u,v)_H = \sum u_nv_n$ and $V = \{u : \sum n^2u_n^2 < \infty\}$ with $(u,v)_V = \sum n^2u_nv_n.$ Clearly $V \subset H$ is dense and continuous injection. We identify $H$ with $H^*$ while $V^*$ is identified with $$V^* = \{f : \sum \frac{1}{n^2}f_n^2 < \infty \}$$ which is bigger than $H$ . The scalar product $\langle , \rangle_{V^*, V}$ is $\langle f, v \rangle_{V^*, V}= \sum f_nv_n$ . Can somebody explain this ""instructive example"" to me as I don't understand the point. Sorry for so many questions but I really do not understand this topic well. Thanks for any help. I already read the other threads on this topic btw..","I am attempting to fully understand Hilbert triples by reading Brezis' Function Analysis book. Consider , where is Banach and is Hilbert. is dense in . Why do we need density of ? Assume the injection is continuous. There is a canonical map that just restricts functionals on to take arguments restricted to . has the properties: (1) (2) is injective, (3) is dense in if is reflexive. Why do we need to be continuous? What's the need for these three properties? I'm not asking ""why are they true"" but what is the significance of these properties for this discussion? The second one is fine, I suppose. I guess the third property is nice as it says we can get close as want to to an element of by elements on , but so what? Identifying with and using as a canonical embedding from into , we write , where all injections are continuous and dense. Why is continuous and dense worth pointing out? The situation is more delicate if turns out to be a Hilbert space with its own inner product. We could identify and with this inner product, but then the Hilbert triple becomes absurd. We cannot simulataneously identify both and with their dual spaces. Here is a very instructive example. Let , with and with Clearly is dense and continuous injection. We identify with while is identified with which is bigger than . The scalar product is . Can somebody explain this ""instructive example"" to me as I don't understand the point. Sorry for so many questions but I really do not understand this topic well. Thanks for any help. I already read the other threads on this topic btw..","V \subset H \subset V^* V H V H V V \subset H T:H^* \to V^* H V T |Tf|_{V^*} \leq C|f|_{H^*}, T R(T) V^* V V \subset H V^* H^* H^* H T H^* V^* V \subset H \equiv H^* \subset V^* V V V^* V H H = \ell^2 (u,v)_H = \sum u_nv_n V = \{u : \sum n^2u_n^2 < \infty\} (u,v)_V = \sum n^2u_nv_n. V \subset H H H^* V^* V^* = \{f : \sum \frac{1}{n^2}f_n^2 < \infty \} H \langle , \rangle_{V^*, V} \langle f, v \rangle_{V^*, V}= \sum f_nv_n","['functional-analysis', 'banach-spaces', 'hilbert-spaces']"
42,Completeness of a finite direct sum of closed subspaces of $L^2$,Completeness of a finite direct sum of closed subspaces of,L^2,"Let $X_1$ and $X_2$ be  real-valued square-integrable random variables defined on a probability space $(\Omega, {\cal F},P)$. For $i=1,2$, set $$ A_i := \{g(X_i)\in L^2 \mid g \text{ is some Borel measurable function with } \mathbb{E}g(X_i)=0  \} .$$  Note that $A_i$ forms a Hilbert subspace of $L^2(\Omega, {\cal F},P)$ for each $i$. My question: does $$A_1 + A_2 := \{g_1(X_1) + g_2(X_2): g_i(X_i)\in A_i, \; i=1,2\}$$ equipped with the norm $||\cdot||_{L^2}$ also form a Hilbert subspace of $L^2(\Omega, {\cal F},P)$?","Let $X_1$ and $X_2$ be  real-valued square-integrable random variables defined on a probability space $(\Omega, {\cal F},P)$. For $i=1,2$, set $$ A_i := \{g(X_i)\in L^2 \mid g \text{ is some Borel measurable function with } \mathbb{E}g(X_i)=0  \} .$$  Note that $A_i$ forms a Hilbert subspace of $L^2(\Omega, {\cal F},P)$ for each $i$. My question: does $$A_1 + A_2 := \{g_1(X_1) + g_2(X_2): g_i(X_i)\in A_i, \; i=1,2\}$$ equipped with the norm $||\cdot||_{L^2}$ also form a Hilbert subspace of $L^2(\Omega, {\cal F},P)$?",,"['functional-analysis', 'probability-theory']"
43,"Closed subspace consisting of continuous functions in $L^{2}([0,1])$ is finite-dimensional",Closed subspace consisting of continuous functions in  is finite-dimensional,"L^{2}([0,1])","I wish to show that any closed subspace $M$ of $L^{2}[0,1]$ consisting of continuous real-valued functions is finite-dimensional (which amazes me quite a bit, I must admit). My approach proceeds as follows: Step 0. Note that $L^{2}[0,1]$ is a separable Hilbert space with the usual scalar product on $L^2$ . Moreover, since $M$ is closed, it is separable Hilbert, too, with inner product of $L^2([0,1])$ restricted to $M$ . Step 1. Let $I: (M, \| \cdot \|_{\infty}) \to (M, \| \cdot \|_{2})$ be the identity operator on $M$ . Since $I$ is bijective, by the open mapping theorem, $I^{-1}$ exists in the space of bounded linear operators on $M$ . Hence, for any $f \in M$ , we have $$ \| f\|_{\infty} = \| I^{-1} (f)\|_{\infty} \leq C \|f \|_{2} \quad \forall f \in M,$$ where $C := \| I^{-1} \|.$ Step 2. Now, let $t \in [0,1]$ and consider the linear functional $\ell_{t}: M \to \mathbb{R}, f \mapsto f(t).$ As $M$ is Hilbert, we may apply Riesz representation theorem to deduce that $\ell_{t} = \langle \cdot, g_t \rangle =: \ell_{g_t}$ for some $g_t \in M$ and $\|\ell_{g_t}\| = \| g_t\|_{2}$ . Moreover, $$ f(t) = l_t (f) =  \langle f, g_t \rangle \quad \forall t \in [0,1].$$ Using step 1, we may further conclude that $\| g_t \|_{2} \leq C$ . Step 3. By seperability of $M$ , we may suppose that $S = \{h_{n}: n \in \mathbb{N}\}$ is a orthonormal basis of $M$ . Then, Parseval's identity yields $$ \infty > \|g_t\|_{2} = \sum_{h \in S} | \langle h, g_t \rangle |^{2} = \sum_{h \in S} |h(t)|^{2} $$ I am stuck in the last line. I want to argue that this sum has to be finite. Can we bound $|h(t)|$ from below? I guess, this suffices to conclude, right? Does this argument work?","I wish to show that any closed subspace of consisting of continuous real-valued functions is finite-dimensional (which amazes me quite a bit, I must admit). My approach proceeds as follows: Step 0. Note that is a separable Hilbert space with the usual scalar product on . Moreover, since is closed, it is separable Hilbert, too, with inner product of restricted to . Step 1. Let be the identity operator on . Since is bijective, by the open mapping theorem, exists in the space of bounded linear operators on . Hence, for any , we have where Step 2. Now, let and consider the linear functional As is Hilbert, we may apply Riesz representation theorem to deduce that for some and . Moreover, Using step 1, we may further conclude that . Step 3. By seperability of , we may suppose that is a orthonormal basis of . Then, Parseval's identity yields I am stuck in the last line. I want to argue that this sum has to be finite. Can we bound from below? I guess, this suffices to conclude, right? Does this argument work?","M L^{2}[0,1] L^{2}[0,1] L^2 M L^2([0,1]) M I: (M, \| \cdot \|_{\infty}) \to (M, \| \cdot \|_{2}) M I I^{-1} M f \in M  \| f\|_{\infty} = \| I^{-1} (f)\|_{\infty} \leq C \|f \|_{2} \quad \forall f \in M, C := \| I^{-1} \|. t \in [0,1] \ell_{t}: M \to \mathbb{R}, f \mapsto f(t). M \ell_{t} = \langle \cdot, g_t \rangle =: \ell_{g_t} g_t \in M \|\ell_{g_t}\| = \| g_t\|_{2}  f(t) = l_t (f) =  \langle f, g_t \rangle \quad \forall t \in [0,1]. \| g_t \|_{2} \leq C M S = \{h_{n}: n \in \mathbb{N}\} M 
\infty > \|g_t\|_{2} = \sum_{h \in S} | \langle h, g_t \rangle |^{2} = \sum_{h \in S} |h(t)|^{2}
 |h(t)|",['functional-analysis']
44,If quotient space $X/Y$ is complete then $X$ is complete,If quotient space  is complete then  is complete,X/Y X,"It is well-known that if $X$ is a Banach space and $Y$ is a closed subspace then $X /Y$ with quotient norm $$ \| [x] \|_{X/Y} = \inf_{y \in Y} \| x-y \| $$ is a Banach space. I am trying to prove the converse: Let $X$ be a normed space, $Y$ its closed subspace which is complete. If $X/Y$ is complete spce, then $X$ is complete. My attempts was to equivalently prove that $X$ is not complete and conclude that $X/Y$ cannot be complete. Assume that there exists sequence $(x_n)$ in $X$ which is Cauchy, but not convergent. Using the inequality  $$ \| [x_n ] \|_{X/Y} \leq \| x \|_X $$ we obtain that sequence $ ([x_n])$ is Cauchy in $X/Y$. Next step, that I cant make would be to prove that it is not convergent, or that this allows us to construct non-convergent Cauchy sequence. I also proved that $Y$ has to be complete, I have a counterexample otherwise. So this fact has to be used somehow. Note that this is an exercise for first weeks of introductory functional analysis course, so I can't use any advanced techniques.","It is well-known that if $X$ is a Banach space and $Y$ is a closed subspace then $X /Y$ with quotient norm $$ \| [x] \|_{X/Y} = \inf_{y \in Y} \| x-y \| $$ is a Banach space. I am trying to prove the converse: Let $X$ be a normed space, $Y$ its closed subspace which is complete. If $X/Y$ is complete spce, then $X$ is complete. My attempts was to equivalently prove that $X$ is not complete and conclude that $X/Y$ cannot be complete. Assume that there exists sequence $(x_n)$ in $X$ which is Cauchy, but not convergent. Using the inequality  $$ \| [x_n ] \|_{X/Y} \leq \| x \|_X $$ we obtain that sequence $ ([x_n])$ is Cauchy in $X/Y$. Next step, that I cant make would be to prove that it is not convergent, or that this allows us to construct non-convergent Cauchy sequence. I also proved that $Y$ has to be complete, I have a counterexample otherwise. So this fact has to be used somehow. Note that this is an exercise for first weeks of introductory functional analysis course, so I can't use any advanced techniques.",,"['functional-analysis', 'banach-spaces', 'quotient-spaces']"
45,Dirac's delta in 3 dimensions: proof of $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$,Dirac's delta in 3 dimensions: proof of,\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0),"If $T_f$ is a distribution, i.e. a linear functional, continuous according to the convergence defined here , defined on the space $K$ of the functions of class $C^\infty$ that are null outside a bounded interval (which is not the same for all functions), its derivative is defined as $$\frac{dT_f}{dx}(\varphi):=-T_f(\varphi')$$where $\varphi'$ is the derivative of $\varphi$. The symbolic writing $T_f(\varphi)=\int_{-\infty}^\infty f(x)\varphi(x)dx$ is often used to write such a functional, since, if $g$ is (Riemann or Lebesgue) integrable on every bounded interval, then $\int_{-\infty}^\infty g(x)\varphi(x)dx$ indeed is such a continuous functional. In this context, we can symbolically define the ""derivative"" $f'$, for any $T_f$, even if the symbolic writing $f$ does not refer to an integrable function, according to the expression$$\int_{-\infty}^\infty f'(x)\varphi(x)dx:=-\int_{-\infty}^\infty f(x)\varphi'(x)dx=:\frac{dT_f}{dx}(\varphi).$$ Let us come to my question. While studying physics, in particular the theory of electromagnetism and the derivation of the Biot-Savart law from Ampère's law , I always find the equality$$\nabla^2\left(\frac{1}{\|\boldsymbol{x}-\boldsymbol{x}_0\|}\right)=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$$where $\nabla^2$ is the Laplacian $^1$. I suppose that, in the tridimensional case, with $\phi:\mathbb{R}^3\to\mathbb{R}$, $\int_{\mathbb{R}^3}\frac{\partial f(\boldsymbol{x})}{\partial x_i}\phi(\boldsymbol{x}) dx_1dx_2dx_3$ is analogously defined as $\frac{\partial T_f}{\partial x_i}(\varphi)$, which I suppose to be analogously defined, in turn, as $-\int_{\mathbb{R}^3}f(\boldsymbol{x})\frac{\partial \phi(\boldsymbol{x})}{\partial x_i} dx_1dx_2dx_3$, although I say I suppose because I have not found a rigourous definition of such derivatives on line nor in cartaceous texts; as to mathematical resources, I have studied Kolmogorov-Fomin's Элементы теории функций и функционального анализа , which only focuses on the monodimensional $\varphi:\mathbb{R}\to\mathbb{R}$ case. Once fixed a proper definition of such derivatives, how can it be proved that $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$? $^1$ The link contains a derivation of $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$ (equations (18)-(24)) , but I do not understand it: I would understand it if we could apply Gauss's divergence theorem at (20), but I know it for functions of class $C^1(\mathring{A})$, $\overline{V}\subset\mathring{A}$, only, while $\nabla\left(\frac{1}{\|\boldsymbol{x}-\boldsymbol{x}_0\|}\right)$ is not even defined for $\boldsymbol{x}=\boldsymbol{x}_0$; the other derivation of the identity $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})$ $=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$ that I have found uses a ""weak limit"", but it does not use the formal definiton of derivative of a distribution that I have written above. These are the two only references addressing what I am asking that I have managed to find.","If $T_f$ is a distribution, i.e. a linear functional, continuous according to the convergence defined here , defined on the space $K$ of the functions of class $C^\infty$ that are null outside a bounded interval (which is not the same for all functions), its derivative is defined as $$\frac{dT_f}{dx}(\varphi):=-T_f(\varphi')$$where $\varphi'$ is the derivative of $\varphi$. The symbolic writing $T_f(\varphi)=\int_{-\infty}^\infty f(x)\varphi(x)dx$ is often used to write such a functional, since, if $g$ is (Riemann or Lebesgue) integrable on every bounded interval, then $\int_{-\infty}^\infty g(x)\varphi(x)dx$ indeed is such a continuous functional. In this context, we can symbolically define the ""derivative"" $f'$, for any $T_f$, even if the symbolic writing $f$ does not refer to an integrable function, according to the expression$$\int_{-\infty}^\infty f'(x)\varphi(x)dx:=-\int_{-\infty}^\infty f(x)\varphi'(x)dx=:\frac{dT_f}{dx}(\varphi).$$ Let us come to my question. While studying physics, in particular the theory of electromagnetism and the derivation of the Biot-Savart law from Ampère's law , I always find the equality$$\nabla^2\left(\frac{1}{\|\boldsymbol{x}-\boldsymbol{x}_0\|}\right)=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$$where $\nabla^2$ is the Laplacian $^1$. I suppose that, in the tridimensional case, with $\phi:\mathbb{R}^3\to\mathbb{R}$, $\int_{\mathbb{R}^3}\frac{\partial f(\boldsymbol{x})}{\partial x_i}\phi(\boldsymbol{x}) dx_1dx_2dx_3$ is analogously defined as $\frac{\partial T_f}{\partial x_i}(\varphi)$, which I suppose to be analogously defined, in turn, as $-\int_{\mathbb{R}^3}f(\boldsymbol{x})\frac{\partial \phi(\boldsymbol{x})}{\partial x_i} dx_1dx_2dx_3$, although I say I suppose because I have not found a rigourous definition of such derivatives on line nor in cartaceous texts; as to mathematical resources, I have studied Kolmogorov-Fomin's Элементы теории функций и функционального анализа , which only focuses on the monodimensional $\varphi:\mathbb{R}\to\mathbb{R}$ case. Once fixed a proper definition of such derivatives, how can it be proved that $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$? $^1$ The link contains a derivation of $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$ (equations (18)-(24)) , but I do not understand it: I would understand it if we could apply Gauss's divergence theorem at (20), but I know it for functions of class $C^1(\mathring{A})$, $\overline{V}\subset\mathring{A}$, only, while $\nabla\left(\frac{1}{\|\boldsymbol{x}-\boldsymbol{x}_0\|}\right)$ is not even defined for $\boldsymbol{x}=\boldsymbol{x}_0$; the other derivation of the identity $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})$ $=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$ that I have found uses a ""weak limit"", but it does not use the formal definiton of derivative of a distribution that I have written above. These are the two only references addressing what I am asking that I have managed to find.",,"['functional-analysis', 'physics', 'distribution-theory', 'dirac-delta', 'laplacian']"
46,Is every Hilbert space a Banach algebra?,Is every Hilbert space a Banach algebra?,,"Let $H$ be a Hilbert space. Could we say that, always there is a multiplication on $H$, that makes it into a Banach algebra? If not, under which conditions does it exist?","Let $H$ be a Hilbert space. Could we say that, always there is a multiplication on $H$, that makes it into a Banach algebra? If not, under which conditions does it exist?",,"['functional-analysis', 'hilbert-spaces', 'harmonic-analysis', 'banach-algebras']"
47,Why is such an operator continuous?,Why is such an operator continuous?,,"These two questions were in one question of a list of exercises. Let $E$ be a Banach space and $T : E \longrightarrow E^*$ be linear. If $\langle T(x),x \rangle \geq 0$ holds for all $x \in E$, then $T$ is continuous. If $\langle T(x),y \rangle = \langle x ,T(y) \rangle$ holds for all $x, y \in E$, then $T$ is continuous. I tried to expand it, as in the proof of the Cauchy-Schwarz inequality, to get a polynomial of degree $2$. Any solution or hint?","These two questions were in one question of a list of exercises. Let $E$ be a Banach space and $T : E \longrightarrow E^*$ be linear. If $\langle T(x),x \rangle \geq 0$ holds for all $x \in E$, then $T$ is continuous. If $\langle T(x),y \rangle = \langle x ,T(y) \rangle$ holds for all $x, y \in E$, then $T$ is continuous. I tried to expand it, as in the proof of the Cauchy-Schwarz inequality, to get a polynomial of degree $2$. Any solution or hint?",,"['functional-analysis', 'operator-theory']"
48,Are the bounded Lipschitz functions dense in $L^1(\mu)$?,Are the bounded Lipschitz functions dense in ?,L^1(\mu),"I am currently reading a paper (L. Ambrosio and B. Kirchheim. Currents in metric spaces) and I stumbled uppon a fact which I don't know how to prove. I have the following setting: Let $X$ be a complete metric space, $\mu$ a finite Borel measure and let $\text{Lip}_b(X)$ denote the bounded Lipschitz functions $X \rightarrow \mathbb{R}$ . Then $\text{Lip}_b(X)$ is supposed to be dense in $L^1(X,\mu)$ . I assume I need to do something with some density of $\text{Lip}_b(X)$ in $C(X, \mathbb{R})$ , but since we don't have any compactness assumptions, we can't apply Stone-Weierstrass and I don't know how we got that fact.","I am currently reading a paper (L. Ambrosio and B. Kirchheim. Currents in metric spaces) and I stumbled uppon a fact which I don't know how to prove. I have the following setting: Let be a complete metric space, a finite Borel measure and let denote the bounded Lipschitz functions . Then is supposed to be dense in . I assume I need to do something with some density of in , but since we don't have any compactness assumptions, we can't apply Stone-Weierstrass and I don't know how we got that fact.","X \mu \text{Lip}_b(X) X \rightarrow \mathbb{R} \text{Lip}_b(X) L^1(X,\mu) \text{Lip}_b(X) C(X, \mathbb{R})","['functional-analysis', 'lipschitz-functions']"
49,Finding the Spectrum of integral operator,Finding the Spectrum of integral operator,,"I have the following integral operator: $$(Ku)(x)=\int_{0}^{1} k(x,y)u(y) \mathop{dy}$$ with $k(x,y)=$min $ \{ x,y \}$ for $0 \leq x,y \leq 1$.$\\$ I have already shown $K$ is a compact, self adjoint operator but now I want to find the spectrum of $K$. I do not understand how to do this. Do I need to find the eigenvalues? If so, how would I go about doing this? (I am self teaching myself functional analysis so perhaps there is an easy way to do this that I just haven't come across? $\\$ Thanks in advance.","I have the following integral operator: $$(Ku)(x)=\int_{0}^{1} k(x,y)u(y) \mathop{dy}$$ with $k(x,y)=$min $ \{ x,y \}$ for $0 \leq x,y \leq 1$.$\\$ I have already shown $K$ is a compact, self adjoint operator but now I want to find the spectrum of $K$. I do not understand how to do this. Do I need to find the eigenvalues? If so, how would I go about doing this? (I am self teaching myself functional analysis so perhaps there is an easy way to do this that I just haven't come across? $\\$ Thanks in advance.",,['functional-analysis']
50,Trace class for operators,Trace class for operators,,"Let $ \mathcal{H} $ be a Hilbert space and $ T: \mathcal{H} \to \mathcal{H} $ a bounded linear operator. The $ n $-th singular number $ {\mu_{n}}(T) $ of $ T $ is defined as the distance from $ T $ to the space of operators of rank at most $ n $. We say that $ T $ is in the trace class if   $$ \sum_{n} {\mu_{n}}(T) < \infty. $$   Show that in this case, $ T $ is compact and if $ \{ \lambda_{n} \} $ are its eigenvalues, then $$ \sum_{n} |\lambda_{n}| < \infty. $$   Also, show that, in general, the converse is not true. I have not seen this definition of ‘trace class’ before. Can anyone give me some hints? Can I approximate $ T $ with finite-rank operators?","Let $ \mathcal{H} $ be a Hilbert space and $ T: \mathcal{H} \to \mathcal{H} $ a bounded linear operator. The $ n $-th singular number $ {\mu_{n}}(T) $ of $ T $ is defined as the distance from $ T $ to the space of operators of rank at most $ n $. We say that $ T $ is in the trace class if   $$ \sum_{n} {\mu_{n}}(T) < \infty. $$   Show that in this case, $ T $ is compact and if $ \{ \lambda_{n} \} $ are its eigenvalues, then $$ \sum_{n} |\lambda_{n}| < \infty. $$   Also, show that, in general, the converse is not true. I have not seen this definition of ‘trace class’ before. Can anyone give me some hints? Can I approximate $ T $ with finite-rank operators?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators']"
51,Topologies on the space $\mathcal D'(U)$ of distributions,Topologies on the space  of distributions,\mathcal D'(U),"In my analysis lecture I am given a topology on the space of distributions as follows: Let $u_k$ be a sequence in $\mathcal D'(u)$, $u \in \mathcal D'(u)$. We say $u_k \rightarrow u$, if $\forall \phi \in \mathcal D(u) : u_k(\phi) \rightarrow u(\phi)$. This is the weak-$*$-topology on $\mathcal D'(u)$. It seems lecturers don't care too much about the topology of $\mathcal D'(u)$, hence I wonder whether there are stronger topologies on $\mathcal D'(u)$.","In my analysis lecture I am given a topology on the space of distributions as follows: Let $u_k$ be a sequence in $\mathcal D'(u)$, $u \in \mathcal D'(u)$. We say $u_k \rightarrow u$, if $\forall \phi \in \mathcal D(u) : u_k(\phi) \rightarrow u(\phi)$. This is the weak-$*$-topology on $\mathcal D'(u)$. It seems lecturers don't care too much about the topology of $\mathcal D'(u)$, hence I wonder whether there are stronger topologies on $\mathcal D'(u)$.",,"['functional-analysis', 'distribution-theory']"
52,Complete Inequivalent Norms,Complete Inequivalent Norms,,"So I know of the following result: If $X$ is infinite dimensional, then number of inequivalent norms on $X$ is $2^{\dim X}$. I was wondering if there is a similar result for complete norms. Basically I want to know how many complete inequivalent norms exist on an infinite dimensional space. Edit 1 : Is it at least possible to get a bound? Edit 2 : I now know an example of a space with no complete norms. So I would like to change my question to: If there exist  a complete norm on an infinite dimensional vector space, then can we get an upper bound to number of inequivalent complete norms? I also know that given a complete norm, we can construct an inequivalent complete norm. How to proceed further? Any hints are appreciated.","So I know of the following result: If $X$ is infinite dimensional, then number of inequivalent norms on $X$ is $2^{\dim X}$. I was wondering if there is a similar result for complete norms. Basically I want to know how many complete inequivalent norms exist on an infinite dimensional space. Edit 1 : Is it at least possible to get a bound? Edit 2 : I now know an example of a space with no complete norms. So I would like to change my question to: If there exist  a complete norm on an infinite dimensional vector space, then can we get an upper bound to number of inequivalent complete norms? I also know that given a complete norm, we can construct an inequivalent complete norm. How to proceed further? Any hints are appreciated.",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
53,Norm of convolution,Norm of convolution,,"Let $f,g: \mathbb{R}^n \to R$. Let $|| \cdot ||_T$ be a translation invariant norm on functions on $\mathbb{R}^n$. How can I prove that $||f*g||_T \leq ||f||_1 ||g||_T$ (where $f*g$ means convolution and $|| \cdot ||_1$ means $L^1$ norm). I suppose I should specify the class of functions $f,g$ are of, but just take them to be functions such that the norms are well defined. In fact I will settle for a formal proof of the inequality. Any help is appreciated!","Let $f,g: \mathbb{R}^n \to R$. Let $|| \cdot ||_T$ be a translation invariant norm on functions on $\mathbb{R}^n$. How can I prove that $||f*g||_T \leq ||f||_1 ||g||_T$ (where $f*g$ means convolution and $|| \cdot ||_1$ means $L^1$ norm). I suppose I should specify the class of functions $f,g$ are of, but just take them to be functions such that the norms are well defined. In fact I will settle for a formal proof of the inequality. Any help is appreciated!",,"['functional-analysis', 'normed-spaces', 'convolution']"
54,$\mathcal{L}^2$-norm of the Laplace transform,-norm of the Laplace transform,\mathcal{L}^2,"I have been considering the Laplace transform $$\mathcal{L}(f)(s)=\int_{0}^{\infty}{f(t)\, e^{-st}dt}$$ defined on $s\in\mathbb{R}^{+}$ as an linear operator from $\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)$ to $\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)$. I have managed to prove that it is well-defined, linear and bounded in the sense that $$||{\mathcal{L}(f)}| |_{\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)}\leq \sqrt{\pi}\cdot ||f||_{\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)}$$ Hence I have established that the operator-norm of $\mathcal{L}$, denoted $||\mathcal{L}||$ is bounded by $\sqrt{\pi}$, however my question is if the constant $\sqrt{\pi}$ is essentially sharp? If it is, how does one prove such a thing? I have tried pluggin in $f(t)=\frac{1}{\sqrt{t}}\cdot 1_{(a,b)}$ ,  where $0<a<b<\infty$, but without any success.","I have been considering the Laplace transform $$\mathcal{L}(f)(s)=\int_{0}^{\infty}{f(t)\, e^{-st}dt}$$ defined on $s\in\mathbb{R}^{+}$ as an linear operator from $\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)$ to $\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)$. I have managed to prove that it is well-defined, linear and bounded in the sense that $$||{\mathcal{L}(f)}| |_{\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)}\leq \sqrt{\pi}\cdot ||f||_{\mathcal{L}^{2}(\mathbb{R}^{+},\lambda)}$$ Hence I have established that the operator-norm of $\mathcal{L}$, denoted $||\mathcal{L}||$ is bounded by $\sqrt{\pi}$, however my question is if the constant $\sqrt{\pi}$ is essentially sharp? If it is, how does one prove such a thing? I have tried pluggin in $f(t)=\frac{1}{\sqrt{t}}\cdot 1_{(a,b)}$ ,  where $0<a<b<\infty$, but without any success.",,"['functional-analysis', 'operator-theory', 'laplace-transform', 'linear-transformations']"
55,Does weak convergence in $L^2$ implies convergence almost everywhere along subsequence?,Does weak convergence in  implies convergence almost everywhere along subsequence?,L^2,"If I know $\int_{[0,1]} f_{n}(x) g(x) dx \rightarrow  \int_{[0,1]} f(x) g(x) dx$ as $n \rightarrow \infty$ for all $g \in L^2([0,1])$ (weak convergence in $L^2$) and $|f_n(x)|_{L^2} <C$ (uniformly bounded in $L^2$-Norm), does then exist a subsequence $f_{n_k}$ such that $\lim_{n \rightarrow \infty}f_{n_k}(x) = f(x)$ for almost every $x \in [0,1]$? Edit: If uniform boundedness in $L^2$ norm is not enough would $f_n$ being uniformly bounded in $L^\infty$ norm help to get a subsequence?","If I know $\int_{[0,1]} f_{n}(x) g(x) dx \rightarrow  \int_{[0,1]} f(x) g(x) dx$ as $n \rightarrow \infty$ for all $g \in L^2([0,1])$ (weak convergence in $L^2$) and $|f_n(x)|_{L^2} <C$ (uniformly bounded in $L^2$-Norm), does then exist a subsequence $f_{n_k}$ such that $\lim_{n \rightarrow \infty}f_{n_k}(x) = f(x)$ for almost every $x \in [0,1]$? Edit: If uniform boundedness in $L^2$ norm is not enough would $f_n$ being uniformly bounded in $L^\infty$ norm help to get a subsequence?",,"['functional-analysis', 'convergence-divergence', 'weak-convergence']"
56,"norm of integral operator in $C([0,1])$",norm of integral operator in,"C([0,1])","If we define on $C([0,1])$ the operator $$ Tf(x) = \int_{0}^{1} K(t,s) f(s) ds$$ where $K$ is a continous function on two variables. I want to show that: $1)$ $||T|| = \displaystyle\max_{t} {\int_{0}^{1} |K(t,s)| ds} $ $2)$ When $K(t,s) = \displaystyle\min(t,s)$, to prove that $T$ is compact Thanks.","If we define on $C([0,1])$ the operator $$ Tf(x) = \int_{0}^{1} K(t,s) f(s) ds$$ where $K$ is a continous function on two variables. I want to show that: $1)$ $||T|| = \displaystyle\max_{t} {\int_{0}^{1} |K(t,s)| ds} $ $2)$ When $K(t,s) = \displaystyle\min(t,s)$, to prove that $T$ is compact Thanks.",,"['functional-analysis', 'operator-theory', 'normed-spaces']"
57,Compact maps problem in Lax,Compact maps problem in Lax,,"In Functional Analysis of Peter Lax there are the following exercise Show that if $\bf C$ is compact and $\{{\bf M}_n \}$ tends strongly to $\bf M$, then $\bf CM_n$ tends uniformly to $\bf CM$. Assumptions are that ${\bf C}: {\bf X} \rightarrow {\bf X},{\bf M_n}: {\bf X} \rightarrow {\bf X}$ where $\bf X$ is a Banach space I was thinking that one could use that if let $x_i$ be such that $|({\bf M_i-M})x_i|\ge||{\bf M_i-M}|| - \epsilon $. Then from compactness of $\bf C$ we have that there is a finite sequence $j=1\ldots,n$ of ${\bf C}({\bf M_j-M})x_j$ s.t $\min_j ||{\bf C}({\bf M_j-M})x_j - {\bf C}({\bf M_i-M})x_i||<\epsilon$ for all i. But I dont get anywhere.","In Functional Analysis of Peter Lax there are the following exercise Show that if $\bf C$ is compact and $\{{\bf M}_n \}$ tends strongly to $\bf M$, then $\bf CM_n$ tends uniformly to $\bf CM$. Assumptions are that ${\bf C}: {\bf X} \rightarrow {\bf X},{\bf M_n}: {\bf X} \rightarrow {\bf X}$ where $\bf X$ is a Banach space I was thinking that one could use that if let $x_i$ be such that $|({\bf M_i-M})x_i|\ge||{\bf M_i-M}|| - \epsilon $. Then from compactness of $\bf C$ we have that there is a finite sequence $j=1\ldots,n$ of ${\bf C}({\bf M_j-M})x_j$ s.t $\min_j ||{\bf C}({\bf M_j-M})x_j - {\bf C}({\bf M_i-M})x_i||<\epsilon$ for all i. But I dont get anywhere.",,"['functional-analysis', 'convergence-divergence', 'operator-theory', 'compactness']"
58,"Given $f$ holomorphic, which are the necessary conditions on $\phi$ in order to make $\phi \circ f \circ \phi^{-1}$ holomorphic?","Given  holomorphic, which are the necessary conditions on  in order to make  holomorphic?",f \phi \phi \circ f \circ \phi^{-1},"It is well known that $\bar f(\bar z)$ is holomorphic whenever f is. I was wondering how to generalize this fact... Let $f: \Omega \longrightarrow \mathbb{C}$ be holomorphic and $\phi: \mathbb{C} \longrightarrow \mathbb{C}$ be an homeomorphism where $\Omega \subseteq \mathbb{C}$ is open. We need the exsistence of the limit $\lim_{h \rightarrow 0} \frac{\phi \circ f \circ \phi^{-1}(z_0 + h) - \phi \circ f \circ \phi^{-1}(z_0)}{h}$ , if $\phi$ is Frechet differentiable this is equivalent to asking for the existence of $\lim_{h \rightarrow 0} \frac{D\phi(f \circ \phi^{-1}(z_0))[f'(\phi^{-1}(z_0))\cdot D\phi^{-1}(z_0)[h]]}{h}$ . I've then found the following sufficient conditions: i) $\phi(z + w) = \phi(z) + \eta(w)$ ii) $\eta(z \cdot w) = \psi(z) \cdot \eta(w)$ Where $\eta,\psi: \mathbb{C} \longrightarrow \mathbb{C}$ and $\eta$ is an homeomorphism. Then $\forall z_0 \in \mathbb{C}.$ $D\phi(z_0)$ exists and $D\phi(z_0) = \eta$ thus $\forall y_0 \in \mathbb{C}$ . $D\phi^{-1}(y_0) = \eta^{-1}$ . Moreover we have $D\phi(f \circ \phi^{-1}(z_0))[f'(\phi^{-1}(z_0))\cdot D\phi^{-1}(z_0)[h]] = \eta(f'(\phi^{-1}(z_0)) \cdot \eta^{-1}(h)) = \psi(f'(\phi^{-1}(z_0))) \cdot h$ , thus the limit exists and has value $\psi(f'(\phi^{-1}(z_0)))$ As an example we can take $\phi(z) = \alpha z + \beta$ with $\alpha, \beta \in \mathbb(C)$ , then $\eta(z) = \alpha z$ and $\psi(z) = z$ thus $(\phi \circ f \circ \phi^{-1})'(z_0) = f'(\frac{z_0}{\alpha} - \frac{\beta}{\alpha})$ and sure enough if we use the standard method to evaluate this derivative we get the same resut. Conditions i) and ii) above are then sufficient, are they necessary too? If not does there exist a complete characterization of such $\phi$ 's?","It is well known that is holomorphic whenever f is. I was wondering how to generalize this fact... Let be holomorphic and be an homeomorphism where is open. We need the exsistence of the limit , if is Frechet differentiable this is equivalent to asking for the existence of . I've then found the following sufficient conditions: i) ii) Where and is an homeomorphism. Then exists and thus . . Moreover we have , thus the limit exists and has value As an example we can take with , then and thus and sure enough if we use the standard method to evaluate this derivative we get the same resut. Conditions i) and ii) above are then sufficient, are they necessary too? If not does there exist a complete characterization of such 's?","\bar f(\bar z) f: \Omega \longrightarrow \mathbb{C} \phi: \mathbb{C} \longrightarrow \mathbb{C} \Omega \subseteq \mathbb{C} \lim_{h \rightarrow 0} \frac{\phi \circ f \circ \phi^{-1}(z_0 + h) - \phi \circ f \circ \phi^{-1}(z_0)}{h} \phi \lim_{h \rightarrow 0} \frac{D\phi(f \circ \phi^{-1}(z_0))[f'(\phi^{-1}(z_0))\cdot D\phi^{-1}(z_0)[h]]}{h} \phi(z + w) = \phi(z) + \eta(w) \eta(z \cdot w) = \psi(z) \cdot \eta(w) \eta,\psi: \mathbb{C} \longrightarrow \mathbb{C} \eta \forall z_0 \in \mathbb{C}. D\phi(z_0) D\phi(z_0) = \eta \forall y_0 \in \mathbb{C} D\phi^{-1}(y_0) = \eta^{-1} D\phi(f \circ \phi^{-1}(z_0))[f'(\phi^{-1}(z_0))\cdot D\phi^{-1}(z_0)[h]] = \eta(f'(\phi^{-1}(z_0)) \cdot \eta^{-1}(h)) = \psi(f'(\phi^{-1}(z_0))) \cdot h \psi(f'(\phi^{-1}(z_0))) \phi(z) = \alpha z + \beta \alpha, \beta \in \mathbb(C) \eta(z) = \alpha z \psi(z) = z (\phi \circ f \circ \phi^{-1})'(z_0) = f'(\frac{z_0}{\alpha} - \frac{\beta}{\alpha}) \phi","['complex-analysis', 'functional-analysis', 'frechet-derivative']"
59,Semi-group theory and Poisson equation on the upper half plane,Semi-group theory and Poisson equation on the upper half plane,,"We first look at the 2D Laplace equation , say on the upper half plane: $$\Delta u=0,\quad -\infty<x<\infty, y>0$$ $$u(x,0)=g(x),$$ where $g\in L^p(\mathbb{R})$ for some $1\leq p<\infty$. Then the general solution can be represented using the Poisson kernel $$P_y(x)=\frac{y}{\pi(y^2+x^2)},$$ with $$u(x,y)=(P_y*g)(x)=\frac{1}{\pi}\int_{-\infty}^\infty \frac{y}{y^2+(x-t)^2}g(t)dt.$$ Now if we define the following linear operator on $L^p(\mathbb{R})$: $$T_yg(x)=(P_y*g)(x).$$ Then we can verify that the family $\{T_y\}_{y\geq 0}$, satisfies the semi-group properties: $T_0=\mathrm{id}$, i.e. $T_0$ is the identity operator; $T_{y+s}=T_yT_s$ for any $y,s\geq 0$. Thus we see that we can study solutions of the Laplace equation from the view of semi-group theory. Here is my question: Can we perform similar analysis to the Poission equation? i.e. consider the solutions of the poisson equation from the view of semi-group theory? The Poisson equation is basically the laplace equation with a source term $$-\Delta u=f(x,y),\quad -\infty<x<\infty, y>0$$ $$u(x,0)=g(x),$$ here we use the same domain as above. In this case the general solution can be represented by using the Green's function: $$G(x,y)=\frac{1}{2\pi}\ln\sqrt{x^2+y^2},$$ with $$u(x,y)=\int_{\mathbb{R}\times\mathbb{R}^+}G(x-x',y-y')f(x',y')dx'dy'+\int_{\{y=0\}}g(x')\frac{\partial G}{\partial\mathbf{n}}(x-x',y-y')dS,$$ where in the second integral above $\mathbf{n}$ is the normal vector of $\{y=0\}$ pointing ourwards the domain $\mathbb{R}\times\mathbb{R}^+$. If we want to view the solution from semi-group theory, then we need to find a suitable Banach space $X$ and a family of bounded linear operators $\{T_t\}_{t\geq 0}$ on $X$ which form a semi-group. But I'm not sure whether this can be done. Any ideas on this question are greatly appreciated.","We first look at the 2D Laplace equation , say on the upper half plane: $$\Delta u=0,\quad -\infty<x<\infty, y>0$$ $$u(x,0)=g(x),$$ where $g\in L^p(\mathbb{R})$ for some $1\leq p<\infty$. Then the general solution can be represented using the Poisson kernel $$P_y(x)=\frac{y}{\pi(y^2+x^2)},$$ with $$u(x,y)=(P_y*g)(x)=\frac{1}{\pi}\int_{-\infty}^\infty \frac{y}{y^2+(x-t)^2}g(t)dt.$$ Now if we define the following linear operator on $L^p(\mathbb{R})$: $$T_yg(x)=(P_y*g)(x).$$ Then we can verify that the family $\{T_y\}_{y\geq 0}$, satisfies the semi-group properties: $T_0=\mathrm{id}$, i.e. $T_0$ is the identity operator; $T_{y+s}=T_yT_s$ for any $y,s\geq 0$. Thus we see that we can study solutions of the Laplace equation from the view of semi-group theory. Here is my question: Can we perform similar analysis to the Poission equation? i.e. consider the solutions of the poisson equation from the view of semi-group theory? The Poisson equation is basically the laplace equation with a source term $$-\Delta u=f(x,y),\quad -\infty<x<\infty, y>0$$ $$u(x,0)=g(x),$$ here we use the same domain as above. In this case the general solution can be represented by using the Green's function: $$G(x,y)=\frac{1}{2\pi}\ln\sqrt{x^2+y^2},$$ with $$u(x,y)=\int_{\mathbb{R}\times\mathbb{R}^+}G(x-x',y-y')f(x',y')dx'dy'+\int_{\{y=0\}}g(x')\frac{\partial G}{\partial\mathbf{n}}(x-x',y-y')dS,$$ where in the second integral above $\mathbf{n}$ is the normal vector of $\{y=0\}$ pointing ourwards the domain $\mathbb{R}\times\mathbb{R}^+$. If we want to view the solution from semi-group theory, then we need to find a suitable Banach space $X$ and a family of bounded linear operators $\{T_t\}_{t\geq 0}$ on $X$ which form a semi-group. But I'm not sure whether this can be done. Any ideas on this question are greatly appreciated.",,"['functional-analysis', 'partial-differential-equations', 'operator-theory', 'poissons-equation', 'semigroup-of-operators']"
60,What is the commutative analogue of a $C^*$-subalgebra?,What is the commutative analogue of a -subalgebra?,C^*,"Using the duality between locally compact Hausdorff spaces and commutative $C^*$-algebras one can write down a vocabulary list translating topological notions regarding a locally compact Hausdorff space $X$ into algebraic notions ragarding its ring of functions $C_0(X)$ (see Wegge-Olsen's book, for instance). For example, we have the following correspondences: \begin{align*} \text{open subset of $X$}\quad &\longleftrightarrow\quad\text{ideal in $C_0(X)$}\newline \text{dense open subset of $X$}\quad &\longleftrightarrow\quad\text{essential ideal in $C_0(X)$}\newline \text{closed subset of $X$}\quad &\longleftrightarrow\quad\text{quotient of $C_0(X)$}\newline \text{locally closed subset of $X$}\quad &\longleftrightarrow\quad\text{subquotient of $C_0(X)$}\newline \text{???}\quad &\longleftrightarrow\quad\text{$C^*$-subalgebra in $C_0(X)$} \end{align*} By ideal I always mean a two-sided closed (and hence self-adjoint) ideal. Well, I can't quite see how to reconvert a $C^*$-subalgebra in $C_0(X)$ into something topological involving only the space $X$. Can you come up with something handy? Example: A simple example of a subalgebra of a commutative $C^*$-algebra not being an ideal is $$ \mathbb C\cdot(1,1)\subset \mathbb C\oplus\mathbb C. $$ (Alternatively, we could think about this question within the duality of affine algebraic varieties and finitely generated commutative reduced algebras or even within the duality between affine schemes and commutative rings.) Edit: Since I was not completely satisfied by the response I got here, I reposted this question on MO .","Using the duality between locally compact Hausdorff spaces and commutative $C^*$-algebras one can write down a vocabulary list translating topological notions regarding a locally compact Hausdorff space $X$ into algebraic notions ragarding its ring of functions $C_0(X)$ (see Wegge-Olsen's book, for instance). For example, we have the following correspondences: \begin{align*} \text{open subset of $X$}\quad &\longleftrightarrow\quad\text{ideal in $C_0(X)$}\newline \text{dense open subset of $X$}\quad &\longleftrightarrow\quad\text{essential ideal in $C_0(X)$}\newline \text{closed subset of $X$}\quad &\longleftrightarrow\quad\text{quotient of $C_0(X)$}\newline \text{locally closed subset of $X$}\quad &\longleftrightarrow\quad\text{subquotient of $C_0(X)$}\newline \text{???}\quad &\longleftrightarrow\quad\text{$C^*$-subalgebra in $C_0(X)$} \end{align*} By ideal I always mean a two-sided closed (and hence self-adjoint) ideal. Well, I can't quite see how to reconvert a $C^*$-subalgebra in $C_0(X)$ into something topological involving only the space $X$. Can you come up with something handy? Example: A simple example of a subalgebra of a commutative $C^*$-algebra not being an ideal is $$ \mathbb C\cdot(1,1)\subset \mathbb C\oplus\mathbb C. $$ (Alternatively, we could think about this question within the duality of affine algebraic varieties and finitely generated commutative reduced algebras or even within the duality between affine schemes and commutative rings.) Edit: Since I was not completely satisfied by the response I got here, I reposted this question on MO .",,"['functional-analysis', 'noncommutative-geometry', 'c-star-algebras']"
61,Is the failure of $\mathcal{B}(H)\simeq H\otimes H^*$ in infinite dimensions the reason for non-normal states in quantum information?,Is the failure of  in infinite dimensions the reason for non-normal states in quantum information?,\mathcal{B}(H)\simeq H\otimes H^*,"In the algebraic formulation of quantum physics/information, states $\omega: \mathcal{A}\rightarrow \mathbb{C}$ are defined as linear functionals on a $C^*$ -algebra $\mathcal{A}$ (algebra of observables, representable as a subalgebra of $\mathcal{B}(H)$ for some Hilbert space $H$ via the GNS construction) that are positive ( $\omega(A^*A)\geq 0\,\forall A\in \mathcal{A}$ ) and normalized ( $\omega(I)=1$ for $\mathcal{A}$ with unit element $I$ or an equivalent condition for non-unital $\mathcal{A}$ ). These quantum states are then usually represented as density operators defined via $\omega(A)=:\text{Tr}(\omega A)$ , but it is well-known that in infinite dimensions there are so-called non-normal states that are not representable this way. Is this due to the fact that for infinite dimensions $\mathcal{B}(\mathcal{H})\simeq H\otimes H^*$ does not hold?","In the algebraic formulation of quantum physics/information, states are defined as linear functionals on a -algebra (algebra of observables, representable as a subalgebra of for some Hilbert space via the GNS construction) that are positive ( ) and normalized ( for with unit element or an equivalent condition for non-unital ). These quantum states are then usually represented as density operators defined via , but it is well-known that in infinite dimensions there are so-called non-normal states that are not representable this way. Is this due to the fact that for infinite dimensions does not hold?","\omega: \mathcal{A}\rightarrow \mathbb{C} C^* \mathcal{A} \mathcal{B}(H) H \omega(A^*A)\geq 0\,\forall A\in \mathcal{A} \omega(I)=1 \mathcal{A} I \mathcal{A} \omega(A)=:\text{Tr}(\omega A) \mathcal{B}(\mathcal{H})\simeq H\otimes H^*","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'quantum-mechanics']"
62,About non-separable Hilbert spaces,About non-separable Hilbert spaces,,"On Reed & Simon, vol 2, chapter X, problem 4, it is asked: Let $M$ and $N$ be closed subspaces of a separable Hilbert space. If $\dim M > \dim N$, prove that $M\cap N^{\perp} \ne \{0\}$. Here, $\dim V$ is the cardinality of a Hilbert basis for $V$. The solution is pretty straightforward, since we must have $\dim N = n \in \mathbb{N}$ and therefore it becomes a linear algebra problem. My question is: does it hold for non-separable Hilbert spaces? I couldn't prove it or think in counterexamples for it. Thanks in advance!","On Reed & Simon, vol 2, chapter X, problem 4, it is asked: Let $M$ and $N$ be closed subspaces of a separable Hilbert space. If $\dim M > \dim N$, prove that $M\cap N^{\perp} \ne \{0\}$. Here, $\dim V$ is the cardinality of a Hilbert basis for $V$. The solution is pretty straightforward, since we must have $\dim N = n \in \mathbb{N}$ and therefore it becomes a linear algebra problem. My question is: does it hold for non-separable Hilbert spaces? I couldn't prove it or think in counterexamples for it. Thanks in advance!",,"['functional-analysis', 'hilbert-spaces', 'geometric-functional-analysis']"
63,Krein-Smulian counterexample for the weak (not *) topology.,Krein-Smulian counterexample for the weak (not *) topology.,,"The Krein-Smulian Theorem states that for a convex set S, having weak*-closed intersections with closed balls implies being weak*-closed. I would be really happy to have an example of a NOT weak-closed convex subset $S$ of a Banach space, such that the intersection with the closed balls are always weak-closed. In this post , there are some counterexamples for the ""convex"" hypothesis. I would like to have counterexamples for the ""weak*"" hypothesis.","The Krein-Smulian Theorem states that for a convex set S, having weak*-closed intersections with closed balls implies being weak*-closed. I would be really happy to have an example of a NOT weak-closed convex subset $S$ of a Banach space, such that the intersection with the closed balls are always weak-closed. In this post , there are some counterexamples for the ""convex"" hypothesis. I would like to have counterexamples for the ""weak*"" hypothesis.",,"['functional-analysis', 'banach-spaces', 'examples-counterexamples', 'weak-convergence']"
64,Understanding why Minkowski’s inequality doesn't hold true for $0 < p < 1$?,Understanding why Minkowski’s inequality doesn't hold true for ?,0 < p < 1,"The triangle inequality given by $\left(\sum_{i=1}^n |x_i+y_i|^p\right)^{1/p}\leq \left(\sum_{i=1}^n |x_i|^p\right)^{1/p} + \left(\sum_{i=1}^n |y_i|^p\right)^{1/p}$ is known as “Minkowski’s inequality"" which holds true for $1\leq p <\infty$ while for $0 < p < 1$ it doesn't  hold. Searching through net I have found that this inequality holds for $1\leq p <\infty$  is related to the observation that for such $p$ the function $x \to x^p$ for $x \geq 0$ is convex. The failure of the triangle inequality is related to the observation that for $0 < p < 1$,the function $x \to x^p$ for $x \geq 0$ is not convex. I am not able to understand these points. Could anybody explain me? Thanks","The triangle inequality given by $\left(\sum_{i=1}^n |x_i+y_i|^p\right)^{1/p}\leq \left(\sum_{i=1}^n |x_i|^p\right)^{1/p} + \left(\sum_{i=1}^n |y_i|^p\right)^{1/p}$ is known as “Minkowski’s inequality"" which holds true for $1\leq p <\infty$ while for $0 < p < 1$ it doesn't  hold. Searching through net I have found that this inequality holds for $1\leq p <\infty$  is related to the observation that for such $p$ the function $x \to x^p$ for $x \geq 0$ is convex. The failure of the triangle inequality is related to the observation that for $0 < p < 1$,the function $x \to x^p$ for $x \geq 0$ is not convex. I am not able to understand these points. Could anybody explain me? Thanks",,"['functional-analysis', 'inequality']"
65,Convolution of two Schwartz functions is Schwartz,Convolution of two Schwartz functions is Schwartz,,"I am trying to show directly (i.e., not using the Fourier transform) that if $S=S(\mathbb{R}^n)$ is the class of Schwartz functions then $f,g \in S$ implies $f*g \in S$. The definition I have is $f \in S$ iff for all $N$, $\|f\|_N:=\sup_{x \in \mathbb{R}^d, |\alpha|,|\beta| \leq N} |x^\beta\partial_x^\alpha f(x)|<\infty$. I have shown that $\|f\|_N<\infty$ is equivalent to: for all $|\alpha|,|\beta| \leq N$, there exists a constant $C_N$ such that $|\partial_x^\alpha f(x)| \leq \frac{C_N}{\prod_{i=1}^n (1+|x_i^{\beta_i}|)}$. I also know that $\partial_x^\alpha (f*g)(x) = \int_{\mathbb{R}^n} \partial_x^\alpha f(x-t) g(t) \ dt$. Since $\partial_x^\alpha f \in S$, I believe it suffices to show that for all $f,g \in S$, all $N$, and all $|\beta| \leq N$, we have $|(f*g)(x)| \leq \frac{C_N}{\prod_{i=1}^n (1+|x_i^{\beta_i}|)}$. I can prove this in the case $\mathbb{R}^n=\mathbb{R}$ as follows: Let $C_N$ be such that for all $b \leq N$, $|f(x)|,|g(x)| \leq \frac{C_N}{1+|x|^b}$. Then \begin{align*} \left| \int_{\mathbb{R}} f(x-t)g(t) \ dt \right| & \leq \int_{\mathbb{R}} \left| f(x-t)g(t)\right| \ dt\\ &= \int_{|x-t| \geq |x|/2} \left| f(x-t)g(t)\right| \ dt + \int_{|x-t| < |x|/2} \left|f(x-t)g(t)\right| \ dt\\ &\leq \sup_{|x-t| \geq |x|/2} |f(x-t)|\int_{\mathbb{R}}|g(t)| \ dt + \sup_{|t| \geq |x|/2} |g(t)| \int_{\mathbb{R}} |f(x-t)| \ dt\\ &\leq \sup_{|x-t| \geq |x|/2}\frac{C_N}{1+|x-t|^b} \|g\|_{L^1} + \sup_{|t| \geq |x|/2}\frac{C_N}{1+|t|^b} \|f\|_{L^1}\\ &\leq \frac{C_N(\|g\|_{L^1}+\|f\|_{L^2})}{1+(|x|/2)^b}\\ & \leq \frac{2^NC_N(\|g\|_{L^1}+\|f\|_{L^2})}{1+|x|^b}.  \end{align*} (Note that $|x-t|<|x|/2$ implies $|t|>|x|/2$.) However, I am struggling with how to split up the integral in $\mathbb{R}^n$. In order to do the step  $\frac{C_N}{\prod_{i=1}^n (1+|x_i-t_i|^{\beta_i})} \leq \frac{C_N}{\prod_{i=1}^n (1+(|x_i|/2)^{\beta_i})}$ I need $|x_i-t_i| \geq |x_i|/2$ for all $i$. But in order to do the step $\frac{C_N}{\prod_{i=1}^n (1+|t_i|^{\beta_i})} \leq \frac{C_N}{\prod_{i=1}^n (1+(|x_i|/2)^{\beta_i})} $ I need $|t_i| \geq |x_i|/2$ for all $i$. However these two sets do not encompass all of $\mathbb{R}^n$ (in particular, we miss all $t$ such that $|x_i-t_i| < |x_i|/2$ for some $i$ and $|t_j| < |x_j|/2$ for some $j$). I have tried integrating over one copy of $\mathbb{R}$ at a time, but as soon as we replace $f$ and $g$ by their upper bounds in the innermost integral, they are no longer guaranteed to have finite $L^1$ norm, so I cannot continue. (Note: I can show the inequality holds for $N=1$, i.e., $x^\beta = x_i$ for some $i$. Is that enough?) Any suggestions would be greatly appreciated.","I am trying to show directly (i.e., not using the Fourier transform) that if $S=S(\mathbb{R}^n)$ is the class of Schwartz functions then $f,g \in S$ implies $f*g \in S$. The definition I have is $f \in S$ iff for all $N$, $\|f\|_N:=\sup_{x \in \mathbb{R}^d, |\alpha|,|\beta| \leq N} |x^\beta\partial_x^\alpha f(x)|<\infty$. I have shown that $\|f\|_N<\infty$ is equivalent to: for all $|\alpha|,|\beta| \leq N$, there exists a constant $C_N$ such that $|\partial_x^\alpha f(x)| \leq \frac{C_N}{\prod_{i=1}^n (1+|x_i^{\beta_i}|)}$. I also know that $\partial_x^\alpha (f*g)(x) = \int_{\mathbb{R}^n} \partial_x^\alpha f(x-t) g(t) \ dt$. Since $\partial_x^\alpha f \in S$, I believe it suffices to show that for all $f,g \in S$, all $N$, and all $|\beta| \leq N$, we have $|(f*g)(x)| \leq \frac{C_N}{\prod_{i=1}^n (1+|x_i^{\beta_i}|)}$. I can prove this in the case $\mathbb{R}^n=\mathbb{R}$ as follows: Let $C_N$ be such that for all $b \leq N$, $|f(x)|,|g(x)| \leq \frac{C_N}{1+|x|^b}$. Then \begin{align*} \left| \int_{\mathbb{R}} f(x-t)g(t) \ dt \right| & \leq \int_{\mathbb{R}} \left| f(x-t)g(t)\right| \ dt\\ &= \int_{|x-t| \geq |x|/2} \left| f(x-t)g(t)\right| \ dt + \int_{|x-t| < |x|/2} \left|f(x-t)g(t)\right| \ dt\\ &\leq \sup_{|x-t| \geq |x|/2} |f(x-t)|\int_{\mathbb{R}}|g(t)| \ dt + \sup_{|t| \geq |x|/2} |g(t)| \int_{\mathbb{R}} |f(x-t)| \ dt\\ &\leq \sup_{|x-t| \geq |x|/2}\frac{C_N}{1+|x-t|^b} \|g\|_{L^1} + \sup_{|t| \geq |x|/2}\frac{C_N}{1+|t|^b} \|f\|_{L^1}\\ &\leq \frac{C_N(\|g\|_{L^1}+\|f\|_{L^2})}{1+(|x|/2)^b}\\ & \leq \frac{2^NC_N(\|g\|_{L^1}+\|f\|_{L^2})}{1+|x|^b}.  \end{align*} (Note that $|x-t|<|x|/2$ implies $|t|>|x|/2$.) However, I am struggling with how to split up the integral in $\mathbb{R}^n$. In order to do the step  $\frac{C_N}{\prod_{i=1}^n (1+|x_i-t_i|^{\beta_i})} \leq \frac{C_N}{\prod_{i=1}^n (1+(|x_i|/2)^{\beta_i})}$ I need $|x_i-t_i| \geq |x_i|/2$ for all $i$. But in order to do the step $\frac{C_N}{\prod_{i=1}^n (1+|t_i|^{\beta_i})} \leq \frac{C_N}{\prod_{i=1}^n (1+(|x_i|/2)^{\beta_i})} $ I need $|t_i| \geq |x_i|/2$ for all $i$. However these two sets do not encompass all of $\mathbb{R}^n$ (in particular, we miss all $t$ such that $|x_i-t_i| < |x_i|/2$ for some $i$ and $|t_j| < |x_j|/2$ for some $j$). I have tried integrating over one copy of $\mathbb{R}$ at a time, but as soon as we replace $f$ and $g$ by their upper bounds in the innermost integral, they are no longer guaranteed to have finite $L^1$ norm, so I cannot continue. (Note: I can show the inequality holds for $N=1$, i.e., $x^\beta = x_i$ for some $i$. Is that enough?) Any suggestions would be greatly appreciated.",,"['functional-analysis', 'convolution']"
66,$\|\hat{f} \|_{\infty} = \lim _ {n \rightarrow \infty} (\|f^{(n)}\|_1)^{1/n}$,,\|\hat{f} \|_{\infty} = \lim _ {n \rightarrow \infty} (\|f^{(n)}\|_1)^{1/n},"Let $f \in L^2 \cap L^1$ on the Real line, and define $f^{(n)}$ to be the $n$-fold convolution $f \circ f ... \circ f $. I want to show that $||\hat{f} ||_{\infty} = \lim _ {n \rightarrow \infty} (||f^{(n)}||_1)^{1/n}$, using the tools of Fourier analysis on $L_1$ and $L_2$. And actually I'm only stuck on the fact that the RHS $\le$ LHS. A formal proof would be something like this, but I'm stuck on technicalities: \begin{align}\lim_n (\|f^{(n)}\|_1)^{1/n} &= \lim_n [\int f^{(n)} \overline{\exp{ (i \arg f^{(n)})}}]^{1/n}   = \lim_n \left\langle f^{(n)}, \exp{ (i \arg f^{(n)})}\right\rangle  ^{1/n}\\   & = \lim_n \left\langle\widehat{f^{(n)}}, \widehat{\exp{ (i \arg f^{(n)})}}\right\rangle^{1/n}    = \lim_n \left\langle{\hat{f}^n}, \widehat{\exp{ (i \arg f^{(n)})}}\right\rangle^{1/n}  \\ & = \lim_n \left[\int \hat{f}^n \overline{\widehat{\exp{ (i \arg f^{(n)})}}}\right]^{1/n}    \le \lim_n \left[\| \hat{f} \|^n _\infty\int \overline{\widehat{\exp{ (i \arg f^{(n)})}}}\right]^{1/n}    \le \|\hat{f}\|_\infty \end{align} Trouble is, $\exp{ (i \arg f^{(n)})}$ is not integrable since its magnitude is always 1. I have tried to do an approach where I insert $g_k$ where $g_k$ is a compact smooth ""hill"" function which becomes wider and wider and limits to $1$, and this allows me to arrive at \begin{align} \lim_n (||f^n||_1)^{1/n} &= \lim_n \lim_k [\int f^{(n)} \overline{g_k \exp{ (i \arg f^{(n)})}}]^{1/n} \\    &\le \lim_n \lim_k \left[\| \hat{f} \|^n _\infty\int \overline{\widehat{g_k \exp{ (i \arg f^{(n)})}}}\right]^{1/n}\\ & \le \| \hat{f} \|_\infty \lim_n \lim_k \int \overline{\widehat{g_k \exp{ (i \arg f^{(n)})}}}]^{1/n}  \end{align} But I can't actually take the limit $k$ because then the term will go to infinity. I thought of making $k$ a function of $n$ but then I couldn't show that this doesn't change the limit. This strategy is taken from an analogous proof on the periodic circle with discrete Fourier transform, and I would like to see if it can be fixed somehow (because this was the hint given by the text).","Let $f \in L^2 \cap L^1$ on the Real line, and define $f^{(n)}$ to be the $n$-fold convolution $f \circ f ... \circ f $. I want to show that $||\hat{f} ||_{\infty} = \lim _ {n \rightarrow \infty} (||f^{(n)}||_1)^{1/n}$, using the tools of Fourier analysis on $L_1$ and $L_2$. And actually I'm only stuck on the fact that the RHS $\le$ LHS. A formal proof would be something like this, but I'm stuck on technicalities: \begin{align}\lim_n (\|f^{(n)}\|_1)^{1/n} &= \lim_n [\int f^{(n)} \overline{\exp{ (i \arg f^{(n)})}}]^{1/n}   = \lim_n \left\langle f^{(n)}, \exp{ (i \arg f^{(n)})}\right\rangle  ^{1/n}\\   & = \lim_n \left\langle\widehat{f^{(n)}}, \widehat{\exp{ (i \arg f^{(n)})}}\right\rangle^{1/n}    = \lim_n \left\langle{\hat{f}^n}, \widehat{\exp{ (i \arg f^{(n)})}}\right\rangle^{1/n}  \\ & = \lim_n \left[\int \hat{f}^n \overline{\widehat{\exp{ (i \arg f^{(n)})}}}\right]^{1/n}    \le \lim_n \left[\| \hat{f} \|^n _\infty\int \overline{\widehat{\exp{ (i \arg f^{(n)})}}}\right]^{1/n}    \le \|\hat{f}\|_\infty \end{align} Trouble is, $\exp{ (i \arg f^{(n)})}$ is not integrable since its magnitude is always 1. I have tried to do an approach where I insert $g_k$ where $g_k$ is a compact smooth ""hill"" function which becomes wider and wider and limits to $1$, and this allows me to arrive at \begin{align} \lim_n (||f^n||_1)^{1/n} &= \lim_n \lim_k [\int f^{(n)} \overline{g_k \exp{ (i \arg f^{(n)})}}]^{1/n} \\    &\le \lim_n \lim_k \left[\| \hat{f} \|^n _\infty\int \overline{\widehat{g_k \exp{ (i \arg f^{(n)})}}}\right]^{1/n}\\ & \le \| \hat{f} \|_\infty \lim_n \lim_k \int \overline{\widehat{g_k \exp{ (i \arg f^{(n)})}}}]^{1/n}  \end{align} But I can't actually take the limit $k$ because then the term will go to infinity. I thought of making $k$ a function of $n$ but then I couldn't show that this doesn't change the limit. This strategy is taken from an analogous proof on the periodic circle with discrete Fourier transform, and I would like to see if it can be fixed somehow (because this was the hint given by the text).",,"['functional-analysis', 'fourier-analysis']"
67,Absolut convergence implies being in trace class,Absolut convergence implies being in trace class,,"I'm asking for your help in the next problem, I can't think how to do it! Prove that if $$\sum_{n=1}^{\infty}|(A\phi_n,\phi_n)|<\infty$$ for all orthonormal bases, then $A$ is in the trace class. I think the fact that the hypothesis is true for all orthonormal bases is the hint, but I don't know!  Thank you.","I'm asking for your help in the next problem, I can't think how to do it! Prove that if $$\sum_{n=1}^{\infty}|(A\phi_n,\phi_n)|<\infty$$ for all orthonormal bases, then $A$ is in the trace class. I think the fact that the hypothesis is true for all orthonormal bases is the hint, but I don't know!  Thank you.",,"['functional-analysis', 'operator-theory', 'trace']"
68,"Why are $L^p$ spaces for $p\not=1,2,\infty$ important?",Why are  spaces for  important?,"L^p p\not=1,2,\infty","$L^p$ spaces for arbitrary $1\le p\le\infty$  are a mainstay of basic functional analysis courses, but I've only seen them ""in action"" when $p$ is 1, 2, or $\infty$. Can anyone give an ""elementary"" concrete example of an application of another $L^p$ space?","$L^p$ spaces for arbitrary $1\le p\le\infty$  are a mainstay of basic functional analysis courses, but I've only seen them ""in action"" when $p$ is 1, 2, or $\infty$. Can anyone give an ""elementary"" concrete example of an application of another $L^p$ space?",,"['functional-analysis', 'lp-spaces']"
69,distributivity of tensor product and direct sum for Hilbert spaces,distributivity of tensor product and direct sum for Hilbert spaces,,"Before I ask my actual question about direct sums and tensor products of Hilbert spaces, let's first talk about direct sums and tensor products of vector spaces. We might define direct sums of vector spaces by the corresponding universal mapping property, but for later, it's more useful to work with a constructive definition. For a family $\{V_i\}_{i \in I}$ of vector spaces, we may define the direct sum $\bigoplus_{i \in I} V_i$ to be the set of all sequences $(v_i)_{i \in I}$ for which $v_i \in V_i$ for all $i \in I$ and $v_i = 0$ for all but finitely many $i \in I$, endowed with the component-wise vector addition $(v_i)_{i \in I} + (w_i)_{i \in I} = (v_i + w_i)_{i \in I}$ and the scalar multiplication $\alpha (v_i)_{i \in I} = (\alpha v_i)_{i \in I}$. I won't repeat the definition of the tensor product of vector spaces here. For the direct sum and the tensor product of vector spaces, it holds that the they are distributive in the sense that there is a canonical isomorphism  \begin{align*}   W \otimes \bigoplus_{i \in I} V_i \simeq \bigoplus_{i \in I} (W \otimes V_i) \,, \end{align*} where $w \otimes (v_i)_{i \in I} \mapsto (w \otimes v_i)_{i \in I}$, as explained, for example, in Theorem 5.4 in this document about tensor products . For Hilbert spaces, the direct sum explained above does not lead necessarily lead to Hilbert spaces since the (vector space) direct sum of infinitely many Hilbert spaces is not complete. Thus, for Hilbert spaces, one usually defines the direct sum as follows. For a family $\{H_i\}_{i \in I}$ of Hilbert spaces, we may define the direct sum $\bigoplus_{i \in I} H_i$ to be the set of all sequences $(v_i)_{i \in I}$ for which $v_i \in H_i$ for all $i \in I$, $v_i = 0$ for all but countably many $i \in I$ and $\sum_{i \in I} \Vert v_i \Vert^2 < \infty$, endowed with the component-wise vector addition $(v_i)_{i \in I} + (w_i)_{i \in I} = (v_i + w_i)_{i \in I}$ and the scalar multiplication $\alpha (v_i)_{i \in I} = (\alpha v_i)_{i \in I}$. The inner product on this space is given by $\langle (v_i)_{i \in I}, (w_i)_{i \in I} \rangle = \sum_{i \in I} \langle v_i, w_i \rangle$. For Hilbert spaces, the (vector space) tensor product does not necessarily lead to Hilbert spaces since the tensor product of infinite-dimensional Hilbert spaces is not complete. However, one may define the tensor product of two Hilbert spaces $H$ and $K$ to be the metric completion of the vector space tensor product with respect to the inner product $\langle v_1 \otimes w_1, v_2 \otimes w_2 \rangle = \langle v_1, v_2 \rangle \langle w_1, w_2 \rangle$ on $H \otimes K$. (See the Wikipedia article on tensor products of Hilbert spaces .) My question: For this ""Hilbert space direct sum"" and ""Hilbert space tensor product"", is there also a canonical isomorphism \begin{align*}   K \otimes \bigoplus_{i \in I} H_i \simeq \bigoplus_{i \in I} (K \otimes H_i)? \end{align*} I know that the tensor product for Hilbert spaces fails to have the universal property (at least for continuous linear functions). Hence, if this would be needed in the proof of the distributivity, then distributivity fails.","Before I ask my actual question about direct sums and tensor products of Hilbert spaces, let's first talk about direct sums and tensor products of vector spaces. We might define direct sums of vector spaces by the corresponding universal mapping property, but for later, it's more useful to work with a constructive definition. For a family $\{V_i\}_{i \in I}$ of vector spaces, we may define the direct sum $\bigoplus_{i \in I} V_i$ to be the set of all sequences $(v_i)_{i \in I}$ for which $v_i \in V_i$ for all $i \in I$ and $v_i = 0$ for all but finitely many $i \in I$, endowed with the component-wise vector addition $(v_i)_{i \in I} + (w_i)_{i \in I} = (v_i + w_i)_{i \in I}$ and the scalar multiplication $\alpha (v_i)_{i \in I} = (\alpha v_i)_{i \in I}$. I won't repeat the definition of the tensor product of vector spaces here. For the direct sum and the tensor product of vector spaces, it holds that the they are distributive in the sense that there is a canonical isomorphism  \begin{align*}   W \otimes \bigoplus_{i \in I} V_i \simeq \bigoplus_{i \in I} (W \otimes V_i) \,, \end{align*} where $w \otimes (v_i)_{i \in I} \mapsto (w \otimes v_i)_{i \in I}$, as explained, for example, in Theorem 5.4 in this document about tensor products . For Hilbert spaces, the direct sum explained above does not lead necessarily lead to Hilbert spaces since the (vector space) direct sum of infinitely many Hilbert spaces is not complete. Thus, for Hilbert spaces, one usually defines the direct sum as follows. For a family $\{H_i\}_{i \in I}$ of Hilbert spaces, we may define the direct sum $\bigoplus_{i \in I} H_i$ to be the set of all sequences $(v_i)_{i \in I}$ for which $v_i \in H_i$ for all $i \in I$, $v_i = 0$ for all but countably many $i \in I$ and $\sum_{i \in I} \Vert v_i \Vert^2 < \infty$, endowed with the component-wise vector addition $(v_i)_{i \in I} + (w_i)_{i \in I} = (v_i + w_i)_{i \in I}$ and the scalar multiplication $\alpha (v_i)_{i \in I} = (\alpha v_i)_{i \in I}$. The inner product on this space is given by $\langle (v_i)_{i \in I}, (w_i)_{i \in I} \rangle = \sum_{i \in I} \langle v_i, w_i \rangle$. For Hilbert spaces, the (vector space) tensor product does not necessarily lead to Hilbert spaces since the tensor product of infinite-dimensional Hilbert spaces is not complete. However, one may define the tensor product of two Hilbert spaces $H$ and $K$ to be the metric completion of the vector space tensor product with respect to the inner product $\langle v_1 \otimes w_1, v_2 \otimes w_2 \rangle = \langle v_1, v_2 \rangle \langle w_1, w_2 \rangle$ on $H \otimes K$. (See the Wikipedia article on tensor products of Hilbert spaces .) My question: For this ""Hilbert space direct sum"" and ""Hilbert space tensor product"", is there also a canonical isomorphism \begin{align*}   K \otimes \bigoplus_{i \in I} H_i \simeq \bigoplus_{i \in I} (K \otimes H_i)? \end{align*} I know that the tensor product for Hilbert spaces fails to have the universal property (at least for continuous linear functions). Hence, if this would be needed in the proof of the distributivity, then distributivity fails.",,"['functional-analysis', 'hilbert-spaces', 'tensor-products', 'direct-sum']"
70,"Weak convergence in $L^{2}(0,T;H^{-1}(\Omega))$",Weak convergence in,"L^{2}(0,T;H^{-1}(\Omega))","What does weak convergence in $L^{2}(0,T;H^{-1}(\Omega))$ means? $\Omega$ is open, bounded, has boundary smooth  and etc...","What does weak convergence in $L^{2}(0,T;H^{-1}(\Omega))$ means? $\Omega$ is open, bounded, has boundary smooth  and etc...",,"['functional-analysis', 'sobolev-spaces', 'weak-convergence', 'bochner-spaces']"
71,"gradient flow and what is, for example, $L^2$ gradient? [duplicate]","gradient flow and what is, for example,  gradient? [duplicate]",L^2,"This question already has an answer here : What is the $L^2$ gradient flow? (1 answer) Closed 3 years ago . Am I right that the gradient flow of a functional $E$ is $$f_t = -\nabla E(f).$$ Solving this for $f$ gives you a minimiser of $E$ in some way? Here the $\nabla$ denotes the gradient or the first variation or Gateaux derivative or whatever is appropriate. What is meant by ""$L^2$ gradient (flow)"" or ""$H^{-1}$ gradient (flow)?"" Thanks","This question already has an answer here : What is the $L^2$ gradient flow? (1 answer) Closed 3 years ago . Am I right that the gradient flow of a functional $E$ is $$f_t = -\nabla E(f).$$ Solving this for $f$ gives you a minimiser of $E$ in some way? Here the $\nabla$ denotes the gradient or the first variation or Gateaux derivative or whatever is appropriate. What is meant by ""$L^2$ gradient (flow)"" or ""$H^{-1}$ gradient (flow)?"" Thanks",,['functional-analysis']
72,Capacity theory beginner resources,Capacity theory beginner resources,,"I'm currently studying a book on shape optimization: Variation et optimisation de formes: Une analyse géométrique By Antoine Henrot, Michel Pierre . The book introduces at some point capacity, and uses this to define quasi-open sets, quasi continuous functions, and these results apply very nice to approximation theorems in Sobolev spaces. As a remark, this is one of the few mathematical concepts I searched on Google, and found nothing like a wikipedia article or some sites which contain good knowledge about this subject in a beginner's terms. The capacity is defined for compact sets first like this: For $K\subset \Bbb{R}^N$ compact, we denote $cap(K)=\inf \{ \|v\|_{H^1(\Bbb{R}^N)}^2 : v \in C_0^\infty(\Bbb{R}^N),\ v \geq 1 \text{ on }K\}<\infty$. $C_0^\infty$ is the space of smooth functions with compact support. From here, capacity extends to open sets, by taking the supremum on the capacities of compact sets contained in an open set. The relative capacity is defined for a compact $K$ subset of a bounded open set $D\subset \Bbb{R}^N$ by $cap_D(K)=\inf\{ \int_D |\nabla v|^2 : v \in C_0^\infty(D),\ v \geq 1 \text{ on }K\}<\infty$. I understood pretty well the Lebesgue measure by finding a way to visualize it (surely, this is not hard). I would like to know if there is something similar for capacity. How could I visualize it or understand it? How it relates to the physical reality? For example, what does the capacity of a ball or box in $\Bbb{R}^3,\Bbb{R}^n$ mean (for Lebesgue measure is the ""volume"")? I would like to know if there are some books which treat the capacity subject in a manner like measure theory books do it, with many proved properties and some study problems to understand it better. How can I understand capacity related to some physical aspect (shape, smoothness, finess...)? What are some good references for a beginner in the field?","I'm currently studying a book on shape optimization: Variation et optimisation de formes: Une analyse géométrique By Antoine Henrot, Michel Pierre . The book introduces at some point capacity, and uses this to define quasi-open sets, quasi continuous functions, and these results apply very nice to approximation theorems in Sobolev spaces. As a remark, this is one of the few mathematical concepts I searched on Google, and found nothing like a wikipedia article or some sites which contain good knowledge about this subject in a beginner's terms. The capacity is defined for compact sets first like this: For $K\subset \Bbb{R}^N$ compact, we denote $cap(K)=\inf \{ \|v\|_{H^1(\Bbb{R}^N)}^2 : v \in C_0^\infty(\Bbb{R}^N),\ v \geq 1 \text{ on }K\}<\infty$. $C_0^\infty$ is the space of smooth functions with compact support. From here, capacity extends to open sets, by taking the supremum on the capacities of compact sets contained in an open set. The relative capacity is defined for a compact $K$ subset of a bounded open set $D\subset \Bbb{R}^N$ by $cap_D(K)=\inf\{ \int_D |\nabla v|^2 : v \in C_0^\infty(D),\ v \geq 1 \text{ on }K\}<\infty$. I understood pretty well the Lebesgue measure by finding a way to visualize it (surely, this is not hard). I would like to know if there is something similar for capacity. How could I visualize it or understand it? How it relates to the physical reality? For example, what does the capacity of a ball or box in $\Bbb{R}^3,\Bbb{R}^n$ mean (for Lebesgue measure is the ""volume"")? I would like to know if there are some books which treat the capacity subject in a manner like measure theory books do it, with many proved properties and some study problems to understand it better. How can I understand capacity related to some physical aspect (shape, smoothness, finess...)? What are some good references for a beginner in the field?",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'self-learning', 'book-recommendation']"
73,Spectrum of sum of operators on Banach spaces,Spectrum of sum of operators on Banach spaces,,"Let $A$ and $B$ be two operators on a Banach space $X$. I am interested in the relationship between the spectra of $A$, $B$ and $A+B$. In particular, are there any set theoretic inclusions or everything can happen in general like: $\sigma(A)\subset\sigma(A+B)$, and conversely, $\sigma(B)\subset\sigma(A+B)$, and conversely? If we know the spectra $\sigma(A)$, $\sigma(B)$ of $A$ and $B$, can we determine the spectrum of $A+B$? I would appreciate any comment or reference.","Let $A$ and $B$ be two operators on a Banach space $X$. I am interested in the relationship between the spectra of $A$, $B$ and $A+B$. In particular, are there any set theoretic inclusions or everything can happen in general like: $\sigma(A)\subset\sigma(A+B)$, and conversely, $\sigma(B)\subset\sigma(A+B)$, and conversely? If we know the spectra $\sigma(A)$, $\sigma(B)$ of $A$ and $B$, can we determine the spectrum of $A+B$? I would appreciate any comment or reference.",,"['reference-request', 'functional-analysis', 'spectral-theory']"
74,Reference Request: Full mathematical treatment of Schrödinger evolution of hydrogen atom,Reference Request: Full mathematical treatment of Schrödinger evolution of hydrogen atom,,"This is to request a reference on the above problem. I have checked various references in the mathematical physics literature and could not really find a clear, satisfactory answer to some questions, or at least I was unable to extract them myself. In particular, I would like to know the following: It is known among mathematical physicists that most problems in quantum mechanics cannot be fully dealt with by just looking at a particular (separable) Hilbert space and are more appropriately dealt with in terms of a Gelfand triple (one reason being that $L^2$ functions are not differentiable). I suspect that in the above problem a ""natural choice"" for that triple is $$\mathcal{S}(\mathbb{R}^3,\mathbb{C}) \subset L^2(\mathbb{R}^3,\mathbb{C}) \hookrightarrow \left( \mathcal{S}(\mathbb{R}^3,\mathbb{C}) \right)^* \, ,$$ where on the left we have the space of complex-valued Schwartz functions in $\mathbb{R}^3$ , in the center we have the respective space of square-integrable functions, and on the right the respective tempered distributions. I base that suspicion on the fact that the common stationary states $\Psi_{n l m}$ are elements of $\mathcal{S}(\mathbb{R}^3,\mathbb{C})$ . Is what is usually assumed in most physics textbooks mathematically correct, namely that any $\Phi \in L^2(\mathbb{R}^3,\mathbb{C}) $ admits a series representation of the form $$\Phi = \sum_{n, l, m} a_{n l m} \, \Psi_{n l m} \, ?$$ If so, then the time evolution is well-defined in that problem for any such $\Phi$ . This concerns the so-called scattering states: If one solves the time-independent Schrödinger equation for the above problem one may ask for stationary states of positive energy. Formal solutions can be found, for instance, in Takhtajan's book ""Quantum Mechanics for Mathematicians"". After reflecting on this question a bit, I guess the fact that those are not square-integrable means that there are no such states --- which makes physical sense, since the only way one should get a stationary state here is if the particle is somehow ""trapped"" by the nucleus. However, for the free particle we can solve that equation and treat the resulting states as generalized eigenfunctions in the sense that we may define $$\Psi(x) = \frac{1}{\sqrt{2 \pi \hbar}^3} \int_{R^3} \operatorname{d}^3 p \,  e^{\mathfrak{i}  p \cdot x / \hbar} \, \Phi(p) \, ,$$ which is, of course, just a Fourier transform. Since we can obtain $\Phi$ for given $\Psi \in L^2(\mathbb{R}^3,\mathbb{C})$ via inverse Fourier transform, the time evolution of $\Psi$ is just given by $$\Psi(t,x) = \frac{1}{\sqrt{2 \pi \hbar}^3} \int_{R^3} \operatorname{d}^3 p \,  e^{\mathfrak{i}  \left( p \cdot x- \omega(p) t \right) / \hbar} \, \Phi(p) \, ,$$ where $\omega(p)=p^2/2m \hbar$ . Does a similar procedure work for the hydrogen atom? EDIT: The above framing of the problem is a slight bit off. As can be found it any textbook, the ground state wave function is proportional to $e^{-|x|/a_0}$ with $a_0$ denoting the Bohr radius. Due to lack of differentiability at the origin, this function is not an element of $\mathcal{S}(\mathbb{R}^3,\mathbb{C})$ . The problem seems to be fixable, however, by using $\mathcal{S}(\mathbb{R}^3 \setminus \lbrace 0 \rbrace,\mathbb{C})$ instead.","This is to request a reference on the above problem. I have checked various references in the mathematical physics literature and could not really find a clear, satisfactory answer to some questions, or at least I was unable to extract them myself. In particular, I would like to know the following: It is known among mathematical physicists that most problems in quantum mechanics cannot be fully dealt with by just looking at a particular (separable) Hilbert space and are more appropriately dealt with in terms of a Gelfand triple (one reason being that functions are not differentiable). I suspect that in the above problem a ""natural choice"" for that triple is where on the left we have the space of complex-valued Schwartz functions in , in the center we have the respective space of square-integrable functions, and on the right the respective tempered distributions. I base that suspicion on the fact that the common stationary states are elements of . Is what is usually assumed in most physics textbooks mathematically correct, namely that any admits a series representation of the form If so, then the time evolution is well-defined in that problem for any such . This concerns the so-called scattering states: If one solves the time-independent Schrödinger equation for the above problem one may ask for stationary states of positive energy. Formal solutions can be found, for instance, in Takhtajan's book ""Quantum Mechanics for Mathematicians"". After reflecting on this question a bit, I guess the fact that those are not square-integrable means that there are no such states --- which makes physical sense, since the only way one should get a stationary state here is if the particle is somehow ""trapped"" by the nucleus. However, for the free particle we can solve that equation and treat the resulting states as generalized eigenfunctions in the sense that we may define which is, of course, just a Fourier transform. Since we can obtain for given via inverse Fourier transform, the time evolution of is just given by where . Does a similar procedure work for the hydrogen atom? EDIT: The above framing of the problem is a slight bit off. As can be found it any textbook, the ground state wave function is proportional to with denoting the Bohr radius. Due to lack of differentiability at the origin, this function is not an element of . The problem seems to be fixable, however, by using instead.","L^2 \mathcal{S}(\mathbb{R}^3,\mathbb{C}) \subset L^2(\mathbb{R}^3,\mathbb{C}) \hookrightarrow \left( \mathcal{S}(\mathbb{R}^3,\mathbb{C}) \right)^* \, , \mathbb{R}^3 \Psi_{n l m} \mathcal{S}(\mathbb{R}^3,\mathbb{C}) \Phi \in L^2(\mathbb{R}^3,\mathbb{C})  \Phi = \sum_{n, l, m} a_{n l m} \, \Psi_{n l m} \, ? \Phi \Psi(x) = \frac{1}{\sqrt{2 \pi \hbar}^3} \int_{R^3} \operatorname{d}^3 p \, 
e^{\mathfrak{i}  p \cdot x / \hbar} \, \Phi(p) \, , \Phi \Psi \in L^2(\mathbb{R}^3,\mathbb{C}) \Psi \Psi(t,x) = \frac{1}{\sqrt{2 \pi \hbar}^3} \int_{R^3} \operatorname{d}^3 p \, 
e^{\mathfrak{i}  \left( p \cdot x- \omega(p) t \right) / \hbar} \, \Phi(p) \, , \omega(p)=p^2/2m \hbar e^{-|x|/a_0} a_0 \mathcal{S}(\mathbb{R}^3,\mathbb{C}) \mathcal{S}(\mathbb{R}^3 \setminus \lbrace 0 \rbrace,\mathbb{C})","['functional-analysis', 'partial-differential-equations', 'hilbert-spaces', 'quantum-mechanics']"
75,Examples of a Banach space with an algebra structure having only left continuity,Examples of a Banach space with an algebra structure having only left continuity,,"There is a theorem (see for example, Rudin's Functional Analysis , theorem 10.2 ) that if $A$ is a Banach space with an algebra structure, such that both left and right multiplication are continuous, then $A$ has a renorming such that $A$ is a Banach algebra. He also provides an example where the lack of completeness causes this to fail. I'm looking to construct an example where $A$ is an algebra, as well as a Banach space, such that only left multiplication is continuous. Any thoughts? Is this possible?","There is a theorem (see for example, Rudin's Functional Analysis , theorem 10.2 ) that if $A$ is a Banach space with an algebra structure, such that both left and right multiplication are continuous, then $A$ has a renorming such that $A$ is a Banach algebra. He also provides an example where the lack of completeness causes this to fail. I'm looking to construct an example where $A$ is an algebra, as well as a Banach space, such that only left multiplication is continuous. Any thoughts? Is this possible?",,['functional-analysis']
76,A sequence that converges weakly but not in the Cesàro sense,A sequence that converges weakly but not in the Cesàro sense,,"Let $H$ be a Hilbert space over $\mathbb{C}$ with inner product $\langle\cdot,\cdot\rangle$, and let $\{x_n\}_{n=1}^\infty\subseteq H$, $x\in H$. I'm using the following definitions: $\{x_n\}_{n=1}^\infty$ norm converges to $x$ $\Longleftrightarrow$ $x_n\rightarrow x$ $\Longleftrightarrow$ $\lim_{n\rightarrow\infty}\|x_n-x\|=0$. $\{x_n\}_{n=1}^\infty$ converges weakly to $x$ $\Longleftrightarrow$ $x_n\rightharpoonup x$ $\Longleftrightarrow$ $\lim_{n\rightarrow\infty}\langle y,x_n\rangle=\langle y,x\rangle$ for all $y\in H$. $\{x_n\}_{n=1}^\infty$ converges in the Cesàro sense to $x$ $\Longleftrightarrow$ $x_n\xrightarrow{Ces} x$ $\Longleftrightarrow$ $\lim_{N\rightarrow\infty}\|\frac{1}{N}\sum_{n=1}^Nx_n-x\|=0$. If $x_n\rightarrow x$, then $x_n\rightharpoonup x$ and $x_n\xrightarrow{Ces}x$. On the other hand, if $H=\mathbb{C}$ with the standard inner product, then $(-1)^n\xrightarrow{Ces}0$ but $(-1)^n\not\rightharpoonup 0$. I'm having some difficulty, however, finding a sequence that converges weakly but not in the Cesàro sense. Since weak and strong convergence are equivalent in a finite-dimensional space, such a sequence can only exist if $H$ is infinite-dimensional. I'm therefore trying to find an example in the space $\ell^2(\mathbb{N})$ of sequences $\alpha=(\alpha_1,\alpha_2,\ldots)$ such that $\sum_{n=1}^\infty|\alpha_n|^2<\infty$ with the usual inner product $\langle\alpha,\beta\rangle=\sum_{n=1}^\infty\bar{\alpha}_n\beta_n$. The sequence I'm considering is $$x_1=\left(1,\frac{1}{2},\frac{1}{3},\ldots\right),$$ $$x_2=\left(0,1,\frac{1}{2},\ldots\right),$$ $$x_3=\left(0,0,1,\ldots\right),$$ $$\vdots$$ i.e, the sequence consisting of repeatedly shifting the harmonic sequence to the right. I've managed to show that $x_n\rightharpoonup 0$, but I haven't been able to show that $\{x_n\}_{n=1}^\infty$ doesn't converge in the Cesàro sense. Am I on the right track? If so, how do I show that Cesàro convergence fails? If not, what would be a sequence that actually works?","Let $H$ be a Hilbert space over $\mathbb{C}$ with inner product $\langle\cdot,\cdot\rangle$, and let $\{x_n\}_{n=1}^\infty\subseteq H$, $x\in H$. I'm using the following definitions: $\{x_n\}_{n=1}^\infty$ norm converges to $x$ $\Longleftrightarrow$ $x_n\rightarrow x$ $\Longleftrightarrow$ $\lim_{n\rightarrow\infty}\|x_n-x\|=0$. $\{x_n\}_{n=1}^\infty$ converges weakly to $x$ $\Longleftrightarrow$ $x_n\rightharpoonup x$ $\Longleftrightarrow$ $\lim_{n\rightarrow\infty}\langle y,x_n\rangle=\langle y,x\rangle$ for all $y\in H$. $\{x_n\}_{n=1}^\infty$ converges in the Cesàro sense to $x$ $\Longleftrightarrow$ $x_n\xrightarrow{Ces} x$ $\Longleftrightarrow$ $\lim_{N\rightarrow\infty}\|\frac{1}{N}\sum_{n=1}^Nx_n-x\|=0$. If $x_n\rightarrow x$, then $x_n\rightharpoonup x$ and $x_n\xrightarrow{Ces}x$. On the other hand, if $H=\mathbb{C}$ with the standard inner product, then $(-1)^n\xrightarrow{Ces}0$ but $(-1)^n\not\rightharpoonup 0$. I'm having some difficulty, however, finding a sequence that converges weakly but not in the Cesàro sense. Since weak and strong convergence are equivalent in a finite-dimensional space, such a sequence can only exist if $H$ is infinite-dimensional. I'm therefore trying to find an example in the space $\ell^2(\mathbb{N})$ of sequences $\alpha=(\alpha_1,\alpha_2,\ldots)$ such that $\sum_{n=1}^\infty|\alpha_n|^2<\infty$ with the usual inner product $\langle\alpha,\beta\rangle=\sum_{n=1}^\infty\bar{\alpha}_n\beta_n$. The sequence I'm considering is $$x_1=\left(1,\frac{1}{2},\frac{1}{3},\ldots\right),$$ $$x_2=\left(0,1,\frac{1}{2},\ldots\right),$$ $$x_3=\left(0,0,1,\ldots\right),$$ $$\vdots$$ i.e, the sequence consisting of repeatedly shifting the harmonic sequence to the right. I've managed to show that $x_n\rightharpoonup 0$, but I haven't been able to show that $\{x_n\}_{n=1}^\infty$ doesn't converge in the Cesàro sense. Am I on the right track? If so, how do I show that Cesàro convergence fails? If not, what would be a sequence that actually works?",,"['functional-analysis', 'convergence-divergence', 'hilbert-spaces', 'weak-convergence']"
77,The set of all normal operators on a Hilbert space is not strongly closed,The set of all normal operators on a Hilbert space is not strongly closed,,"I need an example to show that the set of all normal operators on a Hilbert space is not strongly closed. Also I know that strong operator topology and strong* operator topology coincide in the set of all normal operators, so could I conclude that this set is not strongly* closed?","I need an example to show that the set of all normal operators on a Hilbert space is not strongly closed. Also I know that strong operator topology and strong* operator topology coincide in the set of all normal operators, so could I conclude that this set is not strongly* closed?",,"['functional-analysis', 'operator-theory', 'c-star-algebras']"
78,Heat equation and semigroup theory.,Heat equation and semigroup theory.,,"Theorem: Let $X$ be a Banach space, $\{T(t)\}_{t\geq 0}$ a $C_0$ -semigroup on $X$ and $U_0\in D(A)$ . If $A:D(A)\subset X\to X$ is the infinitesimal generator of $\{T(t)\}_{t\geq0}$ , then the function $U:[0,\infty)\to X$ given by $U(t)=T(t)U_0$ is a solution of $(1)$ . $$\left\{\begin{align*} U_t(t)=AU(t);&~~~~t\in[0,\infty)\\ U(0)=U_0& \end{align*}\right.\tag{1}$$ Now consider the problem $$\left\{\begin{align*} y_t(x,t)=y_{xx}(x,t);&~~~~&&x\in\mathbb{R};\;t\in[0,\infty)\\ ~y(x,0)=f(x);&&&x\in\mathbb{R} \end{align*}\right.\tag{2}$$ where $y_{xx}$ is the weak derivative of second order of $y$ . By theorem above, it's possible to show that $(2)$ has a solution. So, could someone explain me (with some details) how can we rewrite $(2)$ in order to get a equivalent system, analogous to $(1)$ ? The solution that I saw just says that it's enough to show that the operator $A:H^2(\mathbb{R})\to L^2(\mathbb{R})$ defined by $A(y)=y_{xx}$ is a infinitesimal generator of a $C_0$ -semigroup on $L^2(\mathbb{R})$ (for this, the Hille-Yosida theorem is used however my question is not about the application of the Hille-Yosida Theorem. I need help to understand how to transform the original system in a system like $(1)$ and why the existence of a solution for $(1)$ implies the exitece of a solution for the original system ). Thanks.","Theorem: Let be a Banach space, a -semigroup on and . If is the infinitesimal generator of , then the function given by is a solution of . Now consider the problem where is the weak derivative of second order of . By theorem above, it's possible to show that has a solution. So, could someone explain me (with some details) how can we rewrite in order to get a equivalent system, analogous to ? The solution that I saw just says that it's enough to show that the operator defined by is a infinitesimal generator of a -semigroup on (for this, the Hille-Yosida theorem is used however my question is not about the application of the Hille-Yosida Theorem. I need help to understand how to transform the original system in a system like and why the existence of a solution for implies the exitece of a solution for the original system ). Thanks.","X \{T(t)\}_{t\geq 0} C_0 X U_0\in D(A) A:D(A)\subset X\to X \{T(t)\}_{t\geq0} U:[0,\infty)\to X U(t)=T(t)U_0 (1) \left\{\begin{align*}
U_t(t)=AU(t);&~~~~t\in[0,\infty)\\
U(0)=U_0&
\end{align*}\right.\tag{1} \left\{\begin{align*}
y_t(x,t)=y_{xx}(x,t);&~~~~&&x\in\mathbb{R};\;t\in[0,\infty)\\
~y(x,0)=f(x);&&&x\in\mathbb{R}
\end{align*}\right.\tag{2} y_{xx} y (2) (2) (1) A:H^2(\mathbb{R})\to L^2(\mathbb{R}) A(y)=y_{xx} C_0 L^2(\mathbb{R}) (1) (1)","['functional-analysis', 'partial-differential-equations', 'heat-equation', 'semigroup-of-operators']"
79,A clean proof of Chain rule for BV functions,A clean proof of Chain rule for BV functions,,"Let $u\in BV(\mathbb{R})$ then its distributional derivative $u' \in \mathcal{M}(\mathbb{R})$ (the space of bounded radon measures). I am trying to prove that $f\in C^1(\mathbb{R})$ , the function $f\circ u \in BV(\mathbb{R})$ satisfies the chain rule $(f\circ u)'=(f'\circ u)u'$ in the sense of measures by a smoothening argument. For $u\in BV(\mathbb{R})$ , let $u^{\epsilon}$ denote its mollification, so that $\left|u^{\epsilon}\right|_{BV(\mathbb{R})}=\left|u\right|_{BV(\mathbb{R})}$ thus upto a subsequence $u^{\epsilon} \rightarrow u$ in $L^1_{loc}(\mathbb{R})$ and ${u^{\epsilon}}' \rightarrow  u'$ in weak* $\mathcal{M}(\Omega)$ . Now, consider \begin{align} \int_{\mathbb{R}} \phi (f \circ u)'= \lim_{\epsilon \rightarrow 0}  \int_{\mathbb{R}} \phi (f \circ u^{\epsilon})'= \lim_{\epsilon \rightarrow 0} \int_{\mathbb{R}} \phi (f' \circ u^{\epsilon}) {u^{\epsilon}}' = \lim_{\epsilon \rightarrow 0} \int_{\mathbb{R}} \phi (f' \circ u) {u}' \label{1}\tag{1} \end{align} which implies that the chain rule holds. I have the follwoing doubts Is the above argument correct?  especially the last equality in \eqref{1} which uses product of a weakly and strongly convergent sequence is weakly convergent Can we justify the same if $f$ is only Lipschitz continuous in particular $f(x)=|x|$ and $f'(x)=\mathrm{sgn}(x)$ .","Let then its distributional derivative (the space of bounded radon measures). I am trying to prove that , the function satisfies the chain rule in the sense of measures by a smoothening argument. For , let denote its mollification, so that thus upto a subsequence in and in weak* . Now, consider which implies that the chain rule holds. I have the follwoing doubts Is the above argument correct?  especially the last equality in \eqref{1} which uses product of a weakly and strongly convergent sequence is weakly convergent Can we justify the same if is only Lipschitz continuous in particular and .","u\in BV(\mathbb{R}) u' \in \mathcal{M}(\mathbb{R}) f\in C^1(\mathbb{R}) f\circ u \in BV(\mathbb{R}) (f\circ u)'=(f'\circ u)u' u\in BV(\mathbb{R}) u^{\epsilon} \left|u^{\epsilon}\right|_{BV(\mathbb{R})}=\left|u\right|_{BV(\mathbb{R})} u^{\epsilon} \rightarrow u L^1_{loc}(\mathbb{R}) {u^{\epsilon}}' \rightarrow  u' \mathcal{M}(\Omega) \begin{align}
\int_{\mathbb{R}} \phi (f \circ u)'= \lim_{\epsilon \rightarrow 0} 
\int_{\mathbb{R}} \phi (f \circ u^{\epsilon})'= \lim_{\epsilon \rightarrow 0} \int_{\mathbb{R}} \phi (f' \circ u^{\epsilon}) {u^{\epsilon}}' = \lim_{\epsilon \rightarrow 0} \int_{\mathbb{R}} \phi (f' \circ u) {u}' \label{1}\tag{1}
\end{align} f f(x)=|x| f'(x)=\mathrm{sgn}(x)","['functional-analysis', 'analysis', 'weak-derivatives']"
80,Evans' PDE Problem 6 Chapter 6 - Existence and uniqueness of weak solutions of Poisson's equation with mixed Dirichlet-Neumann boundary conditions,Evans' PDE Problem 6 Chapter 6 - Existence and uniqueness of weak solutions of Poisson's equation with mixed Dirichlet-Neumann boundary conditions,,"Suppose $U \subset \mathbb R^n$ is an open, bounded and connected set, with smooth boundary $\partial U$ consisting of two disjoint, closed sets $\Gamma 1$ and $\Gamma 2$ . Define what it means for $u$ to be a weak solution of Poisson's equation with mixed Dirichlet-Neumann boundary conditions: \begin{cases} -\Delta u = f \ \ \ \text{in $U$} \\ u = 0 \ \ \ \text{on $\Gamma_1$} \\ \frac{\partial u}{\partial \nu} = 0 \ \ \text{on $\Gamma_2$}. \end{cases} Discuss the existence and uniqueness of weak solutions. [Source: Evans' PDE 2nd edition, page 366, problem 6] My attempt: Let $u \in C^\infty(U)$ be a solution of the problem and let $H^1_{\Gamma_1}(U) = \{v \in H^1(U)\colon v = 0 \text{ on } \Gamma_1 \}$ , which is a Hilbert space with respect to the inner product in $H^1$ . To define a weak solution of the Poisson's equation multiply it by $v \in H^1_{\Gamma_1}(U)$ and integrate by parts \begin{align*} \int_U fv \,dx &= -\int_U \Delta u \cdot v \,dx \\ &= \int_U Du \cdot Dv \,dx - \int_{\partial U} \frac{\partial u}{\partial \nu} \cdot v \, dS \\ &= \int_U Du \cdot Dv \,dx - \int_{\Gamma_1} \frac{\partial u}{\partial \nu} \cdot v \, dS - \int_{\Gamma_2} \frac{\partial u}{\partial \nu} \cdot v \, dS \\ &= \int_U Du \cdot Dv \,dx \end{align*} where the second integral on RHS is zero since $v \in H^1_{\Gamma_1}(U)$ and the third integral is zero since $\frac{\partial u}{\partial \nu} = 0$ on $\Gamma_2$ . Is it ok to take $v$ only in $H^1_{\Gamma_1}(U)$ or $v$ must be taken in $H^1(U)$ ? Define the bilinear map $B:H^1(U)\times H^1_{\Gamma_1}(U) \to \mathbb R$ by $B[u,v] = \int_U Du \cdot Dv \, dx$ . To prove the existence and uniqueness of weak solutions we have to prove that $B$ satisfies the hypotheses of Lax-Milgram, i.e. that $B$ is continuous (linear + bounded) and coercive. For the boundness we can use Cauchy-Schwarz and the definition of Sobolev norm $||u||_{H^1} = ||u||_{L^2}+||Du||_{L^2}$ , which implies $||u||_{H^1} \ge ||Du||_{L^2}$ . So $$ |B[u,v]| \le \int_U |Du \cdot Dv| \, dx \le ||Du||_{L^2(U)}||Dv||_{L^2(U)} \le ||u||_{H^1(U)}||v||_{H^1(U)}. $$ Is all good until here? What about the proof that $B$ is coercive? I read something about the trace operator $T$ , maybe is better to define $B$ through $T$ ?","Suppose is an open, bounded and connected set, with smooth boundary consisting of two disjoint, closed sets and . Define what it means for to be a weak solution of Poisson's equation with mixed Dirichlet-Neumann boundary conditions: Discuss the existence and uniqueness of weak solutions. [Source: Evans' PDE 2nd edition, page 366, problem 6] My attempt: Let be a solution of the problem and let , which is a Hilbert space with respect to the inner product in . To define a weak solution of the Poisson's equation multiply it by and integrate by parts where the second integral on RHS is zero since and the third integral is zero since on . Is it ok to take only in or must be taken in ? Define the bilinear map by . To prove the existence and uniqueness of weak solutions we have to prove that satisfies the hypotheses of Lax-Milgram, i.e. that is continuous (linear + bounded) and coercive. For the boundness we can use Cauchy-Schwarz and the definition of Sobolev norm , which implies . So Is all good until here? What about the proof that is coercive? I read something about the trace operator , maybe is better to define through ?","U \subset \mathbb R^n \partial U \Gamma 1 \Gamma 2 u \begin{cases}
-\Delta u = f \ \ \ \text{in U} \\
u = 0 \ \ \ \text{on \Gamma_1} \\
\frac{\partial u}{\partial \nu} = 0 \ \ \text{on \Gamma_2}.
\end{cases} u \in C^\infty(U) H^1_{\Gamma_1}(U) = \{v \in H^1(U)\colon v = 0 \text{ on } \Gamma_1 \} H^1 v \in H^1_{\Gamma_1}(U) \begin{align*}
\int_U fv \,dx
&= -\int_U \Delta u \cdot v \,dx \\
&= \int_U Du \cdot Dv \,dx - \int_{\partial U} \frac{\partial u}{\partial \nu} \cdot v \, dS \\
&= \int_U Du \cdot Dv \,dx - \int_{\Gamma_1} \frac{\partial u}{\partial \nu} \cdot v \, dS - \int_{\Gamma_2} \frac{\partial u}{\partial \nu} \cdot v \, dS \\
&= \int_U Du \cdot Dv \,dx
\end{align*} v \in H^1_{\Gamma_1}(U) \frac{\partial u}{\partial \nu} = 0 \Gamma_2 v H^1_{\Gamma_1}(U) v H^1(U) B:H^1(U)\times H^1_{\Gamma_1}(U) \to \mathbb R B[u,v] = \int_U Du \cdot Dv \, dx B B ||u||_{H^1} = ||u||_{L^2}+||Du||_{L^2} ||u||_{H^1} \ge ||Du||_{L^2} 
|B[u,v]|
\le \int_U |Du \cdot Dv| \, dx
\le ||Du||_{L^2(U)}||Dv||_{L^2(U)}
\le ||u||_{H^1(U)}||v||_{H^1(U)}.
 B T B T","['functional-analysis', 'partial-differential-equations', 'boundary-value-problem', 'elliptic-equations']"
81,Does every representation of the harmonic oscillator Lie algebra necessarily admit a basis of eigenfunctions?,Does every representation of the harmonic oscillator Lie algebra necessarily admit a basis of eigenfunctions?,,"It is well-known in quantum mechanics that the harmonic oscillator Hamiltonian given by $\mathcal{H} = -\frac{1}{2}\frac{d^2}{dx^2} + \frac{1}{2}x^2 - \frac{1}{2}$ admits a basis of eigenfunctions on $L^2(\Bbb R,dx)$. There are many proofs of this ranging from hard analysis (brute force proving density) to Bargmann transform techniques to showing that the resolvent is compact. An important part of the analysis is that the Gaussian $e^{-\frac{x^2}{2}}$ is an eigenfunction with eigenvalue $0$. Associated to this system is a very nice Lie algebra. Define the operator $a$ by $$a = \frac{1}{\sqrt{2}}\left(\frac{d}{dx}+x\right)$$ and its (formal - I'm not going through the awful nitty gritty details of domains of definition, etc) adjoint $$a^* = \frac{1}{\sqrt{2}}\left(-\frac{d}{dx}+x\right).$$ $\mathcal{H}$ has the following representation: $$\mathcal{H} = a^*a.$$ Moreover, this triple of operators satisfies (on sufficiently nice functions): $$[\mathcal{H},a^*] = a^*, \qquad [\mathcal{H},a] = -a, \qquad [a,a^*] = -1.$$ The quadruplet $\mathcal{H},a^*,a,1$ generates a Lie algebra. Because of these relations, applying $a^*$ repeatedly to the Gaussian leads to successive eigenfunctions (that they are in $L^2$ needs to be checked, but it is straightforward by induction) and indeed these eigenfunctions form a basis. My question is this: does a representation of the Lie algebra $$[a^*a, a^*] = a^*, \qquad [a^*a, a] = -a, \qquad [a,a^*] = -1$$ on an abstract separable Hilbert space $\mathfrak{H}$ (not necessarily $L^2(\Bbb R,dx)$) necessarily admit a basis of eigenfunctions for $a^*a$ assuming that $\ker a\neq \{0\}$? That is, if $\{\psi_i:i\in I\}$ denotes a basis for the kernel of $a$, does $\{(a^*)^m\psi_i:m\in\Bbb N_0,i\in I\}$ form a basis for $\mathfrak{H}$? Or is this somehow a happy accident of working on $\Bbb R$ (or, as we know, more generally $\Bbb R^n$)?","It is well-known in quantum mechanics that the harmonic oscillator Hamiltonian given by $\mathcal{H} = -\frac{1}{2}\frac{d^2}{dx^2} + \frac{1}{2}x^2 - \frac{1}{2}$ admits a basis of eigenfunctions on $L^2(\Bbb R,dx)$. There are many proofs of this ranging from hard analysis (brute force proving density) to Bargmann transform techniques to showing that the resolvent is compact. An important part of the analysis is that the Gaussian $e^{-\frac{x^2}{2}}$ is an eigenfunction with eigenvalue $0$. Associated to this system is a very nice Lie algebra. Define the operator $a$ by $$a = \frac{1}{\sqrt{2}}\left(\frac{d}{dx}+x\right)$$ and its (formal - I'm not going through the awful nitty gritty details of domains of definition, etc) adjoint $$a^* = \frac{1}{\sqrt{2}}\left(-\frac{d}{dx}+x\right).$$ $\mathcal{H}$ has the following representation: $$\mathcal{H} = a^*a.$$ Moreover, this triple of operators satisfies (on sufficiently nice functions): $$[\mathcal{H},a^*] = a^*, \qquad [\mathcal{H},a] = -a, \qquad [a,a^*] = -1.$$ The quadruplet $\mathcal{H},a^*,a,1$ generates a Lie algebra. Because of these relations, applying $a^*$ repeatedly to the Gaussian leads to successive eigenfunctions (that they are in $L^2$ needs to be checked, but it is straightforward by induction) and indeed these eigenfunctions form a basis. My question is this: does a representation of the Lie algebra $$[a^*a, a^*] = a^*, \qquad [a^*a, a] = -a, \qquad [a,a^*] = -1$$ on an abstract separable Hilbert space $\mathfrak{H}$ (not necessarily $L^2(\Bbb R,dx)$) necessarily admit a basis of eigenfunctions for $a^*a$ assuming that $\ker a\neq \{0\}$? That is, if $\{\psi_i:i\in I\}$ denotes a basis for the kernel of $a$, does $\{(a^*)^m\psi_i:m\in\Bbb N_0,i\in I\}$ form a basis for $\mathfrak{H}$? Or is this somehow a happy accident of working on $\Bbb R$ (or, as we know, more generally $\Bbb R^n$)?",,"['functional-analysis', 'lie-algebras', 'eigenfunctions']"
82,Why do we want or need cross-norms on tensor products?,Why do we want or need cross-norms on tensor products?,,"If $(E, \|\cdot\|_1),(F, \|\cdot\|_2)$ are Banach spaces, their (algebraic) tensor product $E \otimes F$ is a vector space looking forward to be normed. A norm on a tensor product of vector spaces is called cross-norm if it behaves multliplicative on elementary tensors, i.e. for all $x \in E, y \in F$ we have $$ \|x \otimes y\| = \|x\|_1 \|y\|_2. \tag{1} $$ Prominent examples of cross-norms are the projective $\pi$ and injective $\varepsilon$ tensor product. In my lecture notes I found that it is preferable to use cross-norms on tensor products. Somewhere else I found that one wants cross-norms since they are compatible with convergent sequences. This last staement does not convince me since I find it more natural to require only $$ \|x \otimes y\| \leq \|x\|_1 \|y\|_2 \tag{2}. $$ I think we all agree that a useful norm on a tensor product should fulfill (2): If $x_n \to x$ and $y_n \to y$ , inequality $(2)$ implies that $x_n \otimes y_n \to x \otimes y$ . I have yet to find some occasion where I really need a norm fulfilling (1) and just (2) being not enough. What do you think: Are cross-norms not only pretty but indispensable? . This should be taken care of by the addition I provided below: It seems natural to want the algebraic tensor product of the duals to be ""included"" in the dual of the algebraic tensor product, i.e. $E^* \otimes F^* \subseteq (E \otimes^\sim F)^*$ (if we identify a functional $\varphi \otimes \psi$ with its continuous extension to the completion $\cdot^\sim$ of $E \otimes F$ w.r.t. the cross-norm) although I am not capable of anticipating the consequences if this inclusion does not hold: What are the downsides of not having this inclusion? -- Is it reasonable not to use reasonable cross-norms ? I think that $E^* \otimes F^*$ can be a nice point separating subspace of $(E \otimes^\sim F)^*$ but I am not sure about it. Can you provide examples of important norms for tensor products (of Banach spaces) that aren't (reasonable) cross-norms? Some more thoughts: Looking at Ryan's Introduction to Tensor Products p.127, reasonable norms on $E \otimes F$ are cross-norms in the sense of (1): Let $(E,\|\cdot\|_1$ and $(F, \|\cdot\|_2)$ be Banach spaces. A norm $\|\cdot\|_\alpha$ on $E \otimes F$ is called reasonable cross-norm if Inequality (2) holds. For all $\varphi \in E^*$ and $\psi \in Y^*$ , the linear functional $\varphi \otimes \psi$ on $X \otimes Y$ is bounded with operator norm $$ \|\varphi \otimes \psi\| \leq \|\varphi\| \|\psi\|. $$ Then, in proposition 6.1 it is proved that each reasonable cross-norm fulfills (1) automatically. In Category theory, there seems to be the concept of uniform cross norms , see nLab but from the definition there it is not clear why they call it uniform cross norm and not just uniform tensor product norm or something else.","If are Banach spaces, their (algebraic) tensor product is a vector space looking forward to be normed. A norm on a tensor product of vector spaces is called cross-norm if it behaves multliplicative on elementary tensors, i.e. for all we have Prominent examples of cross-norms are the projective and injective tensor product. In my lecture notes I found that it is preferable to use cross-norms on tensor products. Somewhere else I found that one wants cross-norms since they are compatible with convergent sequences. This last staement does not convince me since I find it more natural to require only I think we all agree that a useful norm on a tensor product should fulfill (2): If and , inequality implies that . I have yet to find some occasion where I really need a norm fulfilling (1) and just (2) being not enough. What do you think: Are cross-norms not only pretty but indispensable? . This should be taken care of by the addition I provided below: It seems natural to want the algebraic tensor product of the duals to be ""included"" in the dual of the algebraic tensor product, i.e. (if we identify a functional with its continuous extension to the completion of w.r.t. the cross-norm) although I am not capable of anticipating the consequences if this inclusion does not hold: What are the downsides of not having this inclusion? -- Is it reasonable not to use reasonable cross-norms ? I think that can be a nice point separating subspace of but I am not sure about it. Can you provide examples of important norms for tensor products (of Banach spaces) that aren't (reasonable) cross-norms? Some more thoughts: Looking at Ryan's Introduction to Tensor Products p.127, reasonable norms on are cross-norms in the sense of (1): Let and be Banach spaces. A norm on is called reasonable cross-norm if Inequality (2) holds. For all and , the linear functional on is bounded with operator norm Then, in proposition 6.1 it is proved that each reasonable cross-norm fulfills (1) automatically. In Category theory, there seems to be the concept of uniform cross norms , see nLab but from the definition there it is not clear why they call it uniform cross norm and not just uniform tensor product norm or something else.","(E, \|\cdot\|_1),(F, \|\cdot\|_2) E \otimes F x \in E, y \in F 
\|x \otimes y\| = \|x\|_1 \|y\|_2. \tag{1}
 \pi \varepsilon 
\|x \otimes y\| \leq \|x\|_1 \|y\|_2 \tag{2}.
 x_n \to x y_n \to y (2) x_n \otimes y_n \to x \otimes y E^* \otimes F^* \subseteq (E \otimes^\sim F)^* \varphi \otimes \psi \cdot^\sim E \otimes F E^* \otimes F^* (E \otimes^\sim F)^* E \otimes F (E,\|\cdot\|_1 (F, \|\cdot\|_2) \|\cdot\|_\alpha E \otimes F \varphi \in E^* \psi \in Y^* \varphi \otimes \psi X \otimes Y 
\|\varphi \otimes \psi\| \leq \|\varphi\| \|\psi\|.
","['functional-analysis', 'category-theory', 'banach-spaces', 'tensor-products', 'topological-vector-spaces']"
83,Isometry on a dense sub-space of a Banach space?,Isometry on a dense sub-space of a Banach space?,,Let $X$ be a Banach space and let $D$ be a dense sub-space of $X$. I don't know if the following fact is true: Fact: For every (linear) isometry $T\in\operatorname{Iso}(X)$ and for every $\varepsilon > 0$ there is an isometry (linear) $S\in\operatorname{Iso}(D)$ such that: $\|S-T\|<\varepsilon$. Thank for any hint.,Let $X$ be a Banach space and let $D$ be a dense sub-space of $X$. I don't know if the following fact is true: Fact: For every (linear) isometry $T\in\operatorname{Iso}(X)$ and for every $\varepsilon > 0$ there is an isometry (linear) $S\in\operatorname{Iso}(D)$ such that: $\|S-T\|<\varepsilon$. Thank for any hint.,,"['functional-analysis', 'operator-theory', 'banach-spaces']"
84,Maximal ideal space of $c_{\mathcal{U}}$,Maximal ideal space of,c_{\mathcal{U}},"Let $\mathcal{U}$ be an filter over $\mathbb{N}$. Define $$c_{\mathcal{U}} = \{{(x_n)\in \ell_\infty\colon \lim_{\mathcal{U}, n}x_n =0\}},$$ which is a C*-algebra. Is there an accessible topological description of the maximal ideal space of $c_{\mathcal{U}}$? At least for ultrafilters?","Let $\mathcal{U}$ be an filter over $\mathbb{N}$. Define $$c_{\mathcal{U}} = \{{(x_n)\in \ell_\infty\colon \lim_{\mathcal{U}, n}x_n =0\}},$$ which is a C*-algebra. Is there an accessible topological description of the maximal ideal space of $c_{\mathcal{U}}$? At least for ultrafilters?",,"['functional-analysis', 'commutative-algebra', 'ring-theory', 'set-theory', 'operator-algebras']"
85,Minimizing the energy in a ruler,Minimizing the energy in a ruler,,"I'm trying to find the shape a metal ruler takes when it is forced into certain specific boundary conditions. Introduction Imagine a long thin metal ruler, that is forced to bend around a number of nails that are nailed into a sheet of wood. The ruler will take on a certain shape to minimize its internal deformation energy. The smaller the radius of curvature along the length $l$ of the ruler, the more energy is needed to force it into that shape. If $\theta$ is the angle that the ruler makes with the horizontal, we want to minimize its change, i.e., we want to minimize $$E = \int_0^L \left|\frac{d\theta}{dl}\right| dl = \int_0^X \left|\frac{d\theta}{dx}\right| dx.$$ Using $g(x)$ to describe the path of the ruler, we see that $\theta(x) = \arctan(g'(x))$ . The change in the angle is therefore $$ \frac{d\theta}{dx} = \frac{1}{1+g'(x)^2} g''(x). $$ So: whatever the boundary conditions, we want to find the function $g(x)$ , so that $$E = \int_0^X \left|\frac{1}{1+g'(x)^2} g''(x)\right| dx$$ is minimal. Now, without boundary conditions, this is trivial: due to the absolute value signs, the absolute minimum is $E=0$ , which is obtained when $g''(x)=0 \forall x\in[0,X]$ , i.e., when $g(x)$ is a straight line. Which is what's expected: the ruler is straight if there are no additional conditions it needs to fulfil. It becomes more interesting with boundary conditions. Boundary conditions The most natural boundary conditions, in line with how I initially presented the problem, is that there are several points $(a_i, y_i)$ , and the condition is that, for all $i$ , $$g(a_i) = y_i$$ This is an interesting problem, and already one I couldn't solve. For reasons I won't go into here (see this question if you're interested), the problem I'm actually trying to solve is one where there is a boundary condition on the integral of $g$ . There are several tuples $(a_i, b_i, y_i)$ , and the condition is that, for all $i$ , we have $$\int_{a_i}^{b_i} g(x) dx = y_i \cdot (b_i-a_i)$$ I have no idea how to go about this, and would be grateful for any tips. Many thanks! EDIT: Now, I'm not sure if it's actually helpful, but, solving the integral for E, we get $$ \begin{align} E &= \int_0^X \left|\frac{1}{1+g'(x)^2} g''(x)\right| dx \\  &= \int_{I_+} \frac{1}{1+g'(x)^2} g''(x) dx + \int_{I_-} \frac{1}{1+g'(x)^2} (- g''(x)) dx \\ &= \left. \arctan(g'(x)) \right\vert_{I_+} - \left. \arctan(g'(x)) \right\vert_{I_-} \end{align} $$ With $I_+$ and $I_-$ the $x$ -intervals where $g''(x)$ is positive and negative, respectively. Because $I_+$ and $I_-$ form a continuous interval from $0$ to $X$ , we can also write this as $$ E = \arctan(g'(X)) - \arctan(g'(0)) - \left. 2 \arctan(g'(x)) \right\vert_{I_-}   $$ Our goal is to find the function $g(x)$ that minimizes this expression while conforming to the boundary conditions.","I'm trying to find the shape a metal ruler takes when it is forced into certain specific boundary conditions. Introduction Imagine a long thin metal ruler, that is forced to bend around a number of nails that are nailed into a sheet of wood. The ruler will take on a certain shape to minimize its internal deformation energy. The smaller the radius of curvature along the length of the ruler, the more energy is needed to force it into that shape. If is the angle that the ruler makes with the horizontal, we want to minimize its change, i.e., we want to minimize Using to describe the path of the ruler, we see that . The change in the angle is therefore So: whatever the boundary conditions, we want to find the function , so that is minimal. Now, without boundary conditions, this is trivial: due to the absolute value signs, the absolute minimum is , which is obtained when , i.e., when is a straight line. Which is what's expected: the ruler is straight if there are no additional conditions it needs to fulfil. It becomes more interesting with boundary conditions. Boundary conditions The most natural boundary conditions, in line with how I initially presented the problem, is that there are several points , and the condition is that, for all , This is an interesting problem, and already one I couldn't solve. For reasons I won't go into here (see this question if you're interested), the problem I'm actually trying to solve is one where there is a boundary condition on the integral of . There are several tuples , and the condition is that, for all , we have I have no idea how to go about this, and would be grateful for any tips. Many thanks! EDIT: Now, I'm not sure if it's actually helpful, but, solving the integral for E, we get With and the -intervals where is positive and negative, respectively. Because and form a continuous interval from to , we can also write this as Our goal is to find the function that minimizes this expression while conforming to the boundary conditions.","l \theta E = \int_0^L \left|\frac{d\theta}{dl}\right| dl = \int_0^X \left|\frac{d\theta}{dx}\right| dx. g(x) \theta(x) = \arctan(g'(x))  \frac{d\theta}{dx} = \frac{1}{1+g'(x)^2} g''(x).  g(x) E = \int_0^X \left|\frac{1}{1+g'(x)^2} g''(x)\right| dx E=0 g''(x)=0 \forall x\in[0,X] g(x) (a_i, y_i) i g(a_i) = y_i g (a_i, b_i, y_i) i \int_{a_i}^{b_i} g(x) dx = y_i \cdot (b_i-a_i)  \begin{align} E &= \int_0^X \left|\frac{1}{1+g'(x)^2} g''(x)\right| dx \\ 
&= \int_{I_+} \frac{1}{1+g'(x)^2} g''(x) dx + \int_{I_-} \frac{1}{1+g'(x)^2} (- g''(x)) dx \\
&= \left. \arctan(g'(x)) \right\vert_{I_+} - \left. \arctan(g'(x)) \right\vert_{I_-} \end{align}  I_+ I_- x g''(x) I_+ I_- 0 X 
E = \arctan(g'(X)) - \arctan(g'(0)) - \left. 2 \arctan(g'(x)) \right\vert_{I_-}  
 g(x)","['functional-analysis', 'optimization', 'mathematical-physics', 'calculus-of-variations']"
86,"In a Hilbert space $X$, $T \in B(X)$, $|\lambda|=\lVert T \rVert$. Prove that $Im(\lambda I - T)+Ker(\lambda I-T)$ is dense in $X$","In a Hilbert space , , . Prove that  is dense in",X T \in B(X) |\lambda|=\lVert T \rVert Im(\lambda I - T)+Ker(\lambda I-T) X,"Let $X$ be a Hilbert space, $T\in B(X)$ and $\lambda$ be a scalar such that $|\lambda|=\lVert T \rVert$. Prove that $Im(\lambda I - T)+Ker(\lambda I-T)$ is dense in $X$. Since $Ker(\lambda I -T)=Im(\bar{\lambda}I-T^*)^\perp$ where $T^*$ is the adjoint of $T$, we need to show $Im(\lambda I-T)+Im(\bar{\lambda} I-T^*)^\perp$ is dense. My attempt is to assume it is not dense. Hence we can find something outside its closure. However, I am kind of stuck at this point. I have proved that if $T^*x = \bar{\lambda}x$, then $Tx = \lambda x$. I don't know if this helps.","Let $X$ be a Hilbert space, $T\in B(X)$ and $\lambda$ be a scalar such that $|\lambda|=\lVert T \rVert$. Prove that $Im(\lambda I - T)+Ker(\lambda I-T)$ is dense in $X$. Since $Ker(\lambda I -T)=Im(\bar{\lambda}I-T^*)^\perp$ where $T^*$ is the adjoint of $T$, we need to show $Im(\lambda I-T)+Im(\bar{\lambda} I-T^*)^\perp$ is dense. My attempt is to assume it is not dense. Hence we can find something outside its closure. However, I am kind of stuck at this point. I have proved that if $T^*x = \bar{\lambda}x$, then $Tx = \lambda x$. I don't know if this helps.",,"['functional-analysis', 'hilbert-spaces']"
87,Necessity of Axiom of Choice in Functional Analysis given ZF + Dependent Choice,Necessity of Axiom of Choice in Functional Analysis given ZF + Dependent Choice,,"What do we get with the Axiom of Choice (AC) in Functional Analysis that cannot be accomplished with Zermelo-Fraenkel (ZF) plus the Axiom of Dependent Choice (DC)? So, for instance, just dusted off and opened my old class notes and saw Hahn-Banach (see note below) Baire Category (see note below) Open Mapping / Closed Graph thrms Uniform Boundedness Principle Projection Lemma (Hilbert Space) Unit Ball is weak-* compact (Banach-Algaoglu) Riesz Representation Theorem (see note below) Spectral Theorem Separation of Convex sets by Hyperplanes Basic theorems about distribution functions/L^P spaces ... and any other theorems you can think of that fit in this theme of being well known to anyone who took a basic course in functional analysis, and useful to people who use analysis in their work. Please add to list b/c I am sure I forgot some theorems. (note on Hahn-Banach: In the spirit of the question, the most concrete form that is still abstract enough to use in the proofs of the other theorems is fine here. For instance, in my notes I have $p$ sublinear on a N.V.S. $X$ and $V$ a subspace of $X$, $f\in V^*$ and $|f|\le p$ on $V$ as the assumptions. note on Baire Category: The version that every complete metric space (or Banach space) is a Baire space would likely be sufficient here since I believe that the second one that locally compact Hausdorff spaces are Baire might not be standard material for a basic course in Functional Analysis. Please correct me if I'm wrong!) So, which require AC if one already accepts ZF+DC? Edit This is intended to be more a question about the internal logical dependencies of Functional Analysis than about logic and set theory. A good answer does not need to prove each of the theorems separately. In particular, One might show theorems $n_1$ and $n_2$ can be proven with DC by citing good links. Then say ""a standard proof for $n_3$ uses $n_1$ and some epsilon delta stuff. A standard proof $n_4$ uses $n_2$ and $n_3$ plus image of compact sets is compact, so also doesn't need full AC."" For the ones that do need AC, maybe a good link for one and then a link showing that others are equivalent under ZF. In other words, what I am looking for is for someone to take the few theorems about DC vs. AC that have already been proven, and flesh this out to the rest of (basic) functional analysis by discussing logical dependencies within the field of functional analysis. Please only assume a background in functional analysis, not in Foundations (sets/logic/etc. beyond everyday use). References to other questions where the details have been worked out in more rigour are quite sufficient.","What do we get with the Axiom of Choice (AC) in Functional Analysis that cannot be accomplished with Zermelo-Fraenkel (ZF) plus the Axiom of Dependent Choice (DC)? So, for instance, just dusted off and opened my old class notes and saw Hahn-Banach (see note below) Baire Category (see note below) Open Mapping / Closed Graph thrms Uniform Boundedness Principle Projection Lemma (Hilbert Space) Unit Ball is weak-* compact (Banach-Algaoglu) Riesz Representation Theorem (see note below) Spectral Theorem Separation of Convex sets by Hyperplanes Basic theorems about distribution functions/L^P spaces ... and any other theorems you can think of that fit in this theme of being well known to anyone who took a basic course in functional analysis, and useful to people who use analysis in their work. Please add to list b/c I am sure I forgot some theorems. (note on Hahn-Banach: In the spirit of the question, the most concrete form that is still abstract enough to use in the proofs of the other theorems is fine here. For instance, in my notes I have $p$ sublinear on a N.V.S. $X$ and $V$ a subspace of $X$, $f\in V^*$ and $|f|\le p$ on $V$ as the assumptions. note on Baire Category: The version that every complete metric space (or Banach space) is a Baire space would likely be sufficient here since I believe that the second one that locally compact Hausdorff spaces are Baire might not be standard material for a basic course in Functional Analysis. Please correct me if I'm wrong!) So, which require AC if one already accepts ZF+DC? Edit This is intended to be more a question about the internal logical dependencies of Functional Analysis than about logic and set theory. A good answer does not need to prove each of the theorems separately. In particular, One might show theorems $n_1$ and $n_2$ can be proven with DC by citing good links. Then say ""a standard proof for $n_3$ uses $n_1$ and some epsilon delta stuff. A standard proof $n_4$ uses $n_2$ and $n_3$ plus image of compact sets is compact, so also doesn't need full AC."" For the ones that do need AC, maybe a good link for one and then a link showing that others are equivalent under ZF. In other words, what I am looking for is for someone to take the few theorems about DC vs. AC that have already been proven, and flesh this out to the rest of (basic) functional analysis by discussing logical dependencies within the field of functional analysis. Please only assume a background in functional analysis, not in Foundations (sets/logic/etc. beyond everyday use). References to other questions where the details have been worked out in more rigour are quite sufficient.",,"['functional-analysis', 'axiom-of-choice', 'axioms', 'foundations']"
88,Spectral theorem for a pair of commuting operators,Spectral theorem for a pair of commuting operators,,"Let $H$ be Hilbert space and $A$, $B$ - self-adjoint (bounded or unbounded) operators on $H$. According to spectral theorem for every bounded Borel function $f: \mathbb{R}\to \mathbb{R}$ we have $$f(A) = \int d \mu_A(\lambda) ~f(\lambda) $$ $$f(B) = \int d \mu_B(\lambda) ~f(\lambda) $$ where $\mu_A$, $\mu_B$ are spectral measures of $A$ and $B$ respectively. Let's assume that operators $A$ and $B$ commute (in case either of them is unbounded it means that all the projections in their associated spectral measure commute). I wonder whether it is possible to define $g(A,B)$ for any $g: \mathbb{R}^2\to \mathbb{R}$ by $$g(A,B) = \int d \mu_A(\lambda_1)d\mu_B(\lambda_2) ~g(\lambda_1,\lambda_2) .$$ According to Reed & Simon vol. 1, Thm VII.12 the above statement is true for $g(\lambda_1,\lambda_2)=\exp(i t_1\lambda _1 + i t_2 \lambda_2 )$, where $t_1$, $t_2$ are arbitrary real parameters. If the Borel function $f:\mathbb{R}\to \mathbb{R}$ is unbounded and real-valued then $f(A)$ is self-adjoint on the domain consisting of $\psi\in H$ for which $$ \int (\psi,d\mu_A(\lambda)\psi) ~|f(\lambda)|^2<\infty$$. Is it true that for $g:\mathbb{R}^2\to \mathbb{R}$ unbounded and real-valued, $g(A,B)$ is self-adjoint on the domain consisting of $\psi\in H$ for which $$ \int (\psi,d\mu_A(\lambda_1)d\mu_B(\lambda_2)\psi) ~|g(\lambda_1,\lambda_2)|^2<\infty.$$ For example: if $A$ and $B$ commute (in a sense of spectral projections) then we can define self-adjoint operator $A+B$ with domain consisting of $\psi\in H$ for which  $$ \int (\psi,d\mu_A(\lambda_1)d\mu_B(\lambda_2)\psi) ~(\lambda_1+\lambda_2)^2<\infty.$$ Am I right?","Let $H$ be Hilbert space and $A$, $B$ - self-adjoint (bounded or unbounded) operators on $H$. According to spectral theorem for every bounded Borel function $f: \mathbb{R}\to \mathbb{R}$ we have $$f(A) = \int d \mu_A(\lambda) ~f(\lambda) $$ $$f(B) = \int d \mu_B(\lambda) ~f(\lambda) $$ where $\mu_A$, $\mu_B$ are spectral measures of $A$ and $B$ respectively. Let's assume that operators $A$ and $B$ commute (in case either of them is unbounded it means that all the projections in their associated spectral measure commute). I wonder whether it is possible to define $g(A,B)$ for any $g: \mathbb{R}^2\to \mathbb{R}$ by $$g(A,B) = \int d \mu_A(\lambda_1)d\mu_B(\lambda_2) ~g(\lambda_1,\lambda_2) .$$ According to Reed & Simon vol. 1, Thm VII.12 the above statement is true for $g(\lambda_1,\lambda_2)=\exp(i t_1\lambda _1 + i t_2 \lambda_2 )$, where $t_1$, $t_2$ are arbitrary real parameters. If the Borel function $f:\mathbb{R}\to \mathbb{R}$ is unbounded and real-valued then $f(A)$ is self-adjoint on the domain consisting of $\psi\in H$ for which $$ \int (\psi,d\mu_A(\lambda)\psi) ~|f(\lambda)|^2<\infty$$. Is it true that for $g:\mathbb{R}^2\to \mathbb{R}$ unbounded and real-valued, $g(A,B)$ is self-adjoint on the domain consisting of $\psi\in H$ for which $$ \int (\psi,d\mu_A(\lambda_1)d\mu_B(\lambda_2)\psi) ~|g(\lambda_1,\lambda_2)|^2<\infty.$$ For example: if $A$ and $B$ commute (in a sense of spectral projections) then we can define self-adjoint operator $A+B$ with domain consisting of $\psi\in H$ for which  $$ \int (\psi,d\mu_A(\lambda_1)d\mu_B(\lambda_2)\psi) ~(\lambda_1+\lambda_2)^2<\infty.$$ Am I right?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
89,Can a meager linear subspace be written as a countable increasing union of nowhere dense subspaces?,Can a meager linear subspace be written as a countable increasing union of nowhere dense subspaces?,,"Let $X$ be a separable Banach space.  In this question, ""subspace"" means a linear subspace, not necessarily closed. Suppose $E \subset X$ is a subspace which is meager, so that we can write $E = \bigcup_n E_n$, where the $E_n$ are nowhere dense subsets of $X$.  Without loss of generality, we can also take $E_1 \subset E_2 \subset \cdots$.  Can the $E_n$ be taken to be subspaces of $X$?  That is, can a meager subspace always be written as a countable increasing union of nowhere dense subspaces? Note that the linear span of a nowhere dense set is not necessarily nowhere dense (consider the unit sphere), nor is the sum of two nowhere dense subspaces (for instance, in $C([0,1])$, consider the mean-zero functions and the constants). This came up while thinking about this answer : it isn't sufficient to check weak(-*) convergence in $L^2$ on the subspace $C([0,1])$; a sequence of linear functionals may converge pointwise on $C([0,1])$ but diverge somewhere else.  More generally, when is it sufficient to check weak-* convergence on a dense subspace $A \subset X$?  It is sufficient if $A$ is nonmeager, by a version of the uniform boundedness principle and a triangle inequality argument.  But a subspace which is nonmeager lacks the Baire property, so such an $A$ would be a ""weird"" subspace, something we are not likely to encounter in everyday life.  Most of the examples of dense subspaces I know are either countable dimension (hence meager), or complete in a stronger norm (hence analytic in $X$, hence has the BP, hence meager; as for example $C([0,1]) \subset L^2([0,1])$). So I was wondering whether one could prove that it is never sufficient to check weak-* convergence on a meager subspace.  If my question above has an affirmative answer, then we can do the following: for any meager subspace $E$, write $E = \bigcup_n E_n$ where $E_n$ are increasing nowhere dense subspaces.  Since $E_n$ is nowhere dense, it is not dense, so by Hahn-Banach we may find $f_n \in X^*$ with $f_n(E_n) = 0$ and $\|f_n\| = n$.  Then $f_n(x) \to 0$ for every $x \in E$, but $\{f_n\}$ is unbounded so (by the uniform boundedness principle) it is not weak-* convergent.  Thus it would not suffice to check weak-* convergence on $E$.","Let $X$ be a separable Banach space.  In this question, ""subspace"" means a linear subspace, not necessarily closed. Suppose $E \subset X$ is a subspace which is meager, so that we can write $E = \bigcup_n E_n$, where the $E_n$ are nowhere dense subsets of $X$.  Without loss of generality, we can also take $E_1 \subset E_2 \subset \cdots$.  Can the $E_n$ be taken to be subspaces of $X$?  That is, can a meager subspace always be written as a countable increasing union of nowhere dense subspaces? Note that the linear span of a nowhere dense set is not necessarily nowhere dense (consider the unit sphere), nor is the sum of two nowhere dense subspaces (for instance, in $C([0,1])$, consider the mean-zero functions and the constants). This came up while thinking about this answer : it isn't sufficient to check weak(-*) convergence in $L^2$ on the subspace $C([0,1])$; a sequence of linear functionals may converge pointwise on $C([0,1])$ but diverge somewhere else.  More generally, when is it sufficient to check weak-* convergence on a dense subspace $A \subset X$?  It is sufficient if $A$ is nonmeager, by a version of the uniform boundedness principle and a triangle inequality argument.  But a subspace which is nonmeager lacks the Baire property, so such an $A$ would be a ""weird"" subspace, something we are not likely to encounter in everyday life.  Most of the examples of dense subspaces I know are either countable dimension (hence meager), or complete in a stronger norm (hence analytic in $X$, hence has the BP, hence meager; as for example $C([0,1]) \subset L^2([0,1])$). So I was wondering whether one could prove that it is never sufficient to check weak-* convergence on a meager subspace.  If my question above has an affirmative answer, then we can do the following: for any meager subspace $E$, write $E = \bigcup_n E_n$ where $E_n$ are increasing nowhere dense subspaces.  Since $E_n$ is nowhere dense, it is not dense, so by Hahn-Banach we may find $f_n \in X^*$ with $f_n(E_n) = 0$ and $\|f_n\| = n$.  Then $f_n(x) \to 0$ for every $x \in E$, but $\{f_n\}$ is unbounded so (by the uniform boundedness principle) it is not weak-* convergent.  Thus it would not suffice to check weak-* convergence on $E$.",,"['functional-analysis', 'banach-spaces', 'descriptive-set-theory', 'baire-category']"
90,A type of local minimum (2),A type of local minimum (2),,"Data: $\Omega \subset \mathbb{R}^{n}$ is an open connected (may be unbounded) set, and locally $\partial \Omega$ is a Lipschitz graph. $S \subset \partial \Omega$ is measurable and $H^{n-1}(S)>0$. The Dirichlet data on $S$ are given by non-negative function $u^0 \in ^{1}_{Loc}(\Omega)$ with $\nabla u^0 \in L^{2}(\Omega)$. The given force function $Q$ is non-negative and measurable. Consider the convex set  \begin{equation} K:=\{ v \in L^{1}_{Loc}(\Omega): \nabla v \in L^{2}(\Omega) \quad \mbox{and} \quad v=u^0 \quad \mbox{on } S\}. \end{equation} We are looking for an absolute minimum of the functional \begin{equation} J(v):= \int_{\Omega}(|\nabla v|^{2} + \chi(\{v>0\})Q^2) \end{equation} in the class $K$. Definition: We call $u \in K$ a local minimum if for some small $\varepsilon>0$ we have $J(u)\le J(v)$ for every $v \in K$ with   \begin{equation} \|\nabla (u-v)\|_{L^{2}(\Omega)} + \| \chi(\{v>0\}) -\chi(\{u>0\})\|_{L^{1}(\Omega)} \le \varepsilon. \end{equation} Lemma1: If $u$ is a minimum local, then $u$ is subharmonic, hence we can assume that    \begin{equation} u(x) = \lim_{r\downarrow 0} \oint_{B_r(x)}u \quad \mbox{for} \quad x \in \Omega, \end{equation}   where $\oint $ denotes the mean value. Proof: For non-negative functions $\xi \in C^{\infty}_{0}(\Omega)$ we have \begin{equation} 0 \le \limsup_{\varepsilon\downarrow 0} \dfrac{1}{2\varepsilon} (J(u- \varepsilon \xi) - J(u)) \le - \int_{\Omega} \nabla \xi \nabla u, \end{equation} that is, $u$ is subharmonic. Then the limit in the assertion exists for every $x \in \Omega$, and coincides with $u(x)$ for almost all $x$. 1.How can I prove the part ""hence we can assume that  \begin{equation} u(x) = \lim_{r\downarrow 0} \oint_{B_r(x)}u \quad \mbox{for} \quad x \in \Omega,'' \end{equation} 2.How can I do the  details in the lemma Lemma 2: If $u$ is local minimum, then $u$ is harmonic in the open set $\{u>0\}$. proof: Use $u + \varepsilon \xi$ as first variation. If you want the details can be found in the article Alt, H. M. and Caffarelli, L. A. Existence and regularity for a minimum problem with free boundary. J. Reine Angew. Math., 325, (1981), 105–144. and related question A type of local minimum . I thank any hint. My thoughts for lemma 2 is that I need to prove that for all $\xi \in C^{\infty}_{0}(\{ u>0\})$ we have $\int_{\{u>0\}} \langle \nabla u, \nabla \xi\rangle dx  = 0 $. This should follow by \begin{eqnarray} 0 &=& \lim_{\varepsilon\rightarrow 0} \dfrac{J(u + \varepsilon \xi) - J(u)}{2 \varepsilon} \\ &=&\int_{\{u>0\}} \langle \nabla u \nabla \xi \rangle dx +  \lim_{\varepsilon\rightarrow 0^+ } \dfrac{1}{2\varepsilon}\int_{\Omega} Q^2(\chi_{\{u + \xi>0\}} - \chi_{\{u>0\}})  \end{eqnarray} Then we must have $$  \lim_{\varepsilon\rightarrow 0^+ } \dfrac{1}{2\varepsilon}\int_{\Omega} Q^2(\chi_{\{u + \xi>0\}} - \chi_{\{u>0\}}). $$ Am I rigth here?","Data: $\Omega \subset \mathbb{R}^{n}$ is an open connected (may be unbounded) set, and locally $\partial \Omega$ is a Lipschitz graph. $S \subset \partial \Omega$ is measurable and $H^{n-1}(S)>0$. The Dirichlet data on $S$ are given by non-negative function $u^0 \in ^{1}_{Loc}(\Omega)$ with $\nabla u^0 \in L^{2}(\Omega)$. The given force function $Q$ is non-negative and measurable. Consider the convex set  \begin{equation} K:=\{ v \in L^{1}_{Loc}(\Omega): \nabla v \in L^{2}(\Omega) \quad \mbox{and} \quad v=u^0 \quad \mbox{on } S\}. \end{equation} We are looking for an absolute minimum of the functional \begin{equation} J(v):= \int_{\Omega}(|\nabla v|^{2} + \chi(\{v>0\})Q^2) \end{equation} in the class $K$. Definition: We call $u \in K$ a local minimum if for some small $\varepsilon>0$ we have $J(u)\le J(v)$ for every $v \in K$ with   \begin{equation} \|\nabla (u-v)\|_{L^{2}(\Omega)} + \| \chi(\{v>0\}) -\chi(\{u>0\})\|_{L^{1}(\Omega)} \le \varepsilon. \end{equation} Lemma1: If $u$ is a minimum local, then $u$ is subharmonic, hence we can assume that    \begin{equation} u(x) = \lim_{r\downarrow 0} \oint_{B_r(x)}u \quad \mbox{for} \quad x \in \Omega, \end{equation}   where $\oint $ denotes the mean value. Proof: For non-negative functions $\xi \in C^{\infty}_{0}(\Omega)$ we have \begin{equation} 0 \le \limsup_{\varepsilon\downarrow 0} \dfrac{1}{2\varepsilon} (J(u- \varepsilon \xi) - J(u)) \le - \int_{\Omega} \nabla \xi \nabla u, \end{equation} that is, $u$ is subharmonic. Then the limit in the assertion exists for every $x \in \Omega$, and coincides with $u(x)$ for almost all $x$. 1.How can I prove the part ""hence we can assume that  \begin{equation} u(x) = \lim_{r\downarrow 0} \oint_{B_r(x)}u \quad \mbox{for} \quad x \in \Omega,'' \end{equation} 2.How can I do the  details in the lemma Lemma 2: If $u$ is local minimum, then $u$ is harmonic in the open set $\{u>0\}$. proof: Use $u + \varepsilon \xi$ as first variation. If you want the details can be found in the article Alt, H. M. and Caffarelli, L. A. Existence and regularity for a minimum problem with free boundary. J. Reine Angew. Math., 325, (1981), 105–144. and related question A type of local minimum . I thank any hint. My thoughts for lemma 2 is that I need to prove that for all $\xi \in C^{\infty}_{0}(\{ u>0\})$ we have $\int_{\{u>0\}} \langle \nabla u, \nabla \xi\rangle dx  = 0 $. This should follow by \begin{eqnarray} 0 &=& \lim_{\varepsilon\rightarrow 0} \dfrac{J(u + \varepsilon \xi) - J(u)}{2 \varepsilon} \\ &=&\int_{\{u>0\}} \langle \nabla u \nabla \xi \rangle dx +  \lim_{\varepsilon\rightarrow 0^+ } \dfrac{1}{2\varepsilon}\int_{\Omega} Q^2(\chi_{\{u + \xi>0\}} - \chi_{\{u>0\}})  \end{eqnarray} Then we must have $$  \lim_{\varepsilon\rightarrow 0^+ } \dfrac{1}{2\varepsilon}\int_{\Omega} Q^2(\chi_{\{u + \xi>0\}} - \chi_{\{u>0\}}). $$ Am I rigth here?",,"['functional-analysis', 'measure-theory', 'partial-differential-equations']"
91,Derivative of adjoint operator-valued function,Derivative of adjoint operator-valued function,,"Consider an infinite dimensional complex Hilbert space $H$ . I think that for a bounded operator-valued function $A: x\mapsto A(x) \in \mathcal B(H)$ , where $x\in \mathbb R$ , we can define the derivative $A^\prime(x)$ as the (unique) operator which obeys $$\lim\limits_{h\to 0} \left\|A^\prime(x) - \tfrac{A(x+h)-A(x)}{h}\right\|_{\mathrm{op}} =0 \quad, \tag 1$$ if the limit exists. Here $\|\cdot\|_{\mathrm{op}}$ denotes the operator norm. Now I think that from $\|A(x)^*\|_{\mathrm{op}}=\|A(x)\|_{\mathrm{op}}$ , where $^*$ denotes the adjoint, we can show that the derivative of $A^*: x\mapsto A(x)^*$ exists at $x$ and is simply the adjoint of the derivative of $A$ at $x$ , i.e we have $$ (A^\prime(x))^* = (A^*)^\prime (x) \quad .\tag{2}$$ Question: Can we find the same result as in $(2)$ if we define the derivative of bounded operator-valued functions in the strong operator topology instead of the uniform topology $(1)$ ? Or is there a weaker but similar result under some conditions?","Consider an infinite dimensional complex Hilbert space . I think that for a bounded operator-valued function , where , we can define the derivative as the (unique) operator which obeys if the limit exists. Here denotes the operator norm. Now I think that from , where denotes the adjoint, we can show that the derivative of exists at and is simply the adjoint of the derivative of at , i.e we have Question: Can we find the same result as in if we define the derivative of bounded operator-valued functions in the strong operator topology instead of the uniform topology ? Or is there a weaker but similar result under some conditions?","H A: x\mapsto A(x) \in \mathcal B(H) x\in \mathbb R A^\prime(x) \lim\limits_{h\to 0} \left\|A^\prime(x) - \tfrac{A(x+h)-A(x)}{h}\right\|_{\mathrm{op}} =0 \quad, \tag 1 \|\cdot\|_{\mathrm{op}} \|A(x)^*\|_{\mathrm{op}}=\|A(x)\|_{\mathrm{op}} ^* A^*: x\mapsto A(x)^* x A x  (A^\prime(x))^* = (A^*)^\prime (x) \quad .\tag{2} (2) (1)","['functional-analysis', 'derivatives', 'operator-theory', 'hilbert-spaces', 'adjoint-operators']"
92,"Notations in Functional Analysis: $L^p$, $L_p$, $\mathscr{L}^p$, $\mathscr{L}_p$, $\mathcal{L}^p$, and $\mathcal{L}_p$","Notations in Functional Analysis: , , , , , and",L^p L_p \mathscr{L}^p \mathscr{L}_p \mathcal{L}^p \mathcal{L}_p,"If my memory doesn't fail me, then to some functional analysts, $L^p$ and $L_p$ spaces are two different things.  I understand that many people use $L_p$ to means the space of functions with finite $p$ -norm (i.e, $p^\text{th}$ -power-integrable functions), while other use the notation $L^p$ for the same purpose.  If you are a functional analyst that distinguishes between $L^p$ and $L_p$ , then could you please let me know what $L_p$ means (presumably, your definition of $L^p$ coincides with Wikipedia's definition )? Now, I found another similar notation $\mathscr{L}_p$ .  What is $\mathscr{L}_p$ ?  There seem to be $\mathscr{L}^p$ , $\mathcal{L}^p$ , and $\mathcal{L}_p$ too.  However, I would expect that this is just due to people's using different fonts, i.e., $L^p=\mathscr{L}^p=\mathcal{L}^p$ and $L_p=\mathscr{L}_p=\mathcal{L}_p$ .","If my memory doesn't fail me, then to some functional analysts, and spaces are two different things.  I understand that many people use to means the space of functions with finite -norm (i.e, -power-integrable functions), while other use the notation for the same purpose.  If you are a functional analyst that distinguishes between and , then could you please let me know what means (presumably, your definition of coincides with Wikipedia's definition )? Now, I found another similar notation .  What is ?  There seem to be , , and too.  However, I would expect that this is just due to people's using different fonts, i.e., and .",L^p L_p L_p p p^\text{th} L^p L^p L_p L_p L^p \mathscr{L}_p \mathscr{L}_p \mathscr{L}^p \mathcal{L}^p \mathcal{L}_p L^p=\mathscr{L}^p=\mathcal{L}^p L_p=\mathscr{L}_p=\mathcal{L}_p,"['functional-analysis', 'soft-question', 'notation', 'definition', 'lp-spaces']"
93,Definition of the convolution with tempered distributions and Schwartz function,Definition of the convolution with tempered distributions and Schwartz function,,"In the book where I'm studying there is the following exercise. If $x \in \mathbb{R}^n$, $\varphi \in \mathcal{S}(\mathbb{R}^n)$ and $u \in \mathcal{S}'(\mathbb{R}^n)$ we define $(u \ast \varphi)(x)=\langle \tau_x \widetilde{\varphi} , u \rangle$, where we place $(\tau_x \widetilde{\varphi})(y):=\widetilde{\varphi}(y-x):=\varphi(x-y)$. Then (a) $(u \ast \varphi)(x)$ is continuous with respect to $u \in \mathcal{S}'(\mathbb{R}^n)$, with respect to $\varphi \in \mathcal{S}(\mathbb{R}^n)$, and with respect to $x \in \mathbb{R}^n$ (b) $u \ast \varphi$ is a tempered distribution. (c) If $\psi \in \mathcal{D}(\mathbb{R}^n)$, we have \begin{align*}  \langle \psi, u \ast \varphi \rangle = u \left ( \int_{\mathbb{R}^n} \psi(x) (\tau_x \widetilde{\varphi})(\cdot) dx \right ) \end{align*} and extend this identity to case $\psi \in \mathcal{S}(\mathbb{R}^n)$. HINT: To prove (b), check that $|(u \ast \varphi)(x)| \leq C(1+|x|^2)^N$ by proving an estimate $q_N(\tau_x \varphi) \leq 2^N(1+|x|^2)^N q_N(\varphi)$. Note that for me there are these definitions. Let $\mathcal{S}'(\mathbb{R}^n)$ the topological dual space of $\mathcal{S}(\mathbb{R}^n)$.  We have that the mapping $u \in \mathcal{S}'(\mathbb{R}^n) \longmapsto v=u_{|\mathcal{D}(\mathbb{R}^n)} \in \mathcal{D}'(\mathbb{R}^n)$ is linear and one-to-one  because convergence in $\mathcal{D}(\mathbb{R}^n)$ implies convergence in $\mathcal{S}(\mathbb{R}^n)$, and $u_{|\mathcal{D}(\mathbb{R}^n)} \in \mathcal{D}'(\mathbb{R}^n)$ determines uniquely $u \in \mathcal{S}'(\mathbb{R}^n)$. Then a distribution $v \in \mathcal{D}'(\mathbb{R}^n)$ is the restriction of an element $u \in \mathcal{S}'(\mathbb{R}^n)$ if and only if there exist $N \in \mathbb{N}$ and a constant $C_N>0$ such that \begin{align*}  |u(\varphi)| \leq C_N q_N(\varphi)=C_N \sup_{x \in \mathbb{R}^n; |\alpha| \leq N} (1+|x|^2)^N |D^\alpha \varphi(x)| , \forall  \varphi \in \mathcal{D}(\mathbb{R}^n) \end{align*} where $q_N(\varphi)$ are seminorm that make $\mathcal{S}(\mathbb{R}^n)$  a Fréchet space. The elements of $\mathcal{S}'(\mathbb{R}^n)$ or their restriction to  $\mathcal{D}(\mathbb{R}^n)$ are called tempered distributions. To prove (a). I thought can be done with an application of the closed graph theorem, proving that $\tau_a \cdot : \varphi \in \mathcal{S}(\mathbb{R}^n) \longmapsto \tau_a(\varphi)=\varphi(x-a) \in \mathcal{S}(\mathbb{R}^n)$ $\widetilde{\varphi} \cdot : \varphi \in \mathcal{S}(\mathbb{R}^n) \longmapsto \widetilde{\varphi}=\varphi(-x) \in \mathcal{S}(\mathbb{R}^n)$ are continuous with respect to convergence in $\mathcal{S}(\mathbb{R}^n)$. Is it correct, no? Do you have any idea to the point (b) and (c)? Note that (b) and (c) I tried to show in a different way, as here Tempered distributions and convolution Thanks for any help","In the book where I'm studying there is the following exercise. If $x \in \mathbb{R}^n$, $\varphi \in \mathcal{S}(\mathbb{R}^n)$ and $u \in \mathcal{S}'(\mathbb{R}^n)$ we define $(u \ast \varphi)(x)=\langle \tau_x \widetilde{\varphi} , u \rangle$, where we place $(\tau_x \widetilde{\varphi})(y):=\widetilde{\varphi}(y-x):=\varphi(x-y)$. Then (a) $(u \ast \varphi)(x)$ is continuous with respect to $u \in \mathcal{S}'(\mathbb{R}^n)$, with respect to $\varphi \in \mathcal{S}(\mathbb{R}^n)$, and with respect to $x \in \mathbb{R}^n$ (b) $u \ast \varphi$ is a tempered distribution. (c) If $\psi \in \mathcal{D}(\mathbb{R}^n)$, we have \begin{align*}  \langle \psi, u \ast \varphi \rangle = u \left ( \int_{\mathbb{R}^n} \psi(x) (\tau_x \widetilde{\varphi})(\cdot) dx \right ) \end{align*} and extend this identity to case $\psi \in \mathcal{S}(\mathbb{R}^n)$. HINT: To prove (b), check that $|(u \ast \varphi)(x)| \leq C(1+|x|^2)^N$ by proving an estimate $q_N(\tau_x \varphi) \leq 2^N(1+|x|^2)^N q_N(\varphi)$. Note that for me there are these definitions. Let $\mathcal{S}'(\mathbb{R}^n)$ the topological dual space of $\mathcal{S}(\mathbb{R}^n)$.  We have that the mapping $u \in \mathcal{S}'(\mathbb{R}^n) \longmapsto v=u_{|\mathcal{D}(\mathbb{R}^n)} \in \mathcal{D}'(\mathbb{R}^n)$ is linear and one-to-one  because convergence in $\mathcal{D}(\mathbb{R}^n)$ implies convergence in $\mathcal{S}(\mathbb{R}^n)$, and $u_{|\mathcal{D}(\mathbb{R}^n)} \in \mathcal{D}'(\mathbb{R}^n)$ determines uniquely $u \in \mathcal{S}'(\mathbb{R}^n)$. Then a distribution $v \in \mathcal{D}'(\mathbb{R}^n)$ is the restriction of an element $u \in \mathcal{S}'(\mathbb{R}^n)$ if and only if there exist $N \in \mathbb{N}$ and a constant $C_N>0$ such that \begin{align*}  |u(\varphi)| \leq C_N q_N(\varphi)=C_N \sup_{x \in \mathbb{R}^n; |\alpha| \leq N} (1+|x|^2)^N |D^\alpha \varphi(x)| , \forall  \varphi \in \mathcal{D}(\mathbb{R}^n) \end{align*} where $q_N(\varphi)$ are seminorm that make $\mathcal{S}(\mathbb{R}^n)$  a Fréchet space. The elements of $\mathcal{S}'(\mathbb{R}^n)$ or their restriction to  $\mathcal{D}(\mathbb{R}^n)$ are called tempered distributions. To prove (a). I thought can be done with an application of the closed graph theorem, proving that $\tau_a \cdot : \varphi \in \mathcal{S}(\mathbb{R}^n) \longmapsto \tau_a(\varphi)=\varphi(x-a) \in \mathcal{S}(\mathbb{R}^n)$ $\widetilde{\varphi} \cdot : \varphi \in \mathcal{S}(\mathbb{R}^n) \longmapsto \widetilde{\varphi}=\varphi(-x) \in \mathcal{S}(\mathbb{R}^n)$ are continuous with respect to convergence in $\mathcal{S}(\mathbb{R}^n)$. Is it correct, no? Do you have any idea to the point (b) and (c)? Note that (b) and (c) I tried to show in a different way, as here Tempered distributions and convolution Thanks for any help",,"['functional-analysis', 'fourier-analysis', 'distribution-theory', 'locally-convex-spaces']"
94,Showing a sequence of integrals converges to zero,Showing a sequence of integrals converges to zero,,"Let $\varphi$ be a complex-valued function which is analytic on $\{z \in \mathbb C : |z| \leq 2\}$, let $\gamma$ be the unit circle in the complex plane, and define $$ F_n(z) = \int_\gamma \frac{1}{s-z} \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds, $$ where $|z| < 1/2$. Main Question: Is it true that $F_n(z) \to 0$ uniformly for $|z| < 1/2$ as $n \to \infty$? We should note that the double integral exists.  Indeed, by properties of Cauchy-type integrals (see Gakhov, Boundary Value Problems or here ), the function $$ g(s) = \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt $$ is analytic on $\mathbb C \setminus [-2,2]$ and has continuous extensions from the upper and lower half-planes to the interval $(-2,2)$ which satisfy $$ \lim_{\epsilon \to 0^+} g(x \pm i\epsilon) = \pm i\pi e^{-nx^2} \varphi(x) + \operatorname{P.V.} \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-x}\,dt $$ for $-2 < x < 2$.  Consequently, $g(s)$ is continuous on $\gamma$ except for two jump discontinuities at $s = \pm 1$. Idea for an approach I have an idea for an approach which I have so far been unable to make rigorous.  At the end are a couple of problems that I see with it that I would greatly appreciate some feedback on. First I'd like to split the inner integral up into $$ \int_{-2}^{2} = \int_{|t| < 1} + \int_{1 < |t| < 2}, $$ and so write $$ F_n(z) = \int_\gamma \frac{1}{s-z} \int_{|t| < 1} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds + \int_\gamma \frac{1}{s-z} \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds. \tag{1} $$ Now switch the order of integration in both integrals.  The first becomes $$ \int_\gamma \frac{1}{s-z} \int_{|t| < 1} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds = \int_{|t|<1} e^{-nt^2} \varphi(t) \int_\gamma \frac{ds}{(s-z)(t-s)}\,dt, $$ and the inner integral here is $$ \int_\gamma \frac{ds}{(s-z)(t-s)} = 2\pi i \left(\frac{1}{t-z} - \frac{1}{t-z}\right) = 0. $$ The second integral in $(1)$ becomes $$ \begin{align} \int_\gamma \frac{1}{s-z} \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds &= \int_{1 < |t| < 2} e^{-nt^2} \varphi(t) \int_\gamma \frac{ds}{(s-z)(t-s)}\,dt \\ &= 2\pi i \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-z}\,dt, \end{align} $$ so we conclude that $$ F_n(z) = 2\pi i \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-z}\,dt. $$ Then $$ \begin{align} e^{n} |F_n(z)| &= 2\pi \left| \int_{1 < |t| < 2} e^{-n(t^2-1)} \frac{\varphi(t)}{t-z}\,dt \right| \\ &\leq 2\pi \cdot \operatorname{Length}(\{1 < |t| < 2\}) \cdot \sup_{1 < |t| < 2} \left( e^{-n(t^2-1)} \frac{|\varphi(t)|}{|t-z|} \right) \\ &\leq 2\pi \cdot 2 \cdot \sup_{1 < |t| < 2} \left(1 \cdot \frac{|\varphi(t)|}{1/2} \right) \\ &\leq C \end{align} $$ for some constant $C > 0$, so $$ |F_n(z)| \leq Ce^{-n} \to 0 $$ uniformly for $|z| < 1/2$ as $n \to \infty$. There are a couple of issues that I see with this: Can the interchange of order of integration be justified in both cases? Are the subsequent evaluations of the inner integrals using the residue theorem valid?","Let $\varphi$ be a complex-valued function which is analytic on $\{z \in \mathbb C : |z| \leq 2\}$, let $\gamma$ be the unit circle in the complex plane, and define $$ F_n(z) = \int_\gamma \frac{1}{s-z} \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds, $$ where $|z| < 1/2$. Main Question: Is it true that $F_n(z) \to 0$ uniformly for $|z| < 1/2$ as $n \to \infty$? We should note that the double integral exists.  Indeed, by properties of Cauchy-type integrals (see Gakhov, Boundary Value Problems or here ), the function $$ g(s) = \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt $$ is analytic on $\mathbb C \setminus [-2,2]$ and has continuous extensions from the upper and lower half-planes to the interval $(-2,2)$ which satisfy $$ \lim_{\epsilon \to 0^+} g(x \pm i\epsilon) = \pm i\pi e^{-nx^2} \varphi(x) + \operatorname{P.V.} \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-x}\,dt $$ for $-2 < x < 2$.  Consequently, $g(s)$ is continuous on $\gamma$ except for two jump discontinuities at $s = \pm 1$. Idea for an approach I have an idea for an approach which I have so far been unable to make rigorous.  At the end are a couple of problems that I see with it that I would greatly appreciate some feedback on. First I'd like to split the inner integral up into $$ \int_{-2}^{2} = \int_{|t| < 1} + \int_{1 < |t| < 2}, $$ and so write $$ F_n(z) = \int_\gamma \frac{1}{s-z} \int_{|t| < 1} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds + \int_\gamma \frac{1}{s-z} \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds. \tag{1} $$ Now switch the order of integration in both integrals.  The first becomes $$ \int_\gamma \frac{1}{s-z} \int_{|t| < 1} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds = \int_{|t|<1} e^{-nt^2} \varphi(t) \int_\gamma \frac{ds}{(s-z)(t-s)}\,dt, $$ and the inner integral here is $$ \int_\gamma \frac{ds}{(s-z)(t-s)} = 2\pi i \left(\frac{1}{t-z} - \frac{1}{t-z}\right) = 0. $$ The second integral in $(1)$ becomes $$ \begin{align} \int_\gamma \frac{1}{s-z} \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds &= \int_{1 < |t| < 2} e^{-nt^2} \varphi(t) \int_\gamma \frac{ds}{(s-z)(t-s)}\,dt \\ &= 2\pi i \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-z}\,dt, \end{align} $$ so we conclude that $$ F_n(z) = 2\pi i \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-z}\,dt. $$ Then $$ \begin{align} e^{n} |F_n(z)| &= 2\pi \left| \int_{1 < |t| < 2} e^{-n(t^2-1)} \frac{\varphi(t)}{t-z}\,dt \right| \\ &\leq 2\pi \cdot \operatorname{Length}(\{1 < |t| < 2\}) \cdot \sup_{1 < |t| < 2} \left( e^{-n(t^2-1)} \frac{|\varphi(t)|}{|t-z|} \right) \\ &\leq 2\pi \cdot 2 \cdot \sup_{1 < |t| < 2} \left(1 \cdot \frac{|\varphi(t)|}{1/2} \right) \\ &\leq C \end{align} $$ for some constant $C > 0$, so $$ |F_n(z)| \leq Ce^{-n} \to 0 $$ uniformly for $|z| < 1/2$ as $n \to \infty$. There are a couple of issues that I see with this: Can the interchange of order of integration be justified in both cases? Are the subsequent evaluations of the inner integrals using the residue theorem valid?",,"['complex-analysis', 'functional-analysis', 'proof-verification', 'singular-integrals']"
95,Distributional derivative of bounded functions,Distributional derivative of bounded functions,,"Let $f$ be a bounded measurable function on $\mathbb{R}$.  We may consider its derivative $f'$ as a distribution on $\mathbb{R}$. Is there a reasonable description of those distributions $\psi$ which arise in this way, i.e. are of the form $\psi = f'$ for some bounded measurable $f$? For instance, $f'$ need not be a measure (it is a measure iff $f$ has bounded variation).  On the other hand, the doublet $\psi = \delta_0'$ is not of this form. Considering $f \in L^1_{\mathrm{loc}}$ would also be interesting. More generally, on $\mathbb{R}^n$, I would also like to know which distributions are of the form $\psi = \operatorname{div} F$ for $F : \mathbb{R}^n \to \mathbb{R}^n$ bounded and measurable (or $L^1_{\mathrm{loc}}$).","Let $f$ be a bounded measurable function on $\mathbb{R}$.  We may consider its derivative $f'$ as a distribution on $\mathbb{R}$. Is there a reasonable description of those distributions $\psi$ which arise in this way, i.e. are of the form $\psi = f'$ for some bounded measurable $f$? For instance, $f'$ need not be a measure (it is a measure iff $f$ has bounded variation).  On the other hand, the doublet $\psi = \delta_0'$ is not of this form. Considering $f \in L^1_{\mathrm{loc}}$ would also be interesting. More generally, on $\mathbb{R}^n$, I would also like to know which distributions are of the form $\psi = \operatorname{div} F$ for $F : \mathbb{R}^n \to \mathbb{R}^n$ bounded and measurable (or $L^1_{\mathrm{loc}}$).",,"['functional-analysis', 'distribution-theory']"
96,The Heat Equation in Brezis' book,The Heat Equation in Brezis' book,,"I am reading the heat equation in Functional Analysis, Sobolev Spaces, and Partial Differential Equations by Haim Brezis, and having some concerns about the proof, whose screenshot is as attached below. The notation $u\in L^2 (0, \infty; H^1_0(\Omega))$ I can't find the definition of the notation in the book, but I believe it means $$ \int_0^\infty \left\Vert u(t) \right\Vert ^2 _{H^1_0(\Omega)}   dt < \infty$$ On $H^1_0(\Omega)$ , $\left\Vert \nabla u(t) \right\Vert _{L^2(\Omega)} $ and $\left\Vert u(t) \right\Vert _{H^1(\Omega)} $ are equivalent norms by Poincare inequality. The boundary condition has been incorporated in the definition of the domain of A. I think the key is $H_0^1(\Omega)$ since for a function $g\in H_0^1(\Omega)$ that admits a continuous representative, $g$ vanishes on the boundary. From the definition of domain $D(A) = H^2(\Omega) \cap H^1_0(\Omega)$ , does it imply $g\in D(A)$ has a continuous representative? I believe the answer is no. $D(A^l) = \{g\in H^{2l}(\Omega); g = \Delta g = ... = \Delta^{l-1}g = 0 \text{ on the boundary} \}$ I can see $D(A^l) \subset H^{2l}(\Omega)$ . The argument ( $l = 2$ as an example) goes as follows. $$ g \in D(A^2) \Rightarrow g \in D(A), - \Delta g \in D(A) \Rightarrow - \Delta g + g \in H^2(\Omega) \Rightarrow g \in H^4(\Omega)$$ The last arrow follows from a regularity theorem (Theorem 9.25). But again, $g\in D(A^l)$ may not have a continuous representative (at least when $l$ is not sufficiently large) so how to see $g = \Delta g =... = 0$ on the boundary? $u\in C^k((0,\infty); C^k(\bar \Omega))$ for all k My understanding is that $u$ as a function from $(0,\infty)$ to $C^k(\bar \Omega)$ is a $C^k$ function, and for each fixed $t_1$ , $u(t_1)$ is a $C^k$ function on $\bar \Omega$ . How do we conclude from here that $u(x,t): \Omega \times (0, \infty) \to \mathbb{R}$ is $C^k$ ? The differentiability of $u\in C^k((0,\infty); C^k(\bar \Omega))$ uses the Banach space topology while the partial derivative $u_t(x,t)$ in $t$ is formulated in the usual sense. More specifically, let $[U(t)](x)$ be the map viewed as $(0,\infty)$ to $C^k(\bar \Omega)$ and $u(x,t)$ be the one viewed as $\Omega \times (0,\infty) \to \mathbb{R}$ , how to show that $u_t(x,t) = d[U(t)](x)/dt $ ? (Update) I consulted Evan's PDE book, and my own answers (at least how I convinced myself) go as follows. For point 1, yes. More generally, $u\in L^p(0,\infty; X)$ for a Banach space $X$ means $$ \int_0^\infty \left\Vert u(t) \right\Vert ^ p _X dt < \infty $$ For point 2 & 3, we need the fact that $$ u \in H^1_0 (\Omega) \iff u = 0 \text{ on the boundary}$$ To justify the statement (since $u$ can differ from a set of measure zero and the boundary has measure zero), we probably need the theory of trace. Anyways, in Brezis' book, only a special case is proven (when $u$ has a continuous representative, see Theorem 9.17), and the trace operator is briefly mentioned in page 315. I think I came up with a solution for point 4. Let $u(x,t) = [U(t)](x)$ . Fix a point $x_0 \in \Omega$ . $$(\frac{d[U(t)]}{dt}) (x_0) = (\lim_{h\to 0}\frac{U(t+h)-U(t)}{h})(x_0) = \lim_{h\to 0}\frac{[U(t+h)](x_0)-[U(t)](x_0)}{h} = u_t(x_0,t)$$ since the continuity of evaluation at $x_0$ allows us to pass through the limit. If there is any mistake or there is a better way/answer for my questions, please let me know. Anyways I hope this post helps those who only read Brezis' book like me.","I am reading the heat equation in Functional Analysis, Sobolev Spaces, and Partial Differential Equations by Haim Brezis, and having some concerns about the proof, whose screenshot is as attached below. The notation I can't find the definition of the notation in the book, but I believe it means On , and are equivalent norms by Poincare inequality. The boundary condition has been incorporated in the definition of the domain of A. I think the key is since for a function that admits a continuous representative, vanishes on the boundary. From the definition of domain , does it imply has a continuous representative? I believe the answer is no. I can see . The argument ( as an example) goes as follows. The last arrow follows from a regularity theorem (Theorem 9.25). But again, may not have a continuous representative (at least when is not sufficiently large) so how to see on the boundary? for all k My understanding is that as a function from to is a function, and for each fixed , is a function on . How do we conclude from here that is ? The differentiability of uses the Banach space topology while the partial derivative in is formulated in the usual sense. More specifically, let be the map viewed as to and be the one viewed as , how to show that ? (Update) I consulted Evan's PDE book, and my own answers (at least how I convinced myself) go as follows. For point 1, yes. More generally, for a Banach space means For point 2 & 3, we need the fact that To justify the statement (since can differ from a set of measure zero and the boundary has measure zero), we probably need the theory of trace. Anyways, in Brezis' book, only a special case is proven (when has a continuous representative, see Theorem 9.17), and the trace operator is briefly mentioned in page 315. I think I came up with a solution for point 4. Let . Fix a point . since the continuity of evaluation at allows us to pass through the limit. If there is any mistake or there is a better way/answer for my questions, please let me know. Anyways I hope this post helps those who only read Brezis' book like me.","u\in L^2 (0, \infty; H^1_0(\Omega))  \int_0^\infty \left\Vert u(t) \right\Vert ^2 _{H^1_0(\Omega)} 
 dt < \infty H^1_0(\Omega) \left\Vert \nabla u(t) \right\Vert _{L^2(\Omega)}  \left\Vert u(t) \right\Vert _{H^1(\Omega)}  H_0^1(\Omega) g\in H_0^1(\Omega) g D(A) = H^2(\Omega) \cap H^1_0(\Omega) g\in D(A) D(A^l) = \{g\in H^{2l}(\Omega); g = \Delta g = ... = \Delta^{l-1}g = 0 \text{ on the boundary} \} D(A^l) \subset H^{2l}(\Omega) l = 2  g \in D(A^2) \Rightarrow g \in D(A), - \Delta g \in D(A) \Rightarrow - \Delta g + g \in H^2(\Omega) \Rightarrow g \in H^4(\Omega) g\in D(A^l) l g = \Delta g =... = 0 u\in C^k((0,\infty); C^k(\bar \Omega)) u (0,\infty) C^k(\bar \Omega) C^k t_1 u(t_1) C^k \bar \Omega u(x,t): \Omega \times (0, \infty) \to \mathbb{R} C^k u\in C^k((0,\infty); C^k(\bar \Omega)) u_t(x,t) t [U(t)](x) (0,\infty) C^k(\bar \Omega) u(x,t) \Omega \times (0,\infty) \to \mathbb{R} u_t(x,t) = d[U(t)](x)/dt  u\in L^p(0,\infty; X) X  \int_0^\infty \left\Vert u(t) \right\Vert ^ p _X dt < \infty   u \in H^1_0 (\Omega) \iff u = 0 \text{ on the boundary} u u u(x,t) = [U(t)](x) x_0 \in \Omega (\frac{d[U(t)]}{dt}) (x_0) = (\lim_{h\to 0}\frac{U(t+h)-U(t)}{h})(x_0) = \lim_{h\to 0}\frac{[U(t+h)](x_0)-[U(t)](x_0)}{h} = u_t(x_0,t) x_0","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'heat-equation']"
97,Linear optimization for functions,Linear optimization for functions,,"I have the following linear optimization problem. $$ \max \int_0^1 w(t) dt $$ subject to $$ \int_0^1 w(t) \, x_i(t) \, dt \geq 0, \quad i=1,\dots,n  $$ and $$ 0 \leq w(t) \leq 1 \quad \text{for all} \quad t\in[0,1]. $$ Here, $x_1(t), \dots, x_n(t)$ are some given functions $x_i:[0,1]\to{\mathbb R}$ , and the optimization is over all measurable functions $w:[0,1]\to{\mathbb R}$ satisfying the constraints. I would like to prove that there exists a maximiser $w^*(t)$ such that for every $t\in[0,1]$ either $w^*(t)=0$ or $w^*(t)=1$ . This is ""obvious"" from the intuition that optimal solution for the linear program should be on the ""corner"" of the feasibility set. However, in this example we have uncountably many variables ( $w(t)$ for each $t\in[0,1]$ ) and uncountably many constraints. Can anyone suggest a good reference for study of such linear programs, and/or provide a direct solution for this problem?","I have the following linear optimization problem. subject to and Here, are some given functions , and the optimization is over all measurable functions satisfying the constraints. I would like to prove that there exists a maximiser such that for every either or . This is ""obvious"" from the intuition that optimal solution for the linear program should be on the ""corner"" of the feasibility set. However, in this example we have uncountably many variables ( for each ) and uncountably many constraints. Can anyone suggest a good reference for study of such linear programs, and/or provide a direct solution for this problem?","
\max \int_0^1 w(t) dt
 
\int_0^1 w(t) \, x_i(t) \, dt \geq 0, \quad i=1,\dots,n 
 
0 \leq w(t) \leq 1 \quad \text{for all} \quad t\in[0,1].
 x_1(t), \dots, x_n(t) x_i:[0,1]\to{\mathbb R} w:[0,1]\to{\mathbb R} w^*(t) t\in[0,1] w^*(t)=0 w^*(t)=1 w(t) t\in[0,1]","['functional-analysis', 'optimization', 'convex-optimization', 'linear-programming', 'lagrange-multiplier']"
98,New norm with strictly coarser induced topolgy,New norm with strictly coarser induced topolgy,,"Let $(V,\|\cdot\|)$ be an infinite dimensional normed space. Does there alway exist a norm $|||\cdot|||$ on $V$ which induces a strictly coarser topology than $\|\cdot\|$ ? I know, that there is always a norm  which induces a strictly finer topolgy: We can  choose an unbounded linear functional $l:V\to\mathbb K$ and define a new norm as $\|\cdot\|+|l(\cdot)|$ . Then $$\text{Id}:(V,\|\cdot\|+|l(\cdot)|)\to(V,\|\cdot\|)$$ is bounded with unbounded inverse, so $\|\cdot\|+|l(\cdot)|$ induces a strictly finer topolgy. But what about the converse?","Let be an infinite dimensional normed space. Does there alway exist a norm on which induces a strictly coarser topology than ? I know, that there is always a norm  which induces a strictly finer topolgy: We can  choose an unbounded linear functional and define a new norm as . Then is bounded with unbounded inverse, so induces a strictly finer topolgy. But what about the converse?","(V,\|\cdot\|) |||\cdot||| V \|\cdot\| l:V\to\mathbb K \|\cdot\|+|l(\cdot)| \text{Id}:(V,\|\cdot\|+|l(\cdot)|)\to(V,\|\cdot\|) \|\cdot\|+|l(\cdot)|","['functional-analysis', 'vector-spaces', 'normed-spaces', 'topological-vector-spaces']"
99,Nonlinear funtionals of smooth maps between Riemannian manifolds,Nonlinear funtionals of smooth maps between Riemannian manifolds,,"Let two smooth Riemannian manifolds $M$ and $N$ , and let $C^{\infty}(M, N)$ be the family of smooth maps between them. I would like to study functionals of the form $$E[\cdot]: C^{\infty}(M, N) \to \mathbb{R},$$ where for each $F \in C^{\infty}(M,N)$ i.e., a smooth map $$F:M\to N,$$ $E[F]$ represents strain or energy of the map $F$ (but the energy can be negative etc.). The following three properties define what I mean by strain: Continuity , i.e., $E[F]$ is continuous in $F$ (in some norm on $C^{\infty}(M, N)$ , see definition below for elaboration) $E[F]$ is a valuation on $M$ (please see definition below in elaborations) $E[F]$ is invariant to rigid deformation of $F$ (please see definition below in elaborations) My goal is to better understand this family of functionals and how they can be represented. To get handle of the subject, I would like to understand if one can represent them using integrals on $M$ . So that given arbitrary $E[\cdot]$ we can always write $$ E[F] = \int_M  D_F(x) dV_n, \tag{$\ast$} $$ where $dV_n$ is volume form on $M$ and $D_F(x), x\in M$ is some kind of density on $M$ that depends on $F$ in a reasonable fashion. To make progress with this question (and really understand if it makes sense to pose it) here are few things I struggle with: Find a good reference for functional analysis in this general case, where the functional is not linear. Is there some hope to prove my claim $(*)$ , if yes what one can try to say about the density $D_F(x)$ , how does it depend on $x$ or on $F$ , e.g., is it for example necessarily continuous in $F$ ? Is there any principal way to generate such functionals, if not by using integral, perhaps one can approximate any such functional by some simpler nice functionals (just like continuous functions can be approximated by smooth bump functions)? Below are elaborations and definitions of the terms used above with an example of such a functional: Dirichlet energy. Any comments, answers or thoughts on the subject would be greatly appreciated. Elaborations: I have a smooth map $F$ from a smooth Riemannian n-manifold $M$ to $N$ $$ F: M \to N. $$ Suppose I want to compute Dirichlet energy of $F$ in this very general setting and better understand what kind of functional this energy is. To this end I define a functional, $E_D[F]:C^{(\infty)}(M,N) \to \mathbb{R}$ , given by: $$ E_D[F] := \int_{M} \mathrm{Tr}\left\{\mathrm{det}(DF)^\top\mathrm{det}(DF)\right\} dV. \tag{$\ast\ast$} $$ The above can be interpreted using the following inner product on $C^{\infty}(M, N)$ (smooth maps between smooth manifolds $M$ and $N$ ): let $F,G \in C^{\infty}(M, N)$ define: $$ \langle F, G \rangle_D := \int_{M}  \mathrm{Tr}\left\{\mathrm{det}(DF)^\top\mathrm{det}(DG)\right\}  dV, $$ $$ \|F\|_D^2 := \langle F, F \rangle_D. $$ So that $E[F] = \|F\|_D^2.$ What properties does $E_D[F]$ have as a functional on $C^{\infty}(M, N)$ ?: ( Edited: As pointed out in the comments, this definition of inner product is a sloppy one and one needs to introduce connection on manifold $N$ to make the product of Jacobians meaningful) Continuity. The functional $E_D[F]$ is continuous (in the above defined norm) i.e., for small enough $$ \|F- G\|_D <\delta, $$ we have $$ \left|E_D[F] - E_D[G]\right| < \varepsilon. $$ Valuation . In addition, the functional $E_D[F]$ is a valuation on $M$ . By this I mean  that if we cover $M$ by submanifolds $U, V \subset M$ , i.e., $M = U \cup V$ , such that $U \cap V$ is also submanifold of $M$ . Then we can compute $E_D[F]$ by considering the following maps: $$ F|_U:U \to N, $$ $$ F|_V:V \to N, $$ $$ F|_{V\cap U}:V\cap U \to N. $$ Then $$ E_D[F] = E_D[F|_U] + E_D[F|_V] - E_D[F|_{V\cap U}]. $$ Rigid deformation in-variance Let $V$ be a smooth vector field on $N$ , we can use $V$ to define, for each point $p \in N$ , an integral curve $\gamma:[0, b] \to N$ , which is the curve on $N$ characterized by the property $$ \gamma(0) = p,  $$ $$ \gamma'(t) = V_{\gamma(t)},~~t \in [0, a]. $$ Roughly, all of the integral curves of $V$ define a flow $\Theta_V: N \times [0, a] \to N$ of $V$ on $N$ . With the help of integral curves, we can now make sense of what we mean by applying $V$ to $N$ ( $V$ acts on $N$ ). This can be interpreted as mapping each point $p\in N$ by the flow of $V$ . Which in turn means  that we are moving each point along the integral curve of $V$ for some time $t \in [0,a]$ . So that for a fixed $t \in [0,a]$ we have $$ \Theta_V^{(t)}: N \to N, $$ we can now make sense of composition $\Theta_V^{(t)} \circ F: M \to N$ , and compute Dirichlet energy of this composition: $$ E_D[\Theta_V^{(t)} \circ F].  $$ Dirichlet energy has this property, that if the Vector field $V_K$ is Killing vector field (this is specific field that preserves the Riemannian metric $g$ , i.e., for Lie derivative we have $\mathcal{L}_V g = 0$ and therefore Killing vector field defines isometric transforms of $N$ ) we have: $$ E_D[F] = E_D[\Theta_{V_K}^{(t)} \circ F]. $$ Reiterating my question, I want now to consider the family of all functionals that have the listed property and understand if they all have the form $(**)$ , more generally if one can write them as an integral with those other density. References - I found this question on mathoverflow that seems to be somewhat related. - Another paper that looks at a similar setting","Let two smooth Riemannian manifolds and , and let be the family of smooth maps between them. I would like to study functionals of the form where for each i.e., a smooth map represents strain or energy of the map (but the energy can be negative etc.). The following three properties define what I mean by strain: Continuity , i.e., is continuous in (in some norm on , see definition below for elaboration) is a valuation on (please see definition below in elaborations) is invariant to rigid deformation of (please see definition below in elaborations) My goal is to better understand this family of functionals and how they can be represented. To get handle of the subject, I would like to understand if one can represent them using integrals on . So that given arbitrary we can always write where is volume form on and is some kind of density on that depends on in a reasonable fashion. To make progress with this question (and really understand if it makes sense to pose it) here are few things I struggle with: Find a good reference for functional analysis in this general case, where the functional is not linear. Is there some hope to prove my claim , if yes what one can try to say about the density , how does it depend on or on , e.g., is it for example necessarily continuous in ? Is there any principal way to generate such functionals, if not by using integral, perhaps one can approximate any such functional by some simpler nice functionals (just like continuous functions can be approximated by smooth bump functions)? Below are elaborations and definitions of the terms used above with an example of such a functional: Dirichlet energy. Any comments, answers or thoughts on the subject would be greatly appreciated. Elaborations: I have a smooth map from a smooth Riemannian n-manifold to Suppose I want to compute Dirichlet energy of in this very general setting and better understand what kind of functional this energy is. To this end I define a functional, , given by: The above can be interpreted using the following inner product on (smooth maps between smooth manifolds and ): let define: So that What properties does have as a functional on ?: ( Edited: As pointed out in the comments, this definition of inner product is a sloppy one and one needs to introduce connection on manifold to make the product of Jacobians meaningful) Continuity. The functional is continuous (in the above defined norm) i.e., for small enough we have Valuation . In addition, the functional is a valuation on . By this I mean  that if we cover by submanifolds , i.e., , such that is also submanifold of . Then we can compute by considering the following maps: Then Rigid deformation in-variance Let be a smooth vector field on , we can use to define, for each point , an integral curve , which is the curve on characterized by the property Roughly, all of the integral curves of define a flow of on . With the help of integral curves, we can now make sense of what we mean by applying to ( acts on ). This can be interpreted as mapping each point by the flow of . Which in turn means  that we are moving each point along the integral curve of for some time . So that for a fixed we have we can now make sense of composition , and compute Dirichlet energy of this composition: Dirichlet energy has this property, that if the Vector field is Killing vector field (this is specific field that preserves the Riemannian metric , i.e., for Lie derivative we have and therefore Killing vector field defines isometric transforms of ) we have: Reiterating my question, I want now to consider the family of all functionals that have the listed property and understand if they all have the form , more generally if one can write them as an integral with those other density. References - I found this question on mathoverflow that seems to be somewhat related. - Another paper that looks at a similar setting","M N C^{\infty}(M, N) E[\cdot]: C^{\infty}(M, N) \to \mathbb{R}, F \in C^{\infty}(M,N) F:M\to N, E[F] F E[F] F C^{\infty}(M, N) E[F] M E[F] F M E[\cdot] 
E[F] = \int_M  D_F(x) dV_n, \tag{\ast}
 dV_n M D_F(x), x\in M M F (*) D_F(x) x F F F M N 
F: M \to N.
 F E_D[F]:C^{(\infty)}(M,N) \to \mathbb{R} 
E_D[F] := \int_{M} \mathrm{Tr}\left\{\mathrm{det}(DF)^\top\mathrm{det}(DF)\right\} dV. \tag{\ast\ast}
 C^{\infty}(M, N) M N F,G \in C^{\infty}(M, N) 
\langle F, G \rangle_D := \int_{M}  \mathrm{Tr}\left\{\mathrm{det}(DF)^\top\mathrm{det}(DG)\right\}  dV,
 
\|F\|_D^2 := \langle F, F \rangle_D.
 E[F] = \|F\|_D^2. E_D[F] C^{\infty}(M, N) N E_D[F] 
\|F- G\|_D <\delta,
 
\left|E_D[F] - E_D[G]\right| < \varepsilon.
 E_D[F] M M U, V \subset M M = U \cup V U \cap V M E_D[F] 
F|_U:U \to N,
 
F|_V:V \to N,
 
F|_{V\cap U}:V\cap U \to N.
 
E_D[F] = E_D[F|_U] + E_D[F|_V] - E_D[F|_{V\cap U}].
 V N V p \in N \gamma:[0, b] \to N N 
\gamma(0) = p, 
 
\gamma'(t) = V_{\gamma(t)},~~t \in [0, a].
 V \Theta_V: N \times [0, a] \to N V N V N V N p\in N V V t \in [0,a] t \in [0,a] 
\Theta_V^{(t)}: N \to N,
 \Theta_V^{(t)} \circ F: M \to N 
E_D[\Theta_V^{(t)} \circ F]. 
 V_K g \mathcal{L}_V g = 0 N 
E_D[F] = E_D[\Theta_{V_K}^{(t)} \circ F].
 (**)","['functional-analysis', 'differential-geometry', 'riemannian-geometry', 'sobolev-spaces', 'nonlinear-analysis']"
