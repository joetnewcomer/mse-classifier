,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Let $s\in\mathbb{R}$ and $T: C(\mathbb{R})\to C(\mathbb{R})$ defined by $(Tu)(t)=u(t+s)$. Find the resolvent of $T$, $\rho(T)$.","Let  and  defined by . Find the resolvent of , .",s\in\mathbb{R} T: C(\mathbb{R})\to C(\mathbb{R}) (Tu)(t)=u(t+s) T \rho(T),"I have the following problem: Let $E=C(\mathbb{R})=\{u\in\mathbb{R}^{\mathbb{R}}\mid \sup_{t\in\mathbb{R}}|u(t)|<\infty\,\land\, $ u $\text{ is continuous}\}$ be equipped with the norm $\|u\|_\infty=\sup_{t\in\mathbb{R}}|u(t)|$ . Define $T\colon E\to E$ by $(Tu)(t)=u(t+s)$ where $s$ is a real non-zero constant. Prove $T\in\mathcal{L}(E)$ and that $\|T\|=1$ . Find $\rho(T)$ (the set of all $\lambda\in\mathbb{R}$ that make $T-\lambda I$ bijective). For any $y\in \mathbb{R}$ , define $g_y\colon\mathbb{R}\to\mathbb{R}$ by $t\mapsto t+y$ . I'll adopt the notation $g_s^+=T$ . The first part is easy: Let $u,v\in E$ and $\lambda \in \mathbb{R}$ , then $g_s^+(\lambda u+v)=(\lambda u+v)\circ g_s=\lambda u\circ g_s + v\circ g_s=\lambda g_s^+(u)+g_s^+(v)$ and $\|g_s^{+} (u)\|=\|u\circ g_s\|=\sup_{t\in\mathbb{R}}|u(t+s)|=\|u\|$ and thus $g_s^+\in\mathcal{L}(E)$ and $\|g_s^+\|=1$ . I'm now trying to prove that, if $|\lambda|>1$ , then $\lambda \in \rho(g_s^+)$ (this was a hint on the exercise) but I don't really know how to show that $g_s^+-\lambda I$ is bijective for such $\lambda$ . I'm looking for a hint or a solution on how to continue.","I have the following problem: Let u be equipped with the norm . Define by where is a real non-zero constant. Prove and that . Find (the set of all that make bijective). For any , define by . I'll adopt the notation . The first part is easy: Let and , then and and thus and . I'm now trying to prove that, if , then (this was a hint on the exercise) but I don't really know how to show that is bijective for such . I'm looking for a hint or a solution on how to continue.","E=C(\mathbb{R})=\{u\in\mathbb{R}^{\mathbb{R}}\mid \sup_{t\in\mathbb{R}}|u(t)|<\infty\,\land\,  \text{ is continuous}\} \|u\|_\infty=\sup_{t\in\mathbb{R}}|u(t)| T\colon E\to E (Tu)(t)=u(t+s) s T\in\mathcal{L}(E) \|T\|=1 \rho(T) \lambda\in\mathbb{R} T-\lambda I y\in \mathbb{R} g_y\colon\mathbb{R}\to\mathbb{R} t\mapsto t+y g_s^+=T u,v\in E \lambda \in \mathbb{R} g_s^+(\lambda u+v)=(\lambda u+v)\circ g_s=\lambda u\circ g_s + v\circ g_s=\lambda g_s^+(u)+g_s^+(v) \|g_s^{+} (u)\|=\|u\circ g_s\|=\sup_{t\in\mathbb{R}}|u(t+s)|=\|u\| g_s^+\in\mathcal{L}(E) \|g_s^+\|=1 |\lambda|>1 \lambda \in \rho(g_s^+) g_s^+-\lambda I \lambda","['functional-analysis', 'analysis', 'banach-spaces', 'spectral-theory']"
1,Taylor Series Expansion of a Vector Cross product,Taylor Series Expansion of a Vector Cross product,,"This is confusing me a little. What is the Taylor series expansion of: $$f(u,v) = u \times v$$ Around points (i.e., vectors) $u_0$ and $v_0$ up until the first derivative (i.e., no higher order terms than order 2)? Thank you! Here's what I have so far: so we pick a small values near $(u_0, v_0)$ i.e.,: $$u = \bar{u} + u_0 $$ $$v = \bar{v} + v_0 $$ we want to express $f(u,v)$ as follows: $$f(u,v) \approx f(u_0, v_0) + \frac{\partial f (u,v)}{\partial u}\Big|_{(u_0,v_0)}\,\bar{u} + \frac{\partial f (u,v)}{\partial v}\Big|_{(u_0,v_0)}\,\bar{v}$$ . Which means the Taylor series expansion is given as follows: $$ % f(u,v) \approx u_0 \times v_0 + \frac{\partial}{ \partial u}(u \times v)\Big |_{(u_0,v_0)}\cdot \bar{u} \ \ + \frac{\partial}{ \partial v}(u \times v)\Big |_{(u_0,v_0)}\cdot \bar{v} % $$ $$ = u_0 \times v_0 + (\mathbb{1} \times v_0) \cdot \bar{u} \ \ + (u_0 \times \mathbb{1}) \cdot \bar{v} $$ where $\mathbb{1}$ is simply a column vector of ones i.e., $\frac{\partial }{\partial u}\begin{bmatrix}u_1 \\u_2 \\u_3 \end{bmatrix} = \begin{bmatrix}1 \\1 \\1 \end{bmatrix}$ . Is this correct? Or should $\mathbb{1}$ be the idenity matrix $I_{3\times3}$ instead?","This is confusing me a little. What is the Taylor series expansion of: Around points (i.e., vectors) and up until the first derivative (i.e., no higher order terms than order 2)? Thank you! Here's what I have so far: so we pick a small values near i.e.,: we want to express as follows: . Which means the Taylor series expansion is given as follows: where is simply a column vector of ones i.e., . Is this correct? Or should be the idenity matrix instead?","f(u,v) = u \times v u_0 v_0 (u_0, v_0) u = \bar{u} + u_0  v = \bar{v} + v_0  f(u,v) f(u,v) \approx f(u_0, v_0) + \frac{\partial f (u,v)}{\partial u}\Big|_{(u_0,v_0)}\,\bar{u} + \frac{\partial f (u,v)}{\partial v}\Big|_{(u_0,v_0)}\,\bar{v} 
%
f(u,v) \approx u_0 \times v_0 + \frac{\partial}{ \partial u}(u \times v)\Big |_{(u_0,v_0)}\cdot \bar{u} \ \ + \frac{\partial}{ \partial v}(u \times v)\Big |_{(u_0,v_0)}\cdot \bar{v}
%
 
= u_0 \times v_0 + (\mathbb{1} \times v_0) \cdot \bar{u} \ \ + (u_0 \times \mathbb{1}) \cdot \bar{v}
 \mathbb{1} \frac{\partial }{\partial u}\begin{bmatrix}u_1 \\u_2 \\u_3 \end{bmatrix} = \begin{bmatrix}1 \\1 \\1 \end{bmatrix} \mathbb{1} I_{3\times3}","['linear-algebra', 'functional-analysis', 'multivariable-calculus', 'partial-differential-equations', 'taylor-expansion']"
2,"In a normed space, is the sum of two open sets (open wrt subspace topology of two complements) open?","In a normed space, is the sum of two open sets (open wrt subspace topology of two complements) open?",,"Let $(V,\|\cdot\|)$ be a (possibly infinite-dimensional) normed space and $V_1,V_2 \subseteq V$ be subspaces such that $V = V_1 \oplus V_2$ . Let $B^i_{r_i} \subseteq V_i$ be open balls in $V_i$ , wrt the induced norms $\|\cdot\|_i$ , of radius $r_i > 0$ . Define the sum of these two sets as $$ B_{r_1,r_2} := B^1_{r_1} + B^2_{r_2} := \{y_1 + y_2 \in V\ |\ y_i \in B^i_{r_i}, i = 1, 2\} $$ My question is whether this set is open or not. My idea is: If we have $r := \inf \{\|x\|\ |\ x \in \overline{B^i_{r_i}} + \partial B^j_{r_j}\} > 0$ , $i \neq j$ , then $B_{r} \subseteq B_{r_1,r_2}$ . But I don't know how to show exactly, or even if it helps or the set is open at the first place.","Let be a (possibly infinite-dimensional) normed space and be subspaces such that . Let be open balls in , wrt the induced norms , of radius . Define the sum of these two sets as My question is whether this set is open or not. My idea is: If we have , , then . But I don't know how to show exactly, or even if it helps or the set is open at the first place.","(V,\|\cdot\|) V_1,V_2 \subseteq V V = V_1 \oplus V_2 B^i_{r_i} \subseteq V_i V_i \|\cdot\|_i r_i > 0 
B_{r_1,r_2} := B^1_{r_1} + B^2_{r_2} := \{y_1 + y_2 \in V\ |\ y_i \in B^i_{r_i}, i = 1, 2\}
 r := \inf \{\|x\|\ |\ x \in \overline{B^i_{r_i}} + \partial B^j_{r_j}\} > 0 i \neq j B_{r} \subseteq B_{r_1,r_2}","['general-topology', 'functional-analysis', 'topological-vector-spaces']"
3,Why is this function of bounded variation?,Why is this function of bounded variation?,,"Let $g=[0,1]\rightarrow \mathbb R$ be a function such that for any sequence $(f_n)$ of left-continuous step functions on $[0,1]$ decreasing to $0$ , we have that $\int_0^1 f_n(x) dg(x)$ converges to $0$ . I read that this implies that $g$ is of bounded variation. How to show that? I imagine this has something to do with Carathéodory extension theorem?","Let be a function such that for any sequence of left-continuous step functions on decreasing to , we have that converges to . I read that this implies that is of bounded variation. How to show that? I imagine this has something to do with Carathéodory extension theorem?","g=[0,1]\rightarrow \mathbb R (f_n) [0,1] 0 \int_0^1 f_n(x) dg(x) 0 g","['real-analysis', 'integration', 'functional-analysis', 'convergence-divergence']"
4,Operator whose spectrum is different from the spectrum of its dual,Operator whose spectrum is different from the spectrum of its dual,,"It's mentioned in our functional analysis course that for any operator $T$ on a Banach space, T has the same spectrum as its dual. A friend asked for an example where this fails and I can't think of one for the life of me. As mentioned, it's clear that the space can't be complete. My thoughts are that if $T$ is a bdd linear operator on $X$ , $T$ extends uniquely to a bdd operator $\tilde{T}$ on the completion $\tilde{X}$ . Further, $X$ and $\tilde{X}$ have the same dual space, and also $T$ and $\tilde{T}$ have the same dual operator on this space. Because of this, the spectrum of $T^{*}$ coincides with the spectrum of $\tilde{T}$ , so really what we want is an operator $T$ on a non-complete space whose unique extension to the completion has a different spectrum. My best attempt was to look at some $\ell^{p}$ space ( $p<\infty$ ) as that has the canonical Schauder basis $(e_n)_n$ and take $X$ to be the linear span of this basis. Then try to define an operator that isn't surjective on $X$ , but does extend to an invertible operator on $\ell^p$ . Clearly I was unsuccessful :) It has crossed my mind that the result about Banach spaces uses the axiom of Choice (through the use of Hahn-Banach) so maybe to find an example where it fails I also need Choice, but I didn't manage to come up with and example even when allowing for ""non-canonical"" ones (e.g starting with an algebraic basis of a Banach space and trying to work from there). If anyone has a construction for this, it would be greatly appreciated.","It's mentioned in our functional analysis course that for any operator on a Banach space, T has the same spectrum as its dual. A friend asked for an example where this fails and I can't think of one for the life of me. As mentioned, it's clear that the space can't be complete. My thoughts are that if is a bdd linear operator on , extends uniquely to a bdd operator on the completion . Further, and have the same dual space, and also and have the same dual operator on this space. Because of this, the spectrum of coincides with the spectrum of , so really what we want is an operator on a non-complete space whose unique extension to the completion has a different spectrum. My best attempt was to look at some space ( ) as that has the canonical Schauder basis and take to be the linear span of this basis. Then try to define an operator that isn't surjective on , but does extend to an invertible operator on . Clearly I was unsuccessful :) It has crossed my mind that the result about Banach spaces uses the axiom of Choice (through the use of Hahn-Banach) so maybe to find an example where it fails I also need Choice, but I didn't manage to come up with and example even when allowing for ""non-canonical"" ones (e.g starting with an algebraic basis of a Banach space and trying to work from there). If anyone has a construction for this, it would be greatly appreciated.",T T X T \tilde{T} \tilde{X} X \tilde{X} T \tilde{T} T^{*} \tilde{T} T \ell^{p} p<\infty (e_n)_n X X \ell^p,"['functional-analysis', 'banach-spaces', 'spectral-theory']"
5,Operator-norm Identity (inequalitity) [closed],Operator-norm Identity (inequalitity) [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question in our lecture for functional-analysis we defined the norm of a linear operator as $$||T||:=||T||_{X\rightarrow Y}=\inf\{C\geq0|\forall x\in X:~||Tx||_Y\leq C||x||_X\}$$ and then we said it is: $$||T||_{X\rightarrow Y}\geq \sup_{x\neq0}\frac{||Tx||_Y}{||x||_X}\geq \sup_{||x||\leq1}||Tx||_Y\geq \sup_{||x||=1}||Tx||_Y$$ and i have problems understanding why theese inequalties hold and especially why the first one is not already an equality. Could someone maybe give me hint on that?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question in our lecture for functional-analysis we defined the norm of a linear operator as and then we said it is: and i have problems understanding why theese inequalties hold and especially why the first one is not already an equality. Could someone maybe give me hint on that?",||T||:=||T||_{X\rightarrow Y}=\inf\{C\geq0|\forall x\in X:~||Tx||_Y\leq C||x||_X\} ||T||_{X\rightarrow Y}\geq \sup_{x\neq0}\frac{||Tx||_Y}{||x||_X}\geq \sup_{||x||\leq1}||Tx||_Y\geq \sup_{||x||=1}||Tx||_Y,"['functional-analysis', 'operator-theory']"
6,"If $f$ is a eigenfunction of $-\Delta$ in $L^2[0,1]$, is it necessarily $C^\infty$?","If  is a eigenfunction of  in , is it necessarily ?","f -\Delta L^2[0,1] C^\infty","I am a little bit confused about the properties of the Laplacian $-\Delta$ on $L^2[0,1]$ with the periodic boundary conditions. At least I know that $-\Delta$ is an unbounded self-adjoint operator on $L^2[0,1]$ and its eigenvalues are all nonnegative. Moreover, each eigenvalue has a finite multiplicity. Now, my confusions are as follows: If $f \in L^2[0,1]$ is an eigenfunction of $-\Delta$ , then is $f$ necessarily $C^\infty$ ? I vaguely remember some regularity theorems from PDE context, but I cannot find an exactly relevant reference. If the first item is correct, then each eigenspace of $-\Delta$ must be a finite dimensional subspace of $L^2[0,1]$ , consisting of smooth functions. Is this also true? Lastly, let $g$ be a smooth periodic function on $[0,1]$ such that $-\Delta g$ is an eigenfunction of $-\Delta$ with the eigenvalue $\lambda (\geq 0)$ . Then, I suspect that $g$ itself is an eigenfunction with the eigenvalue $\lambda^2$ . But I cannot really prove this rigorously. All these issues seem to be related with the regularity of the eigenfunctions for the Laplacian and a bit subtle to me. Could anyone please clarify?","I am a little bit confused about the properties of the Laplacian on with the periodic boundary conditions. At least I know that is an unbounded self-adjoint operator on and its eigenvalues are all nonnegative. Moreover, each eigenvalue has a finite multiplicity. Now, my confusions are as follows: If is an eigenfunction of , then is necessarily ? I vaguely remember some regularity theorems from PDE context, but I cannot find an exactly relevant reference. If the first item is correct, then each eigenspace of must be a finite dimensional subspace of , consisting of smooth functions. Is this also true? Lastly, let be a smooth periodic function on such that is an eigenfunction of with the eigenvalue . Then, I suspect that itself is an eigenfunction with the eigenvalue . But I cannot really prove this rigorously. All these issues seem to be related with the regularity of the eigenfunctions for the Laplacian and a bit subtle to me. Could anyone please clarify?","-\Delta L^2[0,1] -\Delta L^2[0,1] f \in L^2[0,1] -\Delta f C^\infty -\Delta L^2[0,1] g [0,1] -\Delta g -\Delta \lambda (\geq 0) g \lambda^2","['functional-analysis', 'partial-differential-equations', 'regularity-theory-of-pdes', 'self-adjoint-operators']"
7,"Does the equality $\|\nabla u\|^{p}_{L^{p}(\mathbb{R}^{n})}=[u]^{p}_{W^{s,p}(\Omega)}$ hold in the fractional Sobolev space?",Does the equality  hold in the fractional Sobolev space?,"\|\nabla u\|^{p}_{L^{p}(\mathbb{R}^{n})}=[u]^{p}_{W^{s,p}(\Omega)}","I have been reading the Hitchhiker’s guide to the fractional Sobolev spaces and there they define the fractional Sobolev space and its norm in the following way. $$W^{s,p}(\Omega):=\Biggl\{ u\in L^{p}(\Omega):(x,y)\mapsto\frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p}+s}}\in L^{p}(\Omega\times\Omega)\Biggl\},$$ and $$\|u\|^{p}_{W^{s,p}(\Omega)}:=\int_{\Omega}|u|^{p}dx+\int_{\Omega}\int_{\Omega}\frac{|u(x)-u(y)|^{p}}{|x-y|^{n+sp}}\,dx\,dy=\|u\|^{p}_{L^{p}(\Omega)}+[u]^{p}_{W^{s,p}(\Omega)}.$$ Where $[u]_{W^{s,p}(\Omega)}$ is the Gagliardo semi-norm. I understand the definition of both the norm and the space, my problem arises in the Proposition 2.2 specifically in the ecuation (2.6), where the next inequality is given. $$C_{1}(n,s,p)\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}               \leq C_{1}(n,s,p)\| \overset{\backsim}{u}\|^{p}_{W^{1,p}(\Omega)}.$$ I asked a profesor and he gave me this $$C_{1}(n,s,p)\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}               \leq C_{1}(n,s,p)\biggl(\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}+\| \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}\biggl)=C_{1}(n,s,p)\| \overset{\backsim}{u}\|^{p}_{W^{1,p}(\Omega)}.$$ Stating that the term $\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}+\| \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}$ is exactly the definition of the fractional Sobolev norm, but as stated above the definition would be $\|\overset{\backsim}{u}\|^{p}_{L^{p}(\Omega)}+[\overset{\backsim}{u}]^{p}_{W^{s,p}(\Omega)}$ . Does that mean that the equality $\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}=[\overset{\backsim}{u}]^{p}_{W^{s,p}(\Omega)}$ holds? or is it that there is another definition for the norm in the fractional Sobolev space? P.D. I tried to prove the equality and I could not achive anything.","I have been reading the Hitchhiker’s guide to the fractional Sobolev spaces and there they define the fractional Sobolev space and its norm in the following way. and Where is the Gagliardo semi-norm. I understand the definition of both the norm and the space, my problem arises in the Proposition 2.2 specifically in the ecuation (2.6), where the next inequality is given. I asked a profesor and he gave me this Stating that the term is exactly the definition of the fractional Sobolev norm, but as stated above the definition would be . Does that mean that the equality holds? or is it that there is another definition for the norm in the fractional Sobolev space? P.D. I tried to prove the equality and I could not achive anything.","W^{s,p}(\Omega):=\Biggl\{ u\in L^{p}(\Omega):(x,y)\mapsto\frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p}+s}}\in L^{p}(\Omega\times\Omega)\Biggl\}, \|u\|^{p}_{W^{s,p}(\Omega)}:=\int_{\Omega}|u|^{p}dx+\int_{\Omega}\int_{\Omega}\frac{|u(x)-u(y)|^{p}}{|x-y|^{n+sp}}\,dx\,dy=\|u\|^{p}_{L^{p}(\Omega)}+[u]^{p}_{W^{s,p}(\Omega)}. [u]_{W^{s,p}(\Omega)} C_{1}(n,s,p)\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}
              \leq C_{1}(n,s,p)\| \overset{\backsim}{u}\|^{p}_{W^{1,p}(\Omega)}. C_{1}(n,s,p)\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}
              \leq C_{1}(n,s,p)\biggl(\|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}+\| \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}\biggl)=C_{1}(n,s,p)\| \overset{\backsim}{u}\|^{p}_{W^{1,p}(\Omega)}. \|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}+\| \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})} \|\overset{\backsim}{u}\|^{p}_{L^{p}(\Omega)}+[\overset{\backsim}{u}]^{p}_{W^{s,p}(\Omega)} \|\nabla \overset{\backsim}{u}\|^{p}_{L^{p}(\mathbb{R}^{n})}=[\overset{\backsim}{u}]^{p}_{W^{s,p}(\Omega)}","['functional-analysis', 'fractional-calculus', 'fractional-sobolev-spaces']"
8,$L^2$ distance between Gaussian probability density functions,distance between Gaussian probability density functions,L^2,"In order to understand different ways of comparing probability functions, I'm trying to bound from above the $L^2$ distance between the pdf of two multivariate Gaussians. More specifically, let $f,f' : \mathbb{R}^n \to \mathbb{R}$ be the pdf of two multivariate Gaussians with means $\mu,\mu' \in \mathbb{R}^n$ , respectively, and with the same covariance matrix $\Sigma$ . My intuition tells me that $$     \|f - f'\|_2 \leq \alpha \|\mu - \mu'\|_2, $$ for some constant $\alpha$ that only depends on $\Sigma$ . However, I'm not even sure of how to start. I have tried considering the differential of the quantity $\|f - f'\|_2$ with respect to $\mu'$ , but I got stuck fairly quickly as I am not too familiar with taking derivatives under a norm.","In order to understand different ways of comparing probability functions, I'm trying to bound from above the distance between the pdf of two multivariate Gaussians. More specifically, let be the pdf of two multivariate Gaussians with means , respectively, and with the same covariance matrix . My intuition tells me that for some constant that only depends on . However, I'm not even sure of how to start. I have tried considering the differential of the quantity with respect to , but I got stuck fairly quickly as I am not too familiar with taking derivatives under a norm.","L^2 f,f' : \mathbb{R}^n \to \mathbb{R} \mu,\mu' \in \mathbb{R}^n \Sigma 
    \|f - f'\|_2 \leq \alpha \|\mu - \mu'\|_2,
 \alpha \Sigma \|f - f'\|_2 \mu'","['real-analysis', 'functional-analysis', 'probability-distributions', 'normed-spaces', 'normal-distribution']"
9,"A bounded positive linear mapping $T$ is an orthogonal projection if $\mathrm{dim}(\mathcal{R}(T))=1$ and $\sum_{k}\left<T(e_k),e_k\right>=1$",A bounded positive linear mapping  is an orthogonal projection if  and,"T \mathrm{dim}(\mathcal{R}(T))=1 \sum_{k}\left<T(e_k),e_k\right>=1","Let $\mathcal{H}$ be a Hilbert space over the field $\mathbb{K}$ and $T:\mathcal{H}\to\mathcal{H}$ be a bounded positive linear mapping such that $\mathrm{dim}(\mathcal{R}(T))=1$ and $\sum_{k\in\mathcal{I}}\left<T(e_k),e_k\right>=1$ for some Hilbert basis $(e_k)_{k\in \mathcal{I}}$ where the index set $\mathcal{I}$ can be countable or uncountable. I want to show that $T$ is an orthogonal projection onto the span of the single linearly independent element of its range. To be precise, $$\mathcal{R}(T):=\{T(v)\mid v\in\mathcal{H}\}$$ and as $\mathrm{dim}(\mathcal{R}(T)) = 1$ it follows that $\exists w\in\mathcal{H}:\forall v\in\mathcal{H}:\exists c_v\in\mathbb{K}:T(v) = c_vw$ . I have a suspicion that the scalar $c_v$ is given by the inner product $\left<v,w\right>$ with linearity in the first argument. Since $T$ is a bounded positive linear mapping, it suffices to show that $T$ is a projection, i.e. $T^2 = T$ and $T|_S=I$ for some $S\subset\mathcal{H}$ . My problem: Confirming the defining two properties of a projection mapping would be quite easy if we were to know the image of $w$ under $T$ . Namely, if we were to know that $T(w) = 1\cdot w = w$ , then for any $v := cw,c\in\mathbb{K},$ we would have $T(cw) = cT(w) = cw = v$ showing that $T = I$ on the span of $w$ and $T^2 = T$ . My problem is that I don't know how to a.) conclude that $T(w) = w$ b.) use the assumption $\sum_{k\in\mathcal{I}}\left<T(e_k),e_k\right>=1$ to my advantage. Since the $e_k$ s form a Hilbert basis, $w = \sum_{k\in\mathcal{C}}\beta_ke_k,\beta_k\in\mathbb{K}$ for some countable $\mathcal{C}\subset\mathcal{I}$ and $T$ is continuous, I suppose I would have to look at some double series of the form $\sum_{k_1\in\mathcal{I}}\sum_{k_2\in\mathcal{C}}\beta_k\left<T(e_{k_2}),e_{k_1}\right>$ and conclude something from this. But as of now it is not clear to me what I should do.","Let be a Hilbert space over the field and be a bounded positive linear mapping such that and for some Hilbert basis where the index set can be countable or uncountable. I want to show that is an orthogonal projection onto the span of the single linearly independent element of its range. To be precise, and as it follows that . I have a suspicion that the scalar is given by the inner product with linearity in the first argument. Since is a bounded positive linear mapping, it suffices to show that is a projection, i.e. and for some . My problem: Confirming the defining two properties of a projection mapping would be quite easy if we were to know the image of under . Namely, if we were to know that , then for any we would have showing that on the span of and . My problem is that I don't know how to a.) conclude that b.) use the assumption to my advantage. Since the s form a Hilbert basis, for some countable and is continuous, I suppose I would have to look at some double series of the form and conclude something from this. But as of now it is not clear to me what I should do.","\mathcal{H} \mathbb{K} T:\mathcal{H}\to\mathcal{H} \mathrm{dim}(\mathcal{R}(T))=1 \sum_{k\in\mathcal{I}}\left<T(e_k),e_k\right>=1 (e_k)_{k\in \mathcal{I}} \mathcal{I} T \mathcal{R}(T):=\{T(v)\mid v\in\mathcal{H}\} \mathrm{dim}(\mathcal{R}(T)) = 1 \exists w\in\mathcal{H}:\forall v\in\mathcal{H}:\exists c_v\in\mathbb{K}:T(v) = c_vw c_v \left<v,w\right> T T T^2 = T T|_S=I S\subset\mathcal{H} w T T(w) = 1\cdot w = w v := cw,c\in\mathbb{K}, T(cw) = cT(w) = cw = v T = I w T^2 = T T(w) = w \sum_{k\in\mathcal{I}}\left<T(e_k),e_k\right>=1 e_k w = \sum_{k\in\mathcal{C}}\beta_ke_k,\beta_k\in\mathbb{K} \mathcal{C}\subset\mathcal{I} T \sum_{k_1\in\mathcal{I}}\sum_{k_2\in\mathcal{C}}\beta_k\left<T(e_{k_2}),e_{k_1}\right>","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'orthogonality']"
10,Is the exponential map of a complex unital Banach algebra surjective onto the set of (two-sidedly) invertible elements?,Is the exponential map of a complex unital Banach algebra surjective onto the set of (two-sidedly) invertible elements?,,"Let $A$ be a complex unital Banach algebra, and let $A^\times$ denote the set of (two-sidedly) invertible elements of $A$ . Let $\exp : A \rightarrow A^\times$ denote the exponential map. My question is, in general is the exponential map surjective onto $A^\times$ ? What I understand so far is as follows: If we replace ""complex"" with ""real"", then the answer becomes no. E.g. we can take $A$ to be $\mathbb{R}$ itself, or more generally the matrix algebra $\mathrm{Mat}_n(\mathbb{R})$ for any integer $n>0$ . (reference) The answer becomes ""yes"" in the case $A = \mathrm{Mat}_n(\mathbb{C})$ , for integer $n>0$ . (reference) However I'm not sure how to generalize the 2nd bullet point, nor how to find a counter-example. Would anyone have any suggestions on how to think about this?","Let be a complex unital Banach algebra, and let denote the set of (two-sidedly) invertible elements of . Let denote the exponential map. My question is, in general is the exponential map surjective onto ? What I understand so far is as follows: If we replace ""complex"" with ""real"", then the answer becomes no. E.g. we can take to be itself, or more generally the matrix algebra for any integer . (reference) The answer becomes ""yes"" in the case , for integer . (reference) However I'm not sure how to generalize the 2nd bullet point, nor how to find a counter-example. Would anyone have any suggestions on how to think about this?",A A^\times A \exp : A \rightarrow A^\times A^\times A \mathbb{R} \mathrm{Mat}_n(\mathbb{R}) n>0 A = \mathrm{Mat}_n(\mathbb{C}) n>0,"['functional-analysis', 'banach-algebras']"
11,bounded normal operator and spectrum,bounded normal operator and spectrum,,"Problem: If A is a bounded normal operator, the spectrum $\sigma(A)=\{s+it:s \in \sigma(B),t \in \sigma(C)\}$ , where B, C are bounded self adjoint operators which commute. Fact: A bounded normal operator A can be written $A=B+iC$ , where B,C are bounded self adjoint operators which commute. Fact: Let H be a complex Hilbert space and let $A:H \rightarrow H$ be a bounded complex linear operator, then A is normal if only if $\Vert A^*x \Vert=\Vert Ax \Vert$ for all $x \in H$ . Also every self-adjoint operator is normal. I was told there is a mistake in the problem, but have not spotted it. Thanks in advance.","Problem: If A is a bounded normal operator, the spectrum , where B, C are bounded self adjoint operators which commute. Fact: A bounded normal operator A can be written , where B,C are bounded self adjoint operators which commute. Fact: Let H be a complex Hilbert space and let be a bounded complex linear operator, then A is normal if only if for all . Also every self-adjoint operator is normal. I was told there is a mistake in the problem, but have not spotted it. Thanks in advance.","\sigma(A)=\{s+it:s \in \sigma(B),t \in \sigma(C)\} A=B+iC A:H \rightarrow H \Vert A^*x \Vert=\Vert Ax \Vert x \in H",['functional-analysis']
12,On the convergence of approximate units for C*-algebras.,On the convergence of approximate units for C*-algebras.,,"Let $A$ be a non-unital C*-algebra and let $\pi : A \to \mathcal{B}(H)$ be a non-degenerate representation of $A$ (that is, $\mathrm{ span }\{\pi(a)h : a \in A, h \in H\}$ is a dense subset of $H$ ). Now let $(u_\lambda)_{\lambda \in \Lambda}$ be an approximate unit for $A$ . A standard argument, using non-degeneracy, shows that $(\pi(u_\lambda))_{\lambda \in \Lambda}$ converges strongly to $1_H$ , the identity operator on $H$ . There are several examples that show that $(\pi(u_\lambda))_{\lambda \in \Lambda}$ is not norm convergent. However, below I will present an argument that ""shows"" that $(\pi(u_\lambda))_{\lambda \in \Lambda}$ converges in norm to $1_H$ . This is certainly at fault, but I want to make sure I understand exactly where the proof goes wrong. Argument: Let $\epsilon >0$ and choose $h \in H$ with $\|h\|=1$ such that $$ \| 1_H - \pi(u_\lambda) \| < \epsilon + \| h - \pi(u_\lambda)h \|. $$ Then, since strong convergence of $(\pi(u_\lambda))_{\lambda \in \Lambda}$ implies that $(\| h - \pi(u_\lambda)h \|)_{\lambda \in \Lambda}$ converges to $0$ , we find $\lambda' \in \Lambda$ such that for all $\lambda \geq \lambda'$ , $$ \| h - \pi(u_\lambda)h \| < \epsilon. $$ Thus, for any $\lambda \geq \lambda'$ , we have shown $$ \| 1_H - \pi(u_\lambda) \| < 2\epsilon, $$ which proves that $\pi(u_\lambda)$ converges in norm to $1_H$ . End of argument. I am pretty sure that the problem in the above argument is that $h$ depends on $\epsilon$ and therefore also $\lambda'$ . Thus, the expression $\| h - \pi(u_\lambda)h \| < \epsilon$ for $\lambda \geq \lambda'$ doesn't make much sense to me. In any case, I am still not quite convinced about this and I would love to hear someone else's thoughts. Thanks in advance!","Let be a non-unital C*-algebra and let be a non-degenerate representation of (that is, is a dense subset of ). Now let be an approximate unit for . A standard argument, using non-degeneracy, shows that converges strongly to , the identity operator on . There are several examples that show that is not norm convergent. However, below I will present an argument that ""shows"" that converges in norm to . This is certainly at fault, but I want to make sure I understand exactly where the proof goes wrong. Argument: Let and choose with such that Then, since strong convergence of implies that converges to , we find such that for all , Thus, for any , we have shown which proves that converges in norm to . End of argument. I am pretty sure that the problem in the above argument is that depends on and therefore also . Thus, the expression for doesn't make much sense to me. In any case, I am still not quite convinced about this and I would love to hear someone else's thoughts. Thanks in advance!","A \pi : A \to \mathcal{B}(H) A \mathrm{ span }\{\pi(a)h : a \in A, h \in H\} H (u_\lambda)_{\lambda \in \Lambda} A (\pi(u_\lambda))_{\lambda \in \Lambda} 1_H H (\pi(u_\lambda))_{\lambda \in \Lambda} (\pi(u_\lambda))_{\lambda \in \Lambda} 1_H \epsilon >0 h \in H \|h\|=1 
\| 1_H - \pi(u_\lambda) \| < \epsilon + \| h - \pi(u_\lambda)h \|.
 (\pi(u_\lambda))_{\lambda \in \Lambda} (\| h - \pi(u_\lambda)h \|)_{\lambda \in \Lambda} 0 \lambda' \in \Lambda \lambda \geq \lambda' 
\| h - \pi(u_\lambda)h \| < \epsilon.
 \lambda \geq \lambda' 
\| 1_H - \pi(u_\lambda) \| < 2\epsilon,
 \pi(u_\lambda) 1_H h \epsilon \lambda' \| h - \pi(u_\lambda)h \| < \epsilon \lambda \geq \lambda'","['functional-analysis', 'hilbert-spaces', 'operator-algebras', 'c-star-algebras']"
13,Weak convergence of functionals $g_n^*(f) = n\int_0^1 x^nf(x)dx$ [closed],Weak convergence of functionals  [closed],g_n^*(f) = n\int_0^1 x^nf(x)dx,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Show that sequnce of functionals $g_n^*(f) = n\displaystyle{\int_0^1 x^nf(x)dx}, f \in C[0,1]$ converges weakly and find its limit functional. Does it converge in the norm of space $C^*[0,1]$ ? I don't even know how to start, I guess I have to guess first which is limit functional, and then prove $g_n^*$ converges to it, but I don't have any idea what it could be.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Show that sequnce of functionals converges weakly and find its limit functional. Does it converge in the norm of space ? I don't even know how to start, I guess I have to guess first which is limit functional, and then prove converges to it, but I don't have any idea what it could be.","g_n^*(f) = n\displaystyle{\int_0^1 x^nf(x)dx}, f \in C[0,1] C^*[0,1] g_n^*","['functional-analysis', 'limits', 'normed-spaces', 'uniform-convergence', 'weak-convergence']"
14,Direct sum decomposition of Hilbert spaces,Direct sum decomposition of Hilbert spaces,,"Let $A$ be a self-adjoint operator on a Hilbert space $\mathscr{H}$ with dense domain $D(A)$ . From the continuous functional calculus, for every continuous function $f \in C(\sigma(A))$ we can associate a bounded operator $f(A)$ on $\mathscr{H}$ . Moreover, if $\psi \in \mathscr{H}$ , the functional: $$\omega(f) := \langle \psi, f(A)\psi\rangle$$ is a positive linear functional, so by Riesz Representation Theorem there is an isomorphism between $\mathscr{H}$ and the set of regular Borel measures on $\sigma(A)$ , denoted by $M(\sigma(A))$ , such that each $\psi \in \mathscr{H}$ is uniquely associated to a measure $\mu_{\psi}$ , with $$\langle \psi, f(A)\psi\rangle = \int_{\sigma(A)}f(\lambda)d\mu_{\psi}(\lambda).$$ I now that every Borel measure $\mu$ has a decomposition $\mu = \mu_{pp}+\mu_{ac}+\mu_{sc}$ , which is a consequence of the Lebesgue Decomposition Theorem . Here $\mu_{pp}$ is a pure point measure, $\mu_{ac}$ is absolutely continuous with respect to the usual Borel measure on $\mathbb{R}$ and $\mu_{sc}$ is singular with respect to the latter. Hence, there is an identification $\psi \to \mu_{\psi} = \mu_{\psi,pp}+\mu_{\psi,ac}+\mu_{\psi,sc}$ . This shows that $\mathscr{H}$ can be written as $\mathscr{H}_{pp}+\mathscr{H}_{ac}+\mathscr{H}_{sc}$ , with $\mathscr{H}_{pp} := \{\psi \in \mathscr{H}: \mbox{$\mu_{\psi}$ is pure point}\}$ , $\mathscr{H}_{ac} := \{\psi \in \mathscr{H}: \mbox{$\mu_{\psi}$ is absolutely continuous with respect to the usual Borel measure}\}$ and $\mathscr{H}_{sc} := \{\psi \in \mathscr{H}: \mbox{$\mu_{\psi}$ is singular with respect to the the usual Borel measure}\}$ . My question is: why this sum is actually a direct sum ? That is, how to prove further that: $$\mathscr{H} = \mathscr{H}_{pp}\oplus \mathscr{H}_{ac}\oplus \mathscr{H}_{sc}?$$","Let be a self-adjoint operator on a Hilbert space with dense domain . From the continuous functional calculus, for every continuous function we can associate a bounded operator on . Moreover, if , the functional: is a positive linear functional, so by Riesz Representation Theorem there is an isomorphism between and the set of regular Borel measures on , denoted by , such that each is uniquely associated to a measure , with I now that every Borel measure has a decomposition , which is a consequence of the Lebesgue Decomposition Theorem . Here is a pure point measure, is absolutely continuous with respect to the usual Borel measure on and is singular with respect to the latter. Hence, there is an identification . This shows that can be written as , with , and . My question is: why this sum is actually a direct sum ? That is, how to prove further that:","A \mathscr{H} D(A) f \in C(\sigma(A)) f(A) \mathscr{H} \psi \in \mathscr{H} \omega(f) := \langle \psi, f(A)\psi\rangle \mathscr{H} \sigma(A) M(\sigma(A)) \psi \in \mathscr{H} \mu_{\psi} \langle \psi, f(A)\psi\rangle = \int_{\sigma(A)}f(\lambda)d\mu_{\psi}(\lambda). \mu \mu = \mu_{pp}+\mu_{ac}+\mu_{sc} \mu_{pp} \mu_{ac} \mathbb{R} \mu_{sc} \psi \to \mu_{\psi} = \mu_{\psi,pp}+\mu_{\psi,ac}+\mu_{\psi,sc} \mathscr{H} \mathscr{H}_{pp}+\mathscr{H}_{ac}+\mathscr{H}_{sc} \mathscr{H}_{pp} := \{\psi \in \mathscr{H}: \mbox{\mu_{\psi} is pure point}\} \mathscr{H}_{ac} := \{\psi \in \mathscr{H}: \mbox{\mu_{\psi} is absolutely continuous with respect to the usual Borel measure}\} \mathscr{H}_{sc} := \{\psi \in \mathscr{H}: \mbox{\mu_{\psi} is singular with respect to the the usual Borel measure}\} \mathscr{H} = \mathscr{H}_{pp}\oplus \mathscr{H}_{ac}\oplus \mathscr{H}_{sc}?","['functional-analysis', 'mathematical-physics', 'spectral-theory']"
15,Show that the set $\lbrace F(x) = \displaystyle\int_0^x f(t)dt | f \in M\rbrace$ is sequentially compact.,Show that the set  is sequentially compact.,\lbrace F(x) = \displaystyle\int_0^x f(t)dt | f \in M\rbrace,"Let $M$ be a bounded subset of $C([0,1])$ . Show that the set $\left\lbrace F(x) = \displaystyle\int_0^x f(t)dt | f \in M \right\rbrace$ is sequentially compact (meaning that any sequence in the set has a convergent subsequence). My idea is that: Let $\lbrace F_n \rbrace$ be the sequence in the set and fix $x \in [0,1]$ , then $\lbrace F_n(x) \rbrace$ is bounded, so by Bolzano-Weierstrass, there exists a subsequent $\lbrace F_{n_k}(x)\rbrace$ converges. So I guess if I repeat the same procedure, I may have a convergent subsequence? But for different $x$ , I may have different subsequence, so I don't know what to handle this. Can somebody please help me with this?","Let be a bounded subset of . Show that the set is sequentially compact (meaning that any sequence in the set has a convergent subsequence). My idea is that: Let be the sequence in the set and fix , then is bounded, so by Bolzano-Weierstrass, there exists a subsequent converges. So I guess if I repeat the same procedure, I may have a convergent subsequence? But for different , I may have different subsequence, so I don't know what to handle this. Can somebody please help me with this?","M C([0,1]) \left\lbrace F(x) = \displaystyle\int_0^x f(t)dt | f \in M \right\rbrace \lbrace F_n \rbrace x \in [0,1] \lbrace F_n(x) \rbrace \lbrace F_{n_k}(x)\rbrace x","['functional-analysis', 'analysis', 'compactness']"
16,Definition of normal state on von Neumann algebra,Definition of normal state on von Neumann algebra,,"I have a question about the notion of normal state on a von Neumann algebra and its relation to a particular representation of the algebra. Let me take from the book by Bratteli and Robinson: Definition 2.4.20: A state $\omega : \mathfrak{M} \to \mathbb{C}$ on a von Neumann algebra $\mathfrak{M}$ is called normal if $\omega ( \text{l.u.b.}_\alpha ~ A_\alpha ) = \text{l.u.b.}_\alpha ~ \omega (A_\alpha)$ , where $\text{l.u.b.}$ is the least upper bound and $\{ A_\alpha \}$ is an increasing net in $\mathfrak{M}_+$ with an upper bound. Theorem 2.4.21: Let $\omega$ be a state on a von Neumann algebra $\mathfrak{M}$ acting on a Hilbert space $H$ . Then $\omega$ is normal if and only if there exists a positive, trace-class operator $\rho$ on $H$ with $\text{Tr} ( \rho) = 1$ such that $$ \omega (A) = \text{Tr}  ( \rho A ) , \quad \forall A \in \mathfrak{M}  . $$ The definition is clearly independent of any representation of the algebra, while from the theorem it seems that a state might be normal in one representation and non-normal in another. Also, every state is a vector state in its GNS representation, so it's also normal. But then how is it possible that the definition of normal be representation independent?","I have a question about the notion of normal state on a von Neumann algebra and its relation to a particular representation of the algebra. Let me take from the book by Bratteli and Robinson: Definition 2.4.20: A state on a von Neumann algebra is called normal if , where is the least upper bound and is an increasing net in with an upper bound. Theorem 2.4.21: Let be a state on a von Neumann algebra acting on a Hilbert space . Then is normal if and only if there exists a positive, trace-class operator on with such that The definition is clearly independent of any representation of the algebra, while from the theorem it seems that a state might be normal in one representation and non-normal in another. Also, every state is a vector state in its GNS representation, so it's also normal. But then how is it possible that the definition of normal be representation independent?","\omega : \mathfrak{M} \to \mathbb{C} \mathfrak{M} \omega ( \text{l.u.b.}_\alpha ~ A_\alpha ) = \text{l.u.b.}_\alpha ~ \omega (A_\alpha) \text{l.u.b.} \{ A_\alpha \} \mathfrak{M}_+ \omega \mathfrak{M} H \omega \rho H \text{Tr} ( \rho) = 1  \omega (A) = \text{Tr}  ( \rho A ) , \quad \forall A \in \mathfrak{M}  . ","['functional-analysis', 'operator-algebras', 'von-neumann-algebras']"
17,General definition of POVM,General definition of POVM,,"Wikipedia gives the following definition of positive operator-valued measure (POVM): A POVM on a measurable space $(X,M)$ is a function $F$ defined on $M$ whose values are bounded non-negative self-adjoint operators on a Hilbert space $\mathcal{H}$ such that $F(X) = 1_\mathcal{H}$ and for every $\psi \in \mathcal{H}$ the map $E \mapsto \langle F(E) \psi , \psi \rangle$ is a non-negative countably additive measure on $M$ . When the set of outcomes $X$ is finite and/or the Hilbert space has finite dimension, a simpler definition can be easily found in standard textbooks, but in the general case none of the books I've checked (on quantum mechanics, functional analysis or $C^*$ -algebras) contains a definition. Do you have a reference, other than Wikipedia, for an equivalent definition of POVM?","Wikipedia gives the following definition of positive operator-valued measure (POVM): A POVM on a measurable space is a function defined on whose values are bounded non-negative self-adjoint operators on a Hilbert space such that and for every the map is a non-negative countably additive measure on . When the set of outcomes is finite and/or the Hilbert space has finite dimension, a simpler definition can be easily found in standard textbooks, but in the general case none of the books I've checked (on quantum mechanics, functional analysis or -algebras) contains a definition. Do you have a reference, other than Wikipedia, for an equivalent definition of POVM?","(X,M) F M \mathcal{H} F(X) = 1_\mathcal{H} \psi \in \mathcal{H} E \mapsto \langle F(E) \psi , \psi \rangle M X C^*","['functional-analysis', 'measure-theory', 'reference-request', 'quantum-mechanics']"
18,How can I approximate this characteristic function?,How can I approximate this characteristic function?,,"Let $F\subset \Bbb{R}^d$ be a closed subset. Let us define $f(x)=\Bbb{1}_F(x)$ . I want to approximate this function by a continuous function. If $d=1$ I know how to solve this problem, but if $d$ is arbitrary I have some problems. In internet I found someone who defined $f_m(x)=\max\{0,1-m\cdot d(x,F)\}$ and claimed that $f_m$ approximates $f$ . The problem is that I don't see how it works. Is there some intuition behind this? It would be nice if someone could explain me the inuition.","Let be a closed subset. Let us define . I want to approximate this function by a continuous function. If I know how to solve this problem, but if is arbitrary I have some problems. In internet I found someone who defined and claimed that approximates . The problem is that I don't see how it works. Is there some intuition behind this? It would be nice if someone could explain me the inuition.","F\subset \Bbb{R}^d f(x)=\Bbb{1}_F(x) d=1 d f_m(x)=\max\{0,1-m\cdot d(x,F)\} f_m f","['functional-analysis', 'analysis', 'approximation']"
19,Maximal domain of unbounded linear differential operator,Maximal domain of unbounded linear differential operator,,"Let's consider the following (unbounded) linear Operator. (So called Transport-Operator in some context.) $$ \mathrm{T}: \mathcal{H} \supset \mathcal{D}(\mathrm{T}) \to \mathcal{H} , f \mapsto \mathrm{T}f:= v \cdot \partial_xf(x,v), $$ where $\mathcal{H}$ is a weighted Hilbert-space defined by $ \mathcal{H} := L^2(\mathbb{T}^1 \times \mathbb{R}, M(v)^{-1}\mathrm{d}x\mathrm{d}v),$ $ M(v) := \frac{1}{\sqrt{2 \pi}}\mathrm{e}^{-\frac{1}{2}v^2},$ and the dot product on $\mathcal{H}$ is defined by $$ (f,g)_{\mathcal{H}} := \int_{\mathrm{T}^1 \times \mathrm{R}}\frac{f(x,v)g(x,v)}{M(v)} \, \, \mathrm{d}x\mathrm{d}v,$$ $\mathbb{T}^1$ denotes the one-dimensional Torus. It is easy to verify that $\mathrm{T}$ is formally a skew-symmetric Operator w.r.t. $(\cdot, \cdot)_{\mathcal{H}}$ . $\mathcal{D}(\mathrm{T})$ denotes the maximal domain of $\mathrm{T}$ which should be unique, dense and $\mathrm{T}$ should be a closed operator on $\mathcal{D}(\mathrm{T})$ . $\mathcal{R}(\mathrm{T})$ denotes the range of $\mathrm{T}.$ My question is now how can I define and determine $\mathcal{D}(\mathrm{T})$ and how can I easily describe/characterize $\mathcal{D}(\mathrm{T})$ explicitly? The same question for $\mathcal{R}(\mathrm{T})$ . The derivative $\partial_x$ is to be understood in the weak-sense, so for all $v \in \mathbb{R}$ we will need $f(x,v) \in H^1(\mathbb{T}^1)$ (Sobolev-space) for example. My conjecture would be $$ \mathcal{D}(\mathrm{T}) = \left \{f \in \mathcal{H} : \int_{\mathbb{T}^1 \times \mathbb{R}} \frac{v^2(\partial_xf(x,v))^2}{M(v)}\, \, \mathrm{d}x\mathrm{d}v < + \infty \right\} = \{f \in \mathcal{H} : \mathrm{T}f \in \mathcal{H} \},$$ so that $(\mathrm{T}f, g)_{\mathcal{H}}$ for arbitrary $g \in \mathcal{H}$ is at least well-defined. Would be grateful for any help and ideas! EDIT: My attempt to show closedness of $\mathrm{T}$ on $\mathcal{D}(\mathrm{T}).$ Set $\Omega := \mathbb{T}^1 \times \mathbb{R}$ and $\mathrm{d}\mu := M(v)^{-1}\mathrm{d}x\mathrm{d}v.$ Let $(f_n)_{n \in \mathbb{N}}$ a sequence in $\mathcal{D}(\mathrm{T})$ with $f_n \rightarrow f$ in $\mathcal{H}$ and $\mathrm{T}f_n \rightarrow g$ in $\mathcal{H}$ . We have to show: 1.) $f \in \mathcal{D}(\mathrm{T})$ and 2.) $\mathrm{T}f = g. $ We can proceed as follows. Strong convergence in $\mathcal{H}=L^2(\Omega, \mathrm{d}\mu)$ implies weak convergence so we have: $$ \int_{\Omega} f_n(x,v) \phi(x,v) \, \mathrm{d}\mu \rightarrow \int_{\Omega} f(x,v) \phi(x,v) \, \mathrm{d}\mu$$ for all $ \phi \in C_c^{\infty}(\Omega),$ and $$ -\int_{\Omega} v \cdot f_n(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu = \int_{\Omega} v \cdot \partial_xf_n(x,v) \phi(x,v) \, \mathrm{d}\mu \rightarrow \int_{\Omega} g(x,v) \phi(x,v) \, \mathrm{d}\mu$$ for all $ \phi \in C_c^{\infty}(\Omega).$ Due to $$  -\int_{\Omega} v \cdot f_n(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu \rightarrow -\int_{\Omega} v \cdot f(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu$$ we have $$ -\int_{\Omega} v \cdot f(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu = \int_{\Omega} g(x,v) \phi(x,v) \, \mathrm{d}\mu,$$ so we can conclude $ g = v \cdot \partial_xf = \mathrm{T}f. $ Would that be correct?","Let's consider the following (unbounded) linear Operator. (So called Transport-Operator in some context.) where is a weighted Hilbert-space defined by and the dot product on is defined by denotes the one-dimensional Torus. It is easy to verify that is formally a skew-symmetric Operator w.r.t. . denotes the maximal domain of which should be unique, dense and should be a closed operator on . denotes the range of My question is now how can I define and determine and how can I easily describe/characterize explicitly? The same question for . The derivative is to be understood in the weak-sense, so for all we will need (Sobolev-space) for example. My conjecture would be so that for arbitrary is at least well-defined. Would be grateful for any help and ideas! EDIT: My attempt to show closedness of on Set and Let a sequence in with in and in . We have to show: 1.) and 2.) We can proceed as follows. Strong convergence in implies weak convergence so we have: for all and for all Due to we have so we can conclude Would that be correct?"," \mathrm{T}: \mathcal{H} \supset \mathcal{D}(\mathrm{T}) \to \mathcal{H} , f \mapsto \mathrm{T}f:= v \cdot \partial_xf(x,v),  \mathcal{H}  \mathcal{H} := L^2(\mathbb{T}^1 \times \mathbb{R}, M(v)^{-1}\mathrm{d}x\mathrm{d}v),  M(v) := \frac{1}{\sqrt{2 \pi}}\mathrm{e}^{-\frac{1}{2}v^2}, \mathcal{H}  (f,g)_{\mathcal{H}} := \int_{\mathrm{T}^1 \times \mathrm{R}}\frac{f(x,v)g(x,v)}{M(v)} \, \, \mathrm{d}x\mathrm{d}v, \mathbb{T}^1 \mathrm{T} (\cdot, \cdot)_{\mathcal{H}} \mathcal{D}(\mathrm{T}) \mathrm{T} \mathrm{T} \mathcal{D}(\mathrm{T}) \mathcal{R}(\mathrm{T}) \mathrm{T}. \mathcal{D}(\mathrm{T}) \mathcal{D}(\mathrm{T}) \mathcal{R}(\mathrm{T}) \partial_x v \in \mathbb{R} f(x,v) \in H^1(\mathbb{T}^1)  \mathcal{D}(\mathrm{T}) = \left \{f \in \mathcal{H} : \int_{\mathbb{T}^1 \times \mathbb{R}} \frac{v^2(\partial_xf(x,v))^2}{M(v)}\, \, \mathrm{d}x\mathrm{d}v < + \infty \right\} = \{f \in \mathcal{H} : \mathrm{T}f \in \mathcal{H} \}, (\mathrm{T}f, g)_{\mathcal{H}} g \in \mathcal{H} \mathrm{T} \mathcal{D}(\mathrm{T}). \Omega := \mathbb{T}^1 \times \mathbb{R} \mathrm{d}\mu := M(v)^{-1}\mathrm{d}x\mathrm{d}v. (f_n)_{n \in \mathbb{N}} \mathcal{D}(\mathrm{T}) f_n \rightarrow f \mathcal{H} \mathrm{T}f_n \rightarrow g \mathcal{H} f \in \mathcal{D}(\mathrm{T}) \mathrm{T}f = g.  \mathcal{H}=L^2(\Omega, \mathrm{d}\mu)  \int_{\Omega} f_n(x,v) \phi(x,v) \, \mathrm{d}\mu \rightarrow \int_{\Omega} f(x,v) \phi(x,v) \, \mathrm{d}\mu  \phi \in C_c^{\infty}(\Omega),  -\int_{\Omega} v \cdot f_n(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu = \int_{\Omega} v \cdot \partial_xf_n(x,v) \phi(x,v) \, \mathrm{d}\mu \rightarrow \int_{\Omega} g(x,v) \phi(x,v) \, \mathrm{d}\mu  \phi \in C_c^{\infty}(\Omega).   -\int_{\Omega} v \cdot f_n(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu \rightarrow -\int_{\Omega} v \cdot f(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu  -\int_{\Omega} v \cdot f(x,v) \partial_x\phi(x,v) \, \mathrm{d}\mu = \int_{\Omega} g(x,v) \phi(x,v) \, \mathrm{d}\mu,  g = v \cdot \partial_xf = \mathrm{T}f. ","['functional-analysis', 'operator-theory', 'differential-operators', 'unbounded-operators', 'function-spaces']"
20,Center of Simple $C^*$-Algebras,Center of Simple -Algebras,C^*,"Given a simple $C^*$ -Algebra $A$ , consider its center $C = A \cap A'$ , i.e. the set of elements in $A$ commuting with every other element in $A$ . I have shown that if $A$ is unital, its center is trivial, i.e. $C = \mathbb{C} \cdot I$ . It should be the case that if $A$ is non-unital, we have $C = 0$ , but I don't know how to approach showing this. In the unital case I considered the spectrum of an arbitrary element $a \in C$ , which has to be nonempty, and showed that for some $\lambda \in \sigma(a)$ the set $\overline{(\lambda - c)A}$ is an ideal not containing $1$ , so it must be $\{0\}$ . However, I cannot do that here.","Given a simple -Algebra , consider its center , i.e. the set of elements in commuting with every other element in . I have shown that if is unital, its center is trivial, i.e. . It should be the case that if is non-unital, we have , but I don't know how to approach showing this. In the unital case I considered the spectrum of an arbitrary element , which has to be nonempty, and showed that for some the set is an ideal not containing , so it must be . However, I cannot do that here.",C^* A C = A \cap A' A A A C = \mathbb{C} \cdot I A C = 0 a \in C \lambda \in \sigma(a) \overline{(\lambda - c)A} 1 \{0\},"['functional-analysis', 'operator-theory', 'ideals', 'operator-algebras', 'c-star-algebras']"
21,"If A is a positive linear transformation, AB is self-adjoint, then $|(ABx,x)| \leq ||B||(Ax,x)$ or $|(ABx,x)| \leq \rho(B)(Ax,x)$","If A is a positive linear transformation, AB is self-adjoint, then  or","|(ABx,x)| \leq ||B||(Ax,x) |(ABx,x)| \leq \rho(B)(Ax,x)","Prove or disprove: If $A$ is a positive linear transformation, $AB$ is self-adjoint, then a, $|(ABx,x)| \leq ||B||.(Ax,x)$ b, $|(ABx,x)| \leq \rho(B).(Ax,x)$ With the matrix norm defined by: $||A|| := \sup_{x \in V}{\frac{||Ax||}{||x||}} = \sup_{x \in V}{\frac{|(Ax,y)|}{||x||.||y||}}.$ If $A$ is self-adjoint, then $||A||$ is also $\sup_{x \in V}{\frac{(Ax,x)}{||x||^2}}$ . And $\rho(B)$ is the spectral radius of linear transformation $B$ . Also, if $A$ is a positive transformation, that means $A = C^{*}C$ for some $C$ , or $A = B^2$ for some self-adjoint $B$ , or $(Ax,x) \geq 0 \space, \forall x \in V$ and $A$ be self-adjoint. These definitions are equivalent. The hypothesis "" $AB$ is self-adjoint"" implys $B$ can be written in the form $CA$ , with $C$ be a self-adjoint transformation. But from here, after trying a lot of things, I can't seem to get to that $||B||$ . One of the closest results I've got is LHS $\leq ||\sqrt{A}C\sqrt{A}||.(Ax,x)$","Prove or disprove: If is a positive linear transformation, is self-adjoint, then a, b, With the matrix norm defined by: If is self-adjoint, then is also . And is the spectral radius of linear transformation . Also, if is a positive transformation, that means for some , or for some self-adjoint , or and be self-adjoint. These definitions are equivalent. The hypothesis "" is self-adjoint"" implys can be written in the form , with be a self-adjoint transformation. But from here, after trying a lot of things, I can't seem to get to that . One of the closest results I've got is LHS","A AB |(ABx,x)| \leq ||B||.(Ax,x) |(ABx,x)| \leq \rho(B).(Ax,x) ||A|| := \sup_{x \in V}{\frac{||Ax||}{||x||}} = \sup_{x \in V}{\frac{|(Ax,y)|}{||x||.||y||}}. A ||A|| \sup_{x \in V}{\frac{(Ax,x)}{||x||^2}} \rho(B) B A A = C^{*}C C A = B^2 B (Ax,x) \geq 0 \space, \forall x \in V A AB B CA C ||B|| \leq ||\sqrt{A}C\sqrt{A}||.(Ax,x)","['linear-algebra', 'functional-analysis', 'linear-transformations']"
22,"Are the ""bounded, uniformly continuous functions"" analogous to test functions as seen in Schwartz Distributions?","Are the ""bounded, uniformly continuous functions"" analogous to test functions as seen in Schwartz Distributions?",,"I am reading this passage from Billingsley's Convergence of Probability measures. Theorem 1.2. Probability measures $P$ and $Q$ on $\mathcal{S}$ coincide if $P f=Q f$ for all bounded, uniformly continuous real functions $f$ . Proof. For the bounded, uniformly continuous $f$ of (1.1), $P F \leq$ $P f=Q f \leq Q F^\epsilon$ . Letting $\epsilon \downarrow 0$ gives $P F \leq Q F$ , provided $F$ is closed. By symmetry and Theorem $1.1, P=Q$ . Because of theorems like this, it is possible to work with measures $P A$ or with integrals $P f$ , whichever is simpler or more natural. We defined weak convergence in terms of the convergence of integrals of functions, and in the next section we characterize it in terms of the convergence of measures of sets. Are the ""bounded, uniformly continuous"" analagous to the ""test functions"" $C_c^\infty(X)$ seen in the ""theory of distributions? Is this describing that we can think of probability measures as ""distributions"" or ""measures"" by the reisz representation theorem? Why do they use ""bounded, uniformly continuous"" real functions instead of infinitely differentiable continuous functions with compact support as used in Schwartz distributions? https://en.wikipedia.org/wiki/Distribution_(mathematics)","I am reading this passage from Billingsley's Convergence of Probability measures. Theorem 1.2. Probability measures and on coincide if for all bounded, uniformly continuous real functions . Proof. For the bounded, uniformly continuous of (1.1), . Letting gives , provided is closed. By symmetry and Theorem . Because of theorems like this, it is possible to work with measures or with integrals , whichever is simpler or more natural. We defined weak convergence in terms of the convergence of integrals of functions, and in the next section we characterize it in terms of the convergence of measures of sets. Are the ""bounded, uniformly continuous"" analagous to the ""test functions"" seen in the ""theory of distributions? Is this describing that we can think of probability measures as ""distributions"" or ""measures"" by the reisz representation theorem? Why do they use ""bounded, uniformly continuous"" real functions instead of infinitely differentiable continuous functions with compact support as used in Schwartz distributions? https://en.wikipedia.org/wiki/Distribution_(mathematics)","P Q \mathcal{S} P f=Q f f f P F \leq P f=Q f \leq Q F^\epsilon \epsilon \downarrow 0 P F \leq Q F F 1.1, P=Q P A P f C_c^\infty(X)","['probability', 'functional-analysis', 'analysis', 'probability-distributions', 'stochastic-processes']"
23,How can i use compactness arguments here?,How can i use compactness arguments here?,,"Question: Let $F$ be a real Banach space, $\mu$ be a Borel probability measure on a compact Hausdorff space $X$ , and let $ f : X \rightarrow F$ be a continuous mapping. Then, using a compactness argument show the existence of a point $ y \in \overline{co}(f(X))$ such that $$ \Psi(y) = \int _X \Psi \circ f d\mu \quad \textrm{for every}\; \Psi \in F'.$$ How can I show this property? can you give me hint? We can use the following Theorem Theorem: Let $F$ be a real Banach space, $\mu$ be a Borel probability measure on a compact Hausdorff space $X$ , and let $ f : X \rightarrow F$ be a continuous mapping. Given $ \Psi_1 , \ldots \Psi_n \in F'$ let $$ \nu _j = \int _X \Psi \circ f d \mu \quad \textrm{for}\quad j = 1, \ldots ,n,$$ and let $T : F \rightarrow \mathbb{R}^n$ linear function defined by $$ T(y) = (\Psi_1(y),\ldots, \Psi_n(y)) \quad \textrm{for every} \quad y \in F.$$ then, $$ (\nu_1,\ldots,\nu_n) \in co(T\circ f(X)) = T(co(f(X))),$$ where $co(B)$ denotes the convex hull of the set B. I used this theorem like that For any $ \Psi \in F'$ , we take $$ \nu = \int _X \Psi \circ f d \mu$$ and let $ T: F \rightarrow \mathbb{R}$ be defined by $$ T(y) = \Psi(y). $$ Hence, applying above theorem we have $$ \Psi(\int_X f d\mu) = \int_X \Psi \circ f d \mu \in co(\Psi (f(X))) = \Psi (co(f(X)))$$ I stack here can you give me any hints ?","Question: Let be a real Banach space, be a Borel probability measure on a compact Hausdorff space , and let be a continuous mapping. Then, using a compactness argument show the existence of a point such that How can I show this property? can you give me hint? We can use the following Theorem Theorem: Let be a real Banach space, be a Borel probability measure on a compact Hausdorff space , and let be a continuous mapping. Given let and let linear function defined by then, where denotes the convex hull of the set B. I used this theorem like that For any , we take and let be defined by Hence, applying above theorem we have I stack here can you give me any hints ?","F \mu X  f : X \rightarrow F  y \in \overline{co}(f(X))  \Psi(y) = \int _X \Psi \circ f d\mu \quad \textrm{for every}\; \Psi \in F'. F \mu X  f : X \rightarrow F  \Psi_1 , \ldots \Psi_n \in F'  \nu _j = \int _X \Psi \circ f d \mu \quad \textrm{for}\quad j = 1, \ldots ,n, T : F \rightarrow \mathbb{R}^n  T(y) = (\Psi_1(y),\ldots, \Psi_n(y)) \quad \textrm{for every} \quad y \in F.  (\nu_1,\ldots,\nu_n) \in co(T\circ f(X)) = T(co(f(X))), co(B)  \Psi \in F'  \nu = \int _X \Psi \circ f d \mu  T: F \rightarrow \mathbb{R}  T(y) = \Psi(y).   \Psi(\int_X f d\mu) = \int_X \Psi \circ f d \mu \in co(\Psi (f(X))) = \Psi (co(f(X)))","['complex-analysis', 'functional-analysis', 'polynomials', 'banach-spaces', 'bochner-spaces']"
24,Norm of an integral functional,Norm of an integral functional,,"Let $k\in C[0,1]$ and let $T$ be the functional on $C[0,1]$ (equipped with sup norm) given by $f\mapsto \int_0^1 kf$ . Show that $\Vert T\Vert = \Vert k\Vert_1$ . My attempt: The inequality $\Vert T\Vert \le \Vert k\Vert_1$ is obvious. Indeed, $\Vert Tf\Vert \le \Vert f\Vert_{\infty} \int_0^1 |k|=\Vert k\Vert_1 \Vert f\Vert_{\infty}$ . On the other hand, for $f=k$ , we have $$Tf=\int_0^1 k^2=\Vert k\Vert_2^2 \ge \Vert k\Vert_1^2\ge \Vert k \Vert_1$$ by Hölder's inequality. It follows that $\Vert T\Vert = \Vert k\Vert_1$ . Is my solution correct? PS: This question was actually answered here but there $f=sgn(k)$ which is not a continuous function, so I think the solution there is incorrect.","Let and let be the functional on (equipped with sup norm) given by . Show that . My attempt: The inequality is obvious. Indeed, . On the other hand, for , we have by Hölder's inequality. It follows that . Is my solution correct? PS: This question was actually answered here but there which is not a continuous function, so I think the solution there is incorrect.","k\in C[0,1] T C[0,1] f\mapsto \int_0^1 kf \Vert T\Vert = \Vert k\Vert_1 \Vert T\Vert \le \Vert k\Vert_1 \Vert Tf\Vert \le \Vert f\Vert_{\infty} \int_0^1 |k|=\Vert k\Vert_1 \Vert f\Vert_{\infty} f=k Tf=\int_0^1 k^2=\Vert k\Vert_2^2 \ge \Vert k\Vert_1^2\ge \Vert k \Vert_1 \Vert T\Vert = \Vert k\Vert_1 f=sgn(k)","['functional-analysis', 'solution-verification', 'operator-theory']"
25,Infinite-dimensional Banach has proper dense subspace,Infinite-dimensional Banach has proper dense subspace,,"Show that every (separable) infinite-dimensional Banach space $X$ contains a proper vector subspace $Y$ with $cl (Y)$ = $X$ This is Exercise 1 (f) p.245 of this book . Assuming $X$ is separable, there is an increasing sequence of finite-dimensional subspaces $G_n$ such that $G:=\bigcup_n G_n$ is dense in $E$ . The vector subspace $span(G)$ is dense as well. Since $X$ has infinite dimension, each $G_n$ is closed and has empty interior. By Baire's theorem, $G$ has empty interior. However this does not imply that $span(G)\neq X$ . Can this line of thought lead to a solution ? Completely different solutions are fine. I'm also interested in a proof for the case where $X$ is not separable.","Show that every (separable) infinite-dimensional Banach space contains a proper vector subspace with = This is Exercise 1 (f) p.245 of this book . Assuming is separable, there is an increasing sequence of finite-dimensional subspaces such that is dense in . The vector subspace is dense as well. Since has infinite dimension, each is closed and has empty interior. By Baire's theorem, has empty interior. However this does not imply that . Can this line of thought lead to a solution ? Completely different solutions are fine. I'm also interested in a proof for the case where is not separable.",X Y cl (Y) X X G_n G:=\bigcup_n G_n E span(G) X G_n G span(G)\neq X X,"['general-topology', 'functional-analysis', 'banach-spaces']"
26,Trouble with simple notation in proving linearity of an operator.,Trouble with simple notation in proving linearity of an operator.,,"Consider the operator $T\colon \mathcal C[0,1]\to \mathcal C[0,1]$ defined by $$ Tf(x) = \int_0^x f(t) \, dt, \quad \forall f \in \mathcal C[0,1].$$ To prove its linearity, consider two scalars $\alpha,\beta \in \mathbb K$ and two functions $f,g \in \mathcal C[0,1]$ , as arbitrary as possible. Then, \begin{equation*}     T(\alpha f+\beta g)\color{red}{(x)} = \int_0^x (\alpha f + \beta g)(t)\, dt = \int_0^x \alpha f(t) + \beta g(t) \, dt = \alpha \int_0^x f(t) \, dt + \beta \int_0^x g(t) \, dt = \alpha Tf\color{red}{(x)} + \beta Tg\color{red}{(x)}. \end{equation*} My question. Does my notation in $\color{red}{red}$ makes sense? Somehow, in my head it would make more sense if I just wrote $T(\alpha f + \beta g)$ but, at the same time, according to the definition it doesn't make that much sense. I get even more confused when it comes to the final conclusion: We just proved that $$ T(\alpha f + \beta g) = \alpha Tf + \beta Tg, \quad \forall \alpha,\beta \in \mathbb K, \, \forall f,g \in \mathcal C[0,1].$$ Here, I didn't use the notation in $\color{red}{red}$ since it makes zero sense to me. Thanks for any help in advance.","Consider the operator defined by To prove its linearity, consider two scalars and two functions , as arbitrary as possible. Then, My question. Does my notation in makes sense? Somehow, in my head it would make more sense if I just wrote but, at the same time, according to the definition it doesn't make that much sense. I get even more confused when it comes to the final conclusion: We just proved that Here, I didn't use the notation in since it makes zero sense to me. Thanks for any help in advance.","T\colon \mathcal C[0,1]\to \mathcal C[0,1]  Tf(x) = \int_0^x f(t) \, dt, \quad \forall f \in \mathcal C[0,1]. \alpha,\beta \in \mathbb K f,g \in \mathcal C[0,1] \begin{equation*}
    T(\alpha f+\beta g)\color{red}{(x)} = \int_0^x (\alpha f + \beta g)(t)\, dt = \int_0^x \alpha f(t) + \beta g(t) \, dt = \alpha \int_0^x f(t) \, dt + \beta \int_0^x g(t) \, dt = \alpha Tf\color{red}{(x)} + \beta Tg\color{red}{(x)}.
\end{equation*} \color{red}{red} T(\alpha f + \beta g)  T(\alpha f + \beta g) = \alpha Tf + \beta Tg, \quad \forall \alpha,\beta \in \mathbb K, \, \forall f,g \in \mathcal C[0,1]. \color{red}{red}","['functional-analysis', 'functions', 'notation']"
27,Determining when $A(e_n) = \alpha_n\sum_{i=n}^{2n}e_i$ is a bounded linear function on $l^1(\mathbb{N})$,Determining when  is a bounded linear function on,A(e_n) = \alpha_n\sum_{i=n}^{2n}e_i l^1(\mathbb{N}),"Consider the space $S = l^1(\mathbb{N})$ over complex coefficients and define $A$ by $A(e_n) = \alpha_n\sum_{i=1}^{2n}e_n$ for the standard basis $\left(e_n\right)_{n\in\mathbb{N}}$ of $S$ . I am trying to determine when $A$ is a bounded linear function, but currently I am stuck at showing that $A$ 's codomain really is $l^1(\mathbb{N})$ , which in turn seems to be equivalent for $A$ to be continuous. I mean the following: $u \equiv \sum_{i=1}^\infty u_ie_i, u_i\in\mathbb{C}$ such that $\sum_{i=1}^\infty |u_i| < \infty$ . Now, $$A\left(u\right) = A\left(\sum_{i=1}^\infty u_ie_i\right)$$ and I would like to be able to conclude that $$A\left(u\right) = \sum_{i=1}^\infty A(u_ie_i) = \sum_{i=1}^\infty u_i\alpha_i\sum_{j=i}^{2i}e_i$$ But I don't really see an immediate way to conclude this. Being able to pull out the limit is equivalent to $$||\lim_{N\to\infty}\sum_{i=1}^NA(u_ie_i) - A(u)|| = \lim_{N\to\infty}||\sum_{i=1}^NA(u_ie_i) - A(u)|| = 0$$ but the problem is that we don't a priori know that $A(u)$ is, and hence concluding the convergence feels sketchy. How should I proceed with this proof?","Consider the space over complex coefficients and define by for the standard basis of . I am trying to determine when is a bounded linear function, but currently I am stuck at showing that 's codomain really is , which in turn seems to be equivalent for to be continuous. I mean the following: such that . Now, and I would like to be able to conclude that But I don't really see an immediate way to conclude this. Being able to pull out the limit is equivalent to but the problem is that we don't a priori know that is, and hence concluding the convergence feels sketchy. How should I proceed with this proof?","S = l^1(\mathbb{N}) A A(e_n) = \alpha_n\sum_{i=1}^{2n}e_n \left(e_n\right)_{n\in\mathbb{N}} S A A l^1(\mathbb{N}) A u \equiv \sum_{i=1}^\infty u_ie_i, u_i\in\mathbb{C} \sum_{i=1}^\infty |u_i| < \infty A\left(u\right) = A\left(\sum_{i=1}^\infty u_ie_i\right) A\left(u\right) = \sum_{i=1}^\infty A(u_ie_i) = \sum_{i=1}^\infty u_i\alpha_i\sum_{j=i}^{2i}e_i ||\lim_{N\to\infty}\sum_{i=1}^NA(u_ie_i) - A(u)|| = \lim_{N\to\infty}||\sum_{i=1}^NA(u_ie_i) - A(u)|| = 0 A(u)","['functional-analysis', 'linear-transformations', 'banach-spaces', 'lp-spaces']"
28,1-Lipschitzian Linear Operators on Hilbert Spaces and Fixed Points,1-Lipschitzian Linear Operators on Hilbert Spaces and Fixed Points,,"$\textbf{Question}$ Let $(\mathcal{H}, \langle \cdot \, | \, \cdot \rangle)$ be a real Hilbert space with induced norm $\|\cdot\| = \sqrt{\langle \cdot \, | \, \cdot \rangle}$ and let $$\mathscr{B}(\mathcal{H},\mathcal{H}) \equiv \mathscr{B}(\mathcal{H}) = \{ T : \mathcal{H} \rightarrow \mathcal{H} \, | \, T ~\textrm{is linear and continuous} \}.$$ Additionally, let $T \in \mathscr{B}(\mathcal{H})$ be 1-Lipschitzian, i.e., $$(\forall x \in \mathcal{H})(\forall y \in \mathcal{H}) ~~ \| T x - T y \| \leq \| x - y \|.$$ Show that $\textrm{Fix} \, T = \textrm{Fix} \, T^{*},$ where $T^{*}$ is the adjoint of $T$ (i.e., $T^{*} \in \mathscr{B}(\mathcal{H})$ is the unique operator that satisfies $\langle T x \, | \, y \rangle = \langle x \, | \, T^{*} y \rangle$ for every $x$ and $y$ in $\mathcal{H}$ ) and $\textrm{Fix} \, T = \{ x \in \mathcal{H} \, | \, T x = x \}.$ $\textit{Remark}$ : $0_{\mathcal{H}}$ designates the zero element in $\mathcal{H}.$ $\textbf{Incomplete Solution Attempt}$ Since $T$ is 1-Lipschitzian, one can show (which I have already done) that $\| T \| \leq 1$ (in fact, this is an equivalent characterization in this particular context). Now, take $x \in \textrm{Fix} \, T.$ Then $$ \| x \| = \|T x\| \leq \| T \| \| x \| \leq \| x \|. $$ Hence, $\| T \| \| x \| = \| x \|,$ or, equivalently, $(\| T \| - 1) \| x \| = 0.$ Therefore, either $\| T \| = 1$ or $\| x \| = 0.$ If $\| x \| = 0,$ then $x = 0_{\mathcal{H}}$ and consequently, $\textrm{Fix} \, T = \{ 0_{\mathcal{H}} \}$ (this follows from the linearity of $T;$ indeed, $(\forall z \in \mathcal{H}) ~~ T 0_{\mathcal{H}} = T (0 z) = 0 T z = 0_{\mathcal{H}}$ ). Thus, $x \in \textrm{Fix} \, T \Rightarrow \| T \| = 1$ or $\textrm{Fix} \, T = \{ 0_{\mathcal{H}} \}.$ Similarly, since $\| T \| = \| T^{*} \|,$ $x \in \textrm{Fix} \, T^{*} \Rightarrow \| T^{*} \| = 1$ or $\textrm{Fix} \, T^{*} = \{ 0_{\mathcal{H}} \}.$ $\textbf{Issue(s)}$ By the above logic, I have only proved the following: either $\textrm{Fix} \, T = \textrm{Fix} \, T^{*} = \{ 0_{\mathcal{H}} \}$ or $\| T \| = \| T^{*} \| = 1.$ I am having trouble resolving the latter consequence ( $\| T \| = \| T^{*} \| = 1$ ), as the former is supposed to be the only true possibility. Any help is appreciated.","Let be a real Hilbert space with induced norm and let Additionally, let be 1-Lipschitzian, i.e., Show that where is the adjoint of (i.e., is the unique operator that satisfies for every and in ) and : designates the zero element in Since is 1-Lipschitzian, one can show (which I have already done) that (in fact, this is an equivalent characterization in this particular context). Now, take Then Hence, or, equivalently, Therefore, either or If then and consequently, (this follows from the linearity of indeed, ). Thus, or Similarly, since or By the above logic, I have only proved the following: either or I am having trouble resolving the latter consequence ( ), as the former is supposed to be the only true possibility. Any help is appreciated.","\textbf{Question} (\mathcal{H}, \langle \cdot \, | \, \cdot \rangle) \|\cdot\| = \sqrt{\langle \cdot \, | \, \cdot \rangle} \mathscr{B}(\mathcal{H},\mathcal{H}) \equiv \mathscr{B}(\mathcal{H}) = \{ T : \mathcal{H} \rightarrow \mathcal{H} \, | \, T ~\textrm{is linear and continuous} \}. T \in \mathscr{B}(\mathcal{H}) (\forall x \in \mathcal{H})(\forall y \in \mathcal{H}) ~~ \| T x - T y \| \leq \| x - y \|. \textrm{Fix} \, T = \textrm{Fix} \, T^{*}, T^{*} T T^{*} \in \mathscr{B}(\mathcal{H}) \langle T x \, | \, y \rangle = \langle x \, | \, T^{*} y \rangle x y \mathcal{H} \textrm{Fix} \, T = \{ x \in \mathcal{H} \, | \, T x = x \}. \textit{Remark} 0_{\mathcal{H}} \mathcal{H}. \textbf{Incomplete Solution Attempt} T \| T \| \leq 1 x \in \textrm{Fix} \, T.  \| x \| = \|T x\| \leq \| T \| \| x \| \leq \| x \|.  \| T \| \| x \| = \| x \|, (\| T \| - 1) \| x \| = 0. \| T \| = 1 \| x \| = 0. \| x \| = 0, x = 0_{\mathcal{H}} \textrm{Fix} \, T = \{ 0_{\mathcal{H}} \} T; (\forall z \in \mathcal{H}) ~~ T 0_{\mathcal{H}} = T (0 z) = 0 T z = 0_{\mathcal{H}} x \in \textrm{Fix} \, T \Rightarrow \| T \| = 1 \textrm{Fix} \, T = \{ 0_{\mathcal{H}} \}. \| T \| = \| T^{*} \|, x \in \textrm{Fix} \, T^{*} \Rightarrow \| T^{*} \| = 1 \textrm{Fix} \, T^{*} = \{ 0_{\mathcal{H}} \}. \textbf{Issue(s)} \textrm{Fix} \, T = \textrm{Fix} \, T^{*} = \{ 0_{\mathcal{H}} \} \| T \| = \| T^{*} \| = 1. \| T \| = \| T^{*} \| = 1","['functional-analysis', 'operator-theory', 'lipschitz-functions', 'adjoint-operators', 'fixed-points']"
29,Folland Real Analysis: Theorem 2.47,Folland Real Analysis: Theorem 2.47,,"I am trying to understand this theorem but I have problems with some parts of the proof: 2.47 Theorem. Suppose that $\Omega$ is an open set in $\mathbb{R}^{n}$ and $G:\Omega\to\mathbb{R}^{n}$ is a $C^1$ diffeomorphism. a. If $f$ is a Lebesgue measurable function on $G(\Omega)$ , then $f\circ G$ is Lebesgue measurable on $\Omega$ . If $f\geq 0$ or $f\in L^1(G(\Omega),m)$ , then $$\int_{G(\Omega)} f(x) d x=\int_{\Omega} f \circ G(x)\left|\operatorname{det} D_x G\right| d x .$$ b. If $E\subsetΩ$ and $E \in \mathcal{L}^n$ , then $G(E) \in \mathcal{L}^n$ and $m(G(E))=\int_E\left|\operatorname{det} D_x G\right| d x$ . Proof. It suffices to consider Borel measurable functions and sets. Since $G$ and $G^{−1}$ are both continuous, there are no measurability problems in this case, and the general case follows as in the proof of Theorem 2.42. A bit of notation: For $x∈\mathbb{R^n}$ and $T=(T_{ij})∈GL(n,\mathbb{R})$ , we set $$\|x\|=\max _{1 \leq j \leq n}\left|x_j\right|, \quad\|T\|=\max _{1 \leq i \leq n} \sum_{j=1}^n\left|T_{i j}\right|$$ We then have $\|T x\| \leq\|T\|\|x\|$ , and $\{x:\|x-a\| \leq h\}$ is the cube of side length 2h centered at a. Let $Q$ be a cube in $Ω$ , say $Q=\{x:\|x-a\| \leq h\}$ . By the mean value theorem, $g_j(x)-g_j(a)=\sum_j\left(x_j-a_j\right)\left(\partial g_j / \partial x_j\right)(y)$ for some $y$ on the line segment joning $x$ and $a$ , so that for $x \in Q,\|G(x)-G(a)\| \leq h\left(\sup _{y \in Q}\left\|D_y G\right\|\right)$ . In other words, $G(Q)$ is contained in a cube of side length $\sup _{y \in Q}\left\|D_y G\right\|$ times that of $Q$ , so that by Theorem 2.44, $m(G(Q)) \leq\color{red}{\left(\sup _{y \in Q}\left\|D_y G\right\|\right)^n} m(Q)$ . If $T \in G L(n, \mathbb{R})$ , we can apply this formula with $G$ replaced by $T^{−1}\circ G$ together with Theorem 2.44 to obtain \begin{aligned} m(G(Q)) &=|\operatorname{det} T| m\left(T^{-1}(G(Q))\right) \\ & \leq|\operatorname{det} T|\left(\sup _{y \in Q}\left\|T^{-1} D_y G\right\|\right)^n m(Q)\hspace{1cm}(2.48) \end{aligned} Since $D_yG$ is continuous in $y$ , for any $\varepsilon>0$ we can choose $\delta>0$ so that $\color{red}{\|(D_zG)^{-1}D_yG\|^n\leq 1+\varepsilon}$ if $y,z\in Q$ and $\|y-z\|\leq\delta$ . Let us now subdivide $Q$ into subcubes $Q_1, ... ,Q_N$ whose interiors are disjoint, whose side lengths are at most $\delta$ , and whose centers are $x_1, . . . ,x_N$ . Applying (2.48) with $Q$ replaced by $Q_j$ and with $T = D_{x_j}G$ , we obtain \begin{aligned} m(G(Q)) &=\sum_1^N m(G(Q_j))\\ &\leq \sum_1^N |\operatorname{det} D_{x_j}G| \left(\sup _{y \in Q}\left\|(D_{x_j}G)^{-1} D_y G\right\|\right)^n m(Q_j) \\ & \leq(1+\varepsilon)\sum_1^N |\operatorname{det} D_{x_j}G| m(Q_j) \end{aligned} This are my questions: Where did that supreme come from and why is it raised to $n$ ? I know that by $D_yG$ continuity, for any $\varepsilon>0$ I can choose $\delta>0$ such that $\|(D_zG)^{-1}D_yG\|\leq 1+\varepsilon$ , and I also know that in the proof $\|(D_zG)^{-1}D_yG\|$ it is raised to $n$ so that in the last inequality $1+\varepsilon$ is not raised to $n$ , but why can I claim that $\|(D_zG)^{-1}D_yG\|^n$ is bounded by $1+\varepsilon$ ?","I am trying to understand this theorem but I have problems with some parts of the proof: 2.47 Theorem. Suppose that is an open set in and is a diffeomorphism. a. If is a Lebesgue measurable function on , then is Lebesgue measurable on . If or , then b. If and , then and . Proof. It suffices to consider Borel measurable functions and sets. Since and are both continuous, there are no measurability problems in this case, and the general case follows as in the proof of Theorem 2.42. A bit of notation: For and , we set We then have , and is the cube of side length 2h centered at a. Let be a cube in , say . By the mean value theorem, for some on the line segment joning and , so that for . In other words, is contained in a cube of side length times that of , so that by Theorem 2.44, . If , we can apply this formula with replaced by together with Theorem 2.44 to obtain Since is continuous in , for any we can choose so that if and . Let us now subdivide into subcubes whose interiors are disjoint, whose side lengths are at most , and whose centers are . Applying (2.48) with replaced by and with , we obtain This are my questions: Where did that supreme come from and why is it raised to ? I know that by continuity, for any I can choose such that , and I also know that in the proof it is raised to so that in the last inequality is not raised to , but why can I claim that is bounded by ?","\Omega \mathbb{R}^{n} G:\Omega\to\mathbb{R}^{n} C^1 f G(\Omega) f\circ G \Omega f\geq 0 f\in L^1(G(\Omega),m) \int_{G(\Omega)} f(x) d x=\int_{\Omega} f \circ G(x)\left|\operatorname{det} D_x G\right| d x . E\subsetΩ E \in \mathcal{L}^n G(E) \in \mathcal{L}^n m(G(E))=\int_E\left|\operatorname{det} D_x G\right| d x G G^{−1} x∈\mathbb{R^n} T=(T_{ij})∈GL(n,\mathbb{R}) \|x\|=\max _{1 \leq j \leq n}\left|x_j\right|, \quad\|T\|=\max _{1 \leq i \leq n} \sum_{j=1}^n\left|T_{i j}\right| \|T x\| \leq\|T\|\|x\| \{x:\|x-a\| \leq h\} Q Ω Q=\{x:\|x-a\| \leq h\} g_j(x)-g_j(a)=\sum_j\left(x_j-a_j\right)\left(\partial g_j / \partial x_j\right)(y) y x a x \in Q,\|G(x)-G(a)\| \leq h\left(\sup _{y \in Q}\left\|D_y G\right\|\right) G(Q) \sup _{y \in Q}\left\|D_y G\right\| Q m(G(Q)) \leq\color{red}{\left(\sup _{y \in Q}\left\|D_y G\right\|\right)^n} m(Q) T \in G L(n, \mathbb{R}) G T^{−1}\circ G \begin{aligned}
m(G(Q)) &=|\operatorname{det} T| m\left(T^{-1}(G(Q))\right) \\
& \leq|\operatorname{det} T|\left(\sup _{y \in Q}\left\|T^{-1} D_y G\right\|\right)^n m(Q)\hspace{1cm}(2.48)
\end{aligned} D_yG y \varepsilon>0 \delta>0 \color{red}{\|(D_zG)^{-1}D_yG\|^n\leq 1+\varepsilon} y,z\in Q \|y-z\|\leq\delta Q Q_1, ... ,Q_N \delta x_1, . . . ,x_N Q Q_j T = D_{x_j}G \begin{aligned}
m(G(Q)) &=\sum_1^N m(G(Q_j))\\
&\leq \sum_1^N |\operatorname{det} D_{x_j}G| \left(\sup _{y \in Q}\left\|(D_{x_j}G)^{-1} D_y G\right\|\right)^n m(Q_j) \\
& \leq(1+\varepsilon)\sum_1^N |\operatorname{det} D_{x_j}G| m(Q_j)
\end{aligned} n D_yG \varepsilon>0 \delta>0 \|(D_zG)^{-1}D_yG\|\leq 1+\varepsilon \|(D_zG)^{-1}D_yG\| n 1+\varepsilon n \|(D_zG)^{-1}D_yG\|^n 1+\varepsilon","['real-analysis', 'functional-analysis', 'analysis', 'measure-theory', 'multivariable-calculus']"
30,Showing that $M_n(\mathbb{C})$ is a unital C*-algebra,Showing that  is a unital C*-algebra,M_n(\mathbb{C}),"I am trying to show that the set of $n \times n$ complex matrices $M_n(\mathbb{C})$ is a unital C*-algebra. Showing that it is a unital *-algebra is no problem, but I am struggling to show that $$ \| A^*A \| = \| A \|^2. $$ I am using the norm on $M_n(\mathbb{C})$ defined by the inner product $$ \langle A, B \rangle = \operatorname{Tr}(A^*B) $$ for all $A, B \in M_n(\mathbb{C})$ . That is, $$ \|A \| = \sqrt{\langle A,A \rangle} = \sqrt{\operatorname{Tr}(A^*A)}. $$ Then $$ \|A^*A\| = \sqrt{\operatorname{Tr}([A^*A]^*A^*A)} = \sqrt{\operatorname{Tr}(A^*AA^*A)}. $$ But $$ \|A\|^2 = \operatorname{Tr}(A^*A) = \sqrt{\operatorname{Tr}(A^*A)\operatorname{Tr}(A^*A)}.$$ So I need to show that $$\operatorname{Tr}(A^*A A^*A) = \operatorname{Tr}(A^*A)\operatorname{Tr}(A^*A).$$ I am aware of the trace property $$\operatorname{Tr}(A \otimes B) = \operatorname{Tr}(A)\operatorname{Tr}(B).$$ But is $\operatorname{Tr}(A^*A A^*A) = \operatorname{Tr}(A^*A \otimes A^*A)$ ? The Kronecker product gives $A^*A \otimes A^*A$ as an $n^2 \times n^2$ matrix, whereas $A^*A A^*A$ is an $n \times n$ matrix.","I am trying to show that the set of complex matrices is a unital C*-algebra. Showing that it is a unital *-algebra is no problem, but I am struggling to show that I am using the norm on defined by the inner product for all . That is, Then But So I need to show that I am aware of the trace property But is ? The Kronecker product gives as an matrix, whereas is an matrix.","n \times n M_n(\mathbb{C})  \| A^*A \| = \| A \|^2.  M_n(\mathbb{C})  \langle A, B \rangle = \operatorname{Tr}(A^*B)  A, B \in M_n(\mathbb{C})  \|A \| = \sqrt{\langle A,A \rangle} = \sqrt{\operatorname{Tr}(A^*A)}.   \|A^*A\| = \sqrt{\operatorname{Tr}([A^*A]^*A^*A)} = \sqrt{\operatorname{Tr}(A^*AA^*A)}.   \|A\|^2 = \operatorname{Tr}(A^*A) = \sqrt{\operatorname{Tr}(A^*A)\operatorname{Tr}(A^*A)}. \operatorname{Tr}(A^*A A^*A) = \operatorname{Tr}(A^*A)\operatorname{Tr}(A^*A). \operatorname{Tr}(A \otimes B) = \operatorname{Tr}(A)\operatorname{Tr}(B). \operatorname{Tr}(A^*A A^*A) = \operatorname{Tr}(A^*A \otimes A^*A) A^*A \otimes A^*A n^2 \times n^2 A^*A A^*A n \times n","['functional-analysis', 'operator-algebras', 'c-star-algebras']"
31,Proving (directly) the closedness of the closed ball $B_1(0)$ in a finite dimensional normed space.,Proving (directly) the closedness of the closed ball  in a finite dimensional normed space.,B_1(0),"Context. Let $X = (X,\|\cdot\|)$ be a finite dimensional normed space. I am trying to show that the unitary closed ball of $X$ ( $B_1(0)$ ) is, indeed, closed with a direct proof. Attempt. By definition, $$ B_1(0) = \{x \in X \colon \|x\| \leqslant 1\}. $$ We say $B_1(0)$ is closed if it contains all of its limits points, i.e., if $\overline{B_1(0)} \subset B_1(0)$ . Thus, let $x \in \overline{B_1(0)}$ be an arbitrary element. Then, there exists a convergent sequence $(x_k)_{k \in \Bbb N}$ such that $x_k$ converges to $x$ . By definition of convergent sequence, $$ \forall \epsilon > 0, \exists N = N(\epsilon) \colon \forall n \in \Bbb N, n > N \Rightarrow \| x_n-x\| < \epsilon. $$ Now, we just see that $$ \|x\| = \|(x-x_n)+x_n \| = \|x_n - (x_n-x) \| \geqslant |\,\|x_n\| - \|x_n-x\|\,| \geqslant | \, \|x_n\| - \epsilon \, |$$ But I don't know how to proceed from here... Is this aproach correct?","Context. Let be a finite dimensional normed space. I am trying to show that the unitary closed ball of ( ) is, indeed, closed with a direct proof. Attempt. By definition, We say is closed if it contains all of its limits points, i.e., if . Thus, let be an arbitrary element. Then, there exists a convergent sequence such that converges to . By definition of convergent sequence, Now, we just see that But I don't know how to proceed from here... Is this aproach correct?","X = (X,\|\cdot\|) X B_1(0)  B_1(0) = \{x \in X \colon \|x\| \leqslant 1\}.  B_1(0) \overline{B_1(0)} \subset B_1(0) x \in \overline{B_1(0)} (x_k)_{k \in \Bbb N} x_k x  \forall \epsilon > 0, \exists N = N(\epsilon) \colon \forall n \in \Bbb N, n > N \Rightarrow \| x_n-x\| < \epsilon.   \|x\| = \|(x-x_n)+x_n \| = \|x_n - (x_n-x) \| \geqslant |\,\|x_n\| - \|x_n-x\|\,| \geqslant | \, \|x_n\| - \epsilon \, |","['functional-analysis', 'normed-spaces']"
32,"If $A$ is a normed space, then ball $A$ is $\sigma(A^{**},A^{*})$ is dense in ball $A^{**}$.","If  is a normed space, then ball  is  is dense in ball .","A A \sigma(A^{**},A^{*}) A^{**}","I am reading Functional Analysis by Conway. The location of that theorem is Chapter V, Prop 4.1. $\sigma(A^{**},A^{*})$ means weak star topology on $A^{**}$ . The prove is as follows: Let $B$ be the $\sigma(A^{**},A^{*})$ -closure of ball $A$ in $A^{**}$ ; clearly, $B \subseteq \text{ball}\, A^{**}$ {because ball $A^{**}$ is weak-* compact by banach Alaoglu's theorem}. If there is an $x_0^{**}$ in ball $A^{**} \text{\B}$ , then the Hahn-Banach theorem implies there is an $x^*$ in $A$ , and $\alpha$ in $\mathbb R$ , and an $\epsilon >0$ such that $$\operatorname{Re}⟨x,x^*⟩<\alpha<\alpha+\epsilon< \operatorname{Re}⟨x^*,x_0^{**}⟩$$ for all $x$ in ball $A$ . And here I am unable to understand how to use Hahn-Banach theorem. What I understood:- First of all what is the meaning of $x^{**}$ belongs to B in the topology of $A^{**}$ . Here $\sigma(A^{**},A^*)$ is the topology such that the collection of evaluation maps $${\{\hat{x^*}:A^{**} \rightarrow \mathbb{C}:\hat{x^*}(x^{**})=x^{**}(x^{*}) \}}$$ are continuous.  Since $x_0^{**}$ not in B so there is no sequence $x_n$ in ball $A$ which converges to $x_0^{**}$ in $A^{**}$ with respect to $\sigma(A^{**},A^{*})$ topology i.e. for any sequence $x_n$ in $A$ there is some $x^*$ in $A^*$ such that $\hat{x^*}(\hat{x_n})$ does not converges to $x_0^{**}$ . That I am able to understand but unable to understand how to get such $x^*$ as in book.","I am reading Functional Analysis by Conway. The location of that theorem is Chapter V, Prop 4.1. means weak star topology on . The prove is as follows: Let be the -closure of ball in ; clearly, {because ball is weak-* compact by banach Alaoglu's theorem}. If there is an in ball , then the Hahn-Banach theorem implies there is an in , and in , and an such that for all in ball . And here I am unable to understand how to use Hahn-Banach theorem. What I understood:- First of all what is the meaning of belongs to B in the topology of . Here is the topology such that the collection of evaluation maps are continuous.  Since not in B so there is no sequence in ball which converges to in with respect to topology i.e. for any sequence in there is some in such that does not converges to . That I am able to understand but unable to understand how to get such as in book.","\sigma(A^{**},A^{*}) A^{**} B \sigma(A^{**},A^{*}) A A^{**} B \subseteq \text{ball}\, A^{**} A^{**} x_0^{**} A^{**} \text{\B} x^* A \alpha \mathbb R \epsilon >0 \operatorname{Re}⟨x,x^*⟩<\alpha<\alpha+\epsilon< \operatorname{Re}⟨x^*,x_0^{**}⟩ x A x^{**} A^{**} \sigma(A^{**},A^*) {\{\hat{x^*}:A^{**} \rightarrow \mathbb{C}:\hat{x^*}(x^{**})=x^{**}(x^{*}) \}} x_0^{**} x_n A x_0^{**} A^{**} \sigma(A^{**},A^{*}) x_n A x^* A^* \hat{x^*}(\hat{x_n}) x_0^{**} x^*","['real-analysis', 'functional-analysis', 'operator-theory', 'operator-algebras']"
33,Collection of all unitary operators in a Hilbert space is a closed set,Collection of all unitary operators in a Hilbert space is a closed set,,"Let $\mathcal{H}$ be a Hilbert space. $\mathcal{U(H)}$ be the set of all unitary operators on H. Then I want to show that $\mathcal{U(H)}$ is a (norm-) closed subset of the Banach space $\mathcal{L(H)}$ , the space of all bounded Linear operators on H. I have tried taking a sequence of unitary operators on $\mathcal{U(H)}$ , but I couldn't conclude. Can somebody please guide me?","Let be a Hilbert space. be the set of all unitary operators on H. Then I want to show that is a (norm-) closed subset of the Banach space , the space of all bounded Linear operators on H. I have tried taking a sequence of unitary operators on , but I couldn't conclude. Can somebody please guide me?",\mathcal{H} \mathcal{U(H)} \mathcal{U(H)} \mathcal{L(H)} \mathcal{U(H)},"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces', 'inner-products']"
34,Does uniform convergence imply Hölder convergence?,Does uniform convergence imply Hölder convergence?,,"Let $\alpha\in(0,1)$ and define the $\alpha$ -Hölder norm of a function $f : [0,1]\to\mathbb{R}$ by $$ \lVert f\rVert_\alpha:=|f(0)| + \sup_{0\le s<t\le 1}\frac{|f(t)-f(s)|}{|t-s|^\alpha}. $$ Let $f_n : [0,1]\to\mathbb{R}$ be a sequence of $\alpha$ -Hölder functions satisfying $\sup_n\lVert f_n\rVert_\alpha<\infty$ , and suppose $f_n\to f$ uniformly. It follows immediately that $\lVert f\rVert_\alpha<\infty$ . Does it also follow that $\lim_{n\to\infty}\lVert f_n-f\rVert_\alpha =0$ ? My intuition says no, but I am struggling to find a counterexample. If in fact the convergence in Hölder norm follows, I am curious to hear whether it also follows when the $f_n$ take values in an arbitrary Banach space.","Let and define the -Hölder norm of a function by Let be a sequence of -Hölder functions satisfying , and suppose uniformly. It follows immediately that . Does it also follow that ? My intuition says no, but I am struggling to find a counterexample. If in fact the convergence in Hölder norm follows, I am curious to hear whether it also follows when the take values in an arbitrary Banach space.","\alpha\in(0,1) \alpha f : [0,1]\to\mathbb{R} 
\lVert f\rVert_\alpha:=|f(0)| + \sup_{0\le s<t\le 1}\frac{|f(t)-f(s)|}{|t-s|^\alpha}.
 f_n : [0,1]\to\mathbb{R} \alpha \sup_n\lVert f_n\rVert_\alpha<\infty f_n\to f \lVert f\rVert_\alpha<\infty \lim_{n\to\infty}\lVert f_n-f\rVert_\alpha =0 f_n","['real-analysis', 'functional-analysis', 'banach-spaces', 'uniform-convergence', 'holder-spaces']"
35,Relationship between weak and nuclear topologies,Relationship between weak and nuclear topologies,,"Let $(X,\Vert\cdot\Vert)$ be a Banach space. Is it always true that $X$ equipped with the weak topology $\sigma(X,X')$ is a nuclear space?",Let be a Banach space. Is it always true that equipped with the weak topology is a nuclear space?,"(X,\Vert\cdot\Vert) X \sigma(X,X')","['functional-analysis', 'analysis', 'weak-topology', 'nuclear-norm']"
36,Bounded variation on $\mathbb{R}$,Bounded variation on,\mathbb{R},"We define for $v \in L^1(\mathbb{R})$ $$ Var_{\mathbb{R}}(v) := \mathrm{sup}\left \lbrace\int_{\mathbb{R}} u(x)g'(x)~\mathrm{d}x: g \in C_0^\infty(\mathbb{R}),~ \lvert g(x) \rvert \leq 1\text{ for all }x \in \mathbb{R} \right \rbrace. $$ If $u \in L^1(\mathbb{R}) \cap C^1(\mathbb{R})$ and $Var_{\mathbb{R}}(u) < \infty$ , is it true that $$ \int_{\mathbb{R}} \lvert v'(x) \rvert~\mathrm{d}x < \infty \quad ? $$ I am sure that it is, but I can not quite find a rigorous proof. I also know that this holds for bounded domains. I also know that $$ \int_{\mathbb{R}} v(x) g'(x)~\mathrm{d}x = - \int_{\mathbb{R}} v'(x) g(x)~\mathrm{d}x. $$ Maybe approximating $-\mathrm{sign}(u')$ could help, but I do not see how. Mabye Riesz Representation Theorem can be helpful... I am grateful for help or a reference. I have found some posts on SE that could not really help me. Maybe it is not even true...","We define for If and , is it true that I am sure that it is, but I can not quite find a rigorous proof. I also know that this holds for bounded domains. I also know that Maybe approximating could help, but I do not see how. Mabye Riesz Representation Theorem can be helpful... I am grateful for help or a reference. I have found some posts on SE that could not really help me. Maybe it is not even true...","v \in L^1(\mathbb{R}) 
Var_{\mathbb{R}}(v) := \mathrm{sup}\left \lbrace\int_{\mathbb{R}} u(x)g'(x)~\mathrm{d}x: g \in C_0^\infty(\mathbb{R}),~ \lvert g(x) \rvert \leq 1\text{ for all }x \in \mathbb{R} \right \rbrace.
 u \in L^1(\mathbb{R}) \cap C^1(\mathbb{R}) Var_{\mathbb{R}}(u) < \infty 
\int_{\mathbb{R}} \lvert v'(x) \rvert~\mathrm{d}x < \infty \quad ?
 
\int_{\mathbb{R}} v(x) g'(x)~\mathrm{d}x = - \int_{\mathbb{R}} v'(x) g(x)~\mathrm{d}x.
 -\mathrm{sign}(u')","['real-analysis', 'functional-analysis', 'reference-request', 'lp-spaces', 'bounded-variation']"
37,Cauchy sequences in a linear normed space form a subspace of the space of bounded sequence,Cauchy sequences in a linear normed space form a subspace of the space of bounded sequence,,"$\mathbb{X}$ is a linear normed space. The set $b(\mathbb{X})$ of sequences $(x_n)_{n\geq1}$ with values in $\mathbb{X}$ , that are bounded, and $$||(x_n)_{n\geq1}||_{*}=\sup_{n\geq 1}{||x_n||}<\infty$$ We check easily that $b(\mathbb{X})$ is a normed linear space. I want to prove that Cauchy sequences in $\mathbb{X}$ form a subspace say $b_c(\mathbb{X})$ , of $b(\mathbb{X})$ . I know that every Cauchy sequence is bounded, so $b_c(\mathbb{X})$ is a subset of $b(\mathbb{X})$ . If $x_n\in b(\mathbb{X})$ , then $x_n+y_n \in b_c(\mathbb{X})$ and $\alpha x_n \in b_c(\mathbb{X})$ . Therefore, $b_c(\mathbb{X})$ is a algebraic subspace of $b(\mathbb{X})$ . But I don't know how to prove $b_c(\mathbb{X})$ is closed.","is a linear normed space. The set of sequences with values in , that are bounded, and We check easily that is a normed linear space. I want to prove that Cauchy sequences in form a subspace say , of . I know that every Cauchy sequence is bounded, so is a subset of . If , then and . Therefore, is a algebraic subspace of . But I don't know how to prove is closed.",\mathbb{X} b(\mathbb{X}) (x_n)_{n\geq1} \mathbb{X} ||(x_n)_{n\geq1}||_{*}=\sup_{n\geq 1}{||x_n||}<\infty b(\mathbb{X}) \mathbb{X} b_c(\mathbb{X}) b(\mathbb{X}) b_c(\mathbb{X}) b(\mathbb{X}) x_n\in b(\mathbb{X}) x_n+y_n \in b_c(\mathbb{X}) \alpha x_n \in b_c(\mathbb{X}) b_c(\mathbb{X}) b(\mathbb{X}) b_c(\mathbb{X}),"['real-analysis', 'functional-analysis', 'cauchy-sequences']"
38,Alternative Proofs: Closed proper subspace of Hilbert space has non-empty orthogonal complement,Alternative Proofs: Closed proper subspace of Hilbert space has non-empty orthogonal complement,,"Let $(H,\langle \cdot, \cdot \rangle)$ be a Hilbert space. I am asking for people to present any short/basic/fundamental proofs they know of the following theorem. Theorem 1: Let $V \subseteq H$ be a closed, proper vector subspace of $H$ . Then $V^\perp$ contains a non-zero vector. Theorem 1 follows pretty easily as a corollary of either of the following theorems. Theorem 2: A vector subspace $U$ of $H$ is dense if and only if $U^\perp$ is trivial. Notes on Theorem 2: The proof may be found here , requiring many pages of prior results. These results include $U^\perp = (\overline{U})^\perp$ and $(U^\perp)^\perp = \overline{U}$ for vector subspaces $U$ of $H$ , which in turn require the ""Hilbert projection theorem"" and the continuity of the inner product. Theorem 3: $H = U \oplus U^\perp$ for any closed vector subspace $U$ of $H$ . Notes on Theorem 3: A proof of this may be found here . I believe this proof requires less machinery than the proof of Theorem 2. In particular, only the construction of the orthogonal projection and some basic properties of the projection are required. Allow me to explain my thoughts a bit further. Theorem 2 and 3 are definitely not long proofs which make use of important, fundamental facts about orthogonality in Hilbert space. However, Theorem 2 and 3 seem to be much stronger results than Theorem 1. I have a gut feeling that Theorem 1 may be proven without having to resort to the ""machinery"" required for Theorem 2 or 3 (if you could really call it machinery). I guess another way to put it is that I believe there should be much more basic proofs of Theorem 1. However, I have not been able to make progress on such a proof myself. If I were to guess, a proof by contradiction making clever use of the continuity of the inner product might work. But, again, I've had no such success. Please feel free to drop your proof approaches below or any reasoning as to why you think Theorem 2 or 3 are the shortest / most fundamental methods. I hope this post allows for a better understanding for the true difficulty or simplicity of Theorem 1. So, although this is not strictly what I am looking for, also feel free to drop any super sleek proofs of Theorem 1 that use really heavy machinery ahaha Maybe such proofs will enlighten why Theorem 1 cannot be proven in a more fundamental manner. Thanks!","Let be a Hilbert space. I am asking for people to present any short/basic/fundamental proofs they know of the following theorem. Theorem 1: Let be a closed, proper vector subspace of . Then contains a non-zero vector. Theorem 1 follows pretty easily as a corollary of either of the following theorems. Theorem 2: A vector subspace of is dense if and only if is trivial. Notes on Theorem 2: The proof may be found here , requiring many pages of prior results. These results include and for vector subspaces of , which in turn require the ""Hilbert projection theorem"" and the continuity of the inner product. Theorem 3: for any closed vector subspace of . Notes on Theorem 3: A proof of this may be found here . I believe this proof requires less machinery than the proof of Theorem 2. In particular, only the construction of the orthogonal projection and some basic properties of the projection are required. Allow me to explain my thoughts a bit further. Theorem 2 and 3 are definitely not long proofs which make use of important, fundamental facts about orthogonality in Hilbert space. However, Theorem 2 and 3 seem to be much stronger results than Theorem 1. I have a gut feeling that Theorem 1 may be proven without having to resort to the ""machinery"" required for Theorem 2 or 3 (if you could really call it machinery). I guess another way to put it is that I believe there should be much more basic proofs of Theorem 1. However, I have not been able to make progress on such a proof myself. If I were to guess, a proof by contradiction making clever use of the continuity of the inner product might work. But, again, I've had no such success. Please feel free to drop your proof approaches below or any reasoning as to why you think Theorem 2 or 3 are the shortest / most fundamental methods. I hope this post allows for a better understanding for the true difficulty or simplicity of Theorem 1. So, although this is not strictly what I am looking for, also feel free to drop any super sleek proofs of Theorem 1 that use really heavy machinery ahaha Maybe such proofs will enlighten why Theorem 1 cannot be proven in a more fundamental manner. Thanks!","(H,\langle \cdot, \cdot \rangle) V \subseteq H H V^\perp U H U^\perp U^\perp = (\overline{U})^\perp (U^\perp)^\perp = \overline{U} U H H = U \oplus U^\perp U H","['functional-analysis', 'hilbert-spaces', 'alternative-proof', 'orthogonality']"
39,Pure states in the proof of the Gelfand-Naimark theorem,Pure states in the proof of the Gelfand-Naimark theorem,,"I'm working through the original proof of the Gelfand-Naimark theorem (every abstract C* algebra is isometrically star-isomorphic to a C* subalgebra of the bounded linear operators on a Hilbert space), and I'm a bit confused on pure states. Subsequent proofs require the linear functionals used (for the GNS constructed representations for the final direct sum) to be pure states, but I'm struggling to find which part of Gelfand and Naimark's proof implies this. So my question is - what in the original proof implies the linear functionals used are pure states? I'm very fresh on pure states so I have probably missed something pretty obvious.","I'm working through the original proof of the Gelfand-Naimark theorem (every abstract C* algebra is isometrically star-isomorphic to a C* subalgebra of the bounded linear operators on a Hilbert space), and I'm a bit confused on pure states. Subsequent proofs require the linear functionals used (for the GNS constructed representations for the final direct sum) to be pure states, but I'm struggling to find which part of Gelfand and Naimark's proof implies this. So my question is - what in the original proof implies the linear functionals used are pure states? I'm very fresh on pure states so I have probably missed something pretty obvious.",,"['functional-analysis', 'c-star-algebras', 'banach-algebras']"
40,Strong Convergence of Resolvents,Strong Convergence of Resolvents,,"Let $T$ be an operator on a Banach space $X$ . Let $\lambda \in \mathbb C$ and let $(\lambda_n)_{n \in \mathbb N}$ be a sequence in $\rho(T)$ . The following result is well known: If $(\lambda - \lambda_n)R(\lambda_n, T) \to 0$ with respect to the operator norm, then $\lambda \in \rho(T)$ . However, I asked myself whether $(\lambda - \lambda_n)R(\lambda_n, T) x \to 0$ for all $x \in X$ is enough to deduce that $\lambda \in \rho(T)$ . In this case, one knows that $\sup_{n \in \mathbb N} \lVert (\lambda - \lambda_n)R(\lambda_n, T) \rVert < \infty$ by the uniform boundedness principle. Hence, there is $c > 0$ such that $$\frac{\lvert \lambda - \lambda_n \rvert}{\operatorname{dist}(\lambda_n, \sigma(T))}  \leq \lVert (\lambda - \lambda_n)R(\lambda_n, T) \rVert \leq c < \infty $$ but that does not seems to be enough to deduce that $\lambda \in \rho(T)$ . Maybe it is wrong but then I would like to now a counter example.","Let be an operator on a Banach space . Let and let be a sequence in . The following result is well known: If with respect to the operator norm, then . However, I asked myself whether for all is enough to deduce that . In this case, one knows that by the uniform boundedness principle. Hence, there is such that but that does not seems to be enough to deduce that . Maybe it is wrong but then I would like to now a counter example.","T X \lambda \in \mathbb C (\lambda_n)_{n \in \mathbb N} \rho(T) (\lambda - \lambda_n)R(\lambda_n, T) \to 0 \lambda \in \rho(T) (\lambda - \lambda_n)R(\lambda_n, T) x \to 0 x \in X \lambda \in \rho(T) \sup_{n \in \mathbb N} \lVert (\lambda - \lambda_n)R(\lambda_n, T) \rVert < \infty c > 0 \frac{\lvert \lambda - \lambda_n \rvert}{\operatorname{dist}(\lambda_n, \sigma(T))}  \leq \lVert (\lambda - \lambda_n)R(\lambda_n, T) \rVert \leq c < \infty  \lambda \in \rho(T)","['real-analysis', 'complex-analysis', 'functional-analysis', 'operator-theory']"
41,"Proof that $\lVert u\rVert_{L^p(M)}\leq C\lVert\Delta u\rVert_{L^p(M)}$ for each $u\in W_0^{2,p}(M)$",Proof that  for each,"\lVert u\rVert_{L^p(M)}\leq C\lVert\Delta u\rVert_{L^p(M)} u\in W_0^{2,p}(M)","Let $(M,g)$ be a compact Riemannian manifold with nontrivial boundary and $W_0^{2,p}(M)$ the elements of $W^{2,p}(M)$ that vanish on $\partial M$ . I'm trying to understand a proof that there exists a constant $C$ such that $$\lVert u\rVert_{L^p(M)}\leq C\lVert\Delta u\rVert_{L^p(M)}$$ for each $u\in W_0^{2,p}(M)$ . Here is the proof: Suppose there does not exist such a constant. Then we can find a sequence $u_i$ with $\lVert u_i\rVert_{L^p}=1$ and $\Delta u_i\to 0$ in $L^p$ . By the elliptic estimate $$\lVert u\rVert_{W^{k+2,p}}\ \leq K(\lVert Lu\rVert_{W^{k,p}}+\lVert u\rVert_{L^p})$$ (existence of the constant $K$ ), it follows that $u_i$ is uniformly bounded in $W^{2,p}$ . By the Rellich-Kondrachov compactness theorem, there exists a subsequence of $u_i$ converging to some function $u$ weakly in $W^{2,p}$ and strongly in $L^p$ . Then for any compactly supported smooth test function $\psi$ , $$\langle\Delta u,\psi\rangle=\langle u,\Delta\psi\rangle=\lim_{i\to\infty}\langle u_i,\Delta\psi\rangle=\lim_{i\to\infty}\langle\Delta u_i,\psi\rangle=0,$$ and therefore $\Delta u=0$ . By elliptic regularity, $u$ must be smooth. Since it vanishes on the boundary, the maximum principle implies that $u$ is identically zero. But this is a contradiction since we must have $\lVert u\rVert_{L^p}=1$ . I feel confused about many of its details: The uniform boundedness here seems strange to me. In my introductory analysis course, a uniform bound is a constant $M$ such that $|u_i(x)|\leq M$ for every $x$ and for every $i$ , but in the proof, it doesn't seem to work this way. I have looked up the Rellich-Kondrachov compactness theorem in my PDE book and Wikipedia, and it doesn't refer to subsequences. How could the author grab such a subsequence? Where does the equality $\langle\Delta u,\psi\rangle=\langle u,\Delta\psi\rangle$ come from? Is there an inner product on $L^p$ ? I only know $L^2$ can be equipped with an inner product, which makes it a Hilbert space. Any suggestion is welcome. Thank you.","Let be a compact Riemannian manifold with nontrivial boundary and the elements of that vanish on . I'm trying to understand a proof that there exists a constant such that for each . Here is the proof: Suppose there does not exist such a constant. Then we can find a sequence with and in . By the elliptic estimate (existence of the constant ), it follows that is uniformly bounded in . By the Rellich-Kondrachov compactness theorem, there exists a subsequence of converging to some function weakly in and strongly in . Then for any compactly supported smooth test function , and therefore . By elliptic regularity, must be smooth. Since it vanishes on the boundary, the maximum principle implies that is identically zero. But this is a contradiction since we must have . I feel confused about many of its details: The uniform boundedness here seems strange to me. In my introductory analysis course, a uniform bound is a constant such that for every and for every , but in the proof, it doesn't seem to work this way. I have looked up the Rellich-Kondrachov compactness theorem in my PDE book and Wikipedia, and it doesn't refer to subsequences. How could the author grab such a subsequence? Where does the equality come from? Is there an inner product on ? I only know can be equipped with an inner product, which makes it a Hilbert space. Any suggestion is welcome. Thank you.","(M,g) W_0^{2,p}(M) W^{2,p}(M) \partial M C \lVert u\rVert_{L^p(M)}\leq C\lVert\Delta u\rVert_{L^p(M)} u\in W_0^{2,p}(M) u_i \lVert u_i\rVert_{L^p}=1 \Delta u_i\to 0 L^p \lVert u\rVert_{W^{k+2,p}}\ \leq K(\lVert Lu\rVert_{W^{k,p}}+\lVert u\rVert_{L^p}) K u_i W^{2,p} u_i u W^{2,p} L^p \psi \langle\Delta u,\psi\rangle=\langle u,\Delta\psi\rangle=\lim_{i\to\infty}\langle u_i,\Delta\psi\rangle=\lim_{i\to\infty}\langle\Delta u_i,\psi\rangle=0, \Delta u=0 u u \lVert u\rVert_{L^p}=1 M |u_i(x)|\leq M x i \langle\Delta u,\psi\rangle=\langle u,\Delta\psi\rangle L^p L^2","['real-analysis', 'functional-analysis', 'differential-geometry', 'partial-differential-equations', 'riemannian-geometry']"
42,Are $L^p$ spaces hemicompact?,Are  spaces hemicompact?,L^p,"A topological space $X$ is said to be hemicompact if one can a find a countable family of compact subsets such that every compact subset of $X$ is contained in some set of this family. Is it true that $L^p(\mathbb T^d), p \geq 1$ is hemicompact, where $\mathbb T^d$ is the $d$ -dimensional flat torus? I feel the answer is no but I have no real evidence either way. I am interested in understanding whether $C(X;Y)$ (with the compact-open topology) is metrisable with $X= L^p$ and $Y$ some Polish space. As I understand, a necessary and sufficient condition for this is that $X$ is hemicompact.","A topological space is said to be hemicompact if one can a find a countable family of compact subsets such that every compact subset of is contained in some set of this family. Is it true that is hemicompact, where is the -dimensional flat torus? I feel the answer is no but I have no real evidence either way. I am interested in understanding whether (with the compact-open topology) is metrisable with and some Polish space. As I understand, a necessary and sufficient condition for this is that is hemicompact.","X X L^p(\mathbb T^d), p \geq 1 \mathbb T^d d C(X;Y) X= L^p Y X","['general-topology', 'functional-analysis']"
43,"Let $L_0 = (-i)^m \frac{d^m u}{dx^m}$. How can I prove, that $L_0$ is a non-negative operator?","Let . How can I prove, that  is a non-negative operator?",L_0 = (-i)^m \frac{d^m u}{dx^m} L_0,"The minimal operator $L_0 = (-i)^m \frac{d^m u}{dx^m}, \ u \in \mathcal{C}_0^{\infty} (a,b)$ for $- \infty \le a < b < \infty$ induced in $L_2 (a,b)$ by the differential form $l[u] = (-i)^m \frac{d^m u}{dx^m}$ is non-negative A self-adjoint extension $A$ of $L_0$ is given by $$Au = (-i)^m \frac{d^{2n} u}{dx^{2n}}, \ u \in dom A$$ where $dom A$ consists of all $u \in W_2^m (a,b)$ such, that $$f(a) = f' (a) = ... = f^{m-1} (a) = 0 \ if \ a > - \infty$$ and $$f(b) = f' (b) = ... = f^{m-1} (b) = 0 \ if \ b < \infty$$ My attempt We want to prove, that $\langle L_0 u, u \rangle \ge 0$ . We know, that if it has to be non-negative, then it has to be real, thus $\langle L_0 u, u \rangle = \overline{\langle L_0 u, u \rangle} = \langle L_0^* u, u \rangle$ . This again means, that $L_0 = L_0^*$ . $$\langle L_0 u, u \rangle = (-i)^m \int_a^b \frac{d^m u}{dx^m} \overline{u} dx = (-i)^m (\frac{d^{m-1}u}{dx^{m-1}} \overline{u} \ |_a^b - \int_a^b \frac{d^{m-1}u}{dx^{m-1}} \overline{u'}dx) = ... $$ Because the support of $u$ here is $(a,b)$ , this means that ultimately, we get: $$... = (-i)^m (-1)^m \int_a^b u \overline{\frac{d^m u}{dx^m}}dx = i^m \int_a^b u \overline{\frac{d^m u}{dx^m}}dx = \int_a^b u \ \cdot \  \overline{(-i)^m \frac{d^m u}{dx^m}}dx = \langle u, L_0 u \rangle$$ I proved that indeed $\langle L_0 u, u \rangle$ is real-valued. But how do I prove that it is non-negative, too? My idea would be to use integration by parts, too. But the problem here is that it's the $2n$ -th derivative, and not the $m$ -th derivative. So that's where I'm stuck","The minimal operator for induced in by the differential form is non-negative A self-adjoint extension of is given by where consists of all such, that and My attempt We want to prove, that . We know, that if it has to be non-negative, then it has to be real, thus . This again means, that . Because the support of here is , this means that ultimately, we get: I proved that indeed is real-valued. But how do I prove that it is non-negative, too? My idea would be to use integration by parts, too. But the problem here is that it's the -th derivative, and not the -th derivative. So that's where I'm stuck","L_0 = (-i)^m \frac{d^m u}{dx^m}, \ u \in \mathcal{C}_0^{\infty} (a,b) - \infty \le a < b < \infty L_2 (a,b) l[u] = (-i)^m \frac{d^m u}{dx^m} A L_0 Au = (-i)^m \frac{d^{2n} u}{dx^{2n}}, \ u \in dom A dom A u \in W_2^m (a,b) f(a) = f' (a) = ... = f^{m-1} (a) = 0 \ if \ a > - \infty f(b) = f' (b) = ... = f^{m-1} (b) = 0 \ if \ b < \infty \langle L_0 u, u \rangle \ge 0 \langle L_0 u, u \rangle = \overline{\langle L_0 u, u \rangle} = \langle L_0^* u, u \rangle L_0 = L_0^* \langle L_0 u, u \rangle = (-i)^m \int_a^b \frac{d^m u}{dx^m} \overline{u} dx = (-i)^m (\frac{d^{m-1}u}{dx^{m-1}} \overline{u} \ |_a^b - \int_a^b \frac{d^{m-1}u}{dx^{m-1}} \overline{u'}dx) = ...  u (a,b) ... = (-i)^m (-1)^m \int_a^b u \overline{\frac{d^m u}{dx^m}}dx = i^m \int_a^b u \overline{\frac{d^m u}{dx^m}}dx = \int_a^b u \ \cdot \  \overline{(-i)^m \frac{d^m u}{dx^m}}dx = \langle u, L_0 u \rangle \langle L_0 u, u \rangle 2n m","['integration', 'functional-analysis', 'operator-theory', 'inner-products']"
44,A question on two self-adjoint operators with same spectrum,A question on two self-adjoint operators with same spectrum,,"What could be an example of two self-adjoint operators $T_1,T_2\in \mathcal B(E)$ ,where $E$ is a hilbert space,such that both of them have cyclic vectors and have same spectrum but they are not unitarily equivalent? What if one of them is compact and injective? Are two operators unitarily equivalent then? I know that, $T_1$ and $T_2$ both are unitarily equivalent to some multiplication operator on $L^2(\sigma(T_i),\mu)$ . So,I was thinking in terms of multiplication operators but could not come up with an example. Any help or hint would be appreciated. Thanks in advance.","What could be an example of two self-adjoint operators ,where is a hilbert space,such that both of them have cyclic vectors and have same spectrum but they are not unitarily equivalent? What if one of them is compact and injective? Are two operators unitarily equivalent then? I know that, and both are unitarily equivalent to some multiplication operator on . So,I was thinking in terms of multiplication operators but could not come up with an example. Any help or hint would be appreciated. Thanks in advance.","T_1,T_2\in \mathcal B(E) E T_1 T_2 L^2(\sigma(T_i),\mu)","['functional-analysis', 'hilbert-spaces', 'spectral-theory', 'compact-operators', 'self-adjoint-operators']"
45,Dual of $L \log L(\mathbb{R})$,Dual of,L \log L(\mathbb{R}),"Consider the space $$L\log L(\mathbb{R})=\left \{f\in L^1(\mathbb{R}):\int \limits _\mathbb{R}|f(x)|\log ^+|f(x)|\,dx<\infty \right \}.$$ Is it known what its dual and predual spaces are? Also any reference on its properties would be great! I learnt of this space and its relationship with the Hardy-Littlewood maximal operator in Stein's paper in Studia Math, and I would like to discover further properties.","Consider the space Is it known what its dual and predual spaces are? Also any reference on its properties would be great! I learnt of this space and its relationship with the Hardy-Littlewood maximal operator in Stein's paper in Studia Math, and I would like to discover further properties.","L\log L(\mathbb{R})=\left \{f\in L^1(\mathbb{R}):\int \limits _\mathbb{R}|f(x)|\log ^+|f(x)|\,dx<\infty \right \}.","['real-analysis', 'functional-analysis', 'reference-request', 'harmonic-analysis']"
46,Why do we care whether the support of a function is compact or not?,Why do we care whether the support of a function is compact or not?,,"This is a question for self-learning. I am too confused by the text to formulate a well-defined question now. I am reading analysis of functions, and confused by the motivations of some theorems and definitions. For example, we want to prove the following result: where $\phi$ is any function $\in C^0(\Omega)$ , and Why do we care whether the support of a function is compact or not? (My thought: since the support is a closure, so it must be closed; then as long as the support is bounded, i.e. the function vanishes as $x\to\infty$ , the support is compact.) Why do we define a function $\tau_x\phi$ with $y$ as the independent variable? (My thought: both $x, y \in \Omega$ , so here we define a function with arbitrarily chosen $x$ as a parameter, and maps a point in $\phi$ 's domain $\Omega$ , to the image of $\phi$ at the difference (distance) of the point from the parameter (reference point) $x$ . $\quad$ The corollary basically says that a translated $C^k_c(\Omega)$ function is still $C^k_c(\Omega)$ , at least if the translation $x$ is near $0$ . In other words, a small perturbation does not change the property of the function. $\quad$ Nevertheless, it seems to me that any finite translation $x < \infty$ should not change the compactness of support and $k$ -th differentiability, right? )","This is a question for self-learning. I am too confused by the text to formulate a well-defined question now. I am reading analysis of functions, and confused by the motivations of some theorems and definitions. For example, we want to prove the following result: where is any function , and Why do we care whether the support of a function is compact or not? (My thought: since the support is a closure, so it must be closed; then as long as the support is bounded, i.e. the function vanishes as , the support is compact.) Why do we define a function with as the independent variable? (My thought: both , so here we define a function with arbitrarily chosen as a parameter, and maps a point in 's domain , to the image of at the difference (distance) of the point from the parameter (reference point) . The corollary basically says that a translated function is still , at least if the translation is near . In other words, a small perturbation does not change the property of the function. Nevertheless, it seems to me that any finite translation should not change the compactness of support and -th differentiability, right? )","\phi \in C^0(\Omega) x\to\infty \tau_x\phi y x, y \in \Omega x \phi \Omega \phi x \quad C^k_c(\Omega) C^k_c(\Omega) x 0 \quad x < \infty k","['real-analysis', 'functional-analysis', 'self-learning']"
47,Set of densities of spectral measures,Set of densities of spectral measures,,"Let $(X,\mathbb{A},E)$ be a spectral measure on Hilbert space $H$ and $f,g \in H$ . We can define scalar measures $\mu_{f,g}(\delta)=(E(\delta)f,g)$ and $\mu_{g}(\delta)=(E(\delta)g,g)$ . Now fix $g$ . It is clear that $\mu_{f,g}$ is absolutely continuous with respect to $\mu_{g}$ . What can we say about the set of densities $D=\displaystyle\bigg\{\frac{d\mu_{f,g}}{d\mu_{g}}\bigg\}_{f\in H}$ . My hypothesis is that $D=L^1(X,\mu_{g})$ . Inclusion $D\subset L^1(X,\mu_{g})$ is obvious. But if $\phi \in L^1(X,\mu_{g})$ is given,  how can we construct $f \in H$ s.t. $(E(\delta)f,g)=\displaystyle\int\limits_{\delta}\phi d\mu_{g}$ for every $\delta \in \mathbb{A}$ ? All my attempts failed. Any help is appreciated. Thanks in advance.","Let be a spectral measure on Hilbert space and . We can define scalar measures and . Now fix . It is clear that is absolutely continuous with respect to . What can we say about the set of densities . My hypothesis is that . Inclusion is obvious. But if is given,  how can we construct s.t. for every ? All my attempts failed. Any help is appreciated. Thanks in advance.","(X,\mathbb{A},E) H f,g \in H \mu_{f,g}(\delta)=(E(\delta)f,g) \mu_{g}(\delta)=(E(\delta)g,g) g \mu_{f,g} \mu_{g} D=\displaystyle\bigg\{\frac{d\mu_{f,g}}{d\mu_{g}}\bigg\}_{f\in H} D=L^1(X,\mu_{g}) D\subset L^1(X,\mu_{g}) \phi \in L^1(X,\mu_{g}) f \in H (E(\delta)f,g)=\displaystyle\int\limits_{\delta}\phi d\mu_{g} \delta \in \mathbb{A}","['functional-analysis', 'measure-theory', 'operator-theory']"
48,Reference for Sobolev-Hölder embedding for unbounded domains,Reference for Sobolev-Hölder embedding for unbounded domains,,"I would like to know whether the following is true and references: If $\Omega\subset\mathbb R^n$ is open (not necessarily bounded) and $k = n/p + r+\alpha$ , and $\alpha \in (0,1),  r\in \mathbb N, k\geq 0,p\geq 1$ , then there is a continuous embedding of the Sobolev space $$ W^{k,p}(\Omega)\to C^{r,\alpha}(\Omega)$$ into the space of Hölder functions. I have found in several places the case the case $k=1$ , and in other places, the case when $\Omega$ is bounded. In this generality it is stated in Wikipedia for $\Omega=\mathbb R^n$ . I am looking for a more reliable source. It is possible that $\Omega$ open is not enough, in that case I would be interested to the case when $\Omega = \mathbb R^n$ or to know what are the most general hypothesis (e.g. $\Omega$ star domain).","I would like to know whether the following is true and references: If is open (not necessarily bounded) and , and , then there is a continuous embedding of the Sobolev space into the space of Hölder functions. I have found in several places the case the case , and in other places, the case when is bounded. In this generality it is stated in Wikipedia for . I am looking for a more reliable source. It is possible that open is not enough, in that case I would be interested to the case when or to know what are the most general hypothesis (e.g. star domain).","\Omega\subset\mathbb R^n k = n/p + r+\alpha \alpha \in (0,1),  r\in \mathbb N, k\geq 0,p\geq 1  W^{k,p}(\Omega)\to C^{r,\alpha}(\Omega) k=1 \Omega \Omega=\mathbb R^n \Omega \Omega = \mathbb R^n \Omega","['real-analysis', 'functional-analysis', 'sobolev-spaces', 'holder-spaces']"
49,"Prove that $A-A = X$, where A is subset of Banach Space and dense $G_{\delta}$ set.","Prove that , where A is subset of Banach Space and dense  set.",A-A = X G_{\delta},"$X$ is Banach Space and $A\subseteq X$ . $A$ is dense $G_{\delta}$ set. We have to show that $A-A=X$ . Since $A$ is dense we can write $\bar{A}= X$ . So, it is enough to show that $A-A= \bar{A}$ . Here $A-A = \{y-z | y,z\in A\}$ . Consider $\tau$ is the induced topology by $X$ . Since $X$ is normable, then $\tau$ has a bounded convex nbd of 0. Let $V$ be a bounded, balanced, convex nbd of 0. So, $A= \cap_{r\in \mathbb{Q} } rV$ . From this I can claim that $A-A\subseteq \bar{A}$ . How to show other side? Any alternative methods also appreciated.","is Banach Space and . is dense set. We have to show that . Since is dense we can write . So, it is enough to show that . Here . Consider is the induced topology by . Since is normable, then has a bounded convex nbd of 0. Let be a bounded, balanced, convex nbd of 0. So, . From this I can claim that . How to show other side? Any alternative methods also appreciated.","X A\subseteq X A G_{\delta} A-A=X A \bar{A}= X A-A= \bar{A} A-A = \{y-z | y,z\in A\} \tau X X \tau V A= \cap_{r\in \mathbb{Q} } rV A-A\subseteq \bar{A}","['functional-analysis', 'banach-spaces', 'topological-vector-spaces']"
50,"In every non-separable incomplete inner product space, is there a maximal orthonormal set which is not an orthonormal basis?","In every non-separable incomplete inner product space, is there a maximal orthonormal set which is not an orthonormal basis?",,"Let $X$ be an inner product space. An orthonormal subset $B \subseteq X$ is called: (i) a maximal orthonormal set if there is no other orthonormal subset of $X$ that contains $B$ (ii) an orthonormaml basis if $\text{span}(B)$ is dense in $X$ Consider the following statements about $X$ . (a) $X$ is complete (b) every maximal orthonormal subset of $X$ is an orthonormal basis for $X$ Note 1. The converse of (b) (i.e., every orthonormal basis for $X$ is a maximal orthonormal subset of $X$ ) is always true and easy to prove. Note 2. The proof that (a) implies (b) is in essentially every textbook that covers Hilbert spaces. Note 3. If $X$ is separable, then (b) implies (a). See: Every incomplete inner product space has a maximal but incomplete orthonormal system Example of complete orthonormal set in an inner product space whose span is not dense Non total orthonormal set in a non Hilbert inner product space Question. If X is not separable, does (b) imply (a)?","Let be an inner product space. An orthonormal subset is called: (i) a maximal orthonormal set if there is no other orthonormal subset of that contains (ii) an orthonormaml basis if is dense in Consider the following statements about . (a) is complete (b) every maximal orthonormal subset of is an orthonormal basis for Note 1. The converse of (b) (i.e., every orthonormal basis for is a maximal orthonormal subset of ) is always true and easy to prove. Note 2. The proof that (a) implies (b) is in essentially every textbook that covers Hilbert spaces. Note 3. If is separable, then (b) implies (a). See: Every incomplete inner product space has a maximal but incomplete orthonormal system Example of complete orthonormal set in an inner product space whose span is not dense Non total orthonormal set in a non Hilbert inner product space Question. If X is not separable, does (b) imply (a)?",X B \subseteq X X B \text{span}(B) X X X X X X X X,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
51,Non Self Adjoint ideal in C(D)?,Non Self Adjoint ideal in C(D)?,,"I'm currently working on a problem that's asking me to give an example of a non self adjoint ideal of $C(D) = \{f: D \longrightarrow \mathbb{C} \: | \: \text{$f$ is continuous}\}$ with $||\cdot||_{\infty}$ , and $D = \{z \in \mathbb{C} \: |\: |z| \leq 1\}$ . So far I've been trying to mess with holomorphicity, integration, compact supports, and  noninvertible functions. My issue is that I keep yielding either a vector subspace which isn't self adjoint but not an ideal (like the collection of all holomorphic functions), or I get an ideal thats self adjoint (functions with compact support, functions whose integral over $D$ is $0$ , maximal ideals of the form $M_y=\{f \in C(D) \: | \: f(y)=0\}$ , etc).  I know that whatever ideal I choose, it can't be closed ofcourse. I would be very appreciative of a $\textbf{small hint that points me in the right direction, not a full answer}$ !","I'm currently working on a problem that's asking me to give an example of a non self adjoint ideal of with , and . So far I've been trying to mess with holomorphicity, integration, compact supports, and  noninvertible functions. My issue is that I keep yielding either a vector subspace which isn't self adjoint but not an ideal (like the collection of all holomorphic functions), or I get an ideal thats self adjoint (functions with compact support, functions whose integral over is , maximal ideals of the form , etc).  I know that whatever ideal I choose, it can't be closed ofcourse. I would be very appreciative of a !","C(D) = \{f: D \longrightarrow \mathbb{C} \: | \: \text{f is continuous}\} ||\cdot||_{\infty} D = \{z \in \mathbb{C} \: |\: |z| \leq 1\} D 0 M_y=\{f \in C(D) \: | \: f(y)=0\} \textbf{small hint that points me in the right direction, not a full answer}","['abstract-algebra', 'complex-analysis', 'functional-analysis', 'operator-theory', 'c-star-algebras']"
52,Contraction Mapping and Fixed Point with two different distance metrics,Contraction Mapping and Fixed Point with two different distance metrics,,"I have been looking at the fixed point theorems that use the contraction-mapping and all seem to use the same distance metric for the input and output spaces. If we have a differentiable mapping $f: X \rightarrow X$ . I was wondering if we could use different distance metrics for the input $X$ and output $X$ , say $d'$ and $d$ . If we have $d'(f(x),f(y))\le k d(x,y)$ with $0<k<1$ , would we still have a fixed point for $f$ ? Will it be unique?","I have been looking at the fixed point theorems that use the contraction-mapping and all seem to use the same distance metric for the input and output spaces. If we have a differentiable mapping . I was wondering if we could use different distance metrics for the input and output , say and . If we have with , would we still have a fixed point for ? Will it be unique?","f: X \rightarrow X X X d' d d'(f(x),f(y))\le k d(x,y) 0<k<1 f","['real-analysis', 'functional-analysis', 'fixed-points', 'contraction-operator']"
53,"Name of the functional $p \mapsto P_X[p] = X\int_X^\infty p(x)\,dx$",Name of the functional,"p \mapsto P_X[p] = X\int_X^\infty p(x)\,dx","Let $p(x): \mathbb{R} \rightarrow \mathbb{R}^+_0$ be a probability distribution with $\int_{-\infty}^\infty p(x)\,dx = 1$ . Is there a special name for the parametrized functional $$p \mapsto P_X[p] = X\int_X^\infty p(x)\,dx\ ?$$ The name of $p \mapsto I_X[p] = \int_X^\infty p(x)\,dx$ is just the definite integral of $p$ from $X$ to infinity and $p \mapsto Id_X[p] = X$ possibly doesn't have a name due to its triviality. But what about the product $X\int_X^\infty p(x)\,dx$ ? Whether there is a special name or not: Which use cases are there for this functional, e.g. in physics, economics, or statistics? I came across it when I tried to calculate the expected revenue when selling a whole stock of products for a given price $X$ per item with $p(x)$ the distribution of willingness to pay . Note the difference with the expected value $$p \mapsto \mathbb{E}[p] = \int_{-\infty}^\infty x\ p(x)\,dx,$$ which is just another functional. To show what the functional may be good for, I plotted it (blue) for a number of distributions $p(x)$ of willingness to pay (green). The maximum is at the price $X$ for which a maximal revenue can be expected. Depicted in red is the reservation price of the supplier ( willingness to accept , set to $1$ ).","Let be a probability distribution with . Is there a special name for the parametrized functional The name of is just the definite integral of from to infinity and possibly doesn't have a name due to its triviality. But what about the product ? Whether there is a special name or not: Which use cases are there for this functional, e.g. in physics, economics, or statistics? I came across it when I tried to calculate the expected revenue when selling a whole stock of products for a given price per item with the distribution of willingness to pay . Note the difference with the expected value which is just another functional. To show what the functional may be good for, I plotted it (blue) for a number of distributions of willingness to pay (green). The maximum is at the price for which a maximal revenue can be expected. Depicted in red is the reservation price of the supplier ( willingness to accept , set to ).","p(x): \mathbb{R} \rightarrow \mathbb{R}^+_0 \int_{-\infty}^\infty p(x)\,dx = 1 p \mapsto P_X[p] = X\int_X^\infty p(x)\,dx\ ? p \mapsto I_X[p] = \int_X^\infty p(x)\,dx p X p \mapsto Id_X[p] = X X\int_X^\infty p(x)\,dx X p(x) p \mapsto \mathbb{E}[p] = \int_{-\infty}^\infty x\ p(x)\,dx, p(x) X 1","['functional-analysis', 'terminology', 'expected-value', 'economics', 'applications']"
54,Spectrum of sum of bilateral shift operator and a compact operator,Spectrum of sum of bilateral shift operator and a compact operator,,"Let $T$ be the bilateral shift operator, that is: $T: \ell^2(\mathbb{Z}) \to \ell^2(\mathbb{Z})$ such that $(T(x))_k=x_{k-1}$ (where $x_{k-1}$ means the $k-1$ coordinate of the sequence. I have been able to prove that its spectrum is the unit circle (set of all $\lambda$ s with unit euclidean norm) and I am then asked to show that I can find a compact operator $K$ such that the spectrum of $T+K$ is the unit ball, i.e. the set of all complex numbers with norm not greater than 1. Previously I have been asked to prove that in general, if $T$ and $K$ are bounded and compact operators (respectively) from a Banach space $X$ to itself, then if $\lambda$ is in the spectrum of $T$ but is not an eigenvalue of finite multiplicity it follows that $\lambda$ is also in the spectrum of $T+K$ . Could someone please help me connect the dots? Thanks.","Let be the bilateral shift operator, that is: such that (where means the coordinate of the sequence. I have been able to prove that its spectrum is the unit circle (set of all s with unit euclidean norm) and I am then asked to show that I can find a compact operator such that the spectrum of is the unit ball, i.e. the set of all complex numbers with norm not greater than 1. Previously I have been asked to prove that in general, if and are bounded and compact operators (respectively) from a Banach space to itself, then if is in the spectrum of but is not an eigenvalue of finite multiplicity it follows that is also in the spectrum of . Could someone please help me connect the dots? Thanks.",T T: \ell^2(\mathbb{Z}) \to \ell^2(\mathbb{Z}) (T(x))_k=x_{k-1} x_{k-1} k-1 \lambda K T+K T K X \lambda T \lambda T+K,['functional-analysis']
55,Spectrum of sum of bounded and compact map,Spectrum of sum of bounded and compact map,,"Assume $X$ is a Banach space and that $T$ is a bounded linear map and $K$ is a compact linear map from $X$ to itself. I need to prove that that if $\lambda$ is in the spectrum of $T$ but is not an eigenvalue of finite multiplicity then $\lambda$ is in the spectrum of $T+K$ . I know some properties of the spectrum of a compact operator, but I am not sure what to say about the sum of a bounded and a compact one. For instance, for a compact operator we know that every $\lambda \neq 0$ in the spectrum has finite multiplicity and is an eigenvalue. But since the sum $T+K$ is not compact in general we can not say much about them at first sight. Also, I know that $T+K$ is Fredholm, but how could this be useful? I would appreciate any hints on the problem. Thanks!","Assume is a Banach space and that is a bounded linear map and is a compact linear map from to itself. I need to prove that that if is in the spectrum of but is not an eigenvalue of finite multiplicity then is in the spectrum of . I know some properties of the spectrum of a compact operator, but I am not sure what to say about the sum of a bounded and a compact one. For instance, for a compact operator we know that every in the spectrum has finite multiplicity and is an eigenvalue. But since the sum is not compact in general we can not say much about them at first sight. Also, I know that is Fredholm, but how could this be useful? I would appreciate any hints on the problem. Thanks!",X T K X \lambda T \lambda T+K \lambda \neq 0 T+K T+K,"['functional-analysis', 'spectral-theory', 'compact-operators']"
56,Prove the discrete spectrum of $A$ equals to the set of those complex $\lambda$ such that $\lambda I-A$ is Fredholm.,Prove the discrete spectrum of  equals to the set of those complex  such that  is Fredholm.,A \lambda \lambda I-A,"There is considerable divergence in the literature concerning the definition of the essential spectrum of a densely defined closed operator $A$ on a Banach space $X$ . I want to find a direct definition of the essential spectrum such that it is the complement of the discrete spectrum and is stable under compact perturbations. It seems to me that I have succeeded, but I still have one problem that I really what to know the proof. It seems that we always define the discrete spectrum $\sigma_{\text{d}}(A)$ of $A$ by $$\sigma_{\text{d}}(A):=\{\lambda\in\mathbb C: \lambda \text{ is an isolated eigenvalue of }\ A \text{ and has finite algebraic multiplicity}\}.\tag 1$$ Here the algebraic multiplicity of an isolated eigenvalue $\lambda$ is defined as the dimension of the range of the Riesz projection $P_\lambda$ . This is a relatively long post. I wrote almost all things that I have done relating to this topic. In the end of the post, I will write a self-contained statement of my problem. If you want to save time, you can skip the heavy body of the post. For a self-adjiont operator $A$ on a Hilbert space $X$ , we can define the essential spectrum $\sigma_{\text{ess}}(A)$ by $\sigma_{\text{ess}}(A):=\sigma(A)\setminus \sigma_{\text{d}}(A)$ . Then we can use Weyl's criterion to prove that the essential spectrum of self-adjiont operators is invariant under symmetric compact perturbations. However, when it comes to general densely defined closed operators on Banach spaces, things become complicated. Kato defined in Chapter 4 of his book Perturbation of Linear Operators that $$\sigma_{\text{ess}}(A):=\sigma(A)\setminus \{\lambda\in \mathbb C: \lambda I-A \text{ is semi-Fredholm}\}.$$ Then Theorem 5.35 in Chapter 4 proves the stability of $\sigma_{\text{ess}}(A)$ under compact perturbations. But as Therorem 5.33 implies, the relation $\sigma_{\text{ess}}(A)=\sigma(A)\setminus \sigma_{\text{d}}(A)$ is not always right. I searched for some materials and finally find out that the definition given by F.Wolf should be satisfying. He wrote: The spectrum $\sigma(A)$ of an operator $A$ can be divided into two parts: The essential spectrum $\sigma_e(A)$ consisting of the points $\lambda$ at which $\Re(\lambda I-A)$ , the range of $\lambda I-A$ is not closed and of eigenvalues of infinite multipilicity. The second part may be called the Fredholm part of $\sigma(A)$ consists beside others of $\rho(A)$ , the resolvent set of $A$ and of isolated eigenvalues of finite multiplicity. But I also find that in another paper the author rewrote Wolf's definition of essential spectrum as the subset of $\sigma(A)$ consisting those $\lambda$ such that $\lambda I-A$ is not Fredholm. These two definitions seem different at the first glance, and I wonder why they are the same. My Problem. Let $A$ be a densely defined closed operator $A$ on a Banach space $X$ and define $\sigma_\text{d}(A)$ as in (1). Prove that $$\sigma_\text{d}(A)=\{\lambda\in\sigma(A): \lambda I-A \text{ is Fredholm}\}.$$ That is to say, $\sigma_\text{d}(A)$ consists of those complex $\lambda\in\sigma(A)$ for which $\Re(\lambda I-A)$ , the range of $\lambda I-A$ , is closed, $\text{dim}\ N(\lambda I-A)$ , the geometric multiplicity of $\lambda$ , is finite, $\text{dim}\ \left(X/\Re(\lambda I-A)\right)$ , the codimension of $\Re(\lambda I-A)$ , is finite. Any hints or useful references are welcome!","There is considerable divergence in the literature concerning the definition of the essential spectrum of a densely defined closed operator on a Banach space . I want to find a direct definition of the essential spectrum such that it is the complement of the discrete spectrum and is stable under compact perturbations. It seems to me that I have succeeded, but I still have one problem that I really what to know the proof. It seems that we always define the discrete spectrum of by Here the algebraic multiplicity of an isolated eigenvalue is defined as the dimension of the range of the Riesz projection . This is a relatively long post. I wrote almost all things that I have done relating to this topic. In the end of the post, I will write a self-contained statement of my problem. If you want to save time, you can skip the heavy body of the post. For a self-adjiont operator on a Hilbert space , we can define the essential spectrum by . Then we can use Weyl's criterion to prove that the essential spectrum of self-adjiont operators is invariant under symmetric compact perturbations. However, when it comes to general densely defined closed operators on Banach spaces, things become complicated. Kato defined in Chapter 4 of his book Perturbation of Linear Operators that Then Theorem 5.35 in Chapter 4 proves the stability of under compact perturbations. But as Therorem 5.33 implies, the relation is not always right. I searched for some materials and finally find out that the definition given by F.Wolf should be satisfying. He wrote: The spectrum of an operator can be divided into two parts: The essential spectrum consisting of the points at which , the range of is not closed and of eigenvalues of infinite multipilicity. The second part may be called the Fredholm part of consists beside others of , the resolvent set of and of isolated eigenvalues of finite multiplicity. But I also find that in another paper the author rewrote Wolf's definition of essential spectrum as the subset of consisting those such that is not Fredholm. These two definitions seem different at the first glance, and I wonder why they are the same. My Problem. Let be a densely defined closed operator on a Banach space and define as in (1). Prove that That is to say, consists of those complex for which , the range of , is closed, , the geometric multiplicity of , is finite, , the codimension of , is finite. Any hints or useful references are welcome!",A X \sigma_{\text{d}}(A) A \sigma_{\text{d}}(A):=\{\lambda\in\mathbb C: \lambda \text{ is an isolated eigenvalue of }\ A \text{ and has finite algebraic multiplicity}\}.\tag 1 \lambda P_\lambda A X \sigma_{\text{ess}}(A) \sigma_{\text{ess}}(A):=\sigma(A)\setminus \sigma_{\text{d}}(A) \sigma_{\text{ess}}(A):=\sigma(A)\setminus \{\lambda\in \mathbb C: \lambda I-A \text{ is semi-Fredholm}\}. \sigma_{\text{ess}}(A) \sigma_{\text{ess}}(A)=\sigma(A)\setminus \sigma_{\text{d}}(A) \sigma(A) A \sigma_e(A) \lambda \Re(\lambda I-A) \lambda I-A \sigma(A) \rho(A) A \sigma(A) \lambda \lambda I-A A A X \sigma_\text{d}(A) \sigma_\text{d}(A)=\{\lambda\in\sigma(A): \lambda I-A \text{ is Fredholm}\}. \sigma_\text{d}(A) \lambda\in\sigma(A) \Re(\lambda I-A) \lambda I-A \text{dim}\ N(\lambda I-A) \lambda \text{dim}\ \left(X/\Re(\lambda I-A)\right) \Re(\lambda I-A),"['functional-analysis', 'reference-request', 'spectral-theory', 'unbounded-operators']"
57,"Why define Sobolev spaces $W^{1,p}_0$ as completion of $C^1_c$ and not of $C^1_0$?",Why define Sobolev spaces  as completion of  and not of ?,"W^{1,p}_0 C^1_c C^1_0","Let $C^1_c(\Omega)$ be the once continuously differentiable functions with compact support, and $C^1_0(\Omega)$ once cont' diff' functions which approach zero on the boundary of $\Omega$ . I am wondering why books don't define $W^{1,p}_0$ as the completion of $C^1_0$ , and instead go in a roundabout way and prove that $C^1_0\subset W^{1,p}_0$ . I mean, when trying to prove that a classical solution which is in $C^2_0$ to some BVP is also a weak solution, it would be trivial if one would define $W^{1,p}$ as I suggested. Instead, the standard definition seems to be as the completion of $C^1_c$ , and then it takes some effort to prove that a classical solution is in $W^{1,p}_0$ . Is there something I'm missing that makes my suggested definition not good?","Let be the once continuously differentiable functions with compact support, and once cont' diff' functions which approach zero on the boundary of . I am wondering why books don't define as the completion of , and instead go in a roundabout way and prove that . I mean, when trying to prove that a classical solution which is in to some BVP is also a weak solution, it would be trivial if one would define as I suggested. Instead, the standard definition seems to be as the completion of , and then it takes some effort to prove that a classical solution is in . Is there something I'm missing that makes my suggested definition not good?","C^1_c(\Omega) C^1_0(\Omega) \Omega W^{1,p}_0 C^1_0 C^1_0\subset W^{1,p}_0 C^2_0 W^{1,p} C^1_c W^{1,p}_0","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
58,"If $pqp = p$ and $qpq=q$, is it true that $p=q?$","If  and , is it true that",pqp = p qpq=q p=q?,"Let $A$ be a unital $C^*$ -algebra and $p,q \in A$ projections in $A$ with the property $$pqp = p, \quad qpq = q.$$ I am trying to show that $p=q$ , but I don't really see why this should be the case. The obvious algebraic manipulations don't seem to work. Of course, we can WLOG assume that $A= B(H)$ . This question occurs because I'm trying to justify a step in the proof of Takesaki's first volume (chapter III, theorem 4.2, p141 below, where they deduce that $q= q_1$ from the equalities $q= qq_1q$ and $q_1 = q_1qq_1$ ).","Let be a unital -algebra and projections in with the property I am trying to show that , but I don't really see why this should be the case. The obvious algebraic manipulations don't seem to work. Of course, we can WLOG assume that . This question occurs because I'm trying to justify a step in the proof of Takesaki's first volume (chapter III, theorem 4.2, p141 below, where they deduce that from the equalities and ).","A C^* p,q \in A A pqp = p, \quad qpq = q. p=q A= B(H) q= q_1 q= qq_1q q_1 = q_1qq_1","['functional-analysis', 'hilbert-spaces', 'operator-algebras', 'c-star-algebras']"
59,"If $T$ is compact, then $\|T e_n \| \to 0$ for any othonormal sequence $e_n$.","If  is compact, then  for any othonormal sequence .",T \|T e_n \| \to 0 e_n,"The following question is a part of question 2.4.6 of Conway's functional analysis: Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces, and let $T: \mathcal{H} \rightarrow \mathcal{K}$ be a bounded linear operator. Show that if $T$ is a compact operator, then $$ \lim _{n \rightarrow \infty}\left\|T\left(e_{n}\right)\right\| =0. $$ This question been extensively answered on the stack exchange (for example here) : A Question on Compact Operators . One thing that is unappealing about the answers that I have seen is that they use  what seem like ""big-gun"" results about weakly convergent sequences and compact operators, which a reader of Conway's book up to this point would not have seen yet! I've devised an alternate proof that uses only basic principles below. Is it correct? If so, could any light be shed as to how it relates to the weak-convergence argument? Proof: $T$ compact implies that $\sup _{\|x\| = 1}\left\|T{x}\right\| \leq M<\infty$ for some $M$ , and that $Te_n$ has a convergent subsequence $ T e_{n_k} $ . Suppose $\left\|T e_{n_k}-h\right\| \rightarrow 0$ , but $h \neq 0$ . By restricting to a further subsequence if necessary, we may assume $\left\|T_{ {e_{n_k} }}-h\right\| \leq 2^{-k}$ . Define $$ x_{m}=\sum_{j=1}^{m} \frac{c}{j} e_{n_{j}} \text {, where } \frac{1}{c}=\left(\sum_{j=1}^{\infty} \frac{1}{j^{2}}\right)^{1/2} \text {. } $$ clearly $\left\|x_{m}\right\| \leq 1$ For all $m$ . But $$ \begin{aligned} M & \geqslant \| T_{x_m}\|=\| \sum_{j=1}^{m} \frac{c}{j} (T_{e n j}-h+h) \| \\ &=\left\|\sum_{j=1}^{m} \frac{c}{j}\left(T_{e_{n_j}}-h\right)+h \sum_{j=1}^{m} \frac{c}{j}\right\| =:\left\|A_{m}+B_{m}\right\| \end{aligned} $$ since $\|h\| \neq 0, \quad\left\|B_{m}\right\| \rightarrow \infty$ as $m \rightarrow \infty$ . By the triangle inequality $\sup_m\left\|A_{m}\right\| \leqslant \sum_{j=1}^{\infty} \frac{c}{j} 2^{-j}<\infty$ . This implies $\left\|A_{m}+B_{m}\right\| \rightarrow \infty$ as $m \rightarrow \infty$ , a contradiction. Hence $h=0$ , and every subsequence of $Te_n$ must have a further subsequence converging to 0, giving $$ \|  Te_n  \| \rightarrow 0 \quad \text { as } n \rightarrow \infty \text {. } $$","The following question is a part of question 2.4.6 of Conway's functional analysis: Let and be Hilbert spaces, and let be a bounded linear operator. Show that if is a compact operator, then This question been extensively answered on the stack exchange (for example here) : A Question on Compact Operators . One thing that is unappealing about the answers that I have seen is that they use  what seem like ""big-gun"" results about weakly convergent sequences and compact operators, which a reader of Conway's book up to this point would not have seen yet! I've devised an alternate proof that uses only basic principles below. Is it correct? If so, could any light be shed as to how it relates to the weak-convergence argument? Proof: compact implies that for some , and that has a convergent subsequence . Suppose , but . By restricting to a further subsequence if necessary, we may assume . Define clearly For all . But since as . By the triangle inequality . This implies as , a contradiction. Hence , and every subsequence of must have a further subsequence converging to 0, giving","\mathcal{H} \mathcal{K} T: \mathcal{H} \rightarrow \mathcal{K} T 
\lim _{n \rightarrow \infty}\left\|T\left(e_{n}\right)\right\| =0.
 T \sup _{\|x\| = 1}\left\|T{x}\right\| \leq M<\infty M Te_n  T e_{n_k}  \left\|T e_{n_k}-h\right\| \rightarrow 0 h \neq 0 \left\|T_{ {e_{n_k} }}-h\right\| \leq 2^{-k} 
x_{m}=\sum_{j=1}^{m} \frac{c}{j} e_{n_{j}} \text {, where } \frac{1}{c}=\left(\sum_{j=1}^{\infty} \frac{1}{j^{2}}\right)^{1/2} \text {. }
 \left\|x_{m}\right\| \leq 1 m  \begin{aligned} M & \geqslant \| T_{x_m}\|=\| \sum_{j=1}^{m} \frac{c}{j} (T_{e n j}-h+h) \| \\ &=\left\|\sum_{j=1}^{m} \frac{c}{j}\left(T_{e_{n_j}}-h\right)+h \sum_{j=1}^{m} \frac{c}{j}\right\| =:\left\|A_{m}+B_{m}\right\| \end{aligned}  \|h\| \neq 0, \quad\left\|B_{m}\right\| \rightarrow \infty m \rightarrow \infty \sup_m\left\|A_{m}\right\| \leqslant \sum_{j=1}^{\infty} \frac{c}{j} 2^{-j}<\infty \left\|A_{m}+B_{m}\right\| \rightarrow \infty m \rightarrow \infty h=0 Te_n 
\|  Te_n  \| \rightarrow 0 \quad \text { as } n \rightarrow \infty \text {. }
","['functional-analysis', 'solution-verification', 'operator-theory']"
60,How to prove T is a closable operator,How to prove T is a closable operator,,"Let $T:H\to H$ a densely defined operator, with $H$ a Hilbert space such that: $$Re(x,Tx)\geq 0, \forall x\in Dom(T) $$ I want to prove that $T$ is a closable operator, that means... that there exists a closed extension $S:H\to H$ where, $Dom(T)\subset Dom(S)$ , alternatively $T$ is closed if its graph $\Gamma(T)$ is closed in the direct sum $H⊕H$ . First of all, If I prove that $T$ is bounded (equivalent to be continuous)I would finish because every linear continuous opearator is closable, neverless I don't know if $Re(x,Tx)\geq 0$ let me what I want. All I can imagine with that hypothesis is that we're working in a half-plane, and see what happens with the adjoint of $T%$ if it's self-adjoint i.e. if $(x,Tx)=(Tx,x) \forall x\in H$ , because of Hellinger-Toeplitz theorem tell me that every symmetric operator is bounded, but symmetric implies self-adjointness... Any idea to undertand what $Re(x,Tx)\geq 0$ is telling me would be appreciated.","Let a densely defined operator, with a Hilbert space such that: I want to prove that is a closable operator, that means... that there exists a closed extension where, , alternatively is closed if its graph is closed in the direct sum . First of all, If I prove that is bounded (equivalent to be continuous)I would finish because every linear continuous opearator is closable, neverless I don't know if let me what I want. All I can imagine with that hypothesis is that we're working in a half-plane, and see what happens with the adjoint of if it's self-adjoint i.e. if , because of Hellinger-Toeplitz theorem tell me that every symmetric operator is bounded, but symmetric implies self-adjointness... Any idea to undertand what is telling me would be appreciated.","T:H\to H H Re(x,Tx)\geq 0, \forall x\in Dom(T)  T S:H\to H Dom(T)\subset Dom(S) T \Gamma(T) H⊕H T Re(x,Tx)\geq 0 T% (x,Tx)=(Tx,x) \forall x\in H Re(x,Tx)\geq 0","['functional-analysis', 'hilbert-spaces', 'adjoint-operators', 'unbounded-operators', 'closed-map']"
61,Dual of the Sobolev space,Dual of the Sobolev space,,"It is well known that for a given bounded domain $\Omega$ , the Sobolev space $W^{1,2}(\Omega)$ is a Hilbert space, which is the space given by $$ W^{1,2}(\Omega)=\{u\in L^2(\Omega):\nabla u\in L^2(\Omega)\} $$ under the norm $$ \|u\|_{W^{1,2}(\Omega)}=\|u\|_{L^2(\Omega)}+\|\nabla u\|_{L^2(\Omega)}. $$ Then by Riesz representation theorem, the dual of this space should be isomorphic to the space itself. But I have seen in PDE books, the dual of $W^{1,2}(\Omega)$ is a bigger space than $W^{1,2}(\Omega)$ , which is also not isomorphic to $W^{1,2}(\Omega)$ , if I understood correctly. I could not understand the reason. Can someone please help me to understand the concept of it? Thank you.","It is well known that for a given bounded domain , the Sobolev space is a Hilbert space, which is the space given by under the norm Then by Riesz representation theorem, the dual of this space should be isomorphic to the space itself. But I have seen in PDE books, the dual of is a bigger space than , which is also not isomorphic to , if I understood correctly. I could not understand the reason. Can someone please help me to understand the concept of it? Thank you.","\Omega W^{1,2}(\Omega) 
W^{1,2}(\Omega)=\{u\in L^2(\Omega):\nabla u\in L^2(\Omega)\}
 
\|u\|_{W^{1,2}(\Omega)}=\|u\|_{L^2(\Omega)}+\|\nabla u\|_{L^2(\Omega)}.
 W^{1,2}(\Omega) W^{1,2}(\Omega) W^{1,2}(\Omega)","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'riesz-representation-theorem']"
62,Weak * Compactness and Local Compactness,Weak * Compactness and Local Compactness,,"I'm reading through Murphy's C* Algebras, and the following theorem is presented: If $A$ is an abelian Banach algebra, then the set of characters $\Omega(A)$ is a locally compact Hausdorff space.  If $A$ is unital, then $\Omega(A)$ is compact. Proof: It's easily checked that $\Omega(A) \cup \{0\}$ is weak* closed in the weak * compact closed unit ball $S$ of $A^*$ .  Thus, $\Omega(A) \cup \{0\}$ is weak * compact implying that $\Omega(A)$ is locally compact.  If $A$ is unital, then $\Omega(A)$ is weak * closed in $S$ , and hence $\Omega(A)$ is compact. So I have two main questions here. Why does weak * compactness of $\Omega(A) \cup \{0\}$ imply local compactness of $\Omega(A)$ ? Does the term ""compact"" is the last sentence of the proof mean weak* compact?  If not, what does it mean simply by compact? I'm brand new to this subject, so any help would be really appreciated.","I'm reading through Murphy's C* Algebras, and the following theorem is presented: If is an abelian Banach algebra, then the set of characters is a locally compact Hausdorff space.  If is unital, then is compact. Proof: It's easily checked that is weak* closed in the weak * compact closed unit ball of .  Thus, is weak * compact implying that is locally compact.  If is unital, then is weak * closed in , and hence is compact. So I have two main questions here. Why does weak * compactness of imply local compactness of ? Does the term ""compact"" is the last sentence of the proof mean weak* compact?  If not, what does it mean simply by compact? I'm brand new to this subject, so any help would be really appreciated.",A \Omega(A) A \Omega(A) \Omega(A) \cup \{0\} S A^* \Omega(A) \cup \{0\} \Omega(A) A \Omega(A) S \Omega(A) \Omega(A) \cup \{0\} \Omega(A),"['general-topology', 'functional-analysis', 'operator-theory', 'operator-algebras', 'banach-algebras']"
63,$F'$ and $E'$ are isomorphic isometrically.,and  are isomorphic isometrically.,F' E',"Let $F$ be a dense subspace of the normed space $E$ . Prove that $F'$ and $E'$ are isomorphic isometrically. At first I was trying to define a function to check the isomorphism and then show that it preserves the norm. However, I couldn't think of a function that is an isometric isomorphism and preserves the norm at the same time. So, I found some sources and I saw that this function defined as $$\varphi:F'\to E' \text{ as }\varphi(f\mid_F)=f.$$ But I don't understand why this function is well defined, is an isometric isomorphism and why it's defined like that. Can someone explain it to me? I don't get why the density property is important as well. Note: $E'$ and $F'$ are the spaces of continuous linear functionals. The topological dual of $E$ and $F$ , respectively.","Let be a dense subspace of the normed space . Prove that and are isomorphic isometrically. At first I was trying to define a function to check the isomorphism and then show that it preserves the norm. However, I couldn't think of a function that is an isometric isomorphism and preserves the norm at the same time. So, I found some sources and I saw that this function defined as But I don't understand why this function is well defined, is an isometric isomorphism and why it's defined like that. Can someone explain it to me? I don't get why the density property is important as well. Note: and are the spaces of continuous linear functionals. The topological dual of and , respectively.",F E F' E' \varphi:F'\to E' \text{ as }\varphi(f\mid_F)=f. E' F' E F,"['general-topology', 'functional-analysis', 'normed-spaces', 'topological-vector-spaces', 'vector-space-isomorphism']"
64,Linear dependence of functionals (Intuition),Linear dependence of functionals (Intuition),,"I'm trying to understand why the linear dependence theorem of functionals is true at an intuitive level. I know the proof given in Brezis's functional analysis book (lemma 3.2), where the Hahn-Banach theorem is used; despite all formal details of the proof are clear to me, I feel I don't understand the intuition underground. Could you help me? Linear Dependence Theorem: Let $X$ be a vector space and let $\varphi, \varphi_1,..., \varphi_k$ be $(k+1)$ linear functionals on $X$ such that $ \bigcap_{i=1}^{k}ker(\varphi_i) \subseteq  ker(\varphi)$ . Then there exist constants $\lambda,\lambda_1,...,\lambda_k$ in $\mathbb{R}$ such that $\varphi=  \sum_{i=1}^{k}\lambda_i\varphi_i$ .","I'm trying to understand why the linear dependence theorem of functionals is true at an intuitive level. I know the proof given in Brezis's functional analysis book (lemma 3.2), where the Hahn-Banach theorem is used; despite all formal details of the proof are clear to me, I feel I don't understand the intuition underground. Could you help me? Linear Dependence Theorem: Let be a vector space and let be linear functionals on such that . Then there exist constants in such that .","X \varphi, \varphi_1,..., \varphi_k (k+1) X  \bigcap_{i=1}^{k}ker(\varphi_i) \subseteq
 ker(\varphi) \lambda,\lambda_1,...,\lambda_k \mathbb{R} \varphi=
 \sum_{i=1}^{k}\lambda_i\varphi_i",['functional-analysis']
65,Takesaki lemma 4.5,Takesaki lemma 4.5,,"Consider the following fragment from Takesaki's book ""Theory of operator algebra I"" (p82 and previous pages): The notation $\mathscr{L}_G$ means all normal operators with spectrum contained in $G$ and similarly $\mathscr{L}_{\mathbb{C}}$ denotes the normal operators. Why is the boxed equality true? The right hand side is the functional calculus on two elements. I suppose it makes intuitive sense. It reminds me of the fact that composition respects classical functional calculus but I can't justify it in this case. In any case, I also think it is relevant that $u(a), v(a) \ne 1$ . Can anybody formally justify why the boxed equality is true and resolve this technicality?","Consider the following fragment from Takesaki's book ""Theory of operator algebra I"" (p82 and previous pages): The notation means all normal operators with spectrum contained in and similarly denotes the normal operators. Why is the boxed equality true? The right hand side is the functional calculus on two elements. I suppose it makes intuitive sense. It reminds me of the fact that composition respects classical functional calculus but I can't justify it in this case. In any case, I also think it is relevant that . Can anybody formally justify why the boxed equality is true and resolve this technicality?","\mathscr{L}_G G \mathscr{L}_{\mathbb{C}} u(a), v(a) \ne 1","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
66,$\sigma(T)$ is finite $\iff \exists p\in P: p(T) = 0$,is finite,\sigma(T) \iff \exists p\in P: p(T) = 0,"The following is an old exam problem and I can not figure out how to solve it. I have been gathering some facts related to the problem, see below. Problem Let $H$ be a separable Hilbert space and let $T: H \to H$ be a compact symmetric linear map. Let $\sigma(T)$ denote the spectrum of $T$ and $P$ the set of polynomials. Prove: $\sigma(T)$ is finite $\iff \exists p\in P: p(T) = 0$ Find a separable Hilbert space $H$ and a compact linear map $C:H\to H$ with finite spectrum such that there is no $p\in P$ with $p(C) = 0$ What I know There exists an orthonormal base $\{z_1,z_2,..\}$ for $H$ , where $z_i$ are eigenvectors of $T$ corresponding to real eigenvalues. $\sigma(T) \subset \{ \lambda : |\lambda| \le |||T||\}$ For any $p \in P, \sigma(p(T)) = p(\sigma(T)) $ The eigenspace corresponding to any $\lambda \neq 0$ is finite dimensional. For $\lambda \neq 0$ , the null spaces of $T_\lambda, T_\lambda^2, T_\lambda^3, ..$ are finite dimensional. ( $T_\lambda = T - \lambda I$ )","The following is an old exam problem and I can not figure out how to solve it. I have been gathering some facts related to the problem, see below. Problem Let be a separable Hilbert space and let be a compact symmetric linear map. Let denote the spectrum of and the set of polynomials. Prove: is finite Find a separable Hilbert space and a compact linear map with finite spectrum such that there is no with What I know There exists an orthonormal base for , where are eigenvectors of corresponding to real eigenvalues. For any The eigenspace corresponding to any is finite dimensional. For , the null spaces of are finite dimensional. ( )","H T: H \to H \sigma(T) T P \sigma(T) \iff \exists p\in P: p(T) = 0 H C:H\to H p\in P p(C) = 0 \{z_1,z_2,..\} H z_i T \sigma(T) \subset \{ \lambda : |\lambda| \le |||T||\} p \in P, \sigma(p(T)) = p(\sigma(T))  \lambda \neq 0 \lambda \neq 0 T_\lambda, T_\lambda^2, T_\lambda^3, .. T_\lambda = T - \lambda I","['functional-analysis', 'eigenvalues-eigenvectors', 'hilbert-spaces']"
67,Spectral integral: reference request,Spectral integral: reference request,,"Consider the following fragment from Takesaki's book ""Theory of operator algebra I"": In this proof, we encounter expressions like $$x = \int_{-\|x\|}^{\|x\|}\lambda de(\lambda).$$ Can someone explain me how to understand this integral or give me an 'accessible' reference where I can read more about these kinds of integrals?  Is this related to the ""Borel functional calculus""?","Consider the following fragment from Takesaki's book ""Theory of operator algebra I"": In this proof, we encounter expressions like Can someone explain me how to understand this integral or give me an 'accessible' reference where I can read more about these kinds of integrals?  Is this related to the ""Borel functional calculus""?",x = \int_{-\|x\|}^{\|x\|}\lambda de(\lambda).,"['integration', 'functional-analysis', 'reference-request', 'operator-algebras', 'spectral-theory']"
68,Show that the sequence $x_N$ converges weakly and compute the weak limit,Show that the sequence  converges weakly and compute the weak limit,x_N,"Let $H$ be a Hilbert space and let $\{ e_k \}_{k = 1}^\infty $ be an orthonormal basis for $H$ . I am trying to prove that the sequence $$x_N = \frac{1}{\sqrt N}\sum_{k = 1}^N e_k $$ converges weakly and to find its weak limit. What I know so far: Proving weak convergence of $u_N$ to $u$ means proving that $\ell (u_N) \to \ell(u)$ for all functionals $\ell$ defined as $\ell :H \to \mathbb R$ . In a Hilbert space, however, linear functionals take the form $\ell(u_N) = \langle u,u_N \rangle $ for some unique $u$ that changes only when $\ell$ changes. Could someone give me any clues in proving the above, i.e., that the weak limit exist and how to find it.","Let be a Hilbert space and let be an orthonormal basis for . I am trying to prove that the sequence converges weakly and to find its weak limit. What I know so far: Proving weak convergence of to means proving that for all functionals defined as . In a Hilbert space, however, linear functionals take the form for some unique that changes only when changes. Could someone give me any clues in proving the above, i.e., that the weak limit exist and how to find it.","H \{ e_k \}_{k = 1}^\infty  H x_N = \frac{1}{\sqrt N}\sum_{k = 1}^N e_k  u_N u \ell (u_N) \to \ell(u) \ell \ell :H \to \mathbb R \ell(u_N) = \langle u,u_N \rangle  u \ell",['functional-analysis']
69,Poincaré’s inequality for a bounded open set in Brezis' book,Poincaré’s inequality for a bounded open set in Brezis' book,,"I am trying to understand the Corollary 9.19 (Poincaré’s inequality) in Functional Analysis, Sobolev Spaces and Partial Differential Equations , by Haim Brezis. Suppose that $1 \le p < \infty$ and $\Omega$ is a bounded open set. Then there exists a constant $C$ (depending on $\Omega$ and $p$ ) such that $\left\Vert u \right\Vert_{L^p(\Omega)} \le C \left\Vert \nabla u \right\Vert_{L^p(\Omega)}$ for all $u \in W^{1,p}_0(\Omega)$ . So far, I know that the zero extension $\bar u$ of $u\in W^{1,p}_0(\Omega)$ is an element in $W^{1,p}(\mathbb{R}^N)$ (which is a consequence of the preceding Proposition 9.18). Case 1: $1\le p<N$ With the help of Theorem 9.9 (Sobolev, Gagliardo, Nirenberg), $\left\Vert \bar u \right\Vert_{L^{p^*}(\mathbb{R}^N)} \le C \left\Vert \nabla \bar u \right\Vert_{L^p(\mathbb{R}^N)}$ , where $\frac{1}{p*} = \frac{1}{p} - \frac{1}{N}$ , I can show the Poincaré’s inequality due to compact support and $p<p^*$ . Case 2: $p>N$ Theorem 9.12 (Morrey) asserts $|\bar u(x) - \bar u(y)|\le C |x-y|^\alpha \left\Vert \nabla \bar u \right\Vert_{L^p(\mathbb{R}^N)} $ a.e. Take the continuous representative and still denote $\bar u$ . By translation, I may take $y = 0$ and $\bar u(y) = 0$ . Then taking p-norm (or $\infty$ -norm) yields the result. My question is how to conclude the Poincaré’s inequality when $p=N$ ?","I am trying to understand the Corollary 9.19 (Poincaré’s inequality) in Functional Analysis, Sobolev Spaces and Partial Differential Equations , by Haim Brezis. Suppose that and is a bounded open set. Then there exists a constant (depending on and ) such that for all . So far, I know that the zero extension of is an element in (which is a consequence of the preceding Proposition 9.18). Case 1: With the help of Theorem 9.9 (Sobolev, Gagliardo, Nirenberg), , where , I can show the Poincaré’s inequality due to compact support and . Case 2: Theorem 9.12 (Morrey) asserts a.e. Take the continuous representative and still denote . By translation, I may take and . Then taking p-norm (or -norm) yields the result. My question is how to conclude the Poincaré’s inequality when ?","1 \le p < \infty \Omega C \Omega p \left\Vert u \right\Vert_{L^p(\Omega)} \le C \left\Vert \nabla u \right\Vert_{L^p(\Omega)} u \in W^{1,p}_0(\Omega) \bar u u\in W^{1,p}_0(\Omega) W^{1,p}(\mathbb{R}^N) 1\le p<N \left\Vert \bar u \right\Vert_{L^{p^*}(\mathbb{R}^N)} \le C \left\Vert \nabla \bar u \right\Vert_{L^p(\mathbb{R}^N)} \frac{1}{p*} = \frac{1}{p} - \frac{1}{N} p<p^* p>N |\bar u(x) - \bar u(y)|\le C |x-y|^\alpha \left\Vert \nabla \bar u \right\Vert_{L^p(\mathbb{R}^N)}  \bar u y = 0 \bar u(y) = 0 \infty p=N","['functional-analysis', 'sobolev-spaces']"
70,Conditions for a linearly independent sequence with dense linear span to be a Schauder basis for a Banach space,Conditions for a linearly independent sequence with dense linear span to be a Schauder basis for a Banach space,,"Let $ (e_n)_{n \in \mathbb{N}} $ be a linearly independent sequence in a Banach space $X$ such that $$ X = \overline{\operatorname{span}} \{e_n : n \in \mathbb{N}\} $$ In particular, $X$ is separable. However, $(e_n)$ may not be a Schauder basis for $X$ , unless $X$ is a Hilbert space. The easiest counter-example is the sequence $ (1, x, x^2, \dots)$ in $ C(\mathbb{R}) $ . Even worse, $X$ may not have a Schauder basis at all. Questions: What are the conditions for $(e_n)$ to be a Schauder basis for $X$ ? Even if $(e_n)$ is not a Schauder basis, what are the conditions for $X$ to have a Schauder basis?","Let be a linearly independent sequence in a Banach space such that In particular, is separable. However, may not be a Schauder basis for , unless is a Hilbert space. The easiest counter-example is the sequence in . Even worse, may not have a Schauder basis at all. Questions: What are the conditions for to be a Schauder basis for ? Even if is not a Schauder basis, what are the conditions for to have a Schauder basis?"," (e_n)_{n \in \mathbb{N}}  X  X = \overline{\operatorname{span}} \{e_n : n \in \mathbb{N}\}  X (e_n) X X  (1, x, x^2, \dots)  C(\mathbb{R})  X (e_n) X (e_n) X","['real-analysis', 'functional-analysis', 'banach-spaces', 'schauder-basis']"
71,"Measurability of $\sup_{[0,1]}X(t)$ with respect to continuity",Measurability of  with respect to continuity,"\sup_{[0,1]}X(t)","Let $X\colon[0,1]\to\mathbb{R}$ be a stochastic process on some probability space $(\Omega, \mathcal{F}, P)$ . I was always told that $$ f(\omega)=\sup_{t\in[0,1]} X(t, \omega) $$ is not always a measurable function. However, if $X$ is a.s. continuous (e.g., a Brownian motion), then it is measurable. My questions are of two folds: How to explictly show that $f\colon\Omega\to\mathbb{R}$ can be non-measurable? Do we have a concrete example to show this? Why does the continuity imply the measurability? People say that if $X$ is continuos, then $\sup_{t\in[0,1]} X(t, \omega) = \sup_{t\in[0,1]\cap\mathbb{Q}} X(t, \omega)$ , but why the latter is measurable (i.e., why the sup over a countable set gives measurable $f$ )? Related questions: Is the supremum of an almost surely continuous stochastic process measurable? This is similar to my question but does not really answers my 1 and 2. $f(x,y)$, continuous in $x$. Is $\sup_{x\in A}f(x,y)$ measurable? https://mathoverflow.net/questions/102258/when-is-the-infimum-of-an-arbitrary-family-of-measurable-functions-also-measurab","Let be a stochastic process on some probability space . I was always told that is not always a measurable function. However, if is a.s. continuous (e.g., a Brownian motion), then it is measurable. My questions are of two folds: How to explictly show that can be non-measurable? Do we have a concrete example to show this? Why does the continuity imply the measurability? People say that if is continuos, then , but why the latter is measurable (i.e., why the sup over a countable set gives measurable )? Related questions: Is the supremum of an almost surely continuous stochastic process measurable? This is similar to my question but does not really answers my 1 and 2. $f(x,y)$, continuous in $x$. Is $\sup_{x\in A}f(x,y)$ measurable? https://mathoverflow.net/questions/102258/when-is-the-infimum-of-an-arbitrary-family-of-measurable-functions-also-measurab","X\colon[0,1]\to\mathbb{R} (\Omega, \mathcal{F}, P) 
f(\omega)=\sup_{t\in[0,1]} X(t, \omega)
 X f\colon\Omega\to\mathbb{R} X \sup_{t\in[0,1]} X(t, \omega) = \sup_{t\in[0,1]\cap\mathbb{Q}} X(t, \omega) f","['functional-analysis', 'probability-theory', 'measure-theory', 'stochastic-processes', 'stochastic-calculus']"
72,"$||x|| \le ||x+ry||$ for all $r \ge 0 \implies \langle j(x), y \rangle \ge 0$, where $j$ is the duality map.","for all , where  is the duality map.","||x|| \le ||x+ry|| r \ge 0 \implies \langle j(x), y \rangle \ge 0 j","Let $X$ be a real Banach space. Let $J \colon X \to 2^{X^*}$ be its (normalized)  duality map, $$ J(x) = \{ x^* \in X^* \colon \langle x^* , x \rangle =||x|| \ ||x^*||, \ || x^* ||=||x||   \} , \ x \in X.$$ Assume that $X$ is smooth, so that $J(x)= \{j(x)\}$ is a singleton. Fix $x,y \in X$ . It is known that, if $$||x|| \le ||x+ry||,  \tag 1$$ for every $r \in \mathbb R$ , then $\langle j(x),y \rangle =0$ .   What happens if we only take $r \ge0$ in $(1)$ ? I expect that $ \langle j(x),y \rangle  \ge 0$ , since that is the case for Hilbert spaces. Indeed, if $X$ is a Hilbert space with inner product $(\cdot,\cdot) $ , then $J$ is just the identity map, and $(1)$ implies that $$ r^2 ||y||^2 + 2r (x,y) \ge 0, $$ for every $r \ge 0$ .  Dividing by $r$ and then letting $r \to 0$ we obtain that $(x,y) \ge 0$ .","Let be a real Banach space. Let be its (normalized)  duality map, Assume that is smooth, so that is a singleton. Fix . It is known that, if for every , then .   What happens if we only take in ? I expect that , since that is the case for Hilbert spaces. Indeed, if is a Hilbert space with inner product , then is just the identity map, and implies that for every .  Dividing by and then letting we obtain that .","X J \colon X \to 2^{X^*}  J(x) = \{ x^* \in X^* \colon \langle x^* , x \rangle =||x|| \ ||x^*||, \ || x^* ||=||x||   \} , \ x \in X. X J(x)= \{j(x)\} x,y \in X ||x|| \le ||x+ry||,  \tag 1 r \in \mathbb R \langle j(x),y \rangle =0 r \ge0 (1)  \langle j(x),y \rangle  \ge 0 X (\cdot,\cdot)  J (1)  r^2 ||y||^2 + 2r (x,y) \ge 0,  r \ge 0 r r \to 0 (x,y) \ge 0","['functional-analysis', 'orthogonality']"
73,Weak-$*$ sequential compactness of closed ball in bidual,Weak- sequential compactness of closed ball in bidual,*,"Let $(X,\|\cdot\|)$ be a normed vector space and let $X^*,X^{**}$ denote its continuous and second continuous dual, each endowed with the usual norm. Let $B$ denote the closed unit ball of $X^{**}$ . Since $X^{**}$ is the dual of $X^*$ , from the Banach-Alaoglu theorem, it is known that $B$ is compact in the weak- $*$ topology. I want to know if $B$ is sequentially compact, or relatively sequentially compact (still in the weak- $*$ topology). I know that the Eberlein-Šmulian theorem can be helpful when dealing with weak topologies, but here we're interested in the weak- $*$ topology. I don't mind adding the assumption that $X$ is Banach. However, I don't want to add a reflexivity assumption on $X$ . I am not well-versed in functional analysis or weak topologies. Actually, my question comes from the theory of optimization of functions.","Let be a normed vector space and let denote its continuous and second continuous dual, each endowed with the usual norm. Let denote the closed unit ball of . Since is the dual of , from the Banach-Alaoglu theorem, it is known that is compact in the weak- topology. I want to know if is sequentially compact, or relatively sequentially compact (still in the weak- topology). I know that the Eberlein-Šmulian theorem can be helpful when dealing with weak topologies, but here we're interested in the weak- topology. I don't mind adding the assumption that is Banach. However, I don't want to add a reflexivity assumption on . I am not well-versed in functional analysis or weak topologies. Actually, my question comes from the theory of optimization of functions.","(X,\|\cdot\|) X^*,X^{**} B X^{**} X^{**} X^* B * B * * X X","['general-topology', 'functional-analysis', 'compactness', 'banach-spaces', 'weak-topology']"
74,Is a measureable function on a polish space an a.s. limit of continuous functions?,Is a measureable function on a polish space an a.s. limit of continuous functions?,,"Let $(E,\mathcal{E},\mathbb{P})$ be a probability space where $E$ is a polish space with Borel sigma algebra $\mathcal{E}$ and let $f:E \rightarrow \mathbb{R}$ be measurable. Can one find $(f_n) \in C(E,\mathbb{R})^\mathbb{N}$ s.t. $$ f=\lim_{n \rightarrow \infty} f_n \; \text{ a.s.} $$ holds? I asked myself this question already many times and I don't know how to use Lusin's theorem since $E$ is not locally compact.",Let be a probability space where is a polish space with Borel sigma algebra and let be measurable. Can one find s.t. holds? I asked myself this question already many times and I don't know how to use Lusin's theorem since is not locally compact.,"(E,\mathcal{E},\mathbb{P}) E \mathcal{E} f:E \rightarrow \mathbb{R} (f_n) \in C(E,\mathbb{R})^\mathbb{N} 
f=\lim_{n \rightarrow \infty} f_n \; \text{ a.s.}
 E","['functional-analysis', 'probability-theory', 'measure-theory', 'measurable-functions']"
75,Polar sets and weak star topology,Polar sets and weak star topology,,"I have to prove the following: Let X a real normed space, and I a non-empty index set. Let $ \{ x_{i}, i \in I \}$ $\subset$ X , $\{  \alpha_{i},\ i \in I \}$ a set of positive real numbers. Define $ S:= \{x^{*} \in X^{*}, ||{x^{*}}|| \leq R \ and \ |x^{*}(x_{i})| \leq \alpha_{i}, \forall i \in I \} $ . Show that $\forall \  x_{0} \in X$ , the set $ \{x^{*}(x_{0}), \ x^{*} \in S \} $ is a bounded closed interval in the real line. My claim was the following: $ \forall i \in I $ , let $ x_{i}^{\circ} = \{x^{*} \in X^{*}, \ such \ that \ |x^{*}(x_{i})| \leq 1 \}$ the polar of $x_{i}$ . Then we know that $\alpha_{i} x_{i}^{\circ} = (x_{i}/\alpha_{i})^{\circ}$ . Now we can characterize $S= B_{R}^{\star} \  \cap \ \cap_{i \in I} (x_{i}/\alpha_{i})^{\circ}$ . Thus S is $wk^{\star}$ compact because $B_{R}^{\star}$ is $wk^{\star}$ compact  (Banach-Alaoglu Theorem) and $\cap_{i \in I} (x_{i}/\alpha_{i})^{\circ} = (\cup_{i \in I} (x_{i}/\alpha_{i}))^{\circ}$ which is $wk^{\star}$ closed because polars are. Thus if we take the evaluation map $\phi_{x_{0}}:S \to \mathbb{R}$ such that $\phi_{x_{0}}(x^{*})=x^{*}(x_{0})$ , this is a continuous map from a compact set so its image must be compact, therefore it is bounded and closed. Am I missing something or it sounds good? Thanks in advance for any help! :)","I have to prove the following: Let X a real normed space, and I a non-empty index set. Let X , a set of positive real numbers. Define . Show that , the set is a bounded closed interval in the real line. My claim was the following: , let the polar of . Then we know that . Now we can characterize . Thus S is compact because is compact  (Banach-Alaoglu Theorem) and which is closed because polars are. Thus if we take the evaluation map such that , this is a continuous map from a compact set so its image must be compact, therefore it is bounded and closed. Am I missing something or it sounds good? Thanks in advance for any help! :)"," \{ x_{i}, i \in I \} \subset \{  \alpha_{i},\ i \in I \}  S:= \{x^{*} \in X^{*}, ||{x^{*}}|| \leq R \ and \ |x^{*}(x_{i})| \leq \alpha_{i}, \forall i \in I \}  \forall \  x_{0} \in X  \{x^{*}(x_{0}), \ x^{*} \in S \}   \forall i \in I   x_{i}^{\circ} = \{x^{*} \in X^{*}, \ such \ that \ |x^{*}(x_{i})| \leq 1 \} x_{i} \alpha_{i} x_{i}^{\circ} = (x_{i}/\alpha_{i})^{\circ} S= B_{R}^{\star} \  \cap \ \cap_{i \in I} (x_{i}/\alpha_{i})^{\circ} wk^{\star} B_{R}^{\star} wk^{\star} \cap_{i \in I} (x_{i}/\alpha_{i})^{\circ} = (\cup_{i \in I} (x_{i}/\alpha_{i}))^{\circ} wk^{\star} \phi_{x_{0}}:S \to \mathbb{R} \phi_{x_{0}}(x^{*})=x^{*}(x_{0})","['functional-analysis', 'weak-topology']"
76,Gateaux derivative and Frechet derivative in calculus of variation,Gateaux derivative and Frechet derivative in calculus of variation,,"Let $X$ be some Banach space, if $f \in C(U,\Bbb{R})$ a continuous real value function.We define the Gateaux derivative  exist  if for any $h\in X$ exist $df(x_0,h) \in \Bbb{R}^1$ s.t: $$|f(x_0+th)-f(x_0)-tdf(x_0,h)|= o(t)$$ For Frechet derivative $f'(x_0)$ exist if for some $\xi\in X^*$ : $$|f(x)-f(x_0)-\langle\xi,x-x_0\rangle| = o(\|x-x_0\|)$$ Denote this $\xi = f'(x_0)$ the Frechet derivative Prove the following result: If $f$ exist Gateaux derivative everywhere inside a neiborhood $V$ around $x_0$ ,for each $x\in V$ exist some $\xi(x)\in X^*$ such that $$\langle \xi(x),h\rangle = df(x,h)$$ Moreover $x\mapsto \xi(x)$ is continuous then $f$ also has Frechet derivative at $x_0$ . To check Frechet derivative exist at the point $x_0$ ,needs to find some $\xi$ satisfies the definition,it's natural to guess that $\xi(x_0)\in X^*$ it's the desired one. Choose $h = (x-x_0)/\|x-x_0\|$ then $\langle \xi(x_0),h\rangle = df(x_0,h) $ Substitute into $$|f(x)-f(x_0)-\langle\xi(x_0),x-x_0\rangle|  =\\ |f(x_0 +(x-x_0))-f(x_0)-\|x-x_0\|\langle\xi(x_0),h\rangle| \\=|f(x + \|x-x_0\|h)-f(x_0)- \|x-x_0\|df(x_0,h)|$$ As $\|x-x_0\|\to 0$ ,it goes to zero,but this gives a wrong proof,the reason is we take $x-x_0$ direction fixed ,and the convergence is not uniformly over all the directions. We need to use continuity of $\xi(x)$ to handle this problem.By definition we have for unit length $h$ , $$|df(h,x)-df(h,x_0)| = |\langle\xi(x)-\xi(x_0),h\rangle|\le \|\xi(x)-\xi(x_0)\| \to 0$$ when $\|x-x_0\|\to 0$ I have no idea how to use this condition.This condition says ""directional derivative"" is continuous in all the directions. My idea to proceed the proof is using the same trick in Rudin's mathematical analysis book p219 9.21:that construct a sequence of line segments. $$f(\mathbf{x}+\mathbf{h})-f(\mathbf{x})=\sum_{j=1}^{n}\left[f\left(\mathbf{x}+\mathbf{v}_{j}\right)-f\left(\mathbf{x}+\mathbf{v}_{j-1}\right)\right]$$ with $\mathbf{v}_{k}=h_{1} \mathbf{e}_{1}+\cdots+h_{k} \mathbf{e}_{k}$ the problem here is we lie in infinite dimension space,this trick seems not apply well in our case?","Let be some Banach space, if a continuous real value function.We define the Gateaux derivative  exist  if for any exist s.t: For Frechet derivative exist if for some : Denote this the Frechet derivative Prove the following result: If exist Gateaux derivative everywhere inside a neiborhood around ,for each exist some such that Moreover is continuous then also has Frechet derivative at . To check Frechet derivative exist at the point ,needs to find some satisfies the definition,it's natural to guess that it's the desired one. Choose then Substitute into As ,it goes to zero,but this gives a wrong proof,the reason is we take direction fixed ,and the convergence is not uniformly over all the directions. We need to use continuity of to handle this problem.By definition we have for unit length , when I have no idea how to use this condition.This condition says ""directional derivative"" is continuous in all the directions. My idea to proceed the proof is using the same trick in Rudin's mathematical analysis book p219 9.21:that construct a sequence of line segments. with the problem here is we lie in infinite dimension space,this trick seems not apply well in our case?","X f \in C(U,\Bbb{R}) h\in X df(x_0,h) \in \Bbb{R}^1 |f(x_0+th)-f(x_0)-tdf(x_0,h)|= o(t) f'(x_0) \xi\in X^* |f(x)-f(x_0)-\langle\xi,x-x_0\rangle| = o(\|x-x_0\|) \xi = f'(x_0) f V x_0 x\in V \xi(x)\in X^* \langle \xi(x),h\rangle = df(x,h) x\mapsto \xi(x) f x_0 x_0 \xi \xi(x_0)\in X^* h = (x-x_0)/\|x-x_0\| \langle \xi(x_0),h\rangle = df(x_0,h)
 |f(x)-f(x_0)-\langle\xi(x_0),x-x_0\rangle|  =\\ |f(x_0 +(x-x_0))-f(x_0)-\|x-x_0\|\langle\xi(x_0),h\rangle|
\\=|f(x + \|x-x_0\|h)-f(x_0)- \|x-x_0\|df(x_0,h)| \|x-x_0\|\to 0 x-x_0 \xi(x) h |df(h,x)-df(h,x_0)| = |\langle\xi(x)-\xi(x_0),h\rangle|\le \|\xi(x)-\xi(x_0)\| \to 0 \|x-x_0\|\to 0 f(\mathbf{x}+\mathbf{h})-f(\mathbf{x})=\sum_{j=1}^{n}\left[f\left(\mathbf{x}+\mathbf{v}_{j}\right)-f\left(\mathbf{x}+\mathbf{v}_{j-1}\right)\right] \mathbf{v}_{k}=h_{1} \mathbf{e}_{1}+\cdots+h_{k} \mathbf{e}_{k}","['real-analysis', 'functional-analysis', 'calculus-of-variations', 'frechet-derivative']"
77,"Norm of the operator $A\colon L^2[0,1] \to L^2[0,1]$, $x(t) \mapsto (t-0.5)\cdot x(t)$","Norm of the operator ,","A\colon L^2[0,1] \to L^2[0,1] x(t) \mapsto (t-0.5)\cdot x(t)","I'm trying to calculate a norm of the operator $$A\colon L^2[0,1] \to L^2[0,1],\qquad  x(t) \mapsto (t-0.5)\cdot x(t).$$ I started finding it as follows: $$\|Ax(t)\|^2 = \int_{0}^1 |(t-0.5)\cdot x(t)|^2\,dt$$ Then I've tried to apply Cauchy-Schwarz inequality, but I can't get $\int_{0}^1 |x(t)|^2\,dt$ (that would be equal to $\|x\|^2$ ) in my expression, so I can't proceed further. P.S. In addition to norm itself, I have to specify some value or sequence on which the norm is reached Please, tell me about the right way to find $\|A\|$ here","I'm trying to calculate a norm of the operator I started finding it as follows: Then I've tried to apply Cauchy-Schwarz inequality, but I can't get (that would be equal to ) in my expression, so I can't proceed further. P.S. In addition to norm itself, I have to specify some value or sequence on which the norm is reached Please, tell me about the right way to find here","A\colon L^2[0,1] \to L^2[0,1],\qquad  x(t) \mapsto (t-0.5)\cdot x(t). \|Ax(t)\|^2 = \int_{0}^1 |(t-0.5)\cdot x(t)|^2\,dt \int_{0}^1 |x(t)|^2\,dt \|x\|^2 \|A\|","['functional-analysis', 'operator-theory', 'normed-spaces']"
78,Sum of tensor products is a bounded operator,Sum of tensor products is a bounded operator,,"I came across this in a book: Let $B$ be a Banach space with Schauder basis $\{\omega_j\}$ , let $B'$ be its dual with $\{\nu_i\}$ being a corresponding biorthogonal system, i.e. $\langle \omega_j,\nu_i\rangle=\delta_{ji}$ . Then it is well-known that the sequence of operators $\{F_n\}$ defined as $$F_n=\sum\limits_{j=1}^n\omega_j \otimes \nu_j$$ is bounded. I am not seeing this. So bounded means there exist some $M>0$ such that for all $n\in\mathbb{N}$ and some $v\in B$ $$\frac{\|F_n v\|}{\|v\|}=\frac{\|\sum\limits^{n}_{j=1}(\omega_j\otimes\nu_j)(v)\|}{\|v\|}\leq M$$ Why is that bounded when I choose an infinite vector and then taking the limit $\lim\limits_{n\to\infty}F_n$ ?","I came across this in a book: Let be a Banach space with Schauder basis , let be its dual with being a corresponding biorthogonal system, i.e. . Then it is well-known that the sequence of operators defined as is bounded. I am not seeing this. So bounded means there exist some such that for all and some Why is that bounded when I choose an infinite vector and then taking the limit ?","B \{\omega_j\} B' \{\nu_i\} \langle \omega_j,\nu_i\rangle=\delta_{ji} \{F_n\} F_n=\sum\limits_{j=1}^n\omega_j \otimes \nu_j M>0 n\in\mathbb{N} v\in B \frac{\|F_n v\|}{\|v\|}=\frac{\|\sum\limits^{n}_{j=1}(\omega_j\otimes\nu_j)(v)\|}{\|v\|}\leq M \lim\limits_{n\to\infty}F_n",['functional-analysis']
79,"Prove $\{f(x_0):f\in A\}$ is closed interval for $A=\{f\in X^*:\|f\|\leq\beta,|f(x_i)|\leq\alpha_i\ \forall i\in I\}$",Prove  is closed interval for,"\{f(x_0):f\in A\} A=\{f\in X^*:\|f\|\leq\beta,|f(x_i)|\leq\alpha_i\ \forall i\in I\}","Let $X$ be a real normed space, let $\beta>0$ , and for some set $I$ , $\{x_i\}_{i\in I}\subset X,\{\alpha_i\}_{i\in I}\subset[0,\infty)$ . Then set $$A=\{f\in X^*:\|f\|\leq\beta,|f(x_i)|\leq\alpha_i\ \forall i\in I\},$$ and set $B=\{f(x_0):f\in A\}$ . I want to prove that $B$ is a closed bounded interval of the real line. Using that each $f\in A$ is norm-bounded by $\beta$ , it is easy to argue that $B$ is bounded. It is easy to show that $A$ is convex, and from there it follows that $B$ is convex. Hence, being a subset of the real line, it follows that $B$ is a bounded interval. The part I'm having troubles with is showing that $B$ is closed. It seems that $A$ is closed, and therefore weakly closed, being convex. Furthermore, we observe that $B=\phi(A)$ , where $\phi:X^{*}\to\mathbb R:f\mapsto f(x_0)$ is clearly continuous, so $\phi\in X^{**}$ . Hence $B$ is the continuous image of a weakly closed set. I don't know if this brings us any further. Other approaches I tried didn't seem helpful. Any help on the ` closed' part is much appreciated.","Let be a real normed space, let , and for some set , . Then set and set . I want to prove that is a closed bounded interval of the real line. Using that each is norm-bounded by , it is easy to argue that is bounded. It is easy to show that is convex, and from there it follows that is convex. Hence, being a subset of the real line, it follows that is a bounded interval. The part I'm having troubles with is showing that is closed. It seems that is closed, and therefore weakly closed, being convex. Furthermore, we observe that , where is clearly continuous, so . Hence is the continuous image of a weakly closed set. I don't know if this brings us any further. Other approaches I tried didn't seem helpful. Any help on the closed' part is much appreciated.","X \beta>0 I \{x_i\}_{i\in I}\subset X,\{\alpha_i\}_{i\in I}\subset[0,\infty) A=\{f\in X^*:\|f\|\leq\beta,|f(x_i)|\leq\alpha_i\ \forall i\in I\}, B=\{f(x_0):f\in A\} B f\in A \beta B A B B B A B=\phi(A) \phi:X^{*}\to\mathbb R:f\mapsto f(x_0) \phi\in X^{**} B `","['real-analysis', 'functional-analysis', 'weak-topology']"
80,Does weak convergence imply pointwise convergence? [duplicate],Does weak convergence imply pointwise convergence? [duplicate],,"This question already has an answer here : Does weak convergence in $L^2$ implies convergence almost everywhere along subsequence? (1 answer) Closed 2 years ago . Let $f_n,f:\mathbb R^d\to[0,\infty)$ with integral $1$ over $\mathbb R^d$ . Suppose that $$ \int_{\mathbb R^d}\phi(x)\,f_n(x)\,d x\,\to\,\int_{\mathbb R^d}\phi(x)\,f(x)\,d x $$ as $n\to\infty$ for all $\phi:\mathbb R^d\to\mathbb R$ continuous and bounded. Can I say that there exists a strictly increasing sequence $(m_n)_{n\in\mathbb N}$ such that $$f_{m_n}(x)\to f(x) \textrm{ for a.e. }x\in\mathbb R^d$$ as $n\to\infty$ ? I know this would be the case for convergence in total variation, since it is equivalent to convergence of densities in $L^1$ and so there exists a subsequence which is convergent almost everywhere. Is weak convergence sufficient?","This question already has an answer here : Does weak convergence in $L^2$ implies convergence almost everywhere along subsequence? (1 answer) Closed 2 years ago . Let with integral over . Suppose that as for all continuous and bounded. Can I say that there exists a strictly increasing sequence such that as ? I know this would be the case for convergence in total variation, since it is equivalent to convergence of densities in and so there exists a subsequence which is convergent almost everywhere. Is weak convergence sufficient?","f_n,f:\mathbb R^d\to[0,\infty) 1 \mathbb R^d  \int_{\mathbb R^d}\phi(x)\,f_n(x)\,d x\,\to\,\int_{\mathbb R^d}\phi(x)\,f(x)\,d x  n\to\infty \phi:\mathbb R^d\to\mathbb R (m_n)_{n\in\mathbb N} f_{m_n}(x)\to f(x) \textrm{ for a.e. }x\in\mathbb R^d n\to\infty L^1","['real-analysis', 'functional-analysis', 'probability-theory', 'convergence-divergence', 'weak-convergence']"
81,"Show that $x_n \notin \overline { \text{span} (x_1,\dots, x_{n-1},x_{n+1},x_{n+2}, ...)}$",Show that,"x_n \notin \overline { \text{span} (x_1,\dots, x_{n-1},x_{n+1},x_{n+2}, ...)}","Let X be a banach spaces and $(x_n)_{n\geq1}$ be a Schauder basis in $X$ . $1)$ $\forall x\in X,$ $x=\sum_{n=1}^\infty \lambda_n x_n$ and for all $n\geq 1$ , we define $x_n^*=\lambda_n$ , show that $x_n^* \in X^*$ . $2)$ And show that $x_n \notin \overline { \text{span} (x_1,\dots, x_{n-1},x_{n+1},x_{n+2}, ...)}$ I can manage $(1)$ but help me for $(2)$ please thank you.","Let X be a banach spaces and be a Schauder basis in . and for all , we define , show that . And show that I can manage but help me for please thank you.","(x_n)_{n\geq1} X 1) \forall x\in X, x=\sum_{n=1}^\infty \lambda_n x_n n\geq 1 x_n^*=\lambda_n x_n^* \in X^* 2) x_n \notin \overline { \text{span} (x_1,\dots, x_{n-1},x_{n+1},x_{n+2}, ...)} (1) (2)","['functional-analysis', 'banach-spaces']"
82,Proof that $f_{n} = \chi_{\Omega_{n}}f \to f$ in $L^{2}$,Proof that  in,f_{n} = \chi_{\Omega_{n}}f \to f L^{2},"Let $f: \mathbb{R} \to \mathbb{C}$ be an unbounded measurable function and let $\mu$ be a finite measure on the Borel $\sigma$ -algebra $\mathbb{B}(\mathbb{R})$ such that: $$\int_{\mathbb{R}}|f(x)|^{2}d\mu(x) < +\infty$$ For each $n \in \mathbb{N}$ , let $\Omega_{n} := \{x \in \mathbb{R}: |f(x)| \le n\}$ and $\chi_{\Omega_{n}}$ its characteristic function, i.e. $\chi_{\Omega_{n}}(x) = 1 $ if $x \in \Omega_{n}$ and zero otherwise. I'm trying to prove that the sequence of functions $f_{n} := \chi_{\Omega_{n}}f$ is Cauchy and converges in $L^{2}(\mathbb{R},\mu)$ to $f$ . My work so far is as follows: $$||f_{n}-f_{m}||^{2} = \int_{\mathbb{R}}|\chi_{\Omega_{n}}f-\chi_{\Omega_{m}}f|^{2}d\mu = \int_{\mathbb{R}}|\chi_{\Omega_{n}}-\chi_{\Omega_{m}}|^{2}|f|^{2}d\mu$$ Now, assuming $m \le n$ , we notice that $\Omega_{m}\subseteq \Omega_{n}$ , so that $|\chi_{\Omega_{n}}-\chi_{\Omega_{m}}| = \chi_{\Omega_{n}}-\chi_{\Omega_{m}} = \chi_{\Omega_{n}\setminus \Omega_{m}}$ . Hence, $$||f_{n}-f_{m}||^{2} = \int_{\mathbb{R}}\chi_{\Omega_{n}\setminus\Omega_{m}}|f|^{2}d\mu = \int_{\Omega_{n}\setminus\Omega_{m}}|f|^{2}d\mu$$ But I'm stuck here. How can I prove this is Cauchy?","Let be an unbounded measurable function and let be a finite measure on the Borel -algebra such that: For each , let and its characteristic function, i.e. if and zero otherwise. I'm trying to prove that the sequence of functions is Cauchy and converges in to . My work so far is as follows: Now, assuming , we notice that , so that . Hence, But I'm stuck here. How can I prove this is Cauchy?","f: \mathbb{R} \to \mathbb{C} \mu \sigma \mathbb{B}(\mathbb{R}) \int_{\mathbb{R}}|f(x)|^{2}d\mu(x) < +\infty n \in \mathbb{N} \Omega_{n} := \{x \in \mathbb{R}: |f(x)| \le n\} \chi_{\Omega_{n}} \chi_{\Omega_{n}}(x) = 1  x \in \Omega_{n} f_{n} := \chi_{\Omega_{n}}f L^{2}(\mathbb{R},\mu) f ||f_{n}-f_{m}||^{2} = \int_{\mathbb{R}}|\chi_{\Omega_{n}}f-\chi_{\Omega_{m}}f|^{2}d\mu = \int_{\mathbb{R}}|\chi_{\Omega_{n}}-\chi_{\Omega_{m}}|^{2}|f|^{2}d\mu m \le n \Omega_{m}\subseteq \Omega_{n} |\chi_{\Omega_{n}}-\chi_{\Omega_{m}}| = \chi_{\Omega_{n}}-\chi_{\Omega_{m}} = \chi_{\Omega_{n}\setminus \Omega_{m}} ||f_{n}-f_{m}||^{2} = \int_{\mathbb{R}}\chi_{\Omega_{n}\setminus\Omega_{m}}|f|^{2}d\mu = \int_{\Omega_{n}\setminus\Omega_{m}}|f|^{2}d\mu","['functional-analysis', 'analysis', 'measure-theory', 'lp-spaces']"
83,Is the differential of a functional norm-dependent?,Is the differential of a functional norm-dependent?,,"A functional $J: (\text{normed function space}) \to \mathbb{R}$ is said to be differentiable at $f$ if there exists a linear functional $\phi$ such that $$\forall h: J(f + h) - J(f) = \phi(h) + r(h) ||h||$$ where $r(h)$ is a functional which goes to $0$ as $||h|| \to 0$ . My questions is: does the existence, and value of, the derivative depend on the norm $||\cdot||$ ? My intuition is that both the existence and value are norm-dependent. As a special case though, I think that if two norms are equivalent, then the existence and value of the derivatives match for both norms. That is, suppose $||\cdot||_0$ and $|| \cdot ||_1$ are two norms with $$c|| \cdot ||_1 \le || \cdot ||_0 \le C || \cdot ||_1$$ for some positive constants $c, C$ and suppose that $J$ is a functional differentiable at $f$ w.r.t. $|| \cdot ||_1$ . Then we can write $$\forall h: J(f + h) - J(f) = \phi(h) + r(h) ||h||_1$$ with $\phi$ linear and $r(h) \to 0$ as $||h||_1 \to 0$ . Fix $\epsilon > 0$ . There exists a $\delta > 0$ such that $||h||_1 < \delta \implies ||r(h)||_1 < \frac{\epsilon}{C}$ . But then $\frac 1C ||r(h)||_0 \le \frac {\epsilon}{C}$ , so $||r(h)||_0 \le \epsilon$ . Thus $J$ is differentiable at $f$ w.r.t. $|| \cdot ||_0$ and has the same derivative. Another special case is that a linear functional $J$ has derivative $J$ at every point, w.r.t. any norm.","A functional is said to be differentiable at if there exists a linear functional such that where is a functional which goes to as . My questions is: does the existence, and value of, the derivative depend on the norm ? My intuition is that both the existence and value are norm-dependent. As a special case though, I think that if two norms are equivalent, then the existence and value of the derivatives match for both norms. That is, suppose and are two norms with for some positive constants and suppose that is a functional differentiable at w.r.t. . Then we can write with linear and as . Fix . There exists a such that . But then , so . Thus is differentiable at w.r.t. and has the same derivative. Another special case is that a linear functional has derivative at every point, w.r.t. any norm.","J: (\text{normed function space}) \to \mathbb{R} f \phi \forall h: J(f + h) - J(f) = \phi(h) + r(h) ||h|| r(h) 0 ||h|| \to 0 ||\cdot|| ||\cdot||_0 || \cdot ||_1 c|| \cdot ||_1 \le || \cdot ||_0 \le C || \cdot ||_1 c, C J f || \cdot ||_1 \forall h: J(f + h) - J(f) = \phi(h) + r(h) ||h||_1 \phi r(h) \to 0 ||h||_1 \to 0 \epsilon > 0 \delta > 0 ||h||_1 < \delta \implies ||r(h)||_1 < \frac{\epsilon}{C} \frac 1C ||r(h)||_0 \le \frac {\epsilon}{C} ||r(h)||_0 \le \epsilon J f || \cdot ||_0 J J","['functional-analysis', 'analysis', 'calculus-of-variations']"
84,Computing the eigenvalues of the precision operator $C_0^{-1}=\eta(-\triangle)^p+KI$,Computing the eigenvalues of the precision operator,C_0^{-1}=\eta(-\triangle)^p+KI,"Consider $L_2(\mathbb{T})$ with the basis $$\phi_{2k}(x)=\sqrt{2}\cos(2\pi k x)\\ \phi_{2k-1}(x)=\sqrt{2}\sin(2\pi k x)$$ for $k\in\mathbb{N}$ . The functions $\phi_k$ belong to the domain $H^{2p}$ of the operator $C_0^{-1}=\eta(-\triangle)^p+KI$ where $\triangle$ is the Lapalcian and I the identity,K and $\eta$ are constants. A simple application of the operator on the basis above yields: $$C_0^{-1}\phi_{2k-1}=\eta((4\pi^2k^2)^p+k)\phi_{2k}\\C_0^{-1}\phi_{2k}=\eta((4\pi^2k^2)^p+K)\phi_{2k-1} $$ It follows that $C_0$ is the operator on $L_2(\mathbb{T})$ which is diagonalized by the basis of $\phi_k$ , with eigenvalues: $$\lambda_k=\eta \left(\left( 4\pi^2\left[\frac{k}{2}\right]^2\right)^p +K\right)^{-1} $$ I am not understanding how the eigenvalues are computed in order to diagonalize the operator. I cannot visualize a matrix that contains the operator. Question: How do I compute the eigenvalues $\lambda_k$ ? Thanks in advance!","Consider with the basis for . The functions belong to the domain of the operator where is the Lapalcian and I the identity,K and are constants. A simple application of the operator on the basis above yields: It follows that is the operator on which is diagonalized by the basis of , with eigenvalues: I am not understanding how the eigenvalues are computed in order to diagonalize the operator. I cannot visualize a matrix that contains the operator. Question: How do I compute the eigenvalues ? Thanks in advance!",L_2(\mathbb{T}) \phi_{2k}(x)=\sqrt{2}\cos(2\pi k x)\\ \phi_{2k-1}(x)=\sqrt{2}\sin(2\pi k x) k\in\mathbb{N} \phi_k H^{2p} C_0^{-1}=\eta(-\triangle)^p+KI \triangle \eta C_0^{-1}\phi_{2k-1}=\eta((4\pi^2k^2)^p+k)\phi_{2k}\\C_0^{-1}\phi_{2k}=\eta((4\pi^2k^2)^p+K)\phi_{2k-1}  C_0 L_2(\mathbb{T}) \phi_k \lambda_k=\eta \left(\left( 4\pi^2\left[\frac{k}{2}\right]^2\right)^p +K\right)^{-1}  \lambda_k,"['linear-algebra', 'functional-analysis', 'eigenfunctions']"
85,Complemented set in X***,Complemented set in X***,,"Let X be a normed space, then prove that the image of $J:X^* \rightarrow X^{***}$ is a complemented subset of $X^{***}$ My attempt: I know that the image of the canonical embedding will be closed in $X^{***}$ but I can't see how to show it's a complemented subspace, though of proving that the codimension of $Im(J)$ has finite dimension.","Let X be a normed space, then prove that the image of is a complemented subset of My attempt: I know that the image of the canonical embedding will be closed in but I can't see how to show it's a complemented subspace, though of proving that the codimension of has finite dimension.",J:X^* \rightarrow X^{***} X^{***} X^{***} Im(J),"['functional-analysis', 'banach-spaces', 'normed-spaces']"
86,Question on the evaluation functional in $L^p$,Question on the evaluation functional in,L^p,"I know that for $1 \leq p < \infty$ we have $C_c(X)$ dense in $L^p(X,\mu)$ . In $L^p(X,\mu)$ the evaluation functional is not bounded, but in $C_c(X)$ it is. So if I define $T_x : C_c(X) \to \mathbb{R}$ as $T_x f = f(x)$ for $x \in X$ I can extend this functional to $L^p(X,\mu)$ using the Hahn Banach (HB) theorem. To make sure I understand how to possibly apply HB I wonder: Is my application correct? Am I right when I say that the extension if $T_x$ is bounded? Thank you.","I know that for we have dense in . In the evaluation functional is not bounded, but in it is. So if I define as for I can extend this functional to using the Hahn Banach (HB) theorem. To make sure I understand how to possibly apply HB I wonder: Is my application correct? Am I right when I say that the extension if is bounded? Thank you.","1 \leq p < \infty C_c(X) L^p(X,\mu) L^p(X,\mu) C_c(X) T_x : C_c(X) \to \mathbb{R} T_x f = f(x) x \in X L^p(X,\mu) T_x",['functional-analysis']
87,Exercise 7 page 93 Functional Analysis book of Conway,Exercise 7 page 93 Functional Analysis book of Conway,,"The following is Exercise 7 page 93 in Functional Analysis book of Conway: Let $1 \le p \le \infty$ and suppose $(a_{ij})$ is a matrix such that $(Af)(i) = \sum_{j=1}^{\infty} a_{ij} f(j)$ defines an element $Af$ of $\ell^p$ for every $f$ in $\ell^p$ . Show that $A \in \mathcal{B}(\ell^p)$ . Case $p=\infty$ : If $f(j)$ is such that $||f(j)||_{\infty} < \infty$ and $\sum_{j=1}^{\infty} a_{ij} f(j) < \infty $ how to show that $(Af)(i)$ is bounded so that A maps $\ell^{\infty}$ to $\ell^{\infty}$ ? Case $1 \le p < \infty$ : For this case same approach I think but this time we use Holder's inequality I suppose? NOTE : I looking for a solution based on the Uniform Boundedness Principle, a solution without using the Closed Graph Theorem. The answer in here has just one sentence mentioning that the result could be proved using Baire Category Theorem, but such mention is not really an answer. The answer itself is based on applying the Closed Graph Theorem.","The following is Exercise 7 page 93 in Functional Analysis book of Conway: Let and suppose is a matrix such that defines an element of for every in . Show that . Case : If is such that and how to show that is bounded so that A maps to ? Case : For this case same approach I think but this time we use Holder's inequality I suppose? NOTE : I looking for a solution based on the Uniform Boundedness Principle, a solution without using the Closed Graph Theorem. The answer in here has just one sentence mentioning that the result could be proved using Baire Category Theorem, but such mention is not really an answer. The answer itself is based on applying the Closed Graph Theorem.",1 \le p \le \infty (a_{ij}) (Af)(i) = \sum_{j=1}^{\infty} a_{ij} f(j) Af \ell^p f \ell^p A \in \mathcal{B}(\ell^p) p=\infty f(j) ||f(j)||_{\infty} < \infty \sum_{j=1}^{\infty} a_{ij} f(j) < \infty  (Af)(i) \ell^{\infty} \ell^{\infty} 1 \le p < \infty,['functional-analysis']
88,Find the domain on which $\log(z^2+9)$ is analytic.,Find the domain on which  is analytic.,\log(z^2+9),"I have the following function $$f(z)=\log(z^2+9)$$ I need to find the set on which this function is analytic. So far I know that $\log(z)$ is analytic in $D= \left \{ z \in \mathbb{C} | z \notin (-\infty, 0] \right \}$ . So, I understand that for my function $D= \left \{ z \in \mathbb{C} | z^2+9 \notin (-\infty, 0] \right \} = \left \{ z \in \mathbb{C} | z^2 \notin (-\infty, -9] \right \}$ . How should I continue?","I have the following function I need to find the set on which this function is analytic. So far I know that is analytic in . So, I understand that for my function . How should I continue?","f(z)=\log(z^2+9) \log(z) D= \left \{ z \in \mathbb{C} | z \notin (-\infty, 0] \right \} D= \left \{ z \in \mathbb{C} | z^2+9 \notin (-\infty, 0] \right \} = \left \{ z \in \mathbb{C} | z^2 \notin (-\infty, -9] \right \}","['complex-analysis', 'functional-analysis', 'analytic-functions']"
89,Finding the norm of a bounded linear operator,Finding the norm of a bounded linear operator,,"I've been trying to find the norm of the linear operator $(Tf)(x) = \int_{-1}^1 xyf(y)dy$ , where $T:L_{\infty}(-1,1) \rightarrow L_{1}(-1,1)$ and $f\in L_{\infty}(-1,1)$ . From definition the norm $||T||$ is defined as $\sup_{f\neq 0}\frac{||Tf||}{||f||_{\infty}}$ , where $||f||_{\infty}$ is the essential supremum of function $f$ over $(-1,1)$ . I've already shown that $||T||$ is bounded by $1$ . In order to find the lower bound of $||T||$ I've been trying to find some sequence of functions that show $\sup_{f\neq 0}\frac{||Tf||}{||f||_{\infty}} \geq \sup_{n}\frac{||Tf_{n}||}{||f{n}||_{\infty}}=1$ but to no avail. Thanks in advance for all the answers.","I've been trying to find the norm of the linear operator , where and . From definition the norm is defined as , where is the essential supremum of function over . I've already shown that is bounded by . In order to find the lower bound of I've been trying to find some sequence of functions that show but to no avail. Thanks in advance for all the answers.","(Tf)(x) = \int_{-1}^1 xyf(y)dy T:L_{\infty}(-1,1) \rightarrow L_{1}(-1,1) f\in L_{\infty}(-1,1) ||T|| \sup_{f\neq 0}\frac{||Tf||}{||f||_{\infty}} ||f||_{\infty} f (-1,1) ||T|| 1 ||T|| \sup_{f\neq 0}\frac{||Tf||}{||f||_{\infty}} \geq \sup_{n}\frac{||Tf_{n}||}{||f{n}||_{\infty}}=1","['functional-analysis', 'linear-transformations', 'normed-spaces']"
90,Do the seminorms $|\int_{\frac{1}{n-1}}^\frac{1}{n} f(x) dx|$ separate points?,Do the seminorms  separate points?,|\int_{\frac{1}{n-1}}^\frac{1}{n} f(x) dx|,"Let's define family of seminorms: $$p_n(f)  = |\int_{\frac{1}{n+1}}^\frac{1}{n} f(x) dx|$$ on $C([0, 1])$ I want to check whether this norm family of seminorms separates points. i.e. I have to check: $$(p_n(f) = 0 )\Rightarrow f = 0$$ My work so far $$p_k(f) = |\int_{\frac{1}{k+1}}^{\frac{1}{k}} f(x) dx| = 0 \Rightarrow \int_{\frac{1}{k+1}}^{\frac{1}{k}} f(x) dx = 0$$ Now I wanted to take function defined in the following way: This function completely fits our example - area under the curve on the interval $[\frac{1}{k+1}, \frac{1}{k}]$ is $0$ . But I realized that it's different function for different $k$ (definition of this function depends on k). I tried to find another function that is $k -$ independent however I wasn't able to. I was also trying to prove that it has to be separable (that $f \equiv 0$ ) but also I end up with nothing. Could you please give me hint what's the direction I should follow?",Let's define family of seminorms: on I want to check whether this norm family of seminorms separates points. i.e. I have to check: My work so far Now I wanted to take function defined in the following way: This function completely fits our example - area under the curve on the interval is . But I realized that it's different function for different (definition of this function depends on k). I tried to find another function that is independent however I wasn't able to. I was also trying to prove that it has to be separable (that ) but also I end up with nothing. Could you please give me hint what's the direction I should follow?,"p_n(f)  = |\int_{\frac{1}{n+1}}^\frac{1}{n} f(x) dx| C([0, 1]) (p_n(f) = 0 )\Rightarrow f = 0 p_k(f) = |\int_{\frac{1}{k+1}}^{\frac{1}{k}} f(x) dx| = 0 \Rightarrow \int_{\frac{1}{k+1}}^{\frac{1}{k}} f(x) dx = 0 [\frac{1}{k+1}, \frac{1}{k}] 0 k k - f \equiv 0","['real-analysis', 'integration', 'functional-analysis', 'normed-spaces']"
91,"book recommendation for functions, function spaces, properties, approximation, embeddings, densensess etc.","book recommendation for functions, function spaces, properties, approximation, embeddings, densensess etc.",,"I am trying to learn more about function spaces, properties and structure of the functions in each space but also properties and structures of the function spaces themselves , with different metrics maybe, embeddings and dense embeddings (with the classical or even different metrics for each space), and approximation arguments for each space. This would include, spaces of functions on manifolds,on $\mathbb{R}$ , on $\mathbb{R}$ , on $\mathbb{R}^n$ , on $\mathbb{C}^n$ , on subsets of manifolds or $\mathbb{R}^n$ or $\mathbb{C}^n$ , even more general metric or topological sets. Spaces of differential functions, of continuous functions (even almost everywhere differential or alamost everywhere continuous etc.), integrable functions, covex functions, real analytic functions, holomorphic functions, Sobolev spaces etc. It would be really nice, if your recommendation are from the more classical to the more general case. For example I think it would be more constructive for me if I'd start with some more classical spaces, for example spaces on $\mathbb{R}^n$ and then go to manifolds. But my reasoning for that could be of course false. Furthermore, it could be books, lecture notes or whatever youy may think would be helpful. Lastly, the more theorems, propositions, properties etc. the better, but I would also like to see many examples, useful methods and tricks, intuitional approaches and explanations and many exercises, if possible. Of course not only the ""trivial"" ones . I have basic (to maybe somewhat advanced knowledge for some of them) knowledge of one-dimensional analysis, multivariable analysis, cmplex analysis, measure theory, functional analysis, Fourier analysis, Banach algebras, operator theory, spectral theory, Sobolev spaces etc. Some books I have already in mind are for example, Differential Topology, Hirsch, Theory of Function Spaces, Triebel, Measure Theory and Fine Properties of Functions, Evans & Gariepy It is probably much to ask and maybe very vague what I am looking for but any help and recommendations are welcome. Thank you!","I am trying to learn more about function spaces, properties and structure of the functions in each space but also properties and structures of the function spaces themselves , with different metrics maybe, embeddings and dense embeddings (with the classical or even different metrics for each space), and approximation arguments for each space. This would include, spaces of functions on manifolds,on , on , on , on , on subsets of manifolds or or , even more general metric or topological sets. Spaces of differential functions, of continuous functions (even almost everywhere differential or alamost everywhere continuous etc.), integrable functions, covex functions, real analytic functions, holomorphic functions, Sobolev spaces etc. It would be really nice, if your recommendation are from the more classical to the more general case. For example I think it would be more constructive for me if I'd start with some more classical spaces, for example spaces on and then go to manifolds. But my reasoning for that could be of course false. Furthermore, it could be books, lecture notes or whatever youy may think would be helpful. Lastly, the more theorems, propositions, properties etc. the better, but I would also like to see many examples, useful methods and tricks, intuitional approaches and explanations and many exercises, if possible. Of course not only the ""trivial"" ones . I have basic (to maybe somewhat advanced knowledge for some of them) knowledge of one-dimensional analysis, multivariable analysis, cmplex analysis, measure theory, functional analysis, Fourier analysis, Banach algebras, operator theory, spectral theory, Sobolev spaces etc. Some books I have already in mind are for example, Differential Topology, Hirsch, Theory of Function Spaces, Triebel, Measure Theory and Fine Properties of Functions, Evans & Gariepy It is probably much to ask and maybe very vague what I am looking for but any help and recommendations are welcome. Thank you!",\mathbb{R} \mathbb{R} \mathbb{R}^n \mathbb{C}^n \mathbb{R}^n \mathbb{C}^n \mathbb{R}^n,"['real-analysis', 'complex-analysis', 'functional-analysis', 'functions', 'book-recommendation']"
92,Bounded Sobolev sequence together with convergence in Lebesgue space implies convergence in intermediate Sobolev spaces,Bounded Sobolev sequence together with convergence in Lebesgue space implies convergence in intermediate Sobolev spaces,,"I am trying to understand the proof of a theorem, but I just can't seem to wrap my head around this one step: We have a sequence of functions $(f_i)_{i \in \mathbb{N}}$ that are bounded in the Sobolev space $W^{k,p}$ , where $k \in \mathbb{N}$ , $p \geq 2$ , i.e. $\|f_i\|_{W^{k,p}} \leq C$ for some constant $C$ and all $i$ . We also know that $f_i$ converges to some $g$ in $L^p(\mathbb{R})$ and this $g$ is also an element of $W^{k,p}$ . The proof now just claims, that using standard properties of Sobolev spaces, this bound together with the convergence in $L^p$ implies the convergence $f_i \to g$ in all intermediate spaces $W^{k',p}$ , where $k' \in (0,k)$ . I am rather new to Sobolev spaces, so I am quite confused as to what these standard properties might be. I tried to read up in the book on Sobolev spaces by Adams, but I could not really find anything helpful. To be honest, I have yet to understand what norms these intermediate spaces use. I also tried to first understand the statement asuming $k'$ is an integer, because in this case I am more familiar with the spaces, but I was also unsuccessful. Do you have ideas on how to approach this task? Any help is appreciated","I am trying to understand the proof of a theorem, but I just can't seem to wrap my head around this one step: We have a sequence of functions that are bounded in the Sobolev space , where , , i.e. for some constant and all . We also know that converges to some in and this is also an element of . The proof now just claims, that using standard properties of Sobolev spaces, this bound together with the convergence in implies the convergence in all intermediate spaces , where . I am rather new to Sobolev spaces, so I am quite confused as to what these standard properties might be. I tried to read up in the book on Sobolev spaces by Adams, but I could not really find anything helpful. To be honest, I have yet to understand what norms these intermediate spaces use. I also tried to first understand the statement asuming is an integer, because in this case I am more familiar with the spaces, but I was also unsuccessful. Do you have ideas on how to approach this task? Any help is appreciated","(f_i)_{i \in \mathbb{N}} W^{k,p} k \in \mathbb{N} p \geq 2 \|f_i\|_{W^{k,p}} \leq C C i f_i g L^p(\mathbb{R}) g W^{k,p} L^p f_i \to g W^{k',p} k' \in (0,k) k'","['functional-analysis', 'sobolev-spaces', 'fractional-sobolev-spaces']"
93,"Is the sine operator on $L^2[0,1]$ Fréchet differentiable or not and why?",Is the sine operator on  Fréchet differentiable or not and why?,"L^2[0,1]","This problem has given me some trouble. Let $F$ be the operator on $L^2[0,1]$ defined by $F(g)(t)=\sin g(t)$ . I'm trying to determine whether or not $F$ is (Fréchet) differentiable in that space. I know that it is in $C[0,1]$ because I have seen this one before. The notion if Fréchet derivative is a direct expansion of the Gâteaux derivative: $f : U \to Y$ where $U\subset X$ and $X, Y$ normed spaces is called (Fréchet) differentiable at $u\in U$ if there exists a bounded linear operator $T$ from $X$ to $Y$ such that for $h\to 0$ we have $$ \frac{f(u+hv)-f(u)}{h} \to Tv $$ uniformly for all $v\in B_X$ , e.g. in the closed unit ball in $X$ . So this is basically Gâteax differentiabilty with added uniformity of convergence. At first, I couldn't really make sense of the difference, but the example here helped me a great deal with that. I checked for Gâteaux differentiability and after some contortions and the realization that the MVT should be applied I figured out the derivative in $g$ to be $T(f)(t)=\cos(g(t))f(t)$ . However, I can't come up with an argument as to whether Fréchet differentiability holds true in this case. If the Fréchet derivative exists, it is equal to $T$ . The point in question should be the null function. But how to proceed from here?","This problem has given me some trouble. Let be the operator on defined by . I'm trying to determine whether or not is (Fréchet) differentiable in that space. I know that it is in because I have seen this one before. The notion if Fréchet derivative is a direct expansion of the Gâteaux derivative: where and normed spaces is called (Fréchet) differentiable at if there exists a bounded linear operator from to such that for we have uniformly for all , e.g. in the closed unit ball in . So this is basically Gâteax differentiabilty with added uniformity of convergence. At first, I couldn't really make sense of the difference, but the example here helped me a great deal with that. I checked for Gâteaux differentiability and after some contortions and the realization that the MVT should be applied I figured out the derivative in to be . However, I can't come up with an argument as to whether Fréchet differentiability holds true in this case. If the Fréchet derivative exists, it is equal to . The point in question should be the null function. But how to proceed from here?","F L^2[0,1] F(g)(t)=\sin g(t) F C[0,1] f : U \to Y U\subset X X, Y u\in U T X Y h\to 0 
\frac{f(u+hv)-f(u)}{h} \to Tv
 v\in B_X X g T(f)(t)=\cos(g(t))f(t) T","['functional-analysis', 'banach-spaces', 'nonlinear-analysis', 'frechet-derivative']"
94,"To what extent it is necessary to assume ""complete regularity"" on $X$ to induce this locally convex topology on $C(X)$?","To what extent it is necessary to assume ""complete regularity"" on  to induce this locally convex topology on ?",X C(X),"I found the following example in Conway's Functional Analysis Book: Suppose $X$ is a completely regular space and let $C(X)=$ all continuous functions from $X$ into $\Bbb{C}$ . If $K$ is a compact subset of $X$ , define $p_K(f)=\sup \{|f(x)|: x \in K\}$ . Then $\{p_K: K \text{ compact in }X \}$ is a family of seminorms that makes $C(X)$ into a LCS. Now for any space $X$ (not necessarily completely regular), $C(X)$ is a vector space. So, once we prove that family $\{p_K: K \text{ compact in }X \}$ of seminorms separates points on $C(X)$ then it would induce a locally convex topology on $C(X)$ . Now for $f\in C(X)\setminus \{0\}$ there is $x_0\in X$ so that $f(x_0)\ne 0$ . But then $p_{\{x_0\}}(f)=|f(x_0)| \ne 0$ . This implies that family of seminorms separates points on $C(X)$ ( we didn't use ""complete regularity"" !) and hence define a locally convex topology on $C(X)$ . My question: Isn't the case that  the space $C(X)$ for any topological space $X$ , not necessarily completely regular, satisfies the assertion of that example with the same family of seminorms? If so then is there any specific reason for restricting our attention to ""completely regular"" spaces $X$ ?? I mean, I know that ""completely regular"" spaces are ""nicer"" than general topological spaces, but can anyone mention some important property/result (related to this locally convex topology) on $C(X)$ that wouldn't hold without the ""complete regularity"" on $X$ . I want to realize the importance of assuming ""complete regularity"" condition in this case. Thanks","I found the following example in Conway's Functional Analysis Book: Suppose is a completely regular space and let all continuous functions from into . If is a compact subset of , define . Then is a family of seminorms that makes into a LCS. Now for any space (not necessarily completely regular), is a vector space. So, once we prove that family of seminorms separates points on then it would induce a locally convex topology on . Now for there is so that . But then . This implies that family of seminorms separates points on ( we didn't use ""complete regularity"" !) and hence define a locally convex topology on . My question: Isn't the case that  the space for any topological space , not necessarily completely regular, satisfies the assertion of that example with the same family of seminorms? If so then is there any specific reason for restricting our attention to ""completely regular"" spaces ?? I mean, I know that ""completely regular"" spaces are ""nicer"" than general topological spaces, but can anyone mention some important property/result (related to this locally convex topology) on that wouldn't hold without the ""complete regularity"" on . I want to realize the importance of assuming ""complete regularity"" condition in this case. Thanks",X C(X)= X \Bbb{C} K X p_K(f)=\sup \{|f(x)|: x \in K\} \{p_K: K \text{ compact in }X \} C(X) X C(X) \{p_K: K \text{ compact in }X \} C(X) C(X) f\in C(X)\setminus \{0\} x_0\in X f(x_0)\ne 0 p_{\{x_0\}}(f)=|f(x_0)| \ne 0 C(X) C(X) C(X) X X C(X) X,"['general-topology', 'functional-analysis', 'vector-spaces', 'topological-vector-spaces', 'locally-convex-spaces']"
95,The regularity of a piecewise constant function in Sobolev spaces,The regularity of a piecewise constant function in Sobolev spaces,,"I want to know what the ""highest"" regularity is for a piecewise constant function. For example: $$ f(x)=\left\{\begin{align*} &1, & x\in [0,1),\\ &0, & x\in (-1,0).\end{align*}\right. $$ We know that $f\in L^p(\Omega)$ where $\Omega=(-1,1)$ and $p\geq 1$ , but $f\not\in W^{1,p}(\Omega)$ ( $W^{k,p}$ denotes the Sobolev space whose functions and their $k$ -th derivatives are both in $L^p$ space) since $f(0^+)\not=f(0^-)$ . Now, I am wondering may the function $f(x)$ has any higher regularities? such as $f\in W^{\varepsilon,p}(\Omega)$ with $0 < \varepsilon < \frac12$ (or $0<\varepsilon <1$ )? If this is right, how to prove it?","I want to know what the ""highest"" regularity is for a piecewise constant function. For example: We know that where and , but ( denotes the Sobolev space whose functions and their -th derivatives are both in space) since . Now, I am wondering may the function has any higher regularities? such as with (or )? If this is right, how to prove it?"," f(x)=\left\{\begin{align*} &1, & x\in [0,1),\\ &0, & x\in (-1,0).\end{align*}\right.  f\in L^p(\Omega) \Omega=(-1,1) p\geq 1 f\not\in W^{1,p}(\Omega) W^{k,p} k L^p f(0^+)\not=f(0^-) f(x) f\in W^{\varepsilon,p}(\Omega) 0 < \varepsilon < \frac12 0<\varepsilon <1","['real-analysis', 'functional-analysis', 'sobolev-spaces', 'regularity-theory-of-pdes', 'piecewise-continuity']"
96,Cayley Transform of self-adjoint operator is unitary,Cayley Transform of self-adjoint operator is unitary,,"If $A$ is a self-adjoint operator, I want to show that the Cayley transform of $A$ defined as the operator $U=(A-iI)(A+iI)^{-1}$ is unitary. Here's my trial: For all $x,y \in \mathcal{H}$ , keeping in mind that $A$ and $I$ have adjoints: $$\langle Ux,Uy \rangle = \langle U^*Ux,y \rangle$$ All i need to show now is that $U$ is an Isometry, i.e, $U^*=U^{-1}$ and I'm all set (right?). Therefore: $$ U^*=[(A-iI)(A+iI)^{-1}]^* = [(A+iI)^{-1}]^*(A-iI)^*$$ But i cannot go further because $(A+iI)$ is not self-adjoint, so I can't switch the inverse and the adjoint operations. Does somenone have some tip on how to get the inverse of this operator or an alternative way to show that $U^*=U^{-1}$ ? all the help will be appreciated.","If is a self-adjoint operator, I want to show that the Cayley transform of defined as the operator is unitary. Here's my trial: For all , keeping in mind that and have adjoints: All i need to show now is that is an Isometry, i.e, and I'm all set (right?). Therefore: But i cannot go further because is not self-adjoint, so I can't switch the inverse and the adjoint operations. Does somenone have some tip on how to get the inverse of this operator or an alternative way to show that ? all the help will be appreciated.","A A U=(A-iI)(A+iI)^{-1} x,y \in \mathcal{H} A I \langle Ux,Uy \rangle = \langle U^*Ux,y \rangle U U^*=U^{-1}  U^*=[(A-iI)(A+iI)^{-1}]^* = [(A+iI)^{-1}]^*(A-iI)^* (A+iI) U^*=U^{-1}","['functional-analysis', 'hilbert-spaces', 'self-adjoint-operators']"
97,Definition of weak* convergence in $L^{\infty}$,Definition of weak* convergence in,L^{\infty},"I'm new to functional analysis and have (what I think is) a basic question on the definition of weak* convergence. Let $X$ be a normed linear space with dual $X^{\ast}$ . According to the definition I know, a sequence $(f_n)_{n \in \mathbb{N}}$ in $X^{\ast}$ is said to converge weakly* to $f \in X^{\ast}$ if $f_n$ converges pointwise to $f$ , that is, if $$\forall x \in X, \quad\lim_{n \rightarrow \infty} f_n(x) = f(x).$$ In the special case that $X^{\ast} = L^{\infty}(\Omega,\mu)$ for some measure space $(\Omega,\mathcal{A},\mu)$ , I've stumpled upon a different definition (for example, here and here ): a sequence $(f_n)_{n \in \mathbb{N}}$ in $L^{\infty}(\Omega,\mu)$ converges weakly* to $f \in L^{\infty}(\Omega,\mu)$ if $$\forall g \in L^1(\Omega,\mu), \quad \lim_{n \rightarrow \infty} \int_{\Omega} f_n g \,\text{d}\mu = \int_{\Omega} f g \,\text{d}\mu.$$ My feeling is that both definitions are equivalent because of Riesz' Representation Theorem. Is this correct? If so, how can the equivalence be formally proved?","I'm new to functional analysis and have (what I think is) a basic question on the definition of weak* convergence. Let be a normed linear space with dual . According to the definition I know, a sequence in is said to converge weakly* to if converges pointwise to , that is, if In the special case that for some measure space , I've stumpled upon a different definition (for example, here and here ): a sequence in converges weakly* to if My feeling is that both definitions are equivalent because of Riesz' Representation Theorem. Is this correct? If so, how can the equivalence be formally proved?","X X^{\ast} (f_n)_{n \in \mathbb{N}} X^{\ast} f \in X^{\ast} f_n f \forall x \in X, \quad\lim_{n \rightarrow \infty} f_n(x) = f(x). X^{\ast} = L^{\infty}(\Omega,\mu) (\Omega,\mathcal{A},\mu) (f_n)_{n \in \mathbb{N}} L^{\infty}(\Omega,\mu) f \in L^{\infty}(\Omega,\mu) \forall g \in L^1(\Omega,\mu), \quad \lim_{n \rightarrow \infty} \int_{\Omega} f_n g \,\text{d}\mu = \int_{\Omega} f g \,\text{d}\mu.","['functional-analysis', 'lp-spaces', 'weak-convergence']"
98,Weak convergence in $l^2$ spaces,Weak convergence in  spaces,l^2,"We say that $x_n$ converges weakly to $x$ in normed space $X$ when for any linear and continuous functional $f$ we have $f(x_n) \rightarrow f(x)$ . Let's define sequence $(e_n)$ as $e_n=1$ and $e_j = 0$ for $j \neq n$ . e.g. $$e_2 = (0, 1, 0, 0, 0...)$$ I want to judge on convergence/divergence of $\sqrt{n}e_n$ in $l^2$ space. My work so far We know that every linear and continuous functional in $l^2$ has to be in form $f(x_n) = \sum_{n=1}^\infty x_na_n$ where $a_n \in l^2$ and $x_n \in l^2$ . We are asking is there is a sequence $b_n \in l^2$ that $\sum_{j=1}^\infty a_j\sqrt{j}e_j$ converges to. But when I take $a_j = e_j$ I have that $a_j \in l^2$ and $$\sum_{j =1}^\infty a_j\sqrt{j}e_j = \sum_{j=1}^\infty \sqrt{j}e_j^2 = 0 + 0 +... +\sqrt{n} + 0 +.. = \sqrt{n} \rightarrow \infty$$ So I found linear, continuous functional that doesn't converge. Is this sufficient argument to say that $\sqrt{n}e_n$ diverges in $l^2$ ?","We say that converges weakly to in normed space when for any linear and continuous functional we have . Let's define sequence as and for . e.g. I want to judge on convergence/divergence of in space. My work so far We know that every linear and continuous functional in has to be in form where and . We are asking is there is a sequence that converges to. But when I take I have that and So I found linear, continuous functional that doesn't converge. Is this sufficient argument to say that diverges in ?","x_n x X f f(x_n) \rightarrow f(x) (e_n) e_n=1 e_j = 0 j \neq n e_2 = (0, 1, 0, 0, 0...) \sqrt{n}e_n l^2 l^2 f(x_n) = \sum_{n=1}^\infty x_na_n a_n \in l^2 x_n \in l^2 b_n \in l^2 \sum_{j=1}^\infty a_j\sqrt{j}e_j a_j = e_j a_j \in l^2 \sum_{j =1}^\infty a_j\sqrt{j}e_j = \sum_{j=1}^\infty \sqrt{j}e_j^2 = 0 + 0 +... +\sqrt{n} + 0 +.. = \sqrt{n} \rightarrow \infty \sqrt{n}e_n l^2","['real-analysis', 'functional-analysis', 'convergence-divergence']"
99,Sequence of Nested Projections in an arbitrary Normed Linear Space Converges to the Identity,Sequence of Nested Projections in an arbitrary Normed Linear Space Converges to the Identity,,"I have seen similar questions on this site, most notably this one: Convergence of projections onto a nested sequence of subspaces of a Hilbert space , but they all include the Hilbert space assumption. The following, from Cheney's Analysis for Applied Mathematics , is more general: Let $P_1, P_2, \cdots$ be a sequence of projections on a normed space $X$ . Suppose that $P_{n+1} P_n = P_n$ for all $n$ and that the union of the ranges of these projections is dense in $X$ . Suppose further that $\sup_n \|P_n \| < \infty$ . Prove that $P_n x \rightarrow x, > \forall x \in X.$ [Problem 4.4.3, p.197.] Thus, $X$ is not even assumed to be a Banach space. These are my thoughts on this: First, let $V_n$ be the range of each $P_n$ . Thus, $X = \overline{ \bigcup _{n=1}^\infty V_n}.$ It is easy to demonstrate that $V_i \subset V_j, j>i:$ $$Let \, \, v_i \in V_i \Rightarrow P_iv_i =v_i.\,\, Then\,\, P_{i+1}(P_i(v_i))=P_iv_i = v_i \Rightarrow v_i \in R(P_{i+1})=V_{i+1}.$$ It is also easy to show that if $x \in V_n \Rightarrow, \exists N,\,s.t.\, P_{N \geq n}x =x.$ Thus, if $x\in \bigcup _{n=1}^\infty V_n \subset X$ , then as $n \rightarrow \infty$ , $\exists N$ such that $P_nx=x, \forall n \geq N.$ But what if $x \in X \setminus \bigcup _{n=1}^\infty V_n $ ? I understand that in that case, $x$ would be a limit point of the union of the ranges, due to $ \bigcup _{n=1}^\infty V_n$ being dense in $X$ . I cannot push it much further from here though. I'd appreciate any help or suggestions for better approaches.","I have seen similar questions on this site, most notably this one: Convergence of projections onto a nested sequence of subspaces of a Hilbert space , but they all include the Hilbert space assumption. The following, from Cheney's Analysis for Applied Mathematics , is more general: Let be a sequence of projections on a normed space . Suppose that for all and that the union of the ranges of these projections is dense in . Suppose further that . Prove that [Problem 4.4.3, p.197.] Thus, is not even assumed to be a Banach space. These are my thoughts on this: First, let be the range of each . Thus, It is easy to demonstrate that It is also easy to show that if Thus, if , then as , such that But what if ? I understand that in that case, would be a limit point of the union of the ranges, due to being dense in . I cannot push it much further from here though. I'd appreciate any help or suggestions for better approaches.","P_1, P_2, \cdots X P_{n+1} P_n = P_n n X \sup_n \|P_n \| < \infty P_n x \rightarrow x,
> \forall x \in X. X V_n P_n X = \overline{ \bigcup _{n=1}^\infty V_n}. V_i \subset V_j, j>i: Let \, \, v_i \in V_i \Rightarrow P_iv_i =v_i.\,\, Then\,\, P_{i+1}(P_i(v_i))=P_iv_i = v_i \Rightarrow v_i \in R(P_{i+1})=V_{i+1}. x \in V_n \Rightarrow, \exists N,\,s.t.\, P_{N \geq n}x =x. x\in \bigcup _{n=1}^\infty V_n \subset X n \rightarrow \infty \exists N P_nx=x, \forall n \geq N. x \in X \setminus \bigcup _{n=1}^\infty V_n  x  \bigcup _{n=1}^\infty V_n X","['functional-analysis', 'proof-explanation', 'alternative-proof', 'projection']"
